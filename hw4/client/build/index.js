(() => {
  var __create = Object.create;
  var __defProp = Object.defineProperty;
  var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
  var __getOwnPropNames = Object.getOwnPropertyNames;
  var __getProtoOf = Object.getPrototypeOf;
  var __hasOwnProp = Object.prototype.hasOwnProperty;
  var __markAsModule = (target) => __defProp(target, "__esModule", { value: true });
  var __commonJS = (cb, mod4) => function __require() {
    return mod4 || (0, cb[Object.keys(cb)[0]])((mod4 = { exports: {} }).exports, mod4), mod4.exports;
  };
  var __export = (target, all4) => {
    __markAsModule(target);
    for (var name in all4)
      __defProp(target, name, { get: all4[name], enumerable: true });
  };
  var __reExport = (target, module, desc) => {
    if (module && typeof module === "object" || typeof module === "function") {
      for (let key of __getOwnPropNames(module))
        if (!__hasOwnProp.call(target, key) && key !== "default")
          __defProp(target, key, { get: () => module[key], enumerable: !(desc = __getOwnPropDesc(module, key)) || desc.enumerable });
    }
    return target;
  };
  var __toModule = (module) => {
    return __reExport(__markAsModule(__defProp(module != null ? __create(__getProtoOf(module)) : {}, "default", module && module.__esModule && "default" in module ? { get: () => module.default, enumerable: true } : { value: module, enumerable: true })), module);
  };

  // node_modules/long/src/long.js
  var require_long = __commonJS({
    "node_modules/long/src/long.js"(exports, module) {
      module.exports = Long2;
      var wasm = null;
      try {
        wasm = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([
          0,
          97,
          115,
          109,
          1,
          0,
          0,
          0,
          1,
          13,
          2,
          96,
          0,
          1,
          127,
          96,
          4,
          127,
          127,
          127,
          127,
          1,
          127,
          3,
          7,
          6,
          0,
          1,
          1,
          1,
          1,
          1,
          6,
          6,
          1,
          127,
          1,
          65,
          0,
          11,
          7,
          50,
          6,
          3,
          109,
          117,
          108,
          0,
          1,
          5,
          100,
          105,
          118,
          95,
          115,
          0,
          2,
          5,
          100,
          105,
          118,
          95,
          117,
          0,
          3,
          5,
          114,
          101,
          109,
          95,
          115,
          0,
          4,
          5,
          114,
          101,
          109,
          95,
          117,
          0,
          5,
          8,
          103,
          101,
          116,
          95,
          104,
          105,
          103,
          104,
          0,
          0,
          10,
          191,
          1,
          6,
          4,
          0,
          35,
          0,
          11,
          36,
          1,
          1,
          126,
          32,
          0,
          173,
          32,
          1,
          173,
          66,
          32,
          134,
          132,
          32,
          2,
          173,
          32,
          3,
          173,
          66,
          32,
          134,
          132,
          126,
          34,
          4,
          66,
          32,
          135,
          167,
          36,
          0,
          32,
          4,
          167,
          11,
          36,
          1,
          1,
          126,
          32,
          0,
          173,
          32,
          1,
          173,
          66,
          32,
          134,
          132,
          32,
          2,
          173,
          32,
          3,
          173,
          66,
          32,
          134,
          132,
          127,
          34,
          4,
          66,
          32,
          135,
          167,
          36,
          0,
          32,
          4,
          167,
          11,
          36,
          1,
          1,
          126,
          32,
          0,
          173,
          32,
          1,
          173,
          66,
          32,
          134,
          132,
          32,
          2,
          173,
          32,
          3,
          173,
          66,
          32,
          134,
          132,
          128,
          34,
          4,
          66,
          32,
          135,
          167,
          36,
          0,
          32,
          4,
          167,
          11,
          36,
          1,
          1,
          126,
          32,
          0,
          173,
          32,
          1,
          173,
          66,
          32,
          134,
          132,
          32,
          2,
          173,
          32,
          3,
          173,
          66,
          32,
          134,
          132,
          129,
          34,
          4,
          66,
          32,
          135,
          167,
          36,
          0,
          32,
          4,
          167,
          11,
          36,
          1,
          1,
          126,
          32,
          0,
          173,
          32,
          1,
          173,
          66,
          32,
          134,
          132,
          32,
          2,
          173,
          32,
          3,
          173,
          66,
          32,
          134,
          132,
          130,
          34,
          4,
          66,
          32,
          135,
          167,
          36,
          0,
          32,
          4,
          167,
          11
        ])), {}).exports;
      } catch (e) {
      }
      function Long2(low, high, unsigned) {
        this.low = low | 0;
        this.high = high | 0;
        this.unsigned = !!unsigned;
      }
      Long2.prototype.__isLong__;
      Object.defineProperty(Long2.prototype, "__isLong__", { value: true });
      function isLong(obj) {
        return (obj && obj["__isLong__"]) === true;
      }
      Long2.isLong = isLong;
      var INT_CACHE = {};
      var UINT_CACHE = {};
      function fromInt(value, unsigned) {
        var obj, cachedObj, cache;
        if (unsigned) {
          value >>>= 0;
          if (cache = 0 <= value && value < 256) {
            cachedObj = UINT_CACHE[value];
            if (cachedObj)
              return cachedObj;
          }
          obj = fromBits(value, (value | 0) < 0 ? -1 : 0, true);
          if (cache)
            UINT_CACHE[value] = obj;
          return obj;
        } else {
          value |= 0;
          if (cache = -128 <= value && value < 128) {
            cachedObj = INT_CACHE[value];
            if (cachedObj)
              return cachedObj;
          }
          obj = fromBits(value, value < 0 ? -1 : 0, false);
          if (cache)
            INT_CACHE[value] = obj;
          return obj;
        }
      }
      Long2.fromInt = fromInt;
      function fromNumber(value, unsigned) {
        if (isNaN(value))
          return unsigned ? UZERO : ZERO;
        if (unsigned) {
          if (value < 0)
            return UZERO;
          if (value >= TWO_PWR_64_DBL)
            return MAX_UNSIGNED_VALUE;
        } else {
          if (value <= -TWO_PWR_63_DBL)
            return MIN_VALUE;
          if (value + 1 >= TWO_PWR_63_DBL)
            return MAX_VALUE;
        }
        if (value < 0)
          return fromNumber(-value, unsigned).neg();
        return fromBits(value % TWO_PWR_32_DBL | 0, value / TWO_PWR_32_DBL | 0, unsigned);
      }
      Long2.fromNumber = fromNumber;
      function fromBits(lowBits, highBits, unsigned) {
        return new Long2(lowBits, highBits, unsigned);
      }
      Long2.fromBits = fromBits;
      var pow_dbl = Math.pow;
      function fromString(str, unsigned, radix) {
        if (str.length === 0)
          throw Error("empty string");
        if (str === "NaN" || str === "Infinity" || str === "+Infinity" || str === "-Infinity")
          return ZERO;
        if (typeof unsigned === "number") {
          radix = unsigned, unsigned = false;
        } else {
          unsigned = !!unsigned;
        }
        radix = radix || 10;
        if (radix < 2 || 36 < radix)
          throw RangeError("radix");
        var p3;
        if ((p3 = str.indexOf("-")) > 0)
          throw Error("interior hyphen");
        else if (p3 === 0) {
          return fromString(str.substring(1), unsigned, radix).neg();
        }
        var radixToPower = fromNumber(pow_dbl(radix, 8));
        var result = ZERO;
        for (var i = 0; i < str.length; i += 8) {
          var size2 = Math.min(8, str.length - i), value = parseInt(str.substring(i, i + size2), radix);
          if (size2 < 8) {
            var power = fromNumber(pow_dbl(radix, size2));
            result = result.mul(power).add(fromNumber(value));
          } else {
            result = result.mul(radixToPower);
            result = result.add(fromNumber(value));
          }
        }
        result.unsigned = unsigned;
        return result;
      }
      Long2.fromString = fromString;
      function fromValue(val, unsigned) {
        if (typeof val === "number")
          return fromNumber(val, unsigned);
        if (typeof val === "string")
          return fromString(val, unsigned);
        return fromBits(val.low, val.high, typeof unsigned === "boolean" ? unsigned : val.unsigned);
      }
      Long2.fromValue = fromValue;
      var TWO_PWR_16_DBL = 1 << 16;
      var TWO_PWR_24_DBL = 1 << 24;
      var TWO_PWR_32_DBL = TWO_PWR_16_DBL * TWO_PWR_16_DBL;
      var TWO_PWR_64_DBL = TWO_PWR_32_DBL * TWO_PWR_32_DBL;
      var TWO_PWR_63_DBL = TWO_PWR_64_DBL / 2;
      var TWO_PWR_24 = fromInt(TWO_PWR_24_DBL);
      var ZERO = fromInt(0);
      Long2.ZERO = ZERO;
      var UZERO = fromInt(0, true);
      Long2.UZERO = UZERO;
      var ONE = fromInt(1);
      Long2.ONE = ONE;
      var UONE = fromInt(1, true);
      Long2.UONE = UONE;
      var NEG_ONE = fromInt(-1);
      Long2.NEG_ONE = NEG_ONE;
      var MAX_VALUE = fromBits(4294967295 | 0, 2147483647 | 0, false);
      Long2.MAX_VALUE = MAX_VALUE;
      var MAX_UNSIGNED_VALUE = fromBits(4294967295 | 0, 4294967295 | 0, true);
      Long2.MAX_UNSIGNED_VALUE = MAX_UNSIGNED_VALUE;
      var MIN_VALUE = fromBits(0, 2147483648 | 0, false);
      Long2.MIN_VALUE = MIN_VALUE;
      var LongPrototype = Long2.prototype;
      LongPrototype.toInt = function toInt() {
        return this.unsigned ? this.low >>> 0 : this.low;
      };
      LongPrototype.toNumber = function toNumber2() {
        if (this.unsigned)
          return (this.high >>> 0) * TWO_PWR_32_DBL + (this.low >>> 0);
        return this.high * TWO_PWR_32_DBL + (this.low >>> 0);
      };
      LongPrototype.toString = function toString(radix) {
        radix = radix || 10;
        if (radix < 2 || 36 < radix)
          throw RangeError("radix");
        if (this.isZero())
          return "0";
        if (this.isNegative()) {
          if (this.eq(MIN_VALUE)) {
            var radixLong = fromNumber(radix), div3 = this.div(radixLong), rem1 = div3.mul(radixLong).sub(this);
            return div3.toString(radix) + rem1.toInt().toString(radix);
          } else
            return "-" + this.neg().toString(radix);
        }
        var radixToPower = fromNumber(pow_dbl(radix, 6), this.unsigned), rem = this;
        var result = "";
        while (true) {
          var remDiv = rem.div(radixToPower), intval = rem.sub(remDiv.mul(radixToPower)).toInt() >>> 0, digits = intval.toString(radix);
          rem = remDiv;
          if (rem.isZero())
            return digits + result;
          else {
            while (digits.length < 6)
              digits = "0" + digits;
            result = "" + digits + result;
          }
        }
      };
      LongPrototype.getHighBits = function getHighBits() {
        return this.high;
      };
      LongPrototype.getHighBitsUnsigned = function getHighBitsUnsigned() {
        return this.high >>> 0;
      };
      LongPrototype.getLowBits = function getLowBits() {
        return this.low;
      };
      LongPrototype.getLowBitsUnsigned = function getLowBitsUnsigned() {
        return this.low >>> 0;
      };
      LongPrototype.getNumBitsAbs = function getNumBitsAbs() {
        if (this.isNegative())
          return this.eq(MIN_VALUE) ? 64 : this.neg().getNumBitsAbs();
        var val = this.high != 0 ? this.high : this.low;
        for (var bit = 31; bit > 0; bit--)
          if ((val & 1 << bit) != 0)
            break;
        return this.high != 0 ? bit + 33 : bit + 1;
      };
      LongPrototype.isZero = function isZero() {
        return this.high === 0 && this.low === 0;
      };
      LongPrototype.eqz = LongPrototype.isZero;
      LongPrototype.isNegative = function isNegative() {
        return !this.unsigned && this.high < 0;
      };
      LongPrototype.isPositive = function isPositive() {
        return this.unsigned || this.high >= 0;
      };
      LongPrototype.isOdd = function isOdd() {
        return (this.low & 1) === 1;
      };
      LongPrototype.isEven = function isEven2() {
        return (this.low & 1) === 0;
      };
      LongPrototype.equals = function equals(other) {
        if (!isLong(other))
          other = fromValue(other);
        if (this.unsigned !== other.unsigned && this.high >>> 31 === 1 && other.high >>> 31 === 1)
          return false;
        return this.high === other.high && this.low === other.low;
      };
      LongPrototype.eq = LongPrototype.equals;
      LongPrototype.notEquals = function notEquals(other) {
        return !this.eq(other);
      };
      LongPrototype.neq = LongPrototype.notEquals;
      LongPrototype.ne = LongPrototype.notEquals;
      LongPrototype.lessThan = function lessThan(other) {
        return this.comp(other) < 0;
      };
      LongPrototype.lt = LongPrototype.lessThan;
      LongPrototype.lessThanOrEqual = function lessThanOrEqual(other) {
        return this.comp(other) <= 0;
      };
      LongPrototype.lte = LongPrototype.lessThanOrEqual;
      LongPrototype.le = LongPrototype.lessThanOrEqual;
      LongPrototype.greaterThan = function greaterThan(other) {
        return this.comp(other) > 0;
      };
      LongPrototype.gt = LongPrototype.greaterThan;
      LongPrototype.greaterThanOrEqual = function greaterThanOrEqual(other) {
        return this.comp(other) >= 0;
      };
      LongPrototype.gte = LongPrototype.greaterThanOrEqual;
      LongPrototype.ge = LongPrototype.greaterThanOrEqual;
      LongPrototype.compare = function compare(other) {
        if (!isLong(other))
          other = fromValue(other);
        if (this.eq(other))
          return 0;
        var thisNeg = this.isNegative(), otherNeg = other.isNegative();
        if (thisNeg && !otherNeg)
          return -1;
        if (!thisNeg && otherNeg)
          return 1;
        if (!this.unsigned)
          return this.sub(other).isNegative() ? -1 : 1;
        return other.high >>> 0 > this.high >>> 0 || other.high === this.high && other.low >>> 0 > this.low >>> 0 ? -1 : 1;
      };
      LongPrototype.comp = LongPrototype.compare;
      LongPrototype.negate = function negate() {
        if (!this.unsigned && this.eq(MIN_VALUE))
          return MIN_VALUE;
        return this.not().add(ONE);
      };
      LongPrototype.neg = LongPrototype.negate;
      LongPrototype.add = function add5(addend) {
        if (!isLong(addend))
          addend = fromValue(addend);
        var a48 = this.high >>> 16;
        var a32 = this.high & 65535;
        var a16 = this.low >>> 16;
        var a00 = this.low & 65535;
        var b48 = addend.high >>> 16;
        var b32 = addend.high & 65535;
        var b16 = addend.low >>> 16;
        var b00 = addend.low & 65535;
        var c48 = 0, c32 = 0, c16 = 0, c00 = 0;
        c00 += a00 + b00;
        c16 += c00 >>> 16;
        c00 &= 65535;
        c16 += a16 + b16;
        c32 += c16 >>> 16;
        c16 &= 65535;
        c32 += a32 + b32;
        c48 += c32 >>> 16;
        c32 &= 65535;
        c48 += a48 + b48;
        c48 &= 65535;
        return fromBits(c16 << 16 | c00, c48 << 16 | c32, this.unsigned);
      };
      LongPrototype.subtract = function subtract(subtrahend) {
        if (!isLong(subtrahend))
          subtrahend = fromValue(subtrahend);
        return this.add(subtrahend.neg());
      };
      LongPrototype.sub = LongPrototype.subtract;
      LongPrototype.multiply = function multiply3(multiplier) {
        if (this.isZero())
          return ZERO;
        if (!isLong(multiplier))
          multiplier = fromValue(multiplier);
        if (wasm) {
          var low = wasm.mul(this.low, this.high, multiplier.low, multiplier.high);
          return fromBits(low, wasm.get_high(), this.unsigned);
        }
        if (multiplier.isZero())
          return ZERO;
        if (this.eq(MIN_VALUE))
          return multiplier.isOdd() ? MIN_VALUE : ZERO;
        if (multiplier.eq(MIN_VALUE))
          return this.isOdd() ? MIN_VALUE : ZERO;
        if (this.isNegative()) {
          if (multiplier.isNegative())
            return this.neg().mul(multiplier.neg());
          else
            return this.neg().mul(multiplier).neg();
        } else if (multiplier.isNegative())
          return this.mul(multiplier.neg()).neg();
        if (this.lt(TWO_PWR_24) && multiplier.lt(TWO_PWR_24))
          return fromNumber(this.toNumber() * multiplier.toNumber(), this.unsigned);
        var a48 = this.high >>> 16;
        var a32 = this.high & 65535;
        var a16 = this.low >>> 16;
        var a00 = this.low & 65535;
        var b48 = multiplier.high >>> 16;
        var b32 = multiplier.high & 65535;
        var b16 = multiplier.low >>> 16;
        var b00 = multiplier.low & 65535;
        var c48 = 0, c32 = 0, c16 = 0, c00 = 0;
        c00 += a00 * b00;
        c16 += c00 >>> 16;
        c00 &= 65535;
        c16 += a16 * b00;
        c32 += c16 >>> 16;
        c16 &= 65535;
        c16 += a00 * b16;
        c32 += c16 >>> 16;
        c16 &= 65535;
        c32 += a32 * b00;
        c48 += c32 >>> 16;
        c32 &= 65535;
        c32 += a16 * b16;
        c48 += c32 >>> 16;
        c32 &= 65535;
        c32 += a00 * b32;
        c48 += c32 >>> 16;
        c32 &= 65535;
        c48 += a48 * b00 + a32 * b16 + a16 * b32 + a00 * b48;
        c48 &= 65535;
        return fromBits(c16 << 16 | c00, c48 << 16 | c32, this.unsigned);
      };
      LongPrototype.mul = LongPrototype.multiply;
      LongPrototype.divide = function divide(divisor) {
        if (!isLong(divisor))
          divisor = fromValue(divisor);
        if (divisor.isZero())
          throw Error("division by zero");
        if (wasm) {
          if (!this.unsigned && this.high === -2147483648 && divisor.low === -1 && divisor.high === -1) {
            return this;
          }
          var low = (this.unsigned ? wasm.div_u : wasm.div_s)(this.low, this.high, divisor.low, divisor.high);
          return fromBits(low, wasm.get_high(), this.unsigned);
        }
        if (this.isZero())
          return this.unsigned ? UZERO : ZERO;
        var approx, rem, res;
        if (!this.unsigned) {
          if (this.eq(MIN_VALUE)) {
            if (divisor.eq(ONE) || divisor.eq(NEG_ONE))
              return MIN_VALUE;
            else if (divisor.eq(MIN_VALUE))
              return ONE;
            else {
              var halfThis = this.shr(1);
              approx = halfThis.div(divisor).shl(1);
              if (approx.eq(ZERO)) {
                return divisor.isNegative() ? ONE : NEG_ONE;
              } else {
                rem = this.sub(divisor.mul(approx));
                res = approx.add(rem.div(divisor));
                return res;
              }
            }
          } else if (divisor.eq(MIN_VALUE))
            return this.unsigned ? UZERO : ZERO;
          if (this.isNegative()) {
            if (divisor.isNegative())
              return this.neg().div(divisor.neg());
            return this.neg().div(divisor).neg();
          } else if (divisor.isNegative())
            return this.div(divisor.neg()).neg();
          res = ZERO;
        } else {
          if (!divisor.unsigned)
            divisor = divisor.toUnsigned();
          if (divisor.gt(this))
            return UZERO;
          if (divisor.gt(this.shru(1)))
            return UONE;
          res = UZERO;
        }
        rem = this;
        while (rem.gte(divisor)) {
          approx = Math.max(1, Math.floor(rem.toNumber() / divisor.toNumber()));
          var log22 = Math.ceil(Math.log(approx) / Math.LN2), delta = log22 <= 48 ? 1 : pow_dbl(2, log22 - 48), approxRes = fromNumber(approx), approxRem = approxRes.mul(divisor);
          while (approxRem.isNegative() || approxRem.gt(rem)) {
            approx -= delta;
            approxRes = fromNumber(approx, this.unsigned);
            approxRem = approxRes.mul(divisor);
          }
          if (approxRes.isZero())
            approxRes = ONE;
          res = res.add(approxRes);
          rem = rem.sub(approxRem);
        }
        return res;
      };
      LongPrototype.div = LongPrototype.divide;
      LongPrototype.modulo = function modulo(divisor) {
        if (!isLong(divisor))
          divisor = fromValue(divisor);
        if (wasm) {
          var low = (this.unsigned ? wasm.rem_u : wasm.rem_s)(this.low, this.high, divisor.low, divisor.high);
          return fromBits(low, wasm.get_high(), this.unsigned);
        }
        return this.sub(this.div(divisor).mul(divisor));
      };
      LongPrototype.mod = LongPrototype.modulo;
      LongPrototype.rem = LongPrototype.modulo;
      LongPrototype.not = function not() {
        return fromBits(~this.low, ~this.high, this.unsigned);
      };
      LongPrototype.and = function and(other) {
        if (!isLong(other))
          other = fromValue(other);
        return fromBits(this.low & other.low, this.high & other.high, this.unsigned);
      };
      LongPrototype.or = function or(other) {
        if (!isLong(other))
          other = fromValue(other);
        return fromBits(this.low | other.low, this.high | other.high, this.unsigned);
      };
      LongPrototype.xor = function xor(other) {
        if (!isLong(other))
          other = fromValue(other);
        return fromBits(this.low ^ other.low, this.high ^ other.high, this.unsigned);
      };
      LongPrototype.shiftLeft = function shiftLeft(numBits) {
        if (isLong(numBits))
          numBits = numBits.toInt();
        if ((numBits &= 63) === 0)
          return this;
        else if (numBits < 32)
          return fromBits(this.low << numBits, this.high << numBits | this.low >>> 32 - numBits, this.unsigned);
        else
          return fromBits(0, this.low << numBits - 32, this.unsigned);
      };
      LongPrototype.shl = LongPrototype.shiftLeft;
      LongPrototype.shiftRight = function shiftRight(numBits) {
        if (isLong(numBits))
          numBits = numBits.toInt();
        if ((numBits &= 63) === 0)
          return this;
        else if (numBits < 32)
          return fromBits(this.low >>> numBits | this.high << 32 - numBits, this.high >> numBits, this.unsigned);
        else
          return fromBits(this.high >> numBits - 32, this.high >= 0 ? 0 : -1, this.unsigned);
      };
      LongPrototype.shr = LongPrototype.shiftRight;
      LongPrototype.shiftRightUnsigned = function shiftRightUnsigned(numBits) {
        if (isLong(numBits))
          numBits = numBits.toInt();
        numBits &= 63;
        if (numBits === 0)
          return this;
        else {
          var high = this.high;
          if (numBits < 32) {
            var low = this.low;
            return fromBits(low >>> numBits | high << 32 - numBits, high >>> numBits, this.unsigned);
          } else if (numBits === 32)
            return fromBits(high, 0, this.unsigned);
          else
            return fromBits(high >>> numBits - 32, 0, this.unsigned);
        }
      };
      LongPrototype.shru = LongPrototype.shiftRightUnsigned;
      LongPrototype.shr_u = LongPrototype.shiftRightUnsigned;
      LongPrototype.toSigned = function toSigned() {
        if (!this.unsigned)
          return this;
        return fromBits(this.low, this.high, false);
      };
      LongPrototype.toUnsigned = function toUnsigned() {
        if (this.unsigned)
          return this;
        return fromBits(this.low, this.high, true);
      };
      LongPrototype.toBytes = function toBytes(le) {
        return le ? this.toBytesLE() : this.toBytesBE();
      };
      LongPrototype.toBytesLE = function toBytesLE() {
        var hi = this.high, lo = this.low;
        return [
          lo & 255,
          lo >>> 8 & 255,
          lo >>> 16 & 255,
          lo >>> 24,
          hi & 255,
          hi >>> 8 & 255,
          hi >>> 16 & 255,
          hi >>> 24
        ];
      };
      LongPrototype.toBytesBE = function toBytesBE() {
        var hi = this.high, lo = this.low;
        return [
          hi >>> 24,
          hi >>> 16 & 255,
          hi >>> 8 & 255,
          hi & 255,
          lo >>> 24,
          lo >>> 16 & 255,
          lo >>> 8 & 255,
          lo & 255
        ];
      };
      Long2.fromBytes = function fromBytes(bytes, unsigned, le) {
        return le ? Long2.fromBytesLE(bytes, unsigned) : Long2.fromBytesBE(bytes, unsigned);
      };
      Long2.fromBytesLE = function fromBytesLE(bytes, unsigned) {
        return new Long2(bytes[0] | bytes[1] << 8 | bytes[2] << 16 | bytes[3] << 24, bytes[4] | bytes[5] << 8 | bytes[6] << 16 | bytes[7] << 24, unsigned);
      };
      Long2.fromBytesBE = function fromBytesBE(bytes, unsigned) {
        return new Long2(bytes[4] << 24 | bytes[5] << 16 | bytes[6] << 8 | bytes[7], bytes[0] << 24 | bytes[1] << 16 | bytes[2] << 8 | bytes[3], unsigned);
      };
    }
  });

  // (disabled):node_modules/node-fetch/browser.js
  var require_browser = __commonJS({
    "(disabled):node_modules/node-fetch/browser.js"() {
    }
  });

  // (disabled):util
  var require_util = __commonJS({
    "(disabled):util"() {
    }
  });

  // node_modules/@tensorflow/tfjs-core/node_modules/seedrandom/lib/alea.js
  var require_alea = __commonJS({
    "node_modules/@tensorflow/tfjs-core/node_modules/seedrandom/lib/alea.js"(exports, module) {
      (function(global2, module2, define2) {
        function Alea(seed) {
          var me = this, mash = Mash();
          me.next = function() {
            var t = 2091639 * me.s0 + me.c * 23283064365386963e-26;
            me.s0 = me.s1;
            me.s1 = me.s2;
            return me.s2 = t - (me.c = t | 0);
          };
          me.c = 1;
          me.s0 = mash(" ");
          me.s1 = mash(" ");
          me.s2 = mash(" ");
          me.s0 -= mash(seed);
          if (me.s0 < 0) {
            me.s0 += 1;
          }
          me.s1 -= mash(seed);
          if (me.s1 < 0) {
            me.s1 += 1;
          }
          me.s2 -= mash(seed);
          if (me.s2 < 0) {
            me.s2 += 1;
          }
          mash = null;
        }
        function copy(f, t) {
          t.c = f.c;
          t.s0 = f.s0;
          t.s1 = f.s1;
          t.s2 = f.s2;
          return t;
        }
        function impl(seed, opts) {
          var xg = new Alea(seed), state = opts && opts.state, prng = xg.next;
          prng.int32 = function() {
            return xg.next() * 4294967296 | 0;
          };
          prng.double = function() {
            return prng() + (prng() * 2097152 | 0) * 11102230246251565e-32;
          };
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        function Mash() {
          var n = 4022871197;
          var mash = function(data) {
            data = data.toString();
            for (var i = 0; i < data.length; i++) {
              n += data.charCodeAt(i);
              var h2 = 0.02519603282416938 * n;
              n = h2 >>> 0;
              h2 -= n;
              h2 *= n;
              n = h2 >>> 0;
              h2 -= n;
              n += h2 * 4294967296;
            }
            return (n >>> 0) * 23283064365386963e-26;
          };
          return mash;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.alea = impl;
        }
      })(exports, typeof module == "object" && module, typeof define == "function" && define);
    }
  });

  // node_modules/@tensorflow/tfjs-core/node_modules/seedrandom/lib/xor128.js
  var require_xor128 = __commonJS({
    "node_modules/@tensorflow/tfjs-core/node_modules/seedrandom/lib/xor128.js"(exports, module) {
      (function(global2, module2, define2) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.x = 0;
          me.y = 0;
          me.z = 0;
          me.w = 0;
          me.next = function() {
            var t = me.x ^ me.x << 11;
            me.x = me.y;
            me.y = me.z;
            me.z = me.w;
            return me.w ^= me.w >>> 19 ^ t ^ t >>> 8;
          };
          if (seed === (seed | 0)) {
            me.x = seed;
          } else {
            strseed += seed;
          }
          for (var k = 0; k < strseed.length + 64; k++) {
            me.x ^= strseed.charCodeAt(k) | 0;
            me.next();
          }
        }
        function copy(f, t) {
          t.x = f.x;
          t.y = f.y;
          t.z = f.z;
          t.w = f.w;
          return t;
        }
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xor128 = impl;
        }
      })(exports, typeof module == "object" && module, typeof define == "function" && define);
    }
  });

  // node_modules/@tensorflow/tfjs-core/node_modules/seedrandom/lib/xorwow.js
  var require_xorwow = __commonJS({
    "node_modules/@tensorflow/tfjs-core/node_modules/seedrandom/lib/xorwow.js"(exports, module) {
      (function(global2, module2, define2) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.next = function() {
            var t = me.x ^ me.x >>> 2;
            me.x = me.y;
            me.y = me.z;
            me.z = me.w;
            me.w = me.v;
            return (me.d = me.d + 362437 | 0) + (me.v = me.v ^ me.v << 4 ^ (t ^ t << 1)) | 0;
          };
          me.x = 0;
          me.y = 0;
          me.z = 0;
          me.w = 0;
          me.v = 0;
          if (seed === (seed | 0)) {
            me.x = seed;
          } else {
            strseed += seed;
          }
          for (var k = 0; k < strseed.length + 64; k++) {
            me.x ^= strseed.charCodeAt(k) | 0;
            if (k == strseed.length) {
              me.d = me.x << 10 ^ me.x >>> 4;
            }
            me.next();
          }
        }
        function copy(f, t) {
          t.x = f.x;
          t.y = f.y;
          t.z = f.z;
          t.w = f.w;
          t.v = f.v;
          t.d = f.d;
          return t;
        }
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xorwow = impl;
        }
      })(exports, typeof module == "object" && module, typeof define == "function" && define);
    }
  });

  // node_modules/@tensorflow/tfjs-core/node_modules/seedrandom/lib/xorshift7.js
  var require_xorshift7 = __commonJS({
    "node_modules/@tensorflow/tfjs-core/node_modules/seedrandom/lib/xorshift7.js"(exports, module) {
      (function(global2, module2, define2) {
        function XorGen(seed) {
          var me = this;
          me.next = function() {
            var X = me.x, i = me.i, t, v, w;
            t = X[i];
            t ^= t >>> 7;
            v = t ^ t << 24;
            t = X[i + 1 & 7];
            v ^= t ^ t >>> 10;
            t = X[i + 3 & 7];
            v ^= t ^ t >>> 3;
            t = X[i + 4 & 7];
            v ^= t ^ t << 7;
            t = X[i + 7 & 7];
            t = t ^ t << 13;
            v ^= t ^ t << 9;
            X[i] = v;
            me.i = i + 1 & 7;
            return v;
          };
          function init(me2, seed2) {
            var j, w, X = [];
            if (seed2 === (seed2 | 0)) {
              w = X[0] = seed2;
            } else {
              seed2 = "" + seed2;
              for (j = 0; j < seed2.length; ++j) {
                X[j & 7] = X[j & 7] << 15 ^ seed2.charCodeAt(j) + X[j + 1 & 7] << 13;
              }
            }
            while (X.length < 8)
              X.push(0);
            for (j = 0; j < 8 && X[j] === 0; ++j)
              ;
            if (j == 8)
              w = X[7] = -1;
            else
              w = X[j];
            me2.x = X;
            me2.i = 0;
            for (j = 256; j > 0; --j) {
              me2.next();
            }
          }
          init(me, seed);
        }
        function copy(f, t) {
          t.x = f.x.slice();
          t.i = f.i;
          return t;
        }
        function impl(seed, opts) {
          if (seed == null)
            seed = +new Date();
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (state.x)
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xorshift7 = impl;
        }
      })(exports, typeof module == "object" && module, typeof define == "function" && define);
    }
  });

  // node_modules/@tensorflow/tfjs-core/node_modules/seedrandom/lib/xor4096.js
  var require_xor4096 = __commonJS({
    "node_modules/@tensorflow/tfjs-core/node_modules/seedrandom/lib/xor4096.js"(exports, module) {
      (function(global2, module2, define2) {
        function XorGen(seed) {
          var me = this;
          me.next = function() {
            var w = me.w, X = me.X, i = me.i, t, v;
            me.w = w = w + 1640531527 | 0;
            v = X[i + 34 & 127];
            t = X[i = i + 1 & 127];
            v ^= v << 13;
            t ^= t << 17;
            v ^= v >>> 15;
            t ^= t >>> 12;
            v = X[i] = v ^ t;
            me.i = i;
            return v + (w ^ w >>> 16) | 0;
          };
          function init(me2, seed2) {
            var t, v, i, j, w, X = [], limit = 128;
            if (seed2 === (seed2 | 0)) {
              v = seed2;
              seed2 = null;
            } else {
              seed2 = seed2 + "\0";
              v = 0;
              limit = Math.max(limit, seed2.length);
            }
            for (i = 0, j = -32; j < limit; ++j) {
              if (seed2)
                v ^= seed2.charCodeAt((j + 32) % seed2.length);
              if (j === 0)
                w = v;
              v ^= v << 10;
              v ^= v >>> 15;
              v ^= v << 4;
              v ^= v >>> 13;
              if (j >= 0) {
                w = w + 1640531527 | 0;
                t = X[j & 127] ^= v + w;
                i = t == 0 ? i + 1 : 0;
              }
            }
            if (i >= 128) {
              X[(seed2 && seed2.length || 0) & 127] = -1;
            }
            i = 127;
            for (j = 4 * 128; j > 0; --j) {
              v = X[i + 34 & 127];
              t = X[i = i + 1 & 127];
              v ^= v << 13;
              t ^= t << 17;
              v ^= v >>> 15;
              t ^= t >>> 12;
              X[i] = v ^ t;
            }
            me2.w = w;
            me2.X = X;
            me2.i = i;
          }
          init(me, seed);
        }
        function copy(f, t) {
          t.i = f.i;
          t.w = f.w;
          t.X = f.X.slice();
          return t;
        }
        ;
        function impl(seed, opts) {
          if (seed == null)
            seed = +new Date();
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (state.X)
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xor4096 = impl;
        }
      })(exports, typeof module == "object" && module, typeof define == "function" && define);
    }
  });

  // node_modules/@tensorflow/tfjs-core/node_modules/seedrandom/lib/tychei.js
  var require_tychei = __commonJS({
    "node_modules/@tensorflow/tfjs-core/node_modules/seedrandom/lib/tychei.js"(exports, module) {
      (function(global2, module2, define2) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.next = function() {
            var b = me.b, c = me.c, d = me.d, a = me.a;
            b = b << 25 ^ b >>> 7 ^ c;
            c = c - d | 0;
            d = d << 24 ^ d >>> 8 ^ a;
            a = a - b | 0;
            me.b = b = b << 20 ^ b >>> 12 ^ c;
            me.c = c = c - d | 0;
            me.d = d << 16 ^ c >>> 16 ^ a;
            return me.a = a - b | 0;
          };
          me.a = 0;
          me.b = 0;
          me.c = 2654435769 | 0;
          me.d = 1367130551;
          if (seed === Math.floor(seed)) {
            me.a = seed / 4294967296 | 0;
            me.b = seed | 0;
          } else {
            strseed += seed;
          }
          for (var k = 0; k < strseed.length + 20; k++) {
            me.b ^= strseed.charCodeAt(k) | 0;
            me.next();
          }
        }
        function copy(f, t) {
          t.a = f.a;
          t.b = f.b;
          t.c = f.c;
          t.d = f.d;
          return t;
        }
        ;
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.tychei = impl;
        }
      })(exports, typeof module == "object" && module, typeof define == "function" && define);
    }
  });

  // (disabled):crypto
  var require_crypto = __commonJS({
    "(disabled):crypto"() {
    }
  });

  // node_modules/@tensorflow/tfjs-core/node_modules/seedrandom/seedrandom.js
  var require_seedrandom = __commonJS({
    "node_modules/@tensorflow/tfjs-core/node_modules/seedrandom/seedrandom.js"(exports, module) {
      (function(pool3, math) {
        var global2 = this, width = 256, chunks = 6, digits = 52, rngname = "random", startdenom = math.pow(width, chunks), significance = math.pow(2, digits), overflow = significance * 2, mask = width - 1, nodecrypto;
        function seedrandom5(seed, options, callback) {
          var key = [];
          options = options == true ? { entropy: true } : options || {};
          var shortseed = mixkey(flatten3(options.entropy ? [seed, tostring(pool3)] : seed == null ? autoseed() : seed, 3), key);
          var arc4 = new ARC4(key);
          var prng = function() {
            var n = arc4.g(chunks), d = startdenom, x = 0;
            while (n < significance) {
              n = (n + x) * width;
              d *= width;
              x = arc4.g(1);
            }
            while (n >= overflow) {
              n /= 2;
              d /= 2;
              x >>>= 1;
            }
            return (n + x) / d;
          };
          prng.int32 = function() {
            return arc4.g(4) | 0;
          };
          prng.quick = function() {
            return arc4.g(4) / 4294967296;
          };
          prng.double = prng;
          mixkey(tostring(arc4.S), pool3);
          return (options.pass || callback || function(prng2, seed2, is_math_call, state) {
            if (state) {
              if (state.S) {
                copy(state, arc4);
              }
              prng2.state = function() {
                return copy(arc4, {});
              };
            }
            if (is_math_call) {
              math[rngname] = prng2;
              return seed2;
            } else
              return prng2;
          })(prng, shortseed, "global" in options ? options.global : this == math, options.state);
        }
        math["seed" + rngname] = seedrandom5;
        function ARC4(key) {
          var t, keylen = key.length, me = this, i = 0, j = me.i = me.j = 0, s = me.S = [];
          if (!keylen) {
            key = [keylen++];
          }
          while (i < width) {
            s[i] = i++;
          }
          for (i = 0; i < width; i++) {
            s[i] = s[j = mask & j + key[i % keylen] + (t = s[i])];
            s[j] = t;
          }
          (me.g = function(count2) {
            var t2, r = 0, i2 = me.i, j2 = me.j, s2 = me.S;
            while (count2--) {
              t2 = s2[i2 = mask & i2 + 1];
              r = r * width + s2[mask & (s2[i2] = s2[j2 = mask & j2 + t2]) + (s2[j2] = t2)];
            }
            me.i = i2;
            me.j = j2;
            return r;
          })(width);
        }
        function copy(f, t) {
          t.i = f.i;
          t.j = f.j;
          t.S = f.S.slice();
          return t;
        }
        ;
        function flatten3(obj, depth) {
          var result = [], typ = typeof obj, prop;
          if (depth && typ == "object") {
            for (prop in obj) {
              try {
                result.push(flatten3(obj[prop], depth - 1));
              } catch (e) {
              }
            }
          }
          return result.length ? result : typ == "string" ? obj : obj + "\0";
        }
        function mixkey(seed, key) {
          var stringseed = seed + "", smear, j = 0;
          while (j < stringseed.length) {
            key[mask & j] = mask & (smear ^= key[mask & j] * 19) + stringseed.charCodeAt(j++);
          }
          return tostring(key);
        }
        function autoseed() {
          try {
            var out;
            if (nodecrypto && (out = nodecrypto.randomBytes)) {
              out = out(width);
            } else {
              out = new Uint8Array(width);
              (global2.crypto || global2.msCrypto).getRandomValues(out);
            }
            return tostring(out);
          } catch (e) {
            var browser = global2.navigator, plugins = browser && browser.plugins;
            return [+new Date(), global2, plugins, global2.screen, tostring(pool3)];
          }
        }
        function tostring(a) {
          return String.fromCharCode.apply(0, a);
        }
        mixkey(math.random(), pool3);
        if (typeof module == "object" && module.exports) {
          module.exports = seedrandom5;
          try {
            nodecrypto = require_crypto();
          } catch (ex) {
          }
        } else if (typeof define == "function" && define.amd) {
          define(function() {
            return seedrandom5;
          });
        }
      })([], Math);
    }
  });

  // node_modules/@tensorflow/tfjs-core/node_modules/seedrandom/index.js
  var require_seedrandom2 = __commonJS({
    "node_modules/@tensorflow/tfjs-core/node_modules/seedrandom/index.js"(exports, module) {
      var alea5 = require_alea();
      var xor128 = require_xor128();
      var xorwow = require_xorwow();
      var xorshift7 = require_xorshift7();
      var xor4096 = require_xor4096();
      var tychei = require_tychei();
      var sr = require_seedrandom();
      sr.alea = alea5;
      sr.xor128 = xor128;
      sr.xorwow = xorwow;
      sr.xorshift7 = xorshift7;
      sr.xor4096 = xor4096;
      sr.tychei = tychei;
      module.exports = sr;
    }
  });

  // node_modules/seedrandom/lib/alea.js
  var require_alea2 = __commonJS({
    "node_modules/seedrandom/lib/alea.js"(exports, module) {
      (function(global2, module2, define2) {
        function Alea(seed) {
          var me = this, mash = Mash();
          me.next = function() {
            var t = 2091639 * me.s0 + me.c * 23283064365386963e-26;
            me.s0 = me.s1;
            me.s1 = me.s2;
            return me.s2 = t - (me.c = t | 0);
          };
          me.c = 1;
          me.s0 = mash(" ");
          me.s1 = mash(" ");
          me.s2 = mash(" ");
          me.s0 -= mash(seed);
          if (me.s0 < 0) {
            me.s0 += 1;
          }
          me.s1 -= mash(seed);
          if (me.s1 < 0) {
            me.s1 += 1;
          }
          me.s2 -= mash(seed);
          if (me.s2 < 0) {
            me.s2 += 1;
          }
          mash = null;
        }
        function copy(f, t) {
          t.c = f.c;
          t.s0 = f.s0;
          t.s1 = f.s1;
          t.s2 = f.s2;
          return t;
        }
        function impl(seed, opts) {
          var xg = new Alea(seed), state = opts && opts.state, prng = xg.next;
          prng.int32 = function() {
            return xg.next() * 4294967296 | 0;
          };
          prng.double = function() {
            return prng() + (prng() * 2097152 | 0) * 11102230246251565e-32;
          };
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        function Mash() {
          var n = 4022871197;
          var mash = function(data) {
            data = data.toString();
            for (var i = 0; i < data.length; i++) {
              n += data.charCodeAt(i);
              var h2 = 0.02519603282416938 * n;
              n = h2 >>> 0;
              h2 -= n;
              h2 *= n;
              n = h2 >>> 0;
              h2 -= n;
              n += h2 * 4294967296;
            }
            return (n >>> 0) * 23283064365386963e-26;
          };
          return mash;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.alea = impl;
        }
      })(exports, typeof module == "object" && module, typeof define == "function" && define);
    }
  });

  // node_modules/seedrandom/lib/xor128.js
  var require_xor1282 = __commonJS({
    "node_modules/seedrandom/lib/xor128.js"(exports, module) {
      (function(global2, module2, define2) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.x = 0;
          me.y = 0;
          me.z = 0;
          me.w = 0;
          me.next = function() {
            var t = me.x ^ me.x << 11;
            me.x = me.y;
            me.y = me.z;
            me.z = me.w;
            return me.w ^= me.w >>> 19 ^ t ^ t >>> 8;
          };
          if (seed === (seed | 0)) {
            me.x = seed;
          } else {
            strseed += seed;
          }
          for (var k = 0; k < strseed.length + 64; k++) {
            me.x ^= strseed.charCodeAt(k) | 0;
            me.next();
          }
        }
        function copy(f, t) {
          t.x = f.x;
          t.y = f.y;
          t.z = f.z;
          t.w = f.w;
          return t;
        }
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xor128 = impl;
        }
      })(exports, typeof module == "object" && module, typeof define == "function" && define);
    }
  });

  // node_modules/seedrandom/lib/xorwow.js
  var require_xorwow2 = __commonJS({
    "node_modules/seedrandom/lib/xorwow.js"(exports, module) {
      (function(global2, module2, define2) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.next = function() {
            var t = me.x ^ me.x >>> 2;
            me.x = me.y;
            me.y = me.z;
            me.z = me.w;
            me.w = me.v;
            return (me.d = me.d + 362437 | 0) + (me.v = me.v ^ me.v << 4 ^ (t ^ t << 1)) | 0;
          };
          me.x = 0;
          me.y = 0;
          me.z = 0;
          me.w = 0;
          me.v = 0;
          if (seed === (seed | 0)) {
            me.x = seed;
          } else {
            strseed += seed;
          }
          for (var k = 0; k < strseed.length + 64; k++) {
            me.x ^= strseed.charCodeAt(k) | 0;
            if (k == strseed.length) {
              me.d = me.x << 10 ^ me.x >>> 4;
            }
            me.next();
          }
        }
        function copy(f, t) {
          t.x = f.x;
          t.y = f.y;
          t.z = f.z;
          t.w = f.w;
          t.v = f.v;
          t.d = f.d;
          return t;
        }
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xorwow = impl;
        }
      })(exports, typeof module == "object" && module, typeof define == "function" && define);
    }
  });

  // node_modules/seedrandom/lib/xorshift7.js
  var require_xorshift72 = __commonJS({
    "node_modules/seedrandom/lib/xorshift7.js"(exports, module) {
      (function(global2, module2, define2) {
        function XorGen(seed) {
          var me = this;
          me.next = function() {
            var X = me.x, i = me.i, t, v, w;
            t = X[i];
            t ^= t >>> 7;
            v = t ^ t << 24;
            t = X[i + 1 & 7];
            v ^= t ^ t >>> 10;
            t = X[i + 3 & 7];
            v ^= t ^ t >>> 3;
            t = X[i + 4 & 7];
            v ^= t ^ t << 7;
            t = X[i + 7 & 7];
            t = t ^ t << 13;
            v ^= t ^ t << 9;
            X[i] = v;
            me.i = i + 1 & 7;
            return v;
          };
          function init(me2, seed2) {
            var j, w, X = [];
            if (seed2 === (seed2 | 0)) {
              w = X[0] = seed2;
            } else {
              seed2 = "" + seed2;
              for (j = 0; j < seed2.length; ++j) {
                X[j & 7] = X[j & 7] << 15 ^ seed2.charCodeAt(j) + X[j + 1 & 7] << 13;
              }
            }
            while (X.length < 8)
              X.push(0);
            for (j = 0; j < 8 && X[j] === 0; ++j)
              ;
            if (j == 8)
              w = X[7] = -1;
            else
              w = X[j];
            me2.x = X;
            me2.i = 0;
            for (j = 256; j > 0; --j) {
              me2.next();
            }
          }
          init(me, seed);
        }
        function copy(f, t) {
          t.x = f.x.slice();
          t.i = f.i;
          return t;
        }
        function impl(seed, opts) {
          if (seed == null)
            seed = +new Date();
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (state.x)
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xorshift7 = impl;
        }
      })(exports, typeof module == "object" && module, typeof define == "function" && define);
    }
  });

  // node_modules/seedrandom/lib/xor4096.js
  var require_xor40962 = __commonJS({
    "node_modules/seedrandom/lib/xor4096.js"(exports, module) {
      (function(global2, module2, define2) {
        function XorGen(seed) {
          var me = this;
          me.next = function() {
            var w = me.w, X = me.X, i = me.i, t, v;
            me.w = w = w + 1640531527 | 0;
            v = X[i + 34 & 127];
            t = X[i = i + 1 & 127];
            v ^= v << 13;
            t ^= t << 17;
            v ^= v >>> 15;
            t ^= t >>> 12;
            v = X[i] = v ^ t;
            me.i = i;
            return v + (w ^ w >>> 16) | 0;
          };
          function init(me2, seed2) {
            var t, v, i, j, w, X = [], limit = 128;
            if (seed2 === (seed2 | 0)) {
              v = seed2;
              seed2 = null;
            } else {
              seed2 = seed2 + "\0";
              v = 0;
              limit = Math.max(limit, seed2.length);
            }
            for (i = 0, j = -32; j < limit; ++j) {
              if (seed2)
                v ^= seed2.charCodeAt((j + 32) % seed2.length);
              if (j === 0)
                w = v;
              v ^= v << 10;
              v ^= v >>> 15;
              v ^= v << 4;
              v ^= v >>> 13;
              if (j >= 0) {
                w = w + 1640531527 | 0;
                t = X[j & 127] ^= v + w;
                i = t == 0 ? i + 1 : 0;
              }
            }
            if (i >= 128) {
              X[(seed2 && seed2.length || 0) & 127] = -1;
            }
            i = 127;
            for (j = 4 * 128; j > 0; --j) {
              v = X[i + 34 & 127];
              t = X[i = i + 1 & 127];
              v ^= v << 13;
              t ^= t << 17;
              v ^= v >>> 15;
              t ^= t >>> 12;
              X[i] = v ^ t;
            }
            me2.w = w;
            me2.X = X;
            me2.i = i;
          }
          init(me, seed);
        }
        function copy(f, t) {
          t.i = f.i;
          t.w = f.w;
          t.X = f.X.slice();
          return t;
        }
        ;
        function impl(seed, opts) {
          if (seed == null)
            seed = +new Date();
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (state.X)
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xor4096 = impl;
        }
      })(exports, typeof module == "object" && module, typeof define == "function" && define);
    }
  });

  // node_modules/seedrandom/lib/tychei.js
  var require_tychei2 = __commonJS({
    "node_modules/seedrandom/lib/tychei.js"(exports, module) {
      (function(global2, module2, define2) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.next = function() {
            var b = me.b, c = me.c, d = me.d, a = me.a;
            b = b << 25 ^ b >>> 7 ^ c;
            c = c - d | 0;
            d = d << 24 ^ d >>> 8 ^ a;
            a = a - b | 0;
            me.b = b = b << 20 ^ b >>> 12 ^ c;
            me.c = c = c - d | 0;
            me.d = d << 16 ^ c >>> 16 ^ a;
            return me.a = a - b | 0;
          };
          me.a = 0;
          me.b = 0;
          me.c = 2654435769 | 0;
          me.d = 1367130551;
          if (seed === Math.floor(seed)) {
            me.a = seed / 4294967296 | 0;
            me.b = seed | 0;
          } else {
            strseed += seed;
          }
          for (var k = 0; k < strseed.length + 20; k++) {
            me.b ^= strseed.charCodeAt(k) | 0;
            me.next();
          }
        }
        function copy(f, t) {
          t.a = f.a;
          t.b = f.b;
          t.c = f.c;
          t.d = f.d;
          return t;
        }
        ;
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.tychei = impl;
        }
      })(exports, typeof module == "object" && module, typeof define == "function" && define);
    }
  });

  // node_modules/seedrandom/seedrandom.js
  var require_seedrandom3 = __commonJS({
    "node_modules/seedrandom/seedrandom.js"(exports, module) {
      (function(pool3, math) {
        var global2 = (0, eval)("this"), width = 256, chunks = 6, digits = 52, rngname = "random", startdenom = math.pow(width, chunks), significance = math.pow(2, digits), overflow = significance * 2, mask = width - 1, nodecrypto;
        function seedrandom5(seed, options, callback) {
          var key = [];
          options = options == true ? { entropy: true } : options || {};
          var shortseed = mixkey(flatten3(options.entropy ? [seed, tostring(pool3)] : seed == null ? autoseed() : seed, 3), key);
          var arc4 = new ARC4(key);
          var prng = function() {
            var n = arc4.g(chunks), d = startdenom, x = 0;
            while (n < significance) {
              n = (n + x) * width;
              d *= width;
              x = arc4.g(1);
            }
            while (n >= overflow) {
              n /= 2;
              d /= 2;
              x >>>= 1;
            }
            return (n + x) / d;
          };
          prng.int32 = function() {
            return arc4.g(4) | 0;
          };
          prng.quick = function() {
            return arc4.g(4) / 4294967296;
          };
          prng.double = prng;
          mixkey(tostring(arc4.S), pool3);
          return (options.pass || callback || function(prng2, seed2, is_math_call, state) {
            if (state) {
              if (state.S) {
                copy(state, arc4);
              }
              prng2.state = function() {
                return copy(arc4, {});
              };
            }
            if (is_math_call) {
              math[rngname] = prng2;
              return seed2;
            } else
              return prng2;
          })(prng, shortseed, "global" in options ? options.global : this == math, options.state);
        }
        math["seed" + rngname] = seedrandom5;
        function ARC4(key) {
          var t, keylen = key.length, me = this, i = 0, j = me.i = me.j = 0, s = me.S = [];
          if (!keylen) {
            key = [keylen++];
          }
          while (i < width) {
            s[i] = i++;
          }
          for (i = 0; i < width; i++) {
            s[i] = s[j = mask & j + key[i % keylen] + (t = s[i])];
            s[j] = t;
          }
          (me.g = function(count2) {
            var t2, r = 0, i2 = me.i, j2 = me.j, s2 = me.S;
            while (count2--) {
              t2 = s2[i2 = mask & i2 + 1];
              r = r * width + s2[mask & (s2[i2] = s2[j2 = mask & j2 + t2]) + (s2[j2] = t2)];
            }
            me.i = i2;
            me.j = j2;
            return r;
          })(width);
        }
        function copy(f, t) {
          t.i = f.i;
          t.j = f.j;
          t.S = f.S.slice();
          return t;
        }
        ;
        function flatten3(obj, depth) {
          var result = [], typ = typeof obj, prop;
          if (depth && typ == "object") {
            for (prop in obj) {
              try {
                result.push(flatten3(obj[prop], depth - 1));
              } catch (e) {
              }
            }
          }
          return result.length ? result : typ == "string" ? obj : obj + "\0";
        }
        function mixkey(seed, key) {
          var stringseed = seed + "", smear, j = 0;
          while (j < stringseed.length) {
            key[mask & j] = mask & (smear ^= key[mask & j] * 19) + stringseed.charCodeAt(j++);
          }
          return tostring(key);
        }
        function autoseed() {
          try {
            var out;
            if (nodecrypto && (out = nodecrypto.randomBytes)) {
              out = out(width);
            } else {
              out = new Uint8Array(width);
              (global2.crypto || global2.msCrypto).getRandomValues(out);
            }
            return tostring(out);
          } catch (e) {
            var browser = global2.navigator, plugins = browser && browser.plugins;
            return [+new Date(), global2, plugins, global2.screen, tostring(pool3)];
          }
        }
        function tostring(a) {
          return String.fromCharCode.apply(0, a);
        }
        mixkey(math.random(), pool3);
        if (typeof module == "object" && module.exports) {
          module.exports = seedrandom5;
          try {
            nodecrypto = require_crypto();
          } catch (ex) {
          }
        } else if (typeof define == "function" && define.amd) {
          define(function() {
            return seedrandom5;
          });
        }
      })([], Math);
    }
  });

  // node_modules/seedrandom/index.js
  var require_seedrandom4 = __commonJS({
    "node_modules/seedrandom/index.js"(exports, module) {
      var alea5 = require_alea2();
      var xor128 = require_xor1282();
      var xorwow = require_xorwow2();
      var xorshift7 = require_xorshift72();
      var xor4096 = require_xor40962();
      var tychei = require_tychei2();
      var sr = require_seedrandom3();
      sr.alea = alea5;
      sr.xor128 = xor128;
      sr.xorwow = xorwow;
      sr.xorshift7 = xorshift7;
      sr.xor4096 = xor4096;
      sr.tychei = tychei;
      module.exports = sr;
    }
  });

  // (disabled):string_decoder
  var require_string_decoder = __commonJS({
    "(disabled):string_decoder"() {
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/node_modules/seedrandom/lib/alea.js
  var require_alea3 = __commonJS({
    "node_modules/@tensorflow/tfjs-backend-cpu/node_modules/seedrandom/lib/alea.js"(exports, module) {
      (function(global2, module2, define2) {
        function Alea(seed) {
          var me = this, mash = Mash();
          me.next = function() {
            var t = 2091639 * me.s0 + me.c * 23283064365386963e-26;
            me.s0 = me.s1;
            me.s1 = me.s2;
            return me.s2 = t - (me.c = t | 0);
          };
          me.c = 1;
          me.s0 = mash(" ");
          me.s1 = mash(" ");
          me.s2 = mash(" ");
          me.s0 -= mash(seed);
          if (me.s0 < 0) {
            me.s0 += 1;
          }
          me.s1 -= mash(seed);
          if (me.s1 < 0) {
            me.s1 += 1;
          }
          me.s2 -= mash(seed);
          if (me.s2 < 0) {
            me.s2 += 1;
          }
          mash = null;
        }
        function copy(f, t) {
          t.c = f.c;
          t.s0 = f.s0;
          t.s1 = f.s1;
          t.s2 = f.s2;
          return t;
        }
        function impl(seed, opts) {
          var xg = new Alea(seed), state = opts && opts.state, prng = xg.next;
          prng.int32 = function() {
            return xg.next() * 4294967296 | 0;
          };
          prng.double = function() {
            return prng() + (prng() * 2097152 | 0) * 11102230246251565e-32;
          };
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        function Mash() {
          var n = 4022871197;
          var mash = function(data) {
            data = data.toString();
            for (var i = 0; i < data.length; i++) {
              n += data.charCodeAt(i);
              var h2 = 0.02519603282416938 * n;
              n = h2 >>> 0;
              h2 -= n;
              h2 *= n;
              n = h2 >>> 0;
              h2 -= n;
              n += h2 * 4294967296;
            }
            return (n >>> 0) * 23283064365386963e-26;
          };
          return mash;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.alea = impl;
        }
      })(exports, typeof module == "object" && module, typeof define == "function" && define);
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/node_modules/seedrandom/lib/xor128.js
  var require_xor1283 = __commonJS({
    "node_modules/@tensorflow/tfjs-backend-cpu/node_modules/seedrandom/lib/xor128.js"(exports, module) {
      (function(global2, module2, define2) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.x = 0;
          me.y = 0;
          me.z = 0;
          me.w = 0;
          me.next = function() {
            var t = me.x ^ me.x << 11;
            me.x = me.y;
            me.y = me.z;
            me.z = me.w;
            return me.w ^= me.w >>> 19 ^ t ^ t >>> 8;
          };
          if (seed === (seed | 0)) {
            me.x = seed;
          } else {
            strseed += seed;
          }
          for (var k = 0; k < strseed.length + 64; k++) {
            me.x ^= strseed.charCodeAt(k) | 0;
            me.next();
          }
        }
        function copy(f, t) {
          t.x = f.x;
          t.y = f.y;
          t.z = f.z;
          t.w = f.w;
          return t;
        }
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xor128 = impl;
        }
      })(exports, typeof module == "object" && module, typeof define == "function" && define);
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/node_modules/seedrandom/lib/xorwow.js
  var require_xorwow3 = __commonJS({
    "node_modules/@tensorflow/tfjs-backend-cpu/node_modules/seedrandom/lib/xorwow.js"(exports, module) {
      (function(global2, module2, define2) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.next = function() {
            var t = me.x ^ me.x >>> 2;
            me.x = me.y;
            me.y = me.z;
            me.z = me.w;
            me.w = me.v;
            return (me.d = me.d + 362437 | 0) + (me.v = me.v ^ me.v << 4 ^ (t ^ t << 1)) | 0;
          };
          me.x = 0;
          me.y = 0;
          me.z = 0;
          me.w = 0;
          me.v = 0;
          if (seed === (seed | 0)) {
            me.x = seed;
          } else {
            strseed += seed;
          }
          for (var k = 0; k < strseed.length + 64; k++) {
            me.x ^= strseed.charCodeAt(k) | 0;
            if (k == strseed.length) {
              me.d = me.x << 10 ^ me.x >>> 4;
            }
            me.next();
          }
        }
        function copy(f, t) {
          t.x = f.x;
          t.y = f.y;
          t.z = f.z;
          t.w = f.w;
          t.v = f.v;
          t.d = f.d;
          return t;
        }
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xorwow = impl;
        }
      })(exports, typeof module == "object" && module, typeof define == "function" && define);
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/node_modules/seedrandom/lib/xorshift7.js
  var require_xorshift73 = __commonJS({
    "node_modules/@tensorflow/tfjs-backend-cpu/node_modules/seedrandom/lib/xorshift7.js"(exports, module) {
      (function(global2, module2, define2) {
        function XorGen(seed) {
          var me = this;
          me.next = function() {
            var X = me.x, i = me.i, t, v, w;
            t = X[i];
            t ^= t >>> 7;
            v = t ^ t << 24;
            t = X[i + 1 & 7];
            v ^= t ^ t >>> 10;
            t = X[i + 3 & 7];
            v ^= t ^ t >>> 3;
            t = X[i + 4 & 7];
            v ^= t ^ t << 7;
            t = X[i + 7 & 7];
            t = t ^ t << 13;
            v ^= t ^ t << 9;
            X[i] = v;
            me.i = i + 1 & 7;
            return v;
          };
          function init(me2, seed2) {
            var j, w, X = [];
            if (seed2 === (seed2 | 0)) {
              w = X[0] = seed2;
            } else {
              seed2 = "" + seed2;
              for (j = 0; j < seed2.length; ++j) {
                X[j & 7] = X[j & 7] << 15 ^ seed2.charCodeAt(j) + X[j + 1 & 7] << 13;
              }
            }
            while (X.length < 8)
              X.push(0);
            for (j = 0; j < 8 && X[j] === 0; ++j)
              ;
            if (j == 8)
              w = X[7] = -1;
            else
              w = X[j];
            me2.x = X;
            me2.i = 0;
            for (j = 256; j > 0; --j) {
              me2.next();
            }
          }
          init(me, seed);
        }
        function copy(f, t) {
          t.x = f.x.slice();
          t.i = f.i;
          return t;
        }
        function impl(seed, opts) {
          if (seed == null)
            seed = +new Date();
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (state.x)
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xorshift7 = impl;
        }
      })(exports, typeof module == "object" && module, typeof define == "function" && define);
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/node_modules/seedrandom/lib/xor4096.js
  var require_xor40963 = __commonJS({
    "node_modules/@tensorflow/tfjs-backend-cpu/node_modules/seedrandom/lib/xor4096.js"(exports, module) {
      (function(global2, module2, define2) {
        function XorGen(seed) {
          var me = this;
          me.next = function() {
            var w = me.w, X = me.X, i = me.i, t, v;
            me.w = w = w + 1640531527 | 0;
            v = X[i + 34 & 127];
            t = X[i = i + 1 & 127];
            v ^= v << 13;
            t ^= t << 17;
            v ^= v >>> 15;
            t ^= t >>> 12;
            v = X[i] = v ^ t;
            me.i = i;
            return v + (w ^ w >>> 16) | 0;
          };
          function init(me2, seed2) {
            var t, v, i, j, w, X = [], limit = 128;
            if (seed2 === (seed2 | 0)) {
              v = seed2;
              seed2 = null;
            } else {
              seed2 = seed2 + "\0";
              v = 0;
              limit = Math.max(limit, seed2.length);
            }
            for (i = 0, j = -32; j < limit; ++j) {
              if (seed2)
                v ^= seed2.charCodeAt((j + 32) % seed2.length);
              if (j === 0)
                w = v;
              v ^= v << 10;
              v ^= v >>> 15;
              v ^= v << 4;
              v ^= v >>> 13;
              if (j >= 0) {
                w = w + 1640531527 | 0;
                t = X[j & 127] ^= v + w;
                i = t == 0 ? i + 1 : 0;
              }
            }
            if (i >= 128) {
              X[(seed2 && seed2.length || 0) & 127] = -1;
            }
            i = 127;
            for (j = 4 * 128; j > 0; --j) {
              v = X[i + 34 & 127];
              t = X[i = i + 1 & 127];
              v ^= v << 13;
              t ^= t << 17;
              v ^= v >>> 15;
              t ^= t >>> 12;
              X[i] = v ^ t;
            }
            me2.w = w;
            me2.X = X;
            me2.i = i;
          }
          init(me, seed);
        }
        function copy(f, t) {
          t.i = f.i;
          t.w = f.w;
          t.X = f.X.slice();
          return t;
        }
        ;
        function impl(seed, opts) {
          if (seed == null)
            seed = +new Date();
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (state.X)
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xor4096 = impl;
        }
      })(exports, typeof module == "object" && module, typeof define == "function" && define);
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/node_modules/seedrandom/lib/tychei.js
  var require_tychei3 = __commonJS({
    "node_modules/@tensorflow/tfjs-backend-cpu/node_modules/seedrandom/lib/tychei.js"(exports, module) {
      (function(global2, module2, define2) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.next = function() {
            var b = me.b, c = me.c, d = me.d, a = me.a;
            b = b << 25 ^ b >>> 7 ^ c;
            c = c - d | 0;
            d = d << 24 ^ d >>> 8 ^ a;
            a = a - b | 0;
            me.b = b = b << 20 ^ b >>> 12 ^ c;
            me.c = c = c - d | 0;
            me.d = d << 16 ^ c >>> 16 ^ a;
            return me.a = a - b | 0;
          };
          me.a = 0;
          me.b = 0;
          me.c = 2654435769 | 0;
          me.d = 1367130551;
          if (seed === Math.floor(seed)) {
            me.a = seed / 4294967296 | 0;
            me.b = seed | 0;
          } else {
            strseed += seed;
          }
          for (var k = 0; k < strseed.length + 20; k++) {
            me.b ^= strseed.charCodeAt(k) | 0;
            me.next();
          }
        }
        function copy(f, t) {
          t.a = f.a;
          t.b = f.b;
          t.c = f.c;
          t.d = f.d;
          return t;
        }
        ;
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.tychei = impl;
        }
      })(exports, typeof module == "object" && module, typeof define == "function" && define);
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/node_modules/seedrandom/seedrandom.js
  var require_seedrandom5 = __commonJS({
    "node_modules/@tensorflow/tfjs-backend-cpu/node_modules/seedrandom/seedrandom.js"(exports, module) {
      (function(pool3, math) {
        var global2 = this, width = 256, chunks = 6, digits = 52, rngname = "random", startdenom = math.pow(width, chunks), significance = math.pow(2, digits), overflow = significance * 2, mask = width - 1, nodecrypto;
        function seedrandom5(seed, options, callback) {
          var key = [];
          options = options == true ? { entropy: true } : options || {};
          var shortseed = mixkey(flatten3(options.entropy ? [seed, tostring(pool3)] : seed == null ? autoseed() : seed, 3), key);
          var arc4 = new ARC4(key);
          var prng = function() {
            var n = arc4.g(chunks), d = startdenom, x = 0;
            while (n < significance) {
              n = (n + x) * width;
              d *= width;
              x = arc4.g(1);
            }
            while (n >= overflow) {
              n /= 2;
              d /= 2;
              x >>>= 1;
            }
            return (n + x) / d;
          };
          prng.int32 = function() {
            return arc4.g(4) | 0;
          };
          prng.quick = function() {
            return arc4.g(4) / 4294967296;
          };
          prng.double = prng;
          mixkey(tostring(arc4.S), pool3);
          return (options.pass || callback || function(prng2, seed2, is_math_call, state) {
            if (state) {
              if (state.S) {
                copy(state, arc4);
              }
              prng2.state = function() {
                return copy(arc4, {});
              };
            }
            if (is_math_call) {
              math[rngname] = prng2;
              return seed2;
            } else
              return prng2;
          })(prng, shortseed, "global" in options ? options.global : this == math, options.state);
        }
        math["seed" + rngname] = seedrandom5;
        function ARC4(key) {
          var t, keylen = key.length, me = this, i = 0, j = me.i = me.j = 0, s = me.S = [];
          if (!keylen) {
            key = [keylen++];
          }
          while (i < width) {
            s[i] = i++;
          }
          for (i = 0; i < width; i++) {
            s[i] = s[j = mask & j + key[i % keylen] + (t = s[i])];
            s[j] = t;
          }
          (me.g = function(count2) {
            var t2, r = 0, i2 = me.i, j2 = me.j, s2 = me.S;
            while (count2--) {
              t2 = s2[i2 = mask & i2 + 1];
              r = r * width + s2[mask & (s2[i2] = s2[j2 = mask & j2 + t2]) + (s2[j2] = t2)];
            }
            me.i = i2;
            me.j = j2;
            return r;
          })(width);
        }
        function copy(f, t) {
          t.i = f.i;
          t.j = f.j;
          t.S = f.S.slice();
          return t;
        }
        ;
        function flatten3(obj, depth) {
          var result = [], typ = typeof obj, prop;
          if (depth && typ == "object") {
            for (prop in obj) {
              try {
                result.push(flatten3(obj[prop], depth - 1));
              } catch (e) {
              }
            }
          }
          return result.length ? result : typ == "string" ? obj : obj + "\0";
        }
        function mixkey(seed, key) {
          var stringseed = seed + "", smear, j = 0;
          while (j < stringseed.length) {
            key[mask & j] = mask & (smear ^= key[mask & j] * 19) + stringseed.charCodeAt(j++);
          }
          return tostring(key);
        }
        function autoseed() {
          try {
            var out;
            if (nodecrypto && (out = nodecrypto.randomBytes)) {
              out = out(width);
            } else {
              out = new Uint8Array(width);
              (global2.crypto || global2.msCrypto).getRandomValues(out);
            }
            return tostring(out);
          } catch (e) {
            var browser = global2.navigator, plugins = browser && browser.plugins;
            return [+new Date(), global2, plugins, global2.screen, tostring(pool3)];
          }
        }
        function tostring(a) {
          return String.fromCharCode.apply(0, a);
        }
        mixkey(math.random(), pool3);
        if (typeof module == "object" && module.exports) {
          module.exports = seedrandom5;
          try {
            nodecrypto = require_crypto();
          } catch (ex) {
          }
        } else if (typeof define == "function" && define.amd) {
          define(function() {
            return seedrandom5;
          });
        }
      })([], Math);
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/node_modules/seedrandom/index.js
  var require_seedrandom6 = __commonJS({
    "node_modules/@tensorflow/tfjs-backend-cpu/node_modules/seedrandom/index.js"(exports, module) {
      var alea5 = require_alea3();
      var xor128 = require_xor1283();
      var xorwow = require_xorwow3();
      var xorshift7 = require_xorshift73();
      var xor4096 = require_xor40963();
      var tychei = require_tychei3();
      var sr = require_seedrandom5();
      sr.alea = alea5;
      sr.xor128 = xor128;
      sr.xorwow = xorwow;
      sr.xorshift7 = xorshift7;
      sr.xor4096 = xor4096;
      sr.tychei = tychei;
      module.exports = sr;
    }
  });

  // node_modules/@vue/shared/dist/shared.esm-bundler.js
  function makeMap(str, expectsLowerCase) {
    const map2 = Object.create(null);
    const list = str.split(",");
    for (let i = 0; i < list.length; i++) {
      map2[list[i]] = true;
    }
    return expectsLowerCase ? (val) => !!map2[val.toLowerCase()] : (val) => !!map2[val];
  }
  var PatchFlagNames = {
    [1]: `TEXT`,
    [2]: `CLASS`,
    [4]: `STYLE`,
    [8]: `PROPS`,
    [16]: `FULL_PROPS`,
    [32]: `HYDRATE_EVENTS`,
    [64]: `STABLE_FRAGMENT`,
    [128]: `KEYED_FRAGMENT`,
    [256]: `UNKEYED_FRAGMENT`,
    [512]: `NEED_PATCH`,
    [1024]: `DYNAMIC_SLOTS`,
    [2048]: `DEV_ROOT_FRAGMENT`,
    [-1]: `HOISTED`,
    [-2]: `BAIL`
  };
  var slotFlagsText = {
    [1]: "STABLE",
    [2]: "DYNAMIC",
    [3]: "FORWARDED"
  };
  var specialBooleanAttrs = `itemscope,allowfullscreen,formnovalidate,ismap,nomodule,novalidate,readonly`;
  var isSpecialBooleanAttr = /* @__PURE__ */ makeMap(specialBooleanAttrs);
  var isBooleanAttr = /* @__PURE__ */ makeMap(specialBooleanAttrs + `,async,autofocus,autoplay,controls,default,defer,disabled,hidden,loop,open,required,reversed,scoped,seamless,checked,muted,multiple,selected`);
  function includeBooleanAttr(value) {
    return !!value || value === "";
  }
  function normalizeStyle(value) {
    if (isArray(value)) {
      const res = {};
      for (let i = 0; i < value.length; i++) {
        const item = value[i];
        const normalized = isString(item) ? parseStringStyle(item) : normalizeStyle(item);
        if (normalized) {
          for (const key in normalized) {
            res[key] = normalized[key];
          }
        }
      }
      return res;
    } else if (isString(value)) {
      return value;
    } else if (isObject(value)) {
      return value;
    }
  }
  var listDelimiterRE = /;(?![^(]*\))/g;
  var propertyDelimiterRE = /:(.+)/;
  function parseStringStyle(cssText) {
    const ret = {};
    cssText.split(listDelimiterRE).forEach((item) => {
      if (item) {
        const tmp = item.split(propertyDelimiterRE);
        tmp.length > 1 && (ret[tmp[0].trim()] = tmp[1].trim());
      }
    });
    return ret;
  }
  function normalizeClass(value) {
    let res = "";
    if (isString(value)) {
      res = value;
    } else if (isArray(value)) {
      for (let i = 0; i < value.length; i++) {
        const normalized = normalizeClass(value[i]);
        if (normalized) {
          res += normalized + " ";
        }
      }
    } else if (isObject(value)) {
      for (const name in value) {
        if (value[name]) {
          res += name + " ";
        }
      }
    }
    return res.trim();
  }
  var HTML_TAGS = "html,body,base,head,link,meta,style,title,address,article,aside,footer,header,h1,h2,h3,h4,h5,h6,nav,section,div,dd,dl,dt,figcaption,figure,picture,hr,img,li,main,ol,p,pre,ul,a,b,abbr,bdi,bdo,br,cite,code,data,dfn,em,i,kbd,mark,q,rp,rt,ruby,s,samp,small,span,strong,sub,sup,time,u,var,wbr,area,audio,map,track,video,embed,object,param,source,canvas,script,noscript,del,ins,caption,col,colgroup,table,thead,tbody,td,th,tr,button,datalist,fieldset,form,input,label,legend,meter,optgroup,option,output,progress,select,textarea,details,dialog,menu,summary,template,blockquote,iframe,tfoot";
  var SVG_TAGS = "svg,animate,animateMotion,animateTransform,circle,clipPath,color-profile,defs,desc,discard,ellipse,feBlend,feColorMatrix,feComponentTransfer,feComposite,feConvolveMatrix,feDiffuseLighting,feDisplacementMap,feDistanceLight,feDropShadow,feFlood,feFuncA,feFuncB,feFuncG,feFuncR,feGaussianBlur,feImage,feMerge,feMergeNode,feMorphology,feOffset,fePointLight,feSpecularLighting,feSpotLight,feTile,feTurbulence,filter,foreignObject,g,hatch,hatchpath,image,line,linearGradient,marker,mask,mesh,meshgradient,meshpatch,meshrow,metadata,mpath,path,pattern,polygon,polyline,radialGradient,rect,set,solidcolor,stop,switch,symbol,text,textPath,title,tspan,unknown,use,view";
  var isHTMLTag = /* @__PURE__ */ makeMap(HTML_TAGS);
  var isSVGTag = /* @__PURE__ */ makeMap(SVG_TAGS);
  var EMPTY_OBJ = true ? Object.freeze({}) : {};
  var EMPTY_ARR = true ? Object.freeze([]) : [];
  var NOOP = () => {
  };
  var NO = () => false;
  var onRE = /^on[^a-z]/;
  var isOn = (key) => onRE.test(key);
  var isModelListener = (key) => key.startsWith("onUpdate:");
  var extend = Object.assign;
  var remove = (arr, el) => {
    const i = arr.indexOf(el);
    if (i > -1) {
      arr.splice(i, 1);
    }
  };
  var hasOwnProperty = Object.prototype.hasOwnProperty;
  var hasOwn = (val, key) => hasOwnProperty.call(val, key);
  var isArray = Array.isArray;
  var isMap = (val) => toTypeString(val) === "[object Map]";
  var isSet = (val) => toTypeString(val) === "[object Set]";
  var isFunction = (val) => typeof val === "function";
  var isString = (val) => typeof val === "string";
  var isSymbol = (val) => typeof val === "symbol";
  var isObject = (val) => val !== null && typeof val === "object";
  var isPromise = (val) => {
    return isObject(val) && isFunction(val.then) && isFunction(val.catch);
  };
  var objectToString = Object.prototype.toString;
  var toTypeString = (value) => objectToString.call(value);
  var toRawType = (value) => {
    return toTypeString(value).slice(8, -1);
  };
  var isPlainObject = (val) => toTypeString(val) === "[object Object]";
  var isIntegerKey = (key) => isString(key) && key !== "NaN" && key[0] !== "-" && "" + parseInt(key, 10) === key;
  var isReservedProp = /* @__PURE__ */ makeMap(",key,ref,onVnodeBeforeMount,onVnodeMounted,onVnodeBeforeUpdate,onVnodeUpdated,onVnodeBeforeUnmount,onVnodeUnmounted");
  var cacheStringFunction = (fn) => {
    const cache = Object.create(null);
    return (str) => {
      const hit = cache[str];
      return hit || (cache[str] = fn(str));
    };
  };
  var camelizeRE = /-(\w)/g;
  var camelize = cacheStringFunction((str) => {
    return str.replace(camelizeRE, (_, c) => c ? c.toUpperCase() : "");
  });
  var hyphenateRE = /\B([A-Z])/g;
  var hyphenate = cacheStringFunction((str) => str.replace(hyphenateRE, "-$1").toLowerCase());
  var capitalize = cacheStringFunction((str) => str.charAt(0).toUpperCase() + str.slice(1));
  var toHandlerKey = cacheStringFunction((str) => str ? `on${capitalize(str)}` : ``);
  var hasChanged = (value, oldValue) => !Object.is(value, oldValue);
  var invokeArrayFns = (fns, arg) => {
    for (let i = 0; i < fns.length; i++) {
      fns[i](arg);
    }
  };
  var def = (obj, key, value) => {
    Object.defineProperty(obj, key, {
      configurable: true,
      enumerable: false,
      value
    });
  };
  var toNumber = (val) => {
    const n = parseFloat(val);
    return isNaN(n) ? val : n;
  };
  var _globalThis;
  var getGlobalThis = () => {
    return _globalThis || (_globalThis = typeof globalThis !== "undefined" ? globalThis : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : typeof global !== "undefined" ? global : {});
  };

  // node_modules/@vue/reactivity/dist/reactivity.esm-bundler.js
  function warn(msg, ...args) {
    console.warn(`[Vue warn] ${msg}`, ...args);
  }
  var activeEffectScope;
  var effectScopeStack = [];
  var EffectScope = class {
    constructor(detached = false) {
      this.active = true;
      this.effects = [];
      this.cleanups = [];
      if (!detached && activeEffectScope) {
        this.parent = activeEffectScope;
        this.index = (activeEffectScope.scopes || (activeEffectScope.scopes = [])).push(this) - 1;
      }
    }
    run(fn) {
      if (this.active) {
        try {
          this.on();
          return fn();
        } finally {
          this.off();
        }
      } else if (true) {
        warn(`cannot run an inactive effect scope.`);
      }
    }
    on() {
      if (this.active) {
        effectScopeStack.push(this);
        activeEffectScope = this;
      }
    }
    off() {
      if (this.active) {
        effectScopeStack.pop();
        activeEffectScope = effectScopeStack[effectScopeStack.length - 1];
      }
    }
    stop(fromParent) {
      if (this.active) {
        this.effects.forEach((e) => e.stop());
        this.cleanups.forEach((cleanup) => cleanup());
        if (this.scopes) {
          this.scopes.forEach((e) => e.stop(true));
        }
        if (this.parent && !fromParent) {
          const last = this.parent.scopes.pop();
          if (last && last !== this) {
            this.parent.scopes[this.index] = last;
            last.index = this.index;
          }
        }
        this.active = false;
      }
    }
  };
  function recordEffectScope(effect2, scope) {
    scope = scope || activeEffectScope;
    if (scope && scope.active) {
      scope.effects.push(effect2);
    }
  }
  var createDep = (effects) => {
    const dep = new Set(effects);
    dep.w = 0;
    dep.n = 0;
    return dep;
  };
  var wasTracked = (dep) => (dep.w & trackOpBit) > 0;
  var newTracked = (dep) => (dep.n & trackOpBit) > 0;
  var initDepMarkers = ({ deps }) => {
    if (deps.length) {
      for (let i = 0; i < deps.length; i++) {
        deps[i].w |= trackOpBit;
      }
    }
  };
  var finalizeDepMarkers = (effect2) => {
    const { deps } = effect2;
    if (deps.length) {
      let ptr = 0;
      for (let i = 0; i < deps.length; i++) {
        const dep = deps[i];
        if (wasTracked(dep) && !newTracked(dep)) {
          dep.delete(effect2);
        } else {
          deps[ptr++] = dep;
        }
        dep.w &= ~trackOpBit;
        dep.n &= ~trackOpBit;
      }
      deps.length = ptr;
    }
  };
  var targetMap = new WeakMap();
  var effectTrackDepth = 0;
  var trackOpBit = 1;
  var maxMarkerBits = 30;
  var effectStack = [];
  var activeEffect;
  var ITERATE_KEY = Symbol(true ? "iterate" : "");
  var MAP_KEY_ITERATE_KEY = Symbol(true ? "Map key iterate" : "");
  var ReactiveEffect = class {
    constructor(fn, scheduler = null, scope) {
      this.fn = fn;
      this.scheduler = scheduler;
      this.active = true;
      this.deps = [];
      recordEffectScope(this, scope);
    }
    run() {
      if (!this.active) {
        return this.fn();
      }
      if (!effectStack.includes(this)) {
        try {
          effectStack.push(activeEffect = this);
          enableTracking();
          trackOpBit = 1 << ++effectTrackDepth;
          if (effectTrackDepth <= maxMarkerBits) {
            initDepMarkers(this);
          } else {
            cleanupEffect(this);
          }
          return this.fn();
        } finally {
          if (effectTrackDepth <= maxMarkerBits) {
            finalizeDepMarkers(this);
          }
          trackOpBit = 1 << --effectTrackDepth;
          resetTracking();
          effectStack.pop();
          const n = effectStack.length;
          activeEffect = n > 0 ? effectStack[n - 1] : void 0;
        }
      }
    }
    stop() {
      if (this.active) {
        cleanupEffect(this);
        if (this.onStop) {
          this.onStop();
        }
        this.active = false;
      }
    }
  };
  function cleanupEffect(effect2) {
    const { deps } = effect2;
    if (deps.length) {
      for (let i = 0; i < deps.length; i++) {
        deps[i].delete(effect2);
      }
      deps.length = 0;
    }
  }
  var shouldTrack = true;
  var trackStack = [];
  function pauseTracking() {
    trackStack.push(shouldTrack);
    shouldTrack = false;
  }
  function enableTracking() {
    trackStack.push(shouldTrack);
    shouldTrack = true;
  }
  function resetTracking() {
    const last = trackStack.pop();
    shouldTrack = last === void 0 ? true : last;
  }
  function track(target, type, key) {
    if (!isTracking()) {
      return;
    }
    let depsMap = targetMap.get(target);
    if (!depsMap) {
      targetMap.set(target, depsMap = new Map());
    }
    let dep = depsMap.get(key);
    if (!dep) {
      depsMap.set(key, dep = createDep());
    }
    const eventInfo = true ? { effect: activeEffect, target, type, key } : void 0;
    trackEffects(dep, eventInfo);
  }
  function isTracking() {
    return shouldTrack && activeEffect !== void 0;
  }
  function trackEffects(dep, debuggerEventExtraInfo) {
    let shouldTrack2 = false;
    if (effectTrackDepth <= maxMarkerBits) {
      if (!newTracked(dep)) {
        dep.n |= trackOpBit;
        shouldTrack2 = !wasTracked(dep);
      }
    } else {
      shouldTrack2 = !dep.has(activeEffect);
    }
    if (shouldTrack2) {
      dep.add(activeEffect);
      activeEffect.deps.push(dep);
      if (activeEffect.onTrack) {
        activeEffect.onTrack(Object.assign({
          effect: activeEffect
        }, debuggerEventExtraInfo));
      }
    }
  }
  function trigger(target, type, key, newValue, oldValue, oldTarget) {
    const depsMap = targetMap.get(target);
    if (!depsMap) {
      return;
    }
    let deps = [];
    if (type === "clear") {
      deps = [...depsMap.values()];
    } else if (key === "length" && isArray(target)) {
      depsMap.forEach((dep, key2) => {
        if (key2 === "length" || key2 >= newValue) {
          deps.push(dep);
        }
      });
    } else {
      if (key !== void 0) {
        deps.push(depsMap.get(key));
      }
      switch (type) {
        case "add":
          if (!isArray(target)) {
            deps.push(depsMap.get(ITERATE_KEY));
            if (isMap(target)) {
              deps.push(depsMap.get(MAP_KEY_ITERATE_KEY));
            }
          } else if (isIntegerKey(key)) {
            deps.push(depsMap.get("length"));
          }
          break;
        case "delete":
          if (!isArray(target)) {
            deps.push(depsMap.get(ITERATE_KEY));
            if (isMap(target)) {
              deps.push(depsMap.get(MAP_KEY_ITERATE_KEY));
            }
          }
          break;
        case "set":
          if (isMap(target)) {
            deps.push(depsMap.get(ITERATE_KEY));
          }
          break;
      }
    }
    const eventInfo = true ? { target, type, key, newValue, oldValue, oldTarget } : void 0;
    if (deps.length === 1) {
      if (deps[0]) {
        if (true) {
          triggerEffects(deps[0], eventInfo);
        } else {
          triggerEffects(deps[0]);
        }
      }
    } else {
      const effects = [];
      for (const dep of deps) {
        if (dep) {
          effects.push(...dep);
        }
      }
      if (true) {
        triggerEffects(createDep(effects), eventInfo);
      } else {
        triggerEffects(createDep(effects));
      }
    }
  }
  function triggerEffects(dep, debuggerEventExtraInfo) {
    for (const effect2 of isArray(dep) ? dep : [...dep]) {
      if (effect2 !== activeEffect || effect2.allowRecurse) {
        if (effect2.onTrigger) {
          effect2.onTrigger(extend({ effect: effect2 }, debuggerEventExtraInfo));
        }
        if (effect2.scheduler) {
          effect2.scheduler();
        } else {
          effect2.run();
        }
      }
    }
  }
  var isNonTrackableKeys = /* @__PURE__ */ makeMap(`__proto__,__v_isRef,__isVue`);
  var builtInSymbols = new Set(Object.getOwnPropertyNames(Symbol).map((key) => Symbol[key]).filter(isSymbol));
  var get = /* @__PURE__ */ createGetter();
  var shallowGet = /* @__PURE__ */ createGetter(false, true);
  var readonlyGet = /* @__PURE__ */ createGetter(true);
  var shallowReadonlyGet = /* @__PURE__ */ createGetter(true, true);
  var arrayInstrumentations = /* @__PURE__ */ createArrayInstrumentations();
  function createArrayInstrumentations() {
    const instrumentations = {};
    ["includes", "indexOf", "lastIndexOf"].forEach((key) => {
      instrumentations[key] = function(...args) {
        const arr = toRaw(this);
        for (let i = 0, l = this.length; i < l; i++) {
          track(arr, "get", i + "");
        }
        const res = arr[key](...args);
        if (res === -1 || res === false) {
          return arr[key](...args.map(toRaw));
        } else {
          return res;
        }
      };
    });
    ["push", "pop", "shift", "unshift", "splice"].forEach((key) => {
      instrumentations[key] = function(...args) {
        pauseTracking();
        const res = toRaw(this)[key].apply(this, args);
        resetTracking();
        return res;
      };
    });
    return instrumentations;
  }
  function createGetter(isReadonly2 = false, shallow = false) {
    return function get4(target, key, receiver) {
      if (key === "__v_isReactive") {
        return !isReadonly2;
      } else if (key === "__v_isReadonly") {
        return isReadonly2;
      } else if (key === "__v_raw" && receiver === (isReadonly2 ? shallow ? shallowReadonlyMap : readonlyMap : shallow ? shallowReactiveMap : reactiveMap).get(target)) {
        return target;
      }
      const targetIsArray = isArray(target);
      if (!isReadonly2 && targetIsArray && hasOwn(arrayInstrumentations, key)) {
        return Reflect.get(arrayInstrumentations, key, receiver);
      }
      const res = Reflect.get(target, key, receiver);
      if (isSymbol(key) ? builtInSymbols.has(key) : isNonTrackableKeys(key)) {
        return res;
      }
      if (!isReadonly2) {
        track(target, "get", key);
      }
      if (shallow) {
        return res;
      }
      if (isRef(res)) {
        const shouldUnwrap = !targetIsArray || !isIntegerKey(key);
        return shouldUnwrap ? res.value : res;
      }
      if (isObject(res)) {
        return isReadonly2 ? readonly(res) : reactive(res);
      }
      return res;
    };
  }
  var set = /* @__PURE__ */ createSetter();
  var shallowSet = /* @__PURE__ */ createSetter(true);
  function createSetter(shallow = false) {
    return function set2(target, key, value, receiver) {
      let oldValue = target[key];
      if (!shallow) {
        value = toRaw(value);
        oldValue = toRaw(oldValue);
        if (!isArray(target) && isRef(oldValue) && !isRef(value)) {
          oldValue.value = value;
          return true;
        }
      }
      const hadKey = isArray(target) && isIntegerKey(key) ? Number(key) < target.length : hasOwn(target, key);
      const result = Reflect.set(target, key, value, receiver);
      if (target === toRaw(receiver)) {
        if (!hadKey) {
          trigger(target, "add", key, value);
        } else if (hasChanged(value, oldValue)) {
          trigger(target, "set", key, value, oldValue);
        }
      }
      return result;
    };
  }
  function deleteProperty(target, key) {
    const hadKey = hasOwn(target, key);
    const oldValue = target[key];
    const result = Reflect.deleteProperty(target, key);
    if (result && hadKey) {
      trigger(target, "delete", key, void 0, oldValue);
    }
    return result;
  }
  function has(target, key) {
    const result = Reflect.has(target, key);
    if (!isSymbol(key) || !builtInSymbols.has(key)) {
      track(target, "has", key);
    }
    return result;
  }
  function ownKeys(target) {
    track(target, "iterate", isArray(target) ? "length" : ITERATE_KEY);
    return Reflect.ownKeys(target);
  }
  var mutableHandlers = {
    get,
    set,
    deleteProperty,
    has,
    ownKeys
  };
  var readonlyHandlers = {
    get: readonlyGet,
    set(target, key) {
      if (true) {
        console.warn(`Set operation on key "${String(key)}" failed: target is readonly.`, target);
      }
      return true;
    },
    deleteProperty(target, key) {
      if (true) {
        console.warn(`Delete operation on key "${String(key)}" failed: target is readonly.`, target);
      }
      return true;
    }
  };
  var shallowReactiveHandlers = /* @__PURE__ */ extend({}, mutableHandlers, {
    get: shallowGet,
    set: shallowSet
  });
  var shallowReadonlyHandlers = /* @__PURE__ */ extend({}, readonlyHandlers, {
    get: shallowReadonlyGet
  });
  var toShallow = (value) => value;
  var getProto = (v) => Reflect.getPrototypeOf(v);
  function get$1(target, key, isReadonly2 = false, isShallow = false) {
    target = target["__v_raw"];
    const rawTarget = toRaw(target);
    const rawKey = toRaw(key);
    if (key !== rawKey) {
      !isReadonly2 && track(rawTarget, "get", key);
    }
    !isReadonly2 && track(rawTarget, "get", rawKey);
    const { has: has2 } = getProto(rawTarget);
    const wrap = isShallow ? toShallow : isReadonly2 ? toReadonly : toReactive;
    if (has2.call(rawTarget, key)) {
      return wrap(target.get(key));
    } else if (has2.call(rawTarget, rawKey)) {
      return wrap(target.get(rawKey));
    } else if (target !== rawTarget) {
      target.get(key);
    }
  }
  function has$1(key, isReadonly2 = false) {
    const target = this["__v_raw"];
    const rawTarget = toRaw(target);
    const rawKey = toRaw(key);
    if (key !== rawKey) {
      !isReadonly2 && track(rawTarget, "has", key);
    }
    !isReadonly2 && track(rawTarget, "has", rawKey);
    return key === rawKey ? target.has(key) : target.has(key) || target.has(rawKey);
  }
  function size(target, isReadonly2 = false) {
    target = target["__v_raw"];
    !isReadonly2 && track(toRaw(target), "iterate", ITERATE_KEY);
    return Reflect.get(target, "size", target);
  }
  function add(value) {
    value = toRaw(value);
    const target = toRaw(this);
    const proto = getProto(target);
    const hadKey = proto.has.call(target, value);
    if (!hadKey) {
      target.add(value);
      trigger(target, "add", value, value);
    }
    return this;
  }
  function set$1(key, value) {
    value = toRaw(value);
    const target = toRaw(this);
    const { has: has2, get: get4 } = getProto(target);
    let hadKey = has2.call(target, key);
    if (!hadKey) {
      key = toRaw(key);
      hadKey = has2.call(target, key);
    } else if (true) {
      checkIdentityKeys(target, has2, key);
    }
    const oldValue = get4.call(target, key);
    target.set(key, value);
    if (!hadKey) {
      trigger(target, "add", key, value);
    } else if (hasChanged(value, oldValue)) {
      trigger(target, "set", key, value, oldValue);
    }
    return this;
  }
  function deleteEntry(key) {
    const target = toRaw(this);
    const { has: has2, get: get4 } = getProto(target);
    let hadKey = has2.call(target, key);
    if (!hadKey) {
      key = toRaw(key);
      hadKey = has2.call(target, key);
    } else if (true) {
      checkIdentityKeys(target, has2, key);
    }
    const oldValue = get4 ? get4.call(target, key) : void 0;
    const result = target.delete(key);
    if (hadKey) {
      trigger(target, "delete", key, void 0, oldValue);
    }
    return result;
  }
  function clear() {
    const target = toRaw(this);
    const hadItems = target.size !== 0;
    const oldTarget = true ? isMap(target) ? new Map(target) : new Set(target) : void 0;
    const result = target.clear();
    if (hadItems) {
      trigger(target, "clear", void 0, void 0, oldTarget);
    }
    return result;
  }
  function createForEach(isReadonly2, isShallow) {
    return function forEach(callback, thisArg) {
      const observed = this;
      const target = observed["__v_raw"];
      const rawTarget = toRaw(target);
      const wrap = isShallow ? toShallow : isReadonly2 ? toReadonly : toReactive;
      !isReadonly2 && track(rawTarget, "iterate", ITERATE_KEY);
      return target.forEach((value, key) => {
        return callback.call(thisArg, wrap(value), wrap(key), observed);
      });
    };
  }
  function createIterableMethod(method, isReadonly2, isShallow) {
    return function(...args) {
      const target = this["__v_raw"];
      const rawTarget = toRaw(target);
      const targetIsMap = isMap(rawTarget);
      const isPair = method === "entries" || method === Symbol.iterator && targetIsMap;
      const isKeyOnly = method === "keys" && targetIsMap;
      const innerIterator = target[method](...args);
      const wrap = isShallow ? toShallow : isReadonly2 ? toReadonly : toReactive;
      !isReadonly2 && track(rawTarget, "iterate", isKeyOnly ? MAP_KEY_ITERATE_KEY : ITERATE_KEY);
      return {
        next() {
          const { value, done } = innerIterator.next();
          return done ? { value, done } : {
            value: isPair ? [wrap(value[0]), wrap(value[1])] : wrap(value),
            done
          };
        },
        [Symbol.iterator]() {
          return this;
        }
      };
    };
  }
  function createReadonlyMethod(type) {
    return function(...args) {
      if (true) {
        const key = args[0] ? `on key "${args[0]}" ` : ``;
        console.warn(`${capitalize(type)} operation ${key}failed: target is readonly.`, toRaw(this));
      }
      return type === "delete" ? false : this;
    };
  }
  function createInstrumentations() {
    const mutableInstrumentations2 = {
      get(key) {
        return get$1(this, key);
      },
      get size() {
        return size(this);
      },
      has: has$1,
      add,
      set: set$1,
      delete: deleteEntry,
      clear,
      forEach: createForEach(false, false)
    };
    const shallowInstrumentations2 = {
      get(key) {
        return get$1(this, key, false, true);
      },
      get size() {
        return size(this);
      },
      has: has$1,
      add,
      set: set$1,
      delete: deleteEntry,
      clear,
      forEach: createForEach(false, true)
    };
    const readonlyInstrumentations2 = {
      get(key) {
        return get$1(this, key, true);
      },
      get size() {
        return size(this, true);
      },
      has(key) {
        return has$1.call(this, key, true);
      },
      add: createReadonlyMethod("add"),
      set: createReadonlyMethod("set"),
      delete: createReadonlyMethod("delete"),
      clear: createReadonlyMethod("clear"),
      forEach: createForEach(true, false)
    };
    const shallowReadonlyInstrumentations2 = {
      get(key) {
        return get$1(this, key, true, true);
      },
      get size() {
        return size(this, true);
      },
      has(key) {
        return has$1.call(this, key, true);
      },
      add: createReadonlyMethod("add"),
      set: createReadonlyMethod("set"),
      delete: createReadonlyMethod("delete"),
      clear: createReadonlyMethod("clear"),
      forEach: createForEach(true, true)
    };
    const iteratorMethods = ["keys", "values", "entries", Symbol.iterator];
    iteratorMethods.forEach((method) => {
      mutableInstrumentations2[method] = createIterableMethod(method, false, false);
      readonlyInstrumentations2[method] = createIterableMethod(method, true, false);
      shallowInstrumentations2[method] = createIterableMethod(method, false, true);
      shallowReadonlyInstrumentations2[method] = createIterableMethod(method, true, true);
    });
    return [
      mutableInstrumentations2,
      readonlyInstrumentations2,
      shallowInstrumentations2,
      shallowReadonlyInstrumentations2
    ];
  }
  var [mutableInstrumentations, readonlyInstrumentations, shallowInstrumentations, shallowReadonlyInstrumentations] = /* @__PURE__ */ createInstrumentations();
  function createInstrumentationGetter(isReadonly2, shallow) {
    const instrumentations = shallow ? isReadonly2 ? shallowReadonlyInstrumentations : shallowInstrumentations : isReadonly2 ? readonlyInstrumentations : mutableInstrumentations;
    return (target, key, receiver) => {
      if (key === "__v_isReactive") {
        return !isReadonly2;
      } else if (key === "__v_isReadonly") {
        return isReadonly2;
      } else if (key === "__v_raw") {
        return target;
      }
      return Reflect.get(hasOwn(instrumentations, key) && key in target ? instrumentations : target, key, receiver);
    };
  }
  var mutableCollectionHandlers = {
    get: /* @__PURE__ */ createInstrumentationGetter(false, false)
  };
  var shallowCollectionHandlers = {
    get: /* @__PURE__ */ createInstrumentationGetter(false, true)
  };
  var readonlyCollectionHandlers = {
    get: /* @__PURE__ */ createInstrumentationGetter(true, false)
  };
  var shallowReadonlyCollectionHandlers = {
    get: /* @__PURE__ */ createInstrumentationGetter(true, true)
  };
  function checkIdentityKeys(target, has2, key) {
    const rawKey = toRaw(key);
    if (rawKey !== key && has2.call(target, rawKey)) {
      const type = toRawType(target);
      console.warn(`Reactive ${type} contains both the raw and reactive versions of the same object${type === `Map` ? ` as keys` : ``}, which can lead to inconsistencies. Avoid differentiating between the raw and reactive versions of an object and only use the reactive version if possible.`);
    }
  }
  var reactiveMap = new WeakMap();
  var shallowReactiveMap = new WeakMap();
  var readonlyMap = new WeakMap();
  var shallowReadonlyMap = new WeakMap();
  function targetTypeMap(rawType) {
    switch (rawType) {
      case "Object":
      case "Array":
        return 1;
      case "Map":
      case "Set":
      case "WeakMap":
      case "WeakSet":
        return 2;
      default:
        return 0;
    }
  }
  function getTargetType(value) {
    return value["__v_skip"] || !Object.isExtensible(value) ? 0 : targetTypeMap(toRawType(value));
  }
  function reactive(target) {
    if (target && target["__v_isReadonly"]) {
      return target;
    }
    return createReactiveObject(target, false, mutableHandlers, mutableCollectionHandlers, reactiveMap);
  }
  function shallowReactive(target) {
    return createReactiveObject(target, false, shallowReactiveHandlers, shallowCollectionHandlers, shallowReactiveMap);
  }
  function readonly(target) {
    return createReactiveObject(target, true, readonlyHandlers, readonlyCollectionHandlers, readonlyMap);
  }
  function shallowReadonly(target) {
    return createReactiveObject(target, true, shallowReadonlyHandlers, shallowReadonlyCollectionHandlers, shallowReadonlyMap);
  }
  function createReactiveObject(target, isReadonly2, baseHandlers, collectionHandlers, proxyMap) {
    if (!isObject(target)) {
      if (true) {
        console.warn(`value cannot be made reactive: ${String(target)}`);
      }
      return target;
    }
    if (target["__v_raw"] && !(isReadonly2 && target["__v_isReactive"])) {
      return target;
    }
    const existingProxy = proxyMap.get(target);
    if (existingProxy) {
      return existingProxy;
    }
    const targetType = getTargetType(target);
    if (targetType === 0) {
      return target;
    }
    const proxy = new Proxy(target, targetType === 2 ? collectionHandlers : baseHandlers);
    proxyMap.set(target, proxy);
    return proxy;
  }
  function isReactive(value) {
    if (isReadonly(value)) {
      return isReactive(value["__v_raw"]);
    }
    return !!(value && value["__v_isReactive"]);
  }
  function isReadonly(value) {
    return !!(value && value["__v_isReadonly"]);
  }
  function isProxy(value) {
    return isReactive(value) || isReadonly(value);
  }
  function toRaw(observed) {
    const raw = observed && observed["__v_raw"];
    return raw ? toRaw(raw) : observed;
  }
  function markRaw(value) {
    def(value, "__v_skip", true);
    return value;
  }
  var toReactive = (value) => isObject(value) ? reactive(value) : value;
  var toReadonly = (value) => isObject(value) ? readonly(value) : value;
  function trackRefValue(ref2) {
    if (isTracking()) {
      ref2 = toRaw(ref2);
      if (!ref2.dep) {
        ref2.dep = createDep();
      }
      if (true) {
        trackEffects(ref2.dep, {
          target: ref2,
          type: "get",
          key: "value"
        });
      } else {
        trackEffects(ref2.dep);
      }
    }
  }
  function triggerRefValue(ref2, newVal) {
    ref2 = toRaw(ref2);
    if (ref2.dep) {
      if (true) {
        triggerEffects(ref2.dep, {
          target: ref2,
          type: "set",
          key: "value",
          newValue: newVal
        });
      } else {
        triggerEffects(ref2.dep);
      }
    }
  }
  function isRef(r) {
    return Boolean(r && r.__v_isRef === true);
  }
  function ref(value) {
    return createRef(value, false);
  }
  function createRef(rawValue, shallow) {
    if (isRef(rawValue)) {
      return rawValue;
    }
    return new RefImpl(rawValue, shallow);
  }
  var RefImpl = class {
    constructor(value, _shallow) {
      this._shallow = _shallow;
      this.dep = void 0;
      this.__v_isRef = true;
      this._rawValue = _shallow ? value : toRaw(value);
      this._value = _shallow ? value : toReactive(value);
    }
    get value() {
      trackRefValue(this);
      return this._value;
    }
    set value(newVal) {
      newVal = this._shallow ? newVal : toRaw(newVal);
      if (hasChanged(newVal, this._rawValue)) {
        this._rawValue = newVal;
        this._value = this._shallow ? newVal : toReactive(newVal);
        triggerRefValue(this, newVal);
      }
    }
  };
  function unref(ref2) {
    return isRef(ref2) ? ref2.value : ref2;
  }
  var shallowUnwrapHandlers = {
    get: (target, key, receiver) => unref(Reflect.get(target, key, receiver)),
    set: (target, key, value, receiver) => {
      const oldValue = target[key];
      if (isRef(oldValue) && !isRef(value)) {
        oldValue.value = value;
        return true;
      } else {
        return Reflect.set(target, key, value, receiver);
      }
    }
  };
  function proxyRefs(objectWithRefs) {
    return isReactive(objectWithRefs) ? objectWithRefs : new Proxy(objectWithRefs, shallowUnwrapHandlers);
  }
  var ComputedRefImpl = class {
    constructor(getter, _setter, isReadonly2) {
      this._setter = _setter;
      this.dep = void 0;
      this._dirty = true;
      this.__v_isRef = true;
      this.effect = new ReactiveEffect(getter, () => {
        if (!this._dirty) {
          this._dirty = true;
          triggerRefValue(this);
        }
      });
      this["__v_isReadonly"] = isReadonly2;
    }
    get value() {
      const self2 = toRaw(this);
      trackRefValue(self2);
      if (self2._dirty) {
        self2._dirty = false;
        self2._value = self2.effect.run();
      }
      return self2._value;
    }
    set value(newValue) {
      this._setter(newValue);
    }
  };
  function computed(getterOrOptions, debugOptions) {
    let getter;
    let setter;
    const onlyGetter = isFunction(getterOrOptions);
    if (onlyGetter) {
      getter = getterOrOptions;
      setter = true ? () => {
        console.warn("Write operation failed: computed value is readonly");
      } : NOOP;
    } else {
      getter = getterOrOptions.get;
      setter = getterOrOptions.set;
    }
    const cRef = new ComputedRefImpl(getter, setter, onlyGetter || !setter);
    if (debugOptions) {
      cRef.effect.onTrack = debugOptions.onTrack;
      cRef.effect.onTrigger = debugOptions.onTrigger;
    }
    return cRef;
  }
  var _a;
  var tick = Promise.resolve();
  _a = "__v_isReadonly";

  // node_modules/@vue/runtime-core/dist/runtime-core.esm-bundler.js
  var isHmrUpdating = false;
  var hmrDirtyComponents = new Set();
  if (true) {
    getGlobalThis().__VUE_HMR_RUNTIME__ = {
      createRecord: tryWrap(createRecord),
      rerender: tryWrap(rerender),
      reload: tryWrap(reload)
    };
  }
  var map = new Map();
  function registerHMR(instance) {
    const id = instance.type.__hmrId;
    let record = map.get(id);
    if (!record) {
      createRecord(id);
      record = map.get(id);
    }
    record.add(instance);
  }
  function unregisterHMR(instance) {
    map.get(instance.type.__hmrId).delete(instance);
  }
  function createRecord(id) {
    if (map.has(id)) {
      return false;
    }
    map.set(id, new Set());
    return true;
  }
  function normalizeClassComponent(component) {
    return isClassComponent(component) ? component.__vccOpts : component;
  }
  function rerender(id, newRender) {
    const record = map.get(id);
    if (!record) {
      return;
    }
    [...record].forEach((instance) => {
      if (newRender) {
        instance.render = newRender;
        normalizeClassComponent(instance.type).render = newRender;
      }
      instance.renderCache = [];
      isHmrUpdating = true;
      instance.update();
      isHmrUpdating = false;
    });
  }
  function reload(id, newComp) {
    const record = map.get(id);
    if (!record)
      return;
    newComp = normalizeClassComponent(newComp);
    const instances = [...record];
    for (const instance of instances) {
      const oldComp = normalizeClassComponent(instance.type);
      if (!hmrDirtyComponents.has(oldComp)) {
        extend(oldComp, newComp);
        for (const key in oldComp) {
          if (key !== "__file" && !(key in newComp)) {
            delete oldComp[key];
          }
        }
        hmrDirtyComponents.add(oldComp);
      }
      instance.appContext.optionsCache.delete(instance.type);
      if (instance.ceReload) {
        hmrDirtyComponents.add(oldComp);
        instance.ceReload(newComp.styles);
        hmrDirtyComponents.delete(oldComp);
      } else if (instance.parent) {
        queueJob(instance.parent.update);
        if (instance.parent.type.__asyncLoader && instance.parent.ceReload) {
          instance.parent.ceReload(newComp.styles);
        }
      } else if (instance.appContext.reload) {
        instance.appContext.reload();
      } else if (typeof window !== "undefined") {
        window.location.reload();
      } else {
        console.warn("[HMR] Root or manually mounted instance modified. Full reload required.");
      }
    }
    queuePostFlushCb(() => {
      for (const instance of instances) {
        hmrDirtyComponents.delete(normalizeClassComponent(instance.type));
      }
    });
  }
  function tryWrap(fn) {
    return (id, arg) => {
      try {
        return fn(id, arg);
      } catch (e) {
        console.error(e);
        console.warn(`[HMR] Something went wrong during Vue component hot-reload. Full reload required.`);
      }
    };
  }
  var devtools;
  var buffer = [];
  function emit(event, ...args) {
    if (devtools) {
      devtools.emit(event, ...args);
    } else {
      buffer.push({ event, args });
    }
  }
  function setDevtoolsHook(hook, target) {
    devtools = hook;
    if (devtools) {
      devtools.enabled = true;
      buffer.forEach(({ event, args }) => devtools.emit(event, ...args));
      buffer = [];
    } else {
      const replay = target.__VUE_DEVTOOLS_HOOK_REPLAY__ = target.__VUE_DEVTOOLS_HOOK_REPLAY__ || [];
      replay.push((newHook) => {
        setDevtoolsHook(newHook, target);
      });
    }
  }
  function devtoolsInitApp(app, version9) {
    emit("app:init", app, version9, {
      Fragment,
      Text,
      Comment,
      Static
    });
  }
  function devtoolsUnmountApp(app) {
    emit("app:unmount", app);
  }
  var devtoolsComponentAdded = /* @__PURE__ */ createDevtoolsComponentHook("component:added");
  var devtoolsComponentUpdated = /* @__PURE__ */ createDevtoolsComponentHook("component:updated");
  var devtoolsComponentRemoved = /* @__PURE__ */ createDevtoolsComponentHook("component:removed");
  function createDevtoolsComponentHook(hook) {
    return (component) => {
      emit(hook, component.appContext.app, component.uid, component.parent ? component.parent.uid : void 0, component);
    };
  }
  var devtoolsPerfStart = /* @__PURE__ */ createDevtoolsPerformanceHook("perf:start");
  var devtoolsPerfEnd = /* @__PURE__ */ createDevtoolsPerformanceHook("perf:end");
  function createDevtoolsPerformanceHook(hook) {
    return (component, type, time) => {
      emit(hook, component.appContext.app, component.uid, component, type, time);
    };
  }
  function devtoolsComponentEmit(component, event, params) {
    emit("component:emit", component.appContext.app, component, event, params);
  }
  function emit$1(instance, event, ...rawArgs) {
    const props = instance.vnode.props || EMPTY_OBJ;
    if (true) {
      const { emitsOptions, propsOptions: [propsOptions] } = instance;
      if (emitsOptions) {
        if (!(event in emitsOptions) && true) {
          if (!propsOptions || !(toHandlerKey(event) in propsOptions)) {
            warn2(`Component emitted event "${event}" but it is neither declared in the emits option nor as an "${toHandlerKey(event)}" prop.`);
          }
        } else {
          const validator = emitsOptions[event];
          if (isFunction(validator)) {
            const isValid = validator(...rawArgs);
            if (!isValid) {
              warn2(`Invalid event arguments: event validation failed for event "${event}".`);
            }
          }
        }
      }
    }
    let args = rawArgs;
    const isModelListener2 = event.startsWith("update:");
    const modelArg = isModelListener2 && event.slice(7);
    if (modelArg && modelArg in props) {
      const modifiersKey = `${modelArg === "modelValue" ? "model" : modelArg}Modifiers`;
      const { number, trim } = props[modifiersKey] || EMPTY_OBJ;
      if (trim) {
        args = rawArgs.map((a) => a.trim());
      } else if (number) {
        args = rawArgs.map(toNumber);
      }
    }
    if (true) {
      devtoolsComponentEmit(instance, event, args);
    }
    if (true) {
      const lowerCaseEvent = event.toLowerCase();
      if (lowerCaseEvent !== event && props[toHandlerKey(lowerCaseEvent)]) {
        warn2(`Event "${lowerCaseEvent}" is emitted in component ${formatComponentName(instance, instance.type)} but the handler is registered for "${event}". Note that HTML attributes are case-insensitive and you cannot use v-on to listen to camelCase events when using in-DOM templates. You should probably use "${hyphenate(event)}" instead of "${event}".`);
      }
    }
    let handlerName;
    let handler = props[handlerName = toHandlerKey(event)] || props[handlerName = toHandlerKey(camelize(event))];
    if (!handler && isModelListener2) {
      handler = props[handlerName = toHandlerKey(hyphenate(event))];
    }
    if (handler) {
      callWithAsyncErrorHandling(handler, instance, 6, args);
    }
    const onceHandler = props[handlerName + `Once`];
    if (onceHandler) {
      if (!instance.emitted) {
        instance.emitted = {};
      } else if (instance.emitted[handlerName]) {
        return;
      }
      instance.emitted[handlerName] = true;
      callWithAsyncErrorHandling(onceHandler, instance, 6, args);
    }
  }
  function normalizeEmitsOptions(comp, appContext, asMixin = false) {
    const cache = appContext.emitsCache;
    const cached = cache.get(comp);
    if (cached !== void 0) {
      return cached;
    }
    const raw = comp.emits;
    let normalized = {};
    let hasExtends = false;
    if (__VUE_OPTIONS_API__ && !isFunction(comp)) {
      const extendEmits = (raw2) => {
        const normalizedFromExtend = normalizeEmitsOptions(raw2, appContext, true);
        if (normalizedFromExtend) {
          hasExtends = true;
          extend(normalized, normalizedFromExtend);
        }
      };
      if (!asMixin && appContext.mixins.length) {
        appContext.mixins.forEach(extendEmits);
      }
      if (comp.extends) {
        extendEmits(comp.extends);
      }
      if (comp.mixins) {
        comp.mixins.forEach(extendEmits);
      }
    }
    if (!raw && !hasExtends) {
      cache.set(comp, null);
      return null;
    }
    if (isArray(raw)) {
      raw.forEach((key) => normalized[key] = null);
    } else {
      extend(normalized, raw);
    }
    cache.set(comp, normalized);
    return normalized;
  }
  function isEmitListener(options, key) {
    if (!options || !isOn(key)) {
      return false;
    }
    key = key.slice(2).replace(/Once$/, "");
    return hasOwn(options, key[0].toLowerCase() + key.slice(1)) || hasOwn(options, hyphenate(key)) || hasOwn(options, key);
  }
  var currentRenderingInstance = null;
  var currentScopeId = null;
  function setCurrentRenderingInstance(instance) {
    const prev = currentRenderingInstance;
    currentRenderingInstance = instance;
    currentScopeId = instance && instance.type.__scopeId || null;
    return prev;
  }
  function withCtx(fn, ctx = currentRenderingInstance, isNonScopedSlot) {
    if (!ctx)
      return fn;
    if (fn._n) {
      return fn;
    }
    const renderFnWithContext = (...args) => {
      if (renderFnWithContext._d) {
        setBlockTracking(-1);
      }
      const prevInstance = setCurrentRenderingInstance(ctx);
      const res = fn(...args);
      setCurrentRenderingInstance(prevInstance);
      if (renderFnWithContext._d) {
        setBlockTracking(1);
      }
      if (true) {
        devtoolsComponentUpdated(ctx);
      }
      return res;
    };
    renderFnWithContext._n = true;
    renderFnWithContext._c = true;
    renderFnWithContext._d = true;
    return renderFnWithContext;
  }
  var accessedAttrs = false;
  function markAttrsAccessed() {
    accessedAttrs = true;
  }
  function renderComponentRoot(instance) {
    const { type: Component, vnode, proxy, withProxy, props, propsOptions: [propsOptions], slots, attrs, emit: emit2, render, renderCache, data, setupState, ctx, inheritAttrs } = instance;
    let result;
    let fallthroughAttrs;
    const prev = setCurrentRenderingInstance(instance);
    if (true) {
      accessedAttrs = false;
    }
    try {
      if (vnode.shapeFlag & 4) {
        const proxyToUse = withProxy || proxy;
        result = normalizeVNode(render.call(proxyToUse, proxyToUse, renderCache, props, setupState, data, ctx));
        fallthroughAttrs = attrs;
      } else {
        const render2 = Component;
        if (attrs === props) {
          markAttrsAccessed();
        }
        result = normalizeVNode(render2.length > 1 ? render2(props, true ? {
          get attrs() {
            markAttrsAccessed();
            return attrs;
          },
          slots,
          emit: emit2
        } : { attrs, slots, emit: emit2 }) : render2(props, null));
        fallthroughAttrs = Component.props ? attrs : getFunctionalFallthrough(attrs);
      }
    } catch (err) {
      blockStack.length = 0;
      handleError(err, instance, 1);
      result = createVNode(Comment);
    }
    let root = result;
    let setRoot = void 0;
    if (result.patchFlag > 0 && result.patchFlag & 2048) {
      [root, setRoot] = getChildRoot(result);
    }
    if (fallthroughAttrs && inheritAttrs !== false) {
      const keys = Object.keys(fallthroughAttrs);
      const { shapeFlag } = root;
      if (keys.length) {
        if (shapeFlag & (1 | 6)) {
          if (propsOptions && keys.some(isModelListener)) {
            fallthroughAttrs = filterModelListeners(fallthroughAttrs, propsOptions);
          }
          root = cloneVNode(root, fallthroughAttrs);
        } else if (!accessedAttrs && root.type !== Comment) {
          const allAttrs = Object.keys(attrs);
          const eventAttrs = [];
          const extraAttrs = [];
          for (let i = 0, l = allAttrs.length; i < l; i++) {
            const key = allAttrs[i];
            if (isOn(key)) {
              if (!isModelListener(key)) {
                eventAttrs.push(key[2].toLowerCase() + key.slice(3));
              }
            } else {
              extraAttrs.push(key);
            }
          }
          if (extraAttrs.length) {
            warn2(`Extraneous non-props attributes (${extraAttrs.join(", ")}) were passed to component but could not be automatically inherited because component renders fragment or text root nodes.`);
          }
          if (eventAttrs.length) {
            warn2(`Extraneous non-emits event listeners (${eventAttrs.join(", ")}) were passed to component but could not be automatically inherited because component renders fragment or text root nodes. If the listener is intended to be a component custom event listener only, declare it using the "emits" option.`);
          }
        }
      }
    }
    if (vnode.dirs) {
      if (!isElementRoot(root)) {
        warn2(`Runtime directive used on component with non-element root node. The directives will not function as intended.`);
      }
      root.dirs = root.dirs ? root.dirs.concat(vnode.dirs) : vnode.dirs;
    }
    if (vnode.transition) {
      if (!isElementRoot(root)) {
        warn2(`Component inside <Transition> renders non-element root node that cannot be animated.`);
      }
      root.transition = vnode.transition;
    }
    if (setRoot) {
      setRoot(root);
    } else {
      result = root;
    }
    setCurrentRenderingInstance(prev);
    return result;
  }
  var getChildRoot = (vnode) => {
    const rawChildren = vnode.children;
    const dynamicChildren = vnode.dynamicChildren;
    const childRoot = filterSingleRoot(rawChildren);
    if (!childRoot) {
      return [vnode, void 0];
    }
    const index = rawChildren.indexOf(childRoot);
    const dynamicIndex = dynamicChildren ? dynamicChildren.indexOf(childRoot) : -1;
    const setRoot = (updatedRoot) => {
      rawChildren[index] = updatedRoot;
      if (dynamicChildren) {
        if (dynamicIndex > -1) {
          dynamicChildren[dynamicIndex] = updatedRoot;
        } else if (updatedRoot.patchFlag > 0) {
          vnode.dynamicChildren = [...dynamicChildren, updatedRoot];
        }
      }
    };
    return [normalizeVNode(childRoot), setRoot];
  };
  function filterSingleRoot(children) {
    let singleRoot;
    for (let i = 0; i < children.length; i++) {
      const child = children[i];
      if (isVNode(child)) {
        if (child.type !== Comment || child.children === "v-if") {
          if (singleRoot) {
            return;
          } else {
            singleRoot = child;
          }
        }
      } else {
        return;
      }
    }
    return singleRoot;
  }
  var getFunctionalFallthrough = (attrs) => {
    let res;
    for (const key in attrs) {
      if (key === "class" || key === "style" || isOn(key)) {
        (res || (res = {}))[key] = attrs[key];
      }
    }
    return res;
  };
  var filterModelListeners = (attrs, props) => {
    const res = {};
    for (const key in attrs) {
      if (!isModelListener(key) || !(key.slice(9) in props)) {
        res[key] = attrs[key];
      }
    }
    return res;
  };
  var isElementRoot = (vnode) => {
    return vnode.shapeFlag & (6 | 1) || vnode.type === Comment;
  };
  function shouldUpdateComponent(prevVNode, nextVNode, optimized) {
    const { props: prevProps, children: prevChildren, component } = prevVNode;
    const { props: nextProps, children: nextChildren, patchFlag } = nextVNode;
    const emits = component.emitsOptions;
    if ((prevChildren || nextChildren) && isHmrUpdating) {
      return true;
    }
    if (nextVNode.dirs || nextVNode.transition) {
      return true;
    }
    if (optimized && patchFlag >= 0) {
      if (patchFlag & 1024) {
        return true;
      }
      if (patchFlag & 16) {
        if (!prevProps) {
          return !!nextProps;
        }
        return hasPropsChanged(prevProps, nextProps, emits);
      } else if (patchFlag & 8) {
        const dynamicProps = nextVNode.dynamicProps;
        for (let i = 0; i < dynamicProps.length; i++) {
          const key = dynamicProps[i];
          if (nextProps[key] !== prevProps[key] && !isEmitListener(emits, key)) {
            return true;
          }
        }
      }
    } else {
      if (prevChildren || nextChildren) {
        if (!nextChildren || !nextChildren.$stable) {
          return true;
        }
      }
      if (prevProps === nextProps) {
        return false;
      }
      if (!prevProps) {
        return !!nextProps;
      }
      if (!nextProps) {
        return true;
      }
      return hasPropsChanged(prevProps, nextProps, emits);
    }
    return false;
  }
  function hasPropsChanged(prevProps, nextProps, emitsOptions) {
    const nextKeys = Object.keys(nextProps);
    if (nextKeys.length !== Object.keys(prevProps).length) {
      return true;
    }
    for (let i = 0; i < nextKeys.length; i++) {
      const key = nextKeys[i];
      if (nextProps[key] !== prevProps[key] && !isEmitListener(emitsOptions, key)) {
        return true;
      }
    }
    return false;
  }
  function updateHOCHostEl({ vnode, parent }, el) {
    while (parent && parent.subTree === vnode) {
      (vnode = parent.vnode).el = el;
      parent = parent.parent;
    }
  }
  var isSuspense = (type) => type.__isSuspense;
  function queueEffectWithSuspense(fn, suspense) {
    if (suspense && suspense.pendingBranch) {
      if (isArray(fn)) {
        suspense.effects.push(...fn);
      } else {
        suspense.effects.push(fn);
      }
    } else {
      queuePostFlushCb(fn);
    }
  }
  function provide(key, value) {
    if (!currentInstance) {
      if (true) {
        warn2(`provide() can only be used inside setup().`);
      }
    } else {
      let provides = currentInstance.provides;
      const parentProvides = currentInstance.parent && currentInstance.parent.provides;
      if (parentProvides === provides) {
        provides = currentInstance.provides = Object.create(parentProvides);
      }
      provides[key] = value;
    }
  }
  function inject(key, defaultValue, treatDefaultAsFactory = false) {
    const instance = currentInstance || currentRenderingInstance;
    if (instance) {
      const provides = instance.parent == null ? instance.vnode.appContext && instance.vnode.appContext.provides : instance.parent.provides;
      if (provides && key in provides) {
        return provides[key];
      } else if (arguments.length > 1) {
        return treatDefaultAsFactory && isFunction(defaultValue) ? defaultValue.call(instance.proxy) : defaultValue;
      } else if (true) {
        warn2(`injection "${String(key)}" not found.`);
      }
    } else if (true) {
      warn2(`inject() can only be used inside setup() or functional components.`);
    }
  }
  function useTransitionState() {
    const state = {
      isMounted: false,
      isLeaving: false,
      isUnmounting: false,
      leavingVNodes: new Map()
    };
    onMounted(() => {
      state.isMounted = true;
    });
    onBeforeUnmount(() => {
      state.isUnmounting = true;
    });
    return state;
  }
  var TransitionHookValidator = [Function, Array];
  var BaseTransitionImpl = {
    name: `BaseTransition`,
    props: {
      mode: String,
      appear: Boolean,
      persisted: Boolean,
      onBeforeEnter: TransitionHookValidator,
      onEnter: TransitionHookValidator,
      onAfterEnter: TransitionHookValidator,
      onEnterCancelled: TransitionHookValidator,
      onBeforeLeave: TransitionHookValidator,
      onLeave: TransitionHookValidator,
      onAfterLeave: TransitionHookValidator,
      onLeaveCancelled: TransitionHookValidator,
      onBeforeAppear: TransitionHookValidator,
      onAppear: TransitionHookValidator,
      onAfterAppear: TransitionHookValidator,
      onAppearCancelled: TransitionHookValidator
    },
    setup(props, { slots }) {
      const instance = getCurrentInstance();
      const state = useTransitionState();
      let prevTransitionKey;
      return () => {
        const children = slots.default && getTransitionRawChildren(slots.default(), true);
        if (!children || !children.length) {
          return;
        }
        if (children.length > 1) {
          warn2("<transition> can only be used on a single element or component. Use <transition-group> for lists.");
        }
        const rawProps = toRaw(props);
        const { mode } = rawProps;
        if (mode && !["in-out", "out-in", "default"].includes(mode)) {
          warn2(`invalid <transition> mode: ${mode}`);
        }
        const child = children[0];
        if (state.isLeaving) {
          return emptyPlaceholder(child);
        }
        const innerChild = getKeepAliveChild(child);
        if (!innerChild) {
          return emptyPlaceholder(child);
        }
        const enterHooks = resolveTransitionHooks(innerChild, rawProps, state, instance);
        setTransitionHooks(innerChild, enterHooks);
        const oldChild = instance.subTree;
        const oldInnerChild = oldChild && getKeepAliveChild(oldChild);
        let transitionKeyChanged = false;
        const { getTransitionKey } = innerChild.type;
        if (getTransitionKey) {
          const key = getTransitionKey();
          if (prevTransitionKey === void 0) {
            prevTransitionKey = key;
          } else if (key !== prevTransitionKey) {
            prevTransitionKey = key;
            transitionKeyChanged = true;
          }
        }
        if (oldInnerChild && oldInnerChild.type !== Comment && (!isSameVNodeType(innerChild, oldInnerChild) || transitionKeyChanged)) {
          const leavingHooks = resolveTransitionHooks(oldInnerChild, rawProps, state, instance);
          setTransitionHooks(oldInnerChild, leavingHooks);
          if (mode === "out-in") {
            state.isLeaving = true;
            leavingHooks.afterLeave = () => {
              state.isLeaving = false;
              instance.update();
            };
            return emptyPlaceholder(child);
          } else if (mode === "in-out" && innerChild.type !== Comment) {
            leavingHooks.delayLeave = (el, earlyRemove, delayedLeave) => {
              const leavingVNodesCache = getLeavingNodesForType(state, oldInnerChild);
              leavingVNodesCache[String(oldInnerChild.key)] = oldInnerChild;
              el._leaveCb = () => {
                earlyRemove();
                el._leaveCb = void 0;
                delete enterHooks.delayedLeave;
              };
              enterHooks.delayedLeave = delayedLeave;
            };
          }
        }
        return child;
      };
    }
  };
  var BaseTransition = BaseTransitionImpl;
  function getLeavingNodesForType(state, vnode) {
    const { leavingVNodes } = state;
    let leavingVNodesCache = leavingVNodes.get(vnode.type);
    if (!leavingVNodesCache) {
      leavingVNodesCache = Object.create(null);
      leavingVNodes.set(vnode.type, leavingVNodesCache);
    }
    return leavingVNodesCache;
  }
  function resolveTransitionHooks(vnode, props, state, instance) {
    const { appear, mode, persisted = false, onBeforeEnter, onEnter, onAfterEnter, onEnterCancelled, onBeforeLeave, onLeave, onAfterLeave, onLeaveCancelled, onBeforeAppear, onAppear, onAfterAppear, onAppearCancelled } = props;
    const key = String(vnode.key);
    const leavingVNodesCache = getLeavingNodesForType(state, vnode);
    const callHook3 = (hook, args) => {
      hook && callWithAsyncErrorHandling(hook, instance, 9, args);
    };
    const hooks = {
      mode,
      persisted,
      beforeEnter(el) {
        let hook = onBeforeEnter;
        if (!state.isMounted) {
          if (appear) {
            hook = onBeforeAppear || onBeforeEnter;
          } else {
            return;
          }
        }
        if (el._leaveCb) {
          el._leaveCb(true);
        }
        const leavingVNode = leavingVNodesCache[key];
        if (leavingVNode && isSameVNodeType(vnode, leavingVNode) && leavingVNode.el._leaveCb) {
          leavingVNode.el._leaveCb();
        }
        callHook3(hook, [el]);
      },
      enter(el) {
        let hook = onEnter;
        let afterHook = onAfterEnter;
        let cancelHook = onEnterCancelled;
        if (!state.isMounted) {
          if (appear) {
            hook = onAppear || onEnter;
            afterHook = onAfterAppear || onAfterEnter;
            cancelHook = onAppearCancelled || onEnterCancelled;
          } else {
            return;
          }
        }
        let called = false;
        const done = el._enterCb = (cancelled) => {
          if (called)
            return;
          called = true;
          if (cancelled) {
            callHook3(cancelHook, [el]);
          } else {
            callHook3(afterHook, [el]);
          }
          if (hooks.delayedLeave) {
            hooks.delayedLeave();
          }
          el._enterCb = void 0;
        };
        if (hook) {
          hook(el, done);
          if (hook.length <= 1) {
            done();
          }
        } else {
          done();
        }
      },
      leave(el, remove2) {
        const key2 = String(vnode.key);
        if (el._enterCb) {
          el._enterCb(true);
        }
        if (state.isUnmounting) {
          return remove2();
        }
        callHook3(onBeforeLeave, [el]);
        let called = false;
        const done = el._leaveCb = (cancelled) => {
          if (called)
            return;
          called = true;
          remove2();
          if (cancelled) {
            callHook3(onLeaveCancelled, [el]);
          } else {
            callHook3(onAfterLeave, [el]);
          }
          el._leaveCb = void 0;
          if (leavingVNodesCache[key2] === vnode) {
            delete leavingVNodesCache[key2];
          }
        };
        leavingVNodesCache[key2] = vnode;
        if (onLeave) {
          onLeave(el, done);
          if (onLeave.length <= 1) {
            done();
          }
        } else {
          done();
        }
      },
      clone(vnode2) {
        return resolveTransitionHooks(vnode2, props, state, instance);
      }
    };
    return hooks;
  }
  function emptyPlaceholder(vnode) {
    if (isKeepAlive(vnode)) {
      vnode = cloneVNode(vnode);
      vnode.children = null;
      return vnode;
    }
  }
  function getKeepAliveChild(vnode) {
    return isKeepAlive(vnode) ? vnode.children ? vnode.children[0] : void 0 : vnode;
  }
  function setTransitionHooks(vnode, hooks) {
    if (vnode.shapeFlag & 6 && vnode.component) {
      setTransitionHooks(vnode.component.subTree, hooks);
    } else if (vnode.shapeFlag & 128) {
      vnode.ssContent.transition = hooks.clone(vnode.ssContent);
      vnode.ssFallback.transition = hooks.clone(vnode.ssFallback);
    } else {
      vnode.transition = hooks;
    }
  }
  function getTransitionRawChildren(children, keepComment = false) {
    let ret = [];
    let keyedFragmentCount = 0;
    for (let i = 0; i < children.length; i++) {
      const child = children[i];
      if (child.type === Fragment) {
        if (child.patchFlag & 128)
          keyedFragmentCount++;
        ret = ret.concat(getTransitionRawChildren(child.children, keepComment));
      } else if (keepComment || child.type !== Comment) {
        ret.push(child);
      }
    }
    if (keyedFragmentCount > 1) {
      for (let i = 0; i < ret.length; i++) {
        ret[i].patchFlag = -2;
      }
    }
    return ret;
  }
  function defineComponent(options) {
    return isFunction(options) ? { setup: options, name: options.name } : options;
  }
  var isAsyncWrapper = (i) => !!i.type.__asyncLoader;
  var isKeepAlive = (vnode) => vnode.type.__isKeepAlive;
  function onActivated(hook, target) {
    registerKeepAliveHook(hook, "a", target);
  }
  function onDeactivated(hook, target) {
    registerKeepAliveHook(hook, "da", target);
  }
  function registerKeepAliveHook(hook, type, target = currentInstance) {
    const wrappedHook = hook.__wdc || (hook.__wdc = () => {
      let current = target;
      while (current) {
        if (current.isDeactivated) {
          return;
        }
        current = current.parent;
      }
      hook();
    });
    injectHook(type, wrappedHook, target);
    if (target) {
      let current = target.parent;
      while (current && current.parent) {
        if (isKeepAlive(current.parent.vnode)) {
          injectToKeepAliveRoot(wrappedHook, type, target, current);
        }
        current = current.parent;
      }
    }
  }
  function injectToKeepAliveRoot(hook, type, target, keepAliveRoot) {
    const injected = injectHook(type, hook, keepAliveRoot, true);
    onUnmounted(() => {
      remove(keepAliveRoot[type], injected);
    }, target);
  }
  function injectHook(type, hook, target = currentInstance, prepend = false) {
    if (target) {
      const hooks = target[type] || (target[type] = []);
      const wrappedHook = hook.__weh || (hook.__weh = (...args) => {
        if (target.isUnmounted) {
          return;
        }
        pauseTracking();
        setCurrentInstance(target);
        const res = callWithAsyncErrorHandling(hook, target, type, args);
        unsetCurrentInstance();
        resetTracking();
        return res;
      });
      if (prepend) {
        hooks.unshift(wrappedHook);
      } else {
        hooks.push(wrappedHook);
      }
      return wrappedHook;
    } else if (true) {
      const apiName = toHandlerKey(ErrorTypeStrings[type].replace(/ hook$/, ""));
      warn2(`${apiName} is called when there is no active component instance to be associated with. Lifecycle injection APIs can only be used during execution of setup(). If you are using async setup(), make sure to register lifecycle hooks before the first await statement.`);
    }
  }
  var createHook = (lifecycle) => (hook, target = currentInstance) => (!isInSSRComponentSetup || lifecycle === "sp") && injectHook(lifecycle, hook, target);
  var onBeforeMount = createHook("bm");
  var onMounted = createHook("m");
  var onBeforeUpdate = createHook("bu");
  var onUpdated = createHook("u");
  var onBeforeUnmount = createHook("bum");
  var onUnmounted = createHook("um");
  var onServerPrefetch = createHook("sp");
  var onRenderTriggered = createHook("rtg");
  var onRenderTracked = createHook("rtc");
  function onErrorCaptured(hook, target = currentInstance) {
    injectHook("ec", hook, target);
  }
  function createDuplicateChecker() {
    const cache = Object.create(null);
    return (type, key) => {
      if (cache[key]) {
        warn2(`${type} property "${key}" is already defined in ${cache[key]}.`);
      } else {
        cache[key] = type;
      }
    };
  }
  var shouldCacheAccess = true;
  function applyOptions(instance) {
    const options = resolveMergedOptions(instance);
    const publicThis = instance.proxy;
    const ctx = instance.ctx;
    shouldCacheAccess = false;
    if (options.beforeCreate) {
      callHook(options.beforeCreate, instance, "bc");
    }
    const {
      data: dataOptions,
      computed: computedOptions,
      methods,
      watch: watchOptions,
      provide: provideOptions,
      inject: injectOptions,
      created,
      beforeMount,
      mounted,
      beforeUpdate,
      updated,
      activated,
      deactivated,
      beforeDestroy,
      beforeUnmount,
      destroyed,
      unmounted,
      render,
      renderTracked,
      renderTriggered,
      errorCaptured,
      serverPrefetch,
      expose,
      inheritAttrs,
      components,
      directives,
      filters
    } = options;
    const checkDuplicateProperties = true ? createDuplicateChecker() : null;
    if (true) {
      const [propsOptions] = instance.propsOptions;
      if (propsOptions) {
        for (const key in propsOptions) {
          checkDuplicateProperties("Props", key);
        }
      }
    }
    if (injectOptions) {
      resolveInjections(injectOptions, ctx, checkDuplicateProperties, instance.appContext.config.unwrapInjectedRef);
    }
    if (methods) {
      for (const key in methods) {
        const methodHandler = methods[key];
        if (isFunction(methodHandler)) {
          if (true) {
            Object.defineProperty(ctx, key, {
              value: methodHandler.bind(publicThis),
              configurable: true,
              enumerable: true,
              writable: true
            });
          } else {
            ctx[key] = methodHandler.bind(publicThis);
          }
          if (true) {
            checkDuplicateProperties("Methods", key);
          }
        } else if (true) {
          warn2(`Method "${key}" has type "${typeof methodHandler}" in the component definition. Did you reference the function correctly?`);
        }
      }
    }
    if (dataOptions) {
      if (!isFunction(dataOptions)) {
        warn2(`The data option must be a function. Plain object usage is no longer supported.`);
      }
      const data = dataOptions.call(publicThis, publicThis);
      if (isPromise(data)) {
        warn2(`data() returned a Promise - note data() cannot be async; If you intend to perform data fetching before component renders, use async setup() + <Suspense>.`);
      }
      if (!isObject(data)) {
        warn2(`data() should return an object.`);
      } else {
        instance.data = reactive(data);
        if (true) {
          for (const key in data) {
            checkDuplicateProperties("Data", key);
            if (key[0] !== "$" && key[0] !== "_") {
              Object.defineProperty(ctx, key, {
                configurable: true,
                enumerable: true,
                get: () => data[key],
                set: NOOP
              });
            }
          }
        }
      }
    }
    shouldCacheAccess = true;
    if (computedOptions) {
      for (const key in computedOptions) {
        const opt = computedOptions[key];
        const get4 = isFunction(opt) ? opt.bind(publicThis, publicThis) : isFunction(opt.get) ? opt.get.bind(publicThis, publicThis) : NOOP;
        if (get4 === NOOP) {
          warn2(`Computed property "${key}" has no getter.`);
        }
        const set2 = !isFunction(opt) && isFunction(opt.set) ? opt.set.bind(publicThis) : true ? () => {
          warn2(`Write operation failed: computed property "${key}" is readonly.`);
        } : NOOP;
        const c = computed({
          get: get4,
          set: set2
        });
        Object.defineProperty(ctx, key, {
          enumerable: true,
          configurable: true,
          get: () => c.value,
          set: (v) => c.value = v
        });
        if (true) {
          checkDuplicateProperties("Computed", key);
        }
      }
    }
    if (watchOptions) {
      for (const key in watchOptions) {
        createWatcher(watchOptions[key], ctx, publicThis, key);
      }
    }
    if (provideOptions) {
      const provides = isFunction(provideOptions) ? provideOptions.call(publicThis) : provideOptions;
      Reflect.ownKeys(provides).forEach((key) => {
        provide(key, provides[key]);
      });
    }
    if (created) {
      callHook(created, instance, "c");
    }
    function registerLifecycleHook(register, hook) {
      if (isArray(hook)) {
        hook.forEach((_hook) => register(_hook.bind(publicThis)));
      } else if (hook) {
        register(hook.bind(publicThis));
      }
    }
    registerLifecycleHook(onBeforeMount, beforeMount);
    registerLifecycleHook(onMounted, mounted);
    registerLifecycleHook(onBeforeUpdate, beforeUpdate);
    registerLifecycleHook(onUpdated, updated);
    registerLifecycleHook(onActivated, activated);
    registerLifecycleHook(onDeactivated, deactivated);
    registerLifecycleHook(onErrorCaptured, errorCaptured);
    registerLifecycleHook(onRenderTracked, renderTracked);
    registerLifecycleHook(onRenderTriggered, renderTriggered);
    registerLifecycleHook(onBeforeUnmount, beforeUnmount);
    registerLifecycleHook(onUnmounted, unmounted);
    registerLifecycleHook(onServerPrefetch, serverPrefetch);
    if (isArray(expose)) {
      if (expose.length) {
        const exposed = instance.exposed || (instance.exposed = {});
        expose.forEach((key) => {
          Object.defineProperty(exposed, key, {
            get: () => publicThis[key],
            set: (val) => publicThis[key] = val
          });
        });
      } else if (!instance.exposed) {
        instance.exposed = {};
      }
    }
    if (render && instance.render === NOOP) {
      instance.render = render;
    }
    if (inheritAttrs != null) {
      instance.inheritAttrs = inheritAttrs;
    }
    if (components)
      instance.components = components;
    if (directives)
      instance.directives = directives;
  }
  function resolveInjections(injectOptions, ctx, checkDuplicateProperties = NOOP, unwrapRef = false) {
    if (isArray(injectOptions)) {
      injectOptions = normalizeInject(injectOptions);
    }
    for (const key in injectOptions) {
      const opt = injectOptions[key];
      let injected;
      if (isObject(opt)) {
        if ("default" in opt) {
          injected = inject(opt.from || key, opt.default, true);
        } else {
          injected = inject(opt.from || key);
        }
      } else {
        injected = inject(opt);
      }
      if (isRef(injected)) {
        if (unwrapRef) {
          Object.defineProperty(ctx, key, {
            enumerable: true,
            configurable: true,
            get: () => injected.value,
            set: (v) => injected.value = v
          });
        } else {
          if (true) {
            warn2(`injected property "${key}" is a ref and will be auto-unwrapped and no longer needs \`.value\` in the next minor release. To opt-in to the new behavior now, set \`app.config.unwrapInjectedRef = true\` (this config is temporary and will not be needed in the future.)`);
          }
          ctx[key] = injected;
        }
      } else {
        ctx[key] = injected;
      }
      if (true) {
        checkDuplicateProperties("Inject", key);
      }
    }
  }
  function callHook(hook, instance, type) {
    callWithAsyncErrorHandling(isArray(hook) ? hook.map((h2) => h2.bind(instance.proxy)) : hook.bind(instance.proxy), instance, type);
  }
  function createWatcher(raw, ctx, publicThis, key) {
    const getter = key.includes(".") ? createPathGetter(publicThis, key) : () => publicThis[key];
    if (isString(raw)) {
      const handler = ctx[raw];
      if (isFunction(handler)) {
        watch(getter, handler);
      } else if (true) {
        warn2(`Invalid watch handler specified by key "${raw}"`, handler);
      }
    } else if (isFunction(raw)) {
      watch(getter, raw.bind(publicThis));
    } else if (isObject(raw)) {
      if (isArray(raw)) {
        raw.forEach((r) => createWatcher(r, ctx, publicThis, key));
      } else {
        const handler = isFunction(raw.handler) ? raw.handler.bind(publicThis) : ctx[raw.handler];
        if (isFunction(handler)) {
          watch(getter, handler, raw);
        } else if (true) {
          warn2(`Invalid watch handler specified by key "${raw.handler}"`, handler);
        }
      }
    } else if (true) {
      warn2(`Invalid watch option: "${key}"`, raw);
    }
  }
  function resolveMergedOptions(instance) {
    const base2 = instance.type;
    const { mixins, extends: extendsOptions } = base2;
    const { mixins: globalMixins, optionsCache: cache, config: { optionMergeStrategies } } = instance.appContext;
    const cached = cache.get(base2);
    let resolved;
    if (cached) {
      resolved = cached;
    } else if (!globalMixins.length && !mixins && !extendsOptions) {
      {
        resolved = base2;
      }
    } else {
      resolved = {};
      if (globalMixins.length) {
        globalMixins.forEach((m) => mergeOptions(resolved, m, optionMergeStrategies, true));
      }
      mergeOptions(resolved, base2, optionMergeStrategies);
    }
    cache.set(base2, resolved);
    return resolved;
  }
  function mergeOptions(to, from, strats, asMixin = false) {
    const { mixins, extends: extendsOptions } = from;
    if (extendsOptions) {
      mergeOptions(to, extendsOptions, strats, true);
    }
    if (mixins) {
      mixins.forEach((m) => mergeOptions(to, m, strats, true));
    }
    for (const key in from) {
      if (asMixin && key === "expose") {
        warn2(`"expose" option is ignored when declared in mixins or extends. It should only be declared in the base component itself.`);
      } else {
        const strat = internalOptionMergeStrats[key] || strats && strats[key];
        to[key] = strat ? strat(to[key], from[key]) : from[key];
      }
    }
    return to;
  }
  var internalOptionMergeStrats = {
    data: mergeDataFn,
    props: mergeObjectOptions,
    emits: mergeObjectOptions,
    methods: mergeObjectOptions,
    computed: mergeObjectOptions,
    beforeCreate: mergeAsArray,
    created: mergeAsArray,
    beforeMount: mergeAsArray,
    mounted: mergeAsArray,
    beforeUpdate: mergeAsArray,
    updated: mergeAsArray,
    beforeDestroy: mergeAsArray,
    beforeUnmount: mergeAsArray,
    destroyed: mergeAsArray,
    unmounted: mergeAsArray,
    activated: mergeAsArray,
    deactivated: mergeAsArray,
    errorCaptured: mergeAsArray,
    serverPrefetch: mergeAsArray,
    components: mergeObjectOptions,
    directives: mergeObjectOptions,
    watch: mergeWatchOptions,
    provide: mergeDataFn,
    inject: mergeInject
  };
  function mergeDataFn(to, from) {
    if (!from) {
      return to;
    }
    if (!to) {
      return from;
    }
    return function mergedDataFn() {
      return extend(isFunction(to) ? to.call(this, this) : to, isFunction(from) ? from.call(this, this) : from);
    };
  }
  function mergeInject(to, from) {
    return mergeObjectOptions(normalizeInject(to), normalizeInject(from));
  }
  function normalizeInject(raw) {
    if (isArray(raw)) {
      const res = {};
      for (let i = 0; i < raw.length; i++) {
        res[raw[i]] = raw[i];
      }
      return res;
    }
    return raw;
  }
  function mergeAsArray(to, from) {
    return to ? [...new Set([].concat(to, from))] : from;
  }
  function mergeObjectOptions(to, from) {
    return to ? extend(extend(Object.create(null), to), from) : from;
  }
  function mergeWatchOptions(to, from) {
    if (!to)
      return from;
    if (!from)
      return to;
    const merged = extend(Object.create(null), to);
    for (const key in from) {
      merged[key] = mergeAsArray(to[key], from[key]);
    }
    return merged;
  }
  function initProps(instance, rawProps, isStateful, isSSR = false) {
    const props = {};
    const attrs = {};
    def(attrs, InternalObjectKey, 1);
    instance.propsDefaults = Object.create(null);
    setFullProps(instance, rawProps, props, attrs);
    for (const key in instance.propsOptions[0]) {
      if (!(key in props)) {
        props[key] = void 0;
      }
    }
    if (true) {
      validateProps(rawProps || {}, props, instance);
    }
    if (isStateful) {
      instance.props = isSSR ? props : shallowReactive(props);
    } else {
      if (!instance.type.props) {
        instance.props = attrs;
      } else {
        instance.props = props;
      }
    }
    instance.attrs = attrs;
  }
  function updateProps(instance, rawProps, rawPrevProps, optimized) {
    const { props, attrs, vnode: { patchFlag } } = instance;
    const rawCurrentProps = toRaw(props);
    const [options] = instance.propsOptions;
    let hasAttrsChanged = false;
    if (!(instance.type.__hmrId || instance.parent && instance.parent.type.__hmrId) && (optimized || patchFlag > 0) && !(patchFlag & 16)) {
      if (patchFlag & 8) {
        const propsToUpdate = instance.vnode.dynamicProps;
        for (let i = 0; i < propsToUpdate.length; i++) {
          let key = propsToUpdate[i];
          const value = rawProps[key];
          if (options) {
            if (hasOwn(attrs, key)) {
              if (value !== attrs[key]) {
                attrs[key] = value;
                hasAttrsChanged = true;
              }
            } else {
              const camelizedKey = camelize(key);
              props[camelizedKey] = resolvePropValue(options, rawCurrentProps, camelizedKey, value, instance, false);
            }
          } else {
            if (value !== attrs[key]) {
              attrs[key] = value;
              hasAttrsChanged = true;
            }
          }
        }
      }
    } else {
      if (setFullProps(instance, rawProps, props, attrs)) {
        hasAttrsChanged = true;
      }
      let kebabKey;
      for (const key in rawCurrentProps) {
        if (!rawProps || !hasOwn(rawProps, key) && ((kebabKey = hyphenate(key)) === key || !hasOwn(rawProps, kebabKey))) {
          if (options) {
            if (rawPrevProps && (rawPrevProps[key] !== void 0 || rawPrevProps[kebabKey] !== void 0)) {
              props[key] = resolvePropValue(options, rawCurrentProps, key, void 0, instance, true);
            }
          } else {
            delete props[key];
          }
        }
      }
      if (attrs !== rawCurrentProps) {
        for (const key in attrs) {
          if (!rawProps || !hasOwn(rawProps, key)) {
            delete attrs[key];
            hasAttrsChanged = true;
          }
        }
      }
    }
    if (hasAttrsChanged) {
      trigger(instance, "set", "$attrs");
    }
    if (true) {
      validateProps(rawProps || {}, props, instance);
    }
  }
  function setFullProps(instance, rawProps, props, attrs) {
    const [options, needCastKeys] = instance.propsOptions;
    let hasAttrsChanged = false;
    let rawCastValues;
    if (rawProps) {
      for (let key in rawProps) {
        if (isReservedProp(key)) {
          continue;
        }
        const value = rawProps[key];
        let camelKey;
        if (options && hasOwn(options, camelKey = camelize(key))) {
          if (!needCastKeys || !needCastKeys.includes(camelKey)) {
            props[camelKey] = value;
          } else {
            (rawCastValues || (rawCastValues = {}))[camelKey] = value;
          }
        } else if (!isEmitListener(instance.emitsOptions, key)) {
          if (value !== attrs[key]) {
            attrs[key] = value;
            hasAttrsChanged = true;
          }
        }
      }
    }
    if (needCastKeys) {
      const rawCurrentProps = toRaw(props);
      const castValues = rawCastValues || EMPTY_OBJ;
      for (let i = 0; i < needCastKeys.length; i++) {
        const key = needCastKeys[i];
        props[key] = resolvePropValue(options, rawCurrentProps, key, castValues[key], instance, !hasOwn(castValues, key));
      }
    }
    return hasAttrsChanged;
  }
  function resolvePropValue(options, props, key, value, instance, isAbsent) {
    const opt = options[key];
    if (opt != null) {
      const hasDefault = hasOwn(opt, "default");
      if (hasDefault && value === void 0) {
        const defaultValue = opt.default;
        if (opt.type !== Function && isFunction(defaultValue)) {
          const { propsDefaults } = instance;
          if (key in propsDefaults) {
            value = propsDefaults[key];
          } else {
            setCurrentInstance(instance);
            value = propsDefaults[key] = defaultValue.call(null, props);
            unsetCurrentInstance();
          }
        } else {
          value = defaultValue;
        }
      }
      if (opt[0]) {
        if (isAbsent && !hasDefault) {
          value = false;
        } else if (opt[1] && (value === "" || value === hyphenate(key))) {
          value = true;
        }
      }
    }
    return value;
  }
  function normalizePropsOptions(comp, appContext, asMixin = false) {
    const cache = appContext.propsCache;
    const cached = cache.get(comp);
    if (cached) {
      return cached;
    }
    const raw = comp.props;
    const normalized = {};
    const needCastKeys = [];
    let hasExtends = false;
    if (__VUE_OPTIONS_API__ && !isFunction(comp)) {
      const extendProps = (raw2) => {
        hasExtends = true;
        const [props, keys] = normalizePropsOptions(raw2, appContext, true);
        extend(normalized, props);
        if (keys)
          needCastKeys.push(...keys);
      };
      if (!asMixin && appContext.mixins.length) {
        appContext.mixins.forEach(extendProps);
      }
      if (comp.extends) {
        extendProps(comp.extends);
      }
      if (comp.mixins) {
        comp.mixins.forEach(extendProps);
      }
    }
    if (!raw && !hasExtends) {
      cache.set(comp, EMPTY_ARR);
      return EMPTY_ARR;
    }
    if (isArray(raw)) {
      for (let i = 0; i < raw.length; i++) {
        if (!isString(raw[i])) {
          warn2(`props must be strings when using array syntax.`, raw[i]);
        }
        const normalizedKey = camelize(raw[i]);
        if (validatePropName(normalizedKey)) {
          normalized[normalizedKey] = EMPTY_OBJ;
        }
      }
    } else if (raw) {
      if (!isObject(raw)) {
        warn2(`invalid props options`, raw);
      }
      for (const key in raw) {
        const normalizedKey = camelize(key);
        if (validatePropName(normalizedKey)) {
          const opt = raw[key];
          const prop = normalized[normalizedKey] = isArray(opt) || isFunction(opt) ? { type: opt } : opt;
          if (prop) {
            const booleanIndex = getTypeIndex(Boolean, prop.type);
            const stringIndex = getTypeIndex(String, prop.type);
            prop[0] = booleanIndex > -1;
            prop[1] = stringIndex < 0 || booleanIndex < stringIndex;
            if (booleanIndex > -1 || hasOwn(prop, "default")) {
              needCastKeys.push(normalizedKey);
            }
          }
        }
      }
    }
    const res = [normalized, needCastKeys];
    cache.set(comp, res);
    return res;
  }
  function validatePropName(key) {
    if (key[0] !== "$") {
      return true;
    } else if (true) {
      warn2(`Invalid prop name: "${key}" is a reserved property.`);
    }
    return false;
  }
  function getType(ctor) {
    const match = ctor && ctor.toString().match(/^\s*function (\w+)/);
    return match ? match[1] : ctor === null ? "null" : "";
  }
  function isSameType(a, b) {
    return getType(a) === getType(b);
  }
  function getTypeIndex(type, expectedTypes) {
    if (isArray(expectedTypes)) {
      return expectedTypes.findIndex((t) => isSameType(t, type));
    } else if (isFunction(expectedTypes)) {
      return isSameType(expectedTypes, type) ? 0 : -1;
    }
    return -1;
  }
  function validateProps(rawProps, props, instance) {
    const resolvedValues = toRaw(props);
    const options = instance.propsOptions[0];
    for (const key in options) {
      let opt = options[key];
      if (opt == null)
        continue;
      validateProp(key, resolvedValues[key], opt, !hasOwn(rawProps, key) && !hasOwn(rawProps, hyphenate(key)));
    }
  }
  function validateProp(name, value, prop, isAbsent) {
    const { type, required, validator } = prop;
    if (required && isAbsent) {
      warn2('Missing required prop: "' + name + '"');
      return;
    }
    if (value == null && !prop.required) {
      return;
    }
    if (type != null && type !== true) {
      let isValid = false;
      const types = isArray(type) ? type : [type];
      const expectedTypes = [];
      for (let i = 0; i < types.length && !isValid; i++) {
        const { valid, expectedType } = assertType(value, types[i]);
        expectedTypes.push(expectedType || "");
        isValid = valid;
      }
      if (!isValid) {
        warn2(getInvalidTypeMessage(name, value, expectedTypes));
        return;
      }
    }
    if (validator && !validator(value)) {
      warn2('Invalid prop: custom validator check failed for prop "' + name + '".');
    }
  }
  var isSimpleType = /* @__PURE__ */ makeMap("String,Number,Boolean,Function,Symbol,BigInt");
  function assertType(value, type) {
    let valid;
    const expectedType = getType(type);
    if (isSimpleType(expectedType)) {
      const t = typeof value;
      valid = t === expectedType.toLowerCase();
      if (!valid && t === "object") {
        valid = value instanceof type;
      }
    } else if (expectedType === "Object") {
      valid = isObject(value);
    } else if (expectedType === "Array") {
      valid = isArray(value);
    } else if (expectedType === "null") {
      valid = value === null;
    } else {
      valid = value instanceof type;
    }
    return {
      valid,
      expectedType
    };
  }
  function getInvalidTypeMessage(name, value, expectedTypes) {
    let message = `Invalid prop: type check failed for prop "${name}". Expected ${expectedTypes.map(capitalize).join(" | ")}`;
    const expectedType = expectedTypes[0];
    const receivedType = toRawType(value);
    const expectedValue = styleValue(value, expectedType);
    const receivedValue = styleValue(value, receivedType);
    if (expectedTypes.length === 1 && isExplicable(expectedType) && !isBoolean(expectedType, receivedType)) {
      message += ` with value ${expectedValue}`;
    }
    message += `, got ${receivedType} `;
    if (isExplicable(receivedType)) {
      message += `with value ${receivedValue}.`;
    }
    return message;
  }
  function styleValue(value, type) {
    if (type === "String") {
      return `"${value}"`;
    } else if (type === "Number") {
      return `${Number(value)}`;
    } else {
      return `${value}`;
    }
  }
  function isExplicable(type) {
    const explicitTypes = ["string", "number", "boolean"];
    return explicitTypes.some((elem) => type.toLowerCase() === elem);
  }
  function isBoolean(...args) {
    return args.some((elem) => elem.toLowerCase() === "boolean");
  }
  var isInternalKey = (key) => key[0] === "_" || key === "$stable";
  var normalizeSlotValue = (value) => isArray(value) ? value.map(normalizeVNode) : [normalizeVNode(value)];
  var normalizeSlot = (key, rawSlot, ctx) => {
    const normalized = withCtx((...args) => {
      if (currentInstance) {
        warn2(`Slot "${key}" invoked outside of the render function: this will not track dependencies used in the slot. Invoke the slot function inside the render function instead.`);
      }
      return normalizeSlotValue(rawSlot(...args));
    }, ctx);
    normalized._c = false;
    return normalized;
  };
  var normalizeObjectSlots = (rawSlots, slots, instance) => {
    const ctx = rawSlots._ctx;
    for (const key in rawSlots) {
      if (isInternalKey(key))
        continue;
      const value = rawSlots[key];
      if (isFunction(value)) {
        slots[key] = normalizeSlot(key, value, ctx);
      } else if (value != null) {
        if (true) {
          warn2(`Non-function value encountered for slot "${key}". Prefer function slots for better performance.`);
        }
        const normalized = normalizeSlotValue(value);
        slots[key] = () => normalized;
      }
    }
  };
  var normalizeVNodeSlots = (instance, children) => {
    if (!isKeepAlive(instance.vnode) && true) {
      warn2(`Non-function value encountered for default slot. Prefer function slots for better performance.`);
    }
    const normalized = normalizeSlotValue(children);
    instance.slots.default = () => normalized;
  };
  var initSlots = (instance, children) => {
    if (instance.vnode.shapeFlag & 32) {
      const type = children._;
      if (type) {
        instance.slots = toRaw(children);
        def(children, "_", type);
      } else {
        normalizeObjectSlots(children, instance.slots = {});
      }
    } else {
      instance.slots = {};
      if (children) {
        normalizeVNodeSlots(instance, children);
      }
    }
    def(instance.slots, InternalObjectKey, 1);
  };
  var updateSlots = (instance, children, optimized) => {
    const { vnode, slots } = instance;
    let needDeletionCheck = true;
    let deletionComparisonTarget = EMPTY_OBJ;
    if (vnode.shapeFlag & 32) {
      const type = children._;
      if (type) {
        if (isHmrUpdating) {
          extend(slots, children);
        } else if (optimized && type === 1) {
          needDeletionCheck = false;
        } else {
          extend(slots, children);
          if (!optimized && type === 1) {
            delete slots._;
          }
        }
      } else {
        needDeletionCheck = !children.$stable;
        normalizeObjectSlots(children, slots);
      }
      deletionComparisonTarget = children;
    } else if (children) {
      normalizeVNodeSlots(instance, children);
      deletionComparisonTarget = { default: 1 };
    }
    if (needDeletionCheck) {
      for (const key in slots) {
        if (!isInternalKey(key) && !(key in deletionComparisonTarget)) {
          delete slots[key];
        }
      }
    }
  };
  var isBuiltInDirective = /* @__PURE__ */ makeMap("bind,cloak,else-if,else,for,html,if,model,on,once,pre,show,slot,text");
  function validateDirectiveName(name) {
    if (isBuiltInDirective(name)) {
      warn2("Do not use built-in directive ids as custom directive id: " + name);
    }
  }
  function invokeDirectiveHook(vnode, prevVNode, instance, name) {
    const bindings = vnode.dirs;
    const oldBindings = prevVNode && prevVNode.dirs;
    for (let i = 0; i < bindings.length; i++) {
      const binding = bindings[i];
      if (oldBindings) {
        binding.oldValue = oldBindings[i].value;
      }
      let hook = binding.dir[name];
      if (hook) {
        pauseTracking();
        callWithAsyncErrorHandling(hook, instance, 8, [
          vnode.el,
          binding,
          vnode,
          prevVNode
        ]);
        resetTracking();
      }
    }
  }
  function createAppContext() {
    return {
      app: null,
      config: {
        isNativeTag: NO,
        performance: false,
        globalProperties: {},
        optionMergeStrategies: {},
        errorHandler: void 0,
        warnHandler: void 0,
        compilerOptions: {}
      },
      mixins: [],
      components: {},
      directives: {},
      provides: Object.create(null),
      optionsCache: new WeakMap(),
      propsCache: new WeakMap(),
      emitsCache: new WeakMap()
    };
  }
  var uid = 0;
  function createAppAPI(render, hydrate) {
    return function createApp2(rootComponent, rootProps = null) {
      if (rootProps != null && !isObject(rootProps)) {
        warn2(`root props passed to app.mount() must be an object.`);
        rootProps = null;
      }
      const context = createAppContext();
      const installedPlugins = new Set();
      let isMounted = false;
      const app = context.app = {
        _uid: uid++,
        _component: rootComponent,
        _props: rootProps,
        _container: null,
        _context: context,
        _instance: null,
        version,
        get config() {
          return context.config;
        },
        set config(v) {
          if (true) {
            warn2(`app.config cannot be replaced. Modify individual options instead.`);
          }
        },
        use(plugin, ...options) {
          if (installedPlugins.has(plugin)) {
            warn2(`Plugin has already been applied to target app.`);
          } else if (plugin && isFunction(plugin.install)) {
            installedPlugins.add(plugin);
            plugin.install(app, ...options);
          } else if (isFunction(plugin)) {
            installedPlugins.add(plugin);
            plugin(app, ...options);
          } else if (true) {
            warn2(`A plugin must either be a function or an object with an "install" function.`);
          }
          return app;
        },
        mixin(mixin) {
          if (__VUE_OPTIONS_API__) {
            if (!context.mixins.includes(mixin)) {
              context.mixins.push(mixin);
            } else if (true) {
              warn2("Mixin has already been applied to target app" + (mixin.name ? `: ${mixin.name}` : ""));
            }
          } else if (true) {
            warn2("Mixins are only available in builds supporting Options API");
          }
          return app;
        },
        component(name, component) {
          if (true) {
            validateComponentName(name, context.config);
          }
          if (!component) {
            return context.components[name];
          }
          if (context.components[name]) {
            warn2(`Component "${name}" has already been registered in target app.`);
          }
          context.components[name] = component;
          return app;
        },
        directive(name, directive) {
          if (true) {
            validateDirectiveName(name);
          }
          if (!directive) {
            return context.directives[name];
          }
          if (context.directives[name]) {
            warn2(`Directive "${name}" has already been registered in target app.`);
          }
          context.directives[name] = directive;
          return app;
        },
        mount(rootContainer, isHydrate, isSVG) {
          if (!isMounted) {
            const vnode = createVNode(rootComponent, rootProps);
            vnode.appContext = context;
            if (true) {
              context.reload = () => {
                render(cloneVNode(vnode), rootContainer, isSVG);
              };
            }
            if (isHydrate && hydrate) {
              hydrate(vnode, rootContainer);
            } else {
              render(vnode, rootContainer, isSVG);
            }
            isMounted = true;
            app._container = rootContainer;
            rootContainer.__vue_app__ = app;
            if (true) {
              app._instance = vnode.component;
              devtoolsInitApp(app, version);
            }
            return getExposeProxy(vnode.component) || vnode.component.proxy;
          } else if (true) {
            warn2(`App has already been mounted.
If you want to remount the same app, move your app creation logic into a factory function and create fresh app instances for each mount - e.g. \`const createMyApp = () => createApp(App)\``);
          }
        },
        unmount() {
          if (isMounted) {
            render(null, app._container);
            if (true) {
              app._instance = null;
              devtoolsUnmountApp(app);
            }
            delete app._container.__vue_app__;
          } else if (true) {
            warn2(`Cannot unmount an app that is not mounted.`);
          }
        },
        provide(key, value) {
          if (key in context.provides) {
            warn2(`App already provides property with key "${String(key)}". It will be overwritten with the new value.`);
          }
          context.provides[key] = value;
          return app;
        }
      };
      return app;
    };
  }
  var supported;
  var perf;
  function startMeasure(instance, type) {
    if (instance.appContext.config.performance && isSupported()) {
      perf.mark(`vue-${type}-${instance.uid}`);
    }
    if (true) {
      devtoolsPerfStart(instance, type, supported ? perf.now() : Date.now());
    }
  }
  function endMeasure(instance, type) {
    if (instance.appContext.config.performance && isSupported()) {
      const startTag = `vue-${type}-${instance.uid}`;
      const endTag = startTag + `:end`;
      perf.mark(endTag);
      perf.measure(`<${formatComponentName(instance, instance.type)}> ${type}`, startTag, endTag);
      perf.clearMarks(startTag);
      perf.clearMarks(endTag);
    }
    if (true) {
      devtoolsPerfEnd(instance, type, supported ? perf.now() : Date.now());
    }
  }
  function isSupported() {
    if (supported !== void 0) {
      return supported;
    }
    if (typeof window !== "undefined" && window.performance) {
      supported = true;
      perf = window.performance;
    } else {
      supported = false;
    }
    return supported;
  }
  function initFeatureFlags() {
    const needWarn = [];
    if (typeof __VUE_OPTIONS_API__ !== "boolean") {
      needWarn.push(`__VUE_OPTIONS_API__`);
      getGlobalThis().__VUE_OPTIONS_API__ = true;
    }
    if (typeof __VUE_PROD_DEVTOOLS__ !== "boolean") {
      needWarn.push(`__VUE_PROD_DEVTOOLS__`);
      getGlobalThis().__VUE_PROD_DEVTOOLS__ = false;
    }
    if (needWarn.length) {
      const multi = needWarn.length > 1;
      console.warn(`Feature flag${multi ? `s` : ``} ${needWarn.join(", ")} ${multi ? `are` : `is`} not explicitly defined. You are running the esm-bundler build of Vue, which expects these compile-time feature flags to be globally injected via the bundler config in order to get better tree-shaking in the production bundle.

For more details, see http://link.vuejs.org/feature-flags.`);
    }
  }
  var queuePostRenderEffect = queueEffectWithSuspense;
  function createRenderer(options) {
    return baseCreateRenderer(options);
  }
  function baseCreateRenderer(options, createHydrationFns) {
    {
      initFeatureFlags();
    }
    const target = getGlobalThis();
    target.__VUE__ = true;
    if (true) {
      setDevtoolsHook(target.__VUE_DEVTOOLS_GLOBAL_HOOK__, target);
    }
    const { insert: hostInsert, remove: hostRemove, patchProp: hostPatchProp, createElement: hostCreateElement, createText: hostCreateText, createComment: hostCreateComment, setText: hostSetText, setElementText: hostSetElementText, parentNode: hostParentNode, nextSibling: hostNextSibling, setScopeId: hostSetScopeId = NOOP, cloneNode: hostCloneNode, insertStaticContent: hostInsertStaticContent } = options;
    const patch = (n1, n2, container, anchor = null, parentComponent = null, parentSuspense = null, isSVG = false, slotScopeIds = null, optimized = isHmrUpdating ? false : !!n2.dynamicChildren) => {
      if (n1 === n2) {
        return;
      }
      if (n1 && !isSameVNodeType(n1, n2)) {
        anchor = getNextHostNode(n1);
        unmount(n1, parentComponent, parentSuspense, true);
        n1 = null;
      }
      if (n2.patchFlag === -2) {
        optimized = false;
        n2.dynamicChildren = null;
      }
      const { type, ref: ref2, shapeFlag } = n2;
      switch (type) {
        case Text:
          processText(n1, n2, container, anchor);
          break;
        case Comment:
          processCommentNode(n1, n2, container, anchor);
          break;
        case Static:
          if (n1 == null) {
            mountStaticNode(n2, container, anchor, isSVG);
          } else if (true) {
            patchStaticNode(n1, n2, container, isSVG);
          }
          break;
        case Fragment:
          processFragment(n1, n2, container, anchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized);
          break;
        default:
          if (shapeFlag & 1) {
            processElement(n1, n2, container, anchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized);
          } else if (shapeFlag & 6) {
            processComponent(n1, n2, container, anchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized);
          } else if (shapeFlag & 64) {
            type.process(n1, n2, container, anchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized, internals);
          } else if (shapeFlag & 128) {
            type.process(n1, n2, container, anchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized, internals);
          } else if (true) {
            warn2("Invalid VNode type:", type, `(${typeof type})`);
          }
      }
      if (ref2 != null && parentComponent) {
        setRef(ref2, n1 && n1.ref, parentSuspense, n2 || n1, !n2);
      }
    };
    const processText = (n1, n2, container, anchor) => {
      if (n1 == null) {
        hostInsert(n2.el = hostCreateText(n2.children), container, anchor);
      } else {
        const el = n2.el = n1.el;
        if (n2.children !== n1.children) {
          hostSetText(el, n2.children);
        }
      }
    };
    const processCommentNode = (n1, n2, container, anchor) => {
      if (n1 == null) {
        hostInsert(n2.el = hostCreateComment(n2.children || ""), container, anchor);
      } else {
        n2.el = n1.el;
      }
    };
    const mountStaticNode = (n2, container, anchor, isSVG) => {
      [n2.el, n2.anchor] = hostInsertStaticContent(n2.children, container, anchor, isSVG);
    };
    const patchStaticNode = (n1, n2, container, isSVG) => {
      if (n2.children !== n1.children) {
        const anchor = hostNextSibling(n1.anchor);
        removeStaticNode(n1);
        [n2.el, n2.anchor] = hostInsertStaticContent(n2.children, container, anchor, isSVG);
      } else {
        n2.el = n1.el;
        n2.anchor = n1.anchor;
      }
    };
    const moveStaticNode = ({ el, anchor }, container, nextSibling) => {
      let next;
      while (el && el !== anchor) {
        next = hostNextSibling(el);
        hostInsert(el, container, nextSibling);
        el = next;
      }
      hostInsert(anchor, container, nextSibling);
    };
    const removeStaticNode = ({ el, anchor }) => {
      let next;
      while (el && el !== anchor) {
        next = hostNextSibling(el);
        hostRemove(el);
        el = next;
      }
      hostRemove(anchor);
    };
    const processElement = (n1, n2, container, anchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized) => {
      isSVG = isSVG || n2.type === "svg";
      if (n1 == null) {
        mountElement(n2, container, anchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized);
      } else {
        patchElement(n1, n2, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized);
      }
    };
    const mountElement = (vnode, container, anchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized) => {
      let el;
      let vnodeHook;
      const { type, props, shapeFlag, transition, patchFlag, dirs } = vnode;
      if (false) {
        el = vnode.el = hostCloneNode(vnode.el);
      } else {
        el = vnode.el = hostCreateElement(vnode.type, isSVG, props && props.is, props);
        if (shapeFlag & 8) {
          hostSetElementText(el, vnode.children);
        } else if (shapeFlag & 16) {
          mountChildren(vnode.children, el, null, parentComponent, parentSuspense, isSVG && type !== "foreignObject", slotScopeIds, optimized);
        }
        if (dirs) {
          invokeDirectiveHook(vnode, null, parentComponent, "created");
        }
        if (props) {
          for (const key in props) {
            if (key !== "value" && !isReservedProp(key)) {
              hostPatchProp(el, key, null, props[key], isSVG, vnode.children, parentComponent, parentSuspense, unmountChildren);
            }
          }
          if ("value" in props) {
            hostPatchProp(el, "value", null, props.value);
          }
          if (vnodeHook = props.onVnodeBeforeMount) {
            invokeVNodeHook(vnodeHook, parentComponent, vnode);
          }
        }
        setScopeId(el, vnode, vnode.scopeId, slotScopeIds, parentComponent);
      }
      if (true) {
        Object.defineProperty(el, "__vnode", {
          value: vnode,
          enumerable: false
        });
        Object.defineProperty(el, "__vueParentComponent", {
          value: parentComponent,
          enumerable: false
        });
      }
      if (dirs) {
        invokeDirectiveHook(vnode, null, parentComponent, "beforeMount");
      }
      const needCallTransitionHooks = (!parentSuspense || parentSuspense && !parentSuspense.pendingBranch) && transition && !transition.persisted;
      if (needCallTransitionHooks) {
        transition.beforeEnter(el);
      }
      hostInsert(el, container, anchor);
      if ((vnodeHook = props && props.onVnodeMounted) || needCallTransitionHooks || dirs) {
        queuePostRenderEffect(() => {
          vnodeHook && invokeVNodeHook(vnodeHook, parentComponent, vnode);
          needCallTransitionHooks && transition.enter(el);
          dirs && invokeDirectiveHook(vnode, null, parentComponent, "mounted");
        }, parentSuspense);
      }
    };
    const setScopeId = (el, vnode, scopeId, slotScopeIds, parentComponent) => {
      if (scopeId) {
        hostSetScopeId(el, scopeId);
      }
      if (slotScopeIds) {
        for (let i = 0; i < slotScopeIds.length; i++) {
          hostSetScopeId(el, slotScopeIds[i]);
        }
      }
      if (parentComponent) {
        let subTree = parentComponent.subTree;
        if (subTree.patchFlag > 0 && subTree.patchFlag & 2048) {
          subTree = filterSingleRoot(subTree.children) || subTree;
        }
        if (vnode === subTree) {
          const parentVNode = parentComponent.vnode;
          setScopeId(el, parentVNode, parentVNode.scopeId, parentVNode.slotScopeIds, parentComponent.parent);
        }
      }
    };
    const mountChildren = (children, container, anchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized, start = 0) => {
      for (let i = start; i < children.length; i++) {
        const child = children[i] = optimized ? cloneIfMounted(children[i]) : normalizeVNode(children[i]);
        patch(null, child, container, anchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized);
      }
    };
    const patchElement = (n1, n2, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized) => {
      const el = n2.el = n1.el;
      let { patchFlag, dynamicChildren, dirs } = n2;
      patchFlag |= n1.patchFlag & 16;
      const oldProps = n1.props || EMPTY_OBJ;
      const newProps = n2.props || EMPTY_OBJ;
      let vnodeHook;
      if (vnodeHook = newProps.onVnodeBeforeUpdate) {
        invokeVNodeHook(vnodeHook, parentComponent, n2, n1);
      }
      if (dirs) {
        invokeDirectiveHook(n2, n1, parentComponent, "beforeUpdate");
      }
      if (isHmrUpdating) {
        patchFlag = 0;
        optimized = false;
        dynamicChildren = null;
      }
      const areChildrenSVG = isSVG && n2.type !== "foreignObject";
      if (dynamicChildren) {
        patchBlockChildren(n1.dynamicChildren, dynamicChildren, el, parentComponent, parentSuspense, areChildrenSVG, slotScopeIds);
        if (parentComponent && parentComponent.type.__hmrId) {
          traverseStaticChildren(n1, n2);
        }
      } else if (!optimized) {
        patchChildren(n1, n2, el, null, parentComponent, parentSuspense, areChildrenSVG, slotScopeIds, false);
      }
      if (patchFlag > 0) {
        if (patchFlag & 16) {
          patchProps(el, n2, oldProps, newProps, parentComponent, parentSuspense, isSVG);
        } else {
          if (patchFlag & 2) {
            if (oldProps.class !== newProps.class) {
              hostPatchProp(el, "class", null, newProps.class, isSVG);
            }
          }
          if (patchFlag & 4) {
            hostPatchProp(el, "style", oldProps.style, newProps.style, isSVG);
          }
          if (patchFlag & 8) {
            const propsToUpdate = n2.dynamicProps;
            for (let i = 0; i < propsToUpdate.length; i++) {
              const key = propsToUpdate[i];
              const prev = oldProps[key];
              const next = newProps[key];
              if (next !== prev || key === "value") {
                hostPatchProp(el, key, prev, next, isSVG, n1.children, parentComponent, parentSuspense, unmountChildren);
              }
            }
          }
        }
        if (patchFlag & 1) {
          if (n1.children !== n2.children) {
            hostSetElementText(el, n2.children);
          }
        }
      } else if (!optimized && dynamicChildren == null) {
        patchProps(el, n2, oldProps, newProps, parentComponent, parentSuspense, isSVG);
      }
      if ((vnodeHook = newProps.onVnodeUpdated) || dirs) {
        queuePostRenderEffect(() => {
          vnodeHook && invokeVNodeHook(vnodeHook, parentComponent, n2, n1);
          dirs && invokeDirectiveHook(n2, n1, parentComponent, "updated");
        }, parentSuspense);
      }
    };
    const patchBlockChildren = (oldChildren, newChildren, fallbackContainer, parentComponent, parentSuspense, isSVG, slotScopeIds) => {
      for (let i = 0; i < newChildren.length; i++) {
        const oldVNode = oldChildren[i];
        const newVNode = newChildren[i];
        const container = oldVNode.el && (oldVNode.type === Fragment || !isSameVNodeType(oldVNode, newVNode) || oldVNode.shapeFlag & (6 | 64)) ? hostParentNode(oldVNode.el) : fallbackContainer;
        patch(oldVNode, newVNode, container, null, parentComponent, parentSuspense, isSVG, slotScopeIds, true);
      }
    };
    const patchProps = (el, vnode, oldProps, newProps, parentComponent, parentSuspense, isSVG) => {
      if (oldProps !== newProps) {
        for (const key in newProps) {
          if (isReservedProp(key))
            continue;
          const next = newProps[key];
          const prev = oldProps[key];
          if (next !== prev && key !== "value") {
            hostPatchProp(el, key, prev, next, isSVG, vnode.children, parentComponent, parentSuspense, unmountChildren);
          }
        }
        if (oldProps !== EMPTY_OBJ) {
          for (const key in oldProps) {
            if (!isReservedProp(key) && !(key in newProps)) {
              hostPatchProp(el, key, oldProps[key], null, isSVG, vnode.children, parentComponent, parentSuspense, unmountChildren);
            }
          }
        }
        if ("value" in newProps) {
          hostPatchProp(el, "value", oldProps.value, newProps.value);
        }
      }
    };
    const processFragment = (n1, n2, container, anchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized) => {
      const fragmentStartAnchor = n2.el = n1 ? n1.el : hostCreateText("");
      const fragmentEndAnchor = n2.anchor = n1 ? n1.anchor : hostCreateText("");
      let { patchFlag, dynamicChildren, slotScopeIds: fragmentSlotScopeIds } = n2;
      if (isHmrUpdating) {
        patchFlag = 0;
        optimized = false;
        dynamicChildren = null;
      }
      if (fragmentSlotScopeIds) {
        slotScopeIds = slotScopeIds ? slotScopeIds.concat(fragmentSlotScopeIds) : fragmentSlotScopeIds;
      }
      if (n1 == null) {
        hostInsert(fragmentStartAnchor, container, anchor);
        hostInsert(fragmentEndAnchor, container, anchor);
        mountChildren(n2.children, container, fragmentEndAnchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized);
      } else {
        if (patchFlag > 0 && patchFlag & 64 && dynamicChildren && n1.dynamicChildren) {
          patchBlockChildren(n1.dynamicChildren, dynamicChildren, container, parentComponent, parentSuspense, isSVG, slotScopeIds);
          if (parentComponent && parentComponent.type.__hmrId) {
            traverseStaticChildren(n1, n2);
          } else if (n2.key != null || parentComponent && n2 === parentComponent.subTree) {
            traverseStaticChildren(n1, n2, true);
          }
        } else {
          patchChildren(n1, n2, container, fragmentEndAnchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized);
        }
      }
    };
    const processComponent = (n1, n2, container, anchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized) => {
      n2.slotScopeIds = slotScopeIds;
      if (n1 == null) {
        if (n2.shapeFlag & 512) {
          parentComponent.ctx.activate(n2, container, anchor, isSVG, optimized);
        } else {
          mountComponent(n2, container, anchor, parentComponent, parentSuspense, isSVG, optimized);
        }
      } else {
        updateComponent(n1, n2, optimized);
      }
    };
    const mountComponent = (initialVNode, container, anchor, parentComponent, parentSuspense, isSVG, optimized) => {
      const instance = initialVNode.component = createComponentInstance(initialVNode, parentComponent, parentSuspense);
      if (instance.type.__hmrId) {
        registerHMR(instance);
      }
      if (true) {
        pushWarningContext(initialVNode);
        startMeasure(instance, `mount`);
      }
      if (isKeepAlive(initialVNode)) {
        instance.ctx.renderer = internals;
      }
      {
        if (true) {
          startMeasure(instance, `init`);
        }
        setupComponent(instance);
        if (true) {
          endMeasure(instance, `init`);
        }
      }
      if (instance.asyncDep) {
        parentSuspense && parentSuspense.registerDep(instance, setupRenderEffect);
        if (!initialVNode.el) {
          const placeholder = instance.subTree = createVNode(Comment);
          processCommentNode(null, placeholder, container, anchor);
        }
        return;
      }
      setupRenderEffect(instance, initialVNode, container, anchor, parentSuspense, isSVG, optimized);
      if (true) {
        popWarningContext();
        endMeasure(instance, `mount`);
      }
    };
    const updateComponent = (n1, n2, optimized) => {
      const instance = n2.component = n1.component;
      if (shouldUpdateComponent(n1, n2, optimized)) {
        if (instance.asyncDep && !instance.asyncResolved) {
          if (true) {
            pushWarningContext(n2);
          }
          updateComponentPreRender(instance, n2, optimized);
          if (true) {
            popWarningContext();
          }
          return;
        } else {
          instance.next = n2;
          invalidateJob(instance.update);
          instance.update();
        }
      } else {
        n2.component = n1.component;
        n2.el = n1.el;
        instance.vnode = n2;
      }
    };
    const setupRenderEffect = (instance, initialVNode, container, anchor, parentSuspense, isSVG, optimized) => {
      const componentUpdateFn = () => {
        if (!instance.isMounted) {
          let vnodeHook;
          const { el, props } = initialVNode;
          const { bm, m, parent } = instance;
          const isAsyncWrapperVNode = isAsyncWrapper(initialVNode);
          effect2.allowRecurse = false;
          if (bm) {
            invokeArrayFns(bm);
          }
          if (!isAsyncWrapperVNode && (vnodeHook = props && props.onVnodeBeforeMount)) {
            invokeVNodeHook(vnodeHook, parent, initialVNode);
          }
          effect2.allowRecurse = true;
          if (el && hydrateNode) {
            const hydrateSubTree = () => {
              if (true) {
                startMeasure(instance, `render`);
              }
              instance.subTree = renderComponentRoot(instance);
              if (true) {
                endMeasure(instance, `render`);
              }
              if (true) {
                startMeasure(instance, `hydrate`);
              }
              hydrateNode(el, instance.subTree, instance, parentSuspense, null);
              if (true) {
                endMeasure(instance, `hydrate`);
              }
            };
            if (isAsyncWrapperVNode) {
              initialVNode.type.__asyncLoader().then(() => !instance.isUnmounted && hydrateSubTree());
            } else {
              hydrateSubTree();
            }
          } else {
            if (true) {
              startMeasure(instance, `render`);
            }
            const subTree = instance.subTree = renderComponentRoot(instance);
            if (true) {
              endMeasure(instance, `render`);
            }
            if (true) {
              startMeasure(instance, `patch`);
            }
            patch(null, subTree, container, anchor, instance, parentSuspense, isSVG);
            if (true) {
              endMeasure(instance, `patch`);
            }
            initialVNode.el = subTree.el;
          }
          if (m) {
            queuePostRenderEffect(m, parentSuspense);
          }
          if (!isAsyncWrapperVNode && (vnodeHook = props && props.onVnodeMounted)) {
            const scopedInitialVNode = initialVNode;
            queuePostRenderEffect(() => invokeVNodeHook(vnodeHook, parent, scopedInitialVNode), parentSuspense);
          }
          if (initialVNode.shapeFlag & 256) {
            instance.a && queuePostRenderEffect(instance.a, parentSuspense);
          }
          instance.isMounted = true;
          if (true) {
            devtoolsComponentAdded(instance);
          }
          initialVNode = container = anchor = null;
        } else {
          let { next, bu, u, parent, vnode } = instance;
          let originNext = next;
          let vnodeHook;
          if (true) {
            pushWarningContext(next || instance.vnode);
          }
          effect2.allowRecurse = false;
          if (next) {
            next.el = vnode.el;
            updateComponentPreRender(instance, next, optimized);
          } else {
            next = vnode;
          }
          if (bu) {
            invokeArrayFns(bu);
          }
          if (vnodeHook = next.props && next.props.onVnodeBeforeUpdate) {
            invokeVNodeHook(vnodeHook, parent, next, vnode);
          }
          effect2.allowRecurse = true;
          if (true) {
            startMeasure(instance, `render`);
          }
          const nextTree = renderComponentRoot(instance);
          if (true) {
            endMeasure(instance, `render`);
          }
          const prevTree = instance.subTree;
          instance.subTree = nextTree;
          if (true) {
            startMeasure(instance, `patch`);
          }
          patch(prevTree, nextTree, hostParentNode(prevTree.el), getNextHostNode(prevTree), instance, parentSuspense, isSVG);
          if (true) {
            endMeasure(instance, `patch`);
          }
          next.el = nextTree.el;
          if (originNext === null) {
            updateHOCHostEl(instance, nextTree.el);
          }
          if (u) {
            queuePostRenderEffect(u, parentSuspense);
          }
          if (vnodeHook = next.props && next.props.onVnodeUpdated) {
            queuePostRenderEffect(() => invokeVNodeHook(vnodeHook, parent, next, vnode), parentSuspense);
          }
          if (true) {
            devtoolsComponentUpdated(instance);
          }
          if (true) {
            popWarningContext();
          }
        }
      };
      const effect2 = new ReactiveEffect(componentUpdateFn, () => queueJob(instance.update), instance.scope);
      const update = instance.update = effect2.run.bind(effect2);
      update.id = instance.uid;
      effect2.allowRecurse = update.allowRecurse = true;
      if (true) {
        effect2.onTrack = instance.rtc ? (e) => invokeArrayFns(instance.rtc, e) : void 0;
        effect2.onTrigger = instance.rtg ? (e) => invokeArrayFns(instance.rtg, e) : void 0;
        update.ownerInstance = instance;
      }
      update();
    };
    const updateComponentPreRender = (instance, nextVNode, optimized) => {
      nextVNode.component = instance;
      const prevProps = instance.vnode.props;
      instance.vnode = nextVNode;
      instance.next = null;
      updateProps(instance, nextVNode.props, prevProps, optimized);
      updateSlots(instance, nextVNode.children, optimized);
      pauseTracking();
      flushPreFlushCbs(void 0, instance.update);
      resetTracking();
    };
    const patchChildren = (n1, n2, container, anchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized = false) => {
      const c1 = n1 && n1.children;
      const prevShapeFlag = n1 ? n1.shapeFlag : 0;
      const c2 = n2.children;
      const { patchFlag, shapeFlag } = n2;
      if (patchFlag > 0) {
        if (patchFlag & 128) {
          patchKeyedChildren(c1, c2, container, anchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized);
          return;
        } else if (patchFlag & 256) {
          patchUnkeyedChildren(c1, c2, container, anchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized);
          return;
        }
      }
      if (shapeFlag & 8) {
        if (prevShapeFlag & 16) {
          unmountChildren(c1, parentComponent, parentSuspense);
        }
        if (c2 !== c1) {
          hostSetElementText(container, c2);
        }
      } else {
        if (prevShapeFlag & 16) {
          if (shapeFlag & 16) {
            patchKeyedChildren(c1, c2, container, anchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized);
          } else {
            unmountChildren(c1, parentComponent, parentSuspense, true);
          }
        } else {
          if (prevShapeFlag & 8) {
            hostSetElementText(container, "");
          }
          if (shapeFlag & 16) {
            mountChildren(c2, container, anchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized);
          }
        }
      }
    };
    const patchUnkeyedChildren = (c1, c2, container, anchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized) => {
      c1 = c1 || EMPTY_ARR;
      c2 = c2 || EMPTY_ARR;
      const oldLength = c1.length;
      const newLength = c2.length;
      const commonLength = Math.min(oldLength, newLength);
      let i;
      for (i = 0; i < commonLength; i++) {
        const nextChild = c2[i] = optimized ? cloneIfMounted(c2[i]) : normalizeVNode(c2[i]);
        patch(c1[i], nextChild, container, null, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized);
      }
      if (oldLength > newLength) {
        unmountChildren(c1, parentComponent, parentSuspense, true, false, commonLength);
      } else {
        mountChildren(c2, container, anchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized, commonLength);
      }
    };
    const patchKeyedChildren = (c1, c2, container, parentAnchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized) => {
      let i = 0;
      const l22 = c2.length;
      let e1 = c1.length - 1;
      let e2 = l22 - 1;
      while (i <= e1 && i <= e2) {
        const n1 = c1[i];
        const n2 = c2[i] = optimized ? cloneIfMounted(c2[i]) : normalizeVNode(c2[i]);
        if (isSameVNodeType(n1, n2)) {
          patch(n1, n2, container, null, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized);
        } else {
          break;
        }
        i++;
      }
      while (i <= e1 && i <= e2) {
        const n1 = c1[e1];
        const n2 = c2[e2] = optimized ? cloneIfMounted(c2[e2]) : normalizeVNode(c2[e2]);
        if (isSameVNodeType(n1, n2)) {
          patch(n1, n2, container, null, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized);
        } else {
          break;
        }
        e1--;
        e2--;
      }
      if (i > e1) {
        if (i <= e2) {
          const nextPos = e2 + 1;
          const anchor = nextPos < l22 ? c2[nextPos].el : parentAnchor;
          while (i <= e2) {
            patch(null, c2[i] = optimized ? cloneIfMounted(c2[i]) : normalizeVNode(c2[i]), container, anchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized);
            i++;
          }
        }
      } else if (i > e2) {
        while (i <= e1) {
          unmount(c1[i], parentComponent, parentSuspense, true);
          i++;
        }
      } else {
        const s1 = i;
        const s2 = i;
        const keyToNewIndexMap = new Map();
        for (i = s2; i <= e2; i++) {
          const nextChild = c2[i] = optimized ? cloneIfMounted(c2[i]) : normalizeVNode(c2[i]);
          if (nextChild.key != null) {
            if (keyToNewIndexMap.has(nextChild.key)) {
              warn2(`Duplicate keys found during update:`, JSON.stringify(nextChild.key), `Make sure keys are unique.`);
            }
            keyToNewIndexMap.set(nextChild.key, i);
          }
        }
        let j;
        let patched = 0;
        const toBePatched = e2 - s2 + 1;
        let moved = false;
        let maxNewIndexSoFar = 0;
        const newIndexToOldIndexMap = new Array(toBePatched);
        for (i = 0; i < toBePatched; i++)
          newIndexToOldIndexMap[i] = 0;
        for (i = s1; i <= e1; i++) {
          const prevChild = c1[i];
          if (patched >= toBePatched) {
            unmount(prevChild, parentComponent, parentSuspense, true);
            continue;
          }
          let newIndex;
          if (prevChild.key != null) {
            newIndex = keyToNewIndexMap.get(prevChild.key);
          } else {
            for (j = s2; j <= e2; j++) {
              if (newIndexToOldIndexMap[j - s2] === 0 && isSameVNodeType(prevChild, c2[j])) {
                newIndex = j;
                break;
              }
            }
          }
          if (newIndex === void 0) {
            unmount(prevChild, parentComponent, parentSuspense, true);
          } else {
            newIndexToOldIndexMap[newIndex - s2] = i + 1;
            if (newIndex >= maxNewIndexSoFar) {
              maxNewIndexSoFar = newIndex;
            } else {
              moved = true;
            }
            patch(prevChild, c2[newIndex], container, null, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized);
            patched++;
          }
        }
        const increasingNewIndexSequence = moved ? getSequence(newIndexToOldIndexMap) : EMPTY_ARR;
        j = increasingNewIndexSequence.length - 1;
        for (i = toBePatched - 1; i >= 0; i--) {
          const nextIndex = s2 + i;
          const nextChild = c2[nextIndex];
          const anchor = nextIndex + 1 < l22 ? c2[nextIndex + 1].el : parentAnchor;
          if (newIndexToOldIndexMap[i] === 0) {
            patch(null, nextChild, container, anchor, parentComponent, parentSuspense, isSVG, slotScopeIds, optimized);
          } else if (moved) {
            if (j < 0 || i !== increasingNewIndexSequence[j]) {
              move(nextChild, container, anchor, 2);
            } else {
              j--;
            }
          }
        }
      }
    };
    const move = (vnode, container, anchor, moveType, parentSuspense = null) => {
      const { el, type, transition, children, shapeFlag } = vnode;
      if (shapeFlag & 6) {
        move(vnode.component.subTree, container, anchor, moveType);
        return;
      }
      if (shapeFlag & 128) {
        vnode.suspense.move(container, anchor, moveType);
        return;
      }
      if (shapeFlag & 64) {
        type.move(vnode, container, anchor, internals);
        return;
      }
      if (type === Fragment) {
        hostInsert(el, container, anchor);
        for (let i = 0; i < children.length; i++) {
          move(children[i], container, anchor, moveType);
        }
        hostInsert(vnode.anchor, container, anchor);
        return;
      }
      if (type === Static) {
        moveStaticNode(vnode, container, anchor);
        return;
      }
      const needTransition = moveType !== 2 && shapeFlag & 1 && transition;
      if (needTransition) {
        if (moveType === 0) {
          transition.beforeEnter(el);
          hostInsert(el, container, anchor);
          queuePostRenderEffect(() => transition.enter(el), parentSuspense);
        } else {
          const { leave, delayLeave, afterLeave } = transition;
          const remove3 = () => hostInsert(el, container, anchor);
          const performLeave = () => {
            leave(el, () => {
              remove3();
              afterLeave && afterLeave();
            });
          };
          if (delayLeave) {
            delayLeave(el, remove3, performLeave);
          } else {
            performLeave();
          }
        }
      } else {
        hostInsert(el, container, anchor);
      }
    };
    const unmount = (vnode, parentComponent, parentSuspense, doRemove = false, optimized = false) => {
      const { type, props, ref: ref2, children, dynamicChildren, shapeFlag, patchFlag, dirs } = vnode;
      if (ref2 != null) {
        setRef(ref2, null, parentSuspense, vnode, true);
      }
      if (shapeFlag & 256) {
        parentComponent.ctx.deactivate(vnode);
        return;
      }
      const shouldInvokeDirs = shapeFlag & 1 && dirs;
      const shouldInvokeVnodeHook = !isAsyncWrapper(vnode);
      let vnodeHook;
      if (shouldInvokeVnodeHook && (vnodeHook = props && props.onVnodeBeforeUnmount)) {
        invokeVNodeHook(vnodeHook, parentComponent, vnode);
      }
      if (shapeFlag & 6) {
        unmountComponent(vnode.component, parentSuspense, doRemove);
      } else {
        if (shapeFlag & 128) {
          vnode.suspense.unmount(parentSuspense, doRemove);
          return;
        }
        if (shouldInvokeDirs) {
          invokeDirectiveHook(vnode, null, parentComponent, "beforeUnmount");
        }
        if (shapeFlag & 64) {
          vnode.type.remove(vnode, parentComponent, parentSuspense, optimized, internals, doRemove);
        } else if (dynamicChildren && (type !== Fragment || patchFlag > 0 && patchFlag & 64)) {
          unmountChildren(dynamicChildren, parentComponent, parentSuspense, false, true);
        } else if (type === Fragment && patchFlag & (128 | 256) || !optimized && shapeFlag & 16) {
          unmountChildren(children, parentComponent, parentSuspense);
        }
        if (doRemove) {
          remove2(vnode);
        }
      }
      if (shouldInvokeVnodeHook && (vnodeHook = props && props.onVnodeUnmounted) || shouldInvokeDirs) {
        queuePostRenderEffect(() => {
          vnodeHook && invokeVNodeHook(vnodeHook, parentComponent, vnode);
          shouldInvokeDirs && invokeDirectiveHook(vnode, null, parentComponent, "unmounted");
        }, parentSuspense);
      }
    };
    const remove2 = (vnode) => {
      const { type, el, anchor, transition } = vnode;
      if (type === Fragment) {
        removeFragment(el, anchor);
        return;
      }
      if (type === Static) {
        removeStaticNode(vnode);
        return;
      }
      const performRemove = () => {
        hostRemove(el);
        if (transition && !transition.persisted && transition.afterLeave) {
          transition.afterLeave();
        }
      };
      if (vnode.shapeFlag & 1 && transition && !transition.persisted) {
        const { leave, delayLeave } = transition;
        const performLeave = () => leave(el, performRemove);
        if (delayLeave) {
          delayLeave(vnode.el, performRemove, performLeave);
        } else {
          performLeave();
        }
      } else {
        performRemove();
      }
    };
    const removeFragment = (cur, end) => {
      let next;
      while (cur !== end) {
        next = hostNextSibling(cur);
        hostRemove(cur);
        cur = next;
      }
      hostRemove(end);
    };
    const unmountComponent = (instance, parentSuspense, doRemove) => {
      if (instance.type.__hmrId) {
        unregisterHMR(instance);
      }
      const { bum, scope, update, subTree, um } = instance;
      if (bum) {
        invokeArrayFns(bum);
      }
      scope.stop();
      if (update) {
        update.active = false;
        unmount(subTree, instance, parentSuspense, doRemove);
      }
      if (um) {
        queuePostRenderEffect(um, parentSuspense);
      }
      queuePostRenderEffect(() => {
        instance.isUnmounted = true;
      }, parentSuspense);
      if (parentSuspense && parentSuspense.pendingBranch && !parentSuspense.isUnmounted && instance.asyncDep && !instance.asyncResolved && instance.suspenseId === parentSuspense.pendingId) {
        parentSuspense.deps--;
        if (parentSuspense.deps === 0) {
          parentSuspense.resolve();
        }
      }
      if (true) {
        devtoolsComponentRemoved(instance);
      }
    };
    const unmountChildren = (children, parentComponent, parentSuspense, doRemove = false, optimized = false, start = 0) => {
      for (let i = start; i < children.length; i++) {
        unmount(children[i], parentComponent, parentSuspense, doRemove, optimized);
      }
    };
    const getNextHostNode = (vnode) => {
      if (vnode.shapeFlag & 6) {
        return getNextHostNode(vnode.component.subTree);
      }
      if (vnode.shapeFlag & 128) {
        return vnode.suspense.next();
      }
      return hostNextSibling(vnode.anchor || vnode.el);
    };
    const render = (vnode, container, isSVG) => {
      if (vnode == null) {
        if (container._vnode) {
          unmount(container._vnode, null, null, true);
        }
      } else {
        patch(container._vnode || null, vnode, container, null, null, null, isSVG);
      }
      flushPostFlushCbs();
      container._vnode = vnode;
    };
    const internals = {
      p: patch,
      um: unmount,
      m: move,
      r: remove2,
      mt: mountComponent,
      mc: mountChildren,
      pc: patchChildren,
      pbc: patchBlockChildren,
      n: getNextHostNode,
      o: options
    };
    let hydrate;
    let hydrateNode;
    if (createHydrationFns) {
      [hydrate, hydrateNode] = createHydrationFns(internals);
    }
    return {
      render,
      hydrate,
      createApp: createAppAPI(render, hydrate)
    };
  }
  function setRef(rawRef, oldRawRef, parentSuspense, vnode, isUnmount = false) {
    if (isArray(rawRef)) {
      rawRef.forEach((r, i) => setRef(r, oldRawRef && (isArray(oldRawRef) ? oldRawRef[i] : oldRawRef), parentSuspense, vnode, isUnmount));
      return;
    }
    if (isAsyncWrapper(vnode) && !isUnmount) {
      return;
    }
    const refValue = vnode.shapeFlag & 4 ? getExposeProxy(vnode.component) || vnode.component.proxy : vnode.el;
    const value = isUnmount ? null : refValue;
    const { i: owner, r: ref2 } = rawRef;
    if (!owner) {
      warn2(`Missing ref owner context. ref cannot be used on hoisted vnodes. A vnode with ref must be created inside the render function.`);
      return;
    }
    const oldRef = oldRawRef && oldRawRef.r;
    const refs = owner.refs === EMPTY_OBJ ? owner.refs = {} : owner.refs;
    const setupState = owner.setupState;
    if (oldRef != null && oldRef !== ref2) {
      if (isString(oldRef)) {
        refs[oldRef] = null;
        if (hasOwn(setupState, oldRef)) {
          setupState[oldRef] = null;
        }
      } else if (isRef(oldRef)) {
        oldRef.value = null;
      }
    }
    if (isString(ref2)) {
      const doSet = () => {
        {
          refs[ref2] = value;
        }
        if (hasOwn(setupState, ref2)) {
          setupState[ref2] = value;
        }
      };
      if (value) {
        doSet.id = -1;
        queuePostRenderEffect(doSet, parentSuspense);
      } else {
        doSet();
      }
    } else if (isRef(ref2)) {
      const doSet = () => {
        ref2.value = value;
      };
      if (value) {
        doSet.id = -1;
        queuePostRenderEffect(doSet, parentSuspense);
      } else {
        doSet();
      }
    } else if (isFunction(ref2)) {
      callWithErrorHandling(ref2, owner, 12, [value, refs]);
    } else if (true) {
      warn2("Invalid template ref type:", value, `(${typeof value})`);
    }
  }
  function invokeVNodeHook(hook, instance, vnode, prevVNode = null) {
    callWithAsyncErrorHandling(hook, instance, 7, [
      vnode,
      prevVNode
    ]);
  }
  function traverseStaticChildren(n1, n2, shallow = false) {
    const ch1 = n1.children;
    const ch2 = n2.children;
    if (isArray(ch1) && isArray(ch2)) {
      for (let i = 0; i < ch1.length; i++) {
        const c1 = ch1[i];
        let c2 = ch2[i];
        if (c2.shapeFlag & 1 && !c2.dynamicChildren) {
          if (c2.patchFlag <= 0 || c2.patchFlag === 32) {
            c2 = ch2[i] = cloneIfMounted(ch2[i]);
            c2.el = c1.el;
          }
          if (!shallow)
            traverseStaticChildren(c1, c2);
        }
        if (c2.type === Comment && !c2.el) {
          c2.el = c1.el;
        }
      }
    }
  }
  function getSequence(arr) {
    const p3 = arr.slice();
    const result = [0];
    let i, j, u, v, c;
    const len = arr.length;
    for (i = 0; i < len; i++) {
      const arrI = arr[i];
      if (arrI !== 0) {
        j = result[result.length - 1];
        if (arr[j] < arrI) {
          p3[i] = j;
          result.push(i);
          continue;
        }
        u = 0;
        v = result.length - 1;
        while (u < v) {
          c = u + v >> 1;
          if (arr[result[c]] < arrI) {
            u = c + 1;
          } else {
            v = c;
          }
        }
        if (arrI < arr[result[u]]) {
          if (u > 0) {
            p3[i] = result[u - 1];
          }
          result[u] = i;
        }
      }
    }
    u = result.length;
    v = result[u - 1];
    while (u-- > 0) {
      result[u] = v;
      v = p3[v];
    }
    return result;
  }
  var isTeleport = (type) => type.__isTeleport;
  var NULL_DYNAMIC_COMPONENT = Symbol();
  var Fragment = Symbol(true ? "Fragment" : void 0);
  var Text = Symbol(true ? "Text" : void 0);
  var Comment = Symbol(true ? "Comment" : void 0);
  var Static = Symbol(true ? "Static" : void 0);
  var blockStack = [];
  var currentBlock = null;
  var isBlockTreeEnabled = 1;
  function setBlockTracking(value) {
    isBlockTreeEnabled += value;
  }
  function isVNode(value) {
    return value ? value.__v_isVNode === true : false;
  }
  function isSameVNodeType(n1, n2) {
    if (n2.shapeFlag & 6 && hmrDirtyComponents.has(n2.type)) {
      return false;
    }
    return n1.type === n2.type && n1.key === n2.key;
  }
  var vnodeArgsTransformer;
  var createVNodeWithArgsTransform = (...args) => {
    return _createVNode(...vnodeArgsTransformer ? vnodeArgsTransformer(args, currentRenderingInstance) : args);
  };
  var InternalObjectKey = `__vInternal`;
  var normalizeKey = ({ key }) => key != null ? key : null;
  var normalizeRef = ({ ref: ref2 }) => {
    return ref2 != null ? isString(ref2) || isRef(ref2) || isFunction(ref2) ? { i: currentRenderingInstance, r: ref2 } : ref2 : null;
  };
  function createBaseVNode(type, props = null, children = null, patchFlag = 0, dynamicProps = null, shapeFlag = type === Fragment ? 0 : 1, isBlockNode = false, needFullChildrenNormalization = false) {
    const vnode = {
      __v_isVNode: true,
      __v_skip: true,
      type,
      props,
      key: props && normalizeKey(props),
      ref: props && normalizeRef(props),
      scopeId: currentScopeId,
      slotScopeIds: null,
      children,
      component: null,
      suspense: null,
      ssContent: null,
      ssFallback: null,
      dirs: null,
      transition: null,
      el: null,
      anchor: null,
      target: null,
      targetAnchor: null,
      staticCount: 0,
      shapeFlag,
      patchFlag,
      dynamicProps,
      dynamicChildren: null,
      appContext: null
    };
    if (needFullChildrenNormalization) {
      normalizeChildren(vnode, children);
      if (shapeFlag & 128) {
        type.normalize(vnode);
      }
    } else if (children) {
      vnode.shapeFlag |= isString(children) ? 8 : 16;
    }
    if (vnode.key !== vnode.key) {
      warn2(`VNode created with invalid key (NaN). VNode type:`, vnode.type);
    }
    if (isBlockTreeEnabled > 0 && !isBlockNode && currentBlock && (vnode.patchFlag > 0 || shapeFlag & 6) && vnode.patchFlag !== 32) {
      currentBlock.push(vnode);
    }
    return vnode;
  }
  var createVNode = true ? createVNodeWithArgsTransform : _createVNode;
  function _createVNode(type, props = null, children = null, patchFlag = 0, dynamicProps = null, isBlockNode = false) {
    if (!type || type === NULL_DYNAMIC_COMPONENT) {
      if (!type) {
        warn2(`Invalid vnode type when creating vnode: ${type}.`);
      }
      type = Comment;
    }
    if (isVNode(type)) {
      const cloned = cloneVNode(type, props, true);
      if (children) {
        normalizeChildren(cloned, children);
      }
      return cloned;
    }
    if (isClassComponent(type)) {
      type = type.__vccOpts;
    }
    if (props) {
      props = guardReactiveProps(props);
      let { class: klass, style } = props;
      if (klass && !isString(klass)) {
        props.class = normalizeClass(klass);
      }
      if (isObject(style)) {
        if (isProxy(style) && !isArray(style)) {
          style = extend({}, style);
        }
        props.style = normalizeStyle(style);
      }
    }
    const shapeFlag = isString(type) ? 1 : isSuspense(type) ? 128 : isTeleport(type) ? 64 : isObject(type) ? 4 : isFunction(type) ? 2 : 0;
    if (shapeFlag & 4 && isProxy(type)) {
      type = toRaw(type);
      warn2(`Vue received a Component which was made a reactive object. This can lead to unnecessary performance overhead, and should be avoided by marking the component with \`markRaw\` or using \`shallowRef\` instead of \`ref\`.`, `
Component that was made reactive: `, type);
    }
    return createBaseVNode(type, props, children, patchFlag, dynamicProps, shapeFlag, isBlockNode, true);
  }
  function guardReactiveProps(props) {
    if (!props)
      return null;
    return isProxy(props) || InternalObjectKey in props ? extend({}, props) : props;
  }
  function cloneVNode(vnode, extraProps, mergeRef = false) {
    const { props, ref: ref2, patchFlag, children } = vnode;
    const mergedProps = extraProps ? mergeProps(props || {}, extraProps) : props;
    const cloned = {
      __v_isVNode: true,
      __v_skip: true,
      type: vnode.type,
      props: mergedProps,
      key: mergedProps && normalizeKey(mergedProps),
      ref: extraProps && extraProps.ref ? mergeRef && ref2 ? isArray(ref2) ? ref2.concat(normalizeRef(extraProps)) : [ref2, normalizeRef(extraProps)] : normalizeRef(extraProps) : ref2,
      scopeId: vnode.scopeId,
      slotScopeIds: vnode.slotScopeIds,
      children: patchFlag === -1 && isArray(children) ? children.map(deepCloneVNode) : children,
      target: vnode.target,
      targetAnchor: vnode.targetAnchor,
      staticCount: vnode.staticCount,
      shapeFlag: vnode.shapeFlag,
      patchFlag: extraProps && vnode.type !== Fragment ? patchFlag === -1 ? 16 : patchFlag | 16 : patchFlag,
      dynamicProps: vnode.dynamicProps,
      dynamicChildren: vnode.dynamicChildren,
      appContext: vnode.appContext,
      dirs: vnode.dirs,
      transition: vnode.transition,
      component: vnode.component,
      suspense: vnode.suspense,
      ssContent: vnode.ssContent && cloneVNode(vnode.ssContent),
      ssFallback: vnode.ssFallback && cloneVNode(vnode.ssFallback),
      el: vnode.el,
      anchor: vnode.anchor
    };
    return cloned;
  }
  function deepCloneVNode(vnode) {
    const cloned = cloneVNode(vnode);
    if (isArray(vnode.children)) {
      cloned.children = vnode.children.map(deepCloneVNode);
    }
    return cloned;
  }
  function createTextVNode(text = " ", flag = 0) {
    return createVNode(Text, null, text, flag);
  }
  function normalizeVNode(child) {
    if (child == null || typeof child === "boolean") {
      return createVNode(Comment);
    } else if (isArray(child)) {
      return createVNode(Fragment, null, child.slice());
    } else if (typeof child === "object") {
      return cloneIfMounted(child);
    } else {
      return createVNode(Text, null, String(child));
    }
  }
  function cloneIfMounted(child) {
    return child.el === null || child.memo ? child : cloneVNode(child);
  }
  function normalizeChildren(vnode, children) {
    let type = 0;
    const { shapeFlag } = vnode;
    if (children == null) {
      children = null;
    } else if (isArray(children)) {
      type = 16;
    } else if (typeof children === "object") {
      if (shapeFlag & (1 | 64)) {
        const slot = children.default;
        if (slot) {
          slot._c && (slot._d = false);
          normalizeChildren(vnode, slot());
          slot._c && (slot._d = true);
        }
        return;
      } else {
        type = 32;
        const slotFlag = children._;
        if (!slotFlag && !(InternalObjectKey in children)) {
          children._ctx = currentRenderingInstance;
        } else if (slotFlag === 3 && currentRenderingInstance) {
          if (currentRenderingInstance.slots._ === 1) {
            children._ = 1;
          } else {
            children._ = 2;
            vnode.patchFlag |= 1024;
          }
        }
      }
    } else if (isFunction(children)) {
      children = { default: children, _ctx: currentRenderingInstance };
      type = 32;
    } else {
      children = String(children);
      if (shapeFlag & 64) {
        type = 16;
        children = [createTextVNode(children)];
      } else {
        type = 8;
      }
    }
    vnode.children = children;
    vnode.shapeFlag |= type;
  }
  function mergeProps(...args) {
    const ret = {};
    for (let i = 0; i < args.length; i++) {
      const toMerge = args[i];
      for (const key in toMerge) {
        if (key === "class") {
          if (ret.class !== toMerge.class) {
            ret.class = normalizeClass([ret.class, toMerge.class]);
          }
        } else if (key === "style") {
          ret.style = normalizeStyle([ret.style, toMerge.style]);
        } else if (isOn(key)) {
          const existing = ret[key];
          const incoming = toMerge[key];
          if (existing !== incoming) {
            ret[key] = existing ? [].concat(existing, incoming) : incoming;
          }
        } else if (key !== "") {
          ret[key] = toMerge[key];
        }
      }
    }
    return ret;
  }
  var getPublicInstance = (i) => {
    if (!i)
      return null;
    if (isStatefulComponent(i))
      return getExposeProxy(i) || i.proxy;
    return getPublicInstance(i.parent);
  };
  var publicPropertiesMap = extend(Object.create(null), {
    $: (i) => i,
    $el: (i) => i.vnode.el,
    $data: (i) => i.data,
    $props: (i) => true ? shallowReadonly(i.props) : i.props,
    $attrs: (i) => true ? shallowReadonly(i.attrs) : i.attrs,
    $slots: (i) => true ? shallowReadonly(i.slots) : i.slots,
    $refs: (i) => true ? shallowReadonly(i.refs) : i.refs,
    $parent: (i) => getPublicInstance(i.parent),
    $root: (i) => getPublicInstance(i.root),
    $emit: (i) => i.emit,
    $options: (i) => __VUE_OPTIONS_API__ ? resolveMergedOptions(i) : i.type,
    $forceUpdate: (i) => () => queueJob(i.update),
    $nextTick: (i) => nextTick.bind(i.proxy),
    $watch: (i) => __VUE_OPTIONS_API__ ? instanceWatch.bind(i) : NOOP
  });
  var PublicInstanceProxyHandlers = {
    get({ _: instance }, key) {
      const { ctx, setupState, data, props, accessCache, type, appContext } = instance;
      if (key === "__isVue") {
        return true;
      }
      if (setupState !== EMPTY_OBJ && setupState.__isScriptSetup && hasOwn(setupState, key)) {
        return setupState[key];
      }
      let normalizedProps;
      if (key[0] !== "$") {
        const n = accessCache[key];
        if (n !== void 0) {
          switch (n) {
            case 0:
              return setupState[key];
            case 1:
              return data[key];
            case 3:
              return ctx[key];
            case 2:
              return props[key];
          }
        } else if (setupState !== EMPTY_OBJ && hasOwn(setupState, key)) {
          accessCache[key] = 0;
          return setupState[key];
        } else if (data !== EMPTY_OBJ && hasOwn(data, key)) {
          accessCache[key] = 1;
          return data[key];
        } else if ((normalizedProps = instance.propsOptions[0]) && hasOwn(normalizedProps, key)) {
          accessCache[key] = 2;
          return props[key];
        } else if (ctx !== EMPTY_OBJ && hasOwn(ctx, key)) {
          accessCache[key] = 3;
          return ctx[key];
        } else if (!__VUE_OPTIONS_API__ || shouldCacheAccess) {
          accessCache[key] = 4;
        }
      }
      const publicGetter = publicPropertiesMap[key];
      let cssModule, globalProperties;
      if (publicGetter) {
        if (key === "$attrs") {
          track(instance, "get", key);
          markAttrsAccessed();
        }
        return publicGetter(instance);
      } else if ((cssModule = type.__cssModules) && (cssModule = cssModule[key])) {
        return cssModule;
      } else if (ctx !== EMPTY_OBJ && hasOwn(ctx, key)) {
        accessCache[key] = 3;
        return ctx[key];
      } else if (globalProperties = appContext.config.globalProperties, hasOwn(globalProperties, key)) {
        {
          return globalProperties[key];
        }
      } else if (currentRenderingInstance && (!isString(key) || key.indexOf("__v") !== 0)) {
        if (data !== EMPTY_OBJ && (key[0] === "$" || key[0] === "_") && hasOwn(data, key)) {
          warn2(`Property ${JSON.stringify(key)} must be accessed via $data because it starts with a reserved character ("$" or "_") and is not proxied on the render context.`);
        } else if (instance === currentRenderingInstance) {
          warn2(`Property ${JSON.stringify(key)} was accessed during render but is not defined on instance.`);
        }
      }
    },
    set({ _: instance }, key, value) {
      const { data, setupState, ctx } = instance;
      if (setupState !== EMPTY_OBJ && hasOwn(setupState, key)) {
        setupState[key] = value;
      } else if (data !== EMPTY_OBJ && hasOwn(data, key)) {
        data[key] = value;
      } else if (hasOwn(instance.props, key)) {
        warn2(`Attempting to mutate prop "${key}". Props are readonly.`, instance);
        return false;
      }
      if (key[0] === "$" && key.slice(1) in instance) {
        warn2(`Attempting to mutate public property "${key}". Properties starting with $ are reserved and readonly.`, instance);
        return false;
      } else {
        if (key in instance.appContext.config.globalProperties) {
          Object.defineProperty(ctx, key, {
            enumerable: true,
            configurable: true,
            value
          });
        } else {
          ctx[key] = value;
        }
      }
      return true;
    },
    has({ _: { data, setupState, accessCache, ctx, appContext, propsOptions } }, key) {
      let normalizedProps;
      return accessCache[key] !== void 0 || data !== EMPTY_OBJ && hasOwn(data, key) || setupState !== EMPTY_OBJ && hasOwn(setupState, key) || (normalizedProps = propsOptions[0]) && hasOwn(normalizedProps, key) || hasOwn(ctx, key) || hasOwn(publicPropertiesMap, key) || hasOwn(appContext.config.globalProperties, key);
    }
  };
  if (true) {
    PublicInstanceProxyHandlers.ownKeys = (target) => {
      warn2(`Avoid app logic that relies on enumerating keys on a component instance. The keys will be empty in production mode to avoid performance overhead.`);
      return Reflect.ownKeys(target);
    };
  }
  function createDevRenderContext(instance) {
    const target = {};
    Object.defineProperty(target, `_`, {
      configurable: true,
      enumerable: false,
      get: () => instance
    });
    Object.keys(publicPropertiesMap).forEach((key) => {
      Object.defineProperty(target, key, {
        configurable: true,
        enumerable: false,
        get: () => publicPropertiesMap[key](instance),
        set: NOOP
      });
    });
    return target;
  }
  function exposePropsOnRenderContext(instance) {
    const { ctx, propsOptions: [propsOptions] } = instance;
    if (propsOptions) {
      Object.keys(propsOptions).forEach((key) => {
        Object.defineProperty(ctx, key, {
          enumerable: true,
          configurable: true,
          get: () => instance.props[key],
          set: NOOP
        });
      });
    }
  }
  function exposeSetupStateOnRenderContext(instance) {
    const { ctx, setupState } = instance;
    Object.keys(toRaw(setupState)).forEach((key) => {
      if (!setupState.__isScriptSetup) {
        if (key[0] === "$" || key[0] === "_") {
          warn2(`setup() return property ${JSON.stringify(key)} should not start with "$" or "_" which are reserved prefixes for Vue internals.`);
          return;
        }
        Object.defineProperty(ctx, key, {
          enumerable: true,
          configurable: true,
          get: () => setupState[key],
          set: NOOP
        });
      }
    });
  }
  var emptyAppContext = createAppContext();
  var uid$1 = 0;
  function createComponentInstance(vnode, parent, suspense) {
    const type = vnode.type;
    const appContext = (parent ? parent.appContext : vnode.appContext) || emptyAppContext;
    const instance = {
      uid: uid$1++,
      vnode,
      type,
      parent,
      appContext,
      root: null,
      next: null,
      subTree: null,
      update: null,
      scope: new EffectScope(true),
      render: null,
      proxy: null,
      exposed: null,
      exposeProxy: null,
      withProxy: null,
      provides: parent ? parent.provides : Object.create(appContext.provides),
      accessCache: null,
      renderCache: [],
      components: null,
      directives: null,
      propsOptions: normalizePropsOptions(type, appContext),
      emitsOptions: normalizeEmitsOptions(type, appContext),
      emit: null,
      emitted: null,
      propsDefaults: EMPTY_OBJ,
      inheritAttrs: type.inheritAttrs,
      ctx: EMPTY_OBJ,
      data: EMPTY_OBJ,
      props: EMPTY_OBJ,
      attrs: EMPTY_OBJ,
      slots: EMPTY_OBJ,
      refs: EMPTY_OBJ,
      setupState: EMPTY_OBJ,
      setupContext: null,
      suspense,
      suspenseId: suspense ? suspense.pendingId : 0,
      asyncDep: null,
      asyncResolved: false,
      isMounted: false,
      isUnmounted: false,
      isDeactivated: false,
      bc: null,
      c: null,
      bm: null,
      m: null,
      bu: null,
      u: null,
      um: null,
      bum: null,
      da: null,
      a: null,
      rtg: null,
      rtc: null,
      ec: null,
      sp: null
    };
    if (true) {
      instance.ctx = createDevRenderContext(instance);
    } else {
      instance.ctx = { _: instance };
    }
    instance.root = parent ? parent.root : instance;
    instance.emit = emit$1.bind(null, instance);
    if (vnode.ce) {
      vnode.ce(instance);
    }
    return instance;
  }
  var currentInstance = null;
  var getCurrentInstance = () => currentInstance || currentRenderingInstance;
  var setCurrentInstance = (instance) => {
    currentInstance = instance;
    instance.scope.on();
  };
  var unsetCurrentInstance = () => {
    currentInstance && currentInstance.scope.off();
    currentInstance = null;
  };
  var isBuiltInTag = /* @__PURE__ */ makeMap("slot,component");
  function validateComponentName(name, config) {
    const appIsNativeTag = config.isNativeTag || NO;
    if (isBuiltInTag(name) || appIsNativeTag(name)) {
      warn2("Do not use built-in or reserved HTML elements as component id: " + name);
    }
  }
  function isStatefulComponent(instance) {
    return instance.vnode.shapeFlag & 4;
  }
  var isInSSRComponentSetup = false;
  function setupComponent(instance, isSSR = false) {
    isInSSRComponentSetup = isSSR;
    const { props, children } = instance.vnode;
    const isStateful = isStatefulComponent(instance);
    initProps(instance, props, isStateful, isSSR);
    initSlots(instance, children);
    const setupResult = isStateful ? setupStatefulComponent(instance, isSSR) : void 0;
    isInSSRComponentSetup = false;
    return setupResult;
  }
  function setupStatefulComponent(instance, isSSR) {
    const Component = instance.type;
    if (true) {
      if (Component.name) {
        validateComponentName(Component.name, instance.appContext.config);
      }
      if (Component.components) {
        const names = Object.keys(Component.components);
        for (let i = 0; i < names.length; i++) {
          validateComponentName(names[i], instance.appContext.config);
        }
      }
      if (Component.directives) {
        const names = Object.keys(Component.directives);
        for (let i = 0; i < names.length; i++) {
          validateDirectiveName(names[i]);
        }
      }
      if (Component.compilerOptions && isRuntimeOnly()) {
        warn2(`"compilerOptions" is only supported when using a build of Vue that includes the runtime compiler. Since you are using a runtime-only build, the options should be passed via your build tool config instead.`);
      }
    }
    instance.accessCache = Object.create(null);
    instance.proxy = markRaw(new Proxy(instance.ctx, PublicInstanceProxyHandlers));
    if (true) {
      exposePropsOnRenderContext(instance);
    }
    const { setup } = Component;
    if (setup) {
      const setupContext = instance.setupContext = setup.length > 1 ? createSetupContext(instance) : null;
      setCurrentInstance(instance);
      pauseTracking();
      const setupResult = callWithErrorHandling(setup, instance, 0, [true ? shallowReadonly(instance.props) : instance.props, setupContext]);
      resetTracking();
      unsetCurrentInstance();
      if (isPromise(setupResult)) {
        setupResult.then(unsetCurrentInstance, unsetCurrentInstance);
        if (isSSR) {
          return setupResult.then((resolvedResult) => {
            handleSetupResult(instance, resolvedResult, isSSR);
          }).catch((e) => {
            handleError(e, instance, 0);
          });
        } else {
          instance.asyncDep = setupResult;
        }
      } else {
        handleSetupResult(instance, setupResult, isSSR);
      }
    } else {
      finishComponentSetup(instance, isSSR);
    }
  }
  function handleSetupResult(instance, setupResult, isSSR) {
    if (isFunction(setupResult)) {
      if (instance.type.__ssrInlineRender) {
        instance.ssrRender = setupResult;
      } else {
        instance.render = setupResult;
      }
    } else if (isObject(setupResult)) {
      if (isVNode(setupResult)) {
        warn2(`setup() should not return VNodes directly - return a render function instead.`);
      }
      if (true) {
        instance.devtoolsRawSetupState = setupResult;
      }
      instance.setupState = proxyRefs(setupResult);
      if (true) {
        exposeSetupStateOnRenderContext(instance);
      }
    } else if (setupResult !== void 0) {
      warn2(`setup() should return an object. Received: ${setupResult === null ? "null" : typeof setupResult}`);
    }
    finishComponentSetup(instance, isSSR);
  }
  var compile;
  var installWithProxy;
  var isRuntimeOnly = () => !compile;
  function finishComponentSetup(instance, isSSR, skipOptions) {
    const Component = instance.type;
    if (!instance.render) {
      if (!isSSR && compile && !Component.render) {
        const template = Component.template;
        if (template) {
          if (true) {
            startMeasure(instance, `compile`);
          }
          const { isCustomElement, compilerOptions } = instance.appContext.config;
          const { delimiters, compilerOptions: componentCompilerOptions } = Component;
          const finalCompilerOptions = extend(extend({
            isCustomElement,
            delimiters
          }, compilerOptions), componentCompilerOptions);
          Component.render = compile(template, finalCompilerOptions);
          if (true) {
            endMeasure(instance, `compile`);
          }
        }
      }
      instance.render = Component.render || NOOP;
      if (installWithProxy) {
        installWithProxy(instance);
      }
    }
    if (__VUE_OPTIONS_API__ && true) {
      setCurrentInstance(instance);
      pauseTracking();
      applyOptions(instance);
      resetTracking();
      unsetCurrentInstance();
    }
    if (!Component.render && instance.render === NOOP && !isSSR) {
      if (!compile && Component.template) {
        warn2(`Component provided template option but runtime compilation is not supported in this build of Vue. Configure your bundler to alias "vue" to "vue/dist/vue.esm-bundler.js".`);
      } else {
        warn2(`Component is missing template or render function.`);
      }
    }
  }
  function createAttrsProxy(instance) {
    return new Proxy(instance.attrs, true ? {
      get(target, key) {
        markAttrsAccessed();
        track(instance, "get", "$attrs");
        return target[key];
      },
      set() {
        warn2(`setupContext.attrs is readonly.`);
        return false;
      },
      deleteProperty() {
        warn2(`setupContext.attrs is readonly.`);
        return false;
      }
    } : {
      get(target, key) {
        track(instance, "get", "$attrs");
        return target[key];
      }
    });
  }
  function createSetupContext(instance) {
    const expose = (exposed) => {
      if (instance.exposed) {
        warn2(`expose() should be called only once per setup().`);
      }
      instance.exposed = exposed || {};
    };
    let attrs;
    if (true) {
      return Object.freeze({
        get attrs() {
          return attrs || (attrs = createAttrsProxy(instance));
        },
        get slots() {
          return shallowReadonly(instance.slots);
        },
        get emit() {
          return (event, ...args) => instance.emit(event, ...args);
        },
        expose
      });
    } else {
      return {
        get attrs() {
          return attrs || (attrs = createAttrsProxy(instance));
        },
        slots: instance.slots,
        emit: instance.emit,
        expose
      };
    }
  }
  function getExposeProxy(instance) {
    if (instance.exposed) {
      return instance.exposeProxy || (instance.exposeProxy = new Proxy(proxyRefs(markRaw(instance.exposed)), {
        get(target, key) {
          if (key in target) {
            return target[key];
          } else if (key in publicPropertiesMap) {
            return publicPropertiesMap[key](instance);
          }
        }
      }));
    }
  }
  var classifyRE = /(?:^|[-_])(\w)/g;
  var classify = (str) => str.replace(classifyRE, (c) => c.toUpperCase()).replace(/[-_]/g, "");
  function getComponentName(Component) {
    return isFunction(Component) ? Component.displayName || Component.name : Component.name;
  }
  function formatComponentName(instance, Component, isRoot = false) {
    let name = getComponentName(Component);
    if (!name && Component.__file) {
      const match = Component.__file.match(/([^/\\]+)\.\w+$/);
      if (match) {
        name = match[1];
      }
    }
    if (!name && instance && instance.parent) {
      const inferFromRegistry = (registry) => {
        for (const key in registry) {
          if (registry[key] === Component) {
            return key;
          }
        }
      };
      name = inferFromRegistry(instance.components || instance.parent.type.components) || inferFromRegistry(instance.appContext.components);
    }
    return name ? classify(name) : isRoot ? `App` : `Anonymous`;
  }
  function isClassComponent(value) {
    return isFunction(value) && "__vccOpts" in value;
  }
  var stack = [];
  function pushWarningContext(vnode) {
    stack.push(vnode);
  }
  function popWarningContext() {
    stack.pop();
  }
  function warn2(msg, ...args) {
    pauseTracking();
    const instance = stack.length ? stack[stack.length - 1].component : null;
    const appWarnHandler = instance && instance.appContext.config.warnHandler;
    const trace = getComponentTrace();
    if (appWarnHandler) {
      callWithErrorHandling(appWarnHandler, instance, 11, [
        msg + args.join(""),
        instance && instance.proxy,
        trace.map(({ vnode }) => `at <${formatComponentName(instance, vnode.type)}>`).join("\n"),
        trace
      ]);
    } else {
      const warnArgs = [`[Vue warn]: ${msg}`, ...args];
      if (trace.length && true) {
        warnArgs.push(`
`, ...formatTrace(trace));
      }
      console.warn(...warnArgs);
    }
    resetTracking();
  }
  function getComponentTrace() {
    let currentVNode = stack[stack.length - 1];
    if (!currentVNode) {
      return [];
    }
    const normalizedStack = [];
    while (currentVNode) {
      const last = normalizedStack[0];
      if (last && last.vnode === currentVNode) {
        last.recurseCount++;
      } else {
        normalizedStack.push({
          vnode: currentVNode,
          recurseCount: 0
        });
      }
      const parentInstance = currentVNode.component && currentVNode.component.parent;
      currentVNode = parentInstance && parentInstance.vnode;
    }
    return normalizedStack;
  }
  function formatTrace(trace) {
    const logs = [];
    trace.forEach((entry, i) => {
      logs.push(...i === 0 ? [] : [`
`], ...formatTraceEntry(entry));
    });
    return logs;
  }
  function formatTraceEntry({ vnode, recurseCount }) {
    const postfix = recurseCount > 0 ? `... (${recurseCount} recursive calls)` : ``;
    const isRoot = vnode.component ? vnode.component.parent == null : false;
    const open = ` at <${formatComponentName(vnode.component, vnode.type, isRoot)}`;
    const close = `>` + postfix;
    return vnode.props ? [open, ...formatProps(vnode.props), close] : [open + close];
  }
  function formatProps(props) {
    const res = [];
    const keys = Object.keys(props);
    keys.slice(0, 3).forEach((key) => {
      res.push(...formatProp(key, props[key]));
    });
    if (keys.length > 3) {
      res.push(` ...`);
    }
    return res;
  }
  function formatProp(key, value, raw) {
    if (isString(value)) {
      value = JSON.stringify(value);
      return raw ? value : [`${key}=${value}`];
    } else if (typeof value === "number" || typeof value === "boolean" || value == null) {
      return raw ? value : [`${key}=${value}`];
    } else if (isRef(value)) {
      value = formatProp(key, toRaw(value.value), true);
      return raw ? value : [`${key}=Ref<`, value, `>`];
    } else if (isFunction(value)) {
      return [`${key}=fn${value.name ? `<${value.name}>` : ``}`];
    } else {
      value = toRaw(value);
      return raw ? value : [`${key}=`, value];
    }
  }
  var ErrorTypeStrings = {
    ["sp"]: "serverPrefetch hook",
    ["bc"]: "beforeCreate hook",
    ["c"]: "created hook",
    ["bm"]: "beforeMount hook",
    ["m"]: "mounted hook",
    ["bu"]: "beforeUpdate hook",
    ["u"]: "updated",
    ["bum"]: "beforeUnmount hook",
    ["um"]: "unmounted hook",
    ["a"]: "activated hook",
    ["da"]: "deactivated hook",
    ["ec"]: "errorCaptured hook",
    ["rtc"]: "renderTracked hook",
    ["rtg"]: "renderTriggered hook",
    [0]: "setup function",
    [1]: "render function",
    [2]: "watcher getter",
    [3]: "watcher callback",
    [4]: "watcher cleanup function",
    [5]: "native event handler",
    [6]: "component event handler",
    [7]: "vnode hook",
    [8]: "directive hook",
    [9]: "transition hook",
    [10]: "app errorHandler",
    [11]: "app warnHandler",
    [12]: "ref function",
    [13]: "async component loader",
    [14]: "scheduler flush. This is likely a Vue internals bug. Please open an issue at https://new-issue.vuejs.org/?repo=vuejs/vue-next"
  };
  function callWithErrorHandling(fn, instance, type, args) {
    let res;
    try {
      res = args ? fn(...args) : fn();
    } catch (err) {
      handleError(err, instance, type);
    }
    return res;
  }
  function callWithAsyncErrorHandling(fn, instance, type, args) {
    if (isFunction(fn)) {
      const res = callWithErrorHandling(fn, instance, type, args);
      if (res && isPromise(res)) {
        res.catch((err) => {
          handleError(err, instance, type);
        });
      }
      return res;
    }
    const values = [];
    for (let i = 0; i < fn.length; i++) {
      values.push(callWithAsyncErrorHandling(fn[i], instance, type, args));
    }
    return values;
  }
  function handleError(err, instance, type, throwInDev = true) {
    const contextVNode = instance ? instance.vnode : null;
    if (instance) {
      let cur = instance.parent;
      const exposedInstance = instance.proxy;
      const errorInfo = true ? ErrorTypeStrings[type] : type;
      while (cur) {
        const errorCapturedHooks = cur.ec;
        if (errorCapturedHooks) {
          for (let i = 0; i < errorCapturedHooks.length; i++) {
            if (errorCapturedHooks[i](err, exposedInstance, errorInfo) === false) {
              return;
            }
          }
        }
        cur = cur.parent;
      }
      const appErrorHandler = instance.appContext.config.errorHandler;
      if (appErrorHandler) {
        callWithErrorHandling(appErrorHandler, null, 10, [err, exposedInstance, errorInfo]);
        return;
      }
    }
    logError(err, type, contextVNode, throwInDev);
  }
  function logError(err, type, contextVNode, throwInDev = true) {
    if (true) {
      const info = ErrorTypeStrings[type];
      if (contextVNode) {
        pushWarningContext(contextVNode);
      }
      warn2(`Unhandled error${info ? ` during execution of ${info}` : ``}`);
      if (contextVNode) {
        popWarningContext();
      }
      if (throwInDev) {
        throw err;
      } else {
        console.error(err);
      }
    } else {
      console.error(err);
    }
  }
  var isFlushing = false;
  var isFlushPending = false;
  var queue = [];
  var flushIndex = 0;
  var pendingPreFlushCbs = [];
  var activePreFlushCbs = null;
  var preFlushIndex = 0;
  var pendingPostFlushCbs = [];
  var activePostFlushCbs = null;
  var postFlushIndex = 0;
  var resolvedPromise = Promise.resolve();
  var currentFlushPromise = null;
  var currentPreFlushParentJob = null;
  var RECURSION_LIMIT = 100;
  function nextTick(fn) {
    const p3 = currentFlushPromise || resolvedPromise;
    return fn ? p3.then(this ? fn.bind(this) : fn) : p3;
  }
  function findInsertionIndex(id) {
    let start = flushIndex + 1;
    let end = queue.length;
    while (start < end) {
      const middle = start + end >>> 1;
      const middleJobId = getId(queue[middle]);
      middleJobId < id ? start = middle + 1 : end = middle;
    }
    return start;
  }
  function queueJob(job) {
    if ((!queue.length || !queue.includes(job, isFlushing && job.allowRecurse ? flushIndex + 1 : flushIndex)) && job !== currentPreFlushParentJob) {
      if (job.id == null) {
        queue.push(job);
      } else {
        queue.splice(findInsertionIndex(job.id), 0, job);
      }
      queueFlush();
    }
  }
  function queueFlush() {
    if (!isFlushing && !isFlushPending) {
      isFlushPending = true;
      currentFlushPromise = resolvedPromise.then(flushJobs);
    }
  }
  function invalidateJob(job) {
    const i = queue.indexOf(job);
    if (i > flushIndex) {
      queue.splice(i, 1);
    }
  }
  function queueCb(cb, activeQueue, pendingQueue, index) {
    if (!isArray(cb)) {
      if (!activeQueue || !activeQueue.includes(cb, cb.allowRecurse ? index + 1 : index)) {
        pendingQueue.push(cb);
      }
    } else {
      pendingQueue.push(...cb);
    }
    queueFlush();
  }
  function queuePreFlushCb(cb) {
    queueCb(cb, activePreFlushCbs, pendingPreFlushCbs, preFlushIndex);
  }
  function queuePostFlushCb(cb) {
    queueCb(cb, activePostFlushCbs, pendingPostFlushCbs, postFlushIndex);
  }
  function flushPreFlushCbs(seen, parentJob = null) {
    if (pendingPreFlushCbs.length) {
      currentPreFlushParentJob = parentJob;
      activePreFlushCbs = [...new Set(pendingPreFlushCbs)];
      pendingPreFlushCbs.length = 0;
      if (true) {
        seen = seen || new Map();
      }
      for (preFlushIndex = 0; preFlushIndex < activePreFlushCbs.length; preFlushIndex++) {
        if (checkRecursiveUpdates(seen, activePreFlushCbs[preFlushIndex])) {
          continue;
        }
        activePreFlushCbs[preFlushIndex]();
      }
      activePreFlushCbs = null;
      preFlushIndex = 0;
      currentPreFlushParentJob = null;
      flushPreFlushCbs(seen, parentJob);
    }
  }
  function flushPostFlushCbs(seen) {
    if (pendingPostFlushCbs.length) {
      const deduped = [...new Set(pendingPostFlushCbs)];
      pendingPostFlushCbs.length = 0;
      if (activePostFlushCbs) {
        activePostFlushCbs.push(...deduped);
        return;
      }
      activePostFlushCbs = deduped;
      if (true) {
        seen = seen || new Map();
      }
      activePostFlushCbs.sort((a, b) => getId(a) - getId(b));
      for (postFlushIndex = 0; postFlushIndex < activePostFlushCbs.length; postFlushIndex++) {
        if (checkRecursiveUpdates(seen, activePostFlushCbs[postFlushIndex])) {
          continue;
        }
        activePostFlushCbs[postFlushIndex]();
      }
      activePostFlushCbs = null;
      postFlushIndex = 0;
    }
  }
  var getId = (job) => job.id == null ? Infinity : job.id;
  function flushJobs(seen) {
    isFlushPending = false;
    isFlushing = true;
    if (true) {
      seen = seen || new Map();
    }
    flushPreFlushCbs(seen);
    queue.sort((a, b) => getId(a) - getId(b));
    const check = true ? (job) => checkRecursiveUpdates(seen, job) : NOOP;
    try {
      for (flushIndex = 0; flushIndex < queue.length; flushIndex++) {
        const job = queue[flushIndex];
        if (job && job.active !== false) {
          if (check(job)) {
            continue;
          }
          callWithErrorHandling(job, null, 14);
        }
      }
    } finally {
      flushIndex = 0;
      queue.length = 0;
      flushPostFlushCbs(seen);
      isFlushing = false;
      currentFlushPromise = null;
      if (queue.length || pendingPreFlushCbs.length || pendingPostFlushCbs.length) {
        flushJobs(seen);
      }
    }
  }
  function checkRecursiveUpdates(seen, fn) {
    if (!seen.has(fn)) {
      seen.set(fn, 1);
    } else {
      const count2 = seen.get(fn);
      if (count2 > RECURSION_LIMIT) {
        const instance = fn.ownerInstance;
        const componentName = instance && getComponentName(instance.type);
        warn2(`Maximum recursive updates exceeded${componentName ? ` in component <${componentName}>` : ``}. This means you have a reactive effect that is mutating its own dependencies and thus recursively triggering itself. Possible sources include component template, render function, updated hook or watcher source function.`);
        return true;
      } else {
        seen.set(fn, count2 + 1);
      }
    }
  }
  var INITIAL_WATCHER_VALUE = {};
  function watch(source, cb, options) {
    if (!isFunction(cb)) {
      warn2(`\`watch(fn, options?)\` signature has been moved to a separate API. Use \`watchEffect(fn, options?)\` instead. \`watch\` now only supports \`watch(source, cb, options?) signature.`);
    }
    return doWatch(source, cb, options);
  }
  function doWatch(source, cb, { immediate, deep, flush, onTrack, onTrigger } = EMPTY_OBJ) {
    if (!cb) {
      if (immediate !== void 0) {
        warn2(`watch() "immediate" option is only respected when using the watch(source, callback, options?) signature.`);
      }
      if (deep !== void 0) {
        warn2(`watch() "deep" option is only respected when using the watch(source, callback, options?) signature.`);
      }
    }
    const warnInvalidSource = (s) => {
      warn2(`Invalid watch source: `, s, `A watch source can only be a getter/effect function, a ref, a reactive object, or an array of these types.`);
    };
    const instance = currentInstance;
    let getter;
    let forceTrigger = false;
    let isMultiSource = false;
    if (isRef(source)) {
      getter = () => source.value;
      forceTrigger = !!source._shallow;
    } else if (isReactive(source)) {
      getter = () => source;
      deep = true;
    } else if (isArray(source)) {
      isMultiSource = true;
      forceTrigger = source.some(isReactive);
      getter = () => source.map((s) => {
        if (isRef(s)) {
          return s.value;
        } else if (isReactive(s)) {
          return traverse(s);
        } else if (isFunction(s)) {
          return callWithErrorHandling(s, instance, 2);
        } else {
          warnInvalidSource(s);
        }
      });
    } else if (isFunction(source)) {
      if (cb) {
        getter = () => callWithErrorHandling(source, instance, 2);
      } else {
        getter = () => {
          if (instance && instance.isUnmounted) {
            return;
          }
          if (cleanup) {
            cleanup();
          }
          return callWithAsyncErrorHandling(source, instance, 3, [onInvalidate]);
        };
      }
    } else {
      getter = NOOP;
      warnInvalidSource(source);
    }
    if (cb && deep) {
      const baseGetter = getter;
      getter = () => traverse(baseGetter());
    }
    let cleanup;
    let onInvalidate = (fn) => {
      cleanup = effect2.onStop = () => {
        callWithErrorHandling(fn, instance, 4);
      };
    };
    if (isInSSRComponentSetup) {
      onInvalidate = NOOP;
      if (!cb) {
        getter();
      } else if (immediate) {
        callWithAsyncErrorHandling(cb, instance, 3, [
          getter(),
          isMultiSource ? [] : void 0,
          onInvalidate
        ]);
      }
      return NOOP;
    }
    let oldValue = isMultiSource ? [] : INITIAL_WATCHER_VALUE;
    const job = () => {
      if (!effect2.active) {
        return;
      }
      if (cb) {
        const newValue = effect2.run();
        if (deep || forceTrigger || (isMultiSource ? newValue.some((v, i) => hasChanged(v, oldValue[i])) : hasChanged(newValue, oldValue)) || false) {
          if (cleanup) {
            cleanup();
          }
          callWithAsyncErrorHandling(cb, instance, 3, [
            newValue,
            oldValue === INITIAL_WATCHER_VALUE ? void 0 : oldValue,
            onInvalidate
          ]);
          oldValue = newValue;
        }
      } else {
        effect2.run();
      }
    };
    job.allowRecurse = !!cb;
    let scheduler;
    if (flush === "sync") {
      scheduler = job;
    } else if (flush === "post") {
      scheduler = () => queuePostRenderEffect(job, instance && instance.suspense);
    } else {
      scheduler = () => {
        if (!instance || instance.isMounted) {
          queuePreFlushCb(job);
        } else {
          job();
        }
      };
    }
    const effect2 = new ReactiveEffect(getter, scheduler);
    if (true) {
      effect2.onTrack = onTrack;
      effect2.onTrigger = onTrigger;
    }
    if (cb) {
      if (immediate) {
        job();
      } else {
        oldValue = effect2.run();
      }
    } else if (flush === "post") {
      queuePostRenderEffect(effect2.run.bind(effect2), instance && instance.suspense);
    } else {
      effect2.run();
    }
    return () => {
      effect2.stop();
      if (instance && instance.scope) {
        remove(instance.scope.effects, effect2);
      }
    };
  }
  function instanceWatch(source, value, options) {
    const publicThis = this.proxy;
    const getter = isString(source) ? source.includes(".") ? createPathGetter(publicThis, source) : () => publicThis[source] : source.bind(publicThis, publicThis);
    let cb;
    if (isFunction(value)) {
      cb = value;
    } else {
      cb = value.handler;
      options = value;
    }
    const cur = currentInstance;
    setCurrentInstance(this);
    const res = doWatch(getter, cb.bind(publicThis), options);
    if (cur) {
      setCurrentInstance(cur);
    } else {
      unsetCurrentInstance();
    }
    return res;
  }
  function createPathGetter(ctx, path) {
    const segments = path.split(".");
    return () => {
      let cur = ctx;
      for (let i = 0; i < segments.length && cur; i++) {
        cur = cur[segments[i]];
      }
      return cur;
    };
  }
  function traverse(value, seen) {
    if (!isObject(value) || value["__v_skip"]) {
      return value;
    }
    seen = seen || new Set();
    if (seen.has(value)) {
      return value;
    }
    seen.add(value);
    if (isRef(value)) {
      traverse(value.value, seen);
    } else if (isArray(value)) {
      for (let i = 0; i < value.length; i++) {
        traverse(value[i], seen);
      }
    } else if (isSet(value) || isMap(value)) {
      value.forEach((v) => {
        traverse(v, seen);
      });
    } else if (isPlainObject(value)) {
      for (const key in value) {
        traverse(value[key], seen);
      }
    }
    return value;
  }
  true ? Object.freeze({}) : {};
  true ? Object.freeze([]) : [];
  function h(type, propsOrChildren, children) {
    const l = arguments.length;
    if (l === 2) {
      if (isObject(propsOrChildren) && !isArray(propsOrChildren)) {
        if (isVNode(propsOrChildren)) {
          return createVNode(type, null, [propsOrChildren]);
        }
        return createVNode(type, propsOrChildren);
      } else {
        return createVNode(type, null, propsOrChildren);
      }
    } else {
      if (l > 3) {
        children = Array.prototype.slice.call(arguments, 2);
      } else if (l === 3 && isVNode(children)) {
        children = [children];
      }
      return createVNode(type, propsOrChildren, children);
    }
  }
  var ssrContextKey = Symbol(true ? `ssrContext` : ``);
  function initCustomFormatter() {
    if (typeof window === "undefined") {
      return;
    }
    const vueStyle = { style: "color:#3ba776" };
    const numberStyle = { style: "color:#0b1bc9" };
    const stringStyle = { style: "color:#b62e24" };
    const keywordStyle = { style: "color:#9d288c" };
    const formatter = {
      header(obj) {
        if (!isObject(obj)) {
          return null;
        }
        if (obj.__isVue) {
          return ["div", vueStyle, `VueInstance`];
        } else if (isRef(obj)) {
          return [
            "div",
            {},
            ["span", vueStyle, genRefFlag(obj)],
            "<",
            formatValue(obj.value),
            `>`
          ];
        } else if (isReactive(obj)) {
          return [
            "div",
            {},
            ["span", vueStyle, "Reactive"],
            "<",
            formatValue(obj),
            `>${isReadonly(obj) ? ` (readonly)` : ``}`
          ];
        } else if (isReadonly(obj)) {
          return [
            "div",
            {},
            ["span", vueStyle, "Readonly"],
            "<",
            formatValue(obj),
            ">"
          ];
        }
        return null;
      },
      hasBody(obj) {
        return obj && obj.__isVue;
      },
      body(obj) {
        if (obj && obj.__isVue) {
          return [
            "div",
            {},
            ...formatInstance(obj.$)
          ];
        }
      }
    };
    function formatInstance(instance) {
      const blocks = [];
      if (instance.type.props && instance.props) {
        blocks.push(createInstanceBlock("props", toRaw(instance.props)));
      }
      if (instance.setupState !== EMPTY_OBJ) {
        blocks.push(createInstanceBlock("setup", instance.setupState));
      }
      if (instance.data !== EMPTY_OBJ) {
        blocks.push(createInstanceBlock("data", toRaw(instance.data)));
      }
      const computed2 = extractKeys(instance, "computed");
      if (computed2) {
        blocks.push(createInstanceBlock("computed", computed2));
      }
      const injected = extractKeys(instance, "inject");
      if (injected) {
        blocks.push(createInstanceBlock("injected", injected));
      }
      blocks.push([
        "div",
        {},
        [
          "span",
          {
            style: keywordStyle.style + ";opacity:0.66"
          },
          "$ (internal): "
        ],
        ["object", { object: instance }]
      ]);
      return blocks;
    }
    function createInstanceBlock(type, target) {
      target = extend({}, target);
      if (!Object.keys(target).length) {
        return ["span", {}];
      }
      return [
        "div",
        { style: "line-height:1.25em;margin-bottom:0.6em" },
        [
          "div",
          {
            style: "color:#476582"
          },
          type
        ],
        [
          "div",
          {
            style: "padding-left:1.25em"
          },
          ...Object.keys(target).map((key) => {
            return [
              "div",
              {},
              ["span", keywordStyle, key + ": "],
              formatValue(target[key], false)
            ];
          })
        ]
      ];
    }
    function formatValue(v, asRaw = true) {
      if (typeof v === "number") {
        return ["span", numberStyle, v];
      } else if (typeof v === "string") {
        return ["span", stringStyle, JSON.stringify(v)];
      } else if (typeof v === "boolean") {
        return ["span", keywordStyle, v];
      } else if (isObject(v)) {
        return ["object", { object: asRaw ? toRaw(v) : v }];
      } else {
        return ["span", stringStyle, String(v)];
      }
    }
    function extractKeys(instance, type) {
      const Comp = instance.type;
      if (isFunction(Comp)) {
        return;
      }
      const extracted = {};
      for (const key in instance.ctx) {
        if (isKeyOfType(Comp, key, type)) {
          extracted[key] = instance.ctx[key];
        }
      }
      return extracted;
    }
    function isKeyOfType(Comp, key, type) {
      const opts = Comp[type];
      if (isArray(opts) && opts.includes(key) || isObject(opts) && key in opts) {
        return true;
      }
      if (Comp.extends && isKeyOfType(Comp.extends, key, type)) {
        return true;
      }
      if (Comp.mixins && Comp.mixins.some((m) => isKeyOfType(m, key, type))) {
        return true;
      }
    }
    function genRefFlag(v) {
      if (v._shallow) {
        return `ShallowRef`;
      }
      if (v.effect) {
        return `ComputedRef`;
      }
      return `Ref`;
    }
    if (window.devtoolsFormatters) {
      window.devtoolsFormatters.push(formatter);
    } else {
      window.devtoolsFormatters = [formatter];
    }
  }
  var version = "3.2.19";

  // node_modules/@vue/runtime-dom/dist/runtime-dom.esm-bundler.js
  var svgNS = "http://www.w3.org/2000/svg";
  var doc = typeof document !== "undefined" ? document : null;
  var staticTemplateCache = new Map();
  var nodeOps = {
    insert: (child, parent, anchor) => {
      parent.insertBefore(child, anchor || null);
    },
    remove: (child) => {
      const parent = child.parentNode;
      if (parent) {
        parent.removeChild(child);
      }
    },
    createElement: (tag, isSVG, is, props) => {
      const el = isSVG ? doc.createElementNS(svgNS, tag) : doc.createElement(tag, is ? { is } : void 0);
      if (tag === "select" && props && props.multiple != null) {
        el.setAttribute("multiple", props.multiple);
      }
      return el;
    },
    createText: (text) => doc.createTextNode(text),
    createComment: (text) => doc.createComment(text),
    setText: (node, text) => {
      node.nodeValue = text;
    },
    setElementText: (el, text) => {
      el.textContent = text;
    },
    parentNode: (node) => node.parentNode,
    nextSibling: (node) => node.nextSibling,
    querySelector: (selector) => doc.querySelector(selector),
    setScopeId(el, id) {
      el.setAttribute(id, "");
    },
    cloneNode(el) {
      const cloned = el.cloneNode(true);
      if (`_value` in el) {
        cloned._value = el._value;
      }
      return cloned;
    },
    insertStaticContent(content, parent, anchor, isSVG) {
      const before = anchor ? anchor.previousSibling : parent.lastChild;
      let template = staticTemplateCache.get(content);
      if (!template) {
        const t = doc.createElement("template");
        t.innerHTML = isSVG ? `<svg>${content}</svg>` : content;
        template = t.content;
        if (isSVG) {
          const wrapper = template.firstChild;
          while (wrapper.firstChild) {
            template.appendChild(wrapper.firstChild);
          }
          template.removeChild(wrapper);
        }
        staticTemplateCache.set(content, template);
      }
      parent.insertBefore(template.cloneNode(true), anchor);
      return [
        before ? before.nextSibling : parent.firstChild,
        anchor ? anchor.previousSibling : parent.lastChild
      ];
    }
  };
  function patchClass(el, value, isSVG) {
    const transitionClasses = el._vtc;
    if (transitionClasses) {
      value = (value ? [value, ...transitionClasses] : [...transitionClasses]).join(" ");
    }
    if (value == null) {
      el.removeAttribute("class");
    } else if (isSVG) {
      el.setAttribute("class", value);
    } else {
      el.className = value;
    }
  }
  function patchStyle(el, prev, next) {
    const style = el.style;
    const currentDisplay = style.display;
    if (!next) {
      el.removeAttribute("style");
    } else if (isString(next)) {
      if (prev !== next) {
        style.cssText = next;
      }
    } else {
      for (const key in next) {
        setStyle(style, key, next[key]);
      }
      if (prev && !isString(prev)) {
        for (const key in prev) {
          if (next[key] == null) {
            setStyle(style, key, "");
          }
        }
      }
    }
    if ("_vod" in el) {
      style.display = currentDisplay;
    }
  }
  var importantRE = /\s*!important$/;
  function setStyle(style, name, val) {
    if (isArray(val)) {
      val.forEach((v) => setStyle(style, name, v));
    } else {
      if (name.startsWith("--")) {
        style.setProperty(name, val);
      } else {
        const prefixed = autoPrefix(style, name);
        if (importantRE.test(val)) {
          style.setProperty(hyphenate(prefixed), val.replace(importantRE, ""), "important");
        } else {
          style[prefixed] = val;
        }
      }
    }
  }
  var prefixes = ["Webkit", "Moz", "ms"];
  var prefixCache = {};
  function autoPrefix(style, rawName) {
    const cached = prefixCache[rawName];
    if (cached) {
      return cached;
    }
    let name = camelize(rawName);
    if (name !== "filter" && name in style) {
      return prefixCache[rawName] = name;
    }
    name = capitalize(name);
    for (let i = 0; i < prefixes.length; i++) {
      const prefixed = prefixes[i] + name;
      if (prefixed in style) {
        return prefixCache[rawName] = prefixed;
      }
    }
    return rawName;
  }
  var xlinkNS = "http://www.w3.org/1999/xlink";
  function patchAttr(el, key, value, isSVG, instance) {
    if (isSVG && key.startsWith("xlink:")) {
      if (value == null) {
        el.removeAttributeNS(xlinkNS, key.slice(6, key.length));
      } else {
        el.setAttributeNS(xlinkNS, key, value);
      }
    } else {
      const isBoolean3 = isSpecialBooleanAttr(key);
      if (value == null || isBoolean3 && !includeBooleanAttr(value)) {
        el.removeAttribute(key);
      } else {
        el.setAttribute(key, isBoolean3 ? "" : value);
      }
    }
  }
  function patchDOMProp(el, key, value, prevChildren, parentComponent, parentSuspense, unmountChildren) {
    if (key === "innerHTML" || key === "textContent") {
      if (prevChildren) {
        unmountChildren(prevChildren, parentComponent, parentSuspense);
      }
      el[key] = value == null ? "" : value;
      return;
    }
    if (key === "value" && el.tagName !== "PROGRESS") {
      el._value = value;
      const newValue = value == null ? "" : value;
      if (el.value !== newValue) {
        el.value = newValue;
      }
      if (value == null) {
        el.removeAttribute(key);
      }
      return;
    }
    if (value === "" || value == null) {
      const type = typeof el[key];
      if (type === "boolean") {
        el[key] = includeBooleanAttr(value);
        return;
      } else if (value == null && type === "string") {
        el[key] = "";
        el.removeAttribute(key);
        return;
      } else if (type === "number") {
        try {
          el[key] = 0;
        } catch (_a2) {
        }
        el.removeAttribute(key);
        return;
      }
    }
    try {
      el[key] = value;
    } catch (e) {
      if (true) {
        warn2(`Failed setting prop "${key}" on <${el.tagName.toLowerCase()}>: value ${value} is invalid.`, e);
      }
    }
  }
  var _getNow = Date.now;
  var skipTimestampCheck = false;
  if (typeof window !== "undefined") {
    if (_getNow() > document.createEvent("Event").timeStamp) {
      _getNow = () => performance.now();
    }
    const ffMatch = navigator.userAgent.match(/firefox\/(\d+)/i);
    skipTimestampCheck = !!(ffMatch && Number(ffMatch[1]) <= 53);
  }
  var cachedNow = 0;
  var p = Promise.resolve();
  var reset = () => {
    cachedNow = 0;
  };
  var getNow = () => cachedNow || (p.then(reset), cachedNow = _getNow());
  function addEventListener(el, event, handler, options) {
    el.addEventListener(event, handler, options);
  }
  function removeEventListener(el, event, handler, options) {
    el.removeEventListener(event, handler, options);
  }
  function patchEvent(el, rawName, prevValue, nextValue, instance = null) {
    const invokers = el._vei || (el._vei = {});
    const existingInvoker = invokers[rawName];
    if (nextValue && existingInvoker) {
      existingInvoker.value = nextValue;
    } else {
      const [name, options] = parseName(rawName);
      if (nextValue) {
        const invoker = invokers[rawName] = createInvoker(nextValue, instance);
        addEventListener(el, name, invoker, options);
      } else if (existingInvoker) {
        removeEventListener(el, name, existingInvoker, options);
        invokers[rawName] = void 0;
      }
    }
  }
  var optionsModifierRE = /(?:Once|Passive|Capture)$/;
  function parseName(name) {
    let options;
    if (optionsModifierRE.test(name)) {
      options = {};
      let m;
      while (m = name.match(optionsModifierRE)) {
        name = name.slice(0, name.length - m[0].length);
        options[m[0].toLowerCase()] = true;
      }
    }
    return [hyphenate(name.slice(2)), options];
  }
  function createInvoker(initialValue, instance) {
    const invoker = (e) => {
      const timeStamp = e.timeStamp || _getNow();
      if (skipTimestampCheck || timeStamp >= invoker.attached - 1) {
        callWithAsyncErrorHandling(patchStopImmediatePropagation(e, invoker.value), instance, 5, [e]);
      }
    };
    invoker.value = initialValue;
    invoker.attached = getNow();
    return invoker;
  }
  function patchStopImmediatePropagation(e, value) {
    if (isArray(value)) {
      const originalStop = e.stopImmediatePropagation;
      e.stopImmediatePropagation = () => {
        originalStop.call(e);
        e._stopped = true;
      };
      return value.map((fn) => (e2) => !e2._stopped && fn(e2));
    } else {
      return value;
    }
  }
  var nativeOnRE = /^on[a-z]/;
  var patchProp = (el, key, prevValue, nextValue, isSVG = false, prevChildren, parentComponent, parentSuspense, unmountChildren) => {
    if (key === "class") {
      patchClass(el, nextValue, isSVG);
    } else if (key === "style") {
      patchStyle(el, prevValue, nextValue);
    } else if (isOn(key)) {
      if (!isModelListener(key)) {
        patchEvent(el, key, prevValue, nextValue, parentComponent);
      }
    } else if (key[0] === "." ? (key = key.slice(1), true) : key[0] === "^" ? (key = key.slice(1), false) : shouldSetAsProp(el, key, nextValue, isSVG)) {
      patchDOMProp(el, key, nextValue, prevChildren, parentComponent, parentSuspense, unmountChildren);
    } else {
      if (key === "true-value") {
        el._trueValue = nextValue;
      } else if (key === "false-value") {
        el._falseValue = nextValue;
      }
      patchAttr(el, key, nextValue, isSVG);
    }
  };
  function shouldSetAsProp(el, key, value, isSVG) {
    if (isSVG) {
      if (key === "innerHTML" || key === "textContent") {
        return true;
      }
      if (key in el && nativeOnRE.test(key) && isFunction(value)) {
        return true;
      }
      return false;
    }
    if (key === "spellcheck" || key === "draggable") {
      return false;
    }
    if (key === "form") {
      return false;
    }
    if (key === "list" && el.tagName === "INPUT") {
      return false;
    }
    if (key === "type" && el.tagName === "TEXTAREA") {
      return false;
    }
    if (nativeOnRE.test(key) && isString(value)) {
      return false;
    }
    return key in el;
  }
  var TRANSITION = "transition";
  var ANIMATION = "animation";
  var Transition = (props, { slots }) => h(BaseTransition, resolveTransitionProps(props), slots);
  Transition.displayName = "Transition";
  var DOMTransitionPropsValidators = {
    name: String,
    type: String,
    css: {
      type: Boolean,
      default: true
    },
    duration: [String, Number, Object],
    enterFromClass: String,
    enterActiveClass: String,
    enterToClass: String,
    appearFromClass: String,
    appearActiveClass: String,
    appearToClass: String,
    leaveFromClass: String,
    leaveActiveClass: String,
    leaveToClass: String
  };
  var TransitionPropsValidators = Transition.props = /* @__PURE__ */ extend({}, BaseTransition.props, DOMTransitionPropsValidators);
  var callHook2 = (hook, args = []) => {
    if (isArray(hook)) {
      hook.forEach((h2) => h2(...args));
    } else if (hook) {
      hook(...args);
    }
  };
  var hasExplicitCallback = (hook) => {
    return hook ? isArray(hook) ? hook.some((h2) => h2.length > 1) : hook.length > 1 : false;
  };
  function resolveTransitionProps(rawProps) {
    const baseProps = {};
    for (const key in rawProps) {
      if (!(key in DOMTransitionPropsValidators)) {
        baseProps[key] = rawProps[key];
      }
    }
    if (rawProps.css === false) {
      return baseProps;
    }
    const { name = "v", type, duration, enterFromClass = `${name}-enter-from`, enterActiveClass = `${name}-enter-active`, enterToClass = `${name}-enter-to`, appearFromClass = enterFromClass, appearActiveClass = enterActiveClass, appearToClass = enterToClass, leaveFromClass = `${name}-leave-from`, leaveActiveClass = `${name}-leave-active`, leaveToClass = `${name}-leave-to` } = rawProps;
    const durations = normalizeDuration(duration);
    const enterDuration = durations && durations[0];
    const leaveDuration = durations && durations[1];
    const { onBeforeEnter, onEnter, onEnterCancelled, onLeave, onLeaveCancelled, onBeforeAppear = onBeforeEnter, onAppear = onEnter, onAppearCancelled = onEnterCancelled } = baseProps;
    const finishEnter = (el, isAppear, done) => {
      removeTransitionClass(el, isAppear ? appearToClass : enterToClass);
      removeTransitionClass(el, isAppear ? appearActiveClass : enterActiveClass);
      done && done();
    };
    const finishLeave = (el, done) => {
      removeTransitionClass(el, leaveToClass);
      removeTransitionClass(el, leaveActiveClass);
      done && done();
    };
    const makeEnterHook = (isAppear) => {
      return (el, done) => {
        const hook = isAppear ? onAppear : onEnter;
        const resolve = () => finishEnter(el, isAppear, done);
        callHook2(hook, [el, resolve]);
        nextFrame(() => {
          removeTransitionClass(el, isAppear ? appearFromClass : enterFromClass);
          addTransitionClass(el, isAppear ? appearToClass : enterToClass);
          if (!hasExplicitCallback(hook)) {
            whenTransitionEnds(el, type, enterDuration, resolve);
          }
        });
      };
    };
    return extend(baseProps, {
      onBeforeEnter(el) {
        callHook2(onBeforeEnter, [el]);
        addTransitionClass(el, enterFromClass);
        addTransitionClass(el, enterActiveClass);
      },
      onBeforeAppear(el) {
        callHook2(onBeforeAppear, [el]);
        addTransitionClass(el, appearFromClass);
        addTransitionClass(el, appearActiveClass);
      },
      onEnter: makeEnterHook(false),
      onAppear: makeEnterHook(true),
      onLeave(el, done) {
        const resolve = () => finishLeave(el, done);
        addTransitionClass(el, leaveFromClass);
        forceReflow();
        addTransitionClass(el, leaveActiveClass);
        nextFrame(() => {
          removeTransitionClass(el, leaveFromClass);
          addTransitionClass(el, leaveToClass);
          if (!hasExplicitCallback(onLeave)) {
            whenTransitionEnds(el, type, leaveDuration, resolve);
          }
        });
        callHook2(onLeave, [el, resolve]);
      },
      onEnterCancelled(el) {
        finishEnter(el, false);
        callHook2(onEnterCancelled, [el]);
      },
      onAppearCancelled(el) {
        finishEnter(el, true);
        callHook2(onAppearCancelled, [el]);
      },
      onLeaveCancelled(el) {
        finishLeave(el);
        callHook2(onLeaveCancelled, [el]);
      }
    });
  }
  function normalizeDuration(duration) {
    if (duration == null) {
      return null;
    } else if (isObject(duration)) {
      return [NumberOf(duration.enter), NumberOf(duration.leave)];
    } else {
      const n = NumberOf(duration);
      return [n, n];
    }
  }
  function NumberOf(val) {
    const res = toNumber(val);
    if (true)
      validateDuration(res);
    return res;
  }
  function validateDuration(val) {
    if (typeof val !== "number") {
      warn2(`<transition> explicit duration is not a valid number - got ${JSON.stringify(val)}.`);
    } else if (isNaN(val)) {
      warn2(`<transition> explicit duration is NaN - the duration expression might be incorrect.`);
    }
  }
  function addTransitionClass(el, cls) {
    cls.split(/\s+/).forEach((c) => c && el.classList.add(c));
    (el._vtc || (el._vtc = new Set())).add(cls);
  }
  function removeTransitionClass(el, cls) {
    cls.split(/\s+/).forEach((c) => c && el.classList.remove(c));
    const { _vtc } = el;
    if (_vtc) {
      _vtc.delete(cls);
      if (!_vtc.size) {
        el._vtc = void 0;
      }
    }
  }
  function nextFrame(cb) {
    requestAnimationFrame(() => {
      requestAnimationFrame(cb);
    });
  }
  var endId = 0;
  function whenTransitionEnds(el, expectedType, explicitTimeout, resolve) {
    const id = el._endId = ++endId;
    const resolveIfNotStale = () => {
      if (id === el._endId) {
        resolve();
      }
    };
    if (explicitTimeout) {
      return setTimeout(resolveIfNotStale, explicitTimeout);
    }
    const { type, timeout, propCount } = getTransitionInfo(el, expectedType);
    if (!type) {
      return resolve();
    }
    const endEvent = type + "end";
    let ended = 0;
    const end = () => {
      el.removeEventListener(endEvent, onEnd);
      resolveIfNotStale();
    };
    const onEnd = (e) => {
      if (e.target === el && ++ended >= propCount) {
        end();
      }
    };
    setTimeout(() => {
      if (ended < propCount) {
        end();
      }
    }, timeout + 1);
    el.addEventListener(endEvent, onEnd);
  }
  function getTransitionInfo(el, expectedType) {
    const styles = window.getComputedStyle(el);
    const getStyleProperties = (key) => (styles[key] || "").split(", ");
    const transitionDelays = getStyleProperties(TRANSITION + "Delay");
    const transitionDurations = getStyleProperties(TRANSITION + "Duration");
    const transitionTimeout = getTimeout(transitionDelays, transitionDurations);
    const animationDelays = getStyleProperties(ANIMATION + "Delay");
    const animationDurations = getStyleProperties(ANIMATION + "Duration");
    const animationTimeout = getTimeout(animationDelays, animationDurations);
    let type = null;
    let timeout = 0;
    let propCount = 0;
    if (expectedType === TRANSITION) {
      if (transitionTimeout > 0) {
        type = TRANSITION;
        timeout = transitionTimeout;
        propCount = transitionDurations.length;
      }
    } else if (expectedType === ANIMATION) {
      if (animationTimeout > 0) {
        type = ANIMATION;
        timeout = animationTimeout;
        propCount = animationDurations.length;
      }
    } else {
      timeout = Math.max(transitionTimeout, animationTimeout);
      type = timeout > 0 ? transitionTimeout > animationTimeout ? TRANSITION : ANIMATION : null;
      propCount = type ? type === TRANSITION ? transitionDurations.length : animationDurations.length : 0;
    }
    const hasTransform = type === TRANSITION && /\b(transform|all)(,|$)/.test(styles[TRANSITION + "Property"]);
    return {
      type,
      timeout,
      propCount,
      hasTransform
    };
  }
  function getTimeout(delays, durations) {
    while (delays.length < durations.length) {
      delays = delays.concat(delays);
    }
    return Math.max(...durations.map((d, i) => toMs(d) + toMs(delays[i])));
  }
  function toMs(s) {
    return Number(s.slice(0, -1).replace(",", ".")) * 1e3;
  }
  function forceReflow() {
    return document.body.offsetHeight;
  }
  var positionMap = new WeakMap();
  var newPositionMap = new WeakMap();
  var rendererOptions = extend({ patchProp }, nodeOps);
  var renderer;
  function ensureRenderer() {
    return renderer || (renderer = createRenderer(rendererOptions));
  }
  var createApp = (...args) => {
    const app = ensureRenderer().createApp(...args);
    if (true) {
      injectNativeTagCheck(app);
      injectCompilerOptionsCheck(app);
    }
    const { mount } = app;
    app.mount = (containerOrSelector) => {
      const container = normalizeContainer(containerOrSelector);
      if (!container)
        return;
      const component = app._component;
      if (!isFunction(component) && !component.render && !component.template) {
        component.template = container.innerHTML;
      }
      container.innerHTML = "";
      const proxy = mount(container, false, container instanceof SVGElement);
      if (container instanceof Element) {
        container.removeAttribute("v-cloak");
        container.setAttribute("data-v-app", "");
      }
      return proxy;
    };
    return app;
  };
  function injectNativeTagCheck(app) {
    Object.defineProperty(app.config, "isNativeTag", {
      value: (tag) => isHTMLTag(tag) || isSVGTag(tag),
      writable: false
    });
  }
  function injectCompilerOptionsCheck(app) {
    if (isRuntimeOnly()) {
      const isCustomElement = app.config.isCustomElement;
      Object.defineProperty(app.config, "isCustomElement", {
        get() {
          return isCustomElement;
        },
        set() {
          warn2(`The \`isCustomElement\` config option is deprecated. Use \`compilerOptions.isCustomElement\` instead.`);
        }
      });
      const compilerOptions = app.config.compilerOptions;
      const msg = `The \`compilerOptions\` config option is only respected when using a build of Vue.js that includes the runtime compiler (aka "full build"). Since you are using the runtime-only build, \`compilerOptions\` must be passed to \`@vue/compiler-dom\` in the build setup instead.
- For vue-loader: pass it via vue-loader's \`compilerOptions\` loader option.
- For vue-cli: see https://cli.vuejs.org/guide/webpack.html#modifying-options-of-a-loader
- For vite: pass it via @vitejs/plugin-vue options. See https://github.com/vitejs/vite/tree/main/packages/plugin-vue#example-for-passing-options-to-vuecompiler-dom`;
      Object.defineProperty(app.config, "compilerOptions", {
        get() {
          warn2(msg);
          return compilerOptions;
        },
        set() {
          warn2(msg);
        }
      });
    }
  }
  function normalizeContainer(container) {
    if (isString(container)) {
      const res = document.querySelector(container);
      if (!res) {
        warn2(`Failed to mount app: mount target selector "${container}" returned null.`);
      }
      return res;
    }
    if (window.ShadowRoot && container instanceof window.ShadowRoot && container.mode === "closed") {
      warn2(`mounting on a ShadowRoot with \`{mode: "closed"}\` may lead to unpredictable bugs`);
    }
    return container;
  }

  // node_modules/vue/dist/vue.runtime.esm-bundler.js
  function initDev() {
    {
      initCustomFormatter();
    }
  }
  if (true) {
    initDev();
  }

  // hw4/client/dev/utils.ts
  var parserVector = (tsv) => {
    return tsv.split("\n").map((v) => v.split("	").map((x) => Number(x)));
  };
  var parserMetadata = (tsv) => {
    return tsv.split("\n");
  };
  var levenshteinDistance = (source, target) => {
    let distances = [
      [
        0,
        ...Array(target.length).fill(0).map((_, idx) => idx + 1)
      ]
    ];
    for (let [i, c1] of source.split("").entries()) {
      distances.push([i + 1]);
      for (let [j, c2] of target.split("").entries()) {
        let ins = distances[i + 1][j] + 1;
        let del = distances[i][j + 1] + 1;
        let sub4 = distances[i][j] + (c1 == c2 ? 0 : 1);
        distances[i + 1].push(Math.min(ins, del, sub4));
      }
    }
    return distances?.at(-1)?.at(-1) ?? NaN;
  };
  var calcTermFreq = (vocab2, sents2, terms2) => {
    let termCount = [];
    for (const [sidx, token] of terms2) {
      const didx = sents2[sidx][0];
      if (termCount[didx] == void 0) {
        termCount[didx] = new Array(vocab2.length).fill(0);
      }
      const vidx = vocab2.findIndex((tk) => tk == token);
      if (vidx != -1) {
        termCount[didx][vidx] += 1;
      }
    }
    const termFreq = termCount.map((docTermCount) => {
      const total = docTermCount.reduce((total2, count2) => total2 + count2, 0);
      return docTermCount.map((count2) => count2 / total);
    });
    return termFreq;
  };
  var calcInvDocFreq = (termFreq) => {
    const docNum = termFreq.length;
    const idf = termFreq.reduce((df, freq) => {
      return df.map((v, i) => v + freq[i] != 0 ? 1 : 0);
    }, termFreq[0].map(() => 1)).map((v) => docNum / v).map((v) => Math.log(v));
    return idf;
  };
  var calcTfidf = (vocab2, sents2, terms2) => {
    const termFreq = calcTermFreq(vocab2, sents2, terms2);
    const idf = calcInvDocFreq(termFreq);
    const tfidf2 = termFreq.map((freq) => {
      return freq.map((f, i) => f * idf[i]);
    });
    return tfidf2;
  };
  var calcSentsEmbWithTfidf = (vocab2, embs2, tfidf2, sents2, terms2) => {
    const dim = embs2[0].length;
    const sentsEmb = sents2.map(() => {
      return new Array(dim).fill(0);
    });
    for (const [sidx, term] of terms2) {
      const didx = sents2[sidx][0];
      const vidx = vocab2.findIndex((v) => v == term);
      if (vidx != -1) {
        for (const [i, e] of embs2[vidx].entries()) {
          sentsEmb[sidx][i] += e * tfidf2[didx][vidx];
        }
      }
    }
    return sentsEmb;
  };
  var stopWord = new Set([
    "about",
    "again",
    "al",
    "all",
    "almost",
    "also",
    "although",
    "always",
    "among",
    "an",
    "and",
    "another",
    "any",
    "are",
    "as",
    "at",
    "be",
    "because",
    "been",
    "before",
    "being",
    "between",
    "both",
    "but",
    "by",
    "can",
    "could",
    "did",
    "do",
    "does",
    "done",
    "due",
    "during",
    "each",
    "eight",
    "either",
    "enough",
    "especially",
    "et.",
    "et",
    "etc",
    "five",
    "for",
    "found",
    "four",
    "from",
    "further",
    "had",
    "has",
    "have",
    "having",
    "here",
    "how",
    "however",
    "i",
    "ie",
    "if",
    "in",
    "into",
    "is",
    "it",
    "its",
    "itself",
    "just",
    "kg",
    "km",
    "made",
    "mainly",
    "make",
    "may",
    "mg",
    "might",
    "ml",
    "mm",
    "many",
    "most",
    "mostly",
    "must",
    "nearly",
    "neither",
    "nine",
    "no",
    "nor",
    "not",
    "obtained",
    "of",
    "often",
    "on",
    "one",
    "or",
    "our",
    "overall",
    "perhaps",
    "quite",
    "rather",
    "really",
    "regarding",
    "seem",
    "seen",
    "seven",
    "several",
    "should",
    "show",
    "showed",
    "shown",
    "shows",
    "significantly",
    "since",
    "six",
    "so",
    "some",
    "such",
    "ten",
    "than",
    "that",
    "the",
    "their",
    "theirs",
    "them",
    "then",
    "there",
    "therefore",
    "these",
    "they",
    "this",
    "those",
    "three",
    "through",
    "thus",
    "to",
    "two",
    "upon",
    "use",
    "used",
    "using",
    "various",
    "very",
    "was",
    "we",
    "were",
    "what",
    "when",
    "where",
    "whether",
    "which",
    "while",
    "who",
    "why",
    "with",
    "within",
    "without"
  ]);

  // node_modules/@tensorflow/tfjs-core/dist/backends/backend.js
  var EPSILON_FLOAT32 = 1e-7;
  var EPSILON_FLOAT16 = 1e-4;
  var DataStorage = class {
    constructor(backend2, dataMover) {
      this.backend = backend2;
      this.dataMover = dataMover;
      this.data = new WeakMap();
      this.dataIdsCount = 0;
    }
    get(dataId) {
      if (!this.data.has(dataId)) {
        this.dataMover.moveData(this.backend, dataId);
      }
      return this.data.get(dataId);
    }
    set(dataId, value) {
      this.dataIdsCount++;
      this.data.set(dataId, value);
    }
    has(dataId) {
      return this.data.has(dataId);
    }
    delete(dataId) {
      this.dataIdsCount--;
      return this.data.delete(dataId);
    }
    numDataIds() {
      return this.dataIdsCount;
    }
  };
  var KernelBackend = class {
    refCount(dataId) {
      return notYetImplemented("refCount");
    }
    incRef(dataId) {
      return notYetImplemented("incRef");
    }
    timerAvailable() {
      return true;
    }
    time(f) {
      return notYetImplemented("time");
    }
    read(dataId) {
      return notYetImplemented("read");
    }
    readSync(dataId) {
      return notYetImplemented("readSync");
    }
    numDataIds() {
      return notYetImplemented("numDataIds");
    }
    disposeData(dataId, force) {
      return notYetImplemented("disposeData");
    }
    write(values, shape, dtype) {
      return notYetImplemented("write");
    }
    move(dataId, values, shape, dtype, refCount) {
      return notYetImplemented("move");
    }
    memory() {
      return notYetImplemented("memory");
    }
    floatPrecision() {
      return notYetImplemented("floatPrecision");
    }
    epsilon() {
      return this.floatPrecision() === 32 ? EPSILON_FLOAT32 : EPSILON_FLOAT16;
    }
    dispose() {
      return notYetImplemented("dispose");
    }
  };
  function notYetImplemented(kernelName) {
    throw new Error(`'${kernelName}' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen`);
  }

  // node_modules/@tensorflow/tfjs-core/dist/util_base.js
  function shuffle(array2) {
    let counter = array2.length;
    let index = 0;
    while (counter > 0) {
      index = Math.random() * counter | 0;
      counter--;
      swap(array2, counter, index);
    }
  }
  function shuffleCombo(array2, array22) {
    if (array2.length !== array22.length) {
      throw new Error(`Array sizes must match to be shuffled together First array length was ${array2.length}Second array length was ${array22.length}`);
    }
    let counter = array2.length;
    let index = 0;
    while (counter > 0) {
      index = Math.random() * counter | 0;
      counter--;
      swap(array2, counter, index);
      swap(array22, counter, index);
    }
  }
  function clamp(min5, x, max5) {
    return Math.max(min5, Math.min(x, max5));
  }
  function nearestLargerEven(val) {
    return val % 2 === 0 ? val : val + 1;
  }
  function swap(object, left, right) {
    const temp = object[left];
    object[left] = object[right];
    object[right] = temp;
  }
  function sum(arr) {
    let sum5 = 0;
    for (let i = 0; i < arr.length; i++) {
      sum5 += arr[i];
    }
    return sum5;
  }
  function randUniform(a, b) {
    const r = Math.random();
    return b * r + (1 - r) * a;
  }
  function distSquared(a, b) {
    let result = 0;
    for (let i = 0; i < a.length; i++) {
      const diff = Number(a[i]) - Number(b[i]);
      result += diff * diff;
    }
    return result;
  }
  function assert(expr, msg) {
    if (!expr) {
      throw new Error(typeof msg === "string" ? msg : msg());
    }
  }
  function assertShapesMatch(shapeA, shapeB, errorMessagePrefix = "") {
    assert(arraysEqual(shapeA, shapeB), () => errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);
  }
  function assertNonNull(a) {
    assert(a != null, () => `The input to the tensor constructor must be a non-null value.`);
  }
  function flatten(arr, result = [], skipTypedArray = false) {
    if (result == null) {
      result = [];
    }
    if (Array.isArray(arr) || isTypedArray(arr) && !skipTypedArray) {
      for (let i = 0; i < arr.length; ++i) {
        flatten(arr[i], result, skipTypedArray);
      }
    } else {
      result.push(arr);
    }
    return result;
  }
  function sizeFromShape(shape) {
    if (shape.length === 0) {
      return 1;
    }
    let size2 = shape[0];
    for (let i = 1; i < shape.length; i++) {
      size2 *= shape[i];
    }
    return size2;
  }
  function isScalarShape(shape) {
    return shape.length === 0;
  }
  function arraysEqual(n1, n2) {
    if (n1 === n2) {
      return true;
    }
    if (n1 == null || n2 == null) {
      return false;
    }
    if (n1.length !== n2.length) {
      return false;
    }
    for (let i = 0; i < n1.length; i++) {
      if (n1[i] !== n2[i]) {
        return false;
      }
    }
    return true;
  }
  function isInt(a) {
    return a % 1 === 0;
  }
  function tanh(x) {
    if (Math.tanh != null) {
      return Math.tanh(x);
    }
    if (x === Infinity) {
      return 1;
    } else if (x === -Infinity) {
      return -1;
    } else {
      const e2x = Math.exp(2 * x);
      return (e2x - 1) / (e2x + 1);
    }
  }
  function sizeToSquarishShape(size2) {
    const width = Math.ceil(Math.sqrt(size2));
    return [width, Math.ceil(size2 / width)];
  }
  function createShuffledIndices(n) {
    const shuffledIndices = new Uint32Array(n);
    for (let i = 0; i < n; ++i) {
      shuffledIndices[i] = i;
    }
    shuffle(shuffledIndices);
    return shuffledIndices;
  }
  function rightPad(a, size2) {
    if (size2 <= a.length) {
      return a;
    }
    return a + " ".repeat(size2 - a.length);
  }
  function repeatedTry(checkFn, delayFn = (counter) => 0, maxCounter) {
    return new Promise((resolve, reject) => {
      let tryCount = 0;
      const tryFn = () => {
        if (checkFn()) {
          resolve();
          return;
        }
        tryCount++;
        const nextBackoff = delayFn(tryCount);
        if (maxCounter != null && tryCount >= maxCounter) {
          reject();
          return;
        }
        setTimeout(tryFn, nextBackoff);
      };
      tryFn();
    });
  }
  function inferFromImplicitShape(shape, size2) {
    let shapeProd = 1;
    let implicitIdx = -1;
    for (let i = 0; i < shape.length; ++i) {
      if (shape[i] >= 0) {
        shapeProd *= shape[i];
      } else if (shape[i] === -1) {
        if (implicitIdx !== -1) {
          throw Error(`Shapes can only have 1 implicit size. Found -1 at dim ${implicitIdx} and dim ${i}`);
        }
        implicitIdx = i;
      } else if (shape[i] < 0) {
        throw Error(`Shapes can not be < 0. Found ${shape[i]} at dim ${i}`);
      }
    }
    if (implicitIdx === -1) {
      if (size2 > 0 && size2 !== shapeProd) {
        throw Error(`Size(${size2}) must match the product of shape ${shape}`);
      }
      return shape;
    }
    if (shapeProd === 0) {
      throw Error(`Cannot infer the missing size in [${shape}] when there are 0 elements`);
    }
    if (size2 % shapeProd !== 0) {
      throw Error(`The implicit shape can't be a fractional number. Got ${size2} / ${shapeProd}`);
    }
    const newShape = shape.slice();
    newShape[implicitIdx] = size2 / shapeProd;
    return newShape;
  }
  function parseAxisParam(axis, shape) {
    const rank = shape.length;
    axis = axis == null ? shape.map((s, i) => i) : [].concat(axis);
    assert(axis.every((ax) => ax >= -rank && ax < rank), () => `All values in axis param must be in range [-${rank}, ${rank}) but got axis ${axis}`);
    assert(axis.every((ax) => isInt(ax)), () => `All values in axis param must be integers but got axis ${axis}`);
    return axis.map((a) => a < 0 ? rank + a : a);
  }
  function squeezeShape(shape, axis) {
    const newShape = [];
    const keptDims = [];
    const isEmptyArray = axis != null && Array.isArray(axis) && axis.length === 0;
    const axes = axis == null || isEmptyArray ? null : parseAxisParam(axis, shape).sort();
    let j = 0;
    for (let i = 0; i < shape.length; ++i) {
      if (axes != null) {
        if (axes[j] === i && shape[i] !== 1) {
          throw new Error(`Can't squeeze axis ${i} since its dim '${shape[i]}' is not 1`);
        }
        if ((axes[j] == null || axes[j] > i) && shape[i] === 1) {
          newShape.push(shape[i]);
          keptDims.push(i);
        }
        if (axes[j] <= i) {
          j++;
        }
      }
      if (shape[i] !== 1) {
        newShape.push(shape[i]);
        keptDims.push(i);
      }
    }
    return { newShape, keptDims };
  }
  function getTypedArrayFromDType(dtype, size2) {
    let values = null;
    if (dtype == null || dtype === "float32") {
      values = new Float32Array(size2);
    } else if (dtype === "int32") {
      values = new Int32Array(size2);
    } else if (dtype === "bool") {
      values = new Uint8Array(size2);
    } else {
      throw new Error(`Unknown data type ${dtype}`);
    }
    return values;
  }
  function getArrayFromDType(dtype, size2) {
    let values = null;
    if (dtype == null || dtype === "float32") {
      values = new Float32Array(size2);
    } else if (dtype === "int32") {
      values = new Int32Array(size2);
    } else if (dtype === "bool") {
      values = new Uint8Array(size2);
    } else if (dtype === "string") {
      values = new Array(size2);
    } else {
      throw new Error(`Unknown data type ${dtype}`);
    }
    return values;
  }
  function checkConversionForErrors(vals, dtype) {
    for (let i = 0; i < vals.length; i++) {
      const num = vals[i];
      if (isNaN(num) || !isFinite(num)) {
        throw Error(`A tensor of type ${dtype} being uploaded contains ${num}.`);
      }
    }
  }
  function isValidDtype(dtype) {
    return dtype === "bool" || dtype === "complex64" || dtype === "float32" || dtype === "int32" || dtype === "string";
  }
  function hasEncodingLoss(oldType, newType) {
    if (newType === "complex64") {
      return false;
    }
    if (newType === "float32" && oldType !== "complex64") {
      return false;
    }
    if (newType === "int32" && oldType !== "float32" && oldType !== "complex64") {
      return false;
    }
    if (newType === "bool" && oldType === "bool") {
      return false;
    }
    return true;
  }
  function isTypedArray(a) {
    return a instanceof Float32Array || a instanceof Int32Array || a instanceof Uint8Array || a instanceof Uint8ClampedArray;
  }
  function bytesPerElement(dtype) {
    if (dtype === "float32" || dtype === "int32") {
      return 4;
    } else if (dtype === "complex64") {
      return 8;
    } else if (dtype === "bool") {
      return 1;
    } else {
      throw new Error(`Unknown dtype ${dtype}`);
    }
  }
  function bytesFromStringArray(arr) {
    if (arr == null) {
      return 0;
    }
    let bytes = 0;
    arr.forEach((x) => bytes += x.length);
    return bytes;
  }
  function isString2(value) {
    return typeof value === "string" || value instanceof String;
  }
  function isBoolean2(value) {
    return typeof value === "boolean";
  }
  function isNumber(value) {
    return typeof value === "number";
  }
  function inferDtype(values) {
    if (Array.isArray(values)) {
      return inferDtype(values[0]);
    }
    if (values instanceof Float32Array) {
      return "float32";
    } else if (values instanceof Int32Array || values instanceof Uint8Array || values instanceof Uint8ClampedArray) {
      return "int32";
    } else if (isNumber(values)) {
      return "float32";
    } else if (isString2(values)) {
      return "string";
    } else if (isBoolean2(values)) {
      return "bool";
    }
    return "float32";
  }
  function isFunction2(f) {
    return !!(f && f.constructor && f.call && f.apply);
  }
  function nearestDivisor(size2, start) {
    for (let i = start; i < size2; ++i) {
      if (size2 % i === 0) {
        return i;
      }
    }
    return size2;
  }
  function computeStrides(shape) {
    const rank = shape.length;
    if (rank < 2) {
      return [];
    }
    const strides = new Array(rank - 1);
    strides[rank - 2] = shape[rank - 1];
    for (let i = rank - 3; i >= 0; --i) {
      strides[i] = strides[i + 1] * shape[i + 1];
    }
    return strides;
  }
  function createNestedArray(offset, shape, a, isComplex = false) {
    const ret = new Array();
    if (shape.length === 1) {
      const d = shape[0] * (isComplex ? 2 : 1);
      for (let i = 0; i < d; i++) {
        ret[i] = a[offset + i];
      }
    } else {
      const d = shape[0];
      const rest = shape.slice(1);
      const len = rest.reduce((acc, c) => acc * c) * (isComplex ? 2 : 1);
      for (let i = 0; i < d; i++) {
        ret[i] = createNestedArray(offset + i * len, rest, a, isComplex);
      }
    }
    return ret;
  }
  function toNestedArray(shape, a, isComplex = false) {
    if (shape.length === 0) {
      return a[0];
    }
    const size2 = shape.reduce((acc, c) => acc * c) * (isComplex ? 2 : 1);
    if (size2 === 0) {
      return [];
    }
    if (size2 !== a.length) {
      throw new Error(`[${shape}] does not match the input size ${a.length}${isComplex ? " for a complex tensor" : ""}.`);
    }
    return createNestedArray(0, shape, a, isComplex);
  }
  function makeOnesTypedArray(size2, dtype) {
    const array2 = makeZerosTypedArray(size2, dtype);
    for (let i = 0; i < array2.length; i++) {
      array2[i] = 1;
    }
    return array2;
  }
  function makeZerosTypedArray(size2, dtype) {
    if (dtype == null || dtype === "float32" || dtype === "complex64") {
      return new Float32Array(size2);
    } else if (dtype === "int32") {
      return new Int32Array(size2);
    } else if (dtype === "bool") {
      return new Uint8Array(size2);
    } else {
      throw new Error(`Unknown data type ${dtype}`);
    }
  }
  function makeZerosNestedTypedArray(shape, dtype) {
    const size2 = shape.reduce((prev, curr) => prev * curr, 1);
    if (dtype == null || dtype === "float32") {
      return toNestedArray(shape, new Float32Array(size2));
    } else if (dtype === "int32") {
      return toNestedArray(shape, new Int32Array(size2));
    } else if (dtype === "bool") {
      return toNestedArray(shape, new Uint8Array(size2));
    } else {
      throw new Error(`Unknown data type ${dtype}`);
    }
  }
  function assertNonNegativeIntegerDimensions(shape) {
    shape.forEach((dimSize) => {
      assert(Number.isInteger(dimSize) && dimSize >= 0, () => `Tensor must have a shape comprised of positive integers but got shape [${shape}].`);
    });
  }
  function locToIndex(locs, rank, strides) {
    if (rank === 0) {
      return 0;
    } else if (rank === 1) {
      return locs[0];
    }
    let index = locs[locs.length - 1];
    for (let i = 0; i < locs.length - 1; ++i) {
      index += strides[i] * locs[i];
    }
    return index;
  }
  function indexToLoc(index, rank, strides) {
    if (rank === 0) {
      return [];
    } else if (rank === 1) {
      return [index];
    }
    const locs = new Array(rank);
    for (let i = 0; i < locs.length - 1; ++i) {
      locs[i] = Math.floor(index / strides[i]);
      index -= locs[i] * strides[i];
    }
    locs[locs.length - 1] = index;
    return locs;
  }
  function isPromise2(object) {
    return object && object.then && typeof object.then === "function";
  }

  // node_modules/@tensorflow/tfjs-core/dist/log.js
  function warn3(...msg) {
    if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
      console.warn(...msg);
    }
  }
  function log(...msg) {
    if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
      console.log(...msg);
    }
  }

  // node_modules/@tensorflow/tfjs-core/dist/environment.js
  var TENSORFLOWJS_FLAGS_PREFIX = "tfjsflags";
  var Environment = class {
    constructor(global2) {
      this.global = global2;
      this.flags = {};
      this.flagRegistry = {};
      this.urlFlags = {};
      this.getQueryParams = getQueryParams;
      this.populateURLFlags();
    }
    setPlatform(platformName, platform) {
      if (this.platform != null) {
        warn3(`Platform ${this.platformName} has already been set. Overwriting the platform with ${platform}.`);
      }
      this.platformName = platformName;
      this.platform = platform;
    }
    registerFlag(flagName, evaluationFn, setHook) {
      this.flagRegistry[flagName] = { evaluationFn, setHook };
      if (this.urlFlags[flagName] != null) {
        const flagValue = this.urlFlags[flagName];
        warn3(`Setting feature override from URL ${flagName}: ${flagValue}.`);
        this.set(flagName, flagValue);
      }
    }
    async getAsync(flagName) {
      if (flagName in this.flags) {
        return this.flags[flagName];
      }
      this.flags[flagName] = await this.evaluateFlag(flagName);
      return this.flags[flagName];
    }
    get(flagName) {
      if (flagName in this.flags) {
        return this.flags[flagName];
      }
      const flagValue = this.evaluateFlag(flagName);
      if (isPromise2(flagValue)) {
        throw new Error(`Flag ${flagName} cannot be synchronously evaluated. Please use getAsync() instead.`);
      }
      this.flags[flagName] = flagValue;
      return this.flags[flagName];
    }
    getNumber(flagName) {
      return this.get(flagName);
    }
    getBool(flagName) {
      return this.get(flagName);
    }
    getFlags() {
      return this.flags;
    }
    get features() {
      return this.flags;
    }
    set(flagName, value) {
      if (this.flagRegistry[flagName] == null) {
        throw new Error(`Cannot set flag ${flagName} as it has not been registered.`);
      }
      this.flags[flagName] = value;
      if (this.flagRegistry[flagName].setHook != null) {
        this.flagRegistry[flagName].setHook(value);
      }
    }
    evaluateFlag(flagName) {
      if (this.flagRegistry[flagName] == null) {
        throw new Error(`Cannot evaluate flag '${flagName}': no evaluation function found.`);
      }
      return this.flagRegistry[flagName].evaluationFn();
    }
    setFlags(flags) {
      this.flags = Object.assign({}, flags);
    }
    reset() {
      this.flags = {};
      this.urlFlags = {};
      this.populateURLFlags();
    }
    populateURLFlags() {
      if (typeof this.global === "undefined" || typeof this.global.location === "undefined" || typeof this.global.location.search === "undefined") {
        return;
      }
      const urlParams = this.getQueryParams(this.global.location.search);
      if (TENSORFLOWJS_FLAGS_PREFIX in urlParams) {
        const keyValues = urlParams[TENSORFLOWJS_FLAGS_PREFIX].split(",");
        keyValues.forEach((keyValue) => {
          const [key, value] = keyValue.split(":");
          this.urlFlags[key] = parseValue(key, value);
        });
      }
    }
  };
  function getQueryParams(queryString) {
    const params = {};
    queryString.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, (s, ...t) => {
      decodeParam(params, t[0], t[1]);
      return t.join("=");
    });
    return params;
  }
  function decodeParam(params, name, value) {
    params[decodeURIComponent(name)] = decodeURIComponent(value || "");
  }
  function parseValue(flagName, value) {
    value = value.toLowerCase();
    if (value === "true" || value === "false") {
      return value === "true";
    } else if (`${+value}` === value) {
      return +value;
    }
    throw new Error(`Could not parse value flag value ${value} for flag ${flagName}.`);
  }
  function env() {
    return ENV;
  }
  var ENV = null;
  function setEnvironmentGlobal(environment) {
    ENV = environment;
  }

  // node_modules/@tensorflow/tfjs-core/dist/global_util.js
  var globalNameSpace;
  function getGlobalNamespace() {
    if (globalNameSpace == null) {
      let ns;
      if (typeof window !== "undefined") {
        ns = window;
      } else if (typeof global !== "undefined") {
        ns = global;
      } else if (typeof process !== "undefined") {
        ns = process;
      } else if (typeof self !== "undefined") {
        ns = self;
      } else {
        throw new Error("Could not find a global object");
      }
      globalNameSpace = ns;
    }
    return globalNameSpace;
  }
  function getGlobalMap() {
    const ns = getGlobalNamespace();
    if (ns._tfGlobals == null) {
      ns._tfGlobals = new Map();
    }
    return ns._tfGlobals;
  }
  function getGlobal(key, init) {
    const globalMap = getGlobalMap();
    if (globalMap.has(key)) {
      return globalMap.get(key);
    } else {
      const singleton = init();
      globalMap.set(key, singleton);
      return globalMap.get(key);
    }
  }

  // node_modules/@tensorflow/tfjs-core/dist/kernel_names.js
  var Abs = "Abs";
  var Acos = "Acos";
  var Acosh = "Acosh";
  var Add = "Add";
  var AddN = "AddN";
  var All = "All";
  var Any = "Any";
  var ArgMax = "ArgMax";
  var ArgMin = "ArgMin";
  var Asin = "Asin";
  var Asinh = "Asinh";
  var Atan = "Atan";
  var Atanh = "Atanh";
  var Atan2 = "Atan2";
  var AvgPool = "AvgPool";
  var AvgPoolGrad = "AvgPoolGrad";
  var AvgPool3D = "AvgPool3D";
  var AvgPool3DGrad = "AvgPool3DGrad";
  var BatchMatMul = "BatchMatMul";
  var BatchToSpaceND = "BatchToSpaceND";
  var Bincount = "Bincount";
  var BroadcastTo = "BroadcastTo";
  var BroadcastArgs = "BroadcastArgs";
  var Cast = "Cast";
  var Ceil = "Ceil";
  var ClipByValue = "ClipByValue";
  var Complex = "Complex";
  var ComplexAbs = "ComplexAbs";
  var Concat = "Concat";
  var Conv2D = "Conv2D";
  var Conv2DBackpropFilter = "Conv2DBackpropFilter";
  var Conv2DBackpropInput = "Conv2DBackpropInput";
  var Conv3D = "Conv3D";
  var Conv3DBackpropFilterV2 = "Conv3DBackpropFilterV2";
  var Conv3DBackpropInputV2 = "Conv3DBackpropInputV2";
  var Cos = "Cos";
  var Cosh = "Cosh";
  var Cumsum = "Cumsum";
  var CropAndResize = "CropAndResize";
  var DenseBincount = "DenseBincount";
  var DepthToSpace = "DepthToSpace";
  var DepthwiseConv2dNative = "DepthwiseConv2dNative";
  var DepthwiseConv2dNativeBackpropFilter = "DepthwiseConv2dNativeBackpropFilter";
  var DepthwiseConv2dNativeBackpropInput = "DepthwiseConv2dNativeBackpropInput";
  var Diag = "Diag";
  var Dilation2D = "Dilation2D";
  var Dilation2DBackpropInput = "Dilation2DBackpropInput";
  var Dilation2DBackpropFilter = "Dilation2DBackpropFilter";
  var RealDiv = "RealDiv";
  var Einsum = "Einsum";
  var Elu = "Elu";
  var EluGrad = "EluGrad";
  var Erf = "Erf";
  var Equal = "Equal";
  var Exp = "Exp";
  var ExpandDims = "ExpandDims";
  var Expm1 = "Expm1";
  var FFT = "FFT";
  var Fill = "Fill";
  var FlipLeftRight = "FlipLeftRight";
  var Floor = "Floor";
  var FloorDiv = "FloorDiv";
  var FusedBatchNorm = "FusedBatchNorm";
  var GatherV2 = "GatherV2";
  var GatherNd = "GatherNd";
  var Greater = "Greater";
  var GreaterEqual = "GreaterEqual";
  var Identity = "Identity";
  var IFFT = "IFFT";
  var Imag = "Imag";
  var IsFinite = "IsFinite";
  var IsInf = "IsInf";
  var IsNan = "IsNan";
  var LeakyRelu = "LeakyRelu";
  var Less = "Less";
  var LessEqual = "LessEqual";
  var LinSpace = "LinSpace";
  var Log = "Log";
  var Log1p = "Log1p";
  var LogicalAnd = "LogicalAnd";
  var LogicalNot = "LogicalNot";
  var LogicalOr = "LogicalOr";
  var LogSoftmax = "LogSoftmax";
  var LRN = "LRN";
  var LRNGrad = "LRNGrad";
  var Max = "Max";
  var Maximum = "Maximum";
  var MaxPool = "MaxPool";
  var MaxPoolGrad = "MaxPoolGrad";
  var MaxPool3D = "MaxPool3D";
  var MaxPool3DGrad = "MaxPool3DGrad";
  var MaxPoolWithArgmax = "MaxPoolWithArgmax";
  var Mean = "Mean";
  var Min = "Min";
  var Minimum = "Minimum";
  var MirrorPad = "MirrorPad";
  var Mod = "Mod";
  var Multinomial = "Multinomial";
  var Multiply = "Multiply";
  var Neg = "Neg";
  var NotEqual = "NotEqual";
  var NonMaxSuppressionV3 = "NonMaxSuppressionV3";
  var NonMaxSuppressionV4 = "NonMaxSuppressionV4";
  var NonMaxSuppressionV5 = "NonMaxSuppressionV5";
  var OnesLike = "OnesLike";
  var OneHot = "OneHot";
  var Pack = "Pack";
  var PadV2 = "PadV2";
  var Pow = "Pow";
  var Prelu = "Prelu";
  var Prod = "Prod";
  var Range = "Range";
  var Real = "Real";
  var Reciprocal = "Reciprocal";
  var Relu = "Relu";
  var Reshape = "Reshape";
  var ResizeNearestNeighbor = "ResizeNearestNeighbor";
  var ResizeNearestNeighborGrad = "ResizeNearestNeighborGrad";
  var ResizeBilinear = "ResizeBilinear";
  var ResizeBilinearGrad = "ResizeBilinearGrad";
  var Relu6 = "Relu6";
  var Reverse = "Reverse";
  var Round = "Round";
  var Rsqrt = "Rsqrt";
  var ScatterNd = "ScatterNd";
  var Select = "Select";
  var Selu = "Selu";
  var Slice = "Slice";
  var Sin = "Sin";
  var Sinh = "Sinh";
  var Sign = "Sign";
  var Sigmoid = "Sigmoid";
  var Softplus = "Softplus";
  var Sqrt = "Sqrt";
  var Sum = "Sum";
  var SpaceToBatchND = "SpaceToBatchND";
  var SplitV = "SplitV";
  var Softmax = "Softmax";
  var SparseFillEmptyRows = "SparseFillEmptyRows";
  var SparseReshape = "SparseReshape";
  var SparseSegmentMean = "SparseSegmentMean";
  var SparseSegmentSum = "SparseSegmentSum";
  var SparseToDense = "SparseToDense";
  var SquaredDifference = "SquaredDifference";
  var Square = "Square";
  var StridedSlice = "StridedSlice";
  var StringNGrams = "StringNGrams";
  var StringSplit = "StringSplit";
  var StringToHashBucketFast = "StringToHashBucketFast";
  var Sub = "Sub";
  var Tan = "Tan";
  var Tanh = "Tanh";
  var Tile = "Tile";
  var TopK = "TopK";
  var Transform = "Transform";
  var Transpose = "Transpose";
  var Unique = "Unique";
  var Unpack = "Unpack";
  var UnsortedSegmentSum = "UnsortedSegmentSum";
  var ZerosLike = "ZerosLike";
  var Step = "Step";
  var FromPixels = "FromPixels";
  var RotateWithOffset = "RotateWithOffset";
  var _FusedMatMul = "_FusedMatMul";
  var FusedConv2D = "FusedConv2D";
  var FusedDepthwiseConv2D = "FusedDepthwiseConv2D";

  // node_modules/@tensorflow/tfjs-core/dist/kernel_registry.js
  var kernelRegistry = getGlobal("kernelRegistry", () => new Map());
  var gradRegistry = getGlobal("gradRegistry", () => new Map());
  function getKernel(kernelName, backendName) {
    const key = makeKey(kernelName, backendName);
    return kernelRegistry.get(key);
  }
  function getGradient(kernelName) {
    return gradRegistry.get(kernelName);
  }
  function getKernelsForBackend(backendName) {
    const it = kernelRegistry.entries();
    const result = [];
    while (true) {
      const { done, value } = it.next();
      if (done) {
        break;
      }
      const [key, config] = value;
      const [backend2] = key.split("_");
      if (backend2 === backendName) {
        result.push(config);
      }
    }
    return result;
  }
  function registerKernel(config) {
    const { kernelName, backendName } = config;
    const key = makeKey(kernelName, backendName);
    if (kernelRegistry.has(key)) {
      warn3(`The kernel '${kernelName}' for backend '${backendName}' is already registered`);
    }
    kernelRegistry.set(key, config);
  }
  function registerGradient(config) {
    const { kernelName } = config;
    if (gradRegistry.has(kernelName)) {
      if (env().getBool("DEBUG")) {
        warn3(`Overriding the gradient for '${kernelName}'`);
      }
    }
    gradRegistry.set(kernelName, config);
  }
  function makeKey(kernelName, backendName) {
    return `${backendName}_${kernelName}`;
  }

  // node_modules/@tensorflow/tfjs-core/dist/util.js
  var util_exports = {};
  __export(util_exports, {
    arraysEqual: () => arraysEqual,
    assert: () => assert,
    assertNonNegativeIntegerDimensions: () => assertNonNegativeIntegerDimensions,
    assertNonNull: () => assertNonNull,
    assertShapesMatch: () => assertShapesMatch,
    bytesFromStringArray: () => bytesFromStringArray,
    bytesPerElement: () => bytesPerElement,
    checkConversionForErrors: () => checkConversionForErrors,
    clamp: () => clamp,
    computeStrides: () => computeStrides,
    createScalarValue: () => createScalarValue,
    createShuffledIndices: () => createShuffledIndices,
    decodeString: () => decodeString,
    distSquared: () => distSquared,
    encodeString: () => encodeString,
    fetch: () => fetch3,
    fingerPrint64: () => fingerPrint64,
    flatten: () => flatten,
    getArrayFromDType: () => getArrayFromDType,
    getTypedArrayFromDType: () => getTypedArrayFromDType,
    hasEncodingLoss: () => hasEncodingLoss,
    hexToLong: () => hexToLong,
    indexToLoc: () => indexToLoc,
    inferDtype: () => inferDtype,
    inferFromImplicitShape: () => inferFromImplicitShape,
    isBoolean: () => isBoolean2,
    isFunction: () => isFunction2,
    isInt: () => isInt,
    isNumber: () => isNumber,
    isPromise: () => isPromise2,
    isScalarShape: () => isScalarShape,
    isString: () => isString2,
    isTypedArray: () => isTypedArray,
    isValidDtype: () => isValidDtype,
    locToIndex: () => locToIndex,
    makeOnesTypedArray: () => makeOnesTypedArray,
    makeZerosNestedTypedArray: () => makeZerosNestedTypedArray,
    makeZerosTypedArray: () => makeZerosTypedArray,
    nearestDivisor: () => nearestDivisor,
    nearestLargerEven: () => nearestLargerEven,
    now: () => now,
    parseAxisParam: () => parseAxisParam,
    randUniform: () => randUniform,
    repeatedTry: () => repeatedTry,
    rightPad: () => rightPad,
    shuffle: () => shuffle,
    shuffleCombo: () => shuffleCombo,
    sizeFromShape: () => sizeFromShape,
    sizeToSquarishShape: () => sizeToSquarishShape,
    squeezeShape: () => squeezeShape,
    sum: () => sum,
    swap: () => swap,
    tanh: () => tanh,
    toNestedArray: () => toNestedArray,
    toTypedArray: () => toTypedArray
  });

  // node_modules/@tensorflow/tfjs-core/dist/hash_util.js
  var LongExports = __toModule(require_long());
  var Long = LongExports.default || LongExports;
  function hexToLong(hex) {
    return Long.fromString(hex, true, 16);
  }
  var k0 = hexToLong("c3a5c85c97cb3127");
  var k1 = hexToLong("b492b66fbe98f273");
  var k2 = hexToLong("9ae16a3b2f90404f");
  function shiftMix(val) {
    return val.xor(val.shru(47));
  }
  function fetch2(s, offset, numBytes) {
    const bytes = s.slice(offset, offset + numBytes);
    return Long.fromBytes(Array.from(bytes), true, true);
  }
  function fetch64(s, offset) {
    return fetch2(s, offset, 8);
  }
  function fetch32(s, offset) {
    return fetch2(s, offset, 4);
  }
  function rotate64(val, shift) {
    return shift === 0 ? val : val.shru(shift).or(val.shl(64 - shift));
  }
  function hashLen16(u, v, mul2 = hexToLong("9ddfea08eb382d69")) {
    let a = u.xor(v).mul(mul2);
    a = a.xor(a.shru(47));
    let b = v.xor(a).mul(mul2);
    b = b.xor(b.shru(47));
    b = b.mul(mul2);
    return b;
  }
  function weakHashLen32WithSeeds(w, x, y, z, a, b) {
    a = a.add(w);
    b = rotate64(b.add(a).add(z), 21);
    const c = a;
    a = a.add(x);
    a = a.add(y);
    b = b.add(rotate64(a, 44));
    return [a.add(z), b.add(c)];
  }
  function weakHashLen32WithSeedsStr(s, offset, a, b) {
    return weakHashLen32WithSeeds(fetch64(s, offset), fetch64(s, offset + 8), fetch64(s, offset + 16), fetch64(s, offset + 24), a, b);
  }
  function hashLen0to16(s, len = s.length) {
    if (len >= 8) {
      const mul2 = k2.add(len * 2);
      const a = fetch64(s, 0).add(k2);
      const b = fetch64(s, len - 8);
      const c = rotate64(b, 37).mul(mul2).add(a);
      const d = rotate64(a, 25).add(b).mul(mul2);
      return hashLen16(c, d, mul2);
    }
    if (len >= 4) {
      const mul2 = k2.add(len * 2);
      const a = fetch32(s, 0);
      return hashLen16(a.shl(3).add(len), fetch32(s, len - 4), mul2);
    }
    if (len > 0) {
      const a = s[0];
      const b = s[len >> 1];
      const c = s[len - 1];
      const y = a + (b << 8);
      const z = len + (c << 2);
      return shiftMix(k2.mul(y).xor(k0.mul(z))).mul(k2);
    }
    return k2;
  }
  function hashLen17to32(s, len = s.length) {
    const mul2 = k2.add(len * 2);
    const a = fetch64(s, 0).mul(k1);
    const b = fetch64(s, 8);
    const c = fetch64(s, len - 8).mul(mul2);
    const d = fetch64(s, len - 16).mul(k2);
    return hashLen16(rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d), a.add(rotate64(b.add(k2), 18)).add(c), mul2);
  }
  function hashLen33to64(s, len = s.length) {
    const mul2 = k2.add(len * 2);
    const a = fetch64(s, 0).mul(k2);
    const b = fetch64(s, 8);
    const c = fetch64(s, len - 8).mul(mul2);
    const d = fetch64(s, len - 16).mul(k2);
    const y = rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d);
    const z = hashLen16(y, a.add(rotate64(b.add(k2), 18)).add(c), mul2);
    const e = fetch64(s, 16).mul(mul2);
    const f = fetch64(s, 24);
    const g = y.add(fetch64(s, len - 32)).mul(mul2);
    const h2 = z.add(fetch64(s, len - 24)).mul(mul2);
    return hashLen16(rotate64(e.add(f), 43).add(rotate64(g, 30)).add(h2), e.add(rotate64(f.add(a), 18)).add(g), mul2);
  }
  function fingerPrint64(s, len = s.length) {
    const seed = Long.fromNumber(81, true);
    if (len <= 32) {
      if (len <= 16) {
        return hashLen0to16(s, len);
      } else {
        return hashLen17to32(s, len);
      }
    } else if (len <= 64) {
      return hashLen33to64(s, len);
    }
    let x = seed;
    let y = seed.mul(k1).add(113);
    let z = shiftMix(y.mul(k2).add(113)).mul(k2);
    let v = [Long.UZERO, Long.UZERO];
    let w = [Long.UZERO, Long.UZERO];
    x = x.mul(k2).add(fetch64(s, 0));
    let offset = 0;
    const end = (len - 1 >> 6) * 64;
    const last64 = end + (len - 1 & 63) - 63;
    do {
      x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(k1);
      y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(k1);
      x = x.xor(w[1]);
      y = y.add(v[0]).add(fetch64(s, offset + 40));
      z = rotate64(z.add(w[0]), 33).mul(k1);
      v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(k1), x.add(w[0]));
      w = weakHashLen32WithSeedsStr(s, offset + 32, z.add(w[1]), y.add(fetch64(s, offset + 16)));
      [z, x] = [x, z];
      offset += 64;
    } while (offset !== end);
    const mul2 = k1.add(z.and(255).shl(1));
    offset = last64;
    w[0] = w[0].add(len - 1 & 63);
    v[0] = v[0].add(w[0]);
    w[0] = w[0].add(v[0]);
    x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(mul2);
    y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(mul2);
    x = x.xor(w[1].mul(9));
    y = y.add(v[0].mul(9).add(fetch64(s, offset + 40)));
    z = rotate64(z.add(w[0]), 33).mul(mul2);
    v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(mul2), x.add(w[0]));
    w = weakHashLen32WithSeedsStr(s, offset + 32, z.add(w[1]), y.add(fetch64(s, offset + 16)));
    [z, x] = [x, z];
    return hashLen16(hashLen16(v[0], w[0], mul2).add(shiftMix(y).mul(k0)).add(z), hashLen16(v[1], w[1], mul2).add(x), mul2);
  }

  // node_modules/@tensorflow/tfjs-core/dist/util.js
  function createScalarValue(value, dtype) {
    if (dtype === "string") {
      return encodeString(value);
    }
    return toTypedArray([value], dtype);
  }
  function noConversionNeeded(a, dtype) {
    return a instanceof Float32Array && dtype === "float32" || a instanceof Int32Array && dtype === "int32" || a instanceof Uint8Array && dtype === "bool";
  }
  function toTypedArray(a, dtype) {
    if (dtype === "string") {
      throw new Error("Cannot convert a string[] to a TypedArray");
    }
    if (Array.isArray(a)) {
      a = flatten(a);
    }
    if (env().getBool("DEBUG")) {
      checkConversionForErrors(a, dtype);
    }
    if (noConversionNeeded(a, dtype)) {
      return a;
    }
    if (dtype == null || dtype === "float32" || dtype === "complex64") {
      return new Float32Array(a);
    } else if (dtype === "int32") {
      return new Int32Array(a);
    } else if (dtype === "bool") {
      const bool = new Uint8Array(a.length);
      for (let i = 0; i < bool.length; ++i) {
        if (Math.round(a[i]) !== 0) {
          bool[i] = 1;
        }
      }
      return bool;
    } else {
      throw new Error(`Unknown data type ${dtype}`);
    }
  }
  function now() {
    return env().platform.now();
  }
  function fetch3(path, requestInits) {
    return env().platform.fetch(path, requestInits);
  }
  function encodeString(s, encoding = "utf-8") {
    encoding = encoding || "utf-8";
    return env().platform.encode(s, encoding);
  }
  function decodeString(bytes, encoding = "utf-8") {
    encoding = encoding || "utf-8";
    return env().platform.decode(bytes, encoding);
  }

  // node_modules/@tensorflow/tfjs-core/dist/profiler.js
  var Profiler = class {
    constructor(backendTimer, logger) {
      this.backendTimer = backendTimer;
      this.logger = logger;
      if (logger == null) {
        this.logger = new Logger();
      }
    }
    profileKernel(kernelName, inputs, f) {
      let outputs;
      const holdResultWrapperFn = () => {
        outputs = f();
      };
      let timer;
      const start = now();
      if (this.backendTimer.timerAvailable()) {
        timer = this.backendTimer.time(holdResultWrapperFn);
      } else {
        holdResultWrapperFn();
        for (const output of outputs) {
          output.dataSync();
        }
        timer = Promise.resolve({ kernelMs: now() - start });
      }
      if (env().getBool("CHECK_COMPUTATION_FOR_ERRORS")) {
        for (let i = 0; i < outputs.length; i++) {
          const output = outputs[i];
          output.data().then((tensorVals) => {
            checkComputationForErrors(tensorVals, output.dtype, kernelName);
          });
        }
      }
      const kernelProfile = {
        kernelName,
        outputs,
        inputs,
        timeMs: timer.then((timing) => timing.kernelMs),
        extraInfo: timer.then((timing) => timing.getExtraProfileInfo != null ? timing.getExtraProfileInfo() : "")
      };
      return kernelProfile;
    }
    logKernelProfile(kernelProfile) {
      const { kernelName, outputs, timeMs, inputs, extraInfo } = kernelProfile;
      outputs.forEach((result) => {
        Promise.all([result.data(), timeMs, extraInfo]).then((valueContainer) => {
          this.logger.logKernelProfile(kernelName, result, valueContainer[0], valueContainer[1], inputs, valueContainer[2]);
        });
      });
    }
  };
  function checkComputationForErrors(vals, dtype, kernelName) {
    if (dtype !== "float32") {
      return false;
    }
    for (let i = 0; i < vals.length; i++) {
      const num = vals[i];
      if (isNaN(num) || !isFinite(num)) {
        console.warn(`Found ${num} in the result of '${kernelName}'`);
        return true;
      }
    }
    return false;
  }
  var Logger = class {
    logKernelProfile(name, result, vals, timeMs, inputs, extraInfo) {
      const time = typeof timeMs === "number" ? rightPad(`${timeMs}ms`, 9) : timeMs["error"];
      const paddedName = rightPad(name, 25);
      const rank = result.rank;
      const size2 = result.size;
      const shape = rightPad(result.shape.toString(), 14);
      let inputShapesDescription = "";
      for (const name2 in inputs) {
        const input2 = inputs[name2];
        if (input2 != null) {
          const inputShape = input2.shape || result.shape;
          const inputRank = inputShape.length;
          inputShapesDescription += `${name2}: ${inputRank}D ${inputRank > 0 ? inputShape : ""} `;
        }
      }
      console.log(`%c${paddedName}	%c${time}	%c${rank}D ${shape}	%c${size2}	%c${inputShapesDescription}	%c${extraInfo}`, "font-weight:bold", "color:red", "color:blue", "color: orange", "color: green", "color: steelblue");
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/tape.js
  function getFilteredNodesXToY(tape, xs, y) {
    const tensorsFromX = {};
    const nodesFromX = {};
    for (let i = 0; i < xs.length; i++) {
      tensorsFromX[xs[i].id] = true;
    }
    for (let i = 0; i < tape.length; i++) {
      const node = tape[i];
      const nodeInputs = node.inputs;
      for (const inputName in nodeInputs) {
        const input2 = nodeInputs[inputName];
        let anyInputFromX = false;
        for (let j = 0; j < xs.length; j++) {
          if (tensorsFromX[input2.id]) {
            node.outputs.forEach((output) => tensorsFromX[output.id] = true);
            anyInputFromX = true;
            nodesFromX[node.id] = true;
            break;
          }
        }
        if (anyInputFromX) {
          break;
        }
      }
    }
    const tensorsLeadToY = {};
    tensorsLeadToY[y.id] = true;
    const nodesToY = {};
    for (let i = tape.length - 1; i >= 0; i--) {
      const node = tape[i];
      const nodeInputs = node.inputs;
      for (let j = 0; j < node.outputs.length; j++) {
        if (tensorsLeadToY[node.outputs[j].id]) {
          for (const inputName in nodeInputs) {
            tensorsLeadToY[nodeInputs[inputName].id] = true;
            nodesToY[node.id] = true;
          }
          break;
        }
      }
    }
    const filteredTape = [];
    for (let i = 0; i < tape.length; i++) {
      const node = tape[i];
      if (nodesFromX[node.id] && nodesToY[node.id]) {
        const prunedInputs = {};
        for (const inputName in node.inputs) {
          const nodeInput = node.inputs[inputName];
          if (tensorsFromX[nodeInput.id]) {
            prunedInputs[inputName] = nodeInput;
          }
        }
        const prunedNode = Object.assign({}, node);
        prunedNode.inputs = prunedInputs;
        prunedNode.outputs = node.outputs;
        filteredTape.push(prunedNode);
      }
    }
    return filteredTape;
  }
  function backpropagateGradients(tensorAccumulatedGradientMap, filteredTape, tidy2, add5) {
    for (let i = filteredTape.length - 1; i >= 0; i--) {
      const node = filteredTape[i];
      const dys = [];
      node.outputs.forEach((o) => {
        const gradTensor = tensorAccumulatedGradientMap[o.id];
        if (gradTensor != null) {
          dys.push(gradTensor);
        } else {
          dys.push(null);
        }
      });
      if (node.gradient == null) {
        throw new Error(`Cannot compute gradient: gradient function not found for ${node.kernelName}.`);
      }
      const inputGradients = node.gradient(dys);
      for (const inputName in node.inputs) {
        if (!(inputName in inputGradients)) {
          throw new Error(`Cannot backprop through input ${inputName}. Available gradients found: ${Object.keys(inputGradients)}.`);
        }
        const dx = tidy2(() => inputGradients[inputName]());
        if (dx.dtype !== "float32") {
          throw new Error(`Error in gradient for op ${node.kernelName}. The gradient of input ${inputName} must have 'float32' dtype, but has '${dx.dtype}'`);
        }
        const x = node.inputs[inputName];
        if (!arraysEqual(dx.shape, x.shape)) {
          throw new Error(`Error in gradient for op ${node.kernelName}. The gradient of input '${inputName}' has shape '${dx.shape}', which does not match the shape of the input '${x.shape}'`);
        }
        if (tensorAccumulatedGradientMap[x.id] == null) {
          tensorAccumulatedGradientMap[x.id] = dx;
        } else {
          const curGradient = tensorAccumulatedGradientMap[x.id];
          tensorAccumulatedGradientMap[x.id] = add5(curGradient, dx);
          curGradient.dispose();
        }
      }
    }
  }

  // node_modules/@tensorflow/tfjs-core/dist/tensor_format.js
  var FORMAT_LIMIT_NUM_VALS = 20;
  var FORMAT_NUM_FIRST_LAST_VALS = 3;
  var FORMAT_NUM_SIG_DIGITS = 7;
  function tensorToString(vals, shape, dtype, verbose) {
    const strides = computeStrides(shape);
    const padPerCol = computeMaxSizePerColumn(vals, shape, dtype, strides);
    const rank = shape.length;
    const valsLines = subTensorToString(vals, shape, dtype, strides, padPerCol);
    const lines = ["Tensor"];
    if (verbose) {
      lines.push(`  dtype: ${dtype}`);
      lines.push(`  rank: ${rank}`);
      lines.push(`  shape: [${shape}]`);
      lines.push(`  values:`);
    }
    lines.push(valsLines.map((l) => "    " + l).join("\n"));
    return lines.join("\n");
  }
  function computeMaxSizePerColumn(vals, shape, dtype, strides) {
    const n = sizeFromShape(shape);
    const numCols = strides[strides.length - 1];
    const padPerCol = new Array(numCols).fill(0);
    const rank = shape.length;
    const valuesOrTuples = dtype === "complex64" ? createComplexTuples(vals) : vals;
    if (rank > 1) {
      for (let row = 0; row < n / numCols; row++) {
        const offset = row * numCols;
        for (let j = 0; j < numCols; j++) {
          padPerCol[j] = Math.max(padPerCol[j], valToString(valuesOrTuples[offset + j], 0, dtype).length);
        }
      }
    }
    return padPerCol;
  }
  function valToString(val, pad2, dtype) {
    let valStr;
    if (Array.isArray(val)) {
      valStr = `${parseFloat(val[0].toFixed(FORMAT_NUM_SIG_DIGITS))} + ${parseFloat(val[1].toFixed(FORMAT_NUM_SIG_DIGITS))}j`;
    } else if (isString2(val)) {
      valStr = `'${val}'`;
    } else if (dtype === "bool") {
      valStr = boolNumToString(val);
    } else {
      valStr = parseFloat(val.toFixed(FORMAT_NUM_SIG_DIGITS)).toString();
    }
    return rightPad(valStr, pad2);
  }
  function boolNumToString(v) {
    return v === 0 ? "false" : "true";
  }
  function subTensorToString(vals, shape, dtype, strides, padPerCol, isLast = true) {
    const storagePerElement = dtype === "complex64" ? 2 : 1;
    const size2 = shape[0];
    const rank = shape.length;
    if (rank === 0) {
      if (dtype === "complex64") {
        const complexTuple = createComplexTuples(vals);
        return [valToString(complexTuple[0], 0, dtype)];
      }
      if (dtype === "bool") {
        return [boolNumToString(vals[0])];
      }
      return [vals[0].toString()];
    }
    if (rank === 1) {
      if (size2 > FORMAT_LIMIT_NUM_VALS) {
        const firstValsSize = FORMAT_NUM_FIRST_LAST_VALS * storagePerElement;
        let firstVals = Array.from(vals.slice(0, firstValsSize));
        let lastVals = Array.from(vals.slice((size2 - FORMAT_NUM_FIRST_LAST_VALS) * storagePerElement, size2 * storagePerElement));
        if (dtype === "complex64") {
          firstVals = createComplexTuples(firstVals);
          lastVals = createComplexTuples(lastVals);
        }
        return [
          "[" + firstVals.map((x, i) => valToString(x, padPerCol[i], dtype)).join(", ") + ", ..., " + lastVals.map((x, i) => valToString(x, padPerCol[size2 - FORMAT_NUM_FIRST_LAST_VALS + i], dtype)).join(", ") + "]"
        ];
      }
      const displayVals = dtype === "complex64" ? createComplexTuples(vals) : Array.from(vals);
      return [
        "[" + displayVals.map((x, i) => valToString(x, padPerCol[i], dtype)).join(", ") + "]"
      ];
    }
    const subshape = shape.slice(1);
    const substrides = strides.slice(1);
    const stride = strides[0] * storagePerElement;
    const lines = [];
    if (size2 > FORMAT_LIMIT_NUM_VALS) {
      for (let i = 0; i < FORMAT_NUM_FIRST_LAST_VALS; i++) {
        const start = i * stride;
        const end = start + stride;
        lines.push(...subTensorToString(vals.slice(start, end), subshape, dtype, substrides, padPerCol, false));
      }
      lines.push("...");
      for (let i = size2 - FORMAT_NUM_FIRST_LAST_VALS; i < size2; i++) {
        const start = i * stride;
        const end = start + stride;
        lines.push(...subTensorToString(vals.slice(start, end), subshape, dtype, substrides, padPerCol, i === size2 - 1));
      }
    } else {
      for (let i = 0; i < size2; i++) {
        const start = i * stride;
        const end = start + stride;
        lines.push(...subTensorToString(vals.slice(start, end), subshape, dtype, substrides, padPerCol, i === size2 - 1));
      }
    }
    const sep = rank === 2 ? "," : "";
    lines[0] = "[" + lines[0] + sep;
    for (let i = 1; i < lines.length - 1; i++) {
      lines[i] = " " + lines[i] + sep;
    }
    let newLineSep = ",\n";
    for (let i = 2; i < rank; i++) {
      newLineSep += "\n";
    }
    lines[lines.length - 1] = " " + lines[lines.length - 1] + "]" + (isLast ? "" : newLineSep);
    return lines;
  }
  function createComplexTuples(vals) {
    const complexTuples = [];
    for (let i = 0; i < vals.length; i += 2) {
      complexTuples.push([vals[i], vals[i + 1]]);
    }
    return complexTuples;
  }

  // node_modules/@tensorflow/tfjs-core/dist/tensor.js
  var TensorBuffer = class {
    constructor(shape, dtype, values) {
      this.dtype = dtype;
      this.shape = shape.slice();
      this.size = sizeFromShape(shape);
      if (values != null) {
        const n = values.length;
        assert(n === this.size, () => `Length of values '${n}' does not match the size inferred by the shape '${this.size}'.`);
      }
      if (dtype === "complex64") {
        throw new Error(`complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).`);
      }
      this.values = values || getArrayFromDType(dtype, this.size);
      this.strides = computeStrides(shape);
    }
    set(value, ...locs) {
      if (locs.length === 0) {
        locs = [0];
      }
      assert(locs.length === this.rank, () => `The number of provided coordinates (${locs.length}) must match the rank (${this.rank})`);
      const index = this.locToIndex(locs);
      this.values[index] = value;
    }
    get(...locs) {
      if (locs.length === 0) {
        locs = [0];
      }
      let i = 0;
      for (const loc of locs) {
        if (loc < 0 || loc >= this.shape[i]) {
          const msg = `Requested out of range element at ${locs}.   Buffer shape=${this.shape}`;
          throw new Error(msg);
        }
        i++;
      }
      let index = locs[locs.length - 1];
      for (let i2 = 0; i2 < locs.length - 1; ++i2) {
        index += this.strides[i2] * locs[i2];
      }
      return this.values[index];
    }
    locToIndex(locs) {
      if (this.rank === 0) {
        return 0;
      } else if (this.rank === 1) {
        return locs[0];
      }
      let index = locs[locs.length - 1];
      for (let i = 0; i < locs.length - 1; ++i) {
        index += this.strides[i] * locs[i];
      }
      return index;
    }
    indexToLoc(index) {
      if (this.rank === 0) {
        return [];
      } else if (this.rank === 1) {
        return [index];
      }
      const locs = new Array(this.shape.length);
      for (let i = 0; i < locs.length - 1; ++i) {
        locs[i] = Math.floor(index / this.strides[i]);
        index -= locs[i] * this.strides[i];
      }
      locs[locs.length - 1] = index;
      return locs;
    }
    get rank() {
      return this.shape.length;
    }
    toTensor() {
      return trackerFn().makeTensor(this.values, this.shape, this.dtype);
    }
  };
  var trackerFn = null;
  var opHandler = null;
  var deprecationWarningFn = null;
  function setTensorTracker(fn) {
    trackerFn = fn;
  }
  function setOpHandler(handler) {
    opHandler = handler;
  }
  function setDeprecationWarningFn(fn) {
    deprecationWarningFn = fn;
  }
  var Tensor = class {
    constructor(shape, dtype, dataId, id) {
      this.kept = false;
      this.isDisposedInternal = false;
      this.shape = shape.slice();
      this.dtype = dtype || "float32";
      this.size = sizeFromShape(shape);
      this.strides = computeStrides(shape);
      this.dataId = dataId;
      this.id = id;
      this.rankType = this.rank < 5 ? this.rank.toString() : "higher";
    }
    get rank() {
      return this.shape.length;
    }
    async buffer() {
      const vals = await this.data();
      return opHandler.buffer(this.shape, this.dtype, vals);
    }
    bufferSync() {
      return opHandler.buffer(this.shape, this.dtype, this.dataSync());
    }
    async array() {
      const vals = await this.data();
      return toNestedArray(this.shape, vals, this.dtype === "complex64");
    }
    arraySync() {
      return toNestedArray(this.shape, this.dataSync(), this.dtype === "complex64");
    }
    async data() {
      this.throwIfDisposed();
      const data = trackerFn().read(this.dataId);
      if (this.dtype === "string") {
        const bytes = await data;
        try {
          return bytes.map((b) => decodeString(b));
        } catch (_a2) {
          throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
        }
      }
      return data;
    }
    dataSync() {
      this.throwIfDisposed();
      const data = trackerFn().readSync(this.dataId);
      if (this.dtype === "string") {
        try {
          return data.map((b) => decodeString(b));
        } catch (_a2) {
          throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
        }
      }
      return data;
    }
    async bytes() {
      this.throwIfDisposed();
      const data = await trackerFn().read(this.dataId);
      if (this.dtype === "string") {
        return data;
      } else {
        return new Uint8Array(data.buffer);
      }
    }
    dispose() {
      if (this.isDisposed) {
        return;
      }
      trackerFn().disposeTensor(this);
      this.isDisposedInternal = true;
    }
    get isDisposed() {
      return this.isDisposedInternal;
    }
    throwIfDisposed() {
      if (this.isDisposed) {
        throw new Error(`Tensor is disposed.`);
      }
    }
    print(verbose = false) {
      return opHandler.print(this, verbose);
    }
    clone() {
      this.throwIfDisposed();
      return opHandler.clone(this);
    }
    toString(verbose = false) {
      const vals = this.dataSync();
      return tensorToString(vals, this.shape, this.dtype, verbose);
    }
    cast(dtype) {
      this.throwIfDisposed();
      return opHandler.cast(this, dtype);
    }
    variable(trainable = true, name, dtype) {
      this.throwIfDisposed();
      return trackerFn().makeVariable(this, trainable, name, dtype);
    }
  };
  Object.defineProperty(Tensor, Symbol.hasInstance, {
    value: (instance) => {
      return !!instance && instance.data != null && instance.dataSync != null && instance.throwIfDisposed != null;
    }
  });
  function getGlobalTensorClass() {
    return getGlobal("Tensor", () => {
      return Tensor;
    });
  }
  getGlobalTensorClass();
  var Variable = class extends Tensor {
    constructor(initialValue, trainable, name, tensorId) {
      super(initialValue.shape, initialValue.dtype, initialValue.dataId, tensorId);
      this.trainable = trainable;
      this.name = name;
    }
    assign(newValue) {
      if (newValue.dtype !== this.dtype) {
        throw new Error(`dtype of the new value (${newValue.dtype}) and previous value (${this.dtype}) must match`);
      }
      if (!arraysEqual(newValue.shape, this.shape)) {
        throw new Error(`shape of the new value (${newValue.shape}) and previous value (${this.shape}) must match`);
      }
      trackerFn().disposeTensor(this);
      this.dataId = newValue.dataId;
      trackerFn().incRef(this, null);
    }
    dispose() {
      trackerFn().disposeVariable(this);
      this.isDisposedInternal = true;
    }
  };
  Object.defineProperty(Variable, Symbol.hasInstance, {
    value: (instance) => {
      return instance instanceof Tensor && instance.assign != null && instance.assign instanceof Function;
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/tensor_util.js
  var tensor_util_exports = {};
  __export(tensor_util_exports, {
    assertTypesMatch: () => assertTypesMatch,
    getTensorsInContainer: () => getTensorsInContainer,
    isTensorInList: () => isTensorInList,
    makeTypesMatch: () => makeTypesMatch
  });

  // node_modules/@tensorflow/tfjs-core/dist/types.js
  var Rank;
  (function(Rank2) {
    Rank2["R0"] = "R0";
    Rank2["R1"] = "R1";
    Rank2["R2"] = "R2";
    Rank2["R3"] = "R3";
    Rank2["R4"] = "R4";
    Rank2["R5"] = "R5";
    Rank2["R6"] = "R6";
  })(Rank || (Rank = {}));
  var UpcastInt32AndMap;
  (function(UpcastInt32AndMap2) {
    UpcastInt32AndMap2["float32"] = "float32";
    UpcastInt32AndMap2["int32"] = "int32";
    UpcastInt32AndMap2["bool"] = "int32";
    UpcastInt32AndMap2["complex64"] = "complex64";
  })(UpcastInt32AndMap || (UpcastInt32AndMap = {}));
  var UpcastBoolAndMap;
  (function(UpcastBoolAndMap2) {
    UpcastBoolAndMap2["float32"] = "float32";
    UpcastBoolAndMap2["int32"] = "int32";
    UpcastBoolAndMap2["bool"] = "bool";
    UpcastBoolAndMap2["complex64"] = "complex64";
  })(UpcastBoolAndMap || (UpcastBoolAndMap = {}));
  var UpcastFloat32AndMap;
  (function(UpcastFloat32AndMap2) {
    UpcastFloat32AndMap2["float32"] = "float32";
    UpcastFloat32AndMap2["int32"] = "float32";
    UpcastFloat32AndMap2["bool"] = "float32";
    UpcastFloat32AndMap2["complex64"] = "complex64";
  })(UpcastFloat32AndMap || (UpcastFloat32AndMap = {}));
  var UpcastComplex64AndMap;
  (function(UpcastComplex64AndMap2) {
    UpcastComplex64AndMap2["float32"] = "complex64";
    UpcastComplex64AndMap2["int32"] = "complex64";
    UpcastComplex64AndMap2["bool"] = "complex64";
    UpcastComplex64AndMap2["complex64"] = "complex64";
  })(UpcastComplex64AndMap || (UpcastComplex64AndMap = {}));
  var upcastTypeMap = {
    "float32": UpcastFloat32AndMap,
    "int32": UpcastInt32AndMap,
    "bool": UpcastBoolAndMap,
    "complex64": UpcastComplex64AndMap
  };
  function upcastType(typeA, typeB) {
    if (typeA === "string" || typeB === "string") {
      if (typeA === "string" && typeB === "string") {
        return "string";
      }
      throw new Error(`Can not upcast ${typeA} with ${typeB}`);
    }
    return upcastTypeMap[typeA][typeB];
  }
  function sumOutType(type) {
    return upcastType(type, "int32");
  }

  // node_modules/@tensorflow/tfjs-core/dist/tensor_util.js
  function makeTypesMatch(a, b) {
    if (a.dtype === b.dtype) {
      return [a, b];
    }
    const dtype = upcastType(a.dtype, b.dtype);
    return [a.cast(dtype), b.cast(dtype)];
  }
  function assertTypesMatch(a, b) {
    assert(a.dtype === b.dtype, () => `The dtypes of the first(${a.dtype}) and second(${b.dtype}) input must match`);
  }
  function isTensorInList(tensor2, tensorList) {
    return tensorList.some((x) => x.id === tensor2.id);
  }
  function getTensorsInContainer(result) {
    const list = [];
    const seen = new Set();
    walkTensorContainer(result, list, seen);
    return list;
  }
  function walkTensorContainer(container, list, seen) {
    if (container == null) {
      return;
    }
    if (container instanceof Tensor) {
      list.push(container);
      return;
    }
    if (!isIterable(container)) {
      return;
    }
    const iterable = container;
    for (const k in iterable) {
      const val = iterable[k];
      if (!seen.has(val)) {
        seen.add(val);
        walkTensorContainer(val, list, seen);
      }
    }
  }
  function isIterable(obj) {
    return Array.isArray(obj) || typeof obj === "object";
  }

  // node_modules/@tensorflow/tfjs-core/dist/engine.js
  function isRegisteredKernelInvocation(kernelInvocation) {
    return kernelInvocation.kernelName != null;
  }
  var EngineState = class {
    constructor() {
      this.registeredVariables = {};
      this.nextTapeNodeId = 0;
      this.numBytes = 0;
      this.numTensors = 0;
      this.numStringTensors = 0;
      this.numDataBuffers = 0;
      this.gradientDepth = 0;
      this.kernelDepth = 0;
      this.scopeStack = [];
      this.numDataMovesStack = [];
      this.nextScopeId = 0;
      this.tensorInfo = new WeakMap();
      this.profiling = false;
      this.activeProfile = {
        newBytes: 0,
        newTensors: 0,
        peakBytes: 0,
        kernels: [],
        result: null,
        get kernelNames() {
          return Array.from(new Set(this.kernels.map((k) => k.name)));
        }
      };
    }
    dispose() {
      for (const variableName in this.registeredVariables) {
        this.registeredVariables[variableName].dispose();
      }
    }
  };
  var Engine = class {
    constructor(ENV4) {
      this.ENV = ENV4;
      this.registry = {};
      this.registryFactory = {};
      this.pendingBackendInitId = 0;
      this.state = new EngineState();
    }
    async ready() {
      if (this.pendingBackendInit != null) {
        return this.pendingBackendInit.then(() => {
        });
      }
      if (this.backendInstance != null) {
        return;
      }
      const sortedBackends = this.getSortedBackends();
      for (let i = 0; i < sortedBackends.length; i++) {
        const backendName = sortedBackends[i];
        const success = await this.initializeBackend(backendName).success;
        if (success) {
          await this.setBackend(backendName);
          return;
        }
      }
      throw new Error(`Could not initialize any backends, all backend initializations failed.`);
    }
    get backend() {
      if (this.pendingBackendInit != null) {
        throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);
      }
      if (this.backendInstance == null) {
        const { name, asyncInit } = this.initializeBackendsAndReturnBest();
        if (asyncInit) {
          throw new Error(`The highest priority backend '${name}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);
        }
        this.setBackend(name);
      }
      return this.backendInstance;
    }
    backendNames() {
      return Object.keys(this.registryFactory);
    }
    findBackend(backendName) {
      if (!(backendName in this.registry)) {
        if (backendName in this.registryFactory) {
          const { asyncInit } = this.initializeBackend(backendName);
          if (asyncInit) {
            return null;
          }
        } else {
          return null;
        }
      }
      return this.registry[backendName];
    }
    findBackendFactory(backendName) {
      if (!(backendName in this.registryFactory)) {
        return null;
      }
      return this.registryFactory[backendName].factory;
    }
    registerBackend(backendName, factory, priority = 1) {
      if (backendName in this.registryFactory) {
        warn3(`${backendName} backend was already registered. Reusing existing backend factory.`);
        return false;
      }
      this.registryFactory[backendName] = { factory, priority };
      return true;
    }
    async setBackend(backendName) {
      if (this.registryFactory[backendName] == null) {
        throw new Error(`Backend name '${backendName}' not found in registry`);
      }
      this.backendName = backendName;
      if (this.registry[backendName] == null) {
        this.backendInstance = null;
        const { success, asyncInit } = this.initializeBackend(backendName);
        const result = asyncInit ? await success : success;
        if (!result) {
          return false;
        }
      }
      this.backendInstance = this.registry[backendName];
      this.setupRegisteredKernels();
      this.profiler = new Profiler(this.backendInstance);
      return true;
    }
    setupRegisteredKernels() {
      const kernels = getKernelsForBackend(this.backendName);
      kernels.forEach((kernel) => {
        if (kernel.setupFunc != null) {
          kernel.setupFunc(this.backendInstance);
        }
      });
    }
    disposeRegisteredKernels(backendName) {
      const kernels = getKernelsForBackend(backendName);
      kernels.forEach((kernel) => {
        if (kernel.disposeFunc != null) {
          kernel.disposeFunc(this.registry[backendName]);
        }
      });
    }
    initializeBackend(backendName) {
      const registryFactoryEntry = this.registryFactory[backendName];
      if (registryFactoryEntry == null) {
        throw new Error(`Cannot initialize backend ${backendName}, no registration found.`);
      }
      try {
        const backend2 = registryFactoryEntry.factory();
        if (backend2 && !(backend2 instanceof KernelBackend) && typeof backend2.then === "function") {
          const promiseId = ++this.pendingBackendInitId;
          const success = backend2.then((backendInstance) => {
            if (promiseId < this.pendingBackendInitId) {
              return false;
            }
            this.registry[backendName] = backendInstance;
            this.pendingBackendInit = null;
            return true;
          }).catch((err) => {
            if (promiseId < this.pendingBackendInitId) {
              return false;
            }
            this.pendingBackendInit = null;
            warn3(`Initialization of backend ${backendName} failed`);
            warn3(err.stack || err.message);
            return false;
          });
          this.pendingBackendInit = success;
          return { success, asyncInit: true };
        } else {
          this.registry[backendName] = backend2;
          return { success: true, asyncInit: false };
        }
      } catch (err) {
        warn3(`Initialization of backend ${backendName} failed`);
        warn3(err.stack || err.message);
        return { success: false, asyncInit: false };
      }
    }
    removeBackend(backendName) {
      if (!(backendName in this.registryFactory)) {
        throw new Error(`${backendName} backend not found in registry`);
      }
      if (this.backendName === backendName && this.pendingBackendInit != null) {
        this.pendingBackendInitId++;
      }
      if (backendName in this.registry) {
        this.disposeRegisteredKernels(backendName);
        this.registry[backendName].dispose();
        delete this.registry[backendName];
      }
      delete this.registryFactory[backendName];
      if (this.backendName === backendName) {
        this.pendingBackendInit = null;
        this.backendName = null;
        this.backendInstance = null;
      }
    }
    getSortedBackends() {
      if (Object.keys(this.registryFactory).length === 0) {
        throw new Error("No backend found in registry.");
      }
      return Object.keys(this.registryFactory).sort((a, b) => {
        return this.registryFactory[b].priority - this.registryFactory[a].priority;
      });
    }
    initializeBackendsAndReturnBest() {
      const sortedBackends = this.getSortedBackends();
      for (let i = 0; i < sortedBackends.length; i++) {
        const backendName = sortedBackends[i];
        const { success, asyncInit } = this.initializeBackend(backendName);
        if (asyncInit || success) {
          return { name: backendName, asyncInit };
        }
      }
      throw new Error(`Could not initialize any backends, all backend initializations failed.`);
    }
    moveData(backend2, dataId) {
      const info = this.state.tensorInfo.get(dataId);
      const srcBackend = info.backend;
      const values = this.readSync(dataId);
      const refCount = srcBackend.refCount(dataId);
      srcBackend.disposeData(dataId, true);
      info.backend = backend2;
      backend2.move(dataId, values, info.shape, info.dtype, refCount);
      if (this.shouldCheckForMemLeaks()) {
        this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;
      }
    }
    tidy(nameOrFn, fn) {
      let name = null;
      if (fn == null) {
        if (typeof nameOrFn !== "function") {
          throw new Error("Please provide a function to tidy()");
        }
        fn = nameOrFn;
      } else {
        if (typeof nameOrFn !== "string" && !(nameOrFn instanceof String)) {
          throw new Error("When calling with two arguments, the first argument to tidy() must be a string");
        }
        if (typeof fn !== "function") {
          throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");
        }
        name = nameOrFn;
      }
      let result;
      return this.scopedRun(() => this.startScope(name), () => this.endScope(result), () => {
        result = fn();
        if (result instanceof Promise) {
          console.error("Cannot return a Promise inside of tidy.");
        }
        return result;
      });
    }
    scopedRun(start, end, f) {
      start();
      try {
        const res = f();
        end();
        return res;
      } catch (ex) {
        end();
        throw ex;
      }
    }
    nextTensorId() {
      return Engine.nextTensorId++;
    }
    nextVariableId() {
      return Engine.nextVariableId++;
    }
    clone(x) {
      const y = ENGINE.runKernel(Identity, { x });
      const inputs = { x };
      const grad = (dy) => ({
        x: () => {
          const dtype = "float32";
          const gradInputs = { x: dy };
          const attrs = { dtype };
          return ENGINE.runKernel(Cast, gradInputs, attrs);
        }
      });
      const saved = [];
      this.addTapeNode(this.state.activeScope.name, inputs, [y], grad, saved, {});
      return y;
    }
    runKernel(kernelName, inputs, attrs) {
      if (this.backendName == null) {
        this.backend;
      }
      const hasKernel = getKernel(kernelName, this.backendName) != null;
      if (!hasKernel) {
        throw new Error(`Kernel '${kernelName}' not registered for backend '${this.backendName}'`);
      }
      return this.runKernelFunc({ kernelName, inputs, attrs });
    }
    shouldCheckForMemLeaks() {
      return this.ENV.getBool("IS_TEST");
    }
    checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos) {
      const numDataIdsAfter = this.backend.numDataIds();
      let numOutputDataIds = 0;
      outInfos.forEach((info) => {
        numOutputDataIds += info.dtype === "complex64" ? 3 : 1;
      });
      const numMoves = this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1];
      const dataIdsLeaked = numDataIdsAfter - numDataIdsBefore - numOutputDataIds - numMoves;
      if (dataIdsLeaked > 0) {
        throw new Error(`Backend '${this.backendName}' has an internal memory leak (${dataIdsLeaked} data ids) after running '${kernelName}'`);
      }
    }
    runKernelFunc(kernelParams) {
      let outputs;
      let saved = [];
      const isTapeOn = this.isTapeOn();
      const startingBytecount = this.state.numBytes;
      const startingNumTensors = this.state.numTensors;
      if (this.shouldCheckForMemLeaks()) {
        this.state.numDataMovesStack.push(0);
      }
      let kernelFunc;
      if (this.backendName == null) {
        this.backend;
      }
      let out;
      const kernelOrScopeName = isRegisteredKernelInvocation(kernelParams) ? kernelParams.kernelName : this.state.activeScope != null ? this.state.activeScope.name : "";
      if (isRegisteredKernelInvocation(kernelParams)) {
        const { kernelName, inputs: inputs2, attrs: attrs2 } = kernelParams;
        if (this.backendName == null) {
          this.backend;
        }
        const kernel = getKernel(kernelName, this.backendName);
        assert(kernel != null, () => `Cannot find registered kernel '${kernelName}' for backend '${this.backendName}'`);
        kernelFunc = () => {
          const numDataIdsBefore = this.backend.numDataIds();
          out = kernel.kernelFunc({ inputs: inputs2, attrs: attrs2, backend: this.backend });
          const outInfos = Array.isArray(out) ? out : [out];
          if (this.shouldCheckForMemLeaks()) {
            this.checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos);
          }
          const outTensors = outInfos.map((outInfo) => {
            if (outInfo.rank != null) {
              return outInfo;
            }
            const { dataId, shape, dtype } = outInfo;
            return this.makeTensorFromDataId(dataId, shape, dtype);
          });
          if (isTapeOn) {
            const tensorsToSave = this.getTensorsForGradient(kernelName, inputs2, outTensors);
            saved = this.saveTensorsForBackwardMode(tensorsToSave);
          }
          return outTensors;
        };
      } else {
        const { forwardFunc } = kernelParams;
        const saveFunc = (tensors) => {
          if (!isTapeOn) {
            return;
          }
          saved = tensors.map((tensor2) => this.keep(this.clone(tensor2)));
        };
        kernelFunc = () => {
          const numDataIdsBefore = this.backend.numDataIds();
          out = this.tidy(() => forwardFunc(this.backend, saveFunc));
          const outs = Array.isArray(out) ? out : [out];
          if (this.shouldCheckForMemLeaks()) {
            this.checkKernelForMemLeak(kernelOrScopeName, numDataIdsBefore, outs);
          }
          return outs;
        };
      }
      const { inputs, attrs } = kernelParams;
      const backwardsFunc = isRegisteredKernelInvocation(kernelParams) ? null : kernelParams.backwardsFunc;
      let kernelProfile;
      this.scopedRun(() => this.state.kernelDepth++, () => this.state.kernelDepth--, () => {
        if (!this.ENV.getBool("DEBUG") && !this.state.profiling) {
          outputs = kernelFunc();
        } else {
          kernelProfile = this.profiler.profileKernel(kernelOrScopeName, inputs, () => kernelFunc());
          if (this.ENV.getBool("DEBUG")) {
            this.profiler.logKernelProfile(kernelProfile);
          }
          outputs = kernelProfile.outputs;
        }
      });
      if (isTapeOn) {
        this.addTapeNode(kernelOrScopeName, inputs, outputs, backwardsFunc, saved, attrs);
      }
      if (this.state.profiling) {
        this.state.activeProfile.kernels.push({
          name: kernelOrScopeName,
          bytesAdded: this.state.numBytes - startingBytecount,
          totalBytesSnapshot: this.state.numBytes,
          tensorsAdded: this.state.numTensors - startingNumTensors,
          totalTensorsSnapshot: this.state.numTensors,
          inputShapes: Object.keys(inputs).map((key) => inputs[key] != null ? inputs[key].shape : null),
          outputShapes: outputs.map((item) => item.shape),
          kernelTimeMs: kernelProfile.timeMs,
          extraInfo: kernelProfile.extraInfo
        });
      }
      return Array.isArray(out) ? outputs : outputs[0];
    }
    saveTensorsForBackwardMode(tensors) {
      const saved = tensors.map((tensor2) => this.keep(this.clone(tensor2)));
      return saved;
    }
    getTensorsForGradient(kernelName, inputs, outputs) {
      const gradConfig = getGradient(kernelName);
      if (gradConfig != null) {
        const inputsToSave = gradConfig.inputsToSave || [];
        const outputsToSave = gradConfig.outputsToSave || [];
        let inputTensorsToSave;
        if (gradConfig.saveAllInputs) {
          assert(Array.isArray(inputs), () => "saveAllInputs is true, expected inputs to be an array.");
          inputTensorsToSave = Object.keys(inputs).map((key) => inputs[key]);
        } else {
          inputTensorsToSave = inputsToSave.map((inputName) => inputs[inputName]);
        }
        const outputTensorsToSave = outputs.filter((_, i) => outputsToSave[i]);
        return inputTensorsToSave.concat(outputTensorsToSave);
      }
      return [];
    }
    makeTensor(values, shape, dtype, backend2) {
      if (values == null) {
        throw new Error("Values passed to engine.makeTensor() are null");
      }
      dtype = dtype || "float32";
      backend2 = backend2 || this.backend;
      let backendVals = values;
      if (dtype === "string" && isString2(values[0])) {
        backendVals = values.map((d) => encodeString(d));
      }
      const dataId = backend2.write(backendVals, shape, dtype);
      const t = new Tensor(shape, dtype, dataId, this.nextTensorId());
      this.trackTensor(t, backend2);
      if (dtype === "string") {
        const info = this.state.tensorInfo.get(dataId);
        const newBytes = bytesFromStringArray(backendVals);
        this.state.numBytes += newBytes - info.bytes;
        info.bytes = newBytes;
      }
      return t;
    }
    makeTensorFromDataId(dataId, shape, dtype, backend2) {
      dtype = dtype || "float32";
      const t = new Tensor(shape, dtype, dataId, this.nextTensorId());
      this.trackTensor(t, backend2);
      return t;
    }
    makeVariable(initialValue, trainable = true, name, dtype) {
      name = name || this.nextVariableId().toString();
      if (dtype != null && dtype !== initialValue.dtype) {
        initialValue = initialValue.cast(dtype);
      }
      const v = new Variable(initialValue, trainable, name, this.nextTensorId());
      if (this.state.registeredVariables[v.name] != null) {
        throw new Error(`Variable with name ${v.name} was already registered`);
      }
      this.state.registeredVariables[v.name] = v;
      this.incRef(v, this.backend);
      return v;
    }
    trackTensor(a, backend2) {
      this.state.numTensors++;
      if (a.dtype === "string") {
        this.state.numStringTensors++;
      }
      let bytes = 0;
      if (a.dtype !== "complex64" && a.dtype !== "string") {
        bytes = a.size * bytesPerElement(a.dtype);
      }
      this.state.numBytes += bytes;
      if (!this.state.tensorInfo.has(a.dataId)) {
        this.state.numDataBuffers++;
        this.state.tensorInfo.set(a.dataId, {
          backend: backend2 || this.backend,
          dtype: a.dtype,
          shape: a.shape,
          bytes
        });
      }
      if (!(a instanceof Variable)) {
        this.track(a);
      }
    }
    incRef(a, backend2) {
      this.trackTensor(a, backend2);
      this.backend.incRef(a.dataId);
    }
    removeDataId(dataId, backend2) {
      if (this.state.tensorInfo.has(dataId) && this.state.tensorInfo.get(dataId).backend === backend2) {
        this.state.tensorInfo.delete(dataId);
        this.state.numDataBuffers--;
      }
    }
    disposeTensor(a) {
      if (!this.state.tensorInfo.has(a.dataId)) {
        return;
      }
      const info = this.state.tensorInfo.get(a.dataId);
      this.state.numTensors--;
      if (a.dtype === "string") {
        this.state.numStringTensors--;
        this.state.numBytes -= info.bytes;
      }
      if (a.dtype !== "complex64" && a.dtype !== "string") {
        const bytes = a.size * bytesPerElement(a.dtype);
        this.state.numBytes -= bytes;
      }
      if (info.backend.disposeData(a.dataId)) {
        this.removeDataId(a.dataId, info.backend);
      }
    }
    disposeVariables() {
      for (const varName in this.state.registeredVariables) {
        const v = this.state.registeredVariables[varName];
        this.disposeVariable(v);
      }
    }
    disposeVariable(v) {
      this.disposeTensor(v);
      if (this.state.registeredVariables[v.name] != null) {
        delete this.state.registeredVariables[v.name];
      }
    }
    memory() {
      const info = this.backend.memory();
      info.numTensors = this.state.numTensors;
      info.numDataBuffers = this.state.numDataBuffers;
      info.numBytes = this.state.numBytes;
      if (this.state.numStringTensors > 0) {
        info.unreliable = true;
        if (info.reasons == null) {
          info.reasons = [];
        }
        info.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)");
      }
      return info;
    }
    async profile(query) {
      this.state.profiling = true;
      const startBytes = this.state.numBytes;
      const startNumTensors = this.state.numTensors;
      this.state.activeProfile.kernels = [];
      this.state.activeProfile.result = await query();
      this.state.profiling = false;
      this.state.activeProfile.peakBytes = Math.max(...this.state.activeProfile.kernels.map((d) => d.totalBytesSnapshot));
      this.state.activeProfile.newBytes = this.state.numBytes - startBytes;
      this.state.activeProfile.newTensors = this.state.numTensors - startNumTensors;
      for (const kernel of this.state.activeProfile.kernels) {
        kernel.kernelTimeMs = await kernel.kernelTimeMs;
        kernel.extraInfo = await kernel.extraInfo;
      }
      return this.state.activeProfile;
    }
    isTapeOn() {
      return this.state.gradientDepth > 0 && this.state.kernelDepth === 0;
    }
    addTapeNode(kernelName, inputs, outputs, gradientsFunc, saved, attrs) {
      const tapeNode = { id: this.state.nextTapeNodeId++, kernelName, inputs, outputs, saved };
      const gradConfig = getGradient(kernelName);
      if (gradConfig != null) {
        gradientsFunc = gradConfig.gradFunc;
      }
      if (gradientsFunc != null) {
        tapeNode.gradient = (dys) => {
          dys = dys.map((dy, i) => {
            if (dy == null) {
              const output = outputs[i];
              const vals = makeZerosTypedArray(output.size, output.dtype);
              return this.makeTensor(vals, output.shape, output.dtype);
            }
            return dy;
          });
          return gradientsFunc(dys.length > 1 ? dys : dys[0], saved, attrs);
        };
      }
      this.state.activeTape.push(tapeNode);
    }
    keep(result) {
      result.kept = true;
      return result;
    }
    startTape() {
      if (this.state.gradientDepth === 0) {
        this.state.activeTape = [];
      }
      this.state.gradientDepth++;
    }
    endTape() {
      this.state.gradientDepth--;
    }
    startScope(name) {
      const scopeInfo = {
        track: [],
        name: "unnamed scope",
        id: this.state.nextScopeId++
      };
      if (name) {
        scopeInfo.name = name;
      }
      this.state.scopeStack.push(scopeInfo);
      this.state.activeScope = scopeInfo;
    }
    endScope(result) {
      const tensorsToTrackInParent = getTensorsInContainer(result);
      const tensorsToTrackInParentSet = new Set(tensorsToTrackInParent.map((t) => t.id));
      for (let i = 0; i < this.state.activeScope.track.length; i++) {
        const tensor2 = this.state.activeScope.track[i];
        if (!tensor2.kept && !tensorsToTrackInParentSet.has(tensor2.id)) {
          tensor2.dispose();
        }
      }
      const oldScope = this.state.scopeStack.pop();
      this.state.activeScope = this.state.scopeStack.length === 0 ? null : this.state.scopeStack[this.state.scopeStack.length - 1];
      tensorsToTrackInParent.forEach((tensor2) => {
        if (!tensor2.kept && tensor2.scopeId === oldScope.id) {
          this.track(tensor2);
        }
      });
    }
    gradients(f, xs, dy, allowNoGradients = false) {
      assert(xs.length > 0, () => "gradients() received an empty list of xs.");
      if (dy != null && dy.dtype !== "float32") {
        throw new Error(`dy must have 'float32' dtype, but has '${dy.dtype}'`);
      }
      const y = this.scopedRun(() => this.startTape(), () => this.endTape(), () => this.tidy("forward", f));
      assert(y instanceof Tensor, () => "The result y returned by f() must be a tensor.");
      const filteredTape = getFilteredNodesXToY(this.state.activeTape, xs, y);
      if (!allowNoGradients && filteredTape.length === 0 && xs.length > 0) {
        throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");
      }
      return this.tidy("backward", () => {
        const accumulatedGradientMap = {};
        accumulatedGradientMap[y.id] = dy == null ? ones(y.shape) : dy;
        backpropagateGradients(accumulatedGradientMap, filteredTape, (f2) => this.tidy(f2), add2);
        const grads = xs.map((x) => accumulatedGradientMap[x.id]);
        if (this.state.gradientDepth === 0) {
          this.state.activeTape.forEach((node) => {
            for (const tensor2 of node.saved) {
              tensor2.dispose();
            }
          });
          this.state.activeTape = null;
        }
        return { value: y, grads };
      });
    }
    customGrad(f) {
      assert(isFunction2(f), () => "The f passed in customGrad(f) must be a function.");
      return (...inputs) => {
        assert(inputs.every((t) => t instanceof Tensor), () => "The args passed in customGrad(f)(x1, x2,...) must all be tensors");
        let res;
        const inputMap = {};
        inputs.forEach((input2, i) => {
          inputMap[i] = input2;
        });
        const forwardFunc = (_, save) => {
          res = f(...[...inputs, save]);
          assert(res.value instanceof Tensor, () => "The function f passed in customGrad(f) must return an object where `obj.value` is a tensor");
          assert(isFunction2(res.gradFunc), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function.");
          return res.value;
        };
        const backwardsFunc = (dy, saved) => {
          const gradRes = res.gradFunc(dy, saved);
          const grads = Array.isArray(gradRes) ? gradRes : [gradRes];
          assert(grads.length === inputs.length, () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...).");
          assert(grads.every((t) => t instanceof Tensor), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors.");
          const gradMap = {};
          grads.forEach((grad, i) => {
            gradMap[i] = () => grad;
          });
          return gradMap;
        };
        return this.runKernelFunc({
          forwardFunc,
          backwardsFunc,
          inputs: inputMap
        });
      };
    }
    readSync(dataId) {
      const info = this.state.tensorInfo.get(dataId);
      return info.backend.readSync(dataId);
    }
    read(dataId) {
      const info = this.state.tensorInfo.get(dataId);
      return info.backend.read(dataId);
    }
    async time(query) {
      const start = now();
      const timingInfo = await this.backend.time(query);
      timingInfo.wallMs = now() - start;
      return timingInfo;
    }
    track(result) {
      if (this.state.activeScope != null) {
        result.scopeId = this.state.activeScope.id;
        this.state.activeScope.track.push(result);
      }
      return result;
    }
    get registeredVariables() {
      return this.state.registeredVariables;
    }
    reset() {
      this.pendingBackendInitId++;
      this.state.dispose();
      this.ENV.reset();
      this.state = new EngineState();
      for (const backendName in this.registry) {
        this.disposeRegisteredKernels(backendName);
        this.registry[backendName].dispose();
        delete this.registry[backendName];
      }
      this.backendName = null;
      this.backendInstance = null;
      this.pendingBackendInit = null;
    }
  };
  Engine.nextTensorId = 0;
  Engine.nextVariableId = 0;
  function ones(shape) {
    const values = makeOnesTypedArray(sizeFromShape(shape), "float32");
    return ENGINE.makeTensor(values, shape, "float32");
  }
  function getOrMakeEngine() {
    const ns = getGlobalNamespace();
    if (ns._tfengine == null) {
      const environment = new Environment(ns);
      ns._tfengine = new Engine(environment);
    }
    setEnvironmentGlobal(ns._tfengine.ENV);
    setTensorTracker(() => ns._tfengine);
    return ns._tfengine;
  }
  var ENGINE = getOrMakeEngine();
  function add2(a, b) {
    const inputs = { a, b };
    return ENGINE.runKernel(Add, inputs);
  }

  // node_modules/@tensorflow/tfjs-core/dist/device_util.js
  var device_util_exports = {};
  __export(device_util_exports, {
    isBrowser: () => isBrowser,
    isMobile: () => isMobile,
    mockIsMobile: () => mockIsMobile
  });
  function _isNavigatorDefined() {
    return typeof navigator !== "undefined" && navigator != null;
  }
  var isMobileMockValue;
  function mockIsMobile(value) {
    isMobileMockValue = value;
  }
  function isMobile(nav) {
    if (isMobileMockValue !== void 0) {
      return isMobileMockValue;
    }
    if (nav || _isNavigatorDefined()) {
      if (!nav) {
        nav = navigator;
      }
      if (nav.product === "ReactNative") {
        return true;
      }
      const a = nav.userAgent || nav.vendor || (typeof window !== "undefined" ? window.opera : "");
      if (!a) {
        const navAny = nav;
        return navAny.userAgentData && navAny.userAgentData.mobile;
      }
      return /(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(a) || /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0, 4));
    }
    return false;
  }
  function isBrowser() {
    return typeof window !== "undefined" && window.document != null || typeof WorkerGlobalScope !== "undefined";
  }

  // node_modules/@tensorflow/tfjs-core/dist/flags.js
  var ENV2 = env();
  ENV2.registerFlag("DEBUG", () => false, (debugValue) => {
    if (debugValue) {
      console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.");
    }
  });
  ENV2.registerFlag("IS_BROWSER", () => isBrowser());
  ENV2.registerFlag("IS_NODE", () => typeof process !== "undefined" && typeof process.versions !== "undefined" && typeof process.versions.node !== "undefined");
  ENV2.registerFlag("IS_CHROME", () => typeof navigator !== "undefined" && navigator != null && navigator.userAgent != null && /Chrome/.test(navigator.userAgent) && /Google Inc/.test(navigator.vendor));
  ENV2.registerFlag("PROD", () => false);
  ENV2.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY", () => ENV2.getBool("DEBUG"));
  ENV2.registerFlag("DEPRECATION_WARNINGS_ENABLED", () => true);
  ENV2.registerFlag("IS_TEST", () => false);
  ENV2.registerFlag("CHECK_COMPUTATION_FOR_ERRORS", () => true);
  ENV2.registerFlag("WRAP_TO_IMAGEBITMAP", () => false);

  // node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js
  function inferShape(val, dtype) {
    let firstElem = val;
    if (isTypedArray(val)) {
      return dtype === "string" ? [] : [val.length];
    }
    if (!Array.isArray(val)) {
      return [];
    }
    const shape = [];
    while (Array.isArray(firstElem) || isTypedArray(firstElem) && dtype !== "string") {
      shape.push(firstElem.length);
      firstElem = firstElem[0];
    }
    if (Array.isArray(val) && env().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY")) {
      deepAssertShapeConsistency(val, shape, []);
    }
    return shape;
  }
  function deepAssertShapeConsistency(val, shape, indices) {
    indices = indices || [];
    if (!Array.isArray(val) && !isTypedArray(val)) {
      assert(shape.length === 0, () => `Element arr[${indices.join("][")}] is a primitive, but should be an array/TypedArray of ${shape[0]} elements`);
      return;
    }
    assert(shape.length > 0, () => `Element arr[${indices.join("][")}] should be a primitive, but is an array of ${val.length} elements`);
    assert(val.length === shape[0], () => `Element arr[${indices.join("][")}] should have ${shape[0]} elements, but has ${val.length} elements`);
    const subShape = shape.slice(1);
    for (let i = 0; i < val.length; ++i) {
      deepAssertShapeConsistency(val[i], subShape, indices.concat(i));
    }
  }
  function assertDtype(expectedDtype, actualDType, argName, functionName) {
    if (expectedDtype === "string_or_numeric") {
      return;
    }
    if (expectedDtype == null) {
      throw new Error(`Expected dtype cannot be null.`);
    }
    if (expectedDtype !== "numeric" && expectedDtype !== actualDType || expectedDtype === "numeric" && actualDType === "string") {
      throw new Error(`Argument '${argName}' passed to '${functionName}' must be ${expectedDtype} tensor, but got ${actualDType} tensor`);
    }
  }
  function convertToTensor(x, argName, functionName, parseAsDtype = "numeric") {
    if (x instanceof Tensor) {
      assertDtype(parseAsDtype, x.dtype, argName, functionName);
      return x;
    }
    let inferredDtype = inferDtype(x);
    if (inferredDtype !== "string" && ["bool", "int32", "float32"].indexOf(parseAsDtype) >= 0) {
      inferredDtype = parseAsDtype;
    }
    assertDtype(parseAsDtype, inferredDtype, argName, functionName);
    if (x == null || !isTypedArray(x) && !Array.isArray(x) && typeof x !== "number" && typeof x !== "boolean" && typeof x !== "string") {
      const type = x == null ? "null" : x.constructor.name;
      throw new Error(`Argument '${argName}' passed to '${functionName}' must be a Tensor or TensorLike, but got '${type}'`);
    }
    const inferredShape = inferShape(x, inferredDtype);
    if (!isTypedArray(x) && !Array.isArray(x)) {
      x = [x];
    }
    const skipTypedArray = true;
    const values = inferredDtype !== "string" ? toTypedArray(x, inferredDtype) : flatten(x, [], skipTypedArray);
    return ENGINE.makeTensor(values, inferredShape, inferredDtype);
  }
  function convertToTensorArray(arg, argName, functionName, parseAsDtype = "numeric") {
    if (!Array.isArray(arg)) {
      throw new Error(`Argument ${argName} passed to ${functionName} must be a \`Tensor[]\` or \`TensorLike[]\``);
    }
    const tensors = arg;
    return tensors.map((t, i) => convertToTensor(t, `${argName}[${i}]`, functionName, parseAsDtype));
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/operation.js
  var OP_SCOPE_SUFFIX = "__op";
  function op(f) {
    const keys = Object.keys(f);
    if (keys.length !== 1) {
      throw new Error(`Please provide an object with a single key (operation name) mapping to a function. Got an object with ${keys.length} keys.`);
    }
    let opName = keys[0];
    const fn = f[opName];
    if (opName.endsWith("_")) {
      opName = opName.substring(0, opName.length - 1);
    }
    opName = opName + OP_SCOPE_SUFFIX;
    const f2 = (...args) => {
      ENGINE.startScope(opName);
      try {
        const result = fn(...args);
        if (isPromise2(result)) {
          console.error("Cannot return a Promise inside of tidy.");
        }
        ENGINE.endScope(result);
        return result;
      } catch (ex) {
        ENGINE.endScope(null);
        throw ex;
      }
    };
    Object.defineProperty(f2, "name", { value: opName, configurable: true });
    return f2;
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/complex.js
  function complex_(real4, imag4) {
    const $real = convertToTensor(real4, "real", "complex");
    const $imag = convertToTensor(imag4, "imag", "complex");
    assertShapesMatch($real.shape, $imag.shape, `real and imag shapes, ${$real.shape} and ${$imag.shape}, must match in call to tf.complex().`);
    const inputs = { real: $real, imag: $imag };
    return ENGINE.runKernel(Complex, inputs);
  }
  var complex = op({ complex_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops_util.js
  function makeTensor(values, shape, inferredShape, dtype) {
    if (dtype == null) {
      dtype = inferDtype(values);
    }
    if (dtype === "complex64") {
      throw new Error(`Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).`);
    }
    if (!isTypedArray(values) && !Array.isArray(values) && typeof values !== "number" && typeof values !== "boolean" && typeof values !== "string") {
      throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");
    }
    if (shape != null) {
      assertNonNegativeIntegerDimensions(shape);
      const providedSize = sizeFromShape(shape);
      const inferredSize = sizeFromShape(inferredShape);
      assert(providedSize === inferredSize, () => `Based on the provided shape, [${shape}], the tensor should have ${providedSize} values but has ${inferredSize}`);
      for (let i = 0; i < inferredShape.length; ++i) {
        const inferred = inferredShape[i];
        const flatDimsDontMatch = i === inferredShape.length - 1 ? inferred !== sizeFromShape(shape.slice(i)) : true;
        assert(inferredShape[i] === shape[i] || !flatDimsDontMatch, () => `Error creating a new Tensor. Inferred shape (${inferredShape}) does not match the provided shape (${shape}). `);
      }
    }
    if (!isTypedArray(values) && !Array.isArray(values)) {
      values = [values];
    }
    shape = shape || inferredShape;
    values = dtype !== "string" ? toTypedArray(values, dtype) : flatten(values, [], true);
    return ENGINE.makeTensor(values, shape, dtype);
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/tensor.js
  function tensor(values, shape, dtype) {
    const inferredShape = inferShape(values, dtype);
    return makeTensor(values, shape, inferredShape, dtype);
  }

  // node_modules/@tensorflow/tfjs-core/dist/io/types.js
  var DTYPE_VALUE_SIZE_MAP = {
    "float32": 4,
    "float16": 2,
    "int32": 4,
    "uint16": 2,
    "uint8": 1,
    "bool": 1,
    "complex64": 8
  };

  // node_modules/@tensorflow/tfjs-core/dist/io/io_utils.js
  var NUM_BYTES_STRING_LENGTH = 4;
  async function encodeWeights(tensors, group) {
    const specs = [];
    const dataPromises = [];
    const names = Array.isArray(tensors) ? tensors.map((tensor2) => tensor2.name) : Object.keys(tensors);
    for (let i = 0; i < names.length; ++i) {
      const name = names[i];
      const t = Array.isArray(tensors) ? tensors[i].tensor : tensors[name];
      if (t.dtype !== "float32" && t.dtype !== "int32" && t.dtype !== "bool" && t.dtype !== "string" && t.dtype !== "complex64") {
        throw new Error(`Unsupported dtype in weight '${name}': ${t.dtype}`);
      }
      const spec = { name, shape: t.shape, dtype: t.dtype };
      if (t.dtype === "string") {
        const utf8bytes = new Promise(async (resolve) => {
          const vals = await t.bytes();
          const totalNumBytes = vals.reduce((p3, c) => p3 + c.length, 0) + NUM_BYTES_STRING_LENGTH * vals.length;
          const bytes = new Uint8Array(totalNumBytes);
          let offset = 0;
          for (let i2 = 0; i2 < vals.length; i2++) {
            const val = vals[i2];
            const bytesOfLength = new Uint8Array(new Uint32Array([val.length]).buffer);
            bytes.set(bytesOfLength, offset);
            offset += NUM_BYTES_STRING_LENGTH;
            bytes.set(val, offset);
            offset += val.length;
          }
          resolve(bytes);
        });
        dataPromises.push(utf8bytes);
      } else {
        dataPromises.push(t.data());
      }
      if (group != null) {
        spec.group = group;
      }
      specs.push(spec);
    }
    const tensorValues = await Promise.all(dataPromises);
    return { data: concatenateTypedArrays(tensorValues), specs };
  }
  function decodeWeights(buffer3, specs) {
    const out = {};
    let float16Decode;
    let offset = 0;
    for (const spec of specs) {
      const name = spec.name;
      const dtype = spec.dtype;
      const shape = spec.shape;
      const size2 = sizeFromShape(shape);
      let values;
      if ("quantization" in spec) {
        const quantization = spec.quantization;
        if (quantization.dtype === "uint8" || quantization.dtype === "uint16") {
          if (!("min" in quantization && "scale" in quantization)) {
            throw new Error(`Weight ${spec.name} with quantization ${quantization.dtype} doesn't have corresponding metadata min and scale.`);
          }
        } else if (quantization.dtype === "float16") {
          if (dtype !== "float32") {
            throw new Error(`Weight ${spec.name} is quantized with ${quantization.dtype} which only supports weights of type float32 not ${dtype}.`);
          }
        } else {
          throw new Error(`Weight ${spec.name} has unknown quantization dtype ${quantization.dtype}. Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.`);
        }
        const quantizationSizeFactor = DTYPE_VALUE_SIZE_MAP[quantization.dtype];
        const byteBuffer = buffer3.slice(offset, offset + size2 * quantizationSizeFactor);
        const quantizedArray = quantization.dtype === "uint8" ? new Uint8Array(byteBuffer) : new Uint16Array(byteBuffer);
        if (dtype === "float32") {
          if (quantization.dtype === "uint8" || quantization.dtype === "uint16") {
            values = new Float32Array(quantizedArray.length);
            for (let i = 0; i < quantizedArray.length; i++) {
              const v = quantizedArray[i];
              values[i] = v * quantization.scale + quantization.min;
            }
          } else if (quantization.dtype === "float16") {
            if (float16Decode === void 0) {
              float16Decode = getFloat16Decoder();
            }
            values = float16Decode(quantizedArray);
          } else {
            throw new Error(`Unsupported quantization type ${quantization.dtype} for weight type float32.`);
          }
        } else if (dtype === "int32") {
          if (quantization.dtype !== "uint8" && quantization.dtype !== "uint16") {
            throw new Error(`Unsupported quantization type ${quantization.dtype} for weight type int32.`);
          }
          values = new Int32Array(quantizedArray.length);
          for (let i = 0; i < quantizedArray.length; i++) {
            const v = quantizedArray[i];
            values[i] = Math.round(v * quantization.scale + quantization.min);
          }
        } else {
          throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);
        }
        offset += size2 * quantizationSizeFactor;
      } else if (dtype === "string") {
        const size3 = sizeFromShape(spec.shape);
        values = [];
        for (let i = 0; i < size3; i++) {
          const byteLength = new Uint32Array(buffer3.slice(offset, offset + NUM_BYTES_STRING_LENGTH))[0];
          offset += NUM_BYTES_STRING_LENGTH;
          const bytes = new Uint8Array(buffer3.slice(offset, offset + byteLength));
          values.push(bytes);
          offset += byteLength;
        }
      } else {
        const dtypeFactor = DTYPE_VALUE_SIZE_MAP[dtype];
        const byteBuffer = buffer3.slice(offset, offset + size2 * dtypeFactor);
        if (dtype === "float32") {
          values = new Float32Array(byteBuffer);
        } else if (dtype === "int32") {
          values = new Int32Array(byteBuffer);
        } else if (dtype === "bool") {
          values = new Uint8Array(byteBuffer);
        } else if (dtype === "complex64") {
          values = new Float32Array(byteBuffer);
          const real4 = new Float32Array(values.length / 2);
          const image3 = new Float32Array(values.length / 2);
          for (let i = 0; i < real4.length; i++) {
            real4[i] = values[i * 2];
            image3[i] = values[i * 2 + 1];
          }
          const realTensor = tensor(real4, shape, "float32");
          const imageTensor = tensor(image3, shape, "float32");
          out[name] = complex(realTensor, imageTensor);
          realTensor.dispose();
          imageTensor.dispose();
        } else {
          throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);
        }
        offset += size2 * dtypeFactor;
      }
      if (dtype !== "complex64") {
        out[name] = tensor(values, shape, dtype);
      }
    }
    return out;
  }
  function concatenateTypedArrays(xs) {
    if (xs === null) {
      throw new Error(`Invalid input value: ${JSON.stringify(xs)}`);
    }
    let totalByteLength = 0;
    const normalizedXs = [];
    xs.forEach((x) => {
      totalByteLength += x.byteLength;
      normalizedXs.push(x.byteLength === x.buffer.byteLength ? x : new x.constructor(x));
      if (!(x instanceof Float32Array || x instanceof Int32Array || x instanceof Uint8Array)) {
        throw new Error(`Unsupported TypedArray subtype: ${x.constructor.name}`);
      }
    });
    const y = new Uint8Array(totalByteLength);
    let offset = 0;
    normalizedXs.forEach((x) => {
      y.set(new Uint8Array(x.buffer), offset);
      offset += x.byteLength;
    });
    return y.buffer;
  }
  var useNodeBuffer = typeof Buffer !== "undefined" && (typeof Blob === "undefined" || typeof atob === "undefined" || typeof btoa === "undefined");
  function stringByteLength(str) {
    if (useNodeBuffer) {
      return Buffer.byteLength(str);
    }
    return new Blob([str]).size;
  }
  function arrayBufferToBase64String(buffer3) {
    if (useNodeBuffer) {
      return Buffer.from(buffer3).toString("base64");
    }
    const buf = new Uint8Array(buffer3);
    let s = "";
    for (let i = 0, l = buf.length; i < l; i++) {
      s += String.fromCharCode(buf[i]);
    }
    return btoa(s);
  }
  function base64StringToArrayBuffer(str) {
    if (useNodeBuffer) {
      const buf = Buffer.from(str, "base64");
      return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);
    }
    const s = atob(str);
    const buffer3 = new Uint8Array(s.length);
    for (let i = 0; i < s.length; ++i) {
      buffer3.set([s.charCodeAt(i)], i);
    }
    return buffer3.buffer;
  }
  function concatenateArrayBuffers(buffers) {
    if (buffers.length === 1) {
      return buffers[0];
    }
    let totalByteLength = 0;
    buffers.forEach((buffer3) => {
      totalByteLength += buffer3.byteLength;
    });
    const temp = new Uint8Array(totalByteLength);
    let offset = 0;
    buffers.forEach((buffer3) => {
      temp.set(new Uint8Array(buffer3), offset);
      offset += buffer3.byteLength;
    });
    return temp.buffer;
  }
  function basename(path) {
    const SEPARATOR = "/";
    path = path.trim();
    while (path.endsWith(SEPARATOR)) {
      path = path.slice(0, path.length - 1);
    }
    const items = path.split(SEPARATOR);
    return items[items.length - 1];
  }
  function getModelJSONForModelArtifacts(artifacts, manifest) {
    const result = {
      modelTopology: artifacts.modelTopology,
      format: artifacts.format,
      generatedBy: artifacts.generatedBy,
      convertedBy: artifacts.convertedBy,
      weightsManifest: manifest
    };
    if (artifacts.signature != null) {
      result.signature = artifacts.signature;
    }
    if (artifacts.userDefinedMetadata != null) {
      result.userDefinedMetadata = artifacts.userDefinedMetadata;
    }
    if (artifacts.modelInitializer != null) {
      result.modelInitializer = artifacts.modelInitializer;
    }
    if (artifacts.trainingConfig != null) {
      result.trainingConfig = artifacts.trainingConfig;
    }
    return result;
  }
  async function getModelArtifactsForJSON(modelJSON, loadWeights2) {
    const modelArtifacts = {
      modelTopology: modelJSON.modelTopology,
      format: modelJSON.format,
      generatedBy: modelJSON.generatedBy,
      convertedBy: modelJSON.convertedBy
    };
    if (modelJSON.trainingConfig != null) {
      modelArtifacts.trainingConfig = modelJSON.trainingConfig;
    }
    if (modelJSON.weightsManifest != null) {
      const [weightSpecs, weightData] = await loadWeights2(modelJSON.weightsManifest);
      modelArtifacts.weightSpecs = weightSpecs;
      modelArtifacts.weightData = weightData;
    }
    if (modelJSON.signature != null) {
      modelArtifacts.signature = modelJSON.signature;
    }
    if (modelJSON.userDefinedMetadata != null) {
      modelArtifacts.userDefinedMetadata = modelJSON.userDefinedMetadata;
    }
    if (modelJSON.modelInitializer != null) {
      modelArtifacts.modelInitializer = modelJSON.modelInitializer;
    }
    return modelArtifacts;
  }
  function getModelArtifactsInfoForJSON(modelArtifacts) {
    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
      throw new Error("Expected JSON model topology, received ArrayBuffer.");
    }
    return {
      dateSaved: new Date(),
      modelTopologyType: "JSON",
      modelTopologyBytes: modelArtifacts.modelTopology == null ? 0 : stringByteLength(JSON.stringify(modelArtifacts.modelTopology)),
      weightSpecsBytes: modelArtifacts.weightSpecs == null ? 0 : stringByteLength(JSON.stringify(modelArtifacts.weightSpecs)),
      weightDataBytes: modelArtifacts.weightData == null ? 0 : modelArtifacts.weightData.byteLength
    };
  }
  function computeFloat16MantisaTable() {
    const convertMantissa = (i) => {
      let m = i << 13;
      let e = 0;
      while ((m & 8388608) === 0) {
        e -= 8388608;
        m <<= 1;
      }
      m &= ~8388608;
      e += 947912704;
      return m | e;
    };
    const mantisaTable = new Uint32Array(2048);
    mantisaTable[0] = 0;
    for (let i = 1; i < 1024; i++) {
      mantisaTable[i] = convertMantissa(i);
    }
    for (let i = 1024; i < 2048; i++) {
      mantisaTable[i] = 939524096 + (i - 1024 << 13);
    }
    return mantisaTable;
  }
  function computeFloat16ExponentTable() {
    const exponentTable = new Uint32Array(64);
    exponentTable[0] = 0;
    exponentTable[31] = 1199570944;
    exponentTable[32] = 2147483648;
    exponentTable[63] = 3347054592;
    for (let i = 1; i < 31; i++) {
      exponentTable[i] = i << 23;
    }
    for (let i = 33; i < 63; i++) {
      exponentTable[i] = 2147483648 + (i - 32 << 23);
    }
    return exponentTable;
  }
  function computeFloat16OffsetTable() {
    const offsetTable = new Uint32Array(64);
    for (let i = 0; i < 64; i++) {
      offsetTable[i] = 1024;
    }
    offsetTable[0] = offsetTable[32] = 0;
    return offsetTable;
  }
  function getFloat16Decoder() {
    const mantisaTable = computeFloat16MantisaTable();
    const exponentTable = computeFloat16ExponentTable();
    const offsetTable = computeFloat16OffsetTable();
    return (quantizedArray) => {
      const buffer3 = new ArrayBuffer(4 * quantizedArray.length);
      const bufferUint32View = new Uint32Array(buffer3);
      for (let index = 0; index < quantizedArray.length; index++) {
        const float16Bits = quantizedArray[index];
        const float32Bits = mantisaTable[offsetTable[float16Bits >> 10] + (float16Bits & 1023)] + exponentTable[float16Bits >> 10];
        bufferUint32View[index] = float32Bits;
      }
      return new Float32Array(buffer3);
    };
  }

  // node_modules/@tensorflow/tfjs-core/dist/io/router_registry.js
  var IORouterRegistry = class {
    constructor() {
      this.saveRouters = [];
      this.loadRouters = [];
    }
    static getInstance() {
      if (IORouterRegistry.instance == null) {
        IORouterRegistry.instance = new IORouterRegistry();
      }
      return IORouterRegistry.instance;
    }
    static registerSaveRouter(saveRouter) {
      IORouterRegistry.getInstance().saveRouters.push(saveRouter);
    }
    static registerLoadRouter(loadRouter) {
      IORouterRegistry.getInstance().loadRouters.push(loadRouter);
    }
    static getSaveHandlers(url) {
      return IORouterRegistry.getHandlers(url, "save");
    }
    static getLoadHandlers(url, loadOptions) {
      return IORouterRegistry.getHandlers(url, "load", loadOptions);
    }
    static getHandlers(url, handlerType, loadOptions) {
      const validHandlers = [];
      const routers = handlerType === "load" ? IORouterRegistry.getInstance().loadRouters : IORouterRegistry.getInstance().saveRouters;
      routers.forEach((router) => {
        const handler = router(url, loadOptions);
        if (handler !== null) {
          validHandlers.push(handler);
        }
      });
      return validHandlers;
    }
  };
  var registerSaveRouter = (loudRouter) => IORouterRegistry.registerSaveRouter(loudRouter);
  var registerLoadRouter = (loudRouter) => IORouterRegistry.registerLoadRouter(loudRouter);
  var getSaveHandlers = (url) => IORouterRegistry.getSaveHandlers(url);
  var getLoadHandlers = (url, loadOptions) => IORouterRegistry.getLoadHandlers(url, loadOptions);

  // node_modules/@tensorflow/tfjs-core/dist/io/indexed_db.js
  var DATABASE_NAME = "tensorflowjs";
  var DATABASE_VERSION = 1;
  var MODEL_STORE_NAME = "models_store";
  var INFO_STORE_NAME = "model_info_store";
  function getIndexedDBFactory() {
    if (!env().getBool("IS_BROWSER")) {
      throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");
    }
    const theWindow = typeof window === "undefined" ? self : window;
    const factory = theWindow.indexedDB || theWindow.mozIndexedDB || theWindow.webkitIndexedDB || theWindow.msIndexedDB || theWindow.shimIndexedDB;
    if (factory == null) {
      throw new Error("The current browser does not appear to support IndexedDB.");
    }
    return factory;
  }
  function setUpDatabase(openRequest) {
    const db = openRequest.result;
    db.createObjectStore(MODEL_STORE_NAME, { keyPath: "modelPath" });
    db.createObjectStore(INFO_STORE_NAME, { keyPath: "modelPath" });
  }
  var BrowserIndexedDB = class {
    constructor(modelPath) {
      this.indexedDB = getIndexedDBFactory();
      if (modelPath == null || !modelPath) {
        throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");
      }
      this.modelPath = modelPath;
    }
    async save(modelArtifacts) {
      if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
        throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
      }
      return this.databaseAction(this.modelPath, modelArtifacts);
    }
    async load() {
      return this.databaseAction(this.modelPath);
    }
    databaseAction(modelPath, modelArtifacts) {
      return new Promise((resolve, reject) => {
        const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
        openRequest.onupgradeneeded = () => setUpDatabase(openRequest);
        openRequest.onsuccess = () => {
          const db = openRequest.result;
          if (modelArtifacts == null) {
            const modelTx = db.transaction(MODEL_STORE_NAME, "readonly");
            const modelStore = modelTx.objectStore(MODEL_STORE_NAME);
            const getRequest = modelStore.get(this.modelPath);
            getRequest.onsuccess = () => {
              if (getRequest.result == null) {
                db.close();
                return reject(new Error(`Cannot find model with path '${this.modelPath}' in IndexedDB.`));
              } else {
                resolve(getRequest.result.modelArtifacts);
              }
            };
            getRequest.onerror = (error) => {
              db.close();
              return reject(getRequest.error);
            };
            modelTx.oncomplete = () => db.close();
          } else {
            const modelArtifactsInfo = getModelArtifactsInfoForJSON(modelArtifacts);
            const infoTx = db.transaction(INFO_STORE_NAME, "readwrite");
            let infoStore = infoTx.objectStore(INFO_STORE_NAME);
            const putInfoRequest = infoStore.put({ modelPath: this.modelPath, modelArtifactsInfo });
            let modelTx;
            putInfoRequest.onsuccess = () => {
              modelTx = db.transaction(MODEL_STORE_NAME, "readwrite");
              const modelStore = modelTx.objectStore(MODEL_STORE_NAME);
              const putModelRequest = modelStore.put({
                modelPath: this.modelPath,
                modelArtifacts,
                modelArtifactsInfo
              });
              putModelRequest.onsuccess = () => resolve({ modelArtifactsInfo });
              putModelRequest.onerror = (error) => {
                infoStore = infoTx.objectStore(INFO_STORE_NAME);
                const deleteInfoRequest = infoStore.delete(this.modelPath);
                deleteInfoRequest.onsuccess = () => {
                  db.close();
                  return reject(putModelRequest.error);
                };
                deleteInfoRequest.onerror = (error2) => {
                  db.close();
                  return reject(putModelRequest.error);
                };
              };
            };
            putInfoRequest.onerror = (error) => {
              db.close();
              return reject(putInfoRequest.error);
            };
            infoTx.oncomplete = () => {
              if (modelTx == null) {
                db.close();
              } else {
                modelTx.oncomplete = () => db.close();
              }
            };
          }
        };
        openRequest.onerror = (error) => reject(openRequest.error);
      });
    }
  };
  BrowserIndexedDB.URL_SCHEME = "indexeddb://";
  var indexedDBRouter = (url) => {
    if (!env().getBool("IS_BROWSER")) {
      return null;
    } else {
      if (!Array.isArray(url) && url.startsWith(BrowserIndexedDB.URL_SCHEME)) {
        return browserIndexedDB(url.slice(BrowserIndexedDB.URL_SCHEME.length));
      } else {
        return null;
      }
    }
  };
  IORouterRegistry.registerSaveRouter(indexedDBRouter);
  IORouterRegistry.registerLoadRouter(indexedDBRouter);
  function browserIndexedDB(modelPath) {
    return new BrowserIndexedDB(modelPath);
  }
  function maybeStripScheme(key) {
    return key.startsWith(BrowserIndexedDB.URL_SCHEME) ? key.slice(BrowserIndexedDB.URL_SCHEME.length) : key;
  }
  var BrowserIndexedDBManager = class {
    constructor() {
      this.indexedDB = getIndexedDBFactory();
    }
    async listModels() {
      return new Promise((resolve, reject) => {
        const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
        openRequest.onupgradeneeded = () => setUpDatabase(openRequest);
        openRequest.onsuccess = () => {
          const db = openRequest.result;
          const tx = db.transaction(INFO_STORE_NAME, "readonly");
          const store = tx.objectStore(INFO_STORE_NAME);
          const getAllInfoRequest = store.getAll();
          getAllInfoRequest.onsuccess = () => {
            const out = {};
            for (const item of getAllInfoRequest.result) {
              out[item.modelPath] = item.modelArtifactsInfo;
            }
            resolve(out);
          };
          getAllInfoRequest.onerror = (error) => {
            db.close();
            return reject(getAllInfoRequest.error);
          };
          tx.oncomplete = () => db.close();
        };
        openRequest.onerror = (error) => reject(openRequest.error);
      });
    }
    async removeModel(path) {
      path = maybeStripScheme(path);
      return new Promise((resolve, reject) => {
        const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
        openRequest.onupgradeneeded = () => setUpDatabase(openRequest);
        openRequest.onsuccess = () => {
          const db = openRequest.result;
          const infoTx = db.transaction(INFO_STORE_NAME, "readwrite");
          const infoStore = infoTx.objectStore(INFO_STORE_NAME);
          const getInfoRequest = infoStore.get(path);
          let modelTx;
          getInfoRequest.onsuccess = () => {
            if (getInfoRequest.result == null) {
              db.close();
              return reject(new Error(`Cannot find model with path '${path}' in IndexedDB.`));
            } else {
              const deleteInfoRequest = infoStore.delete(path);
              const deleteModelData = () => {
                modelTx = db.transaction(MODEL_STORE_NAME, "readwrite");
                const modelStore = modelTx.objectStore(MODEL_STORE_NAME);
                const deleteModelRequest = modelStore.delete(path);
                deleteModelRequest.onsuccess = () => resolve(getInfoRequest.result.modelArtifactsInfo);
                deleteModelRequest.onerror = (error) => reject(getInfoRequest.error);
              };
              deleteInfoRequest.onsuccess = deleteModelData;
              deleteInfoRequest.onerror = (error) => {
                deleteModelData();
                db.close();
                return reject(getInfoRequest.error);
              };
            }
          };
          getInfoRequest.onerror = (error) => {
            db.close();
            return reject(getInfoRequest.error);
          };
          infoTx.oncomplete = () => {
            if (modelTx == null) {
              db.close();
            } else {
              modelTx.oncomplete = () => db.close();
            }
          };
        };
        openRequest.onerror = (error) => reject(openRequest.error);
      });
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/io/local_storage.js
  var PATH_SEPARATOR = "/";
  var PATH_PREFIX = "tensorflowjs_models";
  var INFO_SUFFIX = "info";
  var MODEL_TOPOLOGY_SUFFIX = "model_topology";
  var WEIGHT_SPECS_SUFFIX = "weight_specs";
  var WEIGHT_DATA_SUFFIX = "weight_data";
  var MODEL_METADATA_SUFFIX = "model_metadata";
  function getModelKeys(path) {
    return {
      info: [PATH_PREFIX, path, INFO_SUFFIX].join(PATH_SEPARATOR),
      topology: [PATH_PREFIX, path, MODEL_TOPOLOGY_SUFFIX].join(PATH_SEPARATOR),
      weightSpecs: [PATH_PREFIX, path, WEIGHT_SPECS_SUFFIX].join(PATH_SEPARATOR),
      weightData: [PATH_PREFIX, path, WEIGHT_DATA_SUFFIX].join(PATH_SEPARATOR),
      modelMetadata: [PATH_PREFIX, path, MODEL_METADATA_SUFFIX].join(PATH_SEPARATOR)
    };
  }
  function removeItems(keys) {
    for (const key of Object.values(keys)) {
      window.localStorage.removeItem(key);
    }
  }
  function getModelPathFromKey(key) {
    const items = key.split(PATH_SEPARATOR);
    if (items.length < 3) {
      throw new Error(`Invalid key format: ${key}`);
    }
    return items.slice(1, items.length - 1).join(PATH_SEPARATOR);
  }
  function maybeStripScheme2(key) {
    return key.startsWith(BrowserLocalStorage.URL_SCHEME) ? key.slice(BrowserLocalStorage.URL_SCHEME.length) : key;
  }
  var BrowserLocalStorage = class {
    constructor(modelPath) {
      if (!env().getBool("IS_BROWSER") || typeof window === "undefined" || typeof window.localStorage === "undefined") {
        throw new Error("The current environment does not support local storage.");
      }
      this.LS = window.localStorage;
      if (modelPath == null || !modelPath) {
        throw new Error("For local storage, modelPath must not be null, undefined or empty.");
      }
      this.modelPath = modelPath;
      this.keys = getModelKeys(this.modelPath);
    }
    async save(modelArtifacts) {
      if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
        throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
      } else {
        const topology = JSON.stringify(modelArtifacts.modelTopology);
        const weightSpecs = JSON.stringify(modelArtifacts.weightSpecs);
        const modelArtifactsInfo = getModelArtifactsInfoForJSON(modelArtifacts);
        try {
          this.LS.setItem(this.keys.info, JSON.stringify(modelArtifactsInfo));
          this.LS.setItem(this.keys.topology, topology);
          this.LS.setItem(this.keys.weightSpecs, weightSpecs);
          this.LS.setItem(this.keys.weightData, arrayBufferToBase64String(modelArtifacts.weightData));
          const metadata = {
            format: modelArtifacts.format,
            generatedBy: modelArtifacts.generatedBy,
            convertedBy: modelArtifacts.convertedBy,
            signature: modelArtifacts.signature != null ? modelArtifacts.signature : void 0,
            userDefinedMetadata: modelArtifacts.userDefinedMetadata != null ? modelArtifacts.userDefinedMetadata : void 0,
            modelInitializer: modelArtifacts.modelInitializer != null ? modelArtifacts.modelInitializer : void 0,
            trainingConfig: modelArtifacts.trainingConfig != null ? modelArtifacts.trainingConfig : void 0
          };
          this.LS.setItem(this.keys.modelMetadata, JSON.stringify(metadata));
          return { modelArtifactsInfo };
        } catch (err) {
          removeItems(this.keys);
          throw new Error(`Failed to save model '${this.modelPath}' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=${modelArtifactsInfo.modelTopologyBytes}, weightSpecsBytes=${modelArtifactsInfo.weightSpecsBytes}, weightDataBytes=${modelArtifactsInfo.weightDataBytes}.`);
        }
      }
    }
    async load() {
      const info = JSON.parse(this.LS.getItem(this.keys.info));
      if (info == null) {
        throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);
      }
      if (info.modelTopologyType !== "JSON") {
        throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");
      }
      const out = {};
      const topology = JSON.parse(this.LS.getItem(this.keys.topology));
      if (topology == null) {
        throw new Error(`In local storage, the topology of model '${this.modelPath}' is missing.`);
      }
      out.modelTopology = topology;
      const weightSpecs = JSON.parse(this.LS.getItem(this.keys.weightSpecs));
      if (weightSpecs == null) {
        throw new Error(`In local storage, the weight specs of model '${this.modelPath}' are missing.`);
      }
      out.weightSpecs = weightSpecs;
      const metadataString = this.LS.getItem(this.keys.modelMetadata);
      if (metadataString != null) {
        const metadata = JSON.parse(metadataString);
        out.format = metadata.format;
        out.generatedBy = metadata.generatedBy;
        out.convertedBy = metadata.convertedBy;
        if (metadata.signature != null) {
          out.signature = metadata.signature;
        }
        if (metadata.userDefinedMetadata != null) {
          out.userDefinedMetadata = metadata.userDefinedMetadata;
        }
        if (metadata.modelInitializer != null) {
          out.modelInitializer = metadata.modelInitializer;
        }
        if (metadata.trainingConfig != null) {
          out.trainingConfig = metadata.trainingConfig;
        }
      }
      const weightDataBase64 = this.LS.getItem(this.keys.weightData);
      if (weightDataBase64 == null) {
        throw new Error(`In local storage, the binary weight values of model '${this.modelPath}' are missing.`);
      }
      out.weightData = base64StringToArrayBuffer(weightDataBase64);
      return out;
    }
  };
  BrowserLocalStorage.URL_SCHEME = "localstorage://";
  var localStorageRouter = (url) => {
    if (!env().getBool("IS_BROWSER")) {
      return null;
    } else {
      if (!Array.isArray(url) && url.startsWith(BrowserLocalStorage.URL_SCHEME)) {
        return browserLocalStorage(url.slice(BrowserLocalStorage.URL_SCHEME.length));
      } else {
        return null;
      }
    }
  };
  IORouterRegistry.registerSaveRouter(localStorageRouter);
  IORouterRegistry.registerLoadRouter(localStorageRouter);
  function browserLocalStorage(modelPath) {
    return new BrowserLocalStorage(modelPath);
  }
  var BrowserLocalStorageManager = class {
    constructor() {
      assert(env().getBool("IS_BROWSER"), () => "Current environment is not a web browser");
      assert(typeof window === "undefined" || typeof window.localStorage !== "undefined", () => "Current browser does not appear to support localStorage");
      this.LS = window.localStorage;
    }
    async listModels() {
      const out = {};
      const prefix = PATH_PREFIX + PATH_SEPARATOR;
      const suffix = PATH_SEPARATOR + INFO_SUFFIX;
      for (let i = 0; i < this.LS.length; ++i) {
        const key = this.LS.key(i);
        if (key.startsWith(prefix) && key.endsWith(suffix)) {
          const modelPath = getModelPathFromKey(key);
          out[modelPath] = JSON.parse(this.LS.getItem(key));
        }
      }
      return out;
    }
    async removeModel(path) {
      path = maybeStripScheme2(path);
      const keys = getModelKeys(path);
      if (this.LS.getItem(keys.info) == null) {
        throw new Error(`Cannot find model at path '${path}'`);
      }
      const info = JSON.parse(this.LS.getItem(keys.info));
      removeItems(keys);
      return info;
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/io/model_management.js
  var URL_SCHEME_SUFFIX = "://";
  var ModelStoreManagerRegistry = class {
    constructor() {
      this.managers = {};
    }
    static getInstance() {
      if (ModelStoreManagerRegistry.instance == null) {
        ModelStoreManagerRegistry.instance = new ModelStoreManagerRegistry();
      }
      return ModelStoreManagerRegistry.instance;
    }
    static registerManager(scheme, manager) {
      assert(scheme != null, () => "scheme must not be undefined or null.");
      if (scheme.endsWith(URL_SCHEME_SUFFIX)) {
        scheme = scheme.slice(0, scheme.indexOf(URL_SCHEME_SUFFIX));
      }
      assert(scheme.length > 0, () => "scheme must not be an empty string.");
      const registry = ModelStoreManagerRegistry.getInstance();
      assert(registry.managers[scheme] == null, () => `A model store manager is already registered for scheme '${scheme}'.`);
      registry.managers[scheme] = manager;
    }
    static getManager(scheme) {
      const manager = this.getInstance().managers[scheme];
      if (manager == null) {
        throw new Error(`Cannot find model manager for scheme '${scheme}'`);
      }
      return manager;
    }
    static getSchemes() {
      return Object.keys(this.getInstance().managers);
    }
  };
  function parseURL(url) {
    if (url.indexOf(URL_SCHEME_SUFFIX) === -1) {
      throw new Error(`The url string provided does not contain a scheme. Supported schemes are: ${ModelStoreManagerRegistry.getSchemes().join(",")}`);
    }
    return {
      scheme: url.split(URL_SCHEME_SUFFIX)[0],
      path: url.split(URL_SCHEME_SUFFIX)[1]
    };
  }
  async function cloneModelInternal(sourceURL, destURL, deleteSource = false) {
    assert(sourceURL !== destURL, () => `Old path and new path are the same: '${sourceURL}'`);
    const loadHandlers = IORouterRegistry.getLoadHandlers(sourceURL);
    assert(loadHandlers.length > 0, () => `Copying failed because no load handler is found for source URL ${sourceURL}.`);
    assert(loadHandlers.length < 2, () => `Copying failed because more than one (${loadHandlers.length}) load handlers for source URL ${sourceURL}.`);
    const loadHandler = loadHandlers[0];
    const saveHandlers = IORouterRegistry.getSaveHandlers(destURL);
    assert(saveHandlers.length > 0, () => `Copying failed because no save handler is found for destination URL ${destURL}.`);
    assert(saveHandlers.length < 2, () => `Copying failed because more than one (${loadHandlers.length}) save handlers for destination URL ${destURL}.`);
    const saveHandler = saveHandlers[0];
    const sourceScheme = parseURL(sourceURL).scheme;
    const sourcePath = parseURL(sourceURL).path;
    const sameMedium = sourceScheme === parseURL(sourceURL).scheme;
    const modelArtifacts = await loadHandler.load();
    if (deleteSource && sameMedium) {
      await ModelStoreManagerRegistry.getManager(sourceScheme).removeModel(sourcePath);
    }
    const saveResult = await saveHandler.save(modelArtifacts);
    if (deleteSource && !sameMedium) {
      await ModelStoreManagerRegistry.getManager(sourceScheme).removeModel(sourcePath);
    }
    return saveResult.modelArtifactsInfo;
  }
  async function listModels() {
    const schemes = ModelStoreManagerRegistry.getSchemes();
    const out = {};
    for (const scheme of schemes) {
      const schemeOut = await ModelStoreManagerRegistry.getManager(scheme).listModels();
      for (const path in schemeOut) {
        const url = scheme + URL_SCHEME_SUFFIX + path;
        out[url] = schemeOut[path];
      }
    }
    return out;
  }
  async function removeModel(url) {
    const schemeAndPath = parseURL(url);
    const manager = ModelStoreManagerRegistry.getManager(schemeAndPath.scheme);
    return manager.removeModel(schemeAndPath.path);
  }
  async function copyModel(sourceURL, destURL) {
    const deleteSource = false;
    return cloneModelInternal(sourceURL, destURL, deleteSource);
  }
  async function moveModel(sourceURL, destURL) {
    const deleteSource = true;
    return cloneModelInternal(sourceURL, destURL, deleteSource);
  }

  // node_modules/@tensorflow/tfjs-core/dist/platforms/platform_browser.js
  var PlatformBrowser = class {
    fetch(path, init) {
      return fetch(path, init);
    }
    now() {
      return performance.now();
    }
    encode(text, encoding) {
      if (encoding !== "utf-8" && encoding !== "utf8") {
        throw new Error(`Browser's encoder only supports utf-8, but got ${encoding}`);
      }
      if (this.textEncoder == null) {
        this.textEncoder = new TextEncoder();
      }
      return this.textEncoder.encode(text);
    }
    decode(bytes, encoding) {
      return new TextDecoder(encoding).decode(bytes);
    }
  };
  if (env().get("IS_BROWSER")) {
    env().setPlatform("browser", new PlatformBrowser());
    try {
      ModelStoreManagerRegistry.registerManager(BrowserLocalStorage.URL_SCHEME, new BrowserLocalStorageManager());
    } catch (err) {
    }
    try {
      ModelStoreManagerRegistry.registerManager(BrowserIndexedDB.URL_SCHEME, new BrowserIndexedDBManager());
    } catch (err) {
    }
  }

  // node_modules/@tensorflow/tfjs-core/dist/platforms/platform_node.js
  var getNodeFetch = {
    importFetch: () => require_browser()
  };
  var systemFetch;
  var PlatformNode = class {
    constructor() {
      this.util = require_util();
      this.textEncoder = new this.util.TextEncoder();
    }
    fetch(path, requestInits) {
      if (env().global.fetch != null) {
        return env().global.fetch(path, requestInits);
      }
      if (systemFetch == null) {
        systemFetch = getNodeFetch.importFetch();
      }
      return systemFetch(path, requestInits);
    }
    now() {
      const time = process.hrtime();
      return time[0] * 1e3 + time[1] / 1e6;
    }
    encode(text, encoding) {
      if (encoding !== "utf-8" && encoding !== "utf8") {
        throw new Error(`Node built-in encoder only supports utf-8, but got ${encoding}`);
      }
      return this.textEncoder.encode(text);
    }
    decode(bytes, encoding) {
      if (bytes.length === 0) {
        return "";
      }
      return new this.util.TextDecoder(encoding).decode(bytes);
    }
  };
  if (env().get("IS_NODE")) {
    env().setPlatform("node", new PlatformNode());
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/buffer.js
  function buffer2(shape, dtype = "float32", values) {
    dtype = dtype || "float32";
    assertNonNegativeIntegerDimensions(shape);
    return new TensorBuffer(shape, dtype, values);
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/cast.js
  function cast_(x, dtype) {
    const $x = convertToTensor(x, "x", "cast");
    if (!isValidDtype(dtype)) {
      throw new Error(`Failed to cast to unknown dtype ${dtype}`);
    }
    if (dtype === "string" && $x.dtype !== "string" || dtype !== "string" && $x.dtype === "string") {
      throw new Error("Only strings can be casted to strings");
    }
    const inputs = { x: $x };
    const attrs = { dtype };
    return ENGINE.runKernel(Cast, inputs, attrs);
  }
  var cast = op({ cast_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/clone.js
  function clone_(x) {
    const $x = convertToTensor(x, "x", "clone", "string_or_numeric");
    const inputs = { x: $x };
    return ENGINE.runKernel(Identity, inputs);
  }
  var clone = op({ clone_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/print.js
  function print(x, verbose = false) {
    console.log(x.toString(verbose));
  }

  // node_modules/@tensorflow/tfjs-core/dist/base_side_effects.js
  getOrMakeEngine();
  var opHandler2 = {
    buffer: buffer2,
    cast,
    clone,
    print
  };
  setOpHandler(opHandler2);

  // node_modules/@tensorflow/tfjs-core/dist/io/io.js
  var io_exports = {};
  __export(io_exports, {
    browserFiles: () => browserFiles,
    browserHTTPRequest: () => browserHTTPRequest,
    concatenateArrayBuffers: () => concatenateArrayBuffers,
    copyModel: () => copyModel,
    decodeWeights: () => decodeWeights,
    encodeWeights: () => encodeWeights,
    fromMemory: () => fromMemory,
    getLoadHandlers: () => getLoadHandlers,
    getModelArtifactsForJSON: () => getModelArtifactsForJSON,
    getModelArtifactsInfoForJSON: () => getModelArtifactsInfoForJSON,
    getSaveHandlers: () => getSaveHandlers,
    http: () => http,
    isHTTPScheme: () => isHTTPScheme,
    listModels: () => listModels,
    loadWeights: () => loadWeights,
    moveModel: () => moveModel,
    registerLoadRouter: () => registerLoadRouter,
    registerSaveRouter: () => registerSaveRouter,
    removeModel: () => removeModel,
    weightsLoaderFactory: () => weightsLoaderFactory,
    withSaveHandler: () => withSaveHandler
  });

  // node_modules/@tensorflow/tfjs-core/dist/io/browser_files.js
  var DEFAULT_FILE_NAME_PREFIX = "model";
  var DEFAULT_JSON_EXTENSION_NAME = ".json";
  var DEFAULT_WEIGHT_DATA_EXTENSION_NAME = ".weights.bin";
  function defer(f) {
    return new Promise((resolve) => setTimeout(resolve)).then(f);
  }
  var BrowserDownloads = class {
    constructor(fileNamePrefix) {
      if (!env().getBool("IS_BROWSER")) {
        throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");
      }
      if (fileNamePrefix.startsWith(BrowserDownloads.URL_SCHEME)) {
        fileNamePrefix = fileNamePrefix.slice(BrowserDownloads.URL_SCHEME.length);
      }
      if (fileNamePrefix == null || fileNamePrefix.length === 0) {
        fileNamePrefix = DEFAULT_FILE_NAME_PREFIX;
      }
      this.modelJsonFileName = fileNamePrefix + DEFAULT_JSON_EXTENSION_NAME;
      this.weightDataFileName = fileNamePrefix + DEFAULT_WEIGHT_DATA_EXTENSION_NAME;
    }
    async save(modelArtifacts) {
      if (typeof document === "undefined") {
        throw new Error("Browser downloads are not supported in this environment since `document` is not present");
      }
      const weightsURL = window.URL.createObjectURL(new Blob([modelArtifacts.weightData], { type: "application/octet-stream" }));
      if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
        throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");
      } else {
        const weightsManifest = [{
          paths: ["./" + this.weightDataFileName],
          weights: modelArtifacts.weightSpecs
        }];
        const modelJSON = getModelJSONForModelArtifacts(modelArtifacts, weightsManifest);
        const modelJsonURL = window.URL.createObjectURL(new Blob([JSON.stringify(modelJSON)], { type: "application/json" }));
        const jsonAnchor = this.modelJsonAnchor == null ? document.createElement("a") : this.modelJsonAnchor;
        jsonAnchor.download = this.modelJsonFileName;
        jsonAnchor.href = modelJsonURL;
        await defer(() => jsonAnchor.dispatchEvent(new MouseEvent("click")));
        if (modelArtifacts.weightData != null) {
          const weightDataAnchor = this.weightDataAnchor == null ? document.createElement("a") : this.weightDataAnchor;
          weightDataAnchor.download = this.weightDataFileName;
          weightDataAnchor.href = weightsURL;
          await defer(() => weightDataAnchor.dispatchEvent(new MouseEvent("click")));
        }
        return { modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts) };
      }
    }
  };
  BrowserDownloads.URL_SCHEME = "downloads://";
  var BrowserFiles = class {
    constructor(files) {
      if (files == null || files.length < 1) {
        throw new Error(`When calling browserFiles, at least 1 file is required, but received ${files}`);
      }
      this.jsonFile = files[0];
      this.weightsFiles = files.slice(1);
    }
    async load() {
      return new Promise((resolve, reject) => {
        const jsonReader = new FileReader();
        jsonReader.onload = (event) => {
          const modelJSON = JSON.parse(event.target.result);
          const modelTopology = modelJSON.modelTopology;
          if (modelTopology == null) {
            reject(new Error(`modelTopology field is missing from file ${this.jsonFile.name}`));
            return;
          }
          const weightsManifest = modelJSON.weightsManifest;
          if (weightsManifest == null) {
            reject(new Error(`weightManifest field is missing from file ${this.jsonFile.name}`));
            return;
          }
          if (this.weightsFiles.length === 0) {
            resolve({ modelTopology });
            return;
          }
          const modelArtifactsPromise = getModelArtifactsForJSON(modelJSON, (weightsManifest2) => this.loadWeights(weightsManifest2));
          resolve(modelArtifactsPromise);
        };
        jsonReader.onerror = (error) => reject(`Failed to read model topology and weights manifest JSON from file '${this.jsonFile.name}'. BrowserFiles supports loading Keras-style tf.Model artifacts only.`);
        jsonReader.readAsText(this.jsonFile);
      });
    }
    loadWeights(weightsManifest) {
      const weightSpecs = [];
      const paths = [];
      for (const entry of weightsManifest) {
        weightSpecs.push(...entry.weights);
        paths.push(...entry.paths);
      }
      const pathToFile = this.checkManifestAndWeightFiles(weightsManifest);
      const promises = paths.map((path) => this.loadWeightsFile(path, pathToFile[path]));
      return Promise.all(promises).then((buffers) => [weightSpecs, concatenateArrayBuffers(buffers)]);
    }
    loadWeightsFile(path, file) {
      return new Promise((resolve, reject) => {
        const weightFileReader = new FileReader();
        weightFileReader.onload = (event) => {
          const weightData = event.target.result;
          resolve(weightData);
        };
        weightFileReader.onerror = (error) => reject(`Failed to weights data from file of path '${path}'.`);
        weightFileReader.readAsArrayBuffer(file);
      });
    }
    checkManifestAndWeightFiles(manifest) {
      const basenames = [];
      const fileNames = this.weightsFiles.map((file) => basename(file.name));
      const pathToFile = {};
      for (const group of manifest) {
        group.paths.forEach((path) => {
          const pathBasename = basename(path);
          if (basenames.indexOf(pathBasename) !== -1) {
            throw new Error(`Duplicate file basename found in weights manifest: '${pathBasename}'`);
          }
          basenames.push(pathBasename);
          if (fileNames.indexOf(pathBasename) === -1) {
            throw new Error(`Weight file with basename '${pathBasename}' is not provided.`);
          } else {
            pathToFile[path] = this.weightsFiles[fileNames.indexOf(pathBasename)];
          }
        });
      }
      if (basenames.length !== this.weightsFiles.length) {
        throw new Error(`Mismatch in the number of files in weights manifest (${basenames.length}) and the number of weight files provided (${this.weightsFiles.length}).`);
      }
      return pathToFile;
    }
  };
  var browserDownloadsRouter = (url) => {
    if (!env().getBool("IS_BROWSER")) {
      return null;
    } else {
      if (!Array.isArray(url) && url.startsWith(BrowserDownloads.URL_SCHEME)) {
        return browserDownloads(url.slice(BrowserDownloads.URL_SCHEME.length));
      } else {
        return null;
      }
    }
  };
  IORouterRegistry.registerSaveRouter(browserDownloadsRouter);
  function browserDownloads(fileNamePrefix = "model") {
    return new BrowserDownloads(fileNamePrefix);
  }
  function browserFiles(files) {
    return new BrowserFiles(files);
  }

  // node_modules/@tensorflow/tfjs-core/dist/io/progress.js
  function monitorPromisesProgress(promises, onProgress, startFraction, endFraction) {
    checkPromises(promises);
    startFraction = startFraction == null ? 0 : startFraction;
    endFraction = endFraction == null ? 1 : endFraction;
    checkFraction(startFraction, endFraction);
    let resolvedPromise2 = 0;
    const registerMonitor = (promise) => {
      promise.then((value) => {
        const fraction = startFraction + ++resolvedPromise2 / promises.length * (endFraction - startFraction);
        onProgress(fraction);
        return value;
      });
      return promise;
    };
    function checkPromises(promises2) {
      assert(promises2 != null && Array.isArray(promises2) && promises2.length > 0, () => "promises must be a none empty array");
    }
    function checkFraction(startFraction2, endFraction2) {
      assert(startFraction2 >= 0 && startFraction2 <= 1, () => `Progress fraction must be in range [0, 1], but got startFraction ${startFraction2}`);
      assert(endFraction2 >= 0 && endFraction2 <= 1, () => `Progress fraction must be in range [0, 1], but got endFraction ${endFraction2}`);
      assert(endFraction2 >= startFraction2, () => `startFraction must be no more than endFraction, but got startFraction ${startFraction2} and endFraction ${endFraction2}`);
    }
    return Promise.all(promises.map(registerMonitor));
  }

  // node_modules/@tensorflow/tfjs-core/dist/io/weights_loader.js
  async function loadWeightsAsArrayBuffer(fetchURLs, loadOptions) {
    if (loadOptions == null) {
      loadOptions = {};
    }
    const fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch : loadOptions.fetchFunc;
    const requests = fetchURLs.map((fetchURL) => fetchFunc(fetchURL, loadOptions.requestInit, { isBinary: true }));
    const fetchStartFraction = 0;
    const fetchEndFraction = 0.5;
    const responses = loadOptions.onProgress == null ? await Promise.all(requests) : await monitorPromisesProgress(requests, loadOptions.onProgress, fetchStartFraction, fetchEndFraction);
    const bufferPromises = responses.map((response) => response.arrayBuffer());
    const bufferStartFraction = 0.5;
    const bufferEndFraction = 1;
    const buffers = loadOptions.onProgress == null ? await Promise.all(bufferPromises) : await monitorPromisesProgress(bufferPromises, loadOptions.onProgress, bufferStartFraction, bufferEndFraction);
    return buffers;
  }
  async function loadWeights(manifest, filePathPrefix = "", weightNames, requestInit) {
    const fetchWeights = (fetchUrls) => loadWeightsAsArrayBuffer(fetchUrls, { requestInit });
    const loadWeights2 = weightsLoaderFactory(fetchWeights);
    return loadWeights2(manifest, filePathPrefix, weightNames);
  }
  function weightsLoaderFactory(fetchWeightsFunction) {
    return async (manifest, filePathPrefix = "", weightNames) => {
      const groupIndicesToFetchMap = manifest.map(() => false);
      const groupWeightsToFetch = {};
      const weightsFound = weightNames != null ? weightNames.map(() => false) : [];
      const allManifestWeightNames = [];
      manifest.forEach((manifestGroupConfig, groupIndex) => {
        let groupOffset = 0;
        manifestGroupConfig.weights.forEach((weightsEntry) => {
          const rawDtype = "quantization" in weightsEntry ? weightsEntry.quantization.dtype : weightsEntry.dtype;
          const weightsBytes = DTYPE_VALUE_SIZE_MAP[rawDtype] * sizeFromShape(weightsEntry.shape);
          const enqueueWeightsForFetchingFn = () => {
            groupIndicesToFetchMap[groupIndex] = true;
            if (groupWeightsToFetch[groupIndex] == null) {
              groupWeightsToFetch[groupIndex] = [];
            }
            groupWeightsToFetch[groupIndex].push({
              manifestEntry: weightsEntry,
              groupOffset,
              sizeBytes: weightsBytes
            });
          };
          if (weightNames != null) {
            weightNames.forEach((weightName, weightIndex) => {
              if (weightName === weightsEntry.name) {
                enqueueWeightsForFetchingFn();
                weightsFound[weightIndex] = true;
              }
            });
          } else {
            enqueueWeightsForFetchingFn();
          }
          allManifestWeightNames.push(weightsEntry.name);
          groupOffset += weightsBytes;
        });
      });
      if (!weightsFound.every((found) => found)) {
        const weightsNotFound = weightNames.filter((_, i) => !weightsFound[i]);
        throw new Error(`Could not find weights in manifest with names: ${weightsNotFound.join(", ")}. 
Manifest JSON has weights with names: ${allManifestWeightNames.join(", ")}.`);
      }
      const groupIndicesToFetch = groupIndicesToFetchMap.reduce((accumulator, shouldFetch, i) => {
        if (shouldFetch) {
          accumulator.push(i);
        }
        return accumulator;
      }, []);
      const fetchUrls = [];
      groupIndicesToFetch.forEach((i) => {
        manifest[i].paths.forEach((filepath) => {
          const fetchUrl = filePathPrefix + (!filePathPrefix.endsWith("/") ? "/" : "") + filepath;
          fetchUrls.push(fetchUrl);
        });
      });
      const buffers = await fetchWeightsFunction(fetchUrls);
      const weightsTensorMap = {};
      let bufferIndexOffset = 0;
      groupIndicesToFetch.forEach((i) => {
        const numBuffers = manifest[i].paths.length;
        let groupBytes = 0;
        for (let i2 = 0; i2 < numBuffers; i2++) {
          groupBytes += buffers[bufferIndexOffset + i2].byteLength;
        }
        const groupBuffer = new ArrayBuffer(groupBytes);
        const groupByteBuffer = new Uint8Array(groupBuffer);
        let groupBufferOffset = 0;
        for (let i2 = 0; i2 < numBuffers; i2++) {
          const buffer3 = new Uint8Array(buffers[bufferIndexOffset + i2]);
          groupByteBuffer.set(buffer3, groupBufferOffset);
          groupBufferOffset += buffer3.byteLength;
        }
        const weightsEntries = groupWeightsToFetch[i];
        weightsEntries.forEach((weightsEntry) => {
          const byteBuffer = groupBuffer.slice(weightsEntry.groupOffset, weightsEntry.groupOffset + weightsEntry.sizeBytes);
          const nameToTensorMap = decodeWeights(byteBuffer, [weightsEntry.manifestEntry]);
          for (const name in nameToTensorMap) {
            weightsTensorMap[name] = nameToTensorMap[name];
          }
        });
        bufferIndexOffset += numBuffers;
      });
      return weightsTensorMap;
    };
  }

  // node_modules/@tensorflow/tfjs-core/dist/io/http.js
  var OCTET_STREAM_MIME_TYPE = "application/octet-stream";
  var JSON_TYPE = "application/json";
  var HTTPRequest = class {
    constructor(path, loadOptions) {
      this.DEFAULT_METHOD = "POST";
      if (loadOptions == null) {
        loadOptions = {};
      }
      this.weightPathPrefix = loadOptions.weightPathPrefix;
      this.onProgress = loadOptions.onProgress;
      this.weightUrlConverter = loadOptions.weightUrlConverter;
      if (loadOptions.fetchFunc != null) {
        assert(typeof loadOptions.fetchFunc === "function", () => "Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)");
        this.fetch = loadOptions.fetchFunc;
      } else {
        this.fetch = env().platform.fetch;
      }
      assert(path != null && path.length > 0, () => "URL path for http must not be null, undefined or empty.");
      if (Array.isArray(path)) {
        assert(path.length === 2, () => `URL paths for http must have a length of 2, (actual length is ${path.length}).`);
      }
      this.path = path;
      if (loadOptions.requestInit != null && loadOptions.requestInit.body != null) {
        throw new Error("requestInit is expected to have no pre-existing body, but has one.");
      }
      this.requestInit = loadOptions.requestInit || {};
    }
    async save(modelArtifacts) {
      if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
        throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");
      }
      const init = Object.assign({ method: this.DEFAULT_METHOD }, this.requestInit);
      init.body = new FormData();
      const weightsManifest = [{
        paths: ["./model.weights.bin"],
        weights: modelArtifacts.weightSpecs
      }];
      const modelTopologyAndWeightManifest = getModelJSONForModelArtifacts(modelArtifacts, weightsManifest);
      init.body.append("model.json", new Blob([JSON.stringify(modelTopologyAndWeightManifest)], { type: JSON_TYPE }), "model.json");
      if (modelArtifacts.weightData != null) {
        init.body.append("model.weights.bin", new Blob([modelArtifacts.weightData], { type: OCTET_STREAM_MIME_TYPE }), "model.weights.bin");
      }
      const response = await this.fetch(this.path, init);
      if (response.ok) {
        return {
          modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts),
          responses: [response]
        };
      } else {
        throw new Error(`BrowserHTTPRequest.save() failed due to HTTP response status ${response.status}.`);
      }
    }
    async load() {
      const modelConfigRequest = await this.fetch(this.path, this.requestInit);
      if (!modelConfigRequest.ok) {
        throw new Error(`Request to ${this.path} failed with status code ${modelConfigRequest.status}. Please verify this URL points to the model JSON of the model to load.`);
      }
      let modelJSON;
      try {
        modelJSON = await modelConfigRequest.json();
      } catch (e) {
        let message = `Failed to parse model JSON of response from ${this.path}.`;
        if (this.path.endsWith(".pb")) {
          message += " Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository.";
        } else {
          message += " Please make sure the server is serving valid JSON for this request.";
        }
        throw new Error(message);
      }
      const modelTopology = modelJSON.modelTopology;
      const weightsManifest = modelJSON.weightsManifest;
      if (modelTopology == null && weightsManifest == null) {
        throw new Error(`The JSON from HTTP path ${this.path} contains neither model topology or manifest for weights.`);
      }
      return getModelArtifactsForJSON(modelJSON, (weightsManifest2) => this.loadWeights(weightsManifest2));
    }
    async loadWeights(weightsManifest) {
      const weightPath = Array.isArray(this.path) ? this.path[1] : this.path;
      const [prefix, suffix] = parseUrl(weightPath);
      const pathPrefix = this.weightPathPrefix || prefix;
      const weightSpecs = [];
      for (const entry of weightsManifest) {
        weightSpecs.push(...entry.weights);
      }
      const fetchURLs = [];
      const urlPromises = [];
      for (const weightsGroup of weightsManifest) {
        for (const path of weightsGroup.paths) {
          if (this.weightUrlConverter != null) {
            urlPromises.push(this.weightUrlConverter(path));
          } else {
            fetchURLs.push(pathPrefix + path + suffix);
          }
        }
      }
      if (this.weightUrlConverter) {
        fetchURLs.push(...await Promise.all(urlPromises));
      }
      const buffers = await loadWeightsAsArrayBuffer(fetchURLs, {
        requestInit: this.requestInit,
        fetchFunc: this.fetch,
        onProgress: this.onProgress
      });
      return [weightSpecs, concatenateArrayBuffers(buffers)];
    }
  };
  HTTPRequest.URL_SCHEME_REGEX = /^https?:\/\//;
  function parseUrl(url) {
    const lastSlash = url.lastIndexOf("/");
    const lastSearchParam = url.lastIndexOf("?");
    const prefix = url.substring(0, lastSlash);
    const suffix = lastSearchParam > lastSlash ? url.substring(lastSearchParam) : "";
    return [prefix + "/", suffix];
  }
  function isHTTPScheme(url) {
    return url.match(HTTPRequest.URL_SCHEME_REGEX) != null;
  }
  var httpRouter = (url, loadOptions) => {
    if (typeof fetch === "undefined" && (loadOptions == null || loadOptions.fetchFunc == null)) {
      return null;
    } else {
      let isHTTP = true;
      if (Array.isArray(url)) {
        isHTTP = url.every((urlItem) => isHTTPScheme(urlItem));
      } else {
        isHTTP = isHTTPScheme(url);
      }
      if (isHTTP) {
        return http(url, loadOptions);
      }
    }
    return null;
  };
  IORouterRegistry.registerSaveRouter(httpRouter);
  IORouterRegistry.registerLoadRouter(httpRouter);
  function http(path, loadOptions) {
    return new HTTPRequest(path, loadOptions);
  }
  function browserHTTPRequest(path, loadOptions) {
    return http(path, loadOptions);
  }

  // node_modules/@tensorflow/tfjs-core/dist/io/passthrough.js
  var PassthroughLoader = class {
    constructor(modelArtifacts) {
      this.modelArtifacts = modelArtifacts;
    }
    async load() {
      return this.modelArtifacts;
    }
  };
  var PassthroughSaver = class {
    constructor(saveHandler) {
      this.saveHandler = saveHandler;
    }
    async save(modelArtifacts) {
      return this.saveHandler(modelArtifacts);
    }
  };
  function fromMemory(modelArtifacts, weightSpecs, weightData, trainingConfig) {
    if (arguments.length === 1) {
      const isModelArtifacts = modelArtifacts.modelTopology != null || modelArtifacts.weightSpecs != null;
      if (isModelArtifacts) {
        return new PassthroughLoader(modelArtifacts);
      } else {
        console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release.");
        return new PassthroughLoader({ modelTopology: modelArtifacts });
      }
    } else {
      console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release.");
      return new PassthroughLoader({
        modelTopology: modelArtifacts,
        weightSpecs,
        weightData,
        trainingConfig
      });
    }
  }
  function withSaveHandler(saveHandler) {
    return new PassthroughSaver(saveHandler);
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/mat_mul.js
  function matMul_(a, b, transposeA = false, transposeB = false) {
    let $a = convertToTensor(a, "a", "matMul");
    let $b = convertToTensor(b, "b", "matMul");
    [$a, $b] = makeTypesMatch($a, $b);
    const inputs = { a: $a, b: $b };
    const attrs = { transposeA, transposeB };
    return ENGINE.runKernel(BatchMatMul, inputs, attrs);
  }
  var matMul = op({ matMul_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/one_hot.js
  function oneHot_(indices, depth, onValue = 1, offValue = 0) {
    if (depth < 2) {
      throw new Error(`Error in oneHot: depth must be >=2, but it is ${depth}`);
    }
    const $indices = convertToTensor(indices, "indices", "oneHot", "int32");
    const inputs = { indices: $indices };
    const attrs = { depth, onValue, offValue };
    return ENGINE.runKernel(OneHot, inputs, attrs);
  }
  var oneHot = op({ oneHot_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/transpose.js
  function transpose_(x, perm) {
    const $x = convertToTensor(x, "x", "transpose");
    if (perm == null) {
      perm = $x.shape.map((s, i) => i).reverse();
    }
    assert($x.rank === perm.length, () => `Error in transpose: rank of input ${$x.rank} must match length of perm ${perm}.`);
    perm.forEach((axis) => {
      assert(axis >= 0 && axis < $x.rank, () => `All entries in 'perm' must be between 0 and ${$x.rank - 1} but got ${perm}`);
    });
    if ($x.rank <= 1) {
      return $x.clone();
    }
    const inputs = { x: $x };
    const attrs = { perm };
    return ENGINE.runKernel(Transpose, inputs, attrs);
  }
  var transpose = op({ transpose_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd_util.js
  function prepareAndValidate(tensor2, indices) {
    const tensorRank = tensor2.shape.length;
    const indicesRank = indices.shape.length;
    if (tensorRank < 1) {
      throw new Error(`tf.gatherND() expects the input to be rank 1 or higher, but the rank was ${tensorRank}.`);
    }
    if (indicesRank < 1) {
      throw new Error(`tf.gatherND() expects the indices to be rank 1 or higher, but the rank was ${indicesRank}.`);
    }
    if (indices.dtype !== "int32") {
      throw new Error(`tf.gatherND() expects the indices to be int32 type, but the dtype was ${indices.dtype}.`);
    }
    if (indices.shape[indicesRank - 1] > tensorRank) {
      throw new Error(`index innermost dimension length must be <= tensor rank; saw: ${indices.shape[indicesRank - 1]} vs. ${tensorRank}`);
    }
    if (sizeFromShape(tensor2.shape) === 0) {
      throw new Error(`Requested more than 0 entries, but input is empty. Input shape: ${tensor2.shape}.`);
    }
    const indicesShape = indices.shape;
    const sliceRank = indicesShape[indicesShape.length - 1];
    let nResult = 1;
    for (let i = 0; i < indicesShape.length - 1; ++i) {
      nResult *= indicesShape[i];
    }
    const inputShape = tensor2.shape;
    const resultShape = indicesShape.slice();
    resultShape.pop();
    let sliceSize = 1;
    for (let i = sliceRank; i < tensorRank; ++i) {
      sliceSize *= inputShape[i];
      resultShape.push(inputShape[i]);
    }
    const strides = [
      ...computeStrides(tensor2.shape).map((stride) => stride / sliceSize),
      1
    ].slice(0, sliceRank);
    return [resultShape, nResult, sliceSize, strides];
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd_util.js
  function validateUpdateShape(shape, indices, updates) {
    const sliceDim = indices.rank > 1 ? indices.shape[indices.rank - 1] : 1;
    const batchDim = indices.rank > 1 ? indices.rank - 1 : 1;
    const shapeError = `Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: ${updates.shape}, indices.shape: ${indices.shape}, shape: ${shape}, sliceDim: ${sliceDim}, and batchDim: ${batchDim}.`;
    if (updates.rank < batchDim) {
      throw new Error(shapeError + ` update.rank < ${batchDim}. `);
    }
    if (shape.length < sliceDim + (updates.rank - batchDim)) {
      throw new Error(shapeError + ` Output shape length < ${sliceDim + (updates.rank - batchDim)}`);
    }
    if (updates.rank !== batchDim + shape.length - sliceDim) {
      throw new Error(shapeError + ` update.rank != ${batchDim + shape.length - sliceDim}`);
    }
    for (let d = 0; d < batchDim; ++d) {
      if (updates.shape[d] !== indices.shape[d]) {
        throw new Error(shapeError + ` updates.shape[${d}] (${updates.shape[d]}) != indices.shape[${d}] (${indices.shape[d]}).`);
      }
    }
    for (let d = 0; d < updates.rank - batchDim; ++d) {
      if (updates.shape[d + batchDim] !== shape[d + sliceDim]) {
        throw new Error(shapeError + ` updates.shape[${d + batchDim}] (${updates.shape[d + batchDim]}) != shape[${d + batchDim}] (${shape[d + batchDim]})`);
      }
    }
  }
  function validateInput(updates, indices, shape) {
    if (indices.rank < 1) {
      throw new Error(`tf.scatterND() expects the indices to be rank 1 or higher, but the rank was ${indices.rank}.`);
    }
    if (updates.rank < 1) {
      throw new Error(`tf.scatterND() expects the updates to be rank 1 or higher, but the rank was ${updates.rank}.`);
    }
    if (indices.dtype !== "int32") {
      throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${indices.dtype}`);
    }
    if (shape.length < 1) {
      throw new Error(`Output rank must be greater or equal to 1, but got shape: ${shape}`);
    }
    if (shape.length === 0) {
      if (indices.size === 0) {
        throw new Error(`Indices specified for empty output. indices shape: ${indices.shape}`);
      }
      if (updates.size === 0) {
        throw new Error(`Updates specified for empty output. updates shape: ${updates.shape}`);
      }
    }
    validateUpdateShape(shape, indices, updates);
  }
  function calculateShapes(updates, indices, shape) {
    const indicesRank = indices.shape.length;
    const sliceRank = indicesRank > 1 ? indices.shape[indicesRank - 1] : 1;
    const totalNd = shape.length;
    let sliceSize = 1;
    for (let i = sliceRank; i < totalNd; ++i) {
      sliceSize *= shape[i];
    }
    const safeSliceDim = sliceRank < 1 ? 1 : sliceRank;
    const numUpdates = sizeFromShape(indices.shape) / safeSliceDim;
    const strides = [...computeStrides(shape.slice(0, sliceRank)), 1];
    const outputSize = sizeFromShape(shape);
    return { sliceRank, numUpdates, sliceSize, strides, outputSize };
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/slice_util.js
  var slice_util_exports = {};
  __export(slice_util_exports, {
    assertParamsValid: () => assertParamsValid,
    computeFlatOffset: () => computeFlatOffset,
    computeOutShape: () => computeOutShape,
    getNormalizedAxes: () => getNormalizedAxes,
    isSliceContinous: () => isSliceContinous,
    maskToAxes: () => maskToAxes,
    parseSliceParams: () => parseSliceParams,
    sliceInfo: () => sliceInfo,
    startForAxis: () => startForAxis,
    startIndicesWithElidedDims: () => startIndicesWithElidedDims,
    stopForAxis: () => stopForAxis,
    stopIndicesWithElidedDims: () => stopIndicesWithElidedDims,
    stridesForAxis: () => stridesForAxis,
    stridesWithElidedDims: () => stridesWithElidedDims
  });
  var NEW_AXIS = -2;
  var SHRINK_AXIS = -1;
  function assertParamsValid(input2, begin, size2) {
    const inputRank = input2.shape.length;
    assert(inputRank === begin.length, () => `Error in slice${inputRank}D: Length of begin ${begin} must match the rank of the array (${inputRank}).`);
    assert(inputRank === size2.length, () => `Error in slice${inputRank}D: Length of size ${size2} must match the rank of the array (${inputRank}).`);
    for (let i = 0; i < inputRank; ++i) {
      assert(begin[i] + size2[i] <= input2.shape[i], () => `Error in slice${inputRank}D: begin[${i}] + size[${i}] (${begin[i] + size2[i]}) would overflow input.shape[${i}] (${input2.shape[i]})`);
    }
  }
  function maskToAxes(mask) {
    const axes = [];
    let axis = 0;
    while (mask > 0) {
      if (mask & 1) {
        axes.push(axis);
      }
      mask /= 2;
      axis++;
    }
    return axes;
  }
  function computeOutShape(begin, end, strides) {
    const size2 = [];
    for (let axis = 0; axis < begin.length; axis++) {
      size2[axis] = Math.ceil((end[axis] - begin[axis]) / strides[axis]);
    }
    return size2;
  }
  function stridesWithElidedDims(strides, ellipsisInsertionIndex, numElidedAxes, inputShape) {
    const newStrides = [...strides];
    for (let i = newStrides.length; i < inputShape.length; i++) {
      newStrides.push(1);
    }
    for (let i = 0; i < numElidedAxes; i++) {
      if (i === 0) {
        newStrides[ellipsisInsertionIndex] = 1;
      } else {
        newStrides.splice(ellipsisInsertionIndex, 0, 1);
        newStrides.pop();
      }
    }
    return newStrides;
  }
  function unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, normalizedAxis) {
    if (normalizedAxis <= ellipsisInsertionIndex) {
      return normalizedAxis;
    }
    return normalizedAxis - (numElidedAxes - 1);
  }
  function getElidedAxes(numElidedAxes, ellipsisInsertionIndex) {
    const elidedAxes = [];
    for (let i = 0; i < numElidedAxes; i++) {
      elidedAxes.push(ellipsisInsertionIndex + i);
    }
    return elidedAxes;
  }
  function getNormalizedAxes(inputShape, ellipsisAxes, numInterpolatedAxes, begin, end, strides, beginMask, endMask, ellipsisMask) {
    const inputRank = inputShape.length;
    let normalizedBegin = new Array(inputRank), normalizedEnd = new Array(inputRank), normalizedStrides = new Array(inputRank);
    if (ellipsisAxes.length && numInterpolatedAxes > 0) {
      const fullIndex = ellipsisAxes[0];
      const numElidedAxes = numInterpolatedAxes + 1;
      normalizedBegin = startIndicesWithElidedDims(beginMask, fullIndex, numElidedAxes, begin, inputShape);
      normalizedEnd = stopIndicesWithElidedDims(endMask, fullIndex, numElidedAxes, end, inputShape);
      normalizedStrides = stridesWithElidedDims(strides, fullIndex, numElidedAxes, inputShape);
    } else {
      for (let axis = 0; axis < inputRank; axis++) {
        normalizedBegin[axis] = startForAxis(beginMask, begin, strides, inputShape, axis, ellipsisMask);
        normalizedEnd[axis] = stopForAxis(endMask, end, strides, inputShape, axis, ellipsisMask);
        normalizedStrides[axis] = stridesForAxis(strides, axis, ellipsisMask);
      }
    }
    return {
      begin: normalizedBegin,
      end: normalizedEnd,
      strides: normalizedStrides
    };
  }
  function startIndicesWithElidedDims(beginMask, ellipsisInsertionIndex, numElidedAxes, originalBegin, inputShape) {
    const newIndices = [...inputShape];
    const elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);
    for (let axis = 0; axis < newIndices.length; axis++) {
      if (elidedAxes.indexOf(axis) > -1) {
        newIndices[axis] = 0;
      } else {
        const originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);
        let originalValue = originalBegin[originalAxis];
        if (beginMask & 1 << originalAxis) {
          originalValue = 0;
        }
        newIndices[axis] = originalValue;
      }
    }
    return newIndices;
  }
  function stopIndicesWithElidedDims(endMask, ellipsisInsertionIndex, numElidedAxes, originalEnd, inputShape) {
    const newIndices = [...inputShape];
    const elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);
    for (let axis = 0; axis < newIndices.length; axis++) {
      if (elidedAxes.indexOf(axis) > -1) {
        newIndices[axis] = Number.MAX_SAFE_INTEGER;
      } else {
        const originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);
        let originalValue = originalEnd[originalAxis];
        if (endMask & 1 << originalAxis) {
          originalValue = Number.MAX_SAFE_INTEGER;
        }
        newIndices[axis] = originalValue;
      }
    }
    for (let i = 0; i < newIndices.length; i++) {
      const axisSize = inputShape[i];
      if (newIndices[i] < 0) {
        newIndices[i] += axisSize;
      }
      newIndices[i] = clamp(0, newIndices[i], inputShape[i]);
    }
    return newIndices;
  }
  function stridesForAxis(strides, axis, ellipsisMask) {
    let stride = strides[axis];
    if (ellipsisMask & 1 << axis || stride == null) {
      stride = 1;
    }
    return stride;
  }
  function startForAxis(beginMask, startIndices, strides, inputShape, axis, ellipsisMask) {
    let start = startIndices[axis];
    const stride = strides[axis] || 1;
    if (beginMask & 1 << axis || ellipsisMask & 1 << axis || start == null) {
      if (stride > 0) {
        start = Number.MIN_SAFE_INTEGER;
      } else {
        start = Number.MAX_SAFE_INTEGER;
      }
    }
    const axisSize = inputShape[axis];
    if (start < 0) {
      start += axisSize;
    }
    start = clamp(0, start, axisSize - 1);
    return start;
  }
  function stopForAxis(endMask, stopIndices, strides, inputShape, axis, ellipsisMask) {
    let stop2 = stopIndices[axis];
    const stride = strides[axis] || 1;
    if (endMask & 1 << axis || ellipsisMask & 1 << axis || stop2 == null) {
      if (stride > 0) {
        stop2 = Number.MAX_SAFE_INTEGER;
      } else {
        stop2 = Number.MIN_SAFE_INTEGER;
      }
    }
    const axisSize = inputShape[axis];
    if (stop2 < 0) {
      stop2 += axisSize;
    }
    if (stride > 0) {
      stop2 = clamp(0, stop2, axisSize);
    } else {
      stop2 = clamp(-1, stop2, axisSize - 1);
    }
    return stop2;
  }
  function isSliceContinous(shape, begin, size2) {
    let firstNonOneAxis = size2.length;
    for (let i = 0; i < size2.length; i++) {
      if (size2[i] > 1) {
        firstNonOneAxis = i;
        break;
      }
    }
    for (let i = firstNonOneAxis + 1; i < size2.length; i++) {
      if (begin[i] > 0 || size2[i] !== shape[i]) {
        return false;
      }
    }
    return true;
  }
  function computeFlatOffset(begin, strides) {
    let flatOffset = begin.length > 0 ? begin[begin.length - 1] : 1;
    for (let i = 0; i < begin.length - 1; i++) {
      flatOffset += begin[i] * strides[i];
    }
    return flatOffset;
  }
  function parseSliceParams(x, begin, size2) {
    let begin_;
    const xRank = x.shape.length;
    if (typeof begin === "number") {
      begin_ = [begin, ...new Array(xRank - 1).fill(0)];
    } else if (begin.length < xRank) {
      begin_ = begin.concat(new Array(xRank - begin.length).fill(0));
    } else {
      begin_ = begin.slice();
    }
    begin_.forEach((d) => {
      assert(d !== -1, () => "slice() does not support negative begin indexing.");
    });
    let size_;
    if (size2 == null) {
      size_ = new Array(xRank).fill(-1);
    } else if (typeof size2 === "number") {
      size_ = [size2, ...new Array(xRank - 1).fill(-1)];
    } else if (size2.length < xRank) {
      size_ = size2.concat(new Array(xRank - size2.length).fill(-1));
    } else {
      size_ = size2;
    }
    size_ = size_.map((d, i) => {
      if (d >= 0) {
        return d;
      } else {
        assert(d === -1, () => `Negative size values should be exactly -1 but got ${d} for the slice() size at index ${i}.`);
        return x.shape[i] - begin_[i];
      }
    });
    return [begin_, size_];
  }
  function sliceInfo(xShape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {
    let stridesNonNull;
    if (strides == null) {
      stridesNonNull = new Array(begin.length);
      stridesNonNull.fill(1);
    } else {
      stridesNonNull = strides;
    }
    if (ellipsisMask != null && (ellipsisMask & ellipsisMask - 1) !== 0) {
      throw new Error("Multiple ellipses in slice is not allowed.");
    }
    let ellipsisSeen = false;
    const sparseSpec = {
      dims: stridesNonNull.length,
      numAddAxisAfterEllipsis: 0,
      begin: begin.slice(),
      end: end.slice(),
      strides: stridesNonNull.slice(),
      beginMask,
      endMask,
      ellipsisMask,
      newAxisMask,
      shrinkAxisMask
    };
    for (let i = 0; i < sparseSpec.dims; i++) {
      if (ellipsisSeen && (1 << i & newAxisMask) !== 0) {
        sparseSpec.numAddAxisAfterEllipsis++;
      }
      if (1 << i & ellipsisMask) {
        ellipsisSeen = true;
      }
    }
    if (!ellipsisSeen) {
      sparseSpec.ellipsisMask |= 1 << sparseSpec.dims;
      sparseSpec.dims++;
    }
    const denseSpec = {
      dims: xShape.length,
      beginMask: 0,
      endMask: 0,
      beginValid: false,
      endValid: false
    };
    buildDenseSpec(sparseSpec, denseSpec);
    let isIdentity = true;
    let sliceDim0 = true;
    let isSimpleSlice = true;
    const processingShape = [];
    const finalShape = [];
    for (let i = 0; i < xShape.length; ++i) {
      if (denseSpec.strides[i] === 0) {
        throw Error(`strides[${i}] must be non-zero`);
      }
      const shrinkI = !!(denseSpec.shrinkAxisMask & 1 << i);
      const dimI = xShape[i];
      if (dimI === -1) {
        processingShape.push(shrinkI ? 1 : -1);
        continue;
      }
      const masks = [denseSpec.beginMask & 1 << i, denseSpec.endMask & 1 << i];
      const validRange = [
        denseSpec.strides[i] > 0 ? 0 : -1,
        denseSpec.strides[i] > 0 ? dimI : dimI - 1
      ];
      if (shrinkI && denseSpec.strides[i] <= 0) {
        throw Error("only stride 1 allowed on non-range indexing.");
      }
      isSimpleSlice = isSimpleSlice && denseSpec.strides[i] === 1;
      const beginAndEndMasked = !!(denseSpec.beginMask & 1 << i && denseSpec.endMask & 1 << i);
      if (denseSpec.beginValid && denseSpec.endValid) {
        if (shrinkI) {
          const xFwd = denseSpec.begin[i] < 0 ? dimI + denseSpec.begin[i] : denseSpec.begin[i];
          denseSpec.begin[i] = xFwd;
          denseSpec.end[i] = denseSpec.begin[i] + 1;
          if (xFwd < 0 || xFwd >= dimI) {
            throw Error(`slice index ${denseSpec.begin[i]} of dimension ${i} out of bounds.`);
          }
        } else {
          denseSpec.begin[i] = canonical(denseSpec.begin[i], 0, denseSpec.strides[i], dimI, masks, validRange);
          denseSpec.end[i] = canonical(denseSpec.end[i], 1, denseSpec.strides[i], dimI, masks, validRange);
        }
        const takeAllInDimension = denseSpec.strides[i] === 1 && denseSpec.begin[i] === 0 && denseSpec.end[i] === dimI;
        isIdentity = isIdentity && takeAllInDimension;
        sliceDim0 = sliceDim0 && (i === 0 && denseSpec.strides[i] === 1 || takeAllInDimension);
      } else {
        isIdentity = isIdentity && (denseSpec.strides[i] === 1 && beginAndEndMasked);
        sliceDim0 = sliceDim0 && (i === 0 && denseSpec.strides[i] === 1 || beginAndEndMasked);
      }
      let intervalLength;
      let knownInterval = false;
      if (denseSpec.beginValid && denseSpec.endValid) {
        intervalLength = denseSpec.end[i] - denseSpec.begin[i];
        knownInterval = true;
      } else if (shrinkI) {
        intervalLength = 1;
        knownInterval = true;
      } else if (beginAndEndMasked) {
        if (dimI >= 0) {
          if (denseSpec.strides[i] < 0) {
            intervalLength = -dimI;
          } else {
            intervalLength = dimI;
          }
          knownInterval = true;
        }
      }
      if (knownInterval) {
        let sizeI;
        if (intervalLength === 0 || intervalLength < 0 !== denseSpec.strides[i] < 0) {
          sizeI = 0;
        } else {
          sizeI = Math.trunc(intervalLength / denseSpec.strides[i]) + (intervalLength % denseSpec.strides[i] !== 0 ? 1 : 0);
        }
        processingShape.push(sizeI);
      } else {
        processingShape.push(-1);
      }
    }
    for (let denseDim = 0; denseDim < denseSpec.finalShapeGatherIndices.length; ++denseDim) {
      const gatherIndex = denseSpec.finalShapeGatherIndices[denseDim];
      if (gatherIndex >= 0) {
        finalShape.push(processingShape[gatherIndex]);
      } else if (gatherIndex === NEW_AXIS) {
        finalShape.push(1);
      }
    }
    const finalShapeSparse = finalShape.filter((dim, i) => denseSpec.finalShapeGatherIndices[i] !== NEW_AXIS);
    return {
      finalShapeSparse,
      finalShape,
      isIdentity,
      sliceDim0,
      isSimpleSlice,
      begin: denseSpec.begin,
      end: denseSpec.end,
      strides: denseSpec.strides
    };
  }
  function buildDenseSpec(sparse2, dense) {
    dense.beginMask = 0;
    dense.endMask = 0;
    dense.shrinkAxisMask = 0;
    let fullIndex = 0;
    dense.beginValid = sparse2.begin != null;
    dense.endValid = sparse2.end != null;
    dense.begin = new Array(dense.dims);
    dense.end = new Array(dense.dims);
    dense.strides = new Array(dense.dims);
    dense.finalShapeGatherIndices = [];
    dense.finalShapeGatherIndicesSparse = [];
    dense.inputShapeGatherIndicesSparse = new Array(dense.dims);
    for (let i = 0; i < sparse2.dims; i++) {
      if (1 << i & sparse2.ellipsisMask) {
        const nextIndex = Math.min(dense.dims - (sparse2.dims - i) + 1 + sparse2.numAddAxisAfterEllipsis, dense.dims);
        for (; fullIndex < nextIndex; fullIndex++) {
          dense.begin[fullIndex] = 0;
          dense.end[fullIndex] = 0;
          dense.strides[fullIndex] = 1;
          dense.beginMask |= 1 << fullIndex;
          dense.endMask |= 1 << fullIndex;
          dense.finalShapeGatherIndices.push(fullIndex);
          dense.finalShapeGatherIndicesSparse.push(-1);
          dense.inputShapeGatherIndicesSparse[fullIndex] = i;
        }
      } else if (1 << i & sparse2.newAxisMask) {
        dense.finalShapeGatherIndices.push(NEW_AXIS);
        dense.finalShapeGatherIndicesSparse.push(-1);
      } else {
        if (fullIndex === dense.begin.length) {
          throw Error(`Index out of range using input dim ${fullIndex}; input has only ${dense.dims} dims, ${dense.begin.length}.`);
        }
        if (sparse2.begin != null) {
          dense.begin[fullIndex] = sparse2.begin[i];
        }
        if (sparse2.end != null) {
          dense.end[fullIndex] = sparse2.end[i];
        }
        dense.strides[fullIndex] = sparse2.strides[i];
        if (sparse2.beginMask & 1 << i) {
          dense.beginMask |= 1 << fullIndex;
        }
        if (sparse2.endMask & 1 << i) {
          dense.endMask |= 1 << fullIndex;
        }
        if (sparse2.shrinkAxisMask & 1 << i) {
          dense.finalShapeGatherIndices.push(SHRINK_AXIS);
          dense.finalShapeGatherIndicesSparse.push(-1);
          dense.shrinkAxisMask |= 1 << fullIndex;
        } else {
          dense.finalShapeGatherIndices.push(fullIndex);
          dense.finalShapeGatherIndicesSparse.push(i);
        }
        dense.inputShapeGatherIndicesSparse[fullIndex] = i;
        fullIndex++;
      }
    }
  }
  function canonical(x, c, strideI, dimI, masks, validRange) {
    if (masks[c]) {
      return strideI > 0 ? validRange[c] : validRange[c + 1 & 1];
    } else {
      const xFwd = x < 0 ? dimI + x : x;
      return xFwd < validRange[0] ? validRange[0] : xFwd > validRange[1] ? validRange[1] : xFwd;
    }
  }

  // node_modules/@tensorflow/tfjs-core/dist/serialization.js
  var serialization_exports = {};
  __export(serialization_exports, {
    Serializable: () => Serializable,
    SerializationMap: () => SerializationMap,
    registerClass: () => registerClass
  });
  var Serializable = class {
    getClassName() {
      return this.constructor.className;
    }
    static fromConfig(cls, config) {
      return new cls(config);
    }
  };
  var SerializationMap = class {
    constructor() {
      this.classNameMap = {};
    }
    static getMap() {
      if (SerializationMap.instance == null) {
        SerializationMap.instance = new SerializationMap();
      }
      return SerializationMap.instance;
    }
    static register(cls) {
      SerializationMap.getMap().classNameMap[cls.className] = [cls, cls.fromConfig];
    }
  };
  function registerClass(cls) {
    assert(cls.className != null, () => `Class being registered does not have the static className property defined.`);
    assert(typeof cls.className === "string", () => `className is required to be a string, but got type ` + typeof cls.className);
    assert(cls.className.length > 0, () => `Class being registered has an empty-string as its className, which is disallowed.`);
    SerializationMap.register(cls);
  }

  // node_modules/@tensorflow/tfjs-core/dist/globals.js
  function deprecationWarn(msg) {
    if (env().getBool("DEPRECATION_WARNINGS_ENABLED")) {
      console.warn(msg + " You can disable deprecation warnings with tf.disableDeprecationWarnings().");
    }
  }
  setDeprecationWarningFn(deprecationWarn);
  function engine() {
    return ENGINE;
  }
  function memory() {
    return ENGINE.memory();
  }
  function tidy(nameOrFn, fn) {
    return ENGINE.tidy(nameOrFn, fn);
  }
  function dispose(container) {
    const tensors = getTensorsInContainer(container);
    tensors.forEach((tensor2) => tensor2.dispose());
  }
  function keep(result) {
    return ENGINE.keep(result);
  }
  function registerBackend(name, factory, priority = 1) {
    return ENGINE.registerBackend(name, factory, priority);
  }
  function backend() {
    return ENGINE.backend;
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/add.js
  function add_(a, b) {
    let $a = convertToTensor(a, "a", "add");
    let $b = convertToTensor(b, "b", "add");
    [$a, $b] = makeTypesMatch($a, $b);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(Add, inputs);
  }
  var add3 = op({ add_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/floorDiv.js
  function floorDiv_(a, b) {
    let $a = convertToTensor(a, "a", "floorDiv");
    let $b = convertToTensor(b, "b", "floorDiv");
    [$a, $b] = makeTypesMatch($a, $b);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(FloorDiv, inputs);
  }
  var floorDiv = op({ floorDiv_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/div.js
  function div_(a, b) {
    let $a = convertToTensor(a, "a", "div");
    let $b = convertToTensor(b, "b", "div");
    [$a, $b] = makeTypesMatch($a, $b);
    if ($a.dtype === "int32" && $b.dtype === "int32") {
      return floorDiv($a, $b);
    }
    const inputs = { a: $a, b: $b };
    const attrs = {};
    return ENGINE.runKernel(RealDiv, inputs, attrs);
  }
  var div = op({ div_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/mul.js
  function mul_(a, b) {
    let $a = convertToTensor(a, "a", "mul");
    let $b = convertToTensor(b, "b", "mul");
    [$a, $b] = makeTypesMatch($a, $b);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(Multiply, inputs);
  }
  var mul = op({ mul_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/abs.js
  function abs_(x) {
    const $x = convertToTensor(x, "x", "abs");
    if ($x.dtype === "complex64") {
      const inputs = { x: $x };
      return ENGINE.runKernel(ComplexAbs, inputs);
    } else {
      const inputs = { x: $x };
      return ENGINE.runKernel(Abs, inputs);
    }
  }
  var abs = op({ abs_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/acos.js
  function acos_(x) {
    const $x = convertToTensor(x, "x", "acos");
    const inputs = { x: $x };
    return ENGINE.runKernel(Acos, inputs);
  }
  var acos = op({ acos_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/acosh.js
  function acosh_(x) {
    const $x = convertToTensor(x, "x", "acosh");
    const inputs = { x: $x };
    return ENGINE.runKernel(Acosh, inputs);
  }
  var acosh = op({ acosh_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/all.js
  function all_(x, axis = null, keepDims = false) {
    const $x = convertToTensor(x, "x", "all", "bool");
    const inputs = { x: $x };
    const attrs = { axis, keepDims };
    return ENGINE.runKernel(All, inputs, attrs);
  }
  var all = op({ all_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/any.js
  function any_(x, axis = null, keepDims = false) {
    const $x = convertToTensor(x, "x", "any", "bool");
    const inputs = { x: $x };
    const attrs = { axis, keepDims };
    return ENGINE.runKernel(Any, inputs, attrs);
  }
  var any = op({ any_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/arg_max.js
  function argMax_(x, axis = 0) {
    const $x = convertToTensor(x, "x", "argMax");
    const inputs = { x: $x };
    const attrs = { axis };
    return ENGINE.runKernel(ArgMax, inputs, attrs);
  }
  var argMax = op({ argMax_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/arg_min.js
  function argMin_(x, axis = 0) {
    const $x = convertToTensor(x, "x", "argMin");
    const inputs = { x: $x };
    const attrs = { axis };
    return ENGINE.runKernel(ArgMin, inputs, attrs);
  }
  var argMin = op({ argMin_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/asin.js
  function asin_(x) {
    const $x = convertToTensor(x, "x", "asin");
    const inputs = { x: $x };
    return ENGINE.runKernel(Asin, inputs);
  }
  var asin = op({ asin_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/asinh.js
  function asinh_(x) {
    const $x = convertToTensor(x, "x", "asinh");
    const inputs = { x: $x };
    return ENGINE.runKernel(Asinh, inputs);
  }
  var asinh = op({ asinh_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/atan.js
  function atan_(x) {
    const $x = convertToTensor(x, "x", "atan");
    const inputs = { x: $x };
    return ENGINE.runKernel(Atan, inputs);
  }
  var atan = op({ atan_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/atan2.js
  function atan2_(a, b) {
    let $a = convertToTensor(a, "a", "atan2");
    let $b = convertToTensor(b, "b", "atan2");
    [$a, $b] = makeTypesMatch($a, $b);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(Atan2, inputs);
  }
  var atan2 = op({ atan2_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/atanh.js
  function atanh_(x) {
    const $x = convertToTensor(x, "x", "atanh");
    const inputs = { x: $x };
    return ENGINE.runKernel(Atanh, inputs);
  }
  var atanh = op({ atanh_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/conv_util.js
  function computeDilation2DInfo(inputShape, filterShape, strides, pad2, dataFormat = "NHWC", dilations) {
    const inputChannels = inputShape[3];
    const $filterShape = [...filterShape, inputChannels];
    const $dataFormat = convertConv2DDataFormat(dataFormat);
    return computeConv2DInfo(inputShape, $filterShape, strides, dilations, pad2, null, null, $dataFormat);
  }
  function computePool2DInfo(inShape, filterSize, strides, dilations, pad2, roundingMode, dataFormat = "channelsLast") {
    const [filterHeight, filterWidth] = parseTupleParam(filterSize);
    let filterShape;
    if (dataFormat === "channelsLast") {
      filterShape = [filterHeight, filterWidth, inShape[3], inShape[3]];
    } else if (dataFormat === "channelsFirst") {
      filterShape = [filterHeight, filterWidth, inShape[1], inShape[1]];
    } else {
      throw new Error(`Unknown dataFormat ${dataFormat}`);
    }
    return computeConv2DInfo(inShape, filterShape, strides, dilations, pad2, roundingMode, false, dataFormat);
  }
  function computePool3DInfo(inShape, filterSize, strides, dilations, pad2, roundingMode, dataFormat = "NDHWC") {
    const [filterDepth, filterHeight, filterWidth] = parse3TupleParam(filterSize);
    let filterShape;
    let $dataFormat;
    if (dataFormat === "NDHWC") {
      $dataFormat = "channelsLast";
      filterShape = [filterDepth, filterHeight, filterWidth, inShape[4], inShape[4]];
    } else if (dataFormat === "NCDHW") {
      $dataFormat = "channelsFirst";
      filterShape = [filterDepth, filterHeight, filterWidth, inShape[1], inShape[1]];
    } else {
      throw new Error(`Unknown dataFormat ${dataFormat}`);
    }
    return computeConv3DInfo(inShape, filterShape, strides, dilations, pad2, false, $dataFormat, roundingMode);
  }
  function computeConv2DInfo(inShape, filterShape, strides, dilations, pad2, roundingMode, depthwise = false, dataFormat = "channelsLast") {
    let [batchSize, inHeight, inWidth, inChannels] = [-1, -1, -1, -1];
    if (dataFormat === "channelsLast") {
      [batchSize, inHeight, inWidth, inChannels] = inShape;
    } else if (dataFormat === "channelsFirst") {
      [batchSize, inChannels, inHeight, inWidth] = inShape;
    } else {
      throw new Error(`Unknown dataFormat ${dataFormat}`);
    }
    const [filterHeight, filterWidth, , filterChannels] = filterShape;
    const [strideHeight, strideWidth] = parseTupleParam(strides);
    const [dilationHeight, dilationWidth] = parseTupleParam(dilations);
    const effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);
    const effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);
    const { padInfo, outHeight, outWidth } = getPadAndOutInfo(pad2, inHeight, inWidth, strideHeight, strideWidth, effectiveFilterHeight, effectiveFilterWidth, roundingMode, dataFormat);
    const outChannels = depthwise ? filterChannels * inChannels : filterChannels;
    let outShape;
    if (dataFormat === "channelsFirst") {
      outShape = [batchSize, outChannels, outHeight, outWidth];
    } else if (dataFormat === "channelsLast") {
      outShape = [batchSize, outHeight, outWidth, outChannels];
    }
    return {
      batchSize,
      dataFormat,
      inHeight,
      inWidth,
      inChannels,
      outHeight,
      outWidth,
      outChannels,
      padInfo,
      strideHeight,
      strideWidth,
      filterHeight,
      filterWidth,
      effectiveFilterHeight,
      effectiveFilterWidth,
      dilationHeight,
      dilationWidth,
      inShape,
      outShape,
      filterShape
    };
  }
  function computeConv3DInfo(inShape, filterShape, strides, dilations, pad2, depthwise = false, dataFormat = "channelsLast", roundingMode) {
    let [batchSize, inDepth, inHeight, inWidth, inChannels] = [-1, -1, -1, -1, -1];
    if (dataFormat === "channelsLast") {
      [batchSize, inDepth, inHeight, inWidth, inChannels] = inShape;
    } else if (dataFormat === "channelsFirst") {
      [batchSize, inChannels, inDepth, inHeight, inWidth] = inShape;
    } else {
      throw new Error(`Unknown dataFormat ${dataFormat}`);
    }
    const [filterDepth, filterHeight, filterWidth, , filterChannels] = filterShape;
    const [strideDepth, strideHeight, strideWidth] = parse3TupleParam(strides);
    const [dilationDepth, dilationHeight, dilationWidth] = parse3TupleParam(dilations);
    const effectiveFilterDepth = getEffectiveFilterSize(filterDepth, dilationDepth);
    const effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);
    const effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);
    const { padInfo, outDepth, outHeight, outWidth } = get3DPadAndOutInfo(pad2, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, effectiveFilterDepth, effectiveFilterHeight, effectiveFilterWidth, roundingMode);
    const outChannels = depthwise ? filterChannels * inChannels : filterChannels;
    let outShape;
    if (dataFormat === "channelsFirst") {
      outShape = [batchSize, outChannels, outDepth, outHeight, outWidth];
    } else if (dataFormat === "channelsLast") {
      outShape = [batchSize, outDepth, outHeight, outWidth, outChannels];
    }
    return {
      batchSize,
      dataFormat,
      inDepth,
      inHeight,
      inWidth,
      inChannels,
      outDepth,
      outHeight,
      outWidth,
      outChannels,
      padInfo,
      strideDepth,
      strideHeight,
      strideWidth,
      filterDepth,
      filterHeight,
      filterWidth,
      effectiveFilterDepth,
      effectiveFilterHeight,
      effectiveFilterWidth,
      dilationDepth,
      dilationHeight,
      dilationWidth,
      inShape,
      outShape,
      filterShape
    };
  }
  function computeOutputShape2D(inShape, fieldSize, stride, zeroPad, roundingMode) {
    if (zeroPad == null) {
      zeroPad = computeDefaultPad(inShape, fieldSize, stride);
    }
    const inputRows = inShape[0];
    const inputCols = inShape[1];
    const outputRows = round((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
    const outputCols = round((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
    return [outputRows, outputCols];
  }
  function computeOutputShape4D(inShape, fieldSize, outChannels, stride, zeroPad, roundingMode) {
    if (zeroPad == null) {
      zeroPad = computeDefaultPad(inShape, fieldSize, stride);
    }
    const inputDepth = inShape[0];
    const inputRows = inShape[1];
    const inputCols = inShape[2];
    const outputDepths = round((inputDepth - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
    const outputRows = round((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
    const outputCols = round((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
    return [outputDepths, outputRows, outputCols, outChannels];
  }
  function computeDefaultPad(inputShape, fieldSize, stride, dilation = 1) {
    const effectiveFieldSize = getEffectiveFilterSize(fieldSize, dilation);
    return Math.floor((inputShape[0] * (stride - 1) - stride + effectiveFieldSize) / 2);
  }
  function parseTupleParam(param) {
    if (typeof param === "number") {
      return [param, param, param];
    }
    if (param.length === 2) {
      return [param[0], param[1], 1];
    }
    return param;
  }
  function parse3TupleParam(param) {
    return typeof param === "number" ? [param, param, param] : param;
  }
  function getEffectiveFilterSize(filterSize, dilation) {
    if (dilation <= 1) {
      return filterSize;
    }
    return filterSize + (filterSize - 1) * (dilation - 1);
  }
  function getPadAndOutInfo(pad2, inHeight, inWidth, strideHeight, strideWidth, filterHeight, filterWidth, roundingMode, dataFormat) {
    let padInfo;
    let outHeight;
    let outWidth;
    if (typeof pad2 === "number") {
      const padType = pad2 === 0 ? "VALID" : "NUMBER";
      padInfo = { top: pad2, bottom: pad2, left: pad2, right: pad2, type: padType };
      const outShape = computeOutputShape2D([inHeight, inWidth], filterHeight, strideHeight, pad2, roundingMode);
      outHeight = outShape[0];
      outWidth = outShape[1];
    } else if (pad2 === "same") {
      outHeight = Math.ceil(inHeight / strideHeight);
      outWidth = Math.ceil(inWidth / strideWidth);
      const padAlongHeight = Math.max(0, (outHeight - 1) * strideHeight + filterHeight - inHeight);
      const padAlongWidth = Math.max(0, (outWidth - 1) * strideWidth + filterWidth - inWidth);
      const top = Math.floor(padAlongHeight / 2);
      const bottom = padAlongHeight - top;
      const left = Math.floor(padAlongWidth / 2);
      const right = padAlongWidth - left;
      padInfo = { top, bottom, left, right, type: "SAME" };
    } else if (pad2 === "valid") {
      padInfo = { top: 0, bottom: 0, left: 0, right: 0, type: "VALID" };
      outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);
      outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);
    } else if (typeof pad2 === "object") {
      const top = dataFormat === "channelsLast" ? pad2[1][0] : pad2[2][0];
      const bottom = dataFormat === "channelsLast" ? pad2[1][1] : pad2[2][1];
      const left = dataFormat === "channelsLast" ? pad2[2][0] : pad2[3][0];
      const right = dataFormat === "channelsLast" ? pad2[2][1] : pad2[3][1];
      const padType = top === 0 && bottom === 0 && left === 0 && right === 0 ? "VALID" : "EXPLICIT";
      padInfo = { top, bottom, left, right, type: padType };
      outHeight = round((inHeight - filterHeight + top + bottom) / strideHeight + 1, roundingMode);
      outWidth = round((inWidth - filterWidth + left + right) / strideWidth + 1, roundingMode);
    } else {
      throw Error(`Unknown padding parameter: ${pad2}`);
    }
    return { padInfo, outHeight, outWidth };
  }
  function get3DPadAndOutInfo(pad2, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, filterDepth, filterHeight, filterWidth, roundingMode) {
    let padInfo;
    let outDepth;
    let outHeight;
    let outWidth;
    if (typeof pad2 === "number") {
      const padType = pad2 === 0 ? "VALID" : "NUMBER";
      padInfo = {
        top: pad2,
        bottom: pad2,
        left: pad2,
        right: pad2,
        front: pad2,
        back: pad2,
        type: padType
      };
      const outShape = computeOutputShape4D([inDepth, inHeight, inWidth, 1], filterDepth, 1, strideDepth, pad2, roundingMode);
      outDepth = outShape[0];
      outHeight = outShape[1];
      outWidth = outShape[2];
    } else if (pad2 === "same") {
      outDepth = Math.ceil(inDepth / strideDepth);
      outHeight = Math.ceil(inHeight / strideHeight);
      outWidth = Math.ceil(inWidth / strideWidth);
      const padAlongDepth = (outDepth - 1) * strideDepth + filterDepth - inDepth;
      const padAlongHeight = (outHeight - 1) * strideHeight + filterHeight - inHeight;
      const padAlongWidth = (outWidth - 1) * strideWidth + filterWidth - inWidth;
      const front = Math.floor(padAlongDepth / 2);
      const back = padAlongDepth - front;
      const top = Math.floor(padAlongHeight / 2);
      const bottom = padAlongHeight - top;
      const left = Math.floor(padAlongWidth / 2);
      const right = padAlongWidth - left;
      padInfo = { top, bottom, left, right, front, back, type: "SAME" };
    } else if (pad2 === "valid") {
      padInfo = {
        top: 0,
        bottom: 0,
        left: 0,
        right: 0,
        front: 0,
        back: 0,
        type: "VALID"
      };
      outDepth = Math.ceil((inDepth - filterDepth + 1) / strideDepth);
      outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);
      outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);
    } else {
      throw Error(`Unknown padding parameter: ${pad2}`);
    }
    return { padInfo, outDepth, outHeight, outWidth };
  }
  function round(value, roundingMode) {
    if (!roundingMode) {
      return Math.trunc(value);
    }
    switch (roundingMode) {
      case "round":
        return Math.round(value);
      case "ceil":
        return Math.ceil(value);
      case "floor":
        return Math.floor(value);
      default:
        throw new Error(`Unknown roundingMode ${roundingMode}`);
    }
  }
  function tupleValuesAreOne(param) {
    const [dimA, dimB, dimC] = parseTupleParam(param);
    return dimA === 1 && dimB === 1 && dimC === 1;
  }
  function eitherStridesOrDilationsAreOne(strides, dilations) {
    return tupleValuesAreOne(strides) || tupleValuesAreOne(dilations);
  }
  function convertConv2DDataFormat(dataFormat) {
    if (dataFormat === "NHWC") {
      return "channelsLast";
    } else if (dataFormat === "NCHW") {
      return "channelsFirst";
    } else {
      throw new Error(`Unknown dataFormat ${dataFormat}`);
    }
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/reshape.js
  function reshape_(x, shape) {
    const $x = convertToTensor(x, "x", "reshape", "string_or_numeric");
    const inputs = { x: $x };
    const attrs = { shape };
    return ENGINE.runKernel(Reshape, inputs, attrs);
  }
  var reshape = op({ reshape_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool.js
  function avgPool_(x, filterSize, strides, pad2, dimRoundingMode) {
    const $x = convertToTensor(x, "x", "avgPool", "float32");
    const dilations = 1;
    assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
    let x4D = $x;
    let reshapedTo4D = false;
    if ($x.rank === 3) {
      reshapedTo4D = true;
      x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    }
    assert(x4D.rank === 4, () => `Error in avgPool: x must be rank 4 but got rank ${x4D.rank}.`);
    if (dimRoundingMode != null) {
      assert(isInt(pad2), () => `Error in avgPool: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad2}.`);
    }
    const inputs = { x: x4D };
    const attrs = { filterSize, strides, pad: pad2, dimRoundingMode };
    let res = ENGINE.runKernel(AvgPool, inputs, attrs);
    res = cast(res, $x.dtype);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  var avgPool = op({ avgPool_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool_3d.js
  function avgPool3d_(x, filterSize, strides, pad2, dimRoundingMode, dataFormat = "NDHWC") {
    const $x = convertToTensor(x, "x", "avgPool3d", "float32");
    let x5D = $x;
    let reshapedTo5D = false;
    if ($x.rank === 4) {
      reshapedTo5D = true;
      x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
    }
    assert(x5D.rank === 5, () => `Error in avgPool3d: x must be rank 5 but got rank ${x5D.rank}.`);
    assert(dataFormat === "NDHWC", () => `Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of ${dataFormat}`);
    if (dimRoundingMode != null) {
      assert(isInt(pad2), () => `Error in avgPool3d: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad2}.`);
    }
    const inputs = { x: x5D };
    const attrs = { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat };
    let res = ENGINE.runKernel(AvgPool3D, inputs, attrs);
    res = cast(res, x5D.dtype);
    if (reshapedTo5D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
    }
    return res;
  }
  var avgPool3d = op({ avgPool3d_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/concat.js
  function concat_(tensors, axis = 0) {
    assert(tensors.length >= 1, () => "Pass at least one tensor to concat");
    const $tensors = convertToTensorArray(tensors, "tensors", "concat", "string_or_numeric");
    if ($tensors[0].dtype === "complex64") {
      $tensors.forEach((tensor2) => {
        if (tensor2.dtype !== "complex64") {
          throw new Error(`Cannot concatenate complex64 tensors with a tensor
          with dtype ${tensor2.dtype}. `);
        }
      });
    }
    if ($tensors.length === 1) {
      return clone($tensors[0]);
    }
    const inputs = $tensors;
    const attr = { axis };
    return ENGINE.runKernel(Concat, inputs, attr);
  }
  var concat = op({ concat_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sigmoid.js
  function sigmoid_(x) {
    const $x = convertToTensor(x, "x", "sigmoid", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Sigmoid, inputs);
  }
  var sigmoid = op({ sigmoid_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/slice.js
  function slice_(x, begin, size2) {
    const $x = convertToTensor(x, "x", "slice", "string_or_numeric");
    if ($x.rank === 0) {
      throw new Error("Slicing scalar is not possible");
    }
    const inputs = { x: $x };
    const attrs = { begin, size: size2 };
    return ENGINE.runKernel(Slice, inputs, attrs);
  }
  var slice = op({ slice_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/tanh.js
  function tanh_(x) {
    const $x = convertToTensor(x, "x", "tanh", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Tanh, inputs);
  }
  var tanh2 = op({ tanh_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/batch_to_space_nd.js
  function batchToSpaceND_(x, blockShape, crops) {
    const $x = convertToTensor(x, "x", "batchToSpaceND");
    const prod4 = blockShape.reduce((a, b) => a * b);
    assert($x.rank >= 1 + blockShape.length, () => `input rank is ${$x.rank} but should be > than blockShape.length ${blockShape.length}`);
    assert(crops.length === blockShape.length, () => `crops.length is ${crops.length} but should be equal to blockShape.length  ${blockShape.length}`);
    assert($x.shape[0] % prod4 === 0, () => `input tensor batch is ${$x.shape[0]} but is not divisible by the product of the elements of blockShape ${blockShape.join(" * ")} === ${prod4}`);
    const inputs = { x: $x };
    const attrs = { blockShape, crops };
    return ENGINE.runKernel(BatchToSpaceND, inputs, attrs);
  }
  var batchToSpaceND = op({ batchToSpaceND_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm_util.js
  function xAs4D(x) {
    let x4D;
    if (x.rank === 0 || x.rank === 1) {
      x4D = reshape(x, [1, 1, 1, x.size]);
    } else if (x.rank === 2) {
      x4D = reshape(x, [1, 1, x.shape[0], x.shape[1]]);
    } else if (x.rank === 3) {
      x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
    } else {
      x4D = x;
    }
    return x4D;
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm.js
  function batchNorm_(x, mean3, variance, offset, scale2, varianceEpsilon) {
    if (varianceEpsilon == null) {
      varianceEpsilon = 1e-3;
    }
    const $x = convertToTensor(x, "x", "batchNorm");
    const $mean = convertToTensor(mean3, "mean", "batchNorm");
    const $variance = convertToTensor(variance, "variance", "batchNorm");
    let $scale;
    if (scale2 != null) {
      $scale = convertToTensor(scale2, "scale", "batchNorm");
    }
    let $offset;
    if (offset != null) {
      $offset = convertToTensor(offset, "offset", "batchNorm");
    }
    assert($mean.rank === $variance.rank, () => "Batch normalization gradient requires mean and variance to have equal ranks.");
    assert($offset == null || $mean.rank === $offset.rank, () => "Batch normalization gradient requires mean and offset to have equal ranks.");
    assert($scale == null || $mean.rank === $scale.rank, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
    const x4D = xAs4D($x);
    const inputs = {
      x: x4D,
      scale: $scale,
      offset: $offset,
      mean: $mean,
      variance: $variance
    };
    const attrs = { varianceEpsilon };
    const res = ENGINE.runKernel(FusedBatchNorm, inputs, attrs);
    return reshape(res, $x.shape);
  }
  var batchNorm = op({ batchNorm_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm2d.js
  function batchNorm2d_(x, mean3, variance, offset, scale2, varianceEpsilon) {
    const $x = convertToTensor(x, "x", "batchNorm");
    const $mean = convertToTensor(mean3, "mean", "batchNorm");
    const $variance = convertToTensor(variance, "variance", "batchNorm");
    let $scale;
    if (scale2 != null) {
      $scale = convertToTensor(scale2, "scale", "batchNorm");
    }
    let $offset;
    if (offset != null) {
      $offset = convertToTensor(offset, "offset", "batchNorm");
    }
    assert($x.rank === 2, () => `Error in batchNorm2D: x must be rank 2 but got rank ${$x.rank}.`);
    assert($mean.rank === 2 || $mean.rank === 1, () => `Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ${$mean.rank}.`);
    assert($variance.rank === 2 || $variance.rank === 1, () => `Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ${$variance.rank}.`);
    if ($scale != null) {
      assert($scale.rank === 2 || $scale.rank === 1, () => `Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ${$scale.rank}.`);
    }
    if ($offset != null) {
      assert($offset.rank === 2 || $offset.rank === 1, () => `Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ${$offset.rank}.`);
    }
    return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
  }
  var batchNorm2d = op({ batchNorm2d_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm3d.js
  function batchNorm3d_(x, mean3, variance, offset, scale2, varianceEpsilon) {
    const $x = convertToTensor(x, "x", "batchNorm");
    const $mean = convertToTensor(mean3, "mean", "batchNorm");
    const $variance = convertToTensor(variance, "variance", "batchNorm");
    let $scale;
    if (scale2 != null) {
      $scale = convertToTensor(scale2, "scale", "batchNorm");
    }
    let $offset;
    if (offset != null) {
      $offset = convertToTensor(offset, "offset", "batchNorm");
    }
    assert($x.rank === 3, () => `Error in batchNorm3D: x must be rank 3 but got rank ${$x.rank}.`);
    assert($mean.rank === 3 || $mean.rank === 1, () => `Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ${$mean.rank}.`);
    assert($variance.rank === 3 || $variance.rank === 1, () => `Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ${$variance.rank}.`);
    if ($scale != null) {
      assert($scale.rank === 3 || $scale.rank === 1, () => `Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ${$scale.rank}.`);
    }
    if ($offset != null) {
      assert($offset.rank === 3 || $offset.rank === 1, () => `Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ${$offset.rank}.`);
    }
    return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
  }
  var batchNorm3d = op({ batchNorm3d_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm4d.js
  function batchNorm4d_(x, mean3, variance, offset, scale2, varianceEpsilon) {
    const $x = convertToTensor(x, "x", "batchNorm");
    const $mean = convertToTensor(mean3, "mean", "batchNorm");
    const $variance = convertToTensor(variance, "variance", "batchNorm");
    let $scale;
    if (scale2 != null) {
      $scale = convertToTensor(scale2, "scale", "batchNorm");
    }
    let $offset;
    if (offset != null) {
      $offset = convertToTensor(offset, "offset", "batchNorm");
    }
    assert($x.rank === 4, () => `Error in batchNorm4D: x must be rank 4 but got rank ${$x.rank}.`);
    assert($mean.rank === 4 || $mean.rank === 1, () => `Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ${$mean.rank}.`);
    assert($variance.rank === 4 || $variance.rank === 1, () => `Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ${$variance.rank}.`);
    if ($scale != null) {
      assert($scale.rank === 4 || $scale.rank === 1, () => `Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ${$scale.rank}.`);
    }
    if ($offset != null) {
      assert($offset.rank === 4 || $offset.rank === 1, () => `Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ${$offset.rank}.`);
    }
    return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
  }
  var batchNorm4d = op({ batchNorm4d_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/bincount.js
  function bincount_(x, weights, size2) {
    const $x = convertToTensor(x, "x", "bincount");
    const $weights = convertToTensor(weights, "weights", "bincount");
    assert($x.dtype === "int32", () => `Error in bincount: input dtype must be int32, but got ${$x.dtype}`);
    assert(size2 >= 0, () => `size must be non-negative, but got ${size2}.`);
    assert($weights.size === $x.size || $weights.size === 0, () => `Error in bincount: weights must have the same size as input or0-length, but got input shape: ${$x.shape}, weights shape: ${$weights.shape}.`);
    const inputs = { x: $x, weights: $weights };
    const attrs = { size: size2 };
    return ENGINE.runKernel(Bincount, inputs, attrs);
  }
  var bincount = op({ bincount_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_to.js
  function broadcastTo_(x, shape) {
    let input2 = convertToTensor(x, "broadcastTo", "x");
    const xShape = input2.shape;
    if (shape.some((d) => !(d > 0) || d % 1 !== 0)) {
      throw new Error(`broadcastTo(): Invalid broadcast shape [${shape}].`);
    }
    if (shape.length < input2.rank) {
      throw new Error(`broadcastTo(): shape.length=${shape.length} < input.rank=${input2.rank}.`);
    }
    if (shape.length > input2.rank) {
      const newShape = input2.shape.slice();
      while (newShape.length < shape.length) {
        newShape.unshift(1);
      }
      input2 = reshape(input2, newShape);
    }
    const inputShape = input2.shape;
    const reps = Array.from(shape);
    for (let i = shape.length - 1; i >= 0; i--) {
      if (inputShape[i] === shape[i]) {
        reps[i] = 1;
      } else if (input2.shape[i] !== 1) {
        throw new Error(`broadcastTo(): [${xShape}] cannot be broadcast to [${shape}].`);
      }
    }
    const axes = reps.map((n, i) => n > 1 ? i : -1).filter((i) => i >= 0);
    if (axes.length === 0) {
      return clone(input2);
    }
    const inputs = { x: input2 };
    const attrs = { reps };
    return ENGINE.runKernel(Tile, inputs, attrs);
  }
  var broadcastTo = op({ broadcastTo_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/ceil.js
  function ceil_(x) {
    const $x = convertToTensor(x, "x", "ceil", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Ceil, inputs);
  }
  var ceil = op({ ceil_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/clip_by_value.js
  function clipByValue_(x, clipValueMin, clipValueMax) {
    const $x = convertToTensor(x, "x", "clipByValue");
    assert(clipValueMin <= clipValueMax, () => `Error in clip: min (${clipValueMin}) must be less than or equal to max (${clipValueMax}).`);
    const inputs = { x: $x };
    const attrs = { clipValueMin, clipValueMax };
    return ENGINE.runKernel(ClipByValue, inputs, attrs);
  }
  var clipByValue = op({ clipByValue_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/concat_1d.js
  function concat1d_(tensors) {
    return concat(tensors, 0);
  }
  var concat1d = op({ concat1d_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/concat_2d.js
  function concat2d_(tensors, axis) {
    return concat(tensors, axis);
  }
  var concat2d = op({ concat2d_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/concat_3d.js
  function concat3d_(tensors, axis) {
    return concat(tensors, axis);
  }
  var concat3d = op({ concat3d_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/concat_4d.js
  function concat4d_(tensors, axis) {
    return concat(tensors, axis);
  }
  var concat4d = op({ concat4d_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/conv2d.js
  function conv2d_(x, filter, strides, pad2, dataFormat = "NHWC", dilations = [1, 1], dimRoundingMode) {
    const $x = convertToTensor(x, "x", "conv2d", "float32");
    const $filter = convertToTensor(filter, "filter", "conv2d", "float32");
    let x4D = $x;
    let reshapedTo4D = false;
    if ($x.rank === 3) {
      reshapedTo4D = true;
      x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    }
    assert(x4D.rank === 4, () => `Error in conv2d: input must be rank 4, but got rank ${x4D.rank}.`);
    assert($filter.rank === 4, () => `Error in conv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
    if (dimRoundingMode != null) {
      assert(isInt(pad2), () => `Error in conv2d: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad2}.`);
    }
    const inDepth = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
    assert(inDepth === $filter.shape[2], () => `Error in conv2d: depth of input (${inDepth}) must match input depth for filter ${$filter.shape[2]}.`);
    assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in conv2D: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
    const inputs = { x: x4D, filter: $filter };
    const attrs = { strides, pad: pad2, dataFormat, dilations, dimRoundingMode };
    const res = ENGINE.runKernel(Conv2D, inputs, attrs);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  var conv2d = op({ conv2d_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/conv1d.js
  function conv1d_(x, filter, stride, pad2, dataFormat = "NWC", dilation = 1, dimRoundingMode) {
    const $x = convertToTensor(x, "x", "conv1d");
    const $filter = convertToTensor(filter, "filter", "conv1d");
    let x3D = $x;
    let reshapedTo3D = false;
    if ($x.rank === 2) {
      reshapedTo3D = true;
      x3D = reshape($x, [1, $x.shape[0], $x.shape[1]]);
    }
    assert(x3D.rank === 3, () => `Error in conv1d: input must be rank 3, but got rank ${x3D.rank}.`);
    assert($filter.rank === 3, () => `Error in conv1d: filter must be rank 3, but got rank ${$filter.rank}.`);
    if (dimRoundingMode != null) {
      assert(isInt(pad2), () => `Error in conv1d: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad2}.`);
    }
    assert(x3D.shape[2] === $filter.shape[1], () => `Error in conv1d: depth of input (${x3D.shape[2]}) must match input depth for filter ${$filter.shape[1]}.`);
    assert(eitherStridesOrDilationsAreOne(stride, dilation), () => `Error in conv1D: Either stride or dilation must be 1. Got stride ${stride} and dilation '${dilation}'`);
    assert(dataFormat === "NWC", () => `Error in conv1d: got dataFormat of ${dataFormat} but only NWC is currently supported.`);
    const filter4D = reshape($filter, [1, $filter.shape[0], $filter.shape[1], $filter.shape[2]]);
    const input4D = reshape(x3D, [x3D.shape[0], 1, x3D.shape[1], x3D.shape[2]]);
    const strides = [1, stride];
    const dilations = [1, dilation];
    const conv2dDataFormat = "NHWC";
    const res = conv2d(input4D, filter4D, strides, pad2, conv2dDataFormat, dilations, dimRoundingMode);
    if (reshapedTo3D) {
      return reshape(res, [res.shape[2], res.shape[3]]);
    }
    return reshape(res, [res.shape[0], res.shape[2], res.shape[3]]);
  }
  var conv1d = op({ conv1d_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_input.js
  function conv2DBackpropInput_(xShape, dy, filter, strides, pad2, dataFormat = "NHWC", dimRoundingMode) {
    assert(xShape.length === dy.rank, () => `Length of inShape (${xShape.length}) and rank of dy (${dy.rank}) must match`);
    let xShape4D = xShape;
    let dy4D = dy;
    let reshapedTo4D = false;
    if (dy.rank === 3) {
      reshapedTo4D = true;
      dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
      xShape4D = [1, xShape[0], xShape[1], xShape[2]];
    }
    assert(xShape4D.length === 4, () => `Error in conv2dDerInput: inShape must be length 4, but got length ${xShape4D.length}.`);
    assert(dy4D.rank === 4, () => `Error in conv2dDerInput: dy must be rank 4, but got rank ${dy4D.rank}`);
    assert(filter.rank === 4, () => `Error in conv2dDerInput: filter must be rank 4, but got rank ${filter.rank}`);
    const inDepth = dataFormat === "NHWC" ? xShape4D[3] : xShape4D[1];
    const outDepth = dataFormat === "NHWC" ? dy4D.shape[3] : dy4D.shape[1];
    assert(inDepth === filter.shape[2], () => `Error in conv2dDerInput: depth of input (${inDepth}) must match input depth for filter ${filter.shape[2]}.`);
    assert(outDepth === filter.shape[3], () => `Error in conv2dDerInput: depth of output (${outDepth}) must match output depth for filter ${filter.shape[3]}.`);
    if (dimRoundingMode != null) {
      assert(isInt(pad2), () => `Error in conv2dDerInput: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad2}.`);
    }
    const inputs = { dy: dy4D, filter };
    const attrs = { strides, pad: pad2, dataFormat, dimRoundingMode, inputShape: xShape4D };
    const res = ENGINE.runKernel(Conv2DBackpropInput, inputs, attrs);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  var conv2DBackpropInput = op({ conv2DBackpropInput_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_transpose.js
  function conv2dTranspose_(x, filter, outputShape, strides, pad2, dimRoundingMode) {
    const $x = convertToTensor(x, "x", "conv2dTranspose");
    const $filter = convertToTensor(filter, "filter", "conv2dTranspose");
    return conv2DBackpropInput(outputShape, $x, $filter, strides, pad2, "NHWC", dimRoundingMode);
  }
  var conv2dTranspose = op({ conv2dTranspose_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/conv3d.js
  function conv3d_(x, filter, strides, pad2, dataFormat = "NDHWC", dilations = [1, 1, 1]) {
    const $x = convertToTensor(x, "x", "conv3d");
    const $filter = convertToTensor(filter, "filter", "conv3d");
    let x5D = $x;
    let reshapedTo5D = false;
    if ($x.rank === 4) {
      reshapedTo5D = true;
      x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
    }
    assert(x5D.rank === 5, () => `Error in conv3d: input must be rank 5, but got rank ${x5D.rank}.`);
    assert($filter.rank === 5, () => `Error in conv3d: filter must be rank 5, but got rank ${$filter.rank}.`);
    assert(x5D.shape[4] === $filter.shape[3], () => `Error in conv3d: depth of input (${x5D.shape[4]}) must match input depth for filter ${$filter.shape[3]}.`);
    assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in conv3D: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
    assert(dataFormat === "NDHWC", () => `Error in conv3d: got dataFormat of ${dataFormat} but only NDHWC is currently supported.`);
    const inputs = { x: x5D, filter: $filter };
    const attrs = { strides, pad: pad2, dataFormat, dilations };
    const res = ENGINE.runKernel(Conv3D, inputs, attrs);
    if (reshapedTo5D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
    }
    return res;
  }
  var conv3d = op({ conv3d_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_backprop_input.js
  function conv3DBackpropInput_(xShape, dy, filter, strides, pad2) {
    assert(xShape.length === dy.rank, () => `Length of inShape (${xShape.length}) and rank of dy (${dy.rank}) must match`);
    let xShape5D = xShape;
    let dy5D = dy;
    let reshapedTo5D = false;
    if (dy.rank === 4) {
      reshapedTo5D = true;
      dy5D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);
      xShape5D = [1, xShape[0], xShape[1], xShape[2], xShape[3]];
    }
    const inDepth = xShape5D[4];
    const outDepth = dy5D.shape[4];
    assert(xShape5D.length === 5, () => `Error in conv3dDerInput: inShape must be length 5, but got length ${xShape5D.length}.`);
    assert(dy5D.rank === 5, () => `Error in conv3dDerInput: dy must be rank 5, but got rank ${dy5D.rank}`);
    assert(filter.rank === 5, () => `Error in conv3dDerInput: filter must be rank 5, but got rank ${filter.rank}`);
    assert(inDepth === filter.shape[3], () => `Error in conv3dDerInput: depth of input (${inDepth}) must match input depth for filter ${filter.shape[3]}.`);
    assert(outDepth === filter.shape[4], () => `Error in conv3dDerInput: depth of output (${outDepth}) must match output depth for filter ${filter.shape[4]}.`);
    const inputs = { dy: dy5D, filter };
    const attrs = { pad: pad2, strides, inputShape: xShape5D };
    const res = ENGINE.runKernel(Conv3DBackpropInputV2, inputs, attrs);
    if (reshapedTo5D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
    }
    return res;
  }
  var conv3DBackpropInput = op({ conv3DBackpropInput_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_transpose.js
  function conv3dTranspose_(x, filter, outputShape, strides, pad2) {
    const $x = convertToTensor(x, "x", "conv3dTranspose");
    const $filter = convertToTensor(filter, "filter", "conv3dTranspose");
    return conv3DBackpropInput(outputShape, $x, $filter, strides, pad2);
  }
  var conv3dTranspose = op({ conv3dTranspose_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/cos.js
  function cos_(x) {
    const $x = convertToTensor(x, "x", "cos", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Cos, inputs);
  }
  var cos = op({ cos_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/cosh.js
  function cosh_(x) {
    const $x = convertToTensor(x, "x", "cosh", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Cosh, inputs);
  }
  var cosh = op({ cosh_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/cumsum.js
  function cumsum_(x, axis = 0, exclusive = false, reverse4 = false) {
    const $x = convertToTensor(x, "x", "cumsum");
    const inputs = { x: $x };
    const attrs = { axis, exclusive, reverse: reverse4 };
    return ENGINE.runKernel(Cumsum, inputs, attrs);
  }
  var cumsum = op({ cumsum_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/depth_to_space.js
  function depthToSpace_(x, blockSize, dataFormat = "NHWC") {
    const $x = convertToTensor(x, "x", "depthToSpace", "float32");
    const inputHeight = dataFormat === "NHWC" ? $x.shape[1] : $x.shape[2];
    const inputWidth = dataFormat === "NHWC" ? $x.shape[2] : $x.shape[3];
    const inputDepth = dataFormat === "NHWC" ? $x.shape[3] : $x.shape[1];
    assert(blockSize > 1, () => `blockSize should be > 1 for depthToSpace, but was: ${blockSize}`);
    assert(inputHeight * blockSize >= 0, () => `Negative dimension size caused by overflow when multiplying
    ${inputHeight} and ${blockSize}  for depthToSpace with input shape
    ${$x.shape}`);
    assert(inputWidth * blockSize >= 0, () => `Negative dimension size caused by overflow when multiplying
    ${inputWidth} and ${blockSize} for depthToSpace with input shape
        ${$x.shape}`);
    assert(inputDepth % (blockSize * blockSize) === 0, () => `Dimension size must be evenly divisible by ${blockSize * blockSize} but is ${inputDepth} for depthToSpace with input shape ${$x.shape}`);
    const inputs = { x: $x };
    const attrs = { blockSize, dataFormat };
    return ENGINE.runKernel(DepthToSpace, inputs, attrs);
  }
  var depthToSpace = op({ depthToSpace_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d.js
  function depthwiseConv2d_(x, filter, strides, pad2, dataFormat = "NHWC", dilations = [1, 1], dimRoundingMode) {
    const $x = convertToTensor(x, "x", "depthwiseConv2d", "float32");
    const $filter = convertToTensor(filter, "filter", "depthwiseConv2d", "float32");
    let x4D = $x;
    let reshapedTo4D = false;
    if ($x.rank === 3) {
      reshapedTo4D = true;
      x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    }
    assert(x4D.rank === 4, () => `Error in depthwiseConv2d: input must be rank 4, but got rank ${x4D.rank}.`);
    assert($filter.rank === 4, () => `Error in depthwiseConv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
    assert(x4D.shape[3] === $filter.shape[2], () => `Error in depthwiseConv2d: number of input channels (${x4D.shape[3]}) must match the inChannels dimension in filter ${$filter.shape[2]}.`);
    if (dimRoundingMode != null) {
      assert(isInt(pad2), () => `Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad2}.`);
    }
    const inputs = { x: x4D, filter: $filter };
    const attrs = { strides, pad: pad2, dataFormat, dilations, dimRoundingMode };
    const res = ENGINE.runKernel(DepthwiseConv2dNative, inputs, attrs);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  var depthwiseConv2d = op({ depthwiseConv2d_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/dilation2d.js
  function dilation2d_(x, filter, strides, pad2, dilations = [1, 1], dataFormat = "NHWC") {
    const $x = convertToTensor(x, "x", "dilation2d");
    const $filter = convertToTensor(filter, "filter", "dilation2d");
    assert($x.rank === 3 || $x.rank === 4, () => `Error in dilation2d: input must be rank 3 or 4, but got rank ${$x.rank}.`);
    assert($filter.rank === 3, () => `Error in dilation2d: filter must be rank 3, but got rank ${$filter.rank}.`);
    assert(dataFormat === "NHWC", () => `Error in dilation2d: Only NHWC is currently supported, but got dataFormat of ${dataFormat}`);
    let x4D = $x;
    let reshapedTo4D = false;
    if ($x.rank === 3) {
      x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      reshapedTo4D = true;
    }
    const inputs = { x: x4D, filter: $filter };
    const attrs = { strides, pad: pad2, dilations };
    const res = ENGINE.runKernel(Dilation2D, inputs, attrs);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  var dilation2d = op({ dilation2d_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js
  function getBroadcastDims(inShape, outShape) {
    const inRank = inShape.length;
    const dims = [];
    for (let i = 0; i < inRank; i++) {
      const dim = inRank - 1 - i;
      const a = inShape[dim] || 1;
      const b = outShape[outShape.length - 1 - i] || 1;
      if (b > 1 && a === 1) {
        dims.unshift(dim);
      }
    }
    return dims;
  }
  function getReductionAxes(inShape, outShape) {
    const result = [];
    for (let i = 0; i < outShape.length; i++) {
      const inDim = inShape[inShape.length - i - 1];
      const outAxis = outShape.length - i - 1;
      const outDim = outShape[outAxis];
      if (inDim == null || inDim === 1 && outDim > 1) {
        result.unshift(outAxis);
      }
    }
    return result;
  }
  function assertAndGetBroadcastShape(shapeA, shapeB) {
    const result = [];
    const l = Math.max(shapeA.length, shapeB.length);
    for (let i = 0; i < l; i++) {
      let a = shapeA[shapeA.length - i - 1];
      if (a == null) {
        a = 1;
      }
      let b = shapeB[shapeB.length - i - 1];
      if (b == null) {
        b = 1;
      }
      if (a === 1) {
        result.unshift(b);
      } else if (b === 1) {
        result.unshift(a);
      } else if (a !== b) {
        const errMsg = `Operands could not be broadcast together with shapes ${shapeA} and ${shapeB}.`;
        throw Error(errMsg);
      } else {
        result.unshift(a);
      }
    }
    return result;
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/equal.js
  function equal_(a, b) {
    let $a = convertToTensor(a, "a", "equal", "string_or_numeric");
    let $b = convertToTensor(b, "b", "equal", "string_or_numeric");
    [$a, $b] = makeTypesMatch($a, $b);
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(Equal, inputs);
  }
  var equal = op({ equal_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/where.js
  function where_(condition, a, b) {
    const $a = convertToTensor(a, "a", "where");
    const $b = convertToTensor(b, "b", "where");
    const $condition = convertToTensor(condition, "condition", "where", "bool");
    const broadcastShape = assertAndGetBroadcastShape(assertAndGetBroadcastShape($condition.shape, $a.shape), $b.shape);
    const $broadcastedCondition = broadcastTo($condition, broadcastShape);
    const $broadcastedA = broadcastTo($a, broadcastShape);
    const $broadcastedB = broadcastTo($b, broadcastShape);
    const inputs = {
      condition: $broadcastedCondition,
      t: $broadcastedA,
      e: $broadcastedB
    };
    return ENGINE.runKernel(Select, inputs);
  }
  var where = op({ where_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/zeros_like.js
  function zerosLike_(x) {
    const $x = convertToTensor(x, "x", "zerosLike");
    const inputs = { x: $x };
    return ENGINE.runKernel(ZerosLike, inputs);
  }
  var zerosLike = op({ zerosLike_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/div_no_nan.js
  function divNoNan_(a, b) {
    let $a = convertToTensor(a, "a", "div");
    let $b = convertToTensor(b, "b", "div");
    [$a, $b] = makeTypesMatch($a, $b);
    const divResult = div($a, $b);
    const zeros3 = zerosLike(divResult);
    const bEqualsZero = equal($b, zeros3);
    return where(bEqualsZero, zeros3, divResult);
  }
  var divNoNan = op({ divNoNan_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/dot.js
  function dot_(t1, t2) {
    const $t1 = convertToTensor(t1, "t1", "dot");
    const $t2 = convertToTensor(t2, "t2", "dot");
    assert(($t1.rank === 1 || $t1.rank === 2) && ($t2.rank === 1 || $t2.rank === 2), () => `Error in dot: inputs must all be rank 1 or 2, but got ranks ${$t1.rank} and ${$t2.rank}.`);
    const t1Inner = $t1.rank === 1 ? $t1.size : $t1.shape[1];
    const t2Inner = $t2.rank === 1 ? $t2.size : $t2.shape[0];
    assert(t1Inner === t2Inner, () => `Error in dot: inner dimensions of inputs must match, but got ${t1Inner} and ${t2Inner}.`);
    if ($t1.rank === 1 && $t2.rank === 1) {
      const t12D = reshape($t1, [1, -1]);
      const t22D = reshape($t2, [-1, 1]);
      const t1t2 = matMul(t12D, t22D);
      return reshape(t1t2, []);
    } else if ($t1.rank === 1 && $t2.rank === 2) {
      const t12D = reshape($t1, [1, -1]);
      const t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);
      const t1t2 = matMul(t12D, t22D);
      return reshape(t1t2, [t1t2.size]);
    } else if ($t1.rank === 2 && $t2.rank === 1) {
      const t22D = reshape($t2, [-1, 1]);
      const t1t2 = matMul($t1, t22D);
      return reshape(t1t2, [t1t2.size]);
    } else {
      const t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);
      const t1t2 = matMul($t1, t22D);
      return t1t2;
    }
  }
  var dot = op({ dot_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/elu.js
  function elu_(x) {
    const $x = convertToTensor(x, "x", "elu", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Elu, inputs);
  }
  var elu = op({ elu_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/erf.js
  function erf_(x) {
    let $x = convertToTensor(x, "x", "erf");
    assert($x.dtype === "int32" || $x.dtype === "float32", () => "Input dtype must be `int32` or `float32`.");
    if ($x.dtype === "int32") {
      $x = cast($x, "float32");
    }
    const inputs = { x: $x };
    return ENGINE.runKernel(Erf, inputs);
  }
  var erf = op({ erf_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/exp.js
  function exp_(x) {
    const $x = convertToTensor(x, "x", "exp");
    const inputs = { x: $x };
    return ENGINE.runKernel(Exp, inputs);
  }
  var exp = op({ exp_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/expand_dims.js
  function expandDims_(x, axis = 0) {
    const $x = convertToTensor(x, "x", "expandDims", "string_or_numeric");
    assert(axis <= $x.rank, () => "Axis must be <= rank of the tensor");
    const inputs = { input: $x };
    const attrs = { dim: axis };
    return ENGINE.runKernel(ExpandDims, inputs, attrs);
  }
  var expandDims = op({ expandDims_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/expm1.js
  function expm1_(x) {
    const $x = convertToTensor(x, "x", "expm1");
    const inputs = { x: $x };
    return ENGINE.runKernel(Expm1, inputs);
  }
  var expm1 = op({ expm1_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/tile.js
  function tile_(x, reps) {
    const $x = convertToTensor(x, "x", "tile", "string_or_numeric");
    assert($x.rank === reps.length, () => `Error in transpose: rank of input ${$x.rank} must match length of reps ${reps}.`);
    const inputs = { x: $x };
    const attrs = { reps };
    return ENGINE.runKernel(Tile, inputs, attrs);
  }
  var tile = op({ tile_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/eye.js
  function eye_(numRows, numColumns, batchShape, dtype = "float32") {
    if (numColumns == null) {
      numColumns = numRows;
    }
    const buff = buffer2([numRows, numColumns], dtype);
    const n = numRows <= numColumns ? numRows : numColumns;
    for (let i = 0; i < n; ++i) {
      buff.set(1, i, i);
    }
    const out = reshape(buff.toTensor(), [numRows, numColumns]);
    if (batchShape == null) {
      return out;
    } else {
      if (batchShape.length === 1) {
        return tile(expandDims(out, 0), [batchShape[0], 1, 1]);
      } else if (batchShape.length === 2) {
        return tile(expandDims(expandDims(out, 0), 0), [batchShape[0], batchShape[1], 1, 1]);
      } else if (batchShape.length === 3) {
        return tile(expandDims(expandDims(expandDims(out, 0), 0), 0), [
          batchShape[0],
          batchShape[1],
          batchShape[2],
          1,
          1
        ]);
      } else {
        throw new Error(`eye() currently supports only 1D and 2D batchShapes, but received ${batchShape.length}D.`);
      }
    }
  }
  var eye = op({ eye_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/fill.js
  function fill(shape, value, dtype) {
    const attrs = { shape, value, dtype };
    return ENGINE.runKernel(Fill, {}, attrs);
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/floor.js
  function floor_(x) {
    const $x = convertToTensor(x, "x", "floor", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Floor, inputs);
  }
  var floor = op({ floor_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/gather.js
  function gather_(x, indices, axis = 0, batchDims = 0) {
    const $x = convertToTensor(x, "x", "gather");
    const $indices = convertToTensor(indices, "indices", "gather", "int32");
    const inputs = { x: $x, indices: $indices };
    const attrs = { axis, batchDims };
    return ENGINE.runKernel(GatherV2, inputs, attrs);
  }
  var gather = op({ gather_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/greater.js
  function greater_(a, b) {
    let $a = convertToTensor(a, "a", "greater", "string_or_numeric");
    let $b = convertToTensor(b, "b", "greater", "string_or_numeric");
    [$a, $b] = makeTypesMatch($a, $b);
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(Greater, inputs);
  }
  var greater = op({ greater_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/greater_equal.js
  function greaterEqual_(a, b) {
    let $a = convertToTensor(a, "a", "greaterEqual", "string_or_numeric");
    let $b = convertToTensor(b, "b", "greaterEqual", "string_or_numeric");
    [$a, $b] = makeTypesMatch($a, $b);
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(GreaterEqual, inputs);
  }
  var greaterEqual = op({ greaterEqual_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/imag.js
  function imag_(input2) {
    const $input = convertToTensor(input2, "input", "imag");
    const inputs = { input: $input };
    return ENGINE.runKernel(Imag, inputs);
  }
  var imag = op({ imag_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/is_finite.js
  function isFinite_(x) {
    const $x = convertToTensor(x, "x", "isFinite");
    const inputs = { x: $x };
    return ENGINE.runKernel(IsFinite, inputs);
  }
  var isFinite2 = op({ isFinite_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/is_inf.js
  function isInf_(x) {
    const $x = convertToTensor(x, "x", "isInf");
    const inputs = { x: $x };
    return ENGINE.runKernel(IsInf, inputs);
  }
  var isInf = op({ isInf_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/is_nan.js
  function isNaN_(x) {
    const $x = convertToTensor(x, "x", "isNaN");
    const inputs = { x: $x };
    return ENGINE.runKernel(IsNan, inputs);
  }
  var isNaN2 = op({ isNaN_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/leaky_relu.js
  function leakyRelu_(x, alpha = 0.2) {
    const $x = convertToTensor(x, "x", "leakyRelu");
    const inputs = { x: $x };
    const attrs = { alpha };
    return ENGINE.runKernel(LeakyRelu, inputs, attrs);
  }
  var leakyRelu = op({ leakyRelu_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/less.js
  function less_(a, b) {
    let $a = convertToTensor(a, "a", "less", "string_or_numeric");
    let $b = convertToTensor(b, "b", "less", "string_or_numeric");
    [$a, $b] = makeTypesMatch($a, $b);
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(Less, inputs);
  }
  var less = op({ less_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/less_equal.js
  function lessEqual_(a, b) {
    let $a = convertToTensor(a, "a", "lessEqual", "string_or_numeric");
    let $b = convertToTensor(b, "b", "lessEqual", "string_or_numeric");
    [$a, $b] = makeTypesMatch($a, $b);
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(LessEqual, inputs);
  }
  var lessEqual = op({ lessEqual_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/local_response_normalization.js
  function localResponseNormalization_(x, depthRadius = 5, bias = 1, alpha = 1, beta = 0.5) {
    const $x = convertToTensor(x, "x", "localResponseNormalization");
    assert($x.rank === 4 || $x.rank === 3, () => `Error in localResponseNormalization: x must be rank 3 or 4 but got
               rank ${$x.rank}.`);
    assert(isInt(depthRadius), () => `Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ${depthRadius}.`);
    let x4D = $x;
    let reshapedTo4D = false;
    if ($x.rank === 3) {
      reshapedTo4D = true;
      x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    }
    const inputs = { x: x4D };
    const attrs = { depthRadius, bias, alpha, beta };
    const res = ENGINE.runKernel(LRN, inputs, attrs);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    } else {
      return res;
    }
  }
  var localResponseNormalization = op({ localResponseNormalization_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/log.js
  function log_(x) {
    const $x = convertToTensor(x, "x", "log", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Log, inputs);
  }
  var log5 = op({ log_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/log1p.js
  function log1p_(x) {
    const $x = convertToTensor(x, "x", "log1p");
    const inputs = { x: $x };
    return ENGINE.runKernel(Log1p, inputs);
  }
  var log1p = op({ log1p_ });

  // node_modules/@tensorflow/tfjs-core/dist/gradients.js
  function variableGrads(f, varList) {
    assert(isFunction2(f), () => "The f passed in variableGrads(f) must be a function");
    assert(varList == null || Array.isArray(varList) && varList.every((v) => v instanceof Variable), () => "The varList passed in variableGrads(f, varList) must be an array of variables");
    const specifiedVarList = varList != null;
    if (!specifiedVarList) {
      varList = [];
      for (const varName in ENGINE.registeredVariables) {
        varList.push(ENGINE.registeredVariables[varName]);
      }
    }
    const specifiedNonTrainable = specifiedVarList ? varList.filter((variable2) => !variable2.trainable) : null;
    const originalVarCount = varList.length;
    varList = varList.filter((variable2) => variable2.trainable);
    assert(varList.length > 0, () => `variableGrads() expects at least one of the input variables to be trainable, but none of the ${originalVarCount} variables is trainable.`);
    const allowNoGradients = true;
    const { value, grads } = ENGINE.gradients(f, varList, null, allowNoGradients);
    assert(grads.some((g) => g != null), () => "Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize().");
    assert(value.rank === 0, () => `The f passed in variableGrads(f) must return a scalar, but it returned a rank-${value.rank} tensor`);
    const namedGrads = {};
    varList.forEach((v, i) => {
      if (grads[i] != null) {
        namedGrads[v.name] = grads[i];
      }
    });
    if (specifiedNonTrainable != null) {
      specifiedNonTrainable.forEach((v) => namedGrads[v.name] = null);
    }
    return { value, grads: namedGrads };
  }
  function customGrad(f) {
    return ENGINE.customGrad(f);
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/neg.js
  function neg_(x) {
    const $x = convertToTensor(x, "x", "neg");
    const inputs = { x: $x };
    return ENGINE.runKernel(Neg, inputs);
  }
  var neg = op({ neg_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/softplus.js
  function softplus_(x) {
    const $x = convertToTensor(x, "x", "softplus");
    const inputs = { x: $x };
    return ENGINE.runKernel(Softplus, inputs);
  }
  var softplus = op({ softplus_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/log_sigmoid.js
  function logSigmoid_(x) {
    const $x = convertToTensor(x, "x", "logSigmoid");
    const customOp = customGrad((x2) => {
      const value = neg(softplus(neg(x2)));
      const gradFunc = (dy) => {
        const derX = mul(dy, sigmoid(neg(x2)));
        return derX;
      };
      return { value, gradFunc };
    });
    return customOp($x);
  }
  var logSigmoid = op({ logSigmoid_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/max.js
  function max_(x, axis = null, keepDims = false) {
    const $x = convertToTensor(x, "x", "max");
    const inputs = { x: $x };
    const attrs = { reductionIndices: axis, keepDims };
    return ENGINE.runKernel(Max, inputs, attrs);
  }
  var max = op({ max_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sub.js
  function sub_(a, b) {
    let $a = convertToTensor(a, "a", "sub");
    let $b = convertToTensor(b, "b", "sub");
    [$a, $b] = makeTypesMatch($a, $b);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(Sub, inputs);
  }
  var sub = op({ sub_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sum.js
  function sum_(x, axis = null, keepDims = false) {
    let $x = convertToTensor(x, "x", "sum");
    if ($x.dtype === "bool") {
      $x = cast($x, "int32");
    }
    const inputs = { x: $x };
    const attrs = { axis, keepDims };
    return ENGINE.runKernel(Sum, inputs, attrs);
  }
  var sum2 = op({ sum_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/log_softmax.js
  function logSoftmax_(logits, axis = -1) {
    const $logits = convertToTensor(logits, "logits", "logSoftmax");
    if (axis === -1) {
      axis = $logits.rank - 1;
    }
    if (axis !== $logits.rank - 1) {
      throw Error(`Log Softmax along a non-last dimension is not yet supported. Logits was rank ${$logits.rank} and axis was ${axis}`);
    }
    const customOp = customGrad((logits2, save) => {
      const keepDims = true;
      const xMax = max(logits2, axis, true);
      const shifted = sub(logits2, xMax);
      const value = sub(cast(shifted, "float32"), log5(sum2(exp(shifted), axis, keepDims)));
      save([value]);
      const gradFunc = (dy, saved) => {
        const [value2] = saved;
        const keepDims2 = true;
        const softmax4 = exp(value2);
        return sub(dy, mul(sum2(dy, axis, keepDims2), softmax4));
      };
      return { value, gradFunc };
    });
    return customOp($logits);
  }
  var logSoftmax = op({ logSoftmax_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js
  function axesAreInnerMostDims(axes, rank) {
    for (let i = 0; i < axes.length; ++i) {
      if (axes[axes.length - i - 1] !== rank - 1 - i) {
        return false;
      }
    }
    return true;
  }
  function combineLocations(outputLoc, reduceLoc, axes) {
    const rank = outputLoc.length + reduceLoc.length;
    const loc = [];
    let outIdx = 0;
    let reduceIdx = 0;
    for (let dim = 0; dim < rank; dim++) {
      if (axes.indexOf(dim) === -1) {
        loc.push(outputLoc[outIdx++]);
      } else {
        loc.push(reduceLoc[reduceIdx++]);
      }
    }
    return loc;
  }
  function computeOutAndReduceShapes(aShape, axes) {
    const outShape = [];
    const rank = aShape.length;
    for (let dim = 0; dim < rank; dim++) {
      if (axes.indexOf(dim) === -1) {
        outShape.push(aShape[dim]);
      }
    }
    const reduceShape = axes.map((dim) => aShape[dim]);
    return [outShape, reduceShape];
  }
  function expandShapeToKeepDim(shape, axes) {
    const reduceSubShape = axes.map((x) => 1);
    return combineLocations(shape, reduceSubShape, axes);
  }
  function assertAxesAreInnerMostDims(msg, axes, rank) {
    assert(axesAreInnerMostDims(axes, rank), () => `${msg} supports only inner-most axes for now. Got axes ${axes} and rank-${rank} input.`);
  }
  function getAxesPermutation(axes, rank) {
    if (axesAreInnerMostDims(axes, rank)) {
      return null;
    }
    const result = [];
    for (let i = 0; i < rank; ++i) {
      if (axes.indexOf(i) === -1) {
        result.push(i);
      }
    }
    axes.forEach((axis) => result.push(axis));
    return result;
  }
  function getUndoAxesPermutation(axes) {
    return axes.map((axis, i) => [i, axis]).sort((a, b) => a[1] - b[1]).map((x) => x[0]);
  }
  function getInnerMostAxes(numAxes, rank) {
    const res = [];
    for (let i = rank - numAxes; i < rank; ++i) {
      res.push(i);
    }
    return res;
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/log_sum_exp.js
  function logSumExp_(x, axis = null, keepDims = false) {
    const $x = convertToTensor(x, "x", "logSumExp");
    const axes = parseAxisParam(axis, $x.shape);
    const xMax = max($x, axes, true);
    const a = sub($x, xMax);
    const b = exp(a);
    const c = sum2(b, axes);
    const d = log5(c);
    const res = add3(reshape(xMax, d.shape), d);
    if (keepDims) {
      const newShape = expandShapeToKeepDim(res.shape, axes);
      return reshape(res, newShape);
    }
    return res;
  }
  var logSumExp = op({ logSumExp_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/logical_and.js
  function logicalAnd_(a, b) {
    const $a = convertToTensor(a, "a", "logicalAnd", "bool");
    const $b = convertToTensor(b, "b", "logicalAnd", "bool");
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(LogicalAnd, inputs);
  }
  var logicalAnd = op({ logicalAnd_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/logical_not.js
  function logicalNot_(x) {
    const $x = convertToTensor(x, "x", "logicalNot", "bool");
    const inputs = { x: $x };
    return ENGINE.runKernel(LogicalNot, inputs);
  }
  var logicalNot = op({ logicalNot_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/logical_or.js
  function logicalOr_(a, b) {
    const $a = convertToTensor(a, "a", "logicalOr", "bool");
    const $b = convertToTensor(b, "b", "logicalOr", "bool");
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(LogicalOr, inputs);
  }
  var logicalOr = op({ logicalOr_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/logical_xor.js
  function logicalXor_(a, b) {
    const $a = convertToTensor(a, "a", "logicalXor", "bool");
    const $b = convertToTensor(b, "b", "logicalXor", "bool");
    assertAndGetBroadcastShape($a.shape, $b.shape);
    return logicalAnd(logicalOr(a, b), logicalNot(logicalAnd(a, b)));
  }
  var logicalXor = op({ logicalXor_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/max_pool.js
  function maxPool_(x, filterSize, strides, pad2, dimRoundingMode) {
    const $x = convertToTensor(x, "x", "maxPool");
    const dilations = 1;
    let x4D = $x;
    let reshapedTo4D = false;
    if ($x.rank === 3) {
      reshapedTo4D = true;
      x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    }
    assert(x4D.rank === 4, () => `Error in maxPool: input must be rank 4 but got rank ${x4D.rank}.`);
    assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
    if (dimRoundingMode != null) {
      assert(isInt(pad2), () => `Error in maxPool: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad2}.`);
    }
    const inputs = { x: x4D };
    const attrs = { filterSize, strides, pad: pad2, dimRoundingMode };
    const res = ENGINE.runKernel(MaxPool, inputs, attrs);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  var maxPool = op({ maxPool_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/max_pool_3d.js
  function maxPool3d_(x, filterSize = [1, 1, 1], strides, pad2, dimRoundingMode, dataFormat = "NDHWC") {
    const $x = convertToTensor(x, "x", "maxPool3d");
    let x5D = $x;
    let reshapedTo5D = false;
    if ($x.rank === 4) {
      reshapedTo5D = true;
      x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
    }
    assert(x5D.rank === 5, () => `Error in maxPool3d: x must be rank 5 but got rank ${x5D.rank}.`);
    assert(dataFormat === "NDHWC", () => `Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of ${dataFormat}`);
    if (dimRoundingMode != null) {
      assert(isInt(pad2), () => `Error in maxPool3d: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad2}.`);
    }
    const inputs = { x: x5D };
    const attrs = { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat };
    const res = ENGINE.runKernel(MaxPool3D, inputs, attrs);
    if (reshapedTo5D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
    }
    return res;
  }
  var maxPool3d = op({ maxPool3d_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/maximum.js
  function maximum_(a, b) {
    let $a = convertToTensor(a, "a", "maximum");
    let $b = convertToTensor(b, "b", "maximum");
    [$a, $b] = makeTypesMatch($a, $b);
    if ($a.dtype === "bool") {
      $a = cast($a, "int32");
      $b = cast($b, "int32");
    }
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(Maximum, inputs);
  }
  var maximum = op({ maximum_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/mean.js
  function mean_(x, axis = null, keepDims = false) {
    const $x = convertToTensor(x, "x", "mean");
    const inputs = { x: $x };
    const attrs = { axis, keepDims };
    return ENGINE.runKernel(Mean, inputs, attrs);
  }
  var mean = op({ mean_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/zeros.js
  function zeros(shape, dtype = "float32") {
    if (dtype === "complex64") {
      const real4 = zeros(shape, "float32");
      const imag4 = zeros(shape, "float32");
      return complex(real4, imag4);
    }
    const values = makeZerosTypedArray(sizeFromShape(shape), dtype);
    return ENGINE.makeTensor(values, shape, dtype);
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/ones.js
  function ones2(shape, dtype = "float32") {
    if (dtype === "complex64") {
      const real4 = ones2(shape, "float32");
      const imag4 = zeros(shape, "float32");
      return complex(real4, imag4);
    }
    const values = makeOnesTypedArray(sizeFromShape(shape), dtype);
    return ENGINE.makeTensor(values, shape, dtype);
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/min.js
  function min_(x, axis = null, keepDims = false) {
    const $x = convertToTensor(x, "x", "min");
    const inputs = { x: $x };
    const attrs = { axis, keepDims };
    return ENGINE.runKernel(Min, inputs, attrs);
  }
  var min = op({ min_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/minimum.js
  function minimum_(a, b) {
    let $a = convertToTensor(a, "a", "minimum");
    let $b = convertToTensor(b, "b", "minimum");
    [$a, $b] = makeTypesMatch($a, $b);
    if ($a.dtype === "bool") {
      $a = cast($a, "int32");
      $b = cast($b, "int32");
    }
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(Minimum, inputs);
  }
  var minimum = op({ minimum_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/mirror_pad.js
  function mirrorPad_(x, paddings, mode) {
    assert(mode === "reflect" || mode === "symmetric", () => `Invalid mode. Mode must be either reflect or symmetric. Got ${mode}.`);
    const $x = convertToTensor(x, "x", "mirrorPad");
    if ($x.rank === 0) {
      throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");
    }
    assert(paddings.length === $x.rank, () => `Padding doesn't match input. Must be ${$x.rank}. Got ${paddings.length}.`);
    const shapeOffset = mode === "reflect" ? 1 : 0;
    for (let i = 0; i < $x.rank; i++) {
      assert(paddings[i].length === 2, () => `Invalid number of paddings. Must be length of 2 each.`);
      assert(paddings[i][0] >= 0 && paddings[i][0] <= $x.shape[i] - shapeOffset && paddings[i][1] >= 0 && paddings[i][1] <= $x.shape[i] - shapeOffset, () => `Padding in dimension ${i} cannot be greater than or equal to ${$x.shape[i] - shapeOffset} or less than 0 for input of shape ${$x.shape}`);
    }
    const attrs = { paddings, mode };
    const inputs = { x: $x };
    return ENGINE.runKernel(MirrorPad, inputs, attrs);
  }
  var mirrorPad = op({ mirrorPad_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/mod.js
  function mod_(a, b) {
    let $a = convertToTensor(a, "a", "mod");
    let $b = convertToTensor(b, "b", "mod");
    [$a, $b] = makeTypesMatch($a, $b);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(Mod, inputs);
  }
  var mod = op({ mod_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/square.js
  function square_(x) {
    const $x = convertToTensor(x, "x", "square");
    const attrs = {};
    return ENGINE.runKernel("Square", { x: $x }, attrs);
  }
  var square = op({ square_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/moments.js
  function moments_(x, axis = null, keepDims = false) {
    x = convertToTensor(x, "x", "moments");
    const axes = parseAxisParam(axis, x.shape);
    const xMean = mean(x, axes, keepDims);
    let keepDimsShape = xMean.shape;
    if (!keepDims) {
      keepDimsShape = expandShapeToKeepDim(xMean.shape, axes);
    }
    const devSquared = square(sub(cast(x, "float32"), reshape(xMean, keepDimsShape)));
    const variance = mean(devSquared, axes, keepDims);
    return { mean: xMean, variance };
  }
  var moments = op({ moments_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/not_equal.js
  function notEqual_(a, b) {
    let $a = convertToTensor(a, "a", "notEqual", "string_or_numeric");
    let $b = convertToTensor(b, "b", "notEqual", "string_or_numeric");
    [$a, $b] = makeTypesMatch($a, $b);
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(NotEqual, inputs);
  }
  var notEqual = op({ notEqual_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/ones_like.js
  function onesLike_(x) {
    const $x = convertToTensor(x, "x", "onesLike");
    const inputs = { x: $x };
    return ENGINE.runKernel(OnesLike, inputs);
  }
  var onesLike = op({ onesLike_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/pad.js
  function pad_(x, paddings, constantValue = 0) {
    const $x = convertToTensor(x, "x", "pad");
    if ($x.rank === 0) {
      throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");
    }
    const attrs = { paddings, constantValue };
    const inputs = { x: $x };
    return ENGINE.runKernel(PadV2, inputs, attrs);
  }
  var pad = op({ pad_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/space_to_batch_nd.js
  function spaceToBatchND_(x, blockShape, paddings) {
    const $x = convertToTensor(x, "x", "spaceToBatchND");
    assert($x.rank >= 1 + blockShape.length, () => `input rank ${$x.rank} should be > than [blockShape] ${blockShape.length}`);
    assert(paddings.length === blockShape.length, () => `paddings.shape[0] ${paddings.length} must be equal to [blockShape] ${blockShape.length}`);
    assert($x.shape.reduce((a, b, i) => {
      if (i > 0 && i <= blockShape.length) {
        return a && (b + paddings[i - 1][0] + paddings[i - 1][1]) % blockShape[i - 1] === 0;
      }
      return a;
    }, true), () => `input spatial dimensions ${$x.shape.slice(1)} with paddings ${paddings.toString()} must be divisible by blockShapes ${blockShape.toString()}`);
    const inputs = { x: $x };
    const attrs = { blockShape, paddings };
    return ENGINE.runKernel(SpaceToBatchND, inputs, attrs);
  }
  var spaceToBatchND = op({ spaceToBatchND_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/pool.js
  function pool_(input2, windowShape, poolingType, pad2, dilations, strides) {
    if (dilations == null) {
      dilations = [1, 1];
    }
    if (strides == null) {
      strides = 1;
    }
    if (pad2 === 0) {
      pad2 = "valid";
    }
    const $x = convertToTensor(input2, "x", "maxPool");
    let x4D = $x;
    let reshapedTo4D = false;
    if ($x.rank === 3) {
      reshapedTo4D = true;
      x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    }
    assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in pool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
    const convInfo = computePool2DInfo(x4D.shape, windowShape, strides, dilations, pad2);
    const dilation = [convInfo.dilationHeight, convInfo.dilationWidth];
    let basePadding;
    if (pad2 === "same") {
      basePadding = withSpaceToBatchBasePaddings([convInfo.filterHeight, convInfo.filterWidth], dilation);
    } else {
      basePadding = [[0, 0], [0, 0]];
    }
    const isDilationOne = dilation[0] === 1 && dilation[1] === 1;
    const [adjustedPadding, adjustedCrops] = requiredSpaceToBatchPaddings([convInfo.inHeight, convInfo.inWidth], dilation, basePadding);
    const convertedPad = isDilationOne ? pad2 : "valid";
    const convertedX = isDilationOne ? x4D : spaceToBatchND(x4D, dilation, adjustedPadding);
    const forwardOp = poolingType === "avg" ? () => avgPool(convertedX, windowShape, strides, convertedPad) : () => maxPool(convertedX, windowShape, strides, convertedPad);
    const y = forwardOp();
    const res = isDilationOne ? y : batchToSpaceND(y, dilation, adjustedCrops);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  function requiredSpaceToBatchPaddings(inputShape, blockShape, basePadding) {
    const padStart = basePadding.map((b) => b[0]);
    const origPadEnd = basePadding.map((b) => b[1]);
    const fullInputShape = inputShape.concat(padStart, origPadEnd);
    const padEndExtra = blockShape.map((b, i) => (b - fullInputShape[i] % b) % b);
    const padEnd = origPadEnd.map((s, i) => s + padEndExtra[i]);
    const paddings = blockShape.map((_, i) => [padStart[i], padEnd[i]]);
    const crops = blockShape.map((_, i) => [0, padEndExtra[i]]);
    return [paddings, crops];
  }
  function withSpaceToBatchBasePaddings(filterShape, dilation) {
    const dilatedFilterShape = filterShape.map((s, i) => {
      return s + (s - 1) * (dilation[i] - 1);
    });
    const padExtraShape = dilatedFilterShape.map((s) => s - 1);
    const padExtraStart = padExtraShape.map((s) => Math.floor(s / 2));
    const padExtraEnd = padExtraShape.map((s, i) => s - padExtraStart[i]);
    return padExtraShape.map((_, i) => {
      return [padExtraStart[i], padExtraEnd[i]];
    });
  }
  var pool = op({ pool_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/pow.js
  function pow_(base2, exp4) {
    let $base = convertToTensor(base2, "base", "pow");
    let $exp = convertToTensor(exp4, "exp", "pow");
    [$base, $exp] = makeTypesMatch($base, $exp);
    const inputs = { a: $base, b: $exp };
    return ENGINE.runKernel(Pow, inputs);
  }
  var pow = op({ pow_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/prelu.js
  function prelu_(x, alpha) {
    const $x = convertToTensor(x, "x", "prelu");
    const $alpha = convertToTensor(alpha, "alpha", "prelu");
    const inputs = { x: $x, alpha: $alpha };
    return ENGINE.runKernel(Prelu, inputs);
  }
  var prelu = op({ prelu_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/prod.js
  function prod_(x, axis = null, keepDims = false) {
    let $x = convertToTensor(x, "x", "prod");
    if ($x.dtype === "bool") {
      $x = cast($x, "int32");
    }
    const inputs = { x: $x };
    const attrs = { axis, keepDims };
    return ENGINE.runKernel(Prod, inputs, attrs);
  }
  var prod = op({ prod_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/rand_util.js
  var seedrandom = __toModule(require_seedrandom2());
  var MPRandGauss = class {
    constructor(mean3, stdDeviation, dtype, truncated, seed) {
      this.mean = mean3;
      this.stdDev = stdDeviation;
      this.dtype = dtype;
      this.nextVal = NaN;
      this.truncated = truncated;
      if (this.truncated) {
        this.upper = this.mean + this.stdDev * 2;
        this.lower = this.mean - this.stdDev * 2;
      }
      const seedValue = seed ? seed : Math.random();
      this.random = seedrandom.alea(seedValue.toString());
    }
    nextValue() {
      if (!isNaN(this.nextVal)) {
        const value = this.nextVal;
        this.nextVal = NaN;
        return value;
      }
      let resultX, resultY;
      let isValid = false;
      while (!isValid) {
        let v1, v2, s;
        do {
          v1 = 2 * this.random() - 1;
          v2 = 2 * this.random() - 1;
          s = v1 * v1 + v2 * v2;
        } while (s >= 1 || s === 0);
        const mul2 = Math.sqrt(-2 * Math.log(s) / s);
        resultX = this.mean + this.stdDev * v1 * mul2;
        resultY = this.mean + this.stdDev * v2 * mul2;
        if (!this.truncated || this.isValidTruncated(resultX)) {
          isValid = true;
        }
      }
      if (!this.truncated || this.isValidTruncated(resultY)) {
        this.nextVal = this.convertValue(resultY);
      }
      return this.convertValue(resultX);
    }
    convertValue(value) {
      if (this.dtype == null || this.dtype === "float32") {
        return value;
      }
      return Math.round(value);
    }
    isValidTruncated(value) {
      return value <= this.upper && value >= this.lower;
    }
  };
  var UniformRandom = class {
    constructor(min5 = 0, max5 = 1, dtype, seed) {
      this.canReturnFloat = () => this.dtype == null || this.dtype === "float32";
      this.min = min5;
      this.range = max5 - min5;
      this.dtype = dtype;
      if (seed == null) {
        seed = Math.random();
      }
      if (typeof seed === "number") {
        seed = seed.toString();
      }
      if (!this.canReturnFloat() && this.range <= 1) {
        throw new Error(`The difference between ${min5} - ${max5} <= 1 and dtype is not float`);
      }
      this.random = seedrandom.alea(seed);
    }
    convertValue(value) {
      if (this.canReturnFloat()) {
        return value;
      }
      return Math.round(value);
    }
    nextValue() {
      return this.convertValue(this.min + this.range * this.random());
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/ops/random_normal.js
  function randomNormal_(shape, mean3 = 0, stdDev = 1, dtype, seed) {
    if (dtype != null && dtype === "bool") {
      throw new Error(`Unsupported data type ${dtype}`);
    }
    const randGauss = new MPRandGauss(mean3, stdDev, dtype, false, seed);
    const res = buffer2(shape, dtype);
    for (let i = 0; i < res.values.length; i++) {
      res.values[i] = randGauss.nextValue();
    }
    return res.toTensor();
  }
  var randomNormal = op({ randomNormal_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/random_uniform.js
  function randomUniform_(shape, minval = 0, maxval = 1, dtype = "float32", seed) {
    const res = buffer2(shape, dtype);
    const random = new UniformRandom(minval, maxval, null, seed);
    for (let i = 0; i < res.values.length; i++) {
      res.values[i] = random.nextValue();
    }
    return res.toTensor();
  }
  var randomUniform = op({ randomUniform_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/range.js
  function range(start, stop2, step4 = 1, dtype = "float32") {
    if (step4 === 0) {
      throw new Error("Cannot have a step of zero");
    }
    const attrs = { start, stop: stop2, step: step4, dtype };
    return ENGINE.runKernel(Range, {}, attrs);
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/real.js
  function real_(input2) {
    const $input = convertToTensor(input2, "input", "real");
    const inputs = { input: $input };
    return ENGINE.runKernel(Real, inputs);
  }
  var real = op({ real_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/reciprocal.js
  function reciprocal_(x) {
    const $x = convertToTensor(x, "x", "reciprocal");
    const inputs = { x: $x };
    return ENGINE.runKernel(Reciprocal, inputs);
  }
  var reciprocal = op({ reciprocal_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/relu.js
  function relu_(x) {
    const $x = convertToTensor(x, "x", "relu");
    const inputs = { x: $x };
    return ENGINE.runKernel(Relu, inputs);
  }
  var relu = op({ relu_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/relu6.js
  function relu6_(x) {
    const $x = convertToTensor(x, "x", "relu6");
    const inputs = { x: $x };
    return ENGINE.runKernel(Relu6, inputs);
  }
  var relu6 = op({ relu6_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/reverse.js
  function reverse_(x, axis) {
    const $x = convertToTensor(x, "x", "reverse");
    const inputs = { x: $x };
    const attrs = { dims: axis };
    return ENGINE.runKernel(Reverse, inputs, attrs);
  }
  var reverse = op({ reverse_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/round.js
  function round_(x) {
    const $x = convertToTensor(x, "x", "round");
    const inputs = { x: $x };
    return ENGINE.runKernel(Round, inputs);
  }
  var round2 = op({ round_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/rsqrt.js
  function rsqrt_(x) {
    const $x = convertToTensor(x, "x", "rsqrt", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Rsqrt, inputs);
  }
  var rsqrt = op({ rsqrt_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/scalar.js
  function scalar(value, dtype) {
    if ((isTypedArray(value) && dtype !== "string" || Array.isArray(value)) && dtype !== "complex64") {
      throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");
    }
    if (dtype === "string" && isTypedArray(value) && !(value instanceof Uint8Array)) {
      throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");
    }
    const shape = [];
    const inferredShape = [];
    return makeTensor(value, shape, inferredShape, dtype);
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/selu.js
  function selu_(x) {
    const $x = convertToTensor(x, "x", "selu");
    const inputs = { x: $x };
    return ENGINE.runKernel(Selu, inputs);
  }
  var selu = op({ selu_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/separable_conv2d.js
  function separableConv2d_(x, depthwiseFilter, pointwiseFilter, strides, pad2, dilation = [1, 1], dataFormat = "NHWC") {
    const $x = convertToTensor(x, "x", "separableConv2d");
    const $depthwiseFilter = convertToTensor(depthwiseFilter, "depthwiseFilter", "separableConv2d");
    const $pointwiseFilter = convertToTensor(pointwiseFilter, "pointwiseFilter", "separableConv2d");
    let x4D = $x;
    let reshapedTo4D = false;
    if ($x.rank === 3) {
      reshapedTo4D = true;
      x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    }
    if (dataFormat === "NCHW") {
      throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");
    }
    assert(x4D.rank === 4, () => `Error in separableConv2d: input must be rank 4, but got rank ${x4D.rank}.`);
    assert($depthwiseFilter.rank === 4, () => `Error in separableConv2d: depthwise filter must be rank 4, but got rank ${$depthwiseFilter.rank}.`);
    assert($pointwiseFilter.rank === 4, () => `Error in separableConv2d: pointwise filter must be rank 4, but got rank ${$depthwiseFilter.rank}.`);
    assert($pointwiseFilter.shape[0] === 1, () => `Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got ${$pointwiseFilter.shape[0]}.`);
    assert($pointwiseFilter.shape[1] === 1, () => `Error in separableConv2d: the second dimension of pointwise filter must be 1, but got ${$pointwiseFilter.shape[1]}.`);
    const inChannels = $depthwiseFilter.shape[2];
    const channelMultiplier = $depthwiseFilter.shape[3];
    assert($pointwiseFilter.shape[2] === inChannels * channelMultiplier, () => `Error in separableConv2d: the third dimension of pointwise filter must be ${inChannels * channelMultiplier}, but got ${$pointwiseFilter.shape[2]}.`);
    const depthwise = depthwiseConv2d(x4D, $depthwiseFilter, strides, pad2, dataFormat, dilation);
    const pointwiseStride = 1;
    const res = conv2d(depthwise, $pointwiseFilter, pointwiseStride, "valid", dataFormat);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  var separableConv2d = op({ separableConv2d_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sign.js
  function sign_(x) {
    const $x = convertToTensor(x, "x", "sign");
    const inputs = { x: $x };
    return ENGINE.runKernel(Sign, inputs);
  }
  var sign = op({ sign_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sin.js
  function sin_(x) {
    const $x = convertToTensor(x, "x", "sin", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Sin, inputs);
  }
  var sin = op({ sin_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sinh.js
  function sinh_(x) {
    const $x = convertToTensor(x, "x", "sinh");
    const inputs = { x: $x };
    return ENGINE.runKernel(Sinh, inputs);
  }
  var sinh = op({ sinh_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/slice1d.js
  function slice1d_(x, begin, size2) {
    const $x = convertToTensor(x, "x", "slice1d");
    assert($x.rank === 1, () => `slice1d expects a rank-1 tensor, but got a rank-${$x.rank} tensor`);
    return slice($x, [begin], [size2]);
  }
  var slice1d = op({ slice1d_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/slice2d.js
  function slice2d_(x, begin, size2) {
    const $x = convertToTensor(x, "x", "slice2d");
    assert($x.rank === 2, () => `slice2d expects a rank-2 tensor, but got a rank-${$x.rank} tensor`);
    return slice($x, begin, size2);
  }
  var slice2d = op({ slice2d_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/slice3d.js
  function slice3d_(x, begin, size2) {
    const $x = convertToTensor(x, "x", "slice3d");
    assert($x.rank === 3, () => `slice3d expects a rank-3 tensor, but got a rank-${$x.rank} tensor`);
    return slice($x, begin, size2);
  }
  var slice3d = op({ slice3d_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/slice4d.js
  function slice4d_(x, begin, size2) {
    const $x = convertToTensor(x, "x", "slice4d");
    assert($x.rank === 4, () => `slice4d expects a rank-4 tensor, but got a rank-${$x.rank} tensor`);
    return slice($x, begin, size2);
  }
  var slice4d = op({ slice4d_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/softmax.js
  function softmax_(logits, dim = -1) {
    const $logits = convertToTensor(logits, "logits", "softmax", "float32");
    if (dim === -1) {
      dim = $logits.rank - 1;
    }
    if (dim !== $logits.rank - 1) {
      throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${$logits.rank} and dim was ${dim}`);
    }
    const inputs = { logits: $logits };
    const attrs = { dim };
    return ENGINE.runKernel(Softmax, inputs, attrs);
  }
  var softmax = op({ softmax_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/spectral/fft.js
  function fft_(input2) {
    assert(input2.dtype === "complex64", () => `The dtype for tf.spectral.fft() must be complex64 but got ${input2.dtype}.`);
    const inputs = { input: input2 };
    return ENGINE.runKernel(FFT, inputs);
  }
  var fft = op({ fft_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/spectral/ifft.js
  function ifft_(input2) {
    assert(input2.dtype === "complex64", () => `The dtype for tf.spectral.ifft() must be complex64 but got ${input2.dtype}.`);
    const inputs = { input: input2 };
    return ENGINE.runKernel(IFFT, inputs);
  }
  var ifft = op({ ifft_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/spectral/irfft.js
  function irfft_(input2) {
    const innerDimensionSize = input2.shape[input2.shape.length - 1];
    const batch = input2.size / innerDimensionSize;
    let ret;
    if (innerDimensionSize <= 2) {
      const complexInput = reshape(input2, [batch, innerDimensionSize]);
      ret = ifft(complexInput);
    } else {
      const outputShape = [batch, 2 * (innerDimensionSize - 1)];
      const realInput = reshape(real(input2), [batch, innerDimensionSize]);
      const imagInput = reshape(imag(input2), [batch, innerDimensionSize]);
      const realConjugate = reverse(slice(realInput, [0, 1], [batch, innerDimensionSize - 2]), 1);
      const imagConjugate = mul(reverse(slice(imagInput, [0, 1], [batch, innerDimensionSize - 2]), 1), scalar(-1));
      const r = concat([realInput, realConjugate], 1);
      const i = concat([imagInput, imagConjugate], 1);
      const complexInput = reshape(complex(r, i), [outputShape[0], outputShape[1]]);
      ret = ifft(complexInput);
    }
    ret = real(ret);
    if (input2.rank === 3 && input2.shape[0] !== 0) {
      const temp = ret;
      const batch2 = input2.shape[0];
      ret = reshape(ret, [batch2, ret.shape[0] / batch2, ret.shape[1]]);
      temp.dispose();
    }
    return ret;
  }
  var irfft = op({ irfft_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/split.js
  function split_(x, numOrSizeSplits, axis = 0) {
    const $x = convertToTensor(x, "x", "split");
    const inputs = { x: $x };
    const attr = { numOrSizeSplits, axis };
    return ENGINE.runKernel(SplitV, inputs, attr);
  }
  var split = op({ split_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/spectral/rfft.js
  function rfft_(input2, fftLength) {
    assert(input2.dtype === "float32", () => `The dtype for rfft() must be real value but got ${input2.dtype}`);
    let innerDimensionSize = input2.shape[input2.shape.length - 1];
    const batch = input2.size / innerDimensionSize;
    let adjustedInput;
    if (fftLength != null && fftLength < innerDimensionSize) {
      const begin = input2.shape.map((v) => 0);
      const size2 = input2.shape.map((v) => v);
      size2[input2.shape.length - 1] = fftLength;
      adjustedInput = slice(input2, begin, size2);
      innerDimensionSize = fftLength;
    } else if (fftLength != null && fftLength > innerDimensionSize) {
      const zerosShape = input2.shape.map((v) => v);
      zerosShape[input2.shape.length - 1] = fftLength - innerDimensionSize;
      adjustedInput = concat([input2, zeros(zerosShape)], input2.shape.length - 1);
      innerDimensionSize = fftLength;
    } else {
      adjustedInput = input2;
    }
    const zerosInput = zerosLike(adjustedInput);
    const complexInput = reshape(complex(adjustedInput, zerosInput), [batch, innerDimensionSize]);
    const ret = fft(complexInput);
    const half = Math.floor(innerDimensionSize / 2) + 1;
    const realValues = real(ret);
    const imagValues = imag(ret);
    const realComplexConjugate = split(realValues, [half, innerDimensionSize - half], realValues.shape.length - 1);
    const imagComplexConjugate = split(imagValues, [half, innerDimensionSize - half], imagValues.shape.length - 1);
    const outputShape = adjustedInput.shape.slice();
    outputShape[adjustedInput.shape.length - 1] = half;
    return reshape(complex(realComplexConjugate[0], imagComplexConjugate[0]), outputShape);
  }
  var rfft = op({ rfft_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sqrt.js
  function sqrt_(x) {
    const $x = convertToTensor(x, "x", "sqrt", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Sqrt, inputs);
  }
  var sqrt = op({ sqrt_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/squared_difference.js
  function squaredDifference_(a, b) {
    let $a = convertToTensor(a, "a", "squaredDifference");
    let $b = convertToTensor(b, "b", "squaredDifference");
    [$a, $b] = makeTypesMatch($a, $b);
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    const attrs = {};
    return ENGINE.runKernel(SquaredDifference, inputs, attrs);
  }
  var squaredDifference = op({ squaredDifference_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/squeeze.js
  function squeeze_(x, axis) {
    const $x = convertToTensor(x, "x", "squeeze");
    return reshape($x, squeezeShape($x.shape, axis).newShape);
  }
  var squeeze = op({ squeeze_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/stack.js
  function stack_(tensors, axis = 0) {
    const $tensors = convertToTensorArray(tensors, "tensors", "stack", "string_or_numeric");
    assert($tensors.length >= 1, () => "Pass at least one tensor to tf.stack");
    if ($tensors.length > 0) {
      assert(axis <= $tensors[0].rank, () => "Axis must be <= rank of the tensor");
    }
    const inputs = $tensors;
    const attrs = { axis };
    return ENGINE.runKernel(Pack, inputs, attrs);
  }
  var stack2 = op({ stack_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/step.js
  function step_(x, alpha = 0) {
    const $x = convertToTensor(x, "x", "step");
    const inputs = { x: $x };
    const attrs = { alpha };
    return ENGINE.runKernel(Step, inputs, attrs);
  }
  var step = op({ step_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/strided_slice.js
  function stridedSlice_(x, begin, end, strides, beginMask = 0, endMask = 0, ellipsisMask = 0, newAxisMask = 0, shrinkAxisMask = 0) {
    const $x = convertToTensor(x, "x", "stridedSlice", "string_or_numeric");
    const inputs = { x: $x };
    const attrs = {
      begin,
      end,
      strides,
      beginMask,
      endMask,
      ellipsisMask,
      newAxisMask,
      shrinkAxisMask
    };
    return ENGINE.runKernel(StridedSlice, inputs, attrs);
  }
  var stridedSlice = op({ stridedSlice_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/tan.js
  function tan_(x) {
    const $x = convertToTensor(x, "x", "tan", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Tan, inputs);
  }
  var tan = op({ tan_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/tensor1d.js
  function tensor1d(values, dtype) {
    assertNonNull(values);
    const inferredShape = inferShape(values, dtype);
    if (inferredShape.length !== 1) {
      throw new Error("tensor1d() requires values to be a flat/TypedArray");
    }
    const shape = null;
    return makeTensor(values, shape, inferredShape, dtype);
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/tensor2d.js
  function tensor2d(values, shape, dtype) {
    assertNonNull(values);
    if (shape != null && shape.length !== 2) {
      throw new Error("tensor2d() requires shape to have two numbers");
    }
    const inferredShape = inferShape(values, dtype);
    if (inferredShape.length !== 2 && inferredShape.length !== 1) {
      throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");
    }
    if (inferredShape.length === 1 && shape == null) {
      throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");
    }
    return makeTensor(values, shape, inferredShape, dtype);
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/topk.js
  function topk_(x, k = 1, sorted = true) {
    const $x = convertToTensor(x, "x", "topk");
    if ($x.rank === 0) {
      throw new Error("topk() expects the input to be of rank 1 or higher");
    }
    const lastDim = $x.shape[$x.shape.length - 1];
    if (k < 0) {
      throw new Error(`'k' passed to topk() must be >= 0 but got ${k}`);
    }
    if (k > lastDim) {
      throw new Error(`'k' passed to topk() must be <= the last dimension (${lastDim}) but got ${k}`);
    }
    const inputs = { x: $x };
    const attrs = { k, sorted };
    const [values, indices] = ENGINE.runKernel(TopK, inputs, attrs);
    return { values, indices };
  }
  var topk = op({ topk_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/truncated_normal.js
  function truncatedNormal_(shape, mean3 = 0, stdDev = 1, dtype, seed) {
    if (dtype != null && dtype === "bool") {
      throw new Error(`Unsupported data type $ { dtype }`);
    }
    const randGauss = new MPRandGauss(mean3, stdDev, dtype, true, seed);
    const res = buffer2(shape, dtype);
    for (let i = 0; i < res.values.length; i++) {
      res.values[i] = randGauss.nextValue();
    }
    return res.toTensor();
  }
  var truncatedNormal = op({ truncatedNormal_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/unique.js
  function unique_(x, axis = 0) {
    const $x = convertToTensor(x, "x", "unique", "string_or_numeric");
    assert($x.rank > 0, () => "The input tensor must be at least 1D");
    const inputs = { x: $x };
    const attrs = { axis };
    const [values, indices] = ENGINE.runKernel(Unique, inputs, attrs);
    return { values, indices };
  }
  var unique = op({ unique_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/unsorted_segment_sum.js
  function unsortedSegmentSum_(x, segmentIds, numSegments) {
    const $x = convertToTensor(x, "x", "unsortedSegmentSum");
    const $segmentIds = convertToTensor(segmentIds, "segmentIds", "unsortedSegmentSum", "int32");
    assert(isInt(numSegments), () => "numSegments must be of dtype int");
    const inputs = { x: $x, segmentIds: $segmentIds };
    const attrs = { numSegments };
    return ENGINE.runKernel(UnsortedSegmentSum, inputs, attrs);
  }
  var unsortedSegmentSum = op({ unsortedSegmentSum_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/unstack.js
  function unstack_(x, axis = 0) {
    const $x = convertToTensor(x, "x", "unstack", "string_or_numeric");
    assert(axis >= -$x.shape.length && axis < $x.shape.length, () => `Axis = ${axis} is not in [-${$x.shape.length}, ${$x.shape.length})`);
    const inputs = { value: $x };
    const attrs = { axis };
    return ENGINE.runKernel(Unpack, inputs, attrs);
  }
  var unstack = op({ unstack_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/variable.js
  function variable(initialValue, trainable = true, name, dtype) {
    return ENGINE.makeVariable(initialValue, trainable, name, dtype);
  }

  // node_modules/@tensorflow/tfjs-core/dist/backends/where_impl.js
  function whereImpl(condShape, condVals) {
    const indices = [];
    for (let i = 0; i < condVals.length; i++) {
      if (condVals[i]) {
        indices.push(i);
      }
    }
    const inBuffer = buffer2(condShape, "int32");
    const out = buffer2([indices.length, condShape.length], "int32");
    for (let i = 0; i < indices.length; i++) {
      const loc = inBuffer.indexToLoc(indices[i]);
      const offset = i * condShape.length;
      out.values.set(loc, offset);
    }
    return out.toTensor();
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/norm.js
  function norm_(x, ord = "euclidean", axis = null, keepDims = false) {
    x = convertToTensor(x, "x", "norm");
    const norm2 = normImpl(x, ord, axis);
    let keepDimsShape = norm2.shape;
    if (keepDims) {
      const axes = parseAxisParam(axis, x.shape);
      keepDimsShape = expandShapeToKeepDim(norm2.shape, axes);
    }
    return reshape(norm2, keepDimsShape);
  }
  function normImpl(x, p3, axis = null) {
    if (x.rank === 0) {
      return abs(x);
    }
    if (x.rank !== 1 && axis === null) {
      return normImpl(reshape(x, [-1]), p3, axis);
    }
    if (x.rank === 1 || typeof axis === "number" || Array.isArray(axis) && axis.length === 1) {
      if (p3 === 1) {
        return sum2(abs(x), axis);
      }
      if (p3 === Infinity) {
        return max(abs(x), axis);
      }
      if (p3 === -Infinity) {
        return min(abs(x), axis);
      }
      if (p3 === "euclidean" || p3 === 2) {
        return sqrt(sum2(pow(abs(x), scalar(2, "int32")), axis));
      }
      throw new Error(`Error in norm: invalid ord value: ${p3}`);
    }
    if (Array.isArray(axis) && axis.length === 2) {
      if (p3 === 1) {
        return max(sum2(abs(x), axis[0]), axis[1] - 1);
      }
      if (p3 === Infinity) {
        return max(sum2(abs(x), axis[1]), axis[0]);
      }
      if (p3 === -Infinity) {
        return min(sum2(abs(x), axis[1]), axis[0]);
      }
      if (p3 === "fro" || p3 === "euclidean") {
        return sqrt(sum2(square(x), axis));
      }
      throw new Error(`Error in norm: invalid ord value: ${p3}`);
    }
    throw new Error(`Error in norm: invalid axis: ${axis}`);
  }
  var norm = op({ norm_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/dropout_util.js
  function getNoiseShape(x, noiseShape) {
    if (noiseShape == null) {
      return x.shape.slice();
    }
    if (arraysEqual(x.shape, noiseShape)) {
      return noiseShape;
    }
    if (x.shape.length === noiseShape.length) {
      const newDimension = [];
      for (let i = 0; i < x.shape.length; i++) {
        if (noiseShape[i] == null && x.shape[i] != null) {
          newDimension.push(x.shape[i]);
        } else {
          newDimension.push(noiseShape[i]);
        }
      }
      return newDimension;
    }
    return noiseShape;
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/dropout.js
  function dropout_(x, rate, noiseShape, seed) {
    const $x = convertToTensor(x, "x", "dropout");
    assert($x.dtype === "float32", () => `x has to be a floating point tensor since it's going to be scaled, but got a ${$x.dtype} tensor instead.`);
    assert(rate >= 0 && rate < 1, () => `rate must be a float in the range [0, 1), but got ${rate}.`);
    if (rate === 0) {
      return x instanceof Tensor ? $x.clone() : $x;
    }
    const $noiseShape = getNoiseShape($x, noiseShape);
    const keepProb = 1 - rate;
    const multiplier = div(floor(add3(randomUniform($noiseShape, 0, 1, "float32", seed), keepProb)), keepProb);
    return mul($x, multiplier);
  }
  var dropout = op({ dropout_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/fused_ops.js
  var fused_ops_exports = {};
  __export(fused_ops_exports, {
    conv2d: () => conv2d2,
    depthwiseConv2d: () => depthwiseConv2d2,
    matMul: () => matMul2
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_filter.js
  function conv2DBackpropFilter_(x, dy, filterShape, strides, pad2, dataFormat = "NHWC", dimRoundingMode) {
    let x4D = x;
    if (x.rank === 3) {
      x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
    }
    let dy4D = dy;
    if (dy4D.rank === 3) {
      dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
    }
    assert(x4D.rank === 4, () => `Error in conv2dDerFilter: input must be rank 4, but got shape ${x4D.shape}.`);
    assert(dy4D.rank === 4, () => `Error in conv2dDerFilter: dy must be rank 4, but got shape ${dy4D.shape}.`);
    assert(filterShape.length === 4, () => `Error in conv2dDerFilter: filterShape must be length 4, but got ${filterShape}.`);
    const inDepth = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
    const outDepth = dataFormat === "NHWC" ? dy4D.shape[3] : dy4D.shape[1];
    assert(inDepth === filterShape[2], () => `Error in conv2dDerFilter: depth of input ${inDepth}) must match input depth in filter (${filterShape[2]}.`);
    assert(outDepth === filterShape[3], () => `Error in conv2dDerFilter: depth of dy (${outDepth}) must match output depth for filter (${filterShape[3]}).`);
    if (dimRoundingMode != null) {
      assert(isInt(pad2), () => `Error in conv2dDerFilter: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad2}.`);
    }
    const inputs = { x: x4D, dy: dy4D };
    const attrs = { strides, pad: pad2, dataFormat, dimRoundingMode, filterShape };
    return ENGINE.runKernel(Conv2DBackpropFilter, inputs, attrs);
  }
  var conv2DBackpropFilter = op({ conv2DBackpropFilter_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/fused_util.js
  function getFusedDyActivation(dy, y, activation) {
    if (activation == null || activation === "linear") {
      return dy;
    }
    if (activation === "relu") {
      return mul(dy, step(y));
    }
    throw new Error(`Cannot compute gradient for fused activation ${activation}.`);
  }
  function getFusedBiasGradient(bias, dyActivation) {
    let res = dyActivation;
    const reduceAxes = getReductionAxes(bias.shape, dyActivation.shape);
    if (reduceAxes.length > 0) {
      res = sum2(res, reduceAxes);
    }
    return reshape(res, bias.shape);
  }
  function applyActivation(x, activation, preluActivationWeights, leakyreluAlpha) {
    if (activation === "linear") {
      return x;
    } else if (activation === "relu") {
      return relu(x);
    } else if (activation === "elu") {
      return elu(x);
    } else if (activation === "relu6") {
      return relu6(x);
    } else if (activation === "prelu") {
      return prelu(x, preluActivationWeights);
    } else if (activation === "leakyrelu") {
      return leakyRelu(x, leakyreluAlpha);
    } else if (activation === "sigmoid") {
      return sigmoid(x);
    }
    throw new Error(`Unknown fused activation ${activation}.`);
  }
  var shouldFuse = (gradientDepth, activation) => {
    const gradientMode = gradientDepth > 0;
    return !gradientMode || activation === "linear";
  };

  // node_modules/@tensorflow/tfjs-core/dist/ops/fused/conv2d.js
  function fusedConv2d_({ x, filter, strides, pad: pad2, dataFormat = "NHWC", dilations = [1, 1], dimRoundingMode, bias, activation = "linear", preluActivationWeights, leakyreluAlpha }) {
    activation = activation || "linear";
    if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
      let result = conv2d(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode);
      if (bias != null) {
        result = add3(result, bias);
      }
      return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
    }
    const $x = convertToTensor(x, "x", "conv2d", "float32");
    const $filter = convertToTensor(filter, "filter", "conv2d", "float32");
    let x4D = $x;
    let reshapedTo4D = false;
    if ($x.rank === 3) {
      reshapedTo4D = true;
      x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    }
    assert(x4D.rank === 4, () => `Error in fused conv2d: input must be rank 4, but got rank ${x4D.rank}.`);
    assert($filter.rank === 4, () => `Error in fused conv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
    if (dimRoundingMode != null) {
      assert(isInt(pad2), () => `Error in fused conv2d: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad2}.`);
    }
    assert(x4D.shape[3] === $filter.shape[2], () => `Error in conv2d: depth of input (${x4D.shape[3]}) must match input depth for filter ${$filter.shape[2]}.`);
    assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in conv2D: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
    assert(dataFormat === "NHWC", () => `Error in conv2d: got dataFormat of ${dataFormat} but only NHWC is currently supported.`);
    const convInfo = computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad2, dimRoundingMode);
    let $bias;
    if (bias != null) {
      $bias = convertToTensor(bias, "bias", "fused conv2d");
      [$bias] = makeTypesMatch($bias, $x);
      assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);
    }
    let $preluActivationWeights;
    if (preluActivationWeights != null) {
      $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused conv2d");
    }
    const grad = (dy, saved) => {
      const [$filter2, x4D2, y, $bias2] = saved;
      const dyActivation = getFusedDyActivation(dy, y, activation);
      assert(tupleValuesAreOne(dilations), () => `Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${dilations}'`);
      const xDer = conv2DBackpropInput(x4D2.shape, dyActivation, $filter2, strides, pad2);
      const filterDer = conv2DBackpropFilter(x4D2, dyActivation, $filter2.shape, strides, pad2);
      const der = [xDer, filterDer];
      if ($bias2 != null) {
        const biasDer = getFusedBiasGradient($bias2, dyActivation);
        der.push(biasDer);
      }
      return der;
    };
    const inputs = {
      x: x4D,
      filter: $filter,
      bias: $bias,
      preluActivationWeights: $preluActivationWeights
    };
    const attrs = {
      strides,
      pad: pad2,
      dataFormat,
      dilations,
      dimRoundingMode,
      activation,
      leakyreluAlpha
    };
    if (bias == null) {
      const customOp = customGrad((x4D2, filter2, save) => {
        let res = ENGINE.runKernel(FusedConv2D, inputs, attrs);
        save([filter2, x4D2, res]);
        if (reshapedTo4D) {
          res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
        }
        return { value: res, gradFunc: grad };
      });
      return customOp(x4D, $filter);
    } else {
      const customOpWithBias = customGrad((x4D2, filter2, bias2, save) => {
        let res = ENGINE.runKernel(FusedConv2D, inputs, attrs);
        save([filter2, x4D2, res, bias2]);
        if (reshapedTo4D) {
          res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
        }
        return { value: res, gradFunc: grad };
      });
      return customOpWithBias(x4D, $filter, $bias);
    }
  }
  var conv2d2 = op({ fusedConv2d_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_filter.js
  function depthwiseConv2dNativeBackpropFilter_(x, dy, filterShape, strides, pad2, dilations = [1, 1], dimRoundingMode) {
    let x4D = x;
    if (x.rank === 3) {
      x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
    }
    let dy4D = dy;
    if (dy4D.rank === 3) {
      dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
    }
    const inputs = { x: x4D, dy: dy4D };
    const attrs = { strides, pad: pad2, dimRoundingMode, dilations, filterShape };
    return ENGINE.runKernel(DepthwiseConv2dNativeBackpropFilter, inputs, attrs);
  }
  var depthwiseConv2dNativeBackpropFilter = op({ depthwiseConv2dNativeBackpropFilter_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_input.js
  function depthwiseConv2dNativeBackpropInput_(xShape, dy, filter, strides, pad2, dilations = [1, 1], dimRoundingMode) {
    let dy4D = dy;
    let reshapedTo4D = false;
    if (dy.rank === 3) {
      reshapedTo4D = true;
      dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
    }
    const inputs = { dy: dy4D, filter };
    const attrs = { strides, pad: pad2, dimRoundingMode, dilations, inputShape: xShape };
    const res = ENGINE.runKernel(DepthwiseConv2dNativeBackpropInput, inputs, attrs);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  var depthwiseConv2dNativeBackpropInput = op({ depthwiseConv2dNativeBackpropInput_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/fused/depthwise_conv2d.js
  function fusedDepthwiseConv2d_({ x, filter, strides, pad: pad2, dataFormat = "NHWC", dilations = [1, 1], dimRoundingMode, bias, activation = "linear", preluActivationWeights, leakyreluAlpha }) {
    if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
      let result = depthwiseConv2d(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode);
      if (bias != null) {
        result = add3(result, bias);
      }
      return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
    }
    const $x = convertToTensor(x, "x", "depthwiseConv2d", "float32");
    const $filter = convertToTensor(filter, "filter", "depthwiseConv2d", "float32");
    let x4D = $x;
    let reshapedTo4D = false;
    if ($x.rank === 3) {
      reshapedTo4D = true;
      x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    }
    assert(x4D.rank === 4, () => `Error in fused depthwiseConv2d: input must be rank 4, but got rank ${x4D.rank}.`);
    assert($filter.rank === 4, () => `Error in fused depthwiseConv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
    assert(x4D.shape[3] === $filter.shape[2], () => `Error in fused depthwiseConv2d: number of input channels (${x4D.shape[3]}) must match the inChannels dimension in filter ${$filter.shape[2]}.`);
    if (dilations == null) {
      dilations = [1, 1];
    }
    assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in fused depthwiseConv2d: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
    if (dimRoundingMode != null) {
      assert(isInt(pad2), () => `Error in fused depthwiseConv2d: pad must be an integer when using dimRoundingMode ${dimRoundingMode} but got pad ${pad2}.`);
    }
    const convInfo = computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad2, dimRoundingMode, true);
    let $bias;
    if (bias != null) {
      $bias = convertToTensor(bias, "bias", "fused conv2d");
      [$bias] = makeTypesMatch($bias, $x);
      assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);
    }
    let $preluActivationWeights;
    if (preluActivationWeights != null) {
      $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused depthwiseConv2d");
    }
    const grad = (dy, saved) => {
      assert(tupleValuesAreOne(dilations), () => `Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations '${dilations}'`);
      const [$filter2, x4D2, y, bias2] = saved;
      const dyActivation = getFusedDyActivation(dy, y, activation);
      const xDer = depthwiseConv2dNativeBackpropInput(x4D2.shape, dyActivation, $filter2, strides, pad2, dilations, dimRoundingMode);
      const filterDer = depthwiseConv2dNativeBackpropFilter(x4D2, dyActivation, $filter2.shape, strides, pad2, dilations, dimRoundingMode);
      if (bias2 != null) {
        const biasDer = getFusedBiasGradient($bias, dyActivation);
        return [xDer, filterDer, biasDer];
      }
      return [xDer, filterDer];
    };
    const inputs = {
      x: x4D,
      filter: $filter,
      bias: $bias,
      preluActivationWeights: $preluActivationWeights
    };
    const attrs = {
      strides,
      pad: pad2,
      dataFormat,
      dilations,
      dimRoundingMode,
      activation,
      leakyreluAlpha
    };
    if (bias == null) {
      const customOp = customGrad((x4D2, filter2, save) => {
        let res = ENGINE.runKernel(FusedDepthwiseConv2D, inputs, attrs);
        save([filter2, x4D2, res]);
        if (reshapedTo4D) {
          res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
        }
        return { value: res, gradFunc: grad };
      });
      return customOp(x4D, $filter);
    } else {
      const customOpWithBias = customGrad((x4D2, filter2, bias2, save) => {
        let res = ENGINE.runKernel(FusedDepthwiseConv2D, inputs, attrs);
        save([filter2, x4D2, res, bias2]);
        if (reshapedTo4D) {
          res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
        }
        return { value: res, gradFunc: grad };
      });
      return customOpWithBias(x4D, $filter, $bias);
    }
  }
  var depthwiseConv2d2 = op({ fusedDepthwiseConv2d_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/fused/mat_mul.js
  function fusedMatMul_({ a, b, transposeA = false, transposeB = false, bias, activation = "linear", preluActivationWeights, leakyreluAlpha }) {
    if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
      let result = matMul(a, b, transposeA, transposeB);
      if (bias != null) {
        result = add3(result, bias);
      }
      return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
    }
    let $a = convertToTensor(a, "a", "fused matMul");
    let $b = convertToTensor(b, "b", "fused matMul");
    [$a, $b] = makeTypesMatch($a, $b);
    const innerShapeA = transposeA ? $a.shape[$a.rank - 2] : $a.shape[$a.rank - 1];
    const innerShapeB = transposeB ? $b.shape[$b.rank - 1] : $b.shape[$b.rank - 2];
    const outerShapeA = transposeA ? $a.shape[$a.rank - 1] : $a.shape[$a.rank - 2];
    const outerShapeB = transposeB ? $b.shape[$b.rank - 2] : $b.shape[$b.rank - 1];
    const outerDimsA = $a.shape.slice(0, -2);
    const outerDimsB = $b.shape.slice(0, -2);
    const batchDimA = sizeFromShape(outerDimsA);
    const batchDimB = sizeFromShape(outerDimsB);
    assert($a.rank >= 2 && $b.rank >= 2 && $a.rank === $b.rank, () => `Error in fused matMul: inputs must have the same rank of at least 2, got ranks ${$a.rank} and ${$b.rank}.`);
    assert(arraysEqual(outerDimsA, outerDimsB), () => `Error in fused matMul: outer dimensions (${outerDimsA}) and (${outerDimsB}) of Tensors with shapes ${$a.shape} and ${$b.shape} must match.`);
    assert(innerShapeA === innerShapeB, () => `Error in fused matMul: inner shapes (${innerShapeA}) and (${innerShapeB}) of Tensors with shapes ${$a.shape} and ${$b.shape} and transposeA=${transposeA} and transposeB=${transposeB} must match.`);
    const outShape = $a.shape.slice(0, -2).concat([outerShapeA, outerShapeB]);
    const a3D = transposeA ? reshape($a, [batchDimA, innerShapeA, outerShapeA]) : reshape($a, [batchDimA, outerShapeA, innerShapeA]);
    const b3D = transposeB ? reshape($b, [batchDimB, outerShapeB, innerShapeB]) : reshape($b, [batchDimB, innerShapeB, outerShapeB]);
    let $bias;
    if (bias != null) {
      $bias = convertToTensor(bias, "bias", "fused matMul");
      [$bias] = makeTypesMatch($bias, $a);
      assertAndGetBroadcastShape(outShape, $bias.shape);
    }
    let $preluActivationWeights;
    if (preluActivationWeights != null) {
      $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused matMul");
    }
    const grad = (dy, saved) => {
      const [a3D2, b3D2, y, $bias2] = saved;
      const dyActivation = getFusedDyActivation(reshape(dy, y.shape), y, activation);
      let aDer;
      let bDer;
      if (!transposeA && !transposeB) {
        aDer = matMul(dyActivation, b3D2, false, true);
        bDer = matMul(a3D2, dyActivation, true, false);
      } else if (!transposeA && transposeB) {
        aDer = matMul(dyActivation, b3D2, false, false);
        bDer = matMul(dyActivation, a3D2, true, false);
      } else if (transposeA && !transposeB) {
        aDer = matMul(b3D2, dyActivation, false, true);
        bDer = matMul(a3D2, dyActivation, false, false);
      } else {
        aDer = matMul(b3D2, dyActivation, true, true);
        bDer = matMul(dyActivation, a3D2, true, true);
      }
      if (bias != null) {
        const biasDer = getFusedBiasGradient($bias2, dyActivation);
        return [aDer, bDer, biasDer];
      } else {
        return [aDer, bDer];
      }
    };
    const inputs = {
      a: a3D,
      b: b3D,
      bias: $bias,
      preluActivationWeights: $preluActivationWeights
    };
    const attrs = { transposeA, transposeB, activation, leakyreluAlpha };
    if (bias == null) {
      const customOp = customGrad((a3D2, b3D2, save) => {
        const res = ENGINE.runKernel(_FusedMatMul, inputs, attrs);
        save([a3D2, b3D2, res]);
        return { value: reshape(res, outShape), gradFunc: grad };
      });
      return customOp(a3D, b3D);
    } else {
      const customOpWithBias = customGrad((a3D2, b3D2, $bias2, save) => {
        const res = ENGINE.runKernel(_FusedMatMul, inputs, attrs);
        save([a3D2, b3D2, res, $bias2]);
        return { value: reshape(res, outShape), gradFunc: grad };
      });
      return customOpWithBias(a3D, b3D, $bias);
    }
  }
  var matMul2 = op({ fusedMatMul_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/crop_and_resize.js
  function cropAndResize_(image3, boxes, boxInd, cropSize, method = "bilinear", extrapolationValue = 0) {
    const $image = convertToTensor(image3, "image", "cropAndResize");
    const $boxes = convertToTensor(boxes, "boxes", "cropAndResize", "float32");
    const $boxInd = convertToTensor(boxInd, "boxInd", "cropAndResize", "int32");
    const numBoxes = $boxes.shape[0];
    assert($image.rank === 4, () => `Error in cropAndResize: image must be rank 4,but got rank ${$image.rank}.`);
    assert($boxes.rank === 2 && $boxes.shape[1] === 4, () => `Error in cropAndResize: boxes must be have size [${numBoxes},4] but had shape ${$boxes.shape}.`);
    assert($boxInd.rank === 1 && $boxInd.shape[0] === numBoxes, () => `Error in cropAndResize: boxInd must be have size [${numBoxes}] but had shape ${$boxes.shape}.`);
    assert(cropSize.length === 2, () => `Error in cropAndResize: cropSize must be of length 2, but got length ${cropSize.length}.`);
    assert(cropSize[0] >= 1 && cropSize[1] >= 1, () => `cropSize must be atleast [1,1], but was ${cropSize}`);
    assert(method === "bilinear" || method === "nearest", () => `method must be bilinear or nearest, but was ${method}`);
    const inputs = { image: $image, boxes: $boxes, boxInd: $boxInd };
    const attrs = { method, extrapolationValue, cropSize };
    const res = ENGINE.runKernel(CropAndResize, inputs, attrs);
    return res;
  }
  var cropAndResize = op({ cropAndResize_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/flip_left_right.js
  function flipLeftRight_(image3) {
    const $image = convertToTensor(image3, "image", "flipLeftRight", "float32");
    assert($image.rank === 4, () => `Error in flipLeftRight: image must be rank 4,but got rank ${$image.rank}.`);
    const inputs = { image: $image };
    const res = ENGINE.runKernel(FlipLeftRight, inputs, {});
    return res;
  }
  var flipLeftRight = op({ flipLeftRight_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/grayscale_to_rgb.js
  function grayscaleToRGB_(image3) {
    const $image = convertToTensor(image3, "image", "grayscaleToRGB");
    const lastDimsIdx = $image.rank - 1;
    const lastDims = $image.shape[lastDimsIdx];
    assert($image.rank >= 2, () => `Error in grayscaleToRGB: images must be at least rank 2, but got rank ${$image.rank}.`);
    assert(lastDims === 1, () => `Error in grayscaleToRGB: last dimension of a grayscale image should be size 1, but got size ${lastDims}.`);
    const reps = new Array($image.rank);
    reps.fill(1, 0, lastDimsIdx);
    reps[lastDimsIdx] = 3;
    return tile($image, reps);
  }
  var grayscaleToRGB = op({ grayscaleToRGB_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/rotate_with_offset.js
  function rotateWithOffset_(image3, radians, fillValue = 0, center = 0.5) {
    const $image = convertToTensor(image3, "image", "rotateWithOffset", "float32");
    assert($image.rank === 4, () => `Error in rotateWithOffset: image must be rank 4,but got rank ${$image.rank}.`);
    const inputs = { image: $image };
    const attrs = { radians, fillValue, center };
    const res = ENGINE.runKernel(RotateWithOffset, inputs, attrs);
    return res;
  }
  var rotateWithOffset = op({ rotateWithOffset_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/nonmax_util.js
  function nonMaxSuppSanityCheck(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
    if (iouThreshold == null) {
      iouThreshold = 0.5;
    }
    if (scoreThreshold == null) {
      scoreThreshold = Number.NEGATIVE_INFINITY;
    }
    if (softNmsSigma == null) {
      softNmsSigma = 0;
    }
    const numBoxes = boxes.shape[0];
    maxOutputSize = Math.min(maxOutputSize, numBoxes);
    assert(0 <= iouThreshold && iouThreshold <= 1, () => `iouThreshold must be in [0, 1], but was '${iouThreshold}'`);
    assert(boxes.rank === 2, () => `boxes must be a 2D tensor, but was of rank '${boxes.rank}'`);
    assert(boxes.shape[1] === 4, () => `boxes must have 4 columns, but 2nd dimension was ${boxes.shape[1]}`);
    assert(scores.rank === 1, () => "scores must be a 1D tensor");
    assert(scores.shape[0] === numBoxes, () => `scores has incompatible shape with boxes. Expected ${numBoxes}, but was ${scores.shape[0]}`);
    assert(0 <= softNmsSigma && softNmsSigma <= 1, () => `softNmsSigma must be in [0, 1], but was '${softNmsSigma}'`);
    return { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression.js
  function nonMaxSuppression_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY) {
    const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression", "float32");
    const $scores = convertToTensor(scores, "scores", "nonMaxSuppression", "float32");
    const inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);
    maxOutputSize = inputs.maxOutputSize;
    iouThreshold = inputs.iouThreshold;
    scoreThreshold = inputs.scoreThreshold;
    const attrs = { maxOutputSize, iouThreshold, scoreThreshold };
    return ENGINE.runKernel(NonMaxSuppressionV3, { boxes: $boxes, scores: $scores }, attrs);
  }
  var nonMaxSuppression = op({ nonMaxSuppression_ });

  // node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_util.js
  function binaryInsert(arr, element, comparator) {
    const index = binarySearch(arr, element, comparator);
    const insertionPoint = index < 0 ? -(index + 1) : index;
    arr.splice(insertionPoint, 0, element);
  }
  function binarySearch(arr, target, comparator) {
    return binarySearch_(arr, target, comparator || defaultComparator);
  }
  function defaultComparator(a, b) {
    return a > b ? 1 : a < b ? -1 : 0;
  }
  function binarySearch_(arr, target, comparator) {
    let left = 0;
    let right = arr.length;
    let middle = 0;
    let found = false;
    while (left < right) {
      middle = left + (right - left >>> 1);
      const compareResult = comparator(target, arr[middle]);
      if (compareResult > 0) {
        left = middle + 1;
      } else {
        right = middle;
        found = !compareResult;
      }
    }
    return found ? left : -left - 1;
  }

  // node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js
  function nonMaxSuppressionV3Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {
    return nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, 0);
  }
  function nonMaxSuppressionV4Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize) {
    return nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, 0, false, padToMaxOutputSize, true);
  }
  function nonMaxSuppressionV5Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
    return nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, true);
  }
  function nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, returnScoresTensor = false, padToMaxOutputSize = false, returnValidOutputs = false) {
    const candidates = [];
    for (let i = 0; i < scores.length; i++) {
      if (scores[i] > scoreThreshold) {
        candidates.push({ score: scores[i], boxIndex: i, suppressBeginIndex: 0 });
      }
    }
    candidates.sort(ascendingComparator);
    const scale2 = softNmsSigma > 0 ? -0.5 / softNmsSigma : 0;
    const selectedIndices = [];
    const selectedScores = [];
    while (selectedIndices.length < maxOutputSize && candidates.length > 0) {
      const candidate = candidates.pop();
      const { score: originalScore, boxIndex, suppressBeginIndex } = candidate;
      if (originalScore < scoreThreshold) {
        break;
      }
      let ignoreCandidate = false;
      for (let j = selectedIndices.length - 1; j >= suppressBeginIndex; --j) {
        const iou = intersectionOverUnion(boxes, boxIndex, selectedIndices[j]);
        if (iou >= iouThreshold) {
          ignoreCandidate = true;
          break;
        }
        candidate.score = candidate.score * suppressWeight(iouThreshold, scale2, iou);
        if (candidate.score <= scoreThreshold) {
          break;
        }
      }
      candidate.suppressBeginIndex = selectedIndices.length;
      if (!ignoreCandidate) {
        if (candidate.score === originalScore) {
          selectedIndices.push(boxIndex);
          selectedScores.push(candidate.score);
        } else if (candidate.score > scoreThreshold) {
          binaryInsert(candidates, candidate, ascendingComparator);
        }
      }
    }
    const validOutputs = selectedIndices.length;
    const elemsToPad = maxOutputSize - validOutputs;
    if (padToMaxOutputSize && elemsToPad > 0) {
      selectedIndices.push(...new Array(elemsToPad).fill(0));
      selectedScores.push(...new Array(elemsToPad).fill(0));
    }
    const result = { selectedIndices };
    if (returnScoresTensor) {
      result["selectedScores"] = selectedScores;
    }
    if (returnValidOutputs) {
      result["validOutputs"] = validOutputs;
    }
    return result;
  }
  function intersectionOverUnion(boxes, i, j) {
    const iCoord = boxes.subarray(i * 4, i * 4 + 4);
    const jCoord = boxes.subarray(j * 4, j * 4 + 4);
    const yminI = Math.min(iCoord[0], iCoord[2]);
    const xminI = Math.min(iCoord[1], iCoord[3]);
    const ymaxI = Math.max(iCoord[0], iCoord[2]);
    const xmaxI = Math.max(iCoord[1], iCoord[3]);
    const yminJ = Math.min(jCoord[0], jCoord[2]);
    const xminJ = Math.min(jCoord[1], jCoord[3]);
    const ymaxJ = Math.max(jCoord[0], jCoord[2]);
    const xmaxJ = Math.max(jCoord[1], jCoord[3]);
    const areaI = (ymaxI - yminI) * (xmaxI - xminI);
    const areaJ = (ymaxJ - yminJ) * (xmaxJ - xminJ);
    if (areaI <= 0 || areaJ <= 0) {
      return 0;
    }
    const intersectionYmin = Math.max(yminI, yminJ);
    const intersectionXmin = Math.max(xminI, xminJ);
    const intersectionYmax = Math.min(ymaxI, ymaxJ);
    const intersectionXmax = Math.min(xmaxI, xmaxJ);
    const intersectionArea = Math.max(intersectionYmax - intersectionYmin, 0) * Math.max(intersectionXmax - intersectionXmin, 0);
    return intersectionArea / (areaI + areaJ - intersectionArea);
  }
  function suppressWeight(iouThreshold, scale2, iou) {
    const weight = Math.exp(scale2 * iou * iou);
    return iou <= iouThreshold ? weight : 0;
  }
  function ascendingComparator(c1, c2) {
    return c1.score - c2.score || c1.score === c2.score && c2.boxIndex - c1.boxIndex;
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_async.js
  async function nonMaxSuppressionAsync_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY) {
    const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
    const $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
    const inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);
    maxOutputSize = inputs.maxOutputSize;
    iouThreshold = inputs.iouThreshold;
    scoreThreshold = inputs.scoreThreshold;
    const boxesAndScores = await Promise.all([$boxes.data(), $scores.data()]);
    const boxesVals = boxesAndScores[0];
    const scoresVals = boxesAndScores[1];
    const { selectedIndices } = nonMaxSuppressionV3Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);
    if ($boxes !== boxes) {
      $boxes.dispose();
    }
    if ($scores !== scores) {
      $scores.dispose();
    }
    return tensor1d(selectedIndices, "int32");
  }
  var nonMaxSuppressionAsync = nonMaxSuppressionAsync_;

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score.js
  function nonMaxSuppressionWithScore_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, softNmsSigma = 0) {
    const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression");
    const $scores = convertToTensor(scores, "scores", "nonMaxSuppression");
    const params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
    maxOutputSize = params.maxOutputSize;
    iouThreshold = params.iouThreshold;
    scoreThreshold = params.scoreThreshold;
    softNmsSigma = params.softNmsSigma;
    const inputs = { boxes: $boxes, scores: $scores };
    const attrs = { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };
    const result = ENGINE.runKernel(NonMaxSuppressionV5, inputs, attrs);
    return { selectedIndices: result[0], selectedScores: result[1] };
  }
  var nonMaxSuppressionWithScore = op({ nonMaxSuppressionWithScore_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score_async.js
  async function nonMaxSuppressionWithScoreAsync_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, softNmsSigma = 0) {
    const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
    const $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
    const params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
    maxOutputSize = params.maxOutputSize;
    iouThreshold = params.iouThreshold;
    scoreThreshold = params.scoreThreshold;
    softNmsSigma = params.softNmsSigma;
    const boxesAndScores = await Promise.all([$boxes.data(), $scores.data()]);
    const boxesVals = boxesAndScores[0];
    const scoresVals = boxesAndScores[1];
    const { selectedIndices, selectedScores } = nonMaxSuppressionV5Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
    if ($boxes !== boxes) {
      $boxes.dispose();
    }
    if ($scores !== scores) {
      $scores.dispose();
    }
    return {
      selectedIndices: tensor1d(selectedIndices, "int32"),
      selectedScores: tensor1d(selectedScores)
    };
  }
  var nonMaxSuppressionWithScoreAsync = nonMaxSuppressionWithScoreAsync_;

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded.js
  function nonMaxSuppressionPadded_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, padToMaxOutputSize = false) {
    const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression");
    const $scores = convertToTensor(scores, "scores", "nonMaxSuppression");
    const params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, null);
    const $maxOutputSize = params.maxOutputSize;
    const $iouThreshold = params.iouThreshold;
    const $scoreThreshold = params.scoreThreshold;
    const inputs = { boxes: $boxes, scores: $scores };
    const attrs = {
      maxOutputSize: $maxOutputSize,
      iouThreshold: $iouThreshold,
      scoreThreshold: $scoreThreshold,
      padToMaxOutputSize
    };
    const result = ENGINE.runKernel(NonMaxSuppressionV4, inputs, attrs);
    return { selectedIndices: result[0], validOutputs: result[1] };
  }
  var nonMaxSuppressionPadded = op({ nonMaxSuppressionPadded_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded_async.js
  async function nonMaxSuppressionPaddedAsync_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, padToMaxOutputSize = false) {
    const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
    const $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
    const params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, null);
    const $maxOutputSize = params.maxOutputSize;
    const $iouThreshold = params.iouThreshold;
    const $scoreThreshold = params.scoreThreshold;
    const [boxesVals, scoresVals] = await Promise.all([$boxes.data(), $scores.data()]);
    const { selectedIndices, validOutputs } = nonMaxSuppressionV4Impl(boxesVals, scoresVals, $maxOutputSize, $iouThreshold, $scoreThreshold, padToMaxOutputSize);
    if ($boxes !== boxes) {
      $boxes.dispose();
    }
    if ($scores !== scores) {
      $scores.dispose();
    }
    return {
      selectedIndices: tensor1d(selectedIndices, "int32"),
      validOutputs: scalar(validOutputs, "int32")
    };
  }
  var nonMaxSuppressionPaddedAsync = nonMaxSuppressionPaddedAsync_;

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/resize_bilinear.js
  function resizeBilinear_(images, size2, alignCorners = false, halfPixelCenters = false) {
    const $images = convertToTensor(images, "images", "resizeBilinear");
    assert($images.rank === 3 || $images.rank === 4, () => `Error in resizeBilinear: x must be rank 3 or 4, but got rank ${$images.rank}.`);
    assert(size2.length === 2, () => `Error in resizeBilinear: new shape must 2D, but got shape ${size2}.`);
    assert(halfPixelCenters === false || alignCorners === false, () => `Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false.`);
    let batchImages = $images;
    let reshapedTo4D = false;
    if ($images.rank === 3) {
      reshapedTo4D = true;
      batchImages = reshape($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);
    }
    const [] = size2;
    const inputs = { images: batchImages };
    const attrs = { alignCorners, halfPixelCenters, size: size2 };
    const res = ENGINE.runKernel(ResizeBilinear, inputs, attrs);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  var resizeBilinear = op({ resizeBilinear_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/resize_nearest_neighbor.js
  function resizeNearestNeighbor_(images, size2, alignCorners = false, halfPixelCenters = false) {
    const $images = convertToTensor(images, "images", "resizeNearestNeighbor");
    assert($images.rank === 3 || $images.rank === 4, () => `Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ${$images.rank}.`);
    assert(size2.length === 2, () => `Error in resizeNearestNeighbor: new shape must 2D, but got shape ${size2}.`);
    assert($images.dtype === "float32" || $images.dtype === "int32", () => "`images` must have `int32` or `float32` as dtype");
    assert(halfPixelCenters === false || alignCorners === false, () => `Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false.`);
    let batchImages = $images;
    let reshapedTo4D = false;
    if ($images.rank === 3) {
      reshapedTo4D = true;
      batchImages = reshape($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);
    }
    const [] = size2;
    const inputs = { images: batchImages };
    const attrs = { alignCorners, halfPixelCenters, size: size2 };
    const res = ENGINE.runKernel(ResizeNearestNeighbor, inputs, attrs);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  var resizeNearestNeighbor = op({ resizeNearestNeighbor_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/threshold.js
  function threshold_(image3, method = "binary", inverted = false, threshValue = 0.5) {
    const $image = convertToTensor(image3, "image", "threshold");
    const RED_INTENCITY_COEF = 0.2989;
    const GREEN_INTENCITY_COEF = 0.587;
    const BLUE_INTENCITY_COEF = 0.114;
    const totalPixelsInImage = $image.shape[0] * $image.shape[1];
    let $threshold = mul(tensor1d([threshValue]), 255);
    let r, g, b, grayscale;
    assert($image.rank === 3, () => `Error in threshold: image must be rank 3,but got rank ${$image.rank}.`);
    assert($image.shape[2] === 3 || $image.shape[2] === 1, () => `Error in threshold: image color channel must be equal to 3 or 1but got ${$image.shape[2]}.`);
    assert($image.dtype === "int32" || $image.dtype === "float32", () => `Error in dtype: image dtype must be int32 or float32,but got dtype ${$image.dtype}.`);
    assert(method === "otsu" || method === "binary", () => `Method must be binary or otsu, but was ${method}`);
    if ($image.shape[2] === 3) {
      [r, g, b] = split($image, [1, 1, 1], -1);
      const $r = mul(r, RED_INTENCITY_COEF);
      const $g = mul(g, GREEN_INTENCITY_COEF);
      const $b = mul(b, BLUE_INTENCITY_COEF);
      grayscale = add3(add3($r, $g), $b);
    } else {
      grayscale = image3;
    }
    if (method === "otsu") {
      const $histogram = bincount(cast(round2(grayscale), "int32"), tensor([]), 256);
      $threshold = otsu($histogram, totalPixelsInImage);
    }
    const invCondition = inverted ? lessEqual(grayscale, $threshold) : greater(grayscale, $threshold);
    const result = cast(mul(invCondition, 255), "int32");
    return result;
  }
  function otsu(histogram, total) {
    let bestThresh = tensor1d([-1]);
    let bestInBetVar = tensor1d([0]);
    let cInBetVar = tensor1d([0]);
    let classFirst, classSecond, meanFirst, meanSec, weightForeground, weightBack;
    for (let index = 0; index < histogram.size - 1; index++) {
      classFirst = slice(histogram, 0, index + 1);
      classSecond = slice(histogram, index + 1);
      weightForeground = div(sum2(classFirst), total);
      weightBack = div(sum2(classSecond), total);
      const meanFirstDivA = sum2(mul(classFirst, range(0, classFirst.size)));
      meanFirst = div(meanFirstDivA, sum2(classFirst));
      const meanSecFill = fill(classSecond.shape, classFirst.size);
      const meanSecAdd = add3(range(0, classSecond.size), meanSecFill);
      const meanSecMul = mul(classSecond, meanSecAdd);
      meanSec = div(sum2(meanSecMul), sum2(classSecond));
      const cInBetVarSubA = sub(meanFirst, meanSec);
      const cInBetVarSubB = sub(meanFirst, meanSec);
      const cInBetVarMul = mul(weightForeground, weightBack);
      cInBetVar = mul(mul(cInBetVarMul, cInBetVarSubA), cInBetVarSubB);
      const condition = greater(cInBetVar, bestInBetVar);
      bestInBetVar = where(condition, cInBetVar, bestInBetVar);
      bestThresh = where(condition, tensor1d([index]), bestThresh);
    }
    return bestThresh;
  }
  var threshold = op({ threshold_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/transform.js
  function transform_(image3, transforms, interpolation = "nearest", fillMode = "constant", fillValue = 0, outputShape) {
    const $image = convertToTensor(image3, "image", "transform", "float32");
    const $transforms = convertToTensor(transforms, "transforms", "transform", "float32");
    assert($image.rank === 4, () => `Error in transform: image must be rank 4,but got rank ${$image.rank}.`);
    assert($transforms.rank === 2 && ($transforms.shape[0] === $image.shape[0] || $transforms.shape[0] === 1) && $transforms.shape[1] === 8, () => `Error in transform: Input transform should be batch x 8 or 1 x 8`);
    assert(outputShape == null || outputShape.length === 2, () => `Error in transform: outputShape must be [height, width] or null, but got ${outputShape}.`);
    const inputs = { image: $image, transforms: $transforms };
    const attrs = { interpolation, fillMode, fillValue, outputShape };
    return ENGINE.runKernel(Transform, inputs, attrs);
  }
  var transform = op({ transform_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/linalg/band_part.js
  function bandPart_(a, numLower, numUpper) {
    assert(numLower % 1 === 0, () => `bandPart(): numLower must be an integer, got ${numLower}.`);
    assert(numUpper % 1 === 0, () => `bandPart(): numUpper must be an integer, got ${numUpper}.`);
    const $a = convertToTensor(a, "a", "bandPart");
    assert($a.rank >= 2, () => `bandPart(): Rank must be at least 2, got ${$a.rank}.`);
    const shape = $a.shape;
    const [M, N] = $a.shape.slice(-2);
    if (!(numLower <= M)) {
      throw new Error(`bandPart(): numLower (${numLower}) must not be greater than the number of rows (${M}).`);
    }
    if (!(numUpper <= N)) {
      throw new Error(`bandPart(): numUpper (${numUpper}) must not be greater than the number of columns (${N}).`);
    }
    if (numLower < 0) {
      numLower = M;
    }
    if (numUpper < 0) {
      numUpper = N;
    }
    const i = reshape(range(0, M, 1, "int32"), [-1, 1]);
    const j = range(0, N, 1, "int32");
    const ij = sub(i, j);
    const inBand = logicalAnd(lessEqual(ij, scalar(+numLower, "int32")), greaterEqual(ij, scalar(-numUpper, "int32")));
    const zero = zeros([M, N], $a.dtype);
    return reshape(stack2(unstack(reshape($a, [-1, M, N])).map((mat) => where(inBand, mat, zero))), shape);
  }
  var bandPart = op({ bandPart_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/linalg/gram_schmidt.js
  function gramSchmidt_(xs) {
    let inputIsTensor2D;
    if (Array.isArray(xs)) {
      inputIsTensor2D = false;
      assert(xs != null && xs.length > 0, () => "Gram-Schmidt process: input must not be null, undefined, or empty");
      const dim = xs[0].shape[0];
      for (let i = 1; i < xs.length; ++i) {
        assert(xs[i].shape[0] === dim, () => `Gram-Schmidt: Non-unique lengths found in the input vectors: (${xs[i].shape[0]} vs. ${dim})`);
      }
    } else {
      inputIsTensor2D = true;
      xs = split(xs, xs.shape[0], 0).map((x) => squeeze(x, [0]));
    }
    assert(xs.length <= xs[0].shape[0], () => `Gram-Schmidt: Number of vectors (${xs.length}) exceeds number of dimensions (${xs[0].shape[0]}).`);
    const ys = [];
    const xs1d = xs;
    for (let i = 0; i < xs.length; ++i) {
      ys.push(ENGINE.tidy(() => {
        let x = xs1d[i];
        if (i > 0) {
          for (let j = 0; j < i; ++j) {
            const proj = mul(sum2(mul(ys[j], x)), ys[j]);
            x = sub(x, proj);
          }
        }
        return div(x, norm(x, "euclidean"));
      }));
    }
    if (inputIsTensor2D) {
      return stack2(ys, 0);
    } else {
      return ys;
    }
  }
  var gramSchmidt = op({ gramSchmidt_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/linalg/qr.js
  function qr_(x, fullMatrices = false) {
    assert(x.rank >= 2, () => `qr() requires input tensor to have a rank >= 2, but got rank ${x.rank}`);
    if (x.rank === 2) {
      return qr2d(x, fullMatrices);
    } else {
      const outerDimsProd = x.shape.slice(0, x.shape.length - 2).reduce((value, prev) => value * prev);
      const x2ds = unstack(reshape(x, [
        outerDimsProd,
        x.shape[x.shape.length - 2],
        x.shape[x.shape.length - 1]
      ]), 0);
      const q2ds = [];
      const r2ds = [];
      x2ds.forEach((x2d) => {
        const [q2d, r2d] = qr2d(x2d, fullMatrices);
        q2ds.push(q2d);
        r2ds.push(r2d);
      });
      const q = reshape(stack2(q2ds, 0), x.shape);
      const r = reshape(stack2(r2ds, 0), x.shape);
      return [q, r];
    }
  }
  function qr2d(x, fullMatrices = false) {
    return ENGINE.tidy(() => {
      assert(x.shape.length === 2, () => `qr2d() requires a 2D Tensor, but got a ${x.shape.length}D Tensor.`);
      const m = x.shape[0];
      const n = x.shape[1];
      let q = eye(m);
      let r = clone(x);
      const one2D = tensor2d([[1]], [1, 1]);
      let w = clone(one2D);
      const iters = m >= n ? n : m;
      for (let j = 0; j < iters; ++j) {
        const rTemp = r;
        const wTemp = w;
        const qTemp = q;
        [w, r, q] = ENGINE.tidy(() => {
          const rjEnd1 = slice(r, [j, j], [m - j, 1]);
          const normX = norm(rjEnd1);
          const rjj = slice(r, [j, j], [1, 1]);
          const s = where(greater(rjj, 0), tensor2d([[-1]]), tensor2d([[1]]));
          const u1 = sub(rjj, mul(s, normX));
          const wPre = div(rjEnd1, u1);
          if (wPre.shape[0] === 1) {
            w = clone(one2D);
          } else {
            w = concat([
              one2D,
              slice(wPre, [1, 0], [wPre.shape[0] - 1, wPre.shape[1]])
            ], 0);
          }
          const tau = neg(div(matMul(s, u1), normX));
          const rjEndAll = slice(r, [j, 0], [m - j, n]);
          const tauTimesW = mul(tau, w);
          const wT = transpose(w);
          if (j === 0) {
            r = sub(rjEndAll, matMul(tauTimesW, matMul(wT, rjEndAll)));
          } else {
            const rTimesTau = sub(rjEndAll, matMul(tauTimesW, matMul(wT, rjEndAll)));
            r = concat([slice(r, [0, 0], [j, n]), rTimesTau], 0);
          }
          const tawTimesWT = transpose(tauTimesW);
          const qAllJEnd = slice(q, [0, j], [m, q.shape[1] - j]);
          if (j === 0) {
            q = sub(qAllJEnd, matMul(matMul(qAllJEnd, w), tawTimesWT));
          } else {
            const qTimesTau = sub(qAllJEnd, matMul(matMul(qAllJEnd, w), tawTimesWT));
            q = concat([slice(q, [0, 0], [m, j]), qTimesTau], 1);
          }
          return [w, r, q];
        });
        dispose([rTemp, wTemp, qTemp]);
      }
      if (!fullMatrices && m > n) {
        q = slice(q, [0, 0], [m, n]);
        r = slice(r, [0, 0], [n, n]);
      }
      return [q, r];
    });
  }
  var qr = op({ qr_ });

  // node_modules/@tensorflow/tfjs-core/dist/ops/ops.js
  var image = {
    flipLeftRight,
    grayscaleToRGB,
    resizeNearestNeighbor,
    resizeBilinear,
    rotateWithOffset,
    cropAndResize,
    nonMaxSuppression,
    nonMaxSuppressionAsync,
    nonMaxSuppressionWithScore,
    nonMaxSuppressionWithScoreAsync,
    nonMaxSuppressionPadded,
    nonMaxSuppressionPaddedAsync,
    threshold,
    transform
  };
  var linalg = {
    bandPart,
    gramSchmidt,
    qr
  };

  // node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer.js
  var Optimizer = class extends Serializable {
    minimize(f, returnCost = false, varList) {
      const { value, grads } = this.computeGradients(f, varList);
      if (varList != null) {
        const gradArray = varList.map((v) => ({ name: v.name, tensor: grads[v.name] }));
        this.applyGradients(gradArray);
      } else {
        this.applyGradients(grads);
      }
      dispose(grads);
      if (returnCost) {
        return value;
      } else {
        value.dispose();
        return null;
      }
    }
    get iterations() {
      if (this.iterations_ == null) {
        this.iterations_ = 0;
      }
      return this.iterations_;
    }
    incrementIterations() {
      this.iterations_ = this.iterations + 1;
    }
    computeGradients(f, varList) {
      return variableGrads(f, varList);
    }
    dispose() {
      if (this.iterations_ != null) {
        dispose(this.iterations_);
      }
    }
    async saveIterations() {
      if (this.iterations_ == null) {
        this.iterations_ = 0;
      }
      return {
        name: "iter",
        tensor: scalar(this.iterations_, "int32")
      };
    }
    async getWeights() {
      throw new Error("getWeights() is not implemented for this optimizer yet.");
    }
    async setWeights(weightValues) {
      throw new Error(`setWeights() is not implemented for this optimizer class ${this.getClassName()}`);
    }
    async extractIterations(weightValues) {
      this.iterations_ = (await weightValues[0].tensor.data())[0];
      return weightValues.slice(1);
    }
  };
  Object.defineProperty(Optimizer, Symbol.hasInstance, {
    value: (instance) => {
      return instance.minimize != null && instance.computeGradients != null && instance.applyGradients != null;
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/optimizers/adadelta_optimizer.js
  var AdadeltaOptimizer = class extends Optimizer {
    constructor(learningRate, rho, epsilon3 = null) {
      super();
      this.learningRate = learningRate;
      this.rho = rho;
      this.epsilon = epsilon3;
      this.accumulatedGrads = [];
      this.accumulatedUpdates = [];
      if (epsilon3 == null) {
        this.epsilon = ENGINE.backend.epsilon();
      }
    }
    applyGradients(variableGradients) {
      const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
      variableNames.forEach((name, i) => {
        const value = ENGINE.registeredVariables[name];
        const trainable = false;
        if (this.accumulatedGrads[i] == null) {
          this.accumulatedGrads[i] = {
            originalName: `${name}/accum_grad`,
            variable: tidy(() => zerosLike(value).variable(trainable))
          };
        }
        if (this.accumulatedUpdates[i] == null) {
          this.accumulatedUpdates[i] = {
            originalName: `${name}/accum_var`,
            variable: tidy(() => zerosLike(value).variable(trainable))
          };
        }
        const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
        if (gradient == null) {
          return;
        }
        const accumulatedGrad = this.accumulatedGrads[i].variable;
        const accumulatedUpdate = this.accumulatedUpdates[i].variable;
        tidy(() => {
          const newAccumulatedGrad = add3(mul(accumulatedGrad, this.rho), mul(square(gradient), 1 - this.rho));
          const updates = mul(div(sqrt(add3(accumulatedUpdate, this.epsilon)), sqrt(add3(accumulatedGrad, this.epsilon))), gradient);
          const newAccumulatedUpdate = add3(mul(accumulatedUpdate, this.rho), mul(square(updates), 1 - this.rho));
          accumulatedGrad.assign(newAccumulatedGrad);
          accumulatedUpdate.assign(newAccumulatedUpdate);
          const newValue = add3(mul(updates, -this.learningRate), value);
          value.assign(newValue);
        });
      });
      this.incrementIterations();
    }
    dispose() {
      if (this.accumulatedUpdates != null) {
        dispose(this.accumulatedGrads.map((v) => v.variable));
        dispose(this.accumulatedUpdates.map((v) => v.variable));
      }
    }
    async getWeights() {
      const variables = [...this.accumulatedGrads, ...this.accumulatedUpdates];
      return [await this.saveIterations()].concat(variables.map((v) => ({ name: v.originalName, tensor: v.variable })));
    }
    async setWeights(weightValues) {
      weightValues = await this.extractIterations(weightValues);
      const variableCount = weightValues.length / 2;
      const trainable = false;
      this.accumulatedGrads = weightValues.slice(0, variableCount).map((v) => ({
        originalName: v.name,
        variable: v.tensor.variable(trainable)
      }));
      this.accumulatedUpdates = weightValues.slice(variableCount, variableCount * 2).map((v) => ({
        originalName: v.name,
        variable: v.tensor.variable(trainable)
      }));
    }
    getConfig() {
      return {
        "learningRate": this.learningRate,
        "rho": this.rho,
        "epsilon": this.epsilon
      };
    }
    static fromConfig(cls, config) {
      return new cls(config["learningRate"], config["rho"], config["epsilon"]);
    }
  };
  AdadeltaOptimizer.className = "Adadelta";
  registerClass(AdadeltaOptimizer);

  // node_modules/@tensorflow/tfjs-core/dist/optimizers/adagrad_optimizer.js
  var AdagradOptimizer = class extends Optimizer {
    constructor(learningRate, initialAccumulatorValue = 0.1) {
      super();
      this.learningRate = learningRate;
      this.initialAccumulatorValue = initialAccumulatorValue;
      this.accumulatedGrads = [];
    }
    applyGradients(variableGradients) {
      const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
      variableNames.forEach((name, i) => {
        const value = ENGINE.registeredVariables[name];
        if (this.accumulatedGrads[i] == null) {
          const trainable = false;
          this.accumulatedGrads[i] = {
            originalName: `${name}/accumulator`,
            variable: tidy(() => fill(value.shape, this.initialAccumulatorValue).variable(trainable))
          };
        }
        const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
        if (gradient == null) {
          return;
        }
        const accumulatedGrad = this.accumulatedGrads[i].variable;
        tidy(() => {
          const newAccumulatedGrad = add3(accumulatedGrad, square(gradient));
          accumulatedGrad.assign(newAccumulatedGrad);
          const newValue = add3(mul(div(gradient, sqrt(add3(newAccumulatedGrad, ENGINE.backend.epsilon()))), -this.learningRate), value);
          value.assign(newValue);
        });
      });
      this.incrementIterations();
    }
    dispose() {
      if (this.accumulatedGrads != null) {
        dispose(this.accumulatedGrads.map((v) => v.variable));
      }
    }
    async getWeights() {
      return [await this.saveIterations()].concat(this.accumulatedGrads.map((v) => ({ name: v.originalName, tensor: v.variable })));
    }
    async setWeights(weightValues) {
      weightValues = await this.extractIterations(weightValues);
      const trainable = false;
      this.accumulatedGrads = weightValues.map((v) => ({ originalName: v.name, variable: v.tensor.variable(trainable) }));
    }
    getConfig() {
      return {
        "learningRate": this.learningRate,
        "initialAccumulatorValue": this.initialAccumulatorValue
      };
    }
    static fromConfig(cls, config) {
      return new cls(config["learningRate"], config["initialAccumulatorValue"]);
    }
  };
  AdagradOptimizer.className = "Adagrad";
  registerClass(AdagradOptimizer);

  // node_modules/@tensorflow/tfjs-core/dist/optimizers/adam_optimizer.js
  var AdamOptimizer = class extends Optimizer {
    constructor(learningRate, beta1, beta2, epsilon3 = null) {
      super();
      this.learningRate = learningRate;
      this.beta1 = beta1;
      this.beta2 = beta2;
      this.epsilon = epsilon3;
      this.accumulatedFirstMoment = [];
      this.accumulatedSecondMoment = [];
      tidy(() => {
        this.accBeta1 = scalar(beta1).variable();
        this.accBeta2 = scalar(beta2).variable();
      });
      if (epsilon3 == null) {
        this.epsilon = ENGINE.backend.epsilon();
      }
    }
    applyGradients(variableGradients) {
      const varNames = Array.isArray(variableGradients) ? variableGradients.map((v) => v.name) : Object.keys(variableGradients);
      tidy(() => {
        const oneMinusAccBeta1 = sub(1, this.accBeta1);
        const oneMinusAccBeta2 = sub(1, this.accBeta2);
        varNames.forEach((name, i) => {
          const value = ENGINE.registeredVariables[name];
          const trainable = false;
          if (this.accumulatedFirstMoment[i] == null) {
            this.accumulatedFirstMoment[i] = {
              originalName: `${name}/m`,
              variable: tidy(() => zerosLike(value).variable(trainable))
            };
          }
          if (this.accumulatedSecondMoment[i] == null) {
            this.accumulatedSecondMoment[i] = {
              originalName: `${name}/v`,
              variable: tidy(() => zerosLike(value).variable(trainable))
            };
          }
          const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
          if (gradient == null) {
            return;
          }
          const firstMoment = this.accumulatedFirstMoment[i].variable;
          const secondMoment = this.accumulatedSecondMoment[i].variable;
          const newFirstMoment = add3(mul(firstMoment, this.beta1), mul(gradient, 1 - this.beta1));
          const newSecondMoment = add3(mul(secondMoment, this.beta2), mul(square(gradient), 1 - this.beta2));
          const biasCorrectedFirstMoment = div(newFirstMoment, oneMinusAccBeta1);
          const biasCorrectedSecondMoment = div(newSecondMoment, oneMinusAccBeta2);
          firstMoment.assign(newFirstMoment);
          secondMoment.assign(newSecondMoment);
          const newValue = add3(mul(div(biasCorrectedFirstMoment, add3(sqrt(biasCorrectedSecondMoment), this.epsilon)), -this.learningRate), value);
          value.assign(newValue);
        });
        this.accBeta1.assign(mul(this.accBeta1, this.beta1));
        this.accBeta2.assign(mul(this.accBeta2, this.beta2));
      });
      this.incrementIterations();
    }
    dispose() {
      this.accBeta1.dispose();
      this.accBeta2.dispose();
      if (this.accumulatedFirstMoment != null) {
        dispose(this.accumulatedFirstMoment.map((v) => v.variable));
      }
      if (this.accumulatedSecondMoment != null) {
        dispose(this.accumulatedSecondMoment.map((v) => v.variable));
      }
    }
    async getWeights() {
      const variables = [...this.accumulatedFirstMoment, ...this.accumulatedSecondMoment];
      return [await this.saveIterations()].concat(variables.map((v) => ({ name: v.originalName, tensor: v.variable })));
    }
    async setWeights(weightValues) {
      weightValues = await this.extractIterations(weightValues);
      tidy(() => {
        this.accBeta1.assign(pow(this.beta1, this.iterations_ + 1));
        this.accBeta2.assign(pow(this.beta2, this.iterations_ + 1));
      });
      const variableCount = weightValues.length / 2;
      const trainable = false;
      this.accumulatedFirstMoment = weightValues.slice(0, variableCount).map((v) => ({
        originalName: v.name,
        variable: v.tensor.variable(trainable)
      }));
      this.accumulatedSecondMoment = weightValues.slice(variableCount, variableCount * 2).map((v) => ({
        originalName: v.name,
        variable: v.tensor.variable(trainable)
      }));
    }
    getConfig() {
      return {
        "learningRate": this.learningRate,
        "beta1": this.beta1,
        "beta2": this.beta2,
        "epsilon": this.epsilon
      };
    }
    static fromConfig(cls, config) {
      return new cls(config["learningRate"], config["beta1"], config["beta2"], config["epsilon"]);
    }
  };
  AdamOptimizer.className = "Adam";
  registerClass(AdamOptimizer);

  // node_modules/@tensorflow/tfjs-core/dist/optimizers/adamax_optimizer.js
  var AdamaxOptimizer = class extends Optimizer {
    constructor(learningRate, beta1, beta2, epsilon3 = null, decay = 0) {
      super();
      this.learningRate = learningRate;
      this.beta1 = beta1;
      this.beta2 = beta2;
      this.epsilon = epsilon3;
      this.decay = decay;
      this.accumulatedFirstMoment = [];
      this.accumulatedWeightedInfNorm = [];
      tidy(() => {
        this.iteration = scalar(0).variable();
        this.accBeta1 = scalar(beta1).variable();
      });
      if (epsilon3 == null) {
        this.epsilon = ENGINE.backend.epsilon();
      }
    }
    applyGradients(variableGradients) {
      const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
      tidy(() => {
        const oneMinusAccBeta1 = sub(1, this.accBeta1);
        const lr = div(-this.learningRate, add3(mul(this.iteration, this.decay), 1));
        variableNames.forEach((name, i) => {
          const value = ENGINE.registeredVariables[name];
          const trainable = false;
          if (this.accumulatedFirstMoment[i] == null) {
            this.accumulatedFirstMoment[i] = {
              originalName: `${name}/m`,
              variable: zerosLike(value).variable(trainable)
            };
          }
          if (this.accumulatedWeightedInfNorm[i] == null) {
            this.accumulatedWeightedInfNorm[i] = {
              originalName: `${name}/v`,
              variable: zerosLike(value).variable(trainable)
            };
          }
          const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
          if (gradient == null) {
            return;
          }
          const firstMoment = this.accumulatedFirstMoment[i].variable;
          const weightedInfNorm = this.accumulatedWeightedInfNorm[i].variable;
          const newFirstMoment = add3(mul(firstMoment, this.beta1), mul(gradient, 1 - this.beta1));
          const ut0 = mul(weightedInfNorm, this.beta2);
          const ut1 = abs(gradient);
          const newWeightedInfNorm = maximum(ut0, ut1);
          firstMoment.assign(newFirstMoment);
          weightedInfNorm.assign(newWeightedInfNorm);
          const newValue = add3(mul(div(lr, oneMinusAccBeta1), div(newFirstMoment, add3(newWeightedInfNorm, this.epsilon))), value);
          value.assign(newValue);
        });
        this.iteration.assign(add3(this.iteration, 1));
        this.accBeta1.assign(mul(this.accBeta1, this.beta1));
      });
      this.incrementIterations();
    }
    dispose() {
      this.accBeta1.dispose();
      this.iteration.dispose();
      if (this.accumulatedFirstMoment != null) {
        dispose(this.accumulatedFirstMoment.map((v) => v.variable));
      }
      if (this.accumulatedWeightedInfNorm != null) {
        dispose(this.accumulatedWeightedInfNorm.map((v) => v.variable));
      }
    }
    async getWeights() {
      throw new Error("getWeights() is not implemented for Adamax yet.");
    }
    async setWeights(weightValues) {
      throw new Error("setWeights() is not implemented for Adamax yet.");
    }
    getConfig() {
      return {
        "learningRate": this.learningRate,
        "beta1": this.beta1,
        "beta2": this.beta2,
        "epsilon": this.epsilon,
        "decay": this.decay
      };
    }
    static fromConfig(cls, config) {
      return new cls(config["learningRate"], config["beta1"], config["beta2"], config["epsilon"], config["decay"]);
    }
  };
  AdamaxOptimizer.className = "Adamax";
  registerClass(AdamaxOptimizer);

  // node_modules/@tensorflow/tfjs-core/dist/optimizers/sgd_optimizer.js
  var SGDOptimizer = class extends Optimizer {
    constructor(learningRate) {
      super();
      this.learningRate = learningRate;
      this.setLearningRate(learningRate);
    }
    applyGradients(variableGradients) {
      const varNames = Array.isArray(variableGradients) ? variableGradients.map((v) => v.name) : Object.keys(variableGradients);
      varNames.forEach((name, i) => {
        const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
        if (gradient == null) {
          return;
        }
        const value = ENGINE.registeredVariables[name];
        tidy(() => {
          const newValue = add3(mul(this.c, gradient), value);
          value.assign(newValue);
        });
      });
      this.incrementIterations();
    }
    setLearningRate(learningRate) {
      this.learningRate = learningRate;
      if (this.c != null) {
        this.c.dispose();
      }
      this.c = keep(scalar(-learningRate));
    }
    dispose() {
      this.c.dispose();
    }
    async getWeights() {
      return [await this.saveIterations()];
    }
    async setWeights(weightValues) {
      weightValues = await this.extractIterations(weightValues);
      if (weightValues.length !== 0) {
        throw new Error("SGD optimizer does not have settable weights.");
      }
    }
    getConfig() {
      return { "learningRate": this.learningRate };
    }
    static fromConfig(cls, config) {
      return new cls(config["learningRate"]);
    }
  };
  SGDOptimizer.className = "SGD";
  registerClass(SGDOptimizer);

  // node_modules/@tensorflow/tfjs-core/dist/optimizers/momentum_optimizer.js
  var MomentumOptimizer = class extends SGDOptimizer {
    constructor(learningRate, momentum, useNesterov = false) {
      super(learningRate);
      this.learningRate = learningRate;
      this.momentum = momentum;
      this.useNesterov = useNesterov;
      this.accumulations = [];
      this.m = scalar(this.momentum);
    }
    applyGradients(variableGradients) {
      const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
      variableNames.forEach((name, i) => {
        const value = ENGINE.registeredVariables[name];
        if (this.accumulations[i] == null) {
          const trainable = false;
          this.accumulations[i] = {
            originalName: `${name}/momentum`,
            variable: tidy(() => zerosLike(value).variable(trainable))
          };
        }
        const accumulation = this.accumulations[i].variable;
        const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
        if (gradient == null) {
          return;
        }
        tidy(() => {
          let newValue;
          const newAccumulation = add3(mul(this.m, accumulation), gradient);
          if (this.useNesterov) {
            newValue = add3(mul(this.c, add3(gradient, mul(newAccumulation, this.m))), value);
          } else {
            newValue = add3(mul(this.c, newAccumulation), value);
          }
          accumulation.assign(newAccumulation);
          value.assign(newValue);
        });
      });
      this.incrementIterations();
    }
    dispose() {
      this.m.dispose();
      if (this.accumulations != null) {
        dispose(this.accumulations.map((v) => v.variable));
      }
    }
    setMomentum(momentum) {
      this.momentum = momentum;
    }
    async getWeights() {
      return [await this.saveIterations()].concat(this.accumulations.map((v) => ({ name: v.originalName, tensor: v.variable })));
    }
    async setWeights(weightValues) {
      weightValues = await this.extractIterations(weightValues);
      const trainable = false;
      this.accumulations = weightValues.map((v) => ({ originalName: v.name, variable: v.tensor.variable(trainable) }));
    }
    getConfig() {
      return {
        "learningRate": this.learningRate,
        "momentum": this.momentum,
        "useNesterov": this.useNesterov
      };
    }
    static fromConfig(cls, config) {
      return new cls(config["learningRate"], config["momentum"], config["useNesterov"]);
    }
  };
  MomentumOptimizer.className = "Momentum";
  registerClass(MomentumOptimizer);

  // node_modules/@tensorflow/tfjs-core/dist/optimizers/rmsprop_optimizer.js
  var RMSPropOptimizer = class extends Optimizer {
    constructor(learningRate, decay = 0.9, momentum = 0, epsilon3 = null, centered = false) {
      super();
      this.learningRate = learningRate;
      this.decay = decay;
      this.momentum = momentum;
      this.epsilon = epsilon3;
      this.accumulatedMeanSquares = [];
      this.accumulatedMoments = [];
      this.accumulatedMeanGrads = [];
      this.centered = centered;
      if (epsilon3 == null) {
        this.epsilon = ENGINE.backend.epsilon();
      }
      if (learningRate == null) {
        throw new Error(`learningRate for RMSPropOptimizer must be defined.`);
      }
    }
    applyGradients(variableGradients) {
      const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
      variableNames.forEach((name, i) => {
        const value = ENGINE.registeredVariables[name];
        const trainable = false;
        if (this.accumulatedMeanSquares[i] == null) {
          this.accumulatedMeanSquares[i] = {
            originalName: `${name}/rms`,
            variable: tidy(() => zerosLike(value).variable(trainable))
          };
        }
        if (this.accumulatedMoments[i] == null) {
          this.accumulatedMoments[i] = {
            originalName: `${name}/momentum`,
            variable: tidy(() => zerosLike(value).variable(trainable))
          };
        }
        if (this.accumulatedMeanGrads[i] == null && this.centered) {
          this.accumulatedMeanGrads[i] = {
            originalName: `${name}/mg`,
            variable: tidy(() => zerosLike(value).variable(trainable))
          };
        }
        const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
        if (gradient == null) {
          return;
        }
        const accumulatedMeanSquare = this.accumulatedMeanSquares[i].variable;
        const accumulatedMoments = this.accumulatedMoments[i].variable;
        tidy(() => {
          const newAccumulatedMeanSquare = add3(mul(accumulatedMeanSquare, this.decay), mul(square(gradient), 1 - this.decay));
          if (this.centered) {
            const accumulatedMeanGrad = this.accumulatedMeanGrads[i].variable;
            const newAccumulatedMeanGrad = add3(mul(accumulatedMeanGrad, this.decay), mul(gradient, 1 - this.decay));
            const gradContribution = div(mul(gradient, this.learningRate), sqrt(sub(newAccumulatedMeanSquare, add3(square(newAccumulatedMeanGrad), this.epsilon))));
            const newAccumulatedMoments = add3(mul(accumulatedMoments, this.momentum), gradContribution);
            accumulatedMeanSquare.assign(newAccumulatedMeanSquare);
            accumulatedMeanGrad.assign(newAccumulatedMeanGrad);
            accumulatedMoments.assign(newAccumulatedMoments);
            const newValue = sub(value, newAccumulatedMoments);
            value.assign(newValue);
          } else {
            const newAccumulatedMeanSquare2 = add3(mul(accumulatedMeanSquare, this.decay), mul(square(gradient), 1 - this.decay));
            const newAccumulatedMoments = add3(mul(accumulatedMoments, this.momentum), div(mul(gradient, this.learningRate), sqrt(add3(newAccumulatedMeanSquare2, this.epsilon))));
            accumulatedMeanSquare.assign(newAccumulatedMeanSquare2);
            accumulatedMoments.assign(newAccumulatedMoments);
            const newValue = sub(value, newAccumulatedMoments);
            value.assign(newValue);
          }
        });
      });
      this.incrementIterations();
    }
    dispose() {
      if (this.accumulatedMeanSquares != null) {
        dispose(this.accumulatedMeanSquares.map((v) => v.variable));
      }
      if (this.accumulatedMeanGrads != null && this.centered) {
        dispose(this.accumulatedMeanGrads.map((v) => v.variable));
      }
      if (this.accumulatedMoments != null) {
        dispose(this.accumulatedMoments.map((v) => v.variable));
      }
    }
    async getWeights() {
      const variables = [...this.accumulatedMeanSquares, ...this.accumulatedMoments];
      if (this.centered) {
        variables.push(...this.accumulatedMeanGrads);
      }
      return [await this.saveIterations()].concat(variables.map((v) => ({ name: v.originalName, tensor: v.variable })));
    }
    async setWeights(weightValues) {
      weightValues = await this.extractIterations(weightValues);
      const variableCount = this.centered ? weightValues.length / 3 : weightValues.length / 2;
      const trainable = false;
      this.accumulatedMeanSquares = weightValues.slice(0, variableCount).map((v) => ({
        originalName: v.name,
        variable: v.tensor.variable(trainable)
      }));
      this.accumulatedMoments = weightValues.slice(variableCount, variableCount * 2).map((v) => ({
        originalName: v.name,
        variable: v.tensor.variable(trainable)
      }));
      if (this.centered) {
        this.accumulatedMeanGrads = weightValues.slice(variableCount * 2, variableCount * 3).map((v) => ({
          originalName: v.name,
          variable: v.tensor.variable(trainable)
        }));
      }
    }
    getConfig() {
      return {
        "learningRate": this.learningRate,
        "decay": this.decay,
        "momentum": this.momentum,
        "epsilon": this.epsilon,
        "centered": this.centered
      };
    }
    static fromConfig(cls, config) {
      return new cls(config["learningRate"], config["decay"], config["momentum"], config["epsilon"], config["centered"]);
    }
  };
  RMSPropOptimizer.className = "RMSProp";
  registerClass(RMSPropOptimizer);

  // node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer_constructors.js
  var OptimizerConstructors = class {
    static sgd(learningRate) {
      return new SGDOptimizer(learningRate);
    }
    static momentum(learningRate, momentum, useNesterov = false) {
      return new MomentumOptimizer(learningRate, momentum, useNesterov);
    }
    static rmsprop(learningRate, decay = 0.9, momentum = 0, epsilon3 = null, centered = false) {
      return new RMSPropOptimizer(learningRate, decay, momentum, epsilon3, centered);
    }
    static adam(learningRate = 1e-3, beta1 = 0.9, beta2 = 0.999, epsilon3 = null) {
      return new AdamOptimizer(learningRate, beta1, beta2, epsilon3);
    }
    static adadelta(learningRate = 1e-3, rho = 0.95, epsilon3 = null) {
      return new AdadeltaOptimizer(learningRate, rho, epsilon3);
    }
    static adamax(learningRate = 2e-3, beta1 = 0.9, beta2 = 0.999, epsilon3 = null, decay = 0) {
      return new AdamaxOptimizer(learningRate, beta1, beta2, epsilon3, decay);
    }
    static adagrad(learningRate, initialAccumulatorValue = 0.1) {
      return new AdagradOptimizer(learningRate, initialAccumulatorValue);
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/train.js
  var train = {
    sgd: OptimizerConstructors.sgd,
    momentum: OptimizerConstructors.momentum,
    adadelta: OptimizerConstructors.adadelta,
    adagrad: OptimizerConstructors.adagrad,
    rmsprop: OptimizerConstructors.rmsprop,
    adamax: OptimizerConstructors.adamax,
    adam: OptimizerConstructors.adam
  };

  // node_modules/@tensorflow/tfjs-core/dist/browser_util.js
  var delayCallback = (() => {
    if (typeof requestAnimationFrame !== "undefined") {
      return requestAnimationFrame;
    } else if (typeof setImmediate !== "undefined") {
      return setImmediate;
    }
    return (f) => f();
  })();
  function nextFrame2() {
    return new Promise((resolve) => delayCallback(() => resolve()));
  }

  // node_modules/@tensorflow/tfjs-core/dist/backends/backend_util.js
  var backend_util_exports = {};
  __export(backend_util_exports, {
    ERF_A1: () => ERF_A1,
    ERF_A2: () => ERF_A2,
    ERF_A3: () => ERF_A3,
    ERF_A4: () => ERF_A4,
    ERF_A5: () => ERF_A5,
    ERF_P: () => ERF_P,
    PARALLELIZE_THRESHOLD: () => PARALLELIZE_THRESHOLD,
    SELU_SCALE: () => SELU_SCALE,
    SELU_SCALEALPHA: () => SELU_SCALEALPHA,
    applyActivation: () => applyActivation,
    assertAndGetBroadcastShape: () => assertAndGetBroadcastShape,
    assertAxesAreInnerMostDims: () => assertAxesAreInnerMostDims,
    assertParamsConsistent: () => assertParamsConsistent,
    assignToTypedArray: () => assignToTypedArray,
    axesAreInnerMostDims: () => axesAreInnerMostDims,
    calculateShapes: () => calculateShapes,
    checkEinsumDimSizes: () => checkEinsumDimSizes,
    combineLocations: () => combineLocations,
    complexWithEvenIndex: () => complexWithEvenIndex,
    complexWithOddIndex: () => complexWithOddIndex,
    computeConv2DInfo: () => computeConv2DInfo,
    computeConv3DInfo: () => computeConv3DInfo,
    computeDefaultPad: () => computeDefaultPad,
    computeDilation2DInfo: () => computeDilation2DInfo,
    computeOptimalWindowSize: () => computeOptimalWindowSize,
    computeOutAndReduceShapes: () => computeOutAndReduceShapes,
    computeOutShape: () => computeOutShape2,
    computePool2DInfo: () => computePool2DInfo,
    computePool3DInfo: () => computePool3DInfo,
    convertConv2DDataFormat: () => convertConv2DDataFormat,
    decodeEinsumEquation: () => decodeEinsumEquation,
    eitherStridesOrDilationsAreOne: () => eitherStridesOrDilationsAreOne,
    expandShapeToKeepDim: () => expandShapeToKeepDim,
    exponent: () => exponent,
    exponents: () => exponents,
    fromStringArrayToUint8: () => fromStringArrayToUint8,
    fromUint8ToStringArray: () => fromUint8ToStringArray,
    getAxesPermutation: () => getAxesPermutation,
    getBroadcastDims: () => getBroadcastDims,
    getComplexWithIndex: () => getComplexWithIndex,
    getEinsumComputePath: () => getEinsumComputePath,
    getEinsumPermutation: () => getEinsumPermutation,
    getFusedBiasGradient: () => getFusedBiasGradient,
    getFusedDyActivation: () => getFusedDyActivation,
    getImageCenter: () => getImageCenter,
    getInnerMostAxes: () => getInnerMostAxes,
    getPermuted: () => getPermuted,
    getReductionAxes: () => getReductionAxes,
    getReshaped: () => getReshaped,
    getReshapedPermuted: () => getReshapedPermuted,
    getSliceBeginCoords: () => getSliceBeginCoords,
    getSliceSize: () => getSliceSize,
    getUndoAxesPermutation: () => getUndoAxesPermutation,
    isIdentityPermutation: () => isIdentityPermutation,
    log: () => log,
    mergeRealAndImagArrays: () => mergeRealAndImagArrays,
    prepareAndValidate: () => prepareAndValidate,
    prepareSplitSize: () => prepareSplitSize,
    segment_util: () => segment_util_exports,
    shouldFuse: () => shouldFuse,
    slice_util: () => slice_util_exports,
    splitRealAndImagArrays: () => splitRealAndImagArrays,
    tupleValuesAreOne: () => tupleValuesAreOne,
    upcastType: () => upcastType,
    validateInput: () => validateInput,
    validateUpdateShape: () => validateUpdateShape,
    warn: () => warn3
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/concat_util.js
  function assertParamsConsistent(shapes, axis) {
    const rank = shapes[0].length;
    shapes.forEach((shape, i) => {
      assert(shape.length === rank, () => `Error in concat${rank}D: rank of tensors[${i}] must be the same as the rank of the rest (${rank})`);
    });
    assert(axis >= 0 && axis < rank, () => `Error in concat${rank}D: axis must be between 0 and ${rank - 1}.`);
    const firstShape = shapes[0];
    shapes.forEach((shape, i) => {
      for (let r = 0; r < rank; r++) {
        assert(r === axis || shape[r] === firstShape[r], () => `Error in concat${rank}D: Shape of tensors[${i}] (${shape}) does not match the shape of the rest (${firstShape}) along the non-concatenated axis ${i}.`);
      }
    });
  }
  function computeOutShape2(shapes, axis) {
    const outputShape = shapes[0].slice();
    for (let i = 1; i < shapes.length; i++) {
      outputShape[axis] += shapes[i][axis];
    }
    return outputShape;
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/reduce_util.js
  var PARALLELIZE_THRESHOLD = 30;
  function computeOptimalWindowSize(inSize) {
    if (inSize <= PARALLELIZE_THRESHOLD) {
      return inSize;
    }
    return nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/rotate_util.js
  function getImageCenter(center, imageHeight, imageWidth) {
    const centerX = imageWidth * (typeof center === "number" ? center : center[0]);
    const centerY = imageHeight * (typeof center === "number" ? center : center[1]);
    return [centerX, centerY];
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/array_ops_util.js
  function getReshaped(inputShape, blockShape, prod4, batchToSpace = true) {
    let reshaped = [];
    if (batchToSpace) {
      reshaped = reshaped.concat(blockShape.slice(0));
      reshaped.push(inputShape[0] / prod4);
      reshaped = reshaped.concat(inputShape.slice(1));
    } else {
      reshaped = reshaped.concat(inputShape[0]);
      const spatialLength = blockShape.length;
      for (let i = 0; i < spatialLength; ++i) {
        reshaped = reshaped.concat([inputShape[i + 1] / blockShape[i], blockShape[i]]);
      }
      reshaped = reshaped.concat(inputShape.slice(spatialLength + 1));
    }
    return reshaped;
  }
  function getPermuted(reshapedRank, blockShapeRank, batchToSpace = true) {
    const permuted = [];
    if (batchToSpace) {
      permuted.push(blockShapeRank);
      for (let i = blockShapeRank + 1; i < reshapedRank; ++i) {
        if (i <= 2 * blockShapeRank) {
          permuted.push(i);
          permuted.push(i - (blockShapeRank + 1));
        } else {
          permuted.push(i);
        }
      }
    } else {
      const permutedBeforeBatch = [];
      const permutedAfterBatch = [];
      for (let i = 1; i < reshapedRank; ++i) {
        if (i >= blockShapeRank * 2 + 1 || i % 2 === 1) {
          permutedAfterBatch.push(i);
        } else {
          permutedBeforeBatch.push(i);
        }
      }
      permuted.push(...permutedBeforeBatch);
      permuted.push(0);
      permuted.push(...permutedAfterBatch);
    }
    return permuted;
  }
  function getReshapedPermuted(inputShape, blockShape, prod4, batchToSpace = true) {
    const reshapedPermuted = [];
    if (batchToSpace) {
      reshapedPermuted.push(inputShape[0] / prod4);
    } else {
      reshapedPermuted.push(inputShape[0] * prod4);
    }
    for (let i = 1; i < inputShape.length; ++i) {
      if (i <= blockShape.length) {
        if (batchToSpace) {
          reshapedPermuted.push(blockShape[i - 1] * inputShape[i]);
        } else {
          reshapedPermuted.push(inputShape[i] / blockShape[i - 1]);
        }
      } else {
        reshapedPermuted.push(inputShape[i]);
      }
    }
    return reshapedPermuted;
  }
  function getSliceBeginCoords(crops, blockShape) {
    const sliceBeginCoords = [0];
    for (let i = 0; i < blockShape; ++i) {
      sliceBeginCoords.push(crops[i][0]);
    }
    return sliceBeginCoords;
  }
  function getSliceSize(uncroppedShape, crops, blockShape) {
    const sliceSize = uncroppedShape.slice(0, 1);
    for (let i = 0; i < blockShape; ++i) {
      sliceSize.push(uncroppedShape[i + 1] - crops[i][0] - crops[i][1]);
    }
    return sliceSize;
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/selu_util.js
  var SELU_SCALEALPHA = 1.7580993408473768;
  var SELU_SCALE = 1.0507009873554805;

  // node_modules/@tensorflow/tfjs-core/dist/ops/erf_util.js
  var ERF_P = 0.3275911;
  var ERF_A1 = 0.254829592;
  var ERF_A2 = -0.284496736;
  var ERF_A3 = 1.421413741;
  var ERF_A4 = -1.453152027;
  var ERF_A5 = 1.061405429;

  // node_modules/@tensorflow/tfjs-core/dist/backends/complex_util.js
  function mergeRealAndImagArrays(real4, imag4) {
    if (real4.length !== imag4.length) {
      throw new Error(`Cannot merge real and imag arrays of different lengths. real:${real4.length}, imag: ${imag4.length}.`);
    }
    const result = new Float32Array(real4.length * 2);
    for (let i = 0; i < result.length; i += 2) {
      result[i] = real4[i / 2];
      result[i + 1] = imag4[i / 2];
    }
    return result;
  }
  function splitRealAndImagArrays(complex4) {
    const real4 = new Float32Array(complex4.length / 2);
    const imag4 = new Float32Array(complex4.length / 2);
    for (let i = 0; i < complex4.length; i += 2) {
      real4[i / 2] = complex4[i];
      imag4[i / 2] = complex4[i + 1];
    }
    return { real: real4, imag: imag4 };
  }
  function complexWithEvenIndex(complex4) {
    const len = Math.ceil(complex4.length / 4);
    const real4 = new Float32Array(len);
    const imag4 = new Float32Array(len);
    for (let i = 0; i < complex4.length; i += 4) {
      real4[Math.floor(i / 4)] = complex4[i];
      imag4[Math.floor(i / 4)] = complex4[i + 1];
    }
    return { real: real4, imag: imag4 };
  }
  function complexWithOddIndex(complex4) {
    const len = Math.floor(complex4.length / 4);
    const real4 = new Float32Array(len);
    const imag4 = new Float32Array(len);
    for (let i = 2; i < complex4.length; i += 4) {
      real4[Math.floor(i / 4)] = complex4[i];
      imag4[Math.floor(i / 4)] = complex4[i + 1];
    }
    return { real: real4, imag: imag4 };
  }
  function getComplexWithIndex(complex4, index) {
    const real4 = complex4[index * 2];
    const imag4 = complex4[index * 2 + 1];
    return { real: real4, imag: imag4 };
  }
  function assignToTypedArray(data, real4, imag4, index) {
    data[index * 2] = real4;
    data[index * 2 + 1] = imag4;
  }
  function exponents(n, inverse) {
    const real4 = new Float32Array(n / 2);
    const imag4 = new Float32Array(n / 2);
    for (let i = 0; i < Math.ceil(n / 2); i++) {
      const x = (inverse ? 2 : -2) * Math.PI * (i / n);
      real4[i] = Math.cos(x);
      imag4[i] = Math.sin(x);
    }
    return { real: real4, imag: imag4 };
  }
  function exponent(k, n, inverse) {
    const x = (inverse ? 2 : -2) * Math.PI * (k / n);
    const real4 = Math.cos(x);
    const imag4 = Math.sin(x);
    return { real: real4, imag: imag4 };
  }

  // node_modules/@tensorflow/tfjs-core/dist/backends/einsum_util.js
  var ARROW = "->";
  var ARROW_REGEX = /->/g;
  var COMMA = ",";
  var ELLIPSIS = "...";
  function decodeEinsumEquation(equation, numTensors) {
    equation = equation.replace(/\s/g, "");
    const numArrows = (equation.length - equation.replace(ARROW_REGEX, "").length) / ARROW.length;
    if (numArrows < 1) {
      throw new Error("Equations without an arrow are not supported.");
    } else if (numArrows > 1) {
      throw new Error(`Equation must contain exactly one arrow ("${ARROW}").`);
    }
    const [inputString, outputString] = equation.split(ARROW);
    assert(inputString.indexOf(ELLIPSIS) === -1, () => `The ellipsis notation ("${ELLIPSIS}") is not supported yet.`);
    const inputTerms = inputString.split(COMMA);
    const numInputs = inputTerms.length;
    if (numTensors !== numInputs) {
      throw new Error(`Expected ${numInputs} input tensors, received ${numTensors}`);
    }
    if (numInputs > 2) {
      throw new Error("Support for more than 2 input tensors is not implemented yet.");
    }
    const allDims = [];
    for (let i = 0; i < outputString.length; ++i) {
      const dimName = outputString[i];
      if (!inputTerms.some((inputTerm) => inputTerm.indexOf(dimName) !== -1)) {
        throw new Error(`Output subscripts contain the label ${dimName} not present in the input subscripts.`);
      }
      if (allDims.indexOf(dimName) === -1) {
        allDims.push(dimName);
      }
    }
    for (let i = 0; i < inputString.length; ++i) {
      const dimName = inputString[i];
      if (allDims.indexOf(dimName) === -1 && dimName !== COMMA) {
        allDims.push(dimName);
      }
    }
    const idDims = new Array(inputTerms.length);
    for (let i = 0; i < numInputs; ++i) {
      if (new Set(inputTerms[i].split("")).size !== inputTerms[i].length) {
        throw new Error(`Found duplicate axes in input component ${inputTerms[i]}. Support for duplicate axes in input is not implemented yet.`);
      }
      idDims[i] = [];
      for (let j = 0; j < inputTerms[i].length; ++j) {
        idDims[i].push(allDims.indexOf(inputTerms[i][j]));
      }
    }
    const numDims = allDims.length;
    const numOutDims = outputString.length;
    const summedDims = [];
    for (let i = numOutDims; i < numDims; ++i) {
      summedDims.push(i);
    }
    return { allDims, summedDims, idDims };
  }
  function getEinsumPermutation(nDims, idDims) {
    let permutationIndices = new Array(nDims);
    permutationIndices.fill(-1);
    for (let i = 0; i < idDims.length; ++i) {
      permutationIndices[idDims[i]] = i;
    }
    const expandDims5 = [];
    for (let i = 0; i < nDims; ++i) {
      if (permutationIndices[i] === -1) {
        expandDims5.push(i);
      }
    }
    permutationIndices = permutationIndices.filter((d) => d !== -1);
    return { permutationIndices, expandDims: expandDims5 };
  }
  function checkEinsumDimSizes(nDims, idDims, tensors) {
    const dimSizes = new Array(nDims);
    for (let i = 0; i < tensors.length; ++i) {
      const shape = tensors[i].shape;
      for (let j = 0; j < idDims[i].length; ++j) {
        if (dimSizes[idDims[i][j]] === void 0) {
          dimSizes[idDims[i][j]] = shape[j];
        } else {
          assert(dimSizes[idDims[i][j]] === shape[j], () => `Expected dimension ${dimSizes[idDims[i][j]]} at axis ${j} of input shaped ${JSON.stringify(shape)}, but got dimension ${shape[j]}`);
        }
      }
    }
  }
  function getEinsumComputePath(summedDims, idDims) {
    const path = summedDims;
    const steps = [];
    let nSteps = 0;
    if (summedDims.length === 0) {
      path.push(-1);
    }
    nSteps = summedDims.length + 1;
    for (let i = 0; i < nSteps; ++i) {
      steps.push([]);
    }
    const computedTermIndices = [];
    for (let i = 0; i < path.length; ++i) {
      const summedDim = path[i];
      const termIndices = findTermsWithDim(idDims, summedDim);
      for (const termIndex of termIndices) {
        if (computedTermIndices.indexOf(termIndex) === -1) {
          steps[i].push(termIndex);
          computedTermIndices.push(termIndex);
        }
      }
    }
    return { path, steps };
  }
  function isIdentityPermutation(perm) {
    return perm.every((dim, index) => dim === index);
  }
  function findTermsWithDim(idDims, dim) {
    const termIndices = [];
    for (let i = 0; i < idDims.length; ++i) {
      if (idDims[i].length === 0 || idDims[i].indexOf(dim) !== -1 || dim === -1) {
        termIndices.push(i);
      }
    }
    return termIndices;
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/split_util.js
  function prepareSplitSize(x, numOrSizeSplits, axis = 0) {
    let splitSizes = [];
    if (typeof numOrSizeSplits === "number") {
      assert(x.shape[axis] % numOrSizeSplits === 0, () => "Number of splits must evenly divide the axis.");
      splitSizes = new Array(numOrSizeSplits).fill(x.shape[axis] / numOrSizeSplits);
    } else {
      const numOfNegs = numOrSizeSplits.reduce((count2, value) => {
        if (value === -1) {
          count2 += 1;
        }
        return count2;
      }, 0);
      assert(numOfNegs <= 1, () => "There should be only one negative value in split array.");
      const negIndex = numOrSizeSplits.indexOf(-1);
      if (negIndex !== -1) {
        const total = numOrSizeSplits.reduce((a, b) => b > 0 ? a + b : a);
        numOrSizeSplits[negIndex] = x.shape[axis] - total;
      }
      assert(x.shape[axis] === numOrSizeSplits.reduce((a, b) => a + b), () => "The sum of sizes must match the size of the axis dimension.");
      splitSizes = numOrSizeSplits;
    }
    return splitSizes;
  }

  // node_modules/@tensorflow/tfjs-core/dist/ops/segment_util.js
  var segment_util_exports = {};
  __export(segment_util_exports, {
    collectGatherOpShapeInfo: () => collectGatherOpShapeInfo,
    computeOutShape: () => computeOutShape3,
    segOpComputeOptimalWindowSize: () => segOpComputeOptimalWindowSize
  });
  function segOpComputeOptimalWindowSize(inSize, numSegments) {
    let done = false;
    let res;
    if (inSize <= PARALLELIZE_THRESHOLD) {
      res = inSize;
      done = true;
    } else {
      res = nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));
    }
    while (!done) {
      if (res > numSegments || res === inSize) {
        done = true;
      } else {
        res = nearestDivisor(inSize, res + 1);
      }
    }
    return res;
  }
  function computeOutShape3(aShape, axis, numSegments) {
    const outShape = [];
    const rank = aShape.length;
    for (let dim = 0; dim < rank; dim++) {
      if (dim !== axis) {
        outShape.push(aShape[dim]);
      } else {
        outShape.push(numSegments);
      }
    }
    return outShape;
  }
  function collectGatherOpShapeInfo(x, indices, axis, batchDims) {
    const indicesRank = indices.shape.length;
    const xRank = x.shape.length;
    if (batchDims !== 0) {
      if (batchDims < -indicesRank || batchDims > indicesRank) {
        throw new Error(`Expect batchDims in the range of [-${indicesRank}, ${indicesRank}], but got ${batchDims}`);
      }
    }
    if (batchDims < 0) {
      batchDims += indicesRank;
    }
    if (batchDims > xRank) {
      throw new Error(`batchDims (${batchDims}) must be less than rank(x) (
    ${xRank}).`);
    }
    if (axis < batchDims) {
      throw new Error(`batchDims (${batchDims}) must be less than or equal to axis (${axis}).`);
    }
    for (let i = 0; i < batchDims; ++i) {
      if (x.shape[i] !== indices.shape[i]) {
        throw new Error(`x.shape[${i}]: ${x.shape[i]} should be equal to indices.shape[${i}]: ${indices.shape[i]}.`);
      }
    }
    const dimSize = x.shape[axis];
    const outputShape = [];
    let batchSize = 1;
    let outerSize = 1;
    let sliceSize = 1;
    for (let i = 0; i < batchDims; ++i) {
      outputShape.push(x.shape[i]);
      batchSize *= x.shape[i];
    }
    for (let i = batchDims; i < axis; i++) {
      outputShape.push(x.shape[i]);
      outerSize *= x.shape[i];
    }
    for (let i = batchDims; i < indicesRank; i++) {
      outputShape.push(indices.shape[i]);
    }
    for (let i = axis + 1; i < xRank; i++) {
      outputShape.push(x.shape[i]);
      sliceSize *= x.shape[i];
    }
    return { batchSize, sliceSize, outerSize, dimSize, outputShape };
  }

  // node_modules/@tensorflow/tfjs-core/dist/backends/backend_util.js
  function fromUint8ToStringArray(vals) {
    try {
      return vals.map((val) => decodeString(val));
    } catch (err) {
      throw new Error(`Failed to decode encoded string bytes into utf-8, error: ${err}`);
    }
  }
  function fromStringArrayToUint8(strings) {
    return strings.map((s) => encodeString(s));
  }

  // node_modules/@tensorflow/tfjs-core/dist/backends/kernel_impls.js
  var kernel_impls_exports = {};
  __export(kernel_impls_exports, {
    nonMaxSuppressionV3Impl: () => nonMaxSuppressionV3Impl,
    nonMaxSuppressionV4Impl: () => nonMaxSuppressionV4Impl,
    nonMaxSuppressionV5Impl: () => nonMaxSuppressionV5Impl,
    whereImpl: () => whereImpl
  });

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Abs_grad.js
  var absGradConfig = {
    kernelName: Abs,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return { x: () => mul(dy, step(cast(x, "float32"), -1)) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Acos_grad.js
  var acosGradConfig = {
    kernelName: Acos,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return {
        x: () => {
          const a = square(cast(x, "float32"));
          const b = sqrt(sub(scalar(1), a));
          return neg(div(dy, b));
        }
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Acosh_grad.js
  var acoshGradConfig = {
    kernelName: Acosh,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return {
        x: () => {
          const a = sqrt(sub(square(cast(x, "float32")), 1));
          return div(dy, a);
        }
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Add_grad.js
  var addGradConfig = {
    kernelName: Add,
    inputsToSave: ["a", "b"],
    gradFunc: (dy, saved) => {
      const [a, b] = saved;
      const outShape = assertAndGetBroadcastShape(a.shape, b.shape);
      const derA = () => {
        let res = dy;
        const reduceAxes = getReductionAxes(a.shape, outShape);
        if (reduceAxes.length > 0) {
          res = sum2(res, reduceAxes);
        }
        return reshape(res, a.shape);
      };
      const derB = () => {
        let res = dy;
        const reduceAxes = getReductionAxes(b.shape, outShape);
        if (reduceAxes.length > 0) {
          res = sum2(res, reduceAxes);
        }
        return reshape(res, b.shape);
      };
      return { a: derA, b: derB };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/AddN_grad.js
  var addNGradConfig = {
    kernelName: AddN,
    saveAllInputs: true,
    gradFunc: (dy, saved) => {
      const ders = {};
      saved.forEach((_, i) => {
        ders[i] = () => dy.clone();
      });
      return ders;
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/ArgMax_grad.js
  var argMaxGradConfig = {
    kernelName: ArgMax,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return { x: () => zerosLike(x) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/ArgMin_grad.js
  var argMinGradConfig = {
    kernelName: ArgMin,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return { x: () => zerosLike(x) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Asin_grad.js
  var asinGradConfig = {
    kernelName: Asin,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return { x: () => div(dy, sqrt(sub(scalar(1), square(cast(x, "float32"))))) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Asinh_grad.js
  var asinhGradConfig = {
    kernelName: Asinh,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return {
        x: () => {
          const a = sqrt(add3(scalar(1), square(cast(x, "float32"))));
          return div(dy, a);
        }
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Atan2_grad.js
  var atan2GradConfig = {
    kernelName: Atan2,
    inputsToSave: ["a", "b"],
    gradFunc: (dy, saved) => {
      const [a, b] = saved;
      const outShape = assertAndGetBroadcastShape(a.shape, b.shape);
      const derA = () => {
        const d = add3(square(a), square(b));
        let res = mul(dy, div(b, d));
        const reduceAxes = getReductionAxes(a.shape, outShape);
        if (reduceAxes.length > 0) {
          res = sum2(res, reduceAxes);
        }
        return reshape(res, a.shape);
      };
      const derB = () => {
        const d = add3(square(a), square(b));
        let res = neg(mul(dy, div(a, d)));
        const reduceAxes = getReductionAxes(b.shape, outShape);
        if (reduceAxes.length > 0) {
          res = sum2(res, reduceAxes);
        }
        return reshape(res, b.shape);
      };
      return { a: derA, b: derB };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Atan_grad.js
  var atanGradConfig = {
    kernelName: Atan,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return { x: () => div(dy, add3(square(cast(x, "float32")), 1)) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Atanh_grad.js
  var atanhGradConfig = {
    kernelName: Atanh,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return { x: () => div(dy, sub(scalar(1), square(cast(x, "float32")))) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool_3d_grad.js
  function avgPool3dGrad_(dy, input2, filterSize, strides, pad2, dimRoundingMode) {
    const $dy = convertToTensor(dy, "dy", "avgPool3dGrad");
    const $input = convertToTensor(input2, "input", "avgPool3dGrad");
    let dy5D = $dy;
    let input5D = $input;
    let reshapedTo5D = false;
    if ($input.rank === 4) {
      reshapedTo5D = true;
      dy5D = reshape($dy, [1, $dy.shape[0], $dy.shape[1], $dy.shape[2], $dy.shape[3]]);
      input5D = reshape($input, [
        1,
        $input.shape[0],
        $input.shape[1],
        $input.shape[2],
        $input.shape[3]
      ]);
    }
    assert(dy5D.rank === 5, () => `Error in avgPool3dGrad: dy must be rank 5 but got rank ${dy5D.rank}.`);
    assert(input5D.rank === 5, () => `Error in avgPool3dGrad: input must be rank 5 but got rank ${input5D.rank}.`);
    if (dimRoundingMode != null) {
      assert(isInt(pad2), () => `Error in avgPool3dGrad: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad2}.`);
    }
    const inputs = { dy: dy5D, input: input5D };
    const attrs = { filterSize, strides, pad: pad2, dimRoundingMode };
    const res = ENGINE.runKernel(AvgPool3DGrad, inputs, attrs);
    if (reshapedTo5D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
    }
    return res;
  }
  var avgPool3dGrad = op({ avgPool3dGrad_ });

  // node_modules/@tensorflow/tfjs-core/dist/gradients/AvgPool3D_grad.js
  var avgPool3DGradConfig = {
    kernelName: AvgPool3D,
    inputsToSave: ["x"],
    gradFunc: (dy, saved, attrs) => {
      const [x] = saved;
      const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
      return {
        x: () => avgPool3dGrad(dy, x, filterSize, strides, pad2, dimRoundingMode)
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool_grad.js
  function avgPoolGrad_(dy, input2, filterSize, strides, pad2) {
    const $dy = convertToTensor(dy, "dy", "avgPoolGrad");
    const $input = convertToTensor(input2, "input", "avgPoolGrad");
    assert($input.rank === $dy.rank, () => `Rank of input (${$input.rank}) does not match rank of dy (${$dy.rank})`);
    let input4D = $input;
    let dy4D = $dy;
    let reshapedTo4D = false;
    if ($input.rank === 3) {
      reshapedTo4D = true;
      input4D = reshape($input, [1, $input.shape[0], $input.shape[1], $input.shape[2]]);
      dy4D = reshape($dy, [1, $dy.shape[0], $dy.shape[1], $dy.shape[2]]);
    }
    assert(dy4D.rank === 4, () => `Error in avgPoolGrad: dy must be rank 4 but got rank ${dy4D.rank}.`);
    assert(input4D.rank === 4, () => `Error in avgPoolGrad: input must be rank 4 but got rank ${input4D.rank}.`);
    const inputs = { dy: dy4D, input: input4D };
    const attrs = { filterSize, strides, pad: pad2 };
    const res = ENGINE.runKernel(AvgPoolGrad, inputs, attrs);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  var avgPoolGrad = op({ avgPoolGrad_ });

  // node_modules/@tensorflow/tfjs-core/dist/gradients/AvgPool_grad.js
  var avgPoolGradConfig = {
    kernelName: AvgPool,
    inputsToSave: ["x"],
    gradFunc: (dy, saved, attrs) => {
      const [x] = saved;
      const { filterSize, strides, pad: pad2 } = attrs;
      return { x: () => avgPoolGrad(dy, x, filterSize, strides, pad2) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/BatchMatMul_grad.js
  var batchMatMulGradConfig = {
    kernelName: BatchMatMul,
    inputsToSave: ["a", "b"],
    gradFunc: (dy, saved, attrs) => {
      const [a, b] = saved;
      const { transposeA, transposeB } = attrs;
      if (!transposeA && !transposeB) {
        return {
          a: () => matMul(dy, b, false, true),
          b: () => matMul(a, dy, true, false)
        };
      } else if (!transposeA && transposeB) {
        return {
          a: () => matMul(dy, b, false, false),
          b: () => matMul(dy, a, true, false)
        };
      } else if (transposeA && !transposeB) {
        return {
          a: () => matMul(b, dy, false, true),
          b: () => matMul(a, dy, false, false)
        };
      } else {
        return {
          a: () => matMul(b, dy, true, true),
          b: () => matMul(dy, a, true, true)
        };
      }
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/BatchToSpaceND_grad.js
  var batchToSpaceNDGradConfig = {
    kernelName: BatchToSpaceND,
    gradFunc: (dy, saved, attrs) => {
      const { blockShape, crops } = attrs;
      return { x: () => spaceToBatchND(dy, blockShape, crops) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/BroadcastTo_grad.js
  var broadcastToGradConfig = {
    kernelName: BroadcastTo,
    gradFunc: (dy, saved, attrs) => {
      const broadCastToAttrs = attrs;
      const inputShape = broadCastToAttrs.inputShape;
      const outputShape = broadCastToAttrs.shape;
      const reps = Array.from(outputShape);
      for (let i = inputShape.length - 1; i >= 0; i--) {
        if (inputShape[i] === outputShape[i]) {
          reps[i] = 1;
        } else if (inputShape[i] !== 1) {
          throw new Error(`broadcastTo(): [${inputShape}] cannot be broadcast to [${outputShape}].`);
        }
      }
      const axes = [];
      for (let i = 0; i < reps.length; i++) {
        if (reps[i] > 1) {
          axes.push(i);
        }
      }
      return { x: () => sum2(dy, axes, true) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Cast_grad.js
  var castGradConfig = {
    kernelName: Cast,
    gradFunc: (dy) => {
      return { x: () => dy.clone() };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Ceil_grad.js
  var ceilGradConfig = {
    kernelName: Ceil,
    gradFunc: (dy) => {
      return { x: () => zerosLike(dy) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/ClipByValue_grad.js
  var clipByValueGradConfig = {
    kernelName: ClipByValue,
    inputsToSave: ["x"],
    gradFunc: (dy, saved, attrs) => {
      const [x] = saved;
      const { clipValueMin, clipValueMax } = attrs;
      return {
        x: () => where(logicalAnd(greaterEqual(x, clipValueMin), lessEqual(x, clipValueMax)), dy, zerosLike(dy))
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/ComplexAbs_grad.js
  var complexAbsGradConfig = {
    kernelName: ComplexAbs,
    inputsToSave: ["x"],
    gradFunc: absGradConfig.gradFunc
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Concat_grad.js
  var concatGradConfig = {
    kernelName: Concat,
    saveAllInputs: true,
    gradFunc: (dy, saved, attrs) => {
      const shapes = saved.map((t) => t.shape);
      const { axis } = attrs;
      const $axis = parseAxisParam(axis, saved[0].shape)[0];
      const sizeSplits = shapes.map((s) => s[$axis]);
      const derTensors = split(dy, sizeSplits, $axis);
      return derTensors.map((t) => () => t);
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Conv2D_grad.js
  var conv2DGradConfig = {
    kernelName: Conv2D,
    inputsToSave: ["x", "filter"],
    gradFunc: (dy, saved, attrs) => {
      const [x4D, $filter] = saved;
      const { dilations, strides, pad: pad2, dataFormat } = attrs;
      assert(tupleValuesAreOne(dilations), () => `Error in gradient of conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${dilations}'`);
      return {
        x: () => conv2DBackpropInput(x4D.shape, dy, $filter, strides, pad2, dataFormat),
        filter: () => conv2DBackpropFilter(x4D, dy, $filter.shape, strides, pad2, dataFormat)
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Conv2DBackpropInput_grad.js
  var conv2DBackpropInputGradConfig = {
    kernelName: Conv2DBackpropInput,
    inputsToSave: ["dy", "filter"],
    gradFunc: (ddx, saved, attrs) => {
      const [dy, filter] = saved;
      const { strides, pad: pad2, dataFormat, dimRoundingMode } = attrs;
      return {
        dy: () => conv2d(ddx, filter, strides, pad2, dataFormat, 1, dimRoundingMode),
        filter: () => conv2DBackpropFilter(ddx, dy, filter.shape, strides, pad2, dataFormat, dimRoundingMode)
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_backprop_filter.js
  function conv3DBackpropFilter_(x, dy, filterShape, strides, pad2) {
    let x5D = x;
    if (x.rank === 4) {
      x5D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2], x.shape[3]]);
    }
    let dy5D = dy;
    if (dy5D.rank === 4) {
      dy5D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);
    }
    assert(x5D.rank === 5, () => `Error in conv3dDerFilter: input must be rank 5, but got shape ${x5D.shape}.`);
    assert(dy5D.rank === 5, () => `Error in conv3dDerFilter: dy must be rank 5, but got shape ${dy5D.shape}.`);
    assert(filterShape.length === 5, () => `Error in conv3dDerFilter: filterShape must be length 5, but got ${filterShape}.`);
    assert(x5D.shape[4] === filterShape[3], () => `Error in conv3dDerFilter: depth of input ${x5D.shape[4]}) must match input depth in filter (${filterShape[3]}.`);
    assert(dy5D.shape[4] === filterShape[4], () => `Error in conv3dDerFilter: depth of dy (${dy5D.shape[4]}) must match output depth for filter (${filterShape[4]}).`);
    const inputs = { x: x5D, dy: dy5D };
    const attrs = { strides, pad: pad2, filterShape };
    return ENGINE.runKernel(Conv3DBackpropFilterV2, inputs, attrs);
  }
  var conv3DBackpropFilter = op({ conv3DBackpropFilter_ });

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Conv3D_grad.js
  var conv3DGradConfig = {
    kernelName: Conv3D,
    inputsToSave: ["x", "filter"],
    gradFunc: (dy, saved, attrs) => {
      const { dilations, strides, pad: pad2 } = attrs;
      assert(tupleValuesAreOne(dilations), () => `Error in gradient of conv3D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${dilations}'`);
      const [x5D, $filter] = saved;
      return {
        x: () => conv3DBackpropInput(x5D.shape, dy, $filter, strides, pad2),
        filter: () => conv3DBackpropFilter(x5D, dy, $filter.shape, strides, pad2)
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Cos_grad.js
  var cosGradConfig = {
    kernelName: Cos,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return { x: () => mul(neg(sin(cast(x, "float32"))), dy) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Cosh_grad.js
  var coshGradConfig = {
    kernelName: Cosh,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return { x: () => mul(sinh(cast(x, "float32")), dy) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Cumsum_grad.js
  var cumsumGradConfig = {
    kernelName: Cumsum,
    inputsToSave: ["x"],
    gradFunc: (dy, saved, attrs) => {
      const [x] = saved;
      const { axis, exclusive, reverse: reverse4 } = attrs;
      return {
        x: () => {
          const permutation = getAxesPermutation([axis], x.rank);
          let out = cumsum(dy, axis, exclusive, !reverse4);
          if (permutation != null) {
            out = transpose(out, permutation);
          }
          return out;
        }
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/DepthwiseConv2dNative_grad.js
  var depthwiseConv2dNativeGradConfig = {
    kernelName: DepthwiseConv2dNative,
    inputsToSave: ["x", "filter"],
    gradFunc: (dy, saved, attrs) => {
      const { dilations, strides, pad: pad2, dimRoundingMode } = attrs;
      const $dilations = dilations == null ? [1, 1] : dilations;
      assert(tupleValuesAreOne($dilations), () => `Error in gradient of depthwiseConv2dNative: dilation rates greater than 1 are not yet supported. Got dilations '${$dilations}'`);
      const [x, filter] = saved;
      assert(x.rank === 4, () => `Error in gradient of depthwiseConv2dNative: input must be rank 4, but got rank ${x.rank}.`);
      assert(filter.rank === 4, () => `Error in gradient of depthwiseConv2dNative: filter must be rank 4, but got rank ${filter.rank}.`);
      assert(x.shape[3] === filter.shape[2], () => `Error in gradient of depthwiseConv2d: number of input channels (${x.shape[3]}) must match the inChannels dimension in filter ${filter.shape[2]}.`);
      assert(eitherStridesOrDilationsAreOne(strides, $dilations), () => `Error in gradient of depthwiseConv2d: Either strides or dilations must be  1. Got strides ${strides} and dilations '${$dilations}'.`);
      if (dimRoundingMode != null) {
        assert(isInt(pad2), () => `Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad2}.`);
      }
      return {
        x: () => depthwiseConv2dNativeBackpropInput(x.shape, dy, filter, strides, pad2, $dilations, dimRoundingMode),
        filter: () => depthwiseConv2dNativeBackpropFilter(x, dy, filter.shape, strides, pad2, $dilations, dimRoundingMode)
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Dilation2D_grad.js
  var dilation2dGradConfig = {
    kernelName: Dilation2D,
    inputsToSave: ["x", "filter"],
    gradFunc: (dy, saved, attrs) => {
      const [x, filter] = saved;
      const inputInputs = { x, filter, dy };
      const filterInputs = { x, filter, dy };
      return {
        x: () => ENGINE.runKernel(Dilation2DBackpropInput, inputInputs, attrs),
        filter: () => ENGINE.runKernel(Dilation2DBackpropFilter, filterInputs, attrs)
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Elu_grad.js
  var eluGradConfig = {
    kernelName: Elu,
    outputsToSave: [true],
    gradFunc: (dy, saved) => {
      const [y] = saved;
      const inputs = { dy, y };
      return { x: () => ENGINE.runKernel(EluGrad, inputs) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Erf_grad.js
  var erfGradConfig = {
    kernelName: Erf,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      const a = mul(exp(neg(square(x))), 2 / Math.sqrt(Math.PI));
      return { x: () => mul(dy, a) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Exp_grad.js
  var expGradConfig = {
    kernelName: Exp,
    outputsToSave: [true],
    gradFunc: (dy, saved) => {
      const [y] = saved;
      return { x: () => mul(dy, y) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/ExpandDims_grad.js
  var expandDimsGradConfig = {
    kernelName: ExpandDims,
    inputsToSave: ["input"],
    gradFunc: (dy, saved) => {
      const [input2] = saved;
      return { input: () => reshape(dy, input2.shape) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Expm1_grad.js
  var expm1GradConfig = {
    kernelName: Expm1,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return { x: () => mul(dy, exp(x)) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Floor_grad.js
  var floorGradConfig = {
    kernelName: Floor,
    gradFunc: (dy) => {
      return { x: () => zerosLike(dy) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/FloorDiv_grad.js
  var floorDivGradConfig = {
    kernelName: FloorDiv,
    inputsToSave: ["a", "b"],
    gradFunc: (dy, saved) => {
      const [a, b] = saved;
      const outShape = assertAndGetBroadcastShape(a.shape, b.shape);
      const derA = () => {
        const res = div(dy, cast(b, "float32"));
        const reduceAxes = getReductionAxes(a.shape, outShape);
        if (reduceAxes.length > 0) {
          return reshape(sum2(res, reduceAxes), a.shape);
        }
        return res;
      };
      const derB = () => {
        let res = mul(dy, cast(a, "float32"));
        const reduceAxes = getReductionAxes(b.shape, outShape);
        if (reduceAxes.length > 0) {
          res = reshape(sum2(res, reduceAxes), b.shape);
        }
        const tmp = square(b);
        return neg(div(res, cast(tmp, "float32")));
      };
      return { a: derA, b: derB };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/FusedBatchNorm_grad.js
  var fusedBatchNormGradConfig = {
    kernelName: FusedBatchNorm,
    inputsToSave: ["x", "mean", "variance", "scale"],
    gradFunc: (dy, saved, attrs) => {
      const { varianceEpsilon } = attrs;
      const [x, mean3, variance, scale2] = saved;
      const scaleValue = scale2 == null ? scalar(1) : scale2;
      const reductionAxes = getReductionAxes(mean3.shape, x.shape);
      const tileShape = [];
      if (mean3.rank === 1) {
        for (let i = 0; i < x.shape.length - 1; ++i) {
          tileShape.push(x.shape[i]);
        }
        tileShape.push(1);
      }
      const xMinusMean = sub(x, mean3);
      const dyTimesScaleValue = mul(dy, scaleValue);
      const oneOverSqrtVariance = rsqrt(add3(variance, scalar(varianceEpsilon)));
      const minusHalfRCube = mul(mul(mul(oneOverSqrtVariance, oneOverSqrtVariance), oneOverSqrtVariance), scalar(-0.5));
      const derX = () => {
        if (mean3.rank === 1) {
          return reshape(mul(mul(dy, tile(reshape(oneOverSqrtVariance, [1, 1, 1, mean3.shape[0]]), tileShape)), scaleValue), x.shape);
        } else {
          return reshape(mul(mul(dy, oneOverSqrtVariance), scaleValue), x.shape);
        }
      };
      const derMean = () => {
        let meanDer = mul(mul(oneOverSqrtVariance, scalar(-1)), dyTimesScaleValue);
        if (mean3.rank === 1) {
          meanDer = sum2(meanDer, reductionAxes);
        }
        return reshape(meanDer, mean3.shape);
      };
      const derVariance = () => {
        let varianceDer = mul(mul(minusHalfRCube, xMinusMean), dyTimesScaleValue);
        if (mean3.rank === 1) {
          varianceDer = sum2(varianceDer, reductionAxes);
        }
        return reshape(varianceDer, mean3.shape);
      };
      const derScale = () => {
        const xMinusMean2TimesRsqrt = mul(xMinusMean, oneOverSqrtVariance);
        let scaleDer = mul(dy, xMinusMean2TimesRsqrt);
        if (mean3.rank === 1) {
          scaleDer = sum2(scaleDer, reductionAxes);
        }
        return reshape(scaleDer, mean3.shape);
      };
      const derOffset = () => {
        let offsetDer = dy;
        if (mean3.rank === 1) {
          offsetDer = sum2(offsetDer, reductionAxes);
        }
        return reshape(offsetDer, mean3.shape);
      };
      return {
        x: derX,
        mean: derMean,
        variance: derVariance,
        scale: derScale,
        offset: derOffset
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/GatherV2_grad.js
  var gatherGradConfig = {
    kernelName: GatherV2,
    inputsToSave: ["x", "indices"],
    gradFunc: (dy, saved, attrs) => {
      const [x, indices] = saved;
      const { axis } = attrs;
      const parsedAxis = parseAxisParam(axis, x.shape)[0];
      const derX = () => {
        const paramsShape = x.shape;
        const indicesSize = indices.size;
        const outerShape = paramsShape.slice(0, parsedAxis);
        const outerDims = outerShape.length;
        const innerShape = paramsShape.slice(axis, paramsShape.length).slice(1);
        const innerDims = innerShape.length;
        const outerAxesIndices = arrayRange(0, outerDims);
        const innerAxesIndices = arrayRange(outerDims + 1, outerDims + 1 + innerDims);
        const valuesShape = arrayConcat([outerShape, [indicesSize], innerShape]);
        const values = reshape(dy, valuesShape);
        const reshapedIndices = reshape(indices, [indicesSize]);
        const transposeDims = arrayConcat([[outerDims], outerAxesIndices, innerAxesIndices]);
        const valuesTranspose = transpose(values, transposeDims);
        let paramsGrad = unsortedSegmentSum(valuesTranspose, reshapedIndices, x.shape[parsedAxis]);
        const invertTransposeDims = getUndoAxesPermutation(transposeDims);
        paramsGrad = transpose(paramsGrad, invertTransposeDims);
        return paramsGrad;
      };
      return { x: derX, indices: () => indices };
    }
  };
  function arrayRange(start, stop2) {
    const result = [];
    for (let i = start; i < stop2; ++i) {
      result.push(i);
    }
    return result;
  }
  function arrayConcat(arrays) {
    const result = [];
    for (let i = 0; i < arrays.length; ++i) {
      for (let j = 0; j < arrays[i].length; ++j) {
        result.push(arrays[i][j]);
      }
    }
    return result;
  }

  // node_modules/@tensorflow/tfjs-core/dist/gradients/GreaterEqual_grad.js
  var greaterEqualGradConfig = {
    kernelName: GreaterEqual,
    inputsToSave: ["a", "b"],
    gradFunc: (dy, saved) => {
      const [a, b] = saved;
      return { a: () => zerosLike(a), b: () => zerosLike(b) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Identity_grad.js
  var identityGradConfig = {
    kernelName: Identity,
    gradFunc: (dy) => {
      return { x: () => cast(dy, "float32") };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/IsFinite_grad.js
  var isFiniteGradConfig = {
    kernelName: IsFinite,
    gradFunc: (dy) => {
      return { x: () => zerosLike(dy) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/IsInf_grad.js
  var isInfGradConfig = {
    kernelName: IsInf,
    gradFunc: (dy) => {
      return { x: () => zerosLike(dy) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/IsNan_grad.js
  var isNanGradConfig = {
    kernelName: IsNan,
    gradFunc: (dy) => {
      return { x: () => zerosLike(dy) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/LeakyRelu_grad.js
  var leakyReluGradConfig = {
    kernelName: LeakyRelu,
    inputsToSave: ["x"],
    gradFunc: (dy, saved, attrs) => {
      const [x] = saved;
      const { alpha } = attrs;
      const mask = greater(x, 0);
      return { x: () => where(mask, dy, mul(dy, alpha)) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Log1p_grad.js
  var log1pGradConfig = {
    kernelName: Log1p,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return { x: () => div(dy, add3(x, 1)) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Log_grad.js
  var logGradConfig = {
    kernelName: Log,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return { x: () => div(dy, cast(x, "float32")) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/LogSoftmax_grad.js
  var logSoftmaxGradConfig = {
    kernelName: LogSoftmax,
    inputsToSave: [],
    outputsToSave: [true],
    gradFunc: (dy, saved, attrs) => {
      const [value] = saved;
      const { axis } = attrs;
      return {
        logits: () => {
          const keepDims = true;
          const softmax4 = exp(value);
          return sub(dy, mul(sum2(dy, axis, keepDims), softmax4));
        }
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/ops/local_response_normalization_backprop.js
  function localResponseNormalizationBackprop_(x, y, dy, depthRadius = 5, bias = 1, alpha = 1, beta = 0.5) {
    const inputs = { x, y, dy };
    const attrs = { depthRadius, bias, alpha, beta };
    return ENGINE.runKernel(LRNGrad, inputs, attrs);
  }
  var localResponseNormalizationBackprop = op({ localResponseNormalizationBackprop_ });

  // node_modules/@tensorflow/tfjs-core/dist/gradients/LRN_grad.js
  var lrnGradConfig = {
    kernelName: LRN,
    inputsToSave: ["x"],
    outputsToSave: [true],
    gradFunc: (dy, saved, attrs) => {
      const [x, y] = saved;
      const { depthRadius, bias, alpha, beta } = attrs;
      return {
        x: () => localResponseNormalizationBackprop(x, y, dy, depthRadius, bias, alpha, beta)
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/min_max_grad_util.js
  function gradForMinAndMax(dy, y, xOrig, origAxes) {
    if (y.rank < xOrig.rank) {
      y = reshape(y, expandShapeToKeepDim(y.shape, origAxes));
    }
    if (dy.rank < xOrig.rank) {
      dy = reshape(dy, expandShapeToKeepDim(dy.shape, origAxes));
    }
    return {
      x: () => {
        const dx = mul(dy, cast(equal(xOrig, y), dy.dtype));
        return dx;
      }
    };
  }

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Max_grad.js
  var maxGradConfig = {
    kernelName: Max,
    inputsToSave: ["x"],
    outputsToSave: [true],
    gradFunc: (dy, saved, attrs) => {
      const maxAttrs = attrs;
      const { reductionIndices } = maxAttrs;
      const x = saved[0];
      const y = saved[1];
      const origAxes = parseAxisParam(reductionIndices, x.shape);
      const maxGrad = gradForMinAndMax(dy, y, x, origAxes);
      return {
        x: () => {
          return maxGrad["x"]();
        }
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Maximum_grad.js
  var maximumGradConfig = {
    kernelName: Maximum,
    inputsToSave: ["a", "b"],
    gradFunc: (dy, saved) => {
      const [a, b] = saved;
      const derA = () => mul(dy, cast(greaterEqual(a, b), "float32"));
      const derB = () => mul(dy, cast(less(a, b), "float32"));
      return { a: derA, b: derB };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/ops/max_pool_3d_grad.js
  function maxPool3dGrad_(dy, input2, output, filterSize, strides, pad2, dimRoundingMode) {
    const $dy = convertToTensor(dy, "dy", "maxPool3dGrad");
    const $input = convertToTensor(input2, "input", "maxPool3dGrad");
    const $output = convertToTensor(output, "output", "maxPool3dGrad");
    let dy5D = $dy;
    let input5D = $input;
    let output5D = $output;
    let reshapedTo5D = false;
    if ($input.rank === 4) {
      reshapedTo5D = true;
      dy5D = reshape($dy, [1, $dy.shape[0], $dy.shape[1], $dy.shape[2], $dy.shape[3]]);
      input5D = reshape($input, [
        1,
        $input.shape[0],
        $input.shape[1],
        $input.shape[2],
        $input.shape[3]
      ]);
      output5D = reshape($output, [
        1,
        $output.shape[0],
        $output.shape[1],
        $output.shape[2],
        $output.shape[3]
      ]);
    }
    assert(dy5D.rank === 5, () => `Error in maxPool3dGrad: dy must be rank 5 but got rank ${dy5D.rank}.`);
    assert(input5D.rank === 5, () => `Error in maxPool3dGrad: input must be rank 5 but got rank ${input5D.rank}.`);
    assert(output5D.rank === 5, () => `Error in maxPool3dGrad: output must be rank 5 but got rank ${output5D.rank}.`);
    if (dimRoundingMode != null) {
      assert(isInt(pad2), () => `Error in maxPool3dGrad: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad2}.`);
    }
    const inputs = { dy: dy5D, input: input5D, output: output5D };
    const attrs = { filterSize, strides, pad: pad2, dimRoundingMode };
    const res = ENGINE.runKernel(MaxPool3DGrad, inputs, attrs);
    if (reshapedTo5D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
    }
    return res;
  }
  var maxPool3dGrad = op({ maxPool3dGrad_ });

  // node_modules/@tensorflow/tfjs-core/dist/gradients/MaxPool3D_grad.js
  var maxPool3DGradConfig = {
    kernelName: MaxPool3D,
    inputsToSave: ["x"],
    outputsToSave: [true],
    gradFunc: (dy, saved, attrs) => {
      const [x, y] = saved;
      const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
      return {
        x: () => maxPool3dGrad(dy, x, y, filterSize, strides, pad2, dimRoundingMode)
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/ops/max_pool_grad.js
  function maxPoolGrad_(dy, input2, output, filterSize, strides, pad2, dimRoundingMode) {
    const $dy = convertToTensor(dy, "dy", "maxPoolGrad");
    const $input = convertToTensor(input2, "input", "maxPoolGrad");
    const $output = convertToTensor(output, "output", "maxPoolGrad");
    assert($input.rank === $dy.rank, () => `Rank of input (${$input.rank}) does not match rank of dy (${$dy.rank})`);
    assert($dy.rank === 4, () => `Error in maxPoolGrad: dy must be rank 4 but got rank ${$dy.rank}.`);
    assert($input.rank === 4, () => `Error in maxPoolGrad: input must be rank 4 but got rank ${$input.rank}.`);
    if (dimRoundingMode != null) {
      assert(isInt(pad2), () => `Error in maxPoolGrad: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad2}.`);
    }
    const inputs = { dy: $dy, input: $input, output: $output };
    const attrs = { filterSize, strides, pad: pad2, dimRoundingMode };
    return ENGINE.runKernel(MaxPoolGrad, inputs, attrs);
  }
  var maxPoolGrad = op({ maxPoolGrad_ });

  // node_modules/@tensorflow/tfjs-core/dist/gradients/MaxPool_grad.js
  var maxPoolGradConfig = {
    kernelName: MaxPool,
    inputsToSave: ["x"],
    outputsToSave: [true],
    gradFunc: (dy, saved, attrs) => {
      const [x, y] = saved;
      const { filterSize, strides, pad: pad2 } = attrs;
      return {
        x: () => maxPoolGrad(dy, x, y, filterSize, strides, pad2)
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Mean_grad.js
  var meanGradConfig = {
    kernelName: Mean,
    inputsToSave: ["x"],
    gradFunc: (dy, saved, attrs) => {
      const [x] = saved;
      const { axis } = attrs;
      const axes = parseAxisParam(axis, x.shape);
      const shapes = computeOutAndReduceShapes(x.shape, axes);
      const reduceShape = shapes[1];
      const reduceSize = sizeFromShape(reduceShape);
      const derX = () => {
        const expandedDyShape = x.shape.slice();
        axes.forEach((axis2) => {
          expandedDyShape[axis2] = 1;
        });
        const expandedDy = reshape(dy, expandedDyShape);
        const res = div(mul(expandedDy, ones2(x.shape, "float32")), reduceSize);
        return res;
      };
      return { x: derX };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Min_grad.js
  var minGradConfig = {
    kernelName: Min,
    inputsToSave: ["x"],
    outputsToSave: [true],
    gradFunc: (dy, saved, attrs) => {
      const minAttrs = attrs;
      const { axis } = minAttrs;
      const [x, y] = saved;
      const origAxes = parseAxisParam(axis, x.shape);
      const minGrad = gradForMinAndMax(dy, y, x, origAxes);
      return {
        x: () => {
          return minGrad["x"]();
        }
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Minimum_grad.js
  var minimumGradConfig = {
    kernelName: Minimum,
    inputsToSave: ["a", "b"],
    gradFunc: (dy, saved) => {
      const [a, b] = saved;
      const derA = () => mul(dy, cast(lessEqual(a, b), "float32"));
      const derB = () => mul(dy, cast(greater(a, b), "float32"));
      return { a: derA, b: derB };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/MirrorPad_grad.js
  var mirrorPadGradConfig = {
    kernelName: MirrorPad,
    inputsToSave: ["x"],
    gradFunc: (dy, saved, attrs) => {
      const x = saved[0];
      const { paddings } = attrs;
      const begin = paddings.map((p3) => p3[0]);
      return { x: () => slice(dy, begin, x.shape) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Mod_grad.js
  var modGradConfig = {
    kernelName: Mod,
    inputsToSave: ["a", "b"],
    gradFunc: (dy, saved) => {
      const [a, b] = saved;
      const outShape = assertAndGetBroadcastShape(a.shape, b.shape);
      const derA = () => {
        const reduceAxes = getReductionAxes(a.shape, outShape);
        if (reduceAxes.length > 0) {
          return reshape(sum2(dy, reduceAxes), a.shape);
        }
        return dy;
      };
      const derB = () => {
        const res = mul(dy, neg(floor(div(a, b))));
        const reduceAxes = getReductionAxes(b.shape, outShape);
        if (reduceAxes.length > 0) {
          return reshape(sum2(res, reduceAxes), b.shape);
        }
        return res;
      };
      return { a: derA, b: derB };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Multiply_grad.js
  var multiplyGradConfig = {
    kernelName: Multiply,
    inputsToSave: ["a", "b"],
    gradFunc: (dy, saved) => {
      const [a, b] = saved;
      const outShape = assertAndGetBroadcastShape(a.shape, b.shape);
      const derA = () => {
        const res = mul(dy, cast(b, "float32"));
        const reduceAxes = getReductionAxes(a.shape, outShape);
        if (reduceAxes.length > 0) {
          return reshape(sum2(res, reduceAxes), a.shape);
        }
        return res;
      };
      const derB = () => {
        const res = mul(dy, cast(a, "float32"));
        const reduceAxes = getReductionAxes(b.shape, outShape);
        if (reduceAxes.length > 0) {
          return reshape(sum2(res, reduceAxes), b.shape);
        }
        return res;
      };
      return { a: derA, b: derB };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Neg_grad.js
  var negGradConfig = {
    kernelName: Neg,
    gradFunc: (dy) => {
      return { x: () => neg(dy) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/OneHot_grad.js
  var oneHotGradConfig = {
    kernelName: OneHot,
    inputsToSave: ["indices"],
    gradFunc: (dy, saved) => {
      const indices = saved[0];
      return { indices: () => zeros(indices.shape, "float32") };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/OnesLike_grad.js
  var onesLikeGradConfig = {
    kernelName: OnesLike,
    gradFunc: (dy) => {
      return { x: () => zerosLike(dy) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Pack_grad.js
  var packGradConfig = {
    kernelName: Pack,
    saveAllInputs: true,
    gradFunc: (dy, saved, attrs) => {
      const { axis } = attrs;
      const derTensors = unstack(dy, axis);
      return derTensors.map((t) => () => t);
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/PadV2_grad.js
  var padV2GradConfig = {
    kernelName: PadV2,
    inputsToSave: ["x"],
    gradFunc: (dy, saved, attrs) => {
      const x = saved[0];
      const { paddings } = attrs;
      const begin = paddings.map((p3) => p3[0]);
      return { x: () => slice(dy, begin, x.shape) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Pow_grad.js
  var powGradConfig = {
    kernelName: Pow,
    inputsToSave: ["a", "b"],
    outputsToSave: [true],
    gradFunc: (dy, saved) => {
      const [a, b, y] = saved;
      const base2 = a;
      const exp4 = b;
      const outShape = assertAndGetBroadcastShape(base2.shape, exp4.shape);
      const derBase = () => {
        const expFloat = cast(exp4, "float32");
        let res = mul(dy, mul(expFloat, pow(base2, sub(expFloat, scalar(1)))));
        const reduceAxes = getReductionAxes(base2.shape, outShape);
        if (reduceAxes.length > 0) {
          res = sum2(res, reduceAxes);
        }
        return reshape(res, base2.shape);
      };
      const derExp = () => {
        const condition = greater(base2, 0);
        const logBase = where(condition, log5(base2), zerosLike(base2));
        let res = mul(dy, mul(y, logBase));
        const reduceAxes = getReductionAxes(exp4.shape, outShape);
        if (reduceAxes.length > 0) {
          res = sum2(res, reduceAxes);
        }
        return reshape(res, exp4.shape);
      };
      return { a: derBase, b: derExp };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Prelu_grad.js
  var preluGradConfig = {
    kernelName: Prelu,
    inputsToSave: ["x", "alpha"],
    gradFunc: (dy, saved) => {
      const [x, alpha] = saved;
      const mask = greater(x, 0);
      return {
        x: () => where(mask, dy, mul(dy, alpha)),
        alpha: () => {
          let res = where(mask, zerosLike(dy), mul(dy, x));
          const reduceAxes = getReductionAxes(alpha.shape, dy.shape);
          if (reduceAxes.length > 0) {
            res = sum2(res, reduceAxes);
          }
          return reshape(res, alpha.shape);
        }
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/RealDiv_grad.js
  var divGradConfig = {
    kernelName: RealDiv,
    inputsToSave: ["a", "b"],
    gradFunc: (dy, saved) => {
      const [a, b] = saved;
      const outShape = assertAndGetBroadcastShape(a.shape, b.shape);
      const derA = () => {
        const res = div(dy, cast(b, "float32"));
        const reduceAxes = getReductionAxes(a.shape, outShape);
        if (reduceAxes.length > 0) {
          return reshape(sum2(res, reduceAxes), a.shape);
        }
        return res;
      };
      const derB = () => {
        let res = mul(dy, cast(a, "float32"));
        const reduceAxes = getReductionAxes(b.shape, outShape);
        if (reduceAxes.length > 0) {
          res = reshape(sum2(res, reduceAxes), b.shape);
        }
        const tmp = square(b);
        return neg(div(res, cast(tmp, "float32")));
      };
      return { a: derA, b: derB };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Reciprocal_grad.js
  var reciprocalGradConfig = {
    kernelName: Reciprocal,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return { x: () => div(dy, neg(square(x))) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Relu6_grad.js
  var relu6GradConfig = {
    kernelName: Relu6,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      const mask = mul(lessEqual(x, 6), step(x));
      return { x: () => mul(dy, cast(mask, "float32")) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Relu_grad.js
  var reluGradConfig = {
    kernelName: Relu,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return { x: () => mul(dy, cast(step(x), "float32")) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Reshape_grad.js
  var reshapeGradConfig = {
    kernelName: Reshape,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return { x: () => reshape(dy, x.shape) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/ResizeBilinear_grad.js
  var resizeBilinearGradConfig = {
    kernelName: ResizeBilinear,
    inputsToSave: ["images"],
    gradFunc: (dy, saved, attrs) => {
      const [images] = saved;
      const inputs = { dy, images };
      const imagesDer = () => ENGINE.runKernel(ResizeBilinearGrad, inputs, attrs);
      return { images: imagesDer };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/ResizeNearestNeighbor_grad.js
  var resizeNearestNeighborGradConfig = {
    kernelName: ResizeNearestNeighbor,
    inputsToSave: ["images"],
    gradFunc: (dy, saved, attrs) => {
      const [images] = saved;
      const inputs = { dy, images };
      const imagesDer = () => ENGINE.runKernel(ResizeNearestNeighborGrad, inputs, attrs);
      return { images: imagesDer };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Reverse_grad.js
  var reverseGradConfig = {
    kernelName: Reverse,
    gradFunc: (dy, saved, attrs) => {
      const { dims } = attrs;
      const axes = parseAxisParam(dims, dy.shape);
      return { x: () => reverse(dy, axes) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Round_grad.js
  var roundGradConfig = {
    kernelName: Round,
    gradFunc: (dy) => {
      return { x: () => zerosLike(dy) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Rsqrt_grad.js
  var rsqrtGradConfig = {
    kernelName: Rsqrt,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return { x: () => neg(div(dy, mul(pow(x, 1.5), 2))) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Select_grad.js
  var selectGradConfig = {
    kernelName: Select,
    inputsToSave: ["condition"],
    gradFunc: (dy, saved) => {
      const [condition] = saved;
      return {
        condition: () => cast(zerosLike(condition), "float32"),
        t: () => mul(dy, cast(condition, dy.dtype)),
        e: () => mul(dy, cast(logicalNot(condition), dy.dtype))
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Selu_grad.js
  var seluGradConfig = {
    kernelName: Selu,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return {
        x: () => {
          const mask = greater(x, scalar(0));
          const scaleAlpha2 = scalar(SELU_SCALEALPHA);
          const scale2 = scalar(SELU_SCALE);
          const greaterThanZeroDer = mul(dy, scale2);
          const lessEqualZeroDer = mul(mul(dy, scaleAlpha2), exp(cast(x, "float32")));
          return where(mask, greaterThanZeroDer, lessEqualZeroDer);
        }
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Sigmoid_grad.js
  var sigmoidGradConfig = {
    kernelName: Sigmoid,
    outputsToSave: [true],
    gradFunc: (dy, saved) => {
      const [y] = saved;
      return { x: () => mul(dy, mul(y, sub(scalar(1), y))) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Sign_grad.js
  var signGradConfig = {
    kernelName: Sign,
    gradFunc: (dy) => {
      return { x: () => zerosLike(dy) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Sin_grad.js
  var sinGradConfig = {
    kernelName: Sin,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return { x: () => mul(cos(cast(x, "float32")), dy) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Sinh_grad.js
  var sinhGradConfig = {
    kernelName: Sinh,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return { x: () => mul(cosh(cast(x, "float32")), dy) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Slice_grad.js
  var sliceGradConfig = {
    kernelName: Slice,
    inputsToSave: ["x"],
    gradFunc: (dy, saved, attrs) => {
      const [x] = saved;
      const { begin, size: size2 } = attrs;
      const inputShape = x.shape;
      const [begin_, size_] = parseSliceParams(x, begin, size2);
      const paddings = [];
      for (let i = 0; i < dy.rank; i++) {
        paddings.push([begin_[i], inputShape[i] - begin_[i] - size_[i]]);
      }
      return { x: () => pad(dy, paddings) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Softmax_grad.js
  var softmaxGradConfig = {
    kernelName: Softmax,
    outputsToSave: [true],
    gradFunc: (dy, saved, attrs) => {
      const [y] = saved;
      const { dim } = attrs;
      const keepDims = true;
      const dyTimesY = mul(dy, y);
      return {
        logits: () => sub(dyTimesY, mul(sum2(dyTimesY, [dim], keepDims), y))
      };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Softplus_grad.js
  var softplusGradConfig = {
    kernelName: Softplus,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return { x: () => mul(dy, sigmoid(x)) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/SpaceToBatchND_grad.js
  var spaceToBatchNDGradConfig = {
    kernelName: SpaceToBatchND,
    gradFunc: (dy, saved, attrs) => {
      const { blockShape, paddings } = attrs;
      return { x: () => batchToSpaceND(dy, blockShape, paddings) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/SplitV_grad.js
  var splitVGradConfig = {
    kernelName: SplitV,
    gradFunc: (dy, saved, attrs) => {
      const { axis } = attrs;
      return { x: () => concat(dy, axis) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Sqrt_grad.js
  var sqrtGradConfig = {
    kernelName: Sqrt,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return { x: () => div(dy, mul(sqrt(cast(x, "float32")), 2)) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Square_grad.js
  var squareGradConfig = {
    kernelName: Square,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return { x: () => mul(dy, mul(cast(x, "float32"), 2)) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/SquaredDifference_grad.js
  var squaredDifferenceGradConfig = {
    kernelName: SquaredDifference,
    inputsToSave: ["a", "b"],
    gradFunc: (dy, saved) => {
      const [a, b] = saved;
      const two = scalar(2);
      const derA = () => mul(dy, mul(two, sub(a, b)));
      const derB = () => mul(dy, mul(two, sub(b, a)));
      return { a: derA, b: derB };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Step_grad.js
  var stepGradConfig = {
    kernelName: Step,
    gradFunc: (dy) => {
      return { x: () => zerosLike(dy) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Sub_grad.js
  var subGradConfig = {
    kernelName: Sub,
    inputsToSave: ["a", "b"],
    gradFunc: (dy, saved) => {
      const [a, b] = saved;
      const outShape = assertAndGetBroadcastShape(a.shape, b.shape);
      const derA = () => {
        let res = dy;
        const reduceAxes = getReductionAxes(a.shape, outShape);
        if (reduceAxes.length > 0) {
          res = sum2(res, reduceAxes);
        }
        return reshape(res, a.shape);
      };
      const derB = () => {
        let res = dy;
        const reduceAxes = getReductionAxes(b.shape, outShape);
        if (reduceAxes.length > 0) {
          res = sum2(res, reduceAxes);
        }
        return reshape(neg(res), b.shape);
      };
      return { a: derA, b: derB };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Sum_grad.js
  var sumGradConfig = {
    kernelName: Sum,
    inputsToSave: ["x"],
    gradFunc: (dy, saved, attrs) => {
      const [x] = saved;
      const expandedDyShape = x.shape.slice();
      const { axis } = attrs;
      const axes = parseAxisParam(axis, x.shape);
      axes.forEach((axis2) => {
        expandedDyShape[axis2] = 1;
      });
      const expandedDy = reshape(dy, expandedDyShape);
      const derX = mul(expandedDy, ones2(x.shape, "float32"));
      return { x: () => derX };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Tan_grad.js
  var tanGradConfig = {
    kernelName: Tan,
    inputsToSave: ["x"],
    gradFunc: (dy, saved) => {
      const [x] = saved;
      return { x: () => div(dy, square(cos(x))) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Tanh_grad.js
  var tanhGradConfig = {
    kernelName: Tanh,
    outputsToSave: [true],
    gradFunc: (dy, saved) => {
      const [y] = saved;
      return { x: () => mul(sub(scalar(1), square(y)), dy) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Tile_grad.js
  var tileGradConfig = {
    kernelName: Tile,
    inputsToSave: ["x"],
    gradFunc: (dy, saved, attrs) => {
      const [x] = saved;
      const { reps } = attrs;
      const derX = () => {
        let xGrad = zerosLike(x);
        if (x.rank === 1) {
          for (let i = 0; i < reps[0]; ++i) {
            xGrad = add3(xGrad, slice(dy, [i * x.shape[0]], [x.shape[0]]));
          }
        } else if (x.rank === 2) {
          for (let i = 0; i < reps[0]; ++i) {
            for (let j = 0; j < reps[1]; ++j) {
              xGrad = add3(xGrad, slice(dy, [i * x.shape[0], j * x.shape[1]], [
                x.shape[0],
                x.shape[1]
              ]));
            }
          }
        } else if (x.rank === 3) {
          for (let i = 0; i < reps[0]; ++i) {
            for (let j = 0; j < reps[1]; ++j) {
              for (let k = 0; k < reps[2]; ++k) {
                xGrad = add3(xGrad, slice(dy, [i * x.shape[0], j * x.shape[1], k * x.shape[2]], [x.shape[0], x.shape[1], x.shape[2]]));
              }
            }
          }
        } else if (x.rank === 4) {
          for (let i = 0; i < reps[0]; ++i) {
            for (let j = 0; j < reps[1]; ++j) {
              for (let k = 0; k < reps[2]; ++k) {
                for (let l = 0; l < reps[3]; ++l) {
                  xGrad = add3(xGrad, slice(dy, [
                    i * x.shape[0],
                    j * x.shape[1],
                    k * x.shape[2],
                    l * x.shape[3]
                  ], [x.shape[0], x.shape[1], x.shape[2], x.shape[3]]));
                }
              }
            }
          }
        } else {
          throw new Error(`Gradient for tile operation is not implemented for rank-${x.rank} tensors yet.`);
        }
        return xGrad;
      };
      return { x: derX };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Transpose_grad.js
  var transposeGradConfig = {
    kernelName: Transpose,
    gradFunc: (dy, saved, attrs) => {
      const transposeAttrs = attrs;
      const { perm } = transposeAttrs;
      const undoPerm = getUndoAxesPermutation(perm);
      return { x: () => transpose(dy, undoPerm) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/Unpack_grad.js
  var unpackGradConfig = {
    kernelName: Unpack,
    gradFunc: (dy, saved, attrs) => {
      const unpackAttrs = attrs;
      const { axis } = unpackAttrs;
      return { value: () => stack2(dy, axis) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/gradients/UnsortedSegmentSum_grad.js
  var unsortedSegmentSumGradConfig = {
    kernelName: UnsortedSegmentSum,
    inputsToSave: ["segmentIds"],
    gradFunc: (dy, saved) => {
      const [segmentIds] = saved;
      const derX = () => {
        return gatherDropNegatives(dy, segmentIds);
      };
      return { x: derX };
    }
  };
  function gatherDropNegatives(x, indices) {
    const zeroClippedIndices = maximum(indices, zerosLike(indices));
    const gathered = gather(x, zeroClippedIndices);
    let isPositive = greaterEqual(indices, scalar(0, "int32"));
    const numIters = gathered.rank - isPositive.rank;
    for (let i = 0; i < numIters; ++i) {
      isPositive = expandDims(isPositive, i + 1);
    }
    isPositive = logicalAnd(isPositive, ones2(gathered.shape, "bool"));
    const zeroSlice = zerosLike(gathered);
    return where(isPositive, gathered, zeroSlice);
  }

  // node_modules/@tensorflow/tfjs-core/dist/gradients/ZerosLike_grad.js
  var zerosLikeGradConfig = {
    kernelName: ZerosLike,
    gradFunc: (dy) => {
      return { x: () => zerosLike(dy) };
    }
  };

  // node_modules/@tensorflow/tfjs-core/dist/register_all_gradients.js
  var gradConfigs = [
    absGradConfig,
    acosGradConfig,
    acoshGradConfig,
    addGradConfig,
    addNGradConfig,
    argMaxGradConfig,
    argMinGradConfig,
    asinGradConfig,
    asinhGradConfig,
    atan2GradConfig,
    atanGradConfig,
    atanhGradConfig,
    avgPool3DGradConfig,
    avgPoolGradConfig,
    batchMatMulGradConfig,
    batchToSpaceNDGradConfig,
    broadcastToGradConfig,
    castGradConfig,
    ceilGradConfig,
    clipByValueGradConfig,
    complexAbsGradConfig,
    concatGradConfig,
    conv2DBackpropInputGradConfig,
    conv2DGradConfig,
    conv3DGradConfig,
    cosGradConfig,
    coshGradConfig,
    cumsumGradConfig,
    depthwiseConv2dNativeGradConfig,
    dilation2dGradConfig,
    divGradConfig,
    eluGradConfig,
    erfGradConfig,
    expGradConfig,
    expandDimsGradConfig,
    expm1GradConfig,
    floorDivGradConfig,
    floorGradConfig,
    fusedBatchNormGradConfig,
    gatherGradConfig,
    greaterEqualGradConfig,
    identityGradConfig,
    isFiniteGradConfig,
    isInfGradConfig,
    isNanGradConfig,
    leakyReluGradConfig,
    log1pGradConfig,
    logGradConfig,
    logSoftmaxGradConfig,
    lrnGradConfig,
    maxGradConfig,
    maxGradConfig,
    maximumGradConfig,
    maxPool3DGradConfig,
    maxPoolGradConfig,
    meanGradConfig,
    minGradConfig,
    minimumGradConfig,
    mirrorPadGradConfig,
    modGradConfig,
    multiplyGradConfig,
    negGradConfig,
    oneHotGradConfig,
    onesLikeGradConfig,
    packGradConfig,
    padV2GradConfig,
    padV2GradConfig,
    powGradConfig,
    preluGradConfig,
    reciprocalGradConfig,
    relu6GradConfig,
    reluGradConfig,
    reshapeGradConfig,
    resizeBilinearGradConfig,
    resizeNearestNeighborGradConfig,
    reverseGradConfig,
    roundGradConfig,
    rsqrtGradConfig,
    selectGradConfig,
    seluGradConfig,
    sigmoidGradConfig,
    signGradConfig,
    sinGradConfig,
    sinhGradConfig,
    sliceGradConfig,
    softmaxGradConfig,
    softplusGradConfig,
    spaceToBatchNDGradConfig,
    spaceToBatchNDGradConfig,
    splitVGradConfig,
    splitVGradConfig,
    sqrtGradConfig,
    squaredDifferenceGradConfig,
    squareGradConfig,
    stepGradConfig,
    subGradConfig,
    sumGradConfig,
    tanGradConfig,
    tanhGradConfig,
    tileGradConfig,
    transposeGradConfig,
    unpackGradConfig,
    unsortedSegmentSumGradConfig,
    zerosLikeGradConfig
  ];
  for (const gradientConfig of gradConfigs) {
    registerGradient(gradientConfig);
  }

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/abs.js
  getGlobalTensorClass().prototype.abs = function() {
    this.throwIfDisposed();
    return abs(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/acos.js
  getGlobalTensorClass().prototype.acos = function() {
    this.throwIfDisposed();
    return acos(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/acosh.js
  getGlobalTensorClass().prototype.acosh = function() {
    this.throwIfDisposed();
    return acosh(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/add.js
  getGlobalTensorClass().prototype.add = function(b) {
    this.throwIfDisposed();
    return add3(this, b);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/all.js
  getGlobalTensorClass().prototype.all = function(axis, keepDims) {
    this.throwIfDisposed();
    return all(this, axis, keepDims);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/any.js
  getGlobalTensorClass().prototype.any = function(axis, keepDims) {
    this.throwIfDisposed();
    return any(this, axis, keepDims);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/arg_max.js
  getGlobalTensorClass().prototype.argMax = function(axis) {
    this.throwIfDisposed();
    return argMax(this, axis);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/arg_min.js
  getGlobalTensorClass().prototype.argMin = function(axis) {
    this.throwIfDisposed();
    return argMin(this, axis);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/as_scalar.js
  getGlobalTensorClass().prototype.asScalar = function() {
    this.throwIfDisposed();
    assert(this.size === 1, () => "The array must have only 1 element.");
    return reshape(this, []);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/as_type.js
  getGlobalTensorClass().prototype.asType = function(dtype) {
    this.throwIfDisposed();
    return cast(this, dtype);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/as1d.js
  getGlobalTensorClass().prototype.as1D = function() {
    this.throwIfDisposed();
    return reshape(this, [this.size]);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/as2d.js
  getGlobalTensorClass().prototype.as2D = function(rows, columns) {
    this.throwIfDisposed();
    return reshape(this, [rows, columns]);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/as3d.js
  getGlobalTensorClass().prototype.as3D = function(rows, columns, depth) {
    this.throwIfDisposed();
    return reshape(this, [rows, columns, depth]);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/as4d.js
  getGlobalTensorClass().prototype.as4D = function(rows, columns, depth, depth2) {
    this.throwIfDisposed();
    return reshape(this, [rows, columns, depth, depth2]);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/as5d.js
  getGlobalTensorClass().prototype.as5D = function(rows, columns, depth, depth2, depth3) {
    this.throwIfDisposed();
    return reshape(this, [rows, columns, depth, depth2, depth3]);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/asin.js
  getGlobalTensorClass().prototype.asin = function() {
    this.throwIfDisposed();
    return asin(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/asinh.js
  getGlobalTensorClass().prototype.asinh = function() {
    this.throwIfDisposed();
    return asinh(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/atan.js
  getGlobalTensorClass().prototype.atan = function() {
    this.throwIfDisposed();
    return atan(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/atan2.js
  getGlobalTensorClass().prototype.atan2 = function(b) {
    this.throwIfDisposed();
    return atan2(this, b);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/atanh.js
  getGlobalTensorClass().prototype.atanh = function() {
    this.throwIfDisposed();
    return atanh(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/avg_pool.js
  getGlobalTensorClass().prototype.avgPool = function(filterSize, strides, pad2, dimRoundingMode) {
    this.throwIfDisposed();
    return avgPool(this, filterSize, strides, pad2, dimRoundingMode);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/batch_to_space_nd.js
  getGlobalTensorClass().prototype.batchToSpaceND = function(blockShape, crops) {
    this.throwIfDisposed();
    return batchToSpaceND(this, blockShape, crops);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/batchnorm.js
  getGlobalTensorClass().prototype.batchNorm = function(mean3, variance, offset, scale2, varianceEpsilon) {
    this.throwIfDisposed();
    return batchNorm(this, mean3, variance, offset, scale2, varianceEpsilon);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/broadcast_to.js
  getGlobalTensorClass().prototype.broadcastTo = function(shape) {
    this.throwIfDisposed();
    return broadcastTo(this, shape);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/cast.js
  getGlobalTensorClass().prototype.cast = function(dtype) {
    this.throwIfDisposed();
    return cast(this, dtype);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/ceil.js
  getGlobalTensorClass().prototype.ceil = function() {
    this.throwIfDisposed();
    return ceil(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/clip_by_value.js
  getGlobalTensorClass().prototype.clipByValue = function(min5, max5) {
    this.throwIfDisposed();
    return clipByValue(this, min5, max5);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/concat.js
  getGlobalTensorClass().prototype.concat = function(x, axis) {
    this.throwIfDisposed();
    if (x instanceof Tensor) {
      x = [x];
    }
    return concat([this, ...x], axis);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/conv1d.js
  getGlobalTensorClass().prototype.conv1d = function(filter, stride, pad2, dataFormat, dilation, dimRoundingMode) {
    this.throwIfDisposed();
    return conv1d(this, filter, stride, pad2, dataFormat, dilation, dimRoundingMode);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/conv2d_transpose.js
  getGlobalTensorClass().prototype.conv2dTranspose = function(filter, outputShape, strides, pad2, dimRoundingMode) {
    this.throwIfDisposed();
    return conv2dTranspose(this, filter, outputShape, strides, pad2, dimRoundingMode);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/conv2d.js
  getGlobalTensorClass().prototype.conv2d = function(filter, strides, pad2, dataFormat, dilations, dimRoundingMode) {
    this.throwIfDisposed();
    return conv2d(this, filter, strides, pad2, dataFormat, dilations, dimRoundingMode);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/cos.js
  getGlobalTensorClass().prototype.cos = function() {
    this.throwIfDisposed();
    return cos(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/cosh.js
  getGlobalTensorClass().prototype.cosh = function() {
    this.throwIfDisposed();
    return cosh(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/cumsum.js
  getGlobalTensorClass().prototype.cumsum = function(axis, exclusive, reverse4) {
    this.throwIfDisposed();
    return cumsum(this, axis, exclusive, reverse4);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/depth_to_space.js
  getGlobalTensorClass().prototype.depthToSpace = function(blockSize, dataFormat) {
    this.throwIfDisposed();
    return depthToSpace(this, blockSize, dataFormat);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/depthwise_conv2d.js
  getGlobalTensorClass().prototype.depthwiseConv2d = function(filter, strides, pad2, dataFormat, dilations, dimRoundingMode) {
    this.throwIfDisposed();
    return depthwiseConv2d(this, filter, strides, pad2, dataFormat, dilations, dimRoundingMode);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/dilation2d.js
  getGlobalTensorClass().prototype.dilation2d = function(filter, strides, pad2, dilations, dataFormat) {
    this.throwIfDisposed();
    return dilation2d(this, filter, strides, pad2, dilations, dataFormat);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/div_no_nan.js
  getGlobalTensorClass().prototype.divNoNan = function(b) {
    this.throwIfDisposed();
    return divNoNan(this, b);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/div.js
  getGlobalTensorClass().prototype.div = function(b) {
    this.throwIfDisposed();
    return div(this, b);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/dot.js
  getGlobalTensorClass().prototype.dot = function(b) {
    this.throwIfDisposed();
    return dot(this, b);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/elu.js
  getGlobalTensorClass().prototype.elu = function() {
    this.throwIfDisposed();
    return elu(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/equal.js
  getGlobalTensorClass().prototype.equal = function(b) {
    this.throwIfDisposed();
    return equal(this, b);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/erf.js
  getGlobalTensorClass().prototype.erf = function() {
    this.throwIfDisposed();
    return erf(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/exp.js
  getGlobalTensorClass().prototype.exp = function() {
    this.throwIfDisposed();
    return exp(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/expand_dims.js
  getGlobalTensorClass().prototype.expandDims = function(axis) {
    this.throwIfDisposed();
    return expandDims(this, axis);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/expm1.js
  getGlobalTensorClass().prototype.expm1 = function() {
    this.throwIfDisposed();
    return expm1(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/fft.js
  getGlobalTensorClass().prototype.fft = function() {
    this.throwIfDisposed();
    return fft(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/flatten.js
  getGlobalTensorClass().prototype.flatten = function() {
    this.throwIfDisposed();
    return reshape(this, [this.size]);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/floor.js
  getGlobalTensorClass().prototype.floor = function() {
    this.throwIfDisposed();
    return floor(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/floorDiv.js
  getGlobalTensorClass().prototype.floorDiv = function(b) {
    this.throwIfDisposed();
    return floorDiv(this, b);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/gather.js
  getGlobalTensorClass().prototype.gather = function(indices, axis) {
    this.throwIfDisposed();
    return gather(this, indices, axis);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/greater_equal.js
  getGlobalTensorClass().prototype.greaterEqual = function(b) {
    this.throwIfDisposed();
    return greaterEqual(this, b);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/greater.js
  getGlobalTensorClass().prototype.greater = function(b) {
    this.throwIfDisposed();
    return greater(this, b);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/ifft.js
  getGlobalTensorClass().prototype.ifft = function() {
    this.throwIfDisposed();
    return ifft(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/irfft.js
  getGlobalTensorClass().prototype.irfft = function() {
    this.throwIfDisposed();
    return irfft(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/is_finite.js
  getGlobalTensorClass().prototype.isFinite = function() {
    this.throwIfDisposed();
    return isFinite2(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/is_inf.js
  getGlobalTensorClass().prototype.isInf = function() {
    this.throwIfDisposed();
    return isInf(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/is_nan.js
  getGlobalTensorClass().prototype.isNaN = function() {
    this.throwIfDisposed();
    return isNaN2(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/leaky_relu.js
  getGlobalTensorClass().prototype.leakyRelu = function(alpha) {
    this.throwIfDisposed();
    return leakyRelu(this, alpha);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/less_equal.js
  getGlobalTensorClass().prototype.lessEqual = function(b) {
    this.throwIfDisposed();
    return lessEqual(this, b);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/less.js
  getGlobalTensorClass().prototype.less = function(b) {
    this.throwIfDisposed();
    return less(this, b);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/local_response_normalization.js
  getGlobalTensorClass().prototype.localResponseNormalization = function(depthRadius, bias, alpha, beta) {
    this.throwIfDisposed();
    return localResponseNormalization(this, depthRadius, bias, alpha, beta);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/log_sigmoid.js
  getGlobalTensorClass().prototype.logSigmoid = function() {
    this.throwIfDisposed();
    return logSigmoid(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/log_softmax.js
  getGlobalTensorClass().prototype.logSoftmax = function(axis) {
    this.throwIfDisposed();
    return logSoftmax(this, axis);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/log_sum_exp.js
  getGlobalTensorClass().prototype.logSumExp = function(axis, keepDims) {
    this.throwIfDisposed();
    return logSumExp(this, axis, keepDims);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/log.js
  getGlobalTensorClass().prototype.log = function() {
    this.throwIfDisposed();
    return log5(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/log1p.js
  getGlobalTensorClass().prototype.log1p = function() {
    this.throwIfDisposed();
    return log1p(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/logical_and.js
  getGlobalTensorClass().prototype.logicalAnd = function(b) {
    this.throwIfDisposed();
    return logicalAnd(this, b);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/logical_not.js
  getGlobalTensorClass().prototype.logicalNot = function() {
    this.throwIfDisposed();
    return logicalNot(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/logical_or.js
  getGlobalTensorClass().prototype.logicalOr = function(b) {
    this.throwIfDisposed();
    return logicalOr(this, b);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/logical_xor.js
  getGlobalTensorClass().prototype.logicalXor = function(b) {
    this.throwIfDisposed();
    return logicalXor(this, b);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/mat_mul.js
  getGlobalTensorClass().prototype.matMul = function(b, transposeA, transposeB) {
    this.throwIfDisposed();
    return matMul(this, b, transposeA, transposeB);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/max_pool.js
  getGlobalTensorClass().prototype.maxPool = function(filterSize, strides, pad2, dimRoundingMode) {
    this.throwIfDisposed();
    return maxPool(this, filterSize, strides, pad2, dimRoundingMode);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/max.js
  getGlobalTensorClass().prototype.max = function(axis, keepDims) {
    this.throwIfDisposed();
    return max(this, axis, keepDims);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/maximum.js
  getGlobalTensorClass().prototype.maximum = function(b) {
    this.throwIfDisposed();
    return maximum(this, b);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/mean.js
  getGlobalTensorClass().prototype.mean = function(axis, keepDims) {
    this.throwIfDisposed();
    return mean(this, axis, keepDims);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/min.js
  getGlobalTensorClass().prototype.min = function(axis, keepDims) {
    this.throwIfDisposed();
    return min(this, axis, keepDims);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/minimum.js
  getGlobalTensorClass().prototype.minimum = function(b) {
    this.throwIfDisposed();
    return minimum(this, b);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/mirror_pad.js
  getGlobalTensorClass().prototype.mirrorPad = function(paddings, mode) {
    this.throwIfDisposed();
    return mirrorPad(this, paddings, mode);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/mod.js
  getGlobalTensorClass().prototype.mod = function(b) {
    this.throwIfDisposed();
    return mod(this, b);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/mul.js
  getGlobalTensorClass().prototype.mul = function(b) {
    this.throwIfDisposed();
    return mul(this, b);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/neg.js
  getGlobalTensorClass().prototype.neg = function() {
    this.throwIfDisposed();
    return neg(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/norm.js
  getGlobalTensorClass().prototype.norm = function(ord, axis, keepDims) {
    this.throwIfDisposed();
    return norm(this, ord, axis, keepDims);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/not_equal.js
  getGlobalTensorClass().prototype.notEqual = function(b) {
    this.throwIfDisposed();
    return notEqual(this, b);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/one_hot.js
  getGlobalTensorClass().prototype.oneHot = function(depth, onValue = 1, offValue = 0) {
    this.throwIfDisposed();
    return oneHot(this, depth, onValue, offValue);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/ones_like.js
  getGlobalTensorClass().prototype.onesLike = function() {
    this.throwIfDisposed();
    return onesLike(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/pad.js
  getGlobalTensorClass().prototype.pad = function(paddings, constantValue) {
    this.throwIfDisposed();
    return pad(this, paddings, constantValue);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/pool.js
  getGlobalTensorClass().prototype.pool = function(windowShape, poolingType, padding, dilationRate, strides) {
    this.throwIfDisposed();
    return pool(this, windowShape, poolingType, padding, dilationRate, strides);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/pow.js
  getGlobalTensorClass().prototype.pow = function(exp4) {
    this.throwIfDisposed();
    return pow(this, exp4);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/prelu.js
  getGlobalTensorClass().prototype.prelu = function(alpha) {
    this.throwIfDisposed();
    return prelu(this, alpha);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/prod.js
  getGlobalTensorClass().prototype.prod = function(axis, keepDims) {
    this.throwIfDisposed();
    return prod(this, axis, keepDims);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/reciprocal.js
  getGlobalTensorClass().prototype.reciprocal = function() {
    this.throwIfDisposed();
    return reciprocal(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/relu.js
  getGlobalTensorClass().prototype.relu = function() {
    this.throwIfDisposed();
    return relu(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/relu6.js
  getGlobalTensorClass().prototype.relu6 = function() {
    this.throwIfDisposed();
    return relu6(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/reshape_as.js
  getGlobalTensorClass().prototype.reshapeAs = function(x) {
    this.throwIfDisposed();
    return reshape(this, x.shape);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/reshape.js
  getGlobalTensorClass().prototype.reshape = function(shape) {
    this.throwIfDisposed();
    return reshape(this, shape);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/resize_bilinear.js
  getGlobalTensorClass().prototype.resizeBilinear = function(newShape2D, alignCorners, halfPixelCenters) {
    this.throwIfDisposed();
    return resizeBilinear(this, newShape2D, alignCorners, halfPixelCenters);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/resize_nearest_neighbor.js
  getGlobalTensorClass().prototype.resizeNearestNeighbor = function(newShape2D, alignCorners, halfFloatCenters) {
    this.throwIfDisposed();
    return resizeNearestNeighbor(this, newShape2D, alignCorners, halfFloatCenters);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/reverse.js
  getGlobalTensorClass().prototype.reverse = function(axis) {
    this.throwIfDisposed();
    return reverse(this, axis);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/rfft.js
  getGlobalTensorClass().prototype.rfft = function() {
    this.throwIfDisposed();
    return rfft(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/round.js
  getGlobalTensorClass().prototype.round = function() {
    this.throwIfDisposed();
    return round2(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/rsqrt.js
  getGlobalTensorClass().prototype.rsqrt = function() {
    this.throwIfDisposed();
    return rsqrt(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/selu.js
  getGlobalTensorClass().prototype.selu = function() {
    this.throwIfDisposed();
    return selu(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/separable_conv2d.js
  getGlobalTensorClass().prototype.separableConv2d = function(depthwiseFilter, pointwiseFilter, strides, pad2, dilation, dataFormat) {
    this.throwIfDisposed();
    return separableConv2d(this, depthwiseFilter, pointwiseFilter, strides, pad2, dilation, dataFormat);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/sigmoid.js
  getGlobalTensorClass().prototype.sigmoid = function() {
    this.throwIfDisposed();
    return sigmoid(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/sign.js
  getGlobalTensorClass().prototype.sign = function() {
    this.throwIfDisposed();
    return sign(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/sin.js
  getGlobalTensorClass().prototype.sin = function() {
    this.throwIfDisposed();
    return sin(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/sinh.js
  getGlobalTensorClass().prototype.sinh = function() {
    this.throwIfDisposed();
    return sinh(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/slice.js
  getGlobalTensorClass().prototype.slice = function(begin, size2) {
    this.throwIfDisposed();
    return slice(this, begin, size2);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/softmax.js
  getGlobalTensorClass().prototype.softmax = function(dim) {
    this.throwIfDisposed();
    return softmax(this, dim);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/softplus.js
  getGlobalTensorClass().prototype.softplus = function() {
    this.throwIfDisposed();
    return softplus(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/space_to_batch_nd.js
  getGlobalTensorClass().prototype.spaceToBatchND = function(blockShape, paddings) {
    this.throwIfDisposed();
    return spaceToBatchND(this, blockShape, paddings);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/split.js
  getGlobalTensorClass().prototype.split = function(numOrSizeSplits, axis) {
    this.throwIfDisposed();
    return split(this, numOrSizeSplits, axis);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/sqrt.js
  getGlobalTensorClass().prototype.sqrt = function() {
    this.throwIfDisposed();
    return sqrt(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/square.js
  getGlobalTensorClass().prototype.square = function() {
    this.throwIfDisposed();
    return square(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/squared_difference.js
  getGlobalTensorClass().prototype.squaredDifference = function(b) {
    this.throwIfDisposed();
    return squaredDifference(this, b);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/squeeze.js
  getGlobalTensorClass().prototype.squeeze = function(axis) {
    this.throwIfDisposed();
    return squeeze(this, axis);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/stack.js
  getGlobalTensorClass().prototype.stack = function(x, axis) {
    this.throwIfDisposed();
    const tensorsToBeStacked = x instanceof Tensor ? [this, x] : [this, ...x];
    return stack2(tensorsToBeStacked, axis);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/step.js
  getGlobalTensorClass().prototype.step = function(alpha) {
    this.throwIfDisposed();
    return step(this, alpha);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/strided_slice.js
  getGlobalTensorClass().prototype.stridedSlice = function(begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {
    this.throwIfDisposed();
    return stridedSlice(this, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/sub.js
  getGlobalTensorClass().prototype.sub = function(b) {
    this.throwIfDisposed();
    return sub(this, b);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/sum.js
  getGlobalTensorClass().prototype.sum = function(axis, keepDims) {
    this.throwIfDisposed();
    return sum2(this, axis, keepDims);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/tan.js
  getGlobalTensorClass().prototype.tan = function() {
    this.throwIfDisposed();
    return tan(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/tanh.js
  getGlobalTensorClass().prototype.tanh = function() {
    this.throwIfDisposed();
    return tanh2(this);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/tile.js
  getGlobalTensorClass().prototype.tile = function(reps) {
    this.throwIfDisposed();
    return tile(this, reps);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/to_bool.js
  getGlobalTensorClass().prototype.toBool = function() {
    this.throwIfDisposed();
    return cast(this, "bool");
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/to_float.js
  getGlobalTensorClass().prototype.toFloat = function() {
    this.throwIfDisposed();
    return cast(this, "float32");
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/to_int.js
  getGlobalTensorClass().prototype.toInt = function() {
    this.throwIfDisposed();
    return cast(this, "int32");
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/topk.js
  getGlobalTensorClass().prototype.topk = function(k, sorted) {
    this.throwIfDisposed();
    return topk(this, k, sorted);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/transpose.js
  getGlobalTensorClass().prototype.transpose = function(perm) {
    this.throwIfDisposed();
    return transpose(this, perm);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/unique.js
  getGlobalTensorClass().prototype.unique = function(axis) {
    this.throwIfDisposed();
    return unique(this, axis);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/unsorted_segment_sum.js
  getGlobalTensorClass().prototype.unsortedSegmentSum = function(segmentIds, numSegments) {
    this.throwIfDisposed();
    return unsortedSegmentSum(this, segmentIds, numSegments);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/unstack.js
  getGlobalTensorClass().prototype.unstack = function(axis) {
    this.throwIfDisposed();
    return unstack(this, axis);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/where.js
  getGlobalTensorClass().prototype.where = function(condition, x) {
    this.throwIfDisposed();
    return where(condition, this, x);
  };

  // node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/zeros_like.js
  getGlobalTensorClass().prototype.zerosLike = function() {
    this.throwIfDisposed();
    return zerosLike(this);
  };

  // node_modules/@tensorflow/tfjs-layers/dist/backend/common.js
  var _epsilon;
  function epsilon() {
    if (_epsilon == null) {
      _epsilon = backend().epsilon();
    }
    return _epsilon;
  }
  function imageDataFormat() {
    return "channelsLast";
  }

  // node_modules/@tensorflow/tfjs-layers/dist/errors.js
  var AttributeError = class extends Error {
    constructor(message) {
      super(message);
      Object.setPrototypeOf(this, AttributeError.prototype);
    }
  };
  var RuntimeError = class extends Error {
    constructor(message) {
      super(message);
      Object.setPrototypeOf(this, RuntimeError.prototype);
    }
  };
  var ValueError = class extends Error {
    constructor(message) {
      super(message);
      Object.setPrototypeOf(this, ValueError.prototype);
    }
  };
  var NotImplementedError = class extends Error {
    constructor(message) {
      super(message);
      Object.setPrototypeOf(this, NotImplementedError.prototype);
    }
  };
  var AssertionError = class extends Error {
    constructor(message) {
      super(message);
      Object.setPrototypeOf(this, AssertionError.prototype);
    }
  };

  // node_modules/@tensorflow/tfjs-layers/dist/utils/generic_utils.js
  function pyListRepeat(value, numValues) {
    if (Array.isArray(value)) {
      let newArray = [];
      for (let i = 0; i < numValues; i++) {
        newArray = newArray.concat(value);
      }
      return newArray;
    } else {
      const newArray = new Array(numValues);
      newArray.fill(value);
      return newArray;
    }
  }
  function assert2(val, message) {
    if (!val) {
      throw new AssertionError(message);
    }
  }
  function count(array2, refernce) {
    let counter = 0;
    for (const item of array2) {
      if (item === refernce) {
        counter++;
      }
    }
    return counter;
  }
  function singletonOrArray(xs) {
    if (xs.length === 1) {
      return xs[0];
    }
    return xs;
  }
  function toList(x) {
    if (Array.isArray(x)) {
      return x;
    }
    return [x];
  }
  function toSnakeCase(name) {
    const intermediate = name.replace(/(.)([A-Z][a-z0-9]+)/g, "$1_$2");
    const insecure = intermediate.replace(/([a-z])([A-Z])/g, "$1_$2").toLowerCase();
    if (insecure[0] !== "_") {
      return insecure;
    }
    return "private" + insecure;
  }
  function toCamelCase(identifier) {
    if (identifier.length <= 1) {
      return identifier;
    }
    if (identifier.indexOf("_") === -1) {
      return identifier;
    }
    return identifier.replace(/[_]+(\w|$)/g, (m, p1) => p1.toUpperCase());
  }
  var _GLOBAL_CUSTOM_OBJECTS = {};
  function serializeKerasObject(instance) {
    if (instance === null || instance === void 0) {
      return null;
    }
    const dict = {};
    dict["className"] = instance.getClassName();
    dict["config"] = instance.getConfig();
    return dict;
  }
  function convertNDArrayScalarsInConfig(config) {
    if (config == null || typeof config !== "object") {
      return;
    } else if (Array.isArray(config)) {
      config.forEach((configItem) => convertNDArrayScalarsInConfig(configItem));
    } else {
      const fields = Object.keys(config);
      for (const field of fields) {
        const value = config[field];
        if (value != null && typeof value === "object") {
          if (!Array.isArray(value) && value["type"] === "ndarray" && typeof value["value"] === "number") {
            config[field] = value["value"];
          } else {
            convertNDArrayScalarsInConfig(value);
          }
        }
      }
    }
  }
  function deserializeKerasObject(identifier, moduleObjects = {}, customObjects = {}, printableModuleName = "object", fastWeightInit = false) {
    if (typeof identifier === "string") {
      const functionName = identifier;
      let fn;
      if (functionName in customObjects) {
        fn = customObjects[functionName];
      } else if (functionName in _GLOBAL_CUSTOM_OBJECTS) {
        fn = _GLOBAL_CUSTOM_OBJECTS[functionName];
      } else {
        fn = moduleObjects[functionName];
        if (fn == null) {
          throw new ValueError(`Unknown ${printableModuleName}: ${identifier}. This may be due to one of the following reasons:
1. The ${printableModuleName} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.
2. The custom ${printableModuleName} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);
        }
      }
      return fn;
    } else {
      const config = identifier;
      if (config["className"] == null || config["config"] == null) {
        throw new ValueError(`${printableModuleName}: Improper config format: ${JSON.stringify(config)}.
'className' and 'config' must set.`);
      }
      const className = config["className"];
      let cls, fromConfig;
      if (className in customObjects) {
        [cls, fromConfig] = customObjects[className];
      } else if (className in _GLOBAL_CUSTOM_OBJECTS) {
        [cls, fromConfig] = _GLOBAL_CUSTOM_OBJECTS["className"];
      } else if (className in moduleObjects) {
        [cls, fromConfig] = moduleObjects[className];
      }
      if (cls == null) {
        throw new ValueError(`Unknown ${printableModuleName}: ${className}. This may be due to one of the following reasons:
1. The ${printableModuleName} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.
2. The custom ${printableModuleName} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);
      }
      if (fromConfig != null) {
        const customObjectsCombined = {};
        for (const key of Object.keys(_GLOBAL_CUSTOM_OBJECTS)) {
          customObjectsCombined[key] = _GLOBAL_CUSTOM_OBJECTS[key];
        }
        for (const key of Object.keys(customObjects)) {
          customObjectsCombined[key] = customObjects[key];
        }
        const nestedConfig = config["config"];
        nestedConfig["customObjects"] = customObjectsCombined;
        const backupCustomObjects = Object.assign({}, _GLOBAL_CUSTOM_OBJECTS);
        for (const key of Object.keys(customObjects)) {
          _GLOBAL_CUSTOM_OBJECTS[key] = customObjects[key];
        }
        convertNDArrayScalarsInConfig(config["config"]);
        const returnObj = fromConfig(cls, config["config"], customObjects, fastWeightInit);
        _GLOBAL_CUSTOM_OBJECTS = Object.assign({}, backupCustomObjects);
        return returnObj;
      } else {
        const backupCustomObjects = Object.assign({}, _GLOBAL_CUSTOM_OBJECTS);
        for (const key of Object.keys(customObjects)) {
          _GLOBAL_CUSTOM_OBJECTS[key] = customObjects[key];
        }
        const returnObj = new cls(config["config"]);
        _GLOBAL_CUSTOM_OBJECTS = Object.assign({}, backupCustomObjects);
        return returnObj;
      }
    }
  }
  function numberCompare(a, b) {
    return a < b ? -1 : a > b ? 1 : 0;
  }
  function reverseNumberCompare(a, b) {
    return -1 * numberCompare(a, b);
  }
  function unique2(xs) {
    if (xs == null) {
      return xs;
    }
    const out = [];
    for (const x of xs) {
      if (out.indexOf(x) === -1) {
        out.push(x);
      }
    }
    return out;
  }
  function isObjectEmpty(obj) {
    if (obj == null) {
      throw new ValueError(`Invalid value in obj: ${JSON.stringify(obj)}`);
    }
    for (const key in obj) {
      if (obj.hasOwnProperty(key)) {
        return false;
      }
    }
    return true;
  }
  function checkStringTypeUnionValue(values, label, value) {
    if (value == null) {
      return;
    }
    if (values.indexOf(value) < 0) {
      throw new ValueError(`${value} is not a valid ${label}.  Valid values are ${values} or null/undefined.`);
    }
  }
  function checkArrayTypeAndLength(x, expectedType, minLength = 0, maxLength = Infinity) {
    assert2(minLength >= 0);
    assert2(maxLength >= minLength);
    return Array.isArray(x) && x.length >= minLength && x.length <= maxLength && x.every((e) => typeof e === expectedType);
  }
  function assertPositiveInteger(value, name) {
    if (Array.isArray(value)) {
      util_exports.assert(value.length > 0, () => `${name} is unexpectedly an empty array.`);
      value.forEach((v, i) => assertPositiveInteger(v, `element ${i + 1} of ${name}`));
    } else {
      util_exports.assert(Number.isInteger(value) && value > 0, () => `Expected ${name} to be a positive integer, but got ${formatAsFriendlyString(value)}.`);
    }
  }
  function formatAsFriendlyString(value) {
    if (value === null) {
      return "null";
    } else if (Array.isArray(value)) {
      return "[" + value.map((v) => formatAsFriendlyString(v)).join(",") + "]";
    } else if (typeof value === "string") {
      return `"${value}"`;
    } else {
      return `${value}`;
    }
  }
  function debounce(f, waitMs, nowFunc) {
    let lastTime = nowFunc != null ? nowFunc() : util_exports.now();
    let lastResult;
    const f2 = (...args) => {
      const now2 = nowFunc != null ? nowFunc() : util_exports.now();
      if (now2 - lastTime < waitMs) {
        return lastResult;
      }
      lastTime = now2;
      lastResult = f(...args);
      return lastResult;
    };
    return f2;
  }
  function mapActivationToFusedKernel(activationName) {
    if (activationName === "relu") {
      return "relu";
    }
    if (activationName === "linear") {
      return "linear";
    }
    if (activationName === "elu") {
      return "elu";
    }
    return null;
  }

  // node_modules/@tensorflow/tfjs-layers/dist/constraints.js
  function calcL2Norms(w, axis) {
    return tidy(() => sqrt(sum2(mul(w, w), axis, true)));
  }
  var Constraint = class extends serialization_exports.Serializable {
    getConfig() {
      return {};
    }
  };
  var MaxNorm = class extends Constraint {
    constructor(args) {
      super();
      this.defaultMaxValue = 2;
      this.defaultAxis = 0;
      this.maxValue = args.maxValue != null ? args.maxValue : this.defaultMaxValue;
      this.axis = args.axis != null ? args.axis : this.defaultAxis;
    }
    apply(w) {
      return tidy(() => {
        const norms = calcL2Norms(w, this.axis);
        const desired = clipByValue(norms, 0, this.maxValue);
        return mul(w, div(desired, add3(epsilon(), norms)));
      });
    }
    getConfig() {
      return { maxValue: this.maxValue, axis: this.axis };
    }
  };
  MaxNorm.className = "MaxNorm";
  serialization_exports.registerClass(MaxNorm);
  var UnitNorm = class extends Constraint {
    constructor(args) {
      super();
      this.defaultAxis = 0;
      this.axis = args.axis != null ? args.axis : this.defaultAxis;
    }
    apply(w) {
      return tidy(() => div(w, add3(epsilon(), calcL2Norms(w, this.axis))));
    }
    getConfig() {
      return { axis: this.axis };
    }
  };
  UnitNorm.className = "UnitNorm";
  serialization_exports.registerClass(UnitNorm);
  var NonNeg = class extends Constraint {
    apply(w) {
      return relu(w);
    }
  };
  NonNeg.className = "NonNeg";
  serialization_exports.registerClass(NonNeg);
  var MinMaxNorm = class extends Constraint {
    constructor(args) {
      super();
      this.defaultMinValue = 0;
      this.defaultMaxValue = 1;
      this.defaultRate = 1;
      this.defaultAxis = 0;
      this.minValue = args.minValue != null ? args.minValue : this.defaultMinValue;
      this.maxValue = args.maxValue != null ? args.maxValue : this.defaultMaxValue;
      this.rate = args.rate != null ? args.rate : this.defaultRate;
      this.axis = args.axis != null ? args.axis : this.defaultAxis;
    }
    apply(w) {
      return tidy(() => {
        const norms = calcL2Norms(w, this.axis);
        const desired = add3(mul(this.rate, clipByValue(norms, this.minValue, this.maxValue)), mul(1 - this.rate, norms));
        return mul(w, div(desired, add3(epsilon(), norms)));
      });
    }
    getConfig() {
      return {
        minValue: this.minValue,
        maxValue: this.maxValue,
        rate: this.rate,
        axis: this.axis
      };
    }
  };
  MinMaxNorm.className = "MinMaxNorm";
  serialization_exports.registerClass(MinMaxNorm);
  var CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP = {
    "maxNorm": "MaxNorm",
    "minMaxNorm": "MinMaxNorm",
    "nonNeg": "NonNeg",
    "unitNorm": "UnitNorm"
  };
  function serializeConstraint(constraint) {
    return serializeKerasObject(constraint);
  }
  function deserializeConstraint(config, customObjects = {}) {
    return deserializeKerasObject(config, serialization_exports.SerializationMap.getMap().classNameMap, customObjects, "constraint");
  }
  function getConstraint(identifier) {
    if (identifier == null) {
      return null;
    }
    if (typeof identifier === "string") {
      const className = identifier in CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP ? CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier] : identifier;
      const config = { className, config: {} };
      return deserializeConstraint(config);
    } else if (identifier instanceof Constraint) {
      return identifier;
    } else {
      return deserializeConstraint(identifier);
    }
  }

  // node_modules/@tensorflow/tfjs-layers/dist/keras_format/common.js
  var VALID_DATA_FORMAT_VALUES = ["channelsFirst", "channelsLast"];
  var VALID_INTERPOLATION_FORMAT_VALUES = ["nearest", "bilinear"];
  var VALID_PADDING_MODE_VALUES = ["valid", "same", "causal"];
  var VALID_POOL_MODE_VALUES = ["max", "avg"];
  var VALID_BIDIRECTIONAL_MERGE_MODES = ["sum", "mul", "concat", "ave"];

  // node_modules/@tensorflow/tfjs-layers/dist/common.js
  var nameMap = new Map();
  function checkDataFormat(value) {
    checkStringTypeUnionValue(VALID_DATA_FORMAT_VALUES, "DataFormat", value);
  }
  function checkInterpolationFormat(value) {
    checkStringTypeUnionValue(VALID_INTERPOLATION_FORMAT_VALUES, "InterpolationFormat", value);
  }
  function checkPaddingMode(value) {
    checkStringTypeUnionValue(VALID_PADDING_MODE_VALUES, "PaddingMode", value);
  }
  function checkPoolMode(value) {
    checkStringTypeUnionValue(VALID_POOL_MODE_VALUES, "PoolMode", value);
  }
  var _nameScopeStack = [];
  var _nameScopeDivider = "/";
  function nameScope(name, fn) {
    _nameScopeStack.push(name);
    try {
      const val = fn();
      _nameScopeStack.pop();
      return val;
    } catch (e) {
      _nameScopeStack.pop();
      throw e;
    }
  }
  function currentNameScopePrefix() {
    if (_nameScopeStack.length === 0) {
      return "";
    } else {
      return _nameScopeStack.join(_nameScopeDivider) + _nameScopeDivider;
    }
  }
  function getScopedTensorName(tensorName) {
    if (!isValidTensorName(tensorName)) {
      throw new Error("Not a valid tensor name: '" + tensorName + "'");
    }
    return currentNameScopePrefix() + tensorName;
  }
  function getUniqueTensorName(scopedName) {
    if (!isValidTensorName(scopedName)) {
      throw new Error("Not a valid tensor name: '" + scopedName + "'");
    }
    if (!nameMap.has(scopedName)) {
      nameMap.set(scopedName, 0);
    }
    const index = nameMap.get(scopedName);
    nameMap.set(scopedName, nameMap.get(scopedName) + 1);
    if (index > 0) {
      const result = `${scopedName}_${index}`;
      nameMap.set(result, 1);
      return result;
    } else {
      return scopedName;
    }
  }
  var tensorNameRegex = new RegExp(/^[A-Za-z0-9][-A-Za-z0-9\._\/]*$/);
  function isValidTensorName(name) {
    return !!name.match(tensorNameRegex);
  }

  // node_modules/@tensorflow/tfjs-layers/dist/utils/math_utils.js
  function isInteger(x) {
    return x === parseInt(x.toString(), 10);
  }
  function arrayProd(array2, begin, end) {
    if (begin == null) {
      begin = 0;
    }
    if (end == null) {
      end = array2.length;
    }
    let prod4 = 1;
    for (let i = begin; i < end; ++i) {
      prod4 *= array2[i];
    }
    return prod4;
  }
  function min2(array2) {
    if (array2.length === 0) {
      return Number.NaN;
    }
    let min5 = Number.POSITIVE_INFINITY;
    for (let i = 0; i < array2.length; i++) {
      const value = array2[i];
      if (value < min5) {
        min5 = value;
      }
    }
    return min5;
  }
  function max2(array2) {
    if (array2.length === 0) {
      return Number.NaN;
    }
    let max5 = Number.NEGATIVE_INFINITY;
    for (let i = 0; i < array2.length; i++) {
      const value = array2[i];
      if (value > max5) {
        max5 = value;
      }
    }
    return max5;
  }
  function range2(begin, end) {
    if (end < begin) {
      throw new ValueError(`end (${end}) < begin (${begin}) is forbidden.`);
    }
    const out = [];
    for (let i = begin; i < end; ++i) {
      out.push(i);
    }
    return out;
  }

  // node_modules/@tensorflow/tfjs-layers/dist/backend/tfjs_backend.js
  function cast2(x, dtype) {
    return cast(x, dtype);
  }
  function expandDims2(x, axis = -1) {
    const outShape = x.shape.slice();
    if (axis < 0) {
      axis = outShape.length + axis + 1;
    }
    outShape.splice(axis, 0, 1);
    return reshape(x, outShape);
  }
  function repeat(x, n) {
    return tidy(() => {
      if (x.shape.length !== 2) {
        throw new ValueError(`repeat() expects a rank-2 tensor, but received a rank-${x.shape.length} tensor.`);
      }
      const y = expandDims2(x, 1);
      return tile2(y, [1, n, 1]);
    });
  }
  function flatten2(x) {
    const newShape = [arrayProd(x.shape)];
    return reshape(x, newShape);
  }
  function batchFlatten(x) {
    if (x.rank <= 1) {
      throw new ValueError(`batchFlatten requires a minimum rank of 2. Got rank: ${x.rank}.`);
    }
    const newShape = [x.shape[0], arrayProd(x.shape, 1)];
    return reshape(x, newShape);
  }
  function sliceAlongFirstAxis(array2, start, size2) {
    return tidy(() => {
      switch (array2.rank) {
        case 1:
          return slice1d(array2, start, size2);
        case 2:
          return slice2d(array2, [start, 0], [size2, array2.shape[1]]);
        case 3:
          return slice3d(array2, [start, 0, 0], [size2, array2.shape[1], array2.shape[2]]);
        case 4:
          return slice4d(array2, [start, 0, 0, 0], [size2, array2.shape[1], array2.shape[2], array2.shape[3]]);
        case 5:
          return slice(array2, [start, 0, 0, 0, 0], [
            size2,
            array2.shape[1],
            array2.shape[2],
            array2.shape[3],
            array2.shape[4]
          ]);
        case 6:
          return slice(array2, [start, 0, 0, 0, 0, 0], [
            size2,
            array2.shape[1],
            array2.shape[2],
            array2.shape[3],
            array2.shape[4],
            array2.shape[5]
          ]);
        default:
          throw new ValueError(`sliceAlongFirstAxis() received an unsupported tensor rank: ${array2.rank}`);
      }
    });
  }
  function sliceAlongLastAxis(array2, start, size2) {
    return tidy(() => {
      switch (array2.rank) {
        case 1:
          return slice1d(array2, start, size2);
        case 2:
          return slice2d(array2, [0, start], [array2.shape[0], size2]);
        case 3:
          return slice3d(array2, [0, 0, start], [array2.shape[0], array2.shape[1], size2]);
        case 4:
          return slice4d(array2, [0, 0, 0, start], [array2.shape[0], array2.shape[1], array2.shape[2], size2]);
        default:
          throw new ValueError(`sliceAlongLastAxis() received an unsupported tensor rank: ${array2.rank}`);
      }
    });
  }
  function sliceAlongAxis(array2, start, size2, axis) {
    return tidy(() => {
      switch (array2.rank) {
        case 1:
          return slice1d(array2, start, size2);
        case 2:
          switch (axis) {
            case 1:
              return sliceAlongFirstAxis(array2, start, size2);
            case 2:
              return sliceAlongLastAxis(array2, start, size2);
            default:
              throw new ValueError(`The axis is not within the rank of the tensor ${axis}`);
          }
        case 3:
          switch (axis) {
            case 1:
              return sliceAlongFirstAxis(array2, start, size2);
            case 2:
              return slice3d(array2, [0, start, 0], [array2.shape[0], size2, array2.shape[2]]);
            case 3:
              return sliceAlongLastAxis(array2, start, size2);
            default:
              throw new ValueError(`The axis is not within the rank of the tensor ${axis}`);
          }
        case 4:
          switch (axis) {
            case 1:
              return sliceAlongFirstAxis(array2, start, size2);
            case 2:
              return slice4d(array2, [0, start, 0, 0], [array2.shape[0], size2, array2.shape[2], array2.shape[3]]);
            case 3:
              return slice4d(array2, [0, 0, start, 0], [array2.shape[0], array2.shape[1], size2, array2.shape[3]]);
            case 4:
              return sliceAlongLastAxis(array2, start, size2);
            default:
              throw new ValueError(`The axis is not within the rank of the tensor ${axis}`);
          }
        default:
          throw new ValueError(`sliceAlongLastAxis() received an unsupported tensor rank: ${array2.rank}`);
      }
    });
  }
  function concatenate(tensors, axis = -1) {
    let rank;
    if (axis < 0) {
      rank = tensors[0].rank;
      if (rank !== 0) {
        axis = rank;
      } else {
        axis = 0;
      }
    }
    if (axis === tensors[0].rank) {
      axis = -1;
    }
    return concat(tensors, axis);
  }
  function concatAlongFirstAxis(a, b) {
    switch (a.rank) {
      case 1:
        return concat1d([a, b]);
      case 2:
        return concat2d([a, b], 0);
      case 3:
        return concat3d([a, b], 0);
      case 4:
        return concat4d([a, b], 0);
      default:
        throw new ValueError(`concatAlongFirstAxis() received an unsupported tensor rank: ${a.rank}`);
    }
  }
  function tile2(x, n) {
    if (!Array.isArray(n)) {
      n = [n];
    }
    if (x.rank !== n.length) {
      throw new ValueError(`The length of input n (${n.length}) does not match the number of dimensions in input x (${x.rank})`);
    }
    return tile(x, n);
  }
  function randomNormal2(shape, mean3 = 0, stddev = 1, dtype, seed) {
    return randomNormal(shape, mean3, stddev, dtype, seed);
  }
  function dot2(a, b, activation, bias) {
    if (a.rank < 2 || b.rank < 2) {
      throw new NotImplementedError(`dot requires both inputs to be rank >= 2 but got x shape = ${a.shape} and y shape = ${b.shape}`);
    }
    if (b.rank >= 3) {
      const xLastDim = a.shape.slice(-1)[0];
      const ySecondLastDim = b.shape.slice(-2)[0];
      if (xLastDim !== ySecondLastDim) {
        throw new NotImplementedError(`If rank y >= 3, then the second last dim of y must equal the last dim of x but got x shape = ${a.shape} and  y shape = ${b.shape}`);
      }
    }
    if (a.rank === 2 && b.rank === 2) {
      const transposeA = false;
      const transposeB = false;
      return fused_ops_exports.matMul({
        a,
        b,
        transposeA,
        transposeB,
        bias: bias ? reshapeBias(a.rank, bias, imageDataFormat()) : null,
        activation
      });
    } else {
      const aFirstDims = a.shape.slice();
      const aLastDim = aFirstDims.pop();
      a = reshape(a, [-1, aLastDim]);
      const bShape = b.shape.slice();
      const bLastDim = bShape.pop();
      const ySecondLastDim = bShape.pop();
      const yOtherDims = [...bShape, bLastDim];
      const perm = Array.from({ length: b.rank }, (_, i) => {
        if (i === 0) {
          return b.rank - 2;
        } else if (i <= b.rank - 2) {
          return i - 1;
        }
        return i;
      });
      b = reshape(transpose(b, perm), [ySecondLastDim, -1]);
      const outputShape = [...aFirstDims, ...yOtherDims];
      const transposeA = false;
      const transposeB = false;
      return reshape(fused_ops_exports.matMul({
        a,
        b,
        transposeA,
        transposeB,
        bias: bias ? reshapeBias(a.rank, bias, imageDataFormat()) : null,
        activation
      }), outputShape);
    }
  }
  function gather2(reference, indices, axis) {
    return tidy(() => {
      if (Array.isArray(indices)) {
        indices = tensor1d(indices, "int32");
      } else {
        indices = cast(indices, "int32");
      }
      return gather(reference, indices, axis);
    });
  }
  function square2(x) {
    return mul(x, x);
  }
  function reshapeBias(xRank, bias, dataFormat) {
    const biasShape = bias.shape;
    if (bias.rank !== 1 && bias.rank !== xRank) {
      throw new ValueError(`Unexpected bias dimensions: ${bias.rank}; expected it to be 1 or ${xRank}`);
    }
    if (xRank === 5) {
      if (dataFormat === "channelsFirst") {
        if (biasShape.length === 1) {
          return reshape(bias, [1, biasShape[0], 1, 1, 1]);
        } else {
          return reshape(bias, [1, biasShape[3], biasShape[0], biasShape[1], biasShape[2]]);
        }
      } else if (dataFormat === "channelsLast") {
        if (biasShape.length === 1) {
          return reshape(bias, [1, 1, 1, 1, biasShape[0]]);
        } else {
          return reshape(bias, [1].concat(biasShape));
        }
      }
    } else if (xRank === 4) {
      if (dataFormat === "channelsFirst") {
        if (biasShape.length === 1) {
          return reshape(bias, [1, biasShape[0], 1, 1]);
        } else {
          return reshape(bias, [1, biasShape[2], biasShape[0], biasShape[1]]);
        }
      } else if (dataFormat === "channelsLast") {
        if (biasShape.length === 1) {
          return reshape(bias, [1, 1, 1, biasShape[0]]);
        } else {
          return reshape(bias, [1].concat(biasShape));
        }
      }
    } else if (xRank === 3) {
      if (dataFormat === "channelsFirst") {
        if (biasShape.length === 1) {
          return reshape(bias, [1, biasShape[0], 1]);
        } else {
          return reshape(bias, [1, biasShape[1], biasShape[0]]);
        }
      } else if (dataFormat === "channelsLast") {
        if (biasShape.length === 1) {
          return reshape(bias, [1, 1, biasShape[0]]);
        } else {
          return reshape(bias, [1].concat(biasShape));
        }
      }
    } else if (xRank < 3) {
      return bias;
    }
    throw new ValueError(`Unsupported input rank by biasAdd: ${bias.rank}`);
  }
  function biasAdd(x, bias, dataFormat) {
    return tidy(() => {
      if (dataFormat == null) {
        dataFormat = imageDataFormat();
      }
      checkDataFormat(dataFormat);
      return add3(x, reshapeBias(x.rank, bias, dataFormat));
    });
  }
  function elu2(x, alpha = 1) {
    if (alpha !== 1) {
      throw new NotImplementedError(`Support for alpha values other than 1 (${alpha}) is not implemented yet.`);
    }
    return elu(x);
  }
  function softsign(x) {
    return tidy(() => div(x, add3(abs(x), 1)));
  }
  function dropout2(x, level, noiseShape, seed) {
    return tidy(() => dropout(x, level, noiseShape, seed));
  }
  function hardSigmoid(x) {
    return tidy(() => {
      const y = add3(0.5, mul(0.2, x));
      return clipByValue(y, 0, 1);
    });
  }
  function inTrainPhase(x, alt, training = false) {
    return training ? x() : alt();
  }

  // node_modules/@tensorflow/tfjs-layers/dist/keras_format/initializer_config.js
  var VALID_FAN_MODE_VALUES = ["fanIn", "fanOut", "fanAvg"];
  var VALID_DISTRIBUTION_VALUES = ["normal", "uniform", "truncatedNormal"];

  // node_modules/@tensorflow/tfjs-layers/dist/initializers.js
  function checkFanMode(value) {
    checkStringTypeUnionValue(VALID_FAN_MODE_VALUES, "FanMode", value);
  }
  function checkDistribution(value) {
    checkStringTypeUnionValue(VALID_DISTRIBUTION_VALUES, "Distribution", value);
  }
  var Initializer = class extends serialization_exports.Serializable {
    fromConfigUsesCustomObjects() {
      return false;
    }
    getConfig() {
      return {};
    }
  };
  var Zeros = class extends Initializer {
    apply(shape, dtype) {
      return zeros(shape, dtype);
    }
  };
  Zeros.className = "Zeros";
  serialization_exports.registerClass(Zeros);
  var Ones = class extends Initializer {
    apply(shape, dtype) {
      return ones2(shape, dtype);
    }
  };
  Ones.className = "Ones";
  serialization_exports.registerClass(Ones);
  var Constant = class extends Initializer {
    constructor(args) {
      super();
      if (typeof args !== "object") {
        throw new ValueError(`Expected argument of type ConstantConfig but got ${args}`);
      }
      if (args.value === void 0) {
        throw new ValueError(`config must have value set but got ${args}`);
      }
      this.value = args.value;
    }
    apply(shape, dtype) {
      return tidy(() => mul(scalar(this.value), ones2(shape, dtype)));
    }
    getConfig() {
      return {
        value: this.value
      };
    }
  };
  Constant.className = "Constant";
  serialization_exports.registerClass(Constant);
  var RandomUniform = class extends Initializer {
    constructor(args) {
      super();
      this.DEFAULT_MINVAL = -0.05;
      this.DEFAULT_MAXVAL = 0.05;
      this.minval = args.minval || this.DEFAULT_MINVAL;
      this.maxval = args.maxval || this.DEFAULT_MAXVAL;
      this.seed = args.seed;
    }
    apply(shape, dtype) {
      return randomUniform(shape, this.minval, this.maxval, dtype);
    }
    getConfig() {
      return { minval: this.minval, maxval: this.maxval, seed: this.seed };
    }
  };
  RandomUniform.className = "RandomUniform";
  serialization_exports.registerClass(RandomUniform);
  var RandomNormal = class extends Initializer {
    constructor(args) {
      super();
      this.DEFAULT_MEAN = 0;
      this.DEFAULT_STDDEV = 0.05;
      this.mean = args.mean || this.DEFAULT_MEAN;
      this.stddev = args.stddev || this.DEFAULT_STDDEV;
      this.seed = args.seed;
    }
    apply(shape, dtype) {
      dtype = dtype || "float32";
      if (dtype !== "float32" && dtype !== "int32") {
        throw new NotImplementedError(`randomNormal does not support dType ${dtype}.`);
      }
      return randomNormal2(shape, this.mean, this.stddev, dtype, this.seed);
    }
    getConfig() {
      return { mean: this.mean, stddev: this.stddev, seed: this.seed };
    }
  };
  RandomNormal.className = "RandomNormal";
  serialization_exports.registerClass(RandomNormal);
  var TruncatedNormal = class extends Initializer {
    constructor(args) {
      super();
      this.DEFAULT_MEAN = 0;
      this.DEFAULT_STDDEV = 0.05;
      this.mean = args.mean || this.DEFAULT_MEAN;
      this.stddev = args.stddev || this.DEFAULT_STDDEV;
      this.seed = args.seed;
    }
    apply(shape, dtype) {
      dtype = dtype || "float32";
      if (dtype !== "float32" && dtype !== "int32") {
        throw new NotImplementedError(`truncatedNormal does not support dType ${dtype}.`);
      }
      return truncatedNormal(shape, this.mean, this.stddev, dtype, this.seed);
    }
    getConfig() {
      return { mean: this.mean, stddev: this.stddev, seed: this.seed };
    }
  };
  TruncatedNormal.className = "TruncatedNormal";
  serialization_exports.registerClass(TruncatedNormal);
  var Identity2 = class extends Initializer {
    constructor(args) {
      super();
      this.gain = args.gain != null ? args.gain : 1;
    }
    apply(shape, dtype) {
      return tidy(() => {
        if (shape.length !== 2 || shape[0] !== shape[1]) {
          throw new ValueError("Identity matrix initializer can only be used for 2D square matrices.");
        } else {
          return mul(this.gain, eye(shape[0]));
        }
      });
    }
    getConfig() {
      return { gain: this.gain };
    }
  };
  Identity2.className = "Identity";
  serialization_exports.registerClass(Identity2);
  function computeFans(shape, dataFormat = "channelsLast") {
    let fanIn;
    let fanOut;
    checkDataFormat(dataFormat);
    if (shape.length === 2) {
      fanIn = shape[0];
      fanOut = shape[1];
    } else if ([3, 4, 5].indexOf(shape.length) !== -1) {
      if (dataFormat === "channelsFirst") {
        const receptiveFieldSize = arrayProd(shape, 2);
        fanIn = shape[1] * receptiveFieldSize;
        fanOut = shape[0] * receptiveFieldSize;
      } else if (dataFormat === "channelsLast") {
        const receptiveFieldSize = arrayProd(shape, 0, shape.length - 2);
        fanIn = shape[shape.length - 2] * receptiveFieldSize;
        fanOut = shape[shape.length - 1] * receptiveFieldSize;
      }
    } else {
      const shapeProd = arrayProd(shape);
      fanIn = Math.sqrt(shapeProd);
      fanOut = Math.sqrt(shapeProd);
    }
    return [fanIn, fanOut];
  }
  var VarianceScaling = class extends Initializer {
    constructor(args) {
      super();
      if (args.scale < 0) {
        throw new ValueError(`scale must be a positive float. Got: ${args.scale}`);
      }
      this.scale = args.scale == null ? 1 : args.scale;
      this.mode = args.mode == null ? "fanIn" : args.mode;
      checkFanMode(this.mode);
      this.distribution = args.distribution == null ? "normal" : args.distribution;
      checkDistribution(this.distribution);
      this.seed = args.seed;
    }
    apply(shape, dtype) {
      const fans = computeFans(shape);
      const fanIn = fans[0];
      const fanOut = fans[1];
      let scale2 = this.scale;
      if (this.mode === "fanIn") {
        scale2 /= Math.max(1, fanIn);
      } else if (this.mode === "fanOut") {
        scale2 /= Math.max(1, fanOut);
      } else {
        scale2 /= Math.max(1, (fanIn + fanOut) / 2);
      }
      if (this.distribution === "normal") {
        const stddev = Math.sqrt(scale2);
        dtype = dtype || "float32";
        if (dtype !== "float32" && dtype !== "int32") {
          throw new NotImplementedError(`${this.getClassName()} does not support dType ${dtype}.`);
        }
        return truncatedNormal(shape, 0, stddev, dtype, this.seed);
      } else {
        const limit = Math.sqrt(3 * scale2);
        return randomUniform(shape, -limit, limit, dtype);
      }
    }
    getConfig() {
      return {
        scale: this.scale,
        mode: this.mode,
        distribution: this.distribution,
        seed: this.seed
      };
    }
  };
  VarianceScaling.className = "VarianceScaling";
  serialization_exports.registerClass(VarianceScaling);
  var GlorotUniform = class extends VarianceScaling {
    constructor(args) {
      super({
        scale: 1,
        mode: "fanAvg",
        distribution: "uniform",
        seed: args == null ? null : args.seed
      });
    }
    getClassName() {
      return VarianceScaling.className;
    }
  };
  GlorotUniform.className = "GlorotUniform";
  serialization_exports.registerClass(GlorotUniform);
  var GlorotNormal = class extends VarianceScaling {
    constructor(args) {
      super({
        scale: 1,
        mode: "fanAvg",
        distribution: "normal",
        seed: args == null ? null : args.seed
      });
    }
    getClassName() {
      return VarianceScaling.className;
    }
  };
  GlorotNormal.className = "GlorotNormal";
  serialization_exports.registerClass(GlorotNormal);
  var HeNormal = class extends VarianceScaling {
    constructor(args) {
      super({
        scale: 2,
        mode: "fanIn",
        distribution: "normal",
        seed: args == null ? null : args.seed
      });
    }
    getClassName() {
      return VarianceScaling.className;
    }
  };
  HeNormal.className = "HeNormal";
  serialization_exports.registerClass(HeNormal);
  var HeUniform = class extends VarianceScaling {
    constructor(args) {
      super({
        scale: 2,
        mode: "fanIn",
        distribution: "uniform",
        seed: args == null ? null : args.seed
      });
    }
    getClassName() {
      return VarianceScaling.className;
    }
  };
  HeUniform.className = "HeUniform";
  serialization_exports.registerClass(HeUniform);
  var LeCunNormal = class extends VarianceScaling {
    constructor(args) {
      super({
        scale: 1,
        mode: "fanIn",
        distribution: "normal",
        seed: args == null ? null : args.seed
      });
    }
    getClassName() {
      return VarianceScaling.className;
    }
  };
  LeCunNormal.className = "LeCunNormal";
  serialization_exports.registerClass(LeCunNormal);
  var LeCunUniform = class extends VarianceScaling {
    constructor(args) {
      super({
        scale: 1,
        mode: "fanIn",
        distribution: "uniform",
        seed: args == null ? null : args.seed
      });
    }
    getClassName() {
      return VarianceScaling.className;
    }
  };
  LeCunUniform.className = "LeCunNormal";
  serialization_exports.registerClass(LeCunUniform);
  var Orthogonal = class extends Initializer {
    constructor(args) {
      super();
      this.DEFAULT_GAIN = 1;
      this.gain = args.gain == null ? this.DEFAULT_GAIN : args.gain;
      this.seed = args.seed;
      if (this.seed != null) {
        throw new NotImplementedError("Random seed is not implemented for Orthogonal Initializer yet.");
      }
    }
    apply(shape, dtype) {
      return tidy(() => {
        if (shape.length < 2) {
          throw new NotImplementedError("Shape must be at least 2D.");
        }
        if (shape[0] * shape[1] > 2e3) {
          console.warn(`Orthogonal initializer is being called on a matrix with more than 2000 (${shape[0] * shape[1]}) elements: Slowness may result.`);
        }
        const normalizedShape = shape[0] > shape[1] ? [shape[1], shape[0]] : shape;
        const a = randomNormal2(normalizedShape, 0, 1, "float32");
        let q = linalg.gramSchmidt(a);
        if (shape[0] > shape[1]) {
          q = transpose(q);
        }
        return mul(this.gain, q);
      });
    }
    getConfig() {
      return {
        gain: this.gain,
        seed: this.seed
      };
    }
  };
  Orthogonal.className = "Orthogonal";
  serialization_exports.registerClass(Orthogonal);
  var INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP = {
    "constant": "Constant",
    "glorotNormal": "GlorotNormal",
    "glorotUniform": "GlorotUniform",
    "heNormal": "HeNormal",
    "heUniform": "HeUniform",
    "identity": "Identity",
    "leCunNormal": "LeCunNormal",
    "leCunUniform": "LeCunUniform",
    "ones": "Ones",
    "orthogonal": "Orthogonal",
    "randomNormal": "RandomNormal",
    "randomUniform": "RandomUniform",
    "truncatedNormal": "TruncatedNormal",
    "varianceScaling": "VarianceScaling",
    "zeros": "Zeros"
  };
  function deserializeInitializer(config, customObjects = {}) {
    return deserializeKerasObject(config, serialization_exports.SerializationMap.getMap().classNameMap, customObjects, "initializer");
  }
  function serializeInitializer(initializer) {
    return serializeKerasObject(initializer);
  }
  function getInitializer(identifier) {
    if (typeof identifier === "string") {
      const className = identifier in INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP ? INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier] : identifier;
      if (className === "GlorotNormal") {
        return new GlorotNormal();
      } else if (className === "GlorotUniform") {
        return new GlorotUniform();
      } else if (className === "HeNormal") {
        return new HeNormal();
      } else if (className === "HeUniform") {
        return new HeUniform();
      } else if (className === "LeCunNormal") {
        return new LeCunNormal();
      } else if (className === "LeCunUniform") {
        return new LeCunUniform();
      } else {
        const config = {};
        config["className"] = className;
        config["config"] = {};
        return deserializeInitializer(config);
      }
    } else if (identifier instanceof Initializer) {
      return identifier;
    } else {
      return deserializeInitializer(identifier);
    }
  }

  // node_modules/@tensorflow/tfjs-layers/dist/backend/state.js
  var _nextUniqueTensorId = 0;
  function getNextUniqueTensorId() {
    return _nextUniqueTensorId++;
  }
  var _uidPrefixes = {};
  function getUid(prefix = "") {
    if (!(prefix in _uidPrefixes)) {
      _uidPrefixes[prefix] = 0;
    }
    _uidPrefixes[prefix] += 1;
    return prefix + _uidPrefixes[prefix].toString();
  }

  // node_modules/@tensorflow/tfjs-layers/dist/utils/types_utils.js
  function isArrayOfShapes(x) {
    return Array.isArray(x) && Array.isArray(x[0]);
  }
  function normalizeShapeList(x) {
    if (x.length === 0) {
      return [];
    }
    if (!Array.isArray(x[0])) {
      return [x];
    }
    return x;
  }
  function getExactlyOneTensor(xs) {
    let x;
    if (Array.isArray(xs)) {
      if (xs.length !== 1) {
        throw new ValueError(`Expected Tensor length to be 1; got ${xs.length}`);
      }
      x = xs[0];
    } else {
      x = xs;
    }
    return x;
  }
  function getExactlyOneShape(shapes) {
    if (Array.isArray(shapes) && Array.isArray(shapes[0])) {
      if (shapes.length === 1) {
        shapes = shapes;
        return shapes[0];
      } else {
        throw new ValueError(`Expected exactly 1 Shape; got ${shapes.length}`);
      }
    } else {
      return shapes;
    }
  }

  // node_modules/@tensorflow/tfjs-layers/dist/utils/variable_utils.js
  function countParamsInWeights(weights) {
    let count2 = 0;
    for (const weight of weights) {
      if (weight.shape.length === 0) {
        count2 += 1;
      } else {
        count2 += weight.shape.reduce((a, b) => a * b);
      }
    }
    return count2;
  }

  // node_modules/@tensorflow/tfjs-layers/dist/variables.js
  var DEFAULT_VARIABLE_NAME_PREFIX = "Variable";
  var LayerVariable = class {
    constructor(val, dtype = "float32", name = DEFAULT_VARIABLE_NAME_PREFIX, trainable = true, constraint = null) {
      this.dtype = dtype == null ? "float32" : dtype;
      this.shape = val.shape;
      this.id = getNextUniqueTensorId();
      name = name == null ? DEFAULT_VARIABLE_NAME_PREFIX : name;
      this.originalName = getScopedTensorName(name);
      this.name = getUniqueTensorName(this.originalName);
      this.trainable_ = trainable;
      this.constraint = constraint;
      this.val = variable(val, this.trainable_, this.name, this.dtype);
    }
    read() {
      this.assertNotDisposed();
      return this.val;
    }
    write(newVal) {
      this.assertNotDisposed();
      checkShapesMatch(this.val, newVal);
      if (this.val.id !== newVal.id) {
        this.val.assign(newVal);
        if (this.constraint != null) {
          this.val.assign(this.constraint.apply(this.val));
        }
      }
      return this;
    }
    dispose() {
      this.assertNotDisposed();
      this.val.dispose();
    }
    assertNotDisposed() {
      if (this.val.isDisposed) {
        throw new Error(`LayersVariable ${this.name} is already disposed.`);
      }
    }
    get trainable() {
      return this.trainable_;
    }
    set trainable(trainable) {
      this.trainable_ = trainable;
      this.val.trainable = trainable;
    }
  };
  function checkShapesMatch(x, y) {
    if (x.shape.toString() !== y.shape.toString()) {
      throw new Error("Shape mismatch: " + JSON.stringify(x.shape) + " vs. " + JSON.stringify(y.shape));
    }
  }
  function batchGetValue(xs) {
    return xs.map((x) => x.read());
  }
  function batchSetValue(variablesAndValues) {
    variablesAndValues.forEach((variableAndValue) => {
      const variable2 = variableAndValue[0];
      variable2.write(variableAndValue[1]);
    });
  }

  // node_modules/@tensorflow/tfjs-layers/dist/engine/topology.js
  var InputSpec = class {
    constructor(args) {
      this.dtype = args.dtype;
      this.shape = args.shape;
      if (args.shape != null) {
        this.ndim = args.shape.length;
      } else {
        this.ndim = args.ndim;
      }
      this.maxNDim = args.maxNDim;
      this.minNDim = args.minNDim;
      this.axes = args.axes || {};
    }
  };
  var SymbolicTensor = class {
    constructor(dtype, shape, sourceLayer, inputs, callArgs, name, outputTensorIndex) {
      this.dtype = dtype;
      this.shape = shape;
      this.sourceLayer = sourceLayer;
      this.inputs = inputs;
      this.callArgs = callArgs;
      this.outputTensorIndex = outputTensorIndex;
      this.id = getNextUniqueTensorId();
      if (name != null) {
        this.originalName = getScopedTensorName(name);
        this.name = getUniqueTensorName(this.originalName);
      }
      this.rank = shape.length;
    }
  };
  var _nextNodeID = 0;
  var Node = class {
    constructor(args, callArgs) {
      this.callArgs = callArgs;
      this.id = _nextNodeID++;
      this.outboundLayer = args.outboundLayer;
      this.inboundLayers = args.inboundLayers;
      this.nodeIndices = args.nodeIndices;
      this.tensorIndices = args.tensorIndices;
      this.inputTensors = args.inputTensors;
      this.outputTensors = args.outputTensors;
      this.inputMasks = args.inputMasks;
      this.outputMasks = args.outputMasks;
      this.inputShapes = args.inputShapes;
      this.outputShapes = args.outputShapes;
      for (const layer of args.inboundLayers) {
        if (layer != null) {
          layer.outboundNodes.push(this);
        }
      }
      args.outboundLayer.inboundNodes.push(this);
    }
    getConfig() {
      const inboundNames = [];
      for (const layer of this.inboundLayers) {
        if (layer != null) {
          inboundNames.push(layer.name);
        } else {
          inboundNames.push(null);
        }
      }
      return {
        outboundLayer: this.outboundLayer ? this.outboundLayer.name : null,
        inboundLayers: inboundNames,
        nodeIndices: this.nodeIndices,
        tensorIndices: this.tensorIndices
      };
    }
  };
  var _nextLayerID = 0;
  var Layer = class extends serialization_exports.Serializable {
    constructor(args = {}) {
      super();
      this._callHook = null;
      this._addedWeightNames = [];
      this._stateful = false;
      this.id = _nextLayerID++;
      this.activityRegularizer = null;
      this.inputSpec = null;
      this.supportsMasking = false;
      this._trainableWeights = [];
      this._nonTrainableWeights = [];
      this._losses = [];
      this._updates = [];
      this._built = false;
      this.inboundNodes = [];
      this.outboundNodes = [];
      let name = args.name;
      if (!name) {
        const prefix = this.getClassName();
        name = toSnakeCase(prefix) + "_" + getUid(prefix);
      }
      this.name = name;
      this.trainable_ = args.trainable == null ? true : args.trainable;
      if (args.inputShape != null || args.batchInputShape != null) {
        let batchInputShape;
        if (args.batchInputShape != null) {
          batchInputShape = args.batchInputShape;
        } else if (args.inputShape != null) {
          let batchSize = null;
          if (args.batchSize != null) {
            batchSize = args.batchSize;
          }
          batchInputShape = [batchSize].concat(args.inputShape);
        }
        this.batchInputShape = batchInputShape;
        let dtype = args.dtype;
        if (dtype == null) {
          dtype = args.inputDType;
        }
        if (dtype == null) {
          dtype = "float32";
        }
        this.dtype = dtype;
      }
      if (args.weights != null) {
        this.initialWeights = args.weights;
      } else {
        this.initialWeights = null;
      }
      this._refCount = null;
      this.fastWeightInitDuringBuild = false;
    }
    static nodeKey(layer, nodeIndex) {
      return layer.name + "_ib-" + nodeIndex.toString();
    }
    getNodeAtIndex(nodeIndex, attrName) {
      if (this.inboundNodes.length === 0) {
        throw new RuntimeError(`The layer has never been called and thus has no defined ${attrName}.`);
      }
      if (this.inboundNodes.length <= nodeIndex) {
        throw new ValueError(`Asked to get ${attrName} at node ${nodeIndex}, but the layer has only ${this.inboundNodes.length} inbound nodes.`);
      }
      return this.inboundNodes[nodeIndex];
    }
    getInputAt(nodeIndex) {
      return singletonOrArray(this.getNodeAtIndex(nodeIndex, "input").inputTensors);
    }
    getOutputAt(nodeIndex) {
      return singletonOrArray(this.getNodeAtIndex(nodeIndex, "output").outputTensors);
    }
    get input() {
      if (this.inboundNodes.length > 1) {
        throw new AttributeError(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer input" is ill-defined. Use \`getInputAt(nodeIndex)\` instead.`);
      } else if (this.inboundNodes.length === 0) {
        throw new AttributeError(`Layer ${this.name} is not connected, no input to return.`);
      }
      return singletonOrArray(this.getNodeAtIndex(0, "input").inputTensors);
    }
    get output() {
      if (this.inboundNodes.length === 0) {
        throw new AttributeError(`Layer ${this.name} has no inbound nodes.`);
      }
      if (this.inboundNodes.length > 1) {
        throw new AttributeError(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer output" is ill-defined. Use \`getOutputAt(nodeIndex)\` instead.`);
      }
      return singletonOrArray(this.getNodeAtIndex(0, "output").outputTensors);
    }
    get losses() {
      return this._losses;
    }
    calculateLosses() {
      return this.losses.map((lossFn) => lossFn());
    }
    get updates() {
      return this._updates;
    }
    get built() {
      return this._built;
    }
    set built(built) {
      this._built = built;
    }
    get trainable() {
      return this.trainable_;
    }
    set trainable(trainable) {
      this._trainableWeights.forEach((w) => w.trainable = trainable);
      this.trainable_ = trainable;
    }
    get trainableWeights() {
      if (this.trainable_) {
        return this._trainableWeights.filter((w) => w.trainable);
      } else {
        return [];
      }
    }
    set trainableWeights(weights) {
      this._trainableWeights = weights;
    }
    get nonTrainableWeights() {
      if (this.trainable) {
        return this._trainableWeights.filter((w) => !w.trainable).concat(this._nonTrainableWeights);
      } else {
        return this._trainableWeights.concat(this._nonTrainableWeights);
      }
    }
    set nonTrainableWeights(weights) {
      this._nonTrainableWeights = weights;
    }
    get weights() {
      return this.trainableWeights.concat(this.nonTrainableWeights);
    }
    get stateful() {
      return this._stateful;
    }
    resetStates() {
      if (!this.stateful) {
        throw new Error("Cannot call the resetStates() method of a non-stateful Layer object.");
      }
    }
    assertInputCompatibility(inputs) {
      inputs = toList(inputs);
      if (this.inputSpec == null || this.inputSpec.length === 0) {
        return;
      }
      const inputSpec = toList(this.inputSpec);
      if (inputs.length !== inputSpec.length) {
        throw new ValueError(`Layer ${this.name} expects ${inputSpec.length} inputs, but it received ${inputs.length} input tensors. Input received: ${inputs}`);
      }
      for (let inputIndex = 0; inputIndex < inputs.length; inputIndex++) {
        const x = inputs[inputIndex];
        const spec = inputSpec[inputIndex];
        if (spec == null) {
          continue;
        }
        const ndim = x.rank;
        if (spec.ndim != null) {
          if (ndim !== spec.ndim) {
            throw new ValueError(`Input ${inputIndex} is incompatible with layer ${this.name}: expected ndim=${spec.ndim}, found ndim=${ndim}`);
          }
        }
        if (spec.maxNDim != null) {
          if (ndim > spec.maxNDim) {
            throw new ValueError(`Input ${inputIndex} is incompatible with layer ${this.name}: expected max_ndim=${spec.maxNDim}, found ndim=${ndim}`);
          }
        }
        if (spec.minNDim != null) {
          if (ndim < spec.minNDim) {
            throw new ValueError(`Input ${inputIndex} is incompatible with layer ${this.name}: expected min_ndim=${spec.minNDim}, found ndim=${ndim}.`);
          }
        }
        if (spec.dtype != null) {
          if (x.dtype !== spec.dtype) {
            throw new ValueError(`Input ${inputIndex} is incompatible with layer ${this.name} : expected dtype=${spec.dtype}, found dtype=${x.dtype}.`);
          }
        }
        if (spec.axes) {
          const xShape = x.shape;
          for (const key in spec.axes) {
            const axis = Number(key);
            const value = spec.axes[key];
            const xShapeAtAxis = axis >= 0 ? xShape[axis] : xShape[xShape.length + axis];
            if (value != null && [value, null].indexOf(xShapeAtAxis) === -1) {
              throw new ValueError(`Input ${inputIndex} is incompatible with layer ${this.name}: expected axis ${axis} of input shape to have value ${value} but got shape ${xShape}.`);
            }
          }
        }
        if (spec.shape != null) {
          for (let i = 0; i < spec.shape.length; ++i) {
            const specDim = spec.shape[i];
            const dim = x.shape[i];
            if (specDim != null && dim != null) {
              if (specDim !== dim) {
                throw new ValueError(`Input ${inputIndex} is incompatible with layer ${this.name}: expected shape=${spec.shape}, found shape=${x.shape}.`);
              }
            }
          }
        }
      }
    }
    call(inputs, kwargs) {
      return inputs;
    }
    invokeCallHook(inputs, kwargs) {
      if (this._callHook != null) {
        this._callHook(inputs, kwargs);
      }
    }
    setCallHook(callHook3) {
      this._callHook = callHook3;
    }
    clearCallHook() {
      this._callHook = null;
    }
    apply(inputs, kwargs) {
      kwargs = kwargs || {};
      this.assertNotDisposed();
      const inputsList = toList(inputs);
      let allAreSymbolic = true;
      for (const input2 of inputsList) {
        if (!(input2 instanceof SymbolicTensor)) {
          allAreSymbolic = false;
          break;
        }
      }
      let noneAreSymbolic = true;
      for (const input2 of inputsList) {
        if (input2 instanceof SymbolicTensor) {
          noneAreSymbolic = false;
          break;
        }
      }
      if (allAreSymbolic === noneAreSymbolic) {
        throw new ValueError("Arguments to apply() must be all SymbolicTensors or all Tensors");
      }
      return nameScope(this.name, () => {
        if (!this.built) {
          this.assertInputCompatibility(inputs);
          const inputShapes = [];
          for (const xElem of toList(inputs)) {
            inputShapes.push(xElem.shape);
          }
          this.build(singletonOrArray(inputShapes));
          this.built = true;
          if (this.initialWeights) {
            this.setWeights(this.initialWeights);
          }
          if (this._refCount === null && noneAreSymbolic) {
            this._refCount = 1;
          }
        }
        this.assertInputCompatibility(inputs);
        if (noneAreSymbolic) {
          let output = this.call(inputs, kwargs);
          const outputList = toList(output);
          const outputListCopy = [];
          for (let x of outputList) {
            if (inputsList.indexOf(x) !== -1) {
              x = x.clone();
            }
            outputListCopy.push(x);
          }
          output = singletonOrArray(outputListCopy);
          if (this.activityRegularizer != null) {
            throw new NotImplementedError("Layer invocation in the presence of activity regularizer(s) is not supported yet.");
          }
          return output;
        } else {
          const inputShape = collectInputShape(inputs);
          const outputShape = this.computeOutputShape(inputShape);
          let output;
          const outputDType = guessOutputDType(inputs);
          this.warnOnIncompatibleInputShape(Array.isArray(inputs) ? inputShape[0] : inputShape);
          if (outputShape != null && outputShape.length > 0 && Array.isArray(outputShape[0])) {
            output = outputShape.map((shape, index) => new SymbolicTensor(outputDType, shape, this, toList(inputs), kwargs, this.name, index));
          } else {
            output = new SymbolicTensor(outputDType, outputShape, this, toList(inputs), kwargs, this.name);
          }
          this.addInboundNode(inputs, output, null, null, inputShape, outputShape, kwargs);
          this._refCount++;
          if (this.activityRegularizer != null) {
            throw new NotImplementedError("Layer invocation in the presence of activity regularizer(s) is not supported yet.");
          }
          return output;
        }
      });
    }
    warnOnIncompatibleInputShape(inputShape) {
      if (this.batchInputShape == null) {
        return;
      } else if (inputShape.length !== this.batchInputShape.length) {
        console.warn(`The rank of the input tensor provided (shape: ${JSON.stringify(inputShape)}) does not match that of the batchInputShape (${JSON.stringify(this.batchInputShape)}) of the layer ${this.name}`);
      } else {
        let dimMismatch = false;
        this.batchInputShape.forEach((dimension, i) => {
          if (dimension != null && inputShape[i] != null && inputShape[i] !== dimension) {
            dimMismatch = true;
          }
        });
        if (dimMismatch) {
          console.warn(`The shape of the input tensor (${JSON.stringify(inputShape)}) does not match the expectation of layer ${this.name}: ${JSON.stringify(this.batchInputShape)}`);
        }
      }
    }
    get outputShape() {
      if (this.inboundNodes == null || this.inboundNodes.length === 0) {
        throw new AttributeError(`The layer ${this.name} has never been called and thus has no defined output shape.`);
      }
      const allOutputShapes = [];
      for (const node of this.inboundNodes) {
        const shapeString = JSON.stringify(node.outputShapes);
        if (allOutputShapes.indexOf(shapeString) === -1) {
          allOutputShapes.push(shapeString);
        }
      }
      if (allOutputShapes.length === 1) {
        const outputShapes = this.inboundNodes[0].outputShapes;
        if (Array.isArray(outputShapes) && Array.isArray(outputShapes[0]) && outputShapes.length === 1) {
          return outputShapes[0];
        } else {
          return outputShapes;
        }
      } else {
        throw new AttributeError(`The layer ${this.name} has multiple inbound nodes with different output shapes. Hence the notion of "output shape" is ill-defined for the layer.`);
      }
    }
    countParams() {
      if (!this.built) {
        throw new RuntimeError(`You tried to call countParams() on ${this.name}, but the layer is not built yet. Build it first by calling build(batchInputShape).`);
      }
      return countParamsInWeights(this.weights);
    }
    build(inputShape) {
      this.built = true;
    }
    getWeights(trainableOnly = false) {
      return batchGetValue(trainableOnly ? this.trainableWeights : this.weights);
    }
    setWeights(weights) {
      tidy(() => {
        const params = this.weights;
        if (params.length !== weights.length) {
          throw new ValueError(`You called setWeights(weights) on layer "${this.name}" with a weight list of length ${weights.length}, but the layer was expecting ${params.length} weights. Provided weights: ${weights}...`);
        }
        if (params.length === 0) {
          return;
        }
        const weightValueTuples = [];
        const paramValues = batchGetValue(params);
        for (let i = 0; i < paramValues.length; ++i) {
          const pv = paramValues[i];
          const p3 = params[i];
          const w = weights[i];
          if (!util_exports.arraysEqual(pv.shape, w.shape)) {
            throw new ValueError(`Layer weight shape ${pv.shape} not compatible with provided weight shape ${w.shape}`);
          }
          weightValueTuples.push([p3, w]);
        }
        batchSetValue(weightValueTuples);
      });
    }
    addWeight(name, shape, dtype, initializer, regularizer, trainable, constraint, getInitializerFunc) {
      if (this._addedWeightNames.indexOf(name) !== -1) {
        throw new ValueError(`Duplicate weight name ${name} for layer ${this.name}`);
      }
      this._addedWeightNames.push(name);
      if (dtype == null) {
        dtype = "float32";
      }
      if (this.fastWeightInitDuringBuild) {
        initializer = getInitializerFunc != null ? getInitializerFunc() : getInitializer("zeros");
      }
      const initValue = initializer.apply(shape, dtype);
      const weight = new LayerVariable(initValue, dtype, name, trainable, constraint);
      initValue.dispose();
      if (regularizer != null) {
        this.addLoss(() => regularizer.apply(weight.read()));
      }
      if (trainable == null) {
        trainable = true;
      }
      if (trainable) {
        this._trainableWeights.push(weight);
      } else {
        this._nonTrainableWeights.push(weight);
      }
      return weight;
    }
    setFastWeightInitDuringBuild(value) {
      this.fastWeightInitDuringBuild = value;
    }
    addLoss(losses3) {
      if (losses3 == null || Array.isArray(losses3) && losses3.length === 0) {
        return;
      }
      losses3 = toList(losses3);
      if (this._losses !== void 0 && this._losses !== null) {
        this.losses.push(...losses3);
      }
    }
    computeOutputShape(inputShape) {
      return inputShape;
    }
    computeMask(inputs, mask) {
      if (!this.supportsMasking) {
        if (mask != null) {
          if (Array.isArray(mask)) {
            mask.forEach((maskElement) => {
              if (maskElement != null) {
                throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);
              }
            });
          } else {
            throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);
          }
        }
        return null;
      }
      return mask;
    }
    addInboundNode(inputTensors, outputTensors, inputMasks, outputMasks, inputShapes, outputShapes, kwargs = null) {
      const inputTensorList = toList(inputTensors);
      outputTensors = toList(outputTensors);
      inputMasks = toList(inputMasks);
      outputMasks = toList(outputMasks);
      inputShapes = normalizeShapeList(inputShapes);
      outputShapes = normalizeShapeList(outputShapes);
      const inboundLayers = [];
      const nodeIndices = [];
      const tensorIndices = [];
      for (const x of inputTensorList) {
        inboundLayers.push(x.sourceLayer);
        nodeIndices.push(x.nodeIndex);
        tensorIndices.push(x.tensorIndex);
      }
      new Node({
        outboundLayer: this,
        inboundLayers,
        nodeIndices,
        tensorIndices,
        inputTensors: inputTensorList,
        outputTensors,
        inputMasks,
        outputMasks,
        inputShapes,
        outputShapes
      }, kwargs);
      for (let i = 0; i < outputTensors.length; i++) {
        outputTensors[i].sourceLayer = this;
        outputTensors[i].nodeIndex = this.inboundNodes.length - 1;
        outputTensors[i].tensorIndex = i;
      }
    }
    getConfig() {
      const config = { name: this.name, trainable: this.trainable };
      if (this.batchInputShape != null) {
        config["batchInputShape"] = this.batchInputShape;
      }
      if (this.dtype != null) {
        config["dtype"] = this.dtype;
      }
      return config;
    }
    disposeWeights() {
      this.weights.forEach((weight) => weight.dispose());
      return this.weights.length;
    }
    assertNotDisposed() {
      if (this._refCount === 0) {
        throw new Error(`Layer '${this.name}' is already disposed.`);
      }
    }
    dispose() {
      if (!this.built) {
        throw new Error(`Cannot dispose Layer ${this.name} because it has not been built yet.`);
      }
      if (this._refCount === null) {
        throw new Error(`Cannot dispose Layer ${this.name} because it has not been used yet.`);
      }
      this.assertNotDisposed();
      let numDisposedVariables = 0;
      if (--this._refCount === 0) {
        numDisposedVariables = this.disposeWeights();
      }
      return { refCountAfterDispose: this._refCount, numDisposedVariables };
    }
  };
  function collectInputShape(inputTensors) {
    inputTensors = toList(inputTensors);
    const shapes = [];
    for (const x of inputTensors) {
      shapes.push(x.shape);
    }
    return singletonOrArray(shapes);
  }
  function guessOutputDType(inputTensors) {
    return "float32";
  }
  function getSourceInputs(tensor2, layer, nodeIndex) {
    if (layer == null || nodeIndex != null && nodeIndex > 0) {
      layer = tensor2.sourceLayer;
      nodeIndex = tensor2.nodeIndex;
    }
    if (layer.inboundNodes.length === 0) {
      return [tensor2];
    } else {
      const node = layer.inboundNodes[nodeIndex];
      if (node.inboundLayers.length === 0) {
        return node.inputTensors;
      } else {
        const sourceTensors = [];
        for (let i = 0; i < node.inboundLayers.length; i++) {
          const x = node.inputTensors[i];
          const layer2 = node.inboundLayers[i];
          const nodeIndex2 = node.nodeIndices[i];
          const previousSources = getSourceInputs(x, layer2, nodeIndex2);
          for (const x2 of previousSources) {
            if (sourceTensors.indexOf(x2) === -1) {
              sourceTensors.push(x2);
            }
          }
        }
        return sourceTensors;
      }
    }
  }

  // node_modules/@tensorflow/tfjs-layers/dist/engine/input_layer.js
  var InputLayer = class extends Layer {
    constructor(args) {
      super({
        dtype: args.dtype,
        name: args.name != null ? args.name : getUid("input").toString()
      });
      if (args.batchSize == null) {
        args.batchSize = null;
      }
      if (args.sparse == null) {
        args.sparse = false;
      }
      this.trainable = false;
      this.built = true;
      this.sparse = args.sparse;
      if (args.inputShape != null && args.batchInputShape != null) {
        throw new ValueError("Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.");
      }
      let batchInputShape = args.batchInputShape;
      if (batchInputShape == null) {
        if (args.inputShape == null) {
          throw new ValueError("An InputLayer should be passed either a `batchInputShape` or an `inputShape`.");
        } else {
          batchInputShape = [args.batchSize].concat(args.inputShape);
        }
      } else {
        if (args.batchSize != null) {
          throw new ValueError("Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.");
        }
      }
      const dtype = args.dtype || "float32";
      this.batchInputShape = batchInputShape;
      this.dtype = dtype;
      this.inputSpec = [{ shape: batchInputShape }];
      const inputTensor = new SymbolicTensor(this.dtype, this.batchInputShape, this, [], {}, this.name);
      inputTensor.nodeIndex = 0;
      inputTensor.tensorIndex = 0;
      new Node({
        outboundLayer: this,
        inboundLayers: [],
        nodeIndices: [],
        tensorIndices: [],
        inputTensors: [inputTensor],
        outputTensors: [inputTensor],
        inputMasks: [null],
        outputMasks: [null],
        inputShapes: [batchInputShape],
        outputShapes: [batchInputShape]
      });
    }
    apply(inputs, kwargs) {
      throw new ValueError(`Cannot pass any input to an InputLayer's apply() method. InputLayer name: ${this.name}`);
    }
    dispose() {
      return { refCountAfterDispose: this._refCount, numDisposedVariables: 0 };
    }
    getConfig() {
      return {
        batchInputShape: this.batchInputShape,
        dtype: this.dtype,
        sparse: this.sparse,
        name: this.name
      };
    }
  };
  InputLayer.className = "InputLayer";
  serialization_exports.registerClass(InputLayer);
  function Input(config) {
    if (config.batchShape == null && config.shape == null) {
      throw new Error("Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.");
    }
    if (config.batchShape != null && config.shape != null) {
      throw new ValueError("Please provide either a `shape` or `batchShape` argument to Input, but not both.");
    }
    let batchShape = config.batchShape;
    if (config.shape != null && batchShape == null) {
      batchShape = [null].concat(config.shape);
    }
    let dtype = config.dtype;
    if (dtype == null) {
      dtype = "float32";
    }
    const inputLayer = new InputLayer({
      batchInputShape: batchShape,
      name: config.name,
      dtype,
      sparse: config.sparse
    });
    const outputs = inputLayer.inboundNodes[0].outputTensors;
    return outputs[0];
  }

  // node_modules/@tensorflow/tfjs-layers/dist/logs.js
  async function resolveScalarsInLogs(logs) {
    if (logs == null) {
      return;
    }
    const promises = [];
    const keys = [];
    const scalarsToDispose = [];
    for (const key in logs) {
      const value = logs[key];
      if (typeof value !== "number") {
        const valueScalar = value;
        promises.push(valueScalar.data());
        keys.push(key);
        scalarsToDispose.push(valueScalar);
      }
    }
    if (promises.length > 0) {
      const values = await Promise.all(promises);
      for (let i = 0; i < values.length; ++i) {
        logs[keys[i]] = values[i][0];
      }
      dispose(scalarsToDispose);
    }
  }
  function disposeTensorsInLogs(logs) {
    if (logs == null) {
      return;
    }
    for (const key in logs) {
      const value = logs[key];
      if (typeof value !== "number") {
        value.dispose();
      }
    }
  }

  // node_modules/@tensorflow/tfjs-layers/dist/base_callbacks.js
  var ModelLoggingVerbosity;
  (function(ModelLoggingVerbosity2) {
    ModelLoggingVerbosity2[ModelLoggingVerbosity2["SILENT"] = 0] = "SILENT";
    ModelLoggingVerbosity2[ModelLoggingVerbosity2["VERBOSE"] = 1] = "VERBOSE";
  })(ModelLoggingVerbosity || (ModelLoggingVerbosity = {}));
  var DEFAULT_YIELD_EVERY_MS = 125;
  var BaseCallback = class {
    constructor() {
      this.validationData = null;
    }
    setParams(params) {
      this.params = params;
    }
    async onEpochBegin(epoch, logs) {
    }
    async onEpochEnd(epoch, logs) {
    }
    async onBatchBegin(batch, logs) {
    }
    async onBatchEnd(batch, logs) {
    }
    async onTrainBegin(logs) {
    }
    async onTrainEnd(logs) {
    }
    setModel(model2) {
    }
  };
  var CallbackList = class {
    constructor(callbacks2, queueLength = 10) {
      if (callbacks2 == null) {
        callbacks2 = [];
      }
      this.callbacks = callbacks2;
      this.queueLength = queueLength;
    }
    append(callback) {
      this.callbacks.push(callback);
    }
    setParams(params) {
      for (const callback of this.callbacks) {
        callback.setParams(params);
      }
    }
    setModel(model2) {
      for (const callback of this.callbacks) {
        callback.setModel(model2);
      }
    }
    async onEpochBegin(epoch, logs) {
      if (logs == null) {
        logs = {};
      }
      for (const callback of this.callbacks) {
        await callback.onEpochBegin(epoch, logs);
      }
    }
    async onEpochEnd(epoch, logs) {
      if (logs == null) {
        logs = {};
      }
      for (const callback of this.callbacks) {
        await callback.onEpochEnd(epoch, logs);
      }
    }
    async onBatchBegin(batch, logs) {
      if (logs == null) {
        logs = {};
      }
      for (const callback of this.callbacks) {
        await callback.onBatchBegin(batch, logs);
      }
    }
    async onBatchEnd(batch, logs) {
      if (logs == null) {
        logs = {};
      }
      for (const callback of this.callbacks) {
        await callback.onBatchEnd(batch, logs);
      }
    }
    async onTrainBegin(logs) {
      if (logs == null) {
        logs = {};
      }
      for (const callback of this.callbacks) {
        await callback.onTrainBegin(logs);
      }
    }
    async onTrainEnd(logs) {
      if (logs == null) {
        logs = {};
      }
      for (const callback of this.callbacks) {
        await callback.onTrainEnd(logs);
      }
    }
  };
  var BaseLogger = class extends BaseCallback {
    constructor() {
      super();
    }
    async onEpochBegin(epoch) {
      this.seen = 0;
      this.totals = {};
    }
    async onBatchEnd(batch, logs) {
      if (logs == null) {
        logs = {};
      }
      const batchSize = logs["size"] == null ? 0 : logs["size"];
      this.seen += batchSize;
      for (const key in logs) {
        const value = logs[key];
        if (typeof value === "number") {
          if (!this.totals.hasOwnProperty(key)) {
            this.totals[key] = 0;
          }
          this.totals[key] = this.totals[key] + value * batchSize;
        } else {
          let oldTotalsToDispose;
          if (key in this.totals) {
            oldTotalsToDispose = this.totals[key];
          } else {
            this.totals[key] = 0;
          }
          const total = tidy(() => add3(this.totals[key], mul(value, batchSize)));
          this.totals[key] = total;
          if (oldTotalsToDispose != null) {
            oldTotalsToDispose.dispose();
          }
        }
      }
    }
    async onEpochEnd(epoch, logs) {
      if (logs != null) {
        for (const key of this.params["metrics"]) {
          if (this.totals[key] == null) {
            continue;
          }
          if (typeof this.totals[key] === "number") {
            logs[key] = this.totals[key] / this.seen;
          } else {
            tidy(() => {
              const log8 = mul(div(1, this.seen), this.totals[key]);
              logs[key] = log8;
              this.totals[key].dispose();
              keep(logs[key]);
            });
          }
        }
      }
    }
  };
  var History = class extends BaseCallback {
    async onTrainBegin(logs) {
      this.epoch = [];
      this.history = {};
    }
    async onEpochEnd(epoch, logs) {
      if (logs == null) {
        logs = {};
      }
      this.epoch.push(epoch);
      for (const key in logs) {
        if (this.history[key] == null) {
          this.history[key] = [];
        }
        this.history[key].push(logs[key]);
      }
    }
    async syncData() {
      const promises = [];
      const keys = [];
      const indices = [];
      for (const key in this.history) {
        const valueArray = this.history[key];
        for (let i = 0; i < valueArray.length; ++i) {
          if (typeof valueArray[i] !== "number") {
            const valueScalar = valueArray[i];
            promises.push(valueScalar.data());
            keys.push(key);
            indices.push(i);
          }
        }
      }
      const values = await Promise.all(promises);
      for (let n = 0; n < values.length; ++n) {
        const tensorToDispose = this.history[keys[n]][indices[n]];
        tensorToDispose.dispose();
        this.history[keys[n]][indices[n]] = values[n][0];
      }
    }
  };
  var CustomCallback = class extends BaseCallback {
    constructor(args, yieldEvery) {
      super();
      this.currentEpoch = 0;
      this.nowFunc = args.nowFunc;
      this.nextFrameFunc = args.nextFrameFunc || nextFrame2;
      this.yieldEvery = yieldEvery || "auto";
      if (this.yieldEvery === "auto") {
        this.yieldEvery = DEFAULT_YIELD_EVERY_MS;
      }
      if (this.yieldEvery === "never" && args.onYield != null) {
        throw new Error("yieldEvery is `never` but you provided an `onYield` callback. Either change `yieldEvery` or remove the callback");
      }
      if (util_exports.isNumber(this.yieldEvery)) {
        this.maybeWait = debounce(this.maybeWait.bind(this), this.yieldEvery, this.nowFunc);
      }
      this.trainBegin = args.onTrainBegin;
      this.trainEnd = args.onTrainEnd;
      this.epochBegin = args.onEpochBegin;
      this.epochEnd = args.onEpochEnd;
      this.batchBegin = args.onBatchBegin;
      this.batchEnd = args.onBatchEnd;
      this.yield = args.onYield;
    }
    async maybeWait(epoch, batch, logs) {
      const ps = [];
      if (this.yield != null) {
        await resolveScalarsInLogs(logs);
        ps.push(this.yield(epoch, batch, logs));
      }
      ps.push(this.nextFrameFunc());
      await Promise.all(ps);
    }
    async onEpochBegin(epoch, logs) {
      this.currentEpoch = epoch;
      if (this.epochBegin != null) {
        await resolveScalarsInLogs(logs);
        await this.epochBegin(epoch, logs);
      }
    }
    async onEpochEnd(epoch, logs) {
      const ps = [];
      if (this.epochEnd != null) {
        await resolveScalarsInLogs(logs);
        ps.push(this.epochEnd(epoch, logs));
      }
      if (this.yieldEvery === "epoch") {
        ps.push(this.nextFrameFunc());
      }
      await Promise.all(ps);
    }
    async onBatchBegin(batch, logs) {
      if (this.batchBegin != null) {
        await resolveScalarsInLogs(logs);
        await this.batchBegin(batch, logs);
      }
    }
    async onBatchEnd(batch, logs) {
      const ps = [];
      if (this.batchEnd != null) {
        await resolveScalarsInLogs(logs);
        ps.push(this.batchEnd(batch, logs));
      }
      if (this.yieldEvery === "batch") {
        ps.push(this.nextFrameFunc());
      } else if (util_exports.isNumber(this.yieldEvery)) {
        ps.push(this.maybeWait(this.currentEpoch, batch, logs));
      }
      await Promise.all(ps);
    }
    async onTrainBegin(logs) {
      if (this.trainBegin != null) {
        await resolveScalarsInLogs(logs);
        await this.trainBegin(logs);
      }
    }
    async onTrainEnd(logs) {
      if (this.trainEnd != null) {
        await resolveScalarsInLogs(logs);
        await this.trainEnd(logs);
      }
    }
  };
  function standardizeCallbacks(callbacks2, yieldEvery) {
    if (callbacks2 == null) {
      callbacks2 = {};
    }
    if (callbacks2 instanceof BaseCallback) {
      return [callbacks2];
    }
    if (Array.isArray(callbacks2) && callbacks2[0] instanceof BaseCallback) {
      return callbacks2;
    }
    const callbackConfigs = toList(callbacks2);
    return callbackConfigs.map((callbackConfig) => new CustomCallback(callbackConfig, yieldEvery));
  }
  var CallbackConstructorRegistry = class {
    constructor() {
    }
    static registerCallbackConstructor(verbosityLevel, callbackConstructor) {
      util_exports.assert(verbosityLevel >= 0 && Number.isInteger(verbosityLevel), () => `Verbosity level is expected to be an integer >= 0, but got ${verbosityLevel}`);
      CallbackConstructorRegistry.checkForDuplicate(callbackConstructor);
      if (CallbackConstructorRegistry.constructors[verbosityLevel] == null) {
        CallbackConstructorRegistry.constructors[verbosityLevel] = [];
      }
      CallbackConstructorRegistry.constructors[verbosityLevel].push(callbackConstructor);
    }
    static checkForDuplicate(callbackConstructor) {
      for (const levelName in CallbackConstructorRegistry.constructors) {
        const constructors = CallbackConstructorRegistry.constructors[+levelName];
        constructors.forEach((ctor) => {
          if (ctor === callbackConstructor) {
            throw new ValueError("Duplicate callback constructor.");
          }
        });
      }
    }
    static clear() {
      CallbackConstructorRegistry.constructors = {};
    }
    static createCallbacks(verbosityLevel) {
      const constructors = [];
      for (const levelName in CallbackConstructorRegistry.constructors) {
        const level = +levelName;
        if (verbosityLevel >= level) {
          constructors.push(...CallbackConstructorRegistry.constructors[level]);
        }
      }
      return constructors.map((ctor) => new ctor());
    }
  };
  CallbackConstructorRegistry.constructors = {};
  function configureCallbacks(callbacks2, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics) {
    const history = new History();
    const actualCallbacks = [
      new BaseLogger(),
      ...CallbackConstructorRegistry.createCallbacks(verbose)
    ];
    if (callbacks2 != null) {
      actualCallbacks.push(...callbacks2);
    }
    actualCallbacks.push(history);
    const callbackList = new CallbackList(actualCallbacks);
    callbackList.setParams({
      epochs,
      initialEpoch,
      samples: numTrainSamples,
      steps: stepsPerEpoch,
      batchSize,
      verbose,
      doValidation,
      metrics: callbackMetrics
    });
    return { callbackList, history };
  }

  // node_modules/@tensorflow/tfjs-layers/dist/layers/serialization.js
  function deserialize(config, customObjects = {}, fastWeightInit = false) {
    return deserializeKerasObject(config, serialization_exports.SerializationMap.getMap().classNameMap, customObjects, "layer", fastWeightInit);
  }

  // node_modules/@tensorflow/tfjs-layers/dist/losses.js
  function l2Normalize(x, axis) {
    return tidy(() => {
      if (x.dtype !== "float32") {
        x = cast(x, "float32");
      }
      const squareSum = sum2(square2(x), axis, true);
      const epsilonTensor = fill(squareSum.shape, epsilon());
      const norm2 = sqrt(maximum(squareSum, epsilonTensor));
      return div(x, norm2);
    });
  }
  function meanSquaredError(yTrue, yPred) {
    return tidy(() => mean(square2(sub(yPred, yTrue)), -1));
  }
  function meanAbsoluteError(yTrue, yPred) {
    return tidy(() => mean(abs(sub(yPred, yTrue)), -1));
  }
  function meanAbsolutePercentageError(yTrue, yPred) {
    return tidy(() => {
      const diff = sub(yTrue, yPred);
      const clippedTrue = clipByValue(abs(yTrue), epsilon(), Number.MAX_VALUE);
      const absResult = abs(div(diff, clippedTrue));
      return mul(100, mean(absResult, -1));
    });
  }
  function meanSquaredLogarithmicError(yTrue, yPred) {
    return tidy(() => {
      const clippedPred = clipByValue(yPred, epsilon(), Number.MAX_VALUE);
      const firstLog = log5(add3(1, clippedPred));
      const clippedTrue = clipByValue(yTrue, epsilon(), Number.MAX_VALUE);
      const secondLog = log5(add3(1, clippedTrue));
      return mean(square2(sub(firstLog, secondLog)), -1);
    });
  }
  function squaredHinge(yTrue, yPred) {
    return tidy(() => {
      const maxResult = maximum(0, sub(1, mul(yTrue, yPred)));
      return mean(square2(maxResult), -1);
    });
  }
  function hinge(yTrue, yPred) {
    return tidy(() => {
      const maxResult = maximum(0, sub(1, mul(yTrue, yPred)));
      return mean(maxResult, -1);
    });
  }
  function categoricalHinge(yTrue, yPred) {
    return tidy(() => {
      const pos = sum2(mul(yTrue, yPred), -1);
      const neg4 = max(mul(sub(1, yTrue), yPred), -1);
      return maximum(0, add3(1, sub(neg4, pos)));
    });
  }
  function logcosh(yTrue, yPred) {
    return tidy(() => {
      const log22 = Math.log(2);
      const predictionDiff = sub(yPred, yTrue);
      const logcoshResult = sub(add3(predictionDiff, softplus(mul(-2, predictionDiff))), log22);
      return mean(logcoshResult, -1);
    });
  }
  function categoricalCrossentropy(target, output, fromLogits = false) {
    return tidy(() => {
      if (fromLogits) {
        output = softmax(output);
      } else {
        const outputSum = sum2(output, output.shape.length - 1, true);
        output = div(output, outputSum);
      }
      output = clipByValue(output, epsilon(), 1 - epsilon());
      return neg(sum2(mul(cast(target, "float32"), log5(output)), output.shape.length - 1));
    });
  }
  function sparseCategoricalCrossentropy(target, output, fromLogits = false) {
    return tidy(() => {
      const flatTarget = cast(floor(flatten2(target)), "int32");
      output = clipByValue(output, epsilon(), 1 - epsilon());
      const outputShape = output.shape;
      const oneHotTarget = reshape(oneHot(flatTarget, outputShape[outputShape.length - 1]), outputShape);
      return categoricalCrossentropy(oneHotTarget, output, fromLogits);
    });
  }
  function sigmoidCrossEntropyWithLogits(labels, logits) {
    if (!util_exports.arraysEqual(labels.shape, logits.shape)) {
      throw new ValueError(`logits and labels must have the same shape, but got shapes ${JSON.stringify(labels.shape)} and ${JSON.stringify(logits.shape)}`);
    }
    return tidy(() => {
      const reluLogits = relu(logits);
      const negAbsLogits = neg(abs(logits));
      return add3(sub(reluLogits, mul(logits, labels)), log1p(exp(negAbsLogits)));
    });
  }
  function binaryCrossentropy(yTrue, yPred) {
    return tidy(() => {
      let y;
      y = clipByValue(yPred, epsilon(), 1 - epsilon());
      y = log5(div(y, sub(1, y)));
      return mean(sigmoidCrossEntropyWithLogits(yTrue, y), -1);
    });
  }
  function kullbackLeiblerDivergence(yTrue, yPred) {
    return tidy(() => {
      const clippedTrue = clipByValue(yTrue, epsilon(), 1);
      const clippedPred = clipByValue(yPred, epsilon(), 1);
      return sum2(mul(yTrue, log5(div(clippedTrue, clippedPred))), -1);
    });
  }
  function poisson(yTrue, yPred) {
    return tidy(() => {
      const logPred = log5(add3(epsilon(), yPred));
      return mean(sub(yPred, mul(yTrue, logPred)), -1);
    });
  }
  function cosineProximity(yTrue, yPred) {
    return tidy(() => {
      const trueNormalized = l2Normalize(yTrue, -1);
      const predNormalized = l2Normalize(yPred, -1);
      const trueXPred = mul(trueNormalized, predNormalized);
      return neg(sum2(trueXPred, -1));
    });
  }
  var lossesMap = {
    meanSquaredError,
    meanAbsoluteError,
    meanAbsolutePercentageError,
    meanSquaredLogarithmicError,
    squaredHinge,
    hinge,
    categoricalHinge,
    logcosh,
    categoricalCrossentropy,
    sparseCategoricalCrossentropy,
    binaryCrossentropy,
    kullbackLeiblerDivergence,
    poisson,
    cosineProximity
  };
  function get2(identifierOrFn) {
    if (typeof identifierOrFn === "string") {
      if (identifierOrFn in lossesMap) {
        return lossesMap[identifierOrFn];
      }
      let errMsg = `Unknown loss ${identifierOrFn}`;
      if (identifierOrFn.toLowerCase().includes("softmaxcrossentropy")) {
        errMsg = `Unknown loss ${identifierOrFn}. Use "categoricalCrossentropy" as the string name for tf.losses.softmaxCrossEntropy`;
      }
      throw new ValueError(errMsg);
    } else {
      return identifierOrFn;
    }
  }

  // node_modules/@tensorflow/tfjs-layers/dist/metrics.js
  function binaryAccuracy(yTrue, yPred) {
    return tidy(() => {
      const threshold3 = mul(0.5, onesLike(yPred));
      const yPredThresholded = cast2(greater(yPred, threshold3), yTrue.dtype);
      return mean(equal(yTrue, yPredThresholded), -1);
    });
  }
  function categoricalAccuracy(yTrue, yPred) {
    return tidy(() => cast2(equal(argMax(yTrue, -1), argMax(yPred, -1)), "float32"));
  }
  function truePositives(yTrue, yPred) {
    return tidy(() => {
      return cast(sum2(logicalAnd(equal(yTrue, 1), equal(yPred, 1))), "float32");
    });
  }
  function falsePositives(yTrue, yPred) {
    return tidy(() => {
      return cast(sum2(logicalAnd(equal(yTrue, 0), equal(yPred, 1))), "float32");
    });
  }
  function precision(yTrue, yPred) {
    return tidy(() => {
      const tp = truePositives(yTrue, yPred);
      const fp = falsePositives(yTrue, yPred);
      const denominator = add3(tp, fp);
      return cast(where(greater(denominator, 0), div(tp, denominator), 0), "float32");
    });
  }
  function binaryCrossentropy2(yTrue, yPred) {
    return binaryCrossentropy(yTrue, yPred);
  }
  function sparseCategoricalAccuracy(yTrue, yPred) {
    if (yTrue.rank === yPred.rank) {
      yTrue = squeeze(yTrue, [yTrue.rank - 1]);
    }
    yPred = argMax(yPred, -1);
    if (yPred.dtype !== yTrue.dtype) {
      yPred = cast(yPred, yTrue.dtype);
    }
    return cast(equal(yTrue, yPred), "float32");
  }
  var mse = meanSquaredError;
  var MSE = meanSquaredError;
  var mae = meanAbsoluteError;
  var MAE = meanAbsoluteError;
  var mape = meanAbsolutePercentageError;
  var MAPE = meanAbsolutePercentageError;
  var categoricalCrossentropy2 = categoricalCrossentropy;
  var cosine = cosineProximity;
  var sparseCategoricalCrossentropy2 = sparseCategoricalCrossentropy;
  var metricsMap = {
    binaryAccuracy,
    categoricalAccuracy,
    precision,
    categoricalCrossentropy: categoricalCrossentropy2,
    sparseCategoricalCrossentropy: sparseCategoricalCrossentropy2,
    mse,
    MSE,
    mae,
    MAE,
    mape,
    MAPE,
    cosine
  };
  function get3(identifier) {
    if (typeof identifier === "string" && identifier in metricsMap) {
      return metricsMap[identifier];
    } else if (typeof identifier !== "string" && identifier != null) {
      return identifier;
    } else {
      throw new ValueError(`Unknown metric ${identifier}`);
    }
  }
  function getLossOrMetricName(fn) {
    assert2(fn !== null, `Unknown LossOrMetricFn ${fn}`);
    if (typeof fn === "string") {
      return fn;
    } else {
      let fnName;
      for (const key of Object.keys(lossesMap)) {
        if (lossesMap[key] === fn) {
          fnName = key;
          break;
        }
      }
      if (fnName !== void 0) {
        return fnName;
      }
      for (const key of Object.keys(metricsMap)) {
        if (metricsMap[key] === fn) {
          fnName = key;
          break;
        }
      }
      if (fnName !== void 0) {
        return fnName;
      }
      return fn.name;
    }
  }

  // node_modules/@tensorflow/tfjs-layers/dist/optimizers.js
  function getOptimizer(identifier) {
    const optimizerMap = {
      "Adagrad": () => train.adagrad(0.01),
      "Adadelta": () => train.adadelta(1, 0.95, epsilon()),
      "Adam": () => train.adam(1e-3, 0.9, 0.999, epsilon()),
      "Adamax": () => train.adamax(2e-3, 0.9, 0.999, epsilon(), 0),
      "RMSProp": () => train.rmsprop(1e-3, 0.9, 0, epsilon()),
      "SGD": () => train.sgd(0.01)
    };
    optimizerMap["adagrad"] = optimizerMap["Adagrad"];
    optimizerMap["adadelta"] = optimizerMap["Adadelta"];
    optimizerMap["adam"] = optimizerMap["Adam"];
    optimizerMap["adamax"] = optimizerMap["Adamax"];
    optimizerMap["rmsprop"] = optimizerMap["RMSProp"];
    optimizerMap["sgd"] = optimizerMap["SGD"];
    if (identifier in optimizerMap) {
      return optimizerMap[identifier]();
    }
    throw new ValueError(`Unknown Optimizer ${identifier}`);
  }

  // node_modules/@tensorflow/tfjs-layers/dist/user_defined_metadata.js
  var MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH = 1 * 1024 * 1024;
  function checkUserDefinedMetadata(userDefinedMetadata, modelName, checkSize = false) {
    if (userDefinedMetadata == null || typeof userDefinedMetadata !== "object" || Object.getPrototypeOf(userDefinedMetadata) !== Object.prototype || !plainObjectCheck(userDefinedMetadata)) {
      throw new Error("User-defined metadata is expected to be a JSON object, but is not.");
    }
    if (checkSize) {
      const out = JSON.stringify(userDefinedMetadata);
      if (out.length > MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH) {
        console.warn(`User-defined metadata of model "${modelName}" is too large in size (length=${out.length} when serialized). It is not recommended to store such large objects in user-defined metadata. Please make sure its serialized length is <= ${MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH}.`);
      }
    }
  }
  function plainObjectCheck(x) {
    if (x === null) {
      return true;
    } else if (typeof x === "object") {
      if (Object.getPrototypeOf(x) === Object.prototype) {
        const keys = Object.keys(x);
        for (const key of keys) {
          if (typeof key !== "string") {
            return false;
          }
          if (!plainObjectCheck(x[key])) {
            return false;
          }
        }
        return true;
      } else {
        if (Array.isArray(x)) {
          for (const item of x) {
            if (!plainObjectCheck(item)) {
              return false;
            }
          }
          return true;
        } else {
          return false;
        }
      }
    } else {
      const xType = typeof x;
      return xType === "string" || xType === "number" || xType === "boolean";
    }
  }

  // node_modules/@tensorflow/tfjs-layers/dist/utils/layer_utils.js
  function printSummary(model2, lineLength, positions, printFn = console.log) {
    const sequentialLike = isModelSequentialLike(model2);
    const toDisplay = ["Layer (type)", "Output shape", "Param #"];
    if (sequentialLike) {
      lineLength = lineLength || 65;
      positions = positions || [0.45, 0.85, 1];
    } else {
      lineLength = lineLength || 98;
      positions = positions || [0.33, 0.55, 0.67, 1];
    }
    if (positions[positions.length - 1] <= 1) {
      positions = positions.map((p3) => Math.floor(lineLength * p3));
    }
    let relevantNodes;
    if (!sequentialLike) {
      toDisplay.push("Receives inputs");
      relevantNodes = [];
      for (const depth in model2.nodesByDepth) {
        relevantNodes.push(...model2.nodesByDepth[depth]);
      }
    }
    printFn("_".repeat(lineLength));
    printRow(toDisplay, positions, printFn);
    printFn("=".repeat(lineLength));
    const layers = model2.layers;
    for (let i = 0; i < layers.length; ++i) {
      if (sequentialLike) {
        printLayerSummary(layers[i], positions, printFn);
      } else {
        printLayerSummaryWithConnections(layers[i], positions, relevantNodes, printFn);
      }
      printFn((i === layers.length - 1 ? "=" : "_").repeat(lineLength));
    }
    model2.checkTrainableWeightsConsistency();
    const trainableCount = countTrainableParams(model2);
    const nonTrainableCount = countParamsInWeights(model2.nonTrainableWeights);
    printFn(`Total params: ${trainableCount + nonTrainableCount}`);
    printFn(`Trainable params: ${trainableCount}`);
    printFn(`Non-trainable params: ${nonTrainableCount}`);
    printFn("_".repeat(lineLength));
  }
  function countTrainableParams(model2) {
    let trainableCount;
    if (model2.collectedTrainableWeights != null) {
      trainableCount = countParamsInWeights(model2.collectedTrainableWeights);
    } else {
      trainableCount = countParamsInWeights(model2.trainableWeights);
    }
    return trainableCount;
  }
  function isModelSequentialLike(model2) {
    let sequentialLike = true;
    const nodesByDepth = [];
    const nodes = [];
    for (const depth in model2.nodesByDepth) {
      nodesByDepth.push(model2.nodesByDepth[depth]);
    }
    for (const depthNodes of nodesByDepth) {
      if (depthNodes.length > 1 || depthNodes.length === 1 && depthNodes[0].inboundLayers.length > 1) {
        sequentialLike = false;
        break;
      }
      nodes.push(...depthNodes);
    }
    if (sequentialLike) {
      for (const layer of model2.layers) {
        let flag = false;
        for (const node of layer.inboundNodes) {
          if (nodes.indexOf(node) !== -1) {
            if (flag) {
              sequentialLike = false;
              break;
            } else {
              flag = true;
            }
          }
        }
        if (!sequentialLike) {
          break;
        }
      }
    }
    return sequentialLike;
  }
  function printRow(fields, positions, printFn = console.log) {
    let line = "";
    for (let i = 0; i < fields.length; ++i) {
      if (i > 0) {
        line = line.slice(0, line.length - 1) + " ";
      }
      line += fields[i];
      line = line.slice(0, positions[i]);
      line += " ".repeat(positions[i] - line.length);
    }
    printFn(line);
  }
  function printLayerSummary(layer, positions, printFn) {
    let outputShape;
    try {
      outputShape = JSON.stringify(layer.outputShape);
    } catch (err) {
      outputShape = "multiple";
    }
    const name = layer.name;
    const className = layer.getClassName();
    const fields = [`${name} (${className})`, outputShape, layer.countParams().toString()];
    printRow(fields, positions, printFn);
  }
  function printLayerSummaryWithConnections(layer, positions, relevantNodes, printFn) {
    let outputShape;
    try {
      outputShape = JSON.stringify(layer.outputShape);
    } catch (err) {
      outputShape = "multiple";
    }
    const connections = [];
    for (const node of layer.inboundNodes) {
      if (relevantNodes != null && relevantNodes.length > 0 && relevantNodes.indexOf(node) === -1) {
        continue;
      }
      for (let i = 0; i < node.inboundLayers.length; ++i) {
        const inboundLayer = node.inboundLayers[i].name;
        const inboundLayerIndex = node.nodeIndices[i];
        const inboundTensorIndex = node.tensorIndices[i];
        connections.push(`${inboundLayer}[${inboundLayerIndex}][${inboundTensorIndex}]`);
      }
    }
    const name = layer.name;
    const className = layer.getClassName();
    const firstConnection = connections.length === 0 ? "" : connections[0];
    const fields = [
      `${name} (${className})`,
      outputShape,
      layer.countParams().toString(),
      firstConnection
    ];
    printRow(fields, positions, printFn);
    for (let i = 1; i < connections.length; ++i) {
      printRow(["", "", "", connections[i]], positions, printFn);
    }
  }

  // node_modules/@tensorflow/tfjs-layers/dist/utils/serialization_utils.js
  function isArrayItemInputOrOutputName(key, index, value) {
    return (key === "inboundNodes" || key === "outputLayers" || key === "inputLayers") && index === 0 && typeof value === "string";
  }
  function convertPythonicToTs(pythonicConfig, key) {
    if (pythonicConfig === null) {
      return null;
    } else if (typeof pythonicConfig === "string") {
      return toCamelCase(pythonicConfig);
    } else if (typeof pythonicConfig === "number" || typeof pythonicConfig === "boolean") {
      return pythonicConfig;
    } else if (pythonicConfig instanceof Array) {
      const tsArray = [];
      const arrayLength = pythonicConfig.length;
      for (let i = 0; i < arrayLength; ++i) {
        const item = pythonicConfig[i];
        if (isArrayItemInputOrOutputName(key, i, item)) {
          tsArray.push(item);
        } else {
          tsArray.push(convertPythonicToTs(item, key));
        }
      }
      return tsArray;
    } else {
      const tsDict = {};
      for (const pythonicKey of Object.keys(pythonicConfig)) {
        const pythonicValue = pythonicConfig[pythonicKey];
        if (pythonicKey === "name" && typeof pythonicValue === "string") {
          tsDict[pythonicKey] = pythonicValue;
        } else {
          const tsKey = toCamelCase(pythonicKey);
          tsDict[tsKey] = convertPythonicToTs(pythonicValue, tsKey);
        }
      }
      return tsDict;
    }
  }
  function convertTsToPythonic(tsConfig, key) {
    if (tsConfig === null || tsConfig === void 0) {
      return null;
    } else if (typeof tsConfig === "string") {
      return toSnakeCase(tsConfig);
    } else if (typeof tsConfig === "number" || typeof tsConfig === "boolean") {
      return tsConfig;
    } else if (tsConfig instanceof Array) {
      const pyArray = [];
      const arrayLength = tsConfig.length;
      for (let i = 0; i < arrayLength; ++i) {
        const item = tsConfig[i];
        if (isArrayItemInputOrOutputName(key, i, item)) {
          pyArray.push(item);
        } else {
          pyArray.push(convertTsToPythonic(item, key));
        }
      }
      return pyArray;
    } else {
      const pyDict = {};
      for (const tsKey of Object.keys(tsConfig)) {
        const tsValue = tsConfig[tsKey];
        const pyKey = toSnakeCase(tsKey);
        if ((tsKey === "name" || tsKey === "className") && typeof tsValue === "string") {
          pyDict[pyKey] = tsValue;
        } else {
          pyDict[pyKey] = convertTsToPythonic(tsValue, tsKey);
        }
      }
      return pyDict;
    }
  }

  // node_modules/@tensorflow/tfjs-layers/dist/version.js
  var version2 = "3.11.0";

  // node_modules/@tensorflow/tfjs-layers/dist/engine/executor.js
  function assertFeedCompatibility(key, val) {
    if (key.dtype == null || key.dtype === val.dtype) {
      return val;
    }
    try {
      return cast(val, key.dtype);
    } catch (err) {
      throw new ValueError(`The dtype of the feed (${val.dtype}) can not be cast to the dtype of the key '${key.name}' (${key.dtype}).`);
    }
  }
  var FeedDict = class {
    constructor(feeds) {
      this.id2Value = {};
      this.id2Mask = {};
      this.name2Id = {};
      if (feeds instanceof FeedDict) {
        for (const id in feeds.id2Value) {
          this.id2Value[id] = feeds.id2Value[id];
          if (id in feeds.id2Mask) {
            this.id2Mask[id] = feeds.id2Mask[id];
          }
        }
      } else {
        if (feeds == null) {
          return;
        }
        for (const feed of feeds) {
          this.add(feed.key, feed.value);
        }
      }
    }
    add(key, value, mask) {
      if (this.id2Value[key.id] == null) {
        this.id2Value[key.id] = assertFeedCompatibility(key, value);
        this.name2Id[key.name] = key.id;
        if (mask != null) {
          this.id2Mask[key.id] = mask;
        }
      } else {
        throw new ValueError(`Duplicate key: name=${key.name}, id=${key.id}`);
      }
      return this;
    }
    addFeed(feed) {
      this.add(feed.key, feed.value);
    }
    hasKey(key) {
      return this.id2Value[key.id] != null;
    }
    names() {
      return Object.keys(this.name2Id);
    }
    getValue(key) {
      if (key instanceof SymbolicTensor) {
        if (this.id2Value[key.id] == null) {
          throw new ValueError(`Nonexistent key: ${key.name}`);
        } else {
          return this.id2Value[key.id];
        }
      } else {
        const id = this.name2Id[key];
        if (id == null) {
          throw new ValueError(`Feed dict has no SymbolicTensor name: ${key}`);
        }
        return this.id2Value[id];
      }
    }
    getMask(key) {
      if (key instanceof SymbolicTensor) {
        if (this.id2Value[key.id] == null) {
          throw new ValueError(`Nonexistent key: ${key.name}`);
        } else {
          return this.id2Mask[key.id];
        }
      } else {
        const id = this.name2Id[key];
        if (id == null) {
          throw new ValueError(`Feed dict has no SymbolicTensor name: ${key}`);
        }
        return this.id2Mask[id];
      }
    }
    disposeMasks() {
      if (this.id2Mask != null) {
        dispose(this.id2Mask);
      }
    }
  };
  var cachedSorted = {};
  var cachedRecipientCounts = {};
  function execute(fetches, feedDict, kwargs, probe) {
    const training = kwargs == null ? false : kwargs["training"];
    const arrayFetches = Array.isArray(fetches);
    const fetchArray = arrayFetches ? fetches : [fetches];
    const outputNames = fetchArray.map((t) => t.name);
    const finalOutputs = [];
    const feedNames = feedDict.names();
    for (const outputName of outputNames) {
      if (feedNames.indexOf(outputName) !== -1) {
        finalOutputs.push(feedDict.getValue(outputName));
      } else {
        finalOutputs.push(null);
      }
    }
    if (probe != null) {
      probe.maxNumTensors = -Infinity;
      probe.minNumTensors = Infinity;
    }
    const fetchAndFeedKey = outputNames.join(",") + "|" + feedDict.names().join(",");
    let sorted;
    let recipientCounts;
    if (cachedSorted[fetchAndFeedKey] == null) {
      const out = getTopologicalSortAndRecipientCounts(fetchArray, feedDict);
      sorted = out.sorted;
      recipientCounts = out.recipientCounts;
      cachedSorted[fetchAndFeedKey] = sorted;
      cachedRecipientCounts[fetchAndFeedKey] = recipientCounts;
    }
    sorted = cachedSorted[fetchAndFeedKey];
    recipientCounts = {};
    if (!training) {
      Object.assign(recipientCounts, cachedRecipientCounts[fetchAndFeedKey]);
    }
    const internalFeedDict = new FeedDict(feedDict);
    for (let i = 0; i < sorted.length; ++i) {
      if (probe != null) {
        const numTensors = memory().numTensors;
        if (numTensors > probe.maxNumTensors) {
          probe.maxNumTensors = numTensors;
        }
        if (numTensors < probe.minNumTensors) {
          probe.minNumTensors = numTensors;
        }
      }
      const symbolic = sorted[i];
      const srcLayer = symbolic.sourceLayer;
      if (srcLayer instanceof InputLayer) {
        continue;
      }
      const inputValues = [];
      const inputMasks = [];
      const tensorsToDispose = [];
      let maskExists = false;
      for (const input2 of symbolic.inputs) {
        const value = internalFeedDict.getValue(input2);
        const mask = internalFeedDict.getMask(input2);
        inputValues.push(value);
        inputMasks.push(mask);
        if (mask != null) {
          maskExists = true;
        }
        if (!training) {
          recipientCounts[input2.name]--;
          if (recipientCounts[input2.name] === 0 && !feedDict.hasKey(input2) && outputNames.indexOf(input2.name) === -1 && !value.isDisposed && input2.sourceLayer.stateful !== true) {
            tensorsToDispose.push(value);
          }
        }
      }
      if (maskExists) {
        kwargs = kwargs || {};
        kwargs["mask"] = inputMasks[0];
      }
      const outputTensors = toList(srcLayer.apply(inputValues, kwargs));
      let outputMask = null;
      if (srcLayer.supportsMasking) {
        outputMask = srcLayer.computeMask(inputValues, inputMasks);
      }
      const layerOutputs = getNodeOutputs(symbolic);
      const outputSymbolicTensors = Array.isArray(layerOutputs) ? layerOutputs : [layerOutputs];
      for (let i2 = 0; i2 < outputSymbolicTensors.length; ++i2) {
        if (!internalFeedDict.hasKey(outputSymbolicTensors[i2])) {
          internalFeedDict.add(outputSymbolicTensors[i2], outputTensors[i2], Array.isArray(outputMask) ? outputMask[0] : outputMask);
        }
        const index = outputNames.indexOf(outputSymbolicTensors[i2].name);
        if (index !== -1) {
          finalOutputs[index] = outputTensors[i2];
        }
      }
      if (!training) {
        dispose(tensorsToDispose);
      }
    }
    internalFeedDict.disposeMasks();
    return arrayFetches ? finalOutputs : finalOutputs[0];
  }
  function getTopologicalSortAndRecipientCounts(fetches, feedDict) {
    util_exports.assert(fetches != null && fetches.length > 0, () => `Expected at least one fetch, got none`);
    let finalSorted = [];
    let finalRecipientMap = {};
    if (fetches.length === 1) {
      const out = getTopologicalSortAndRecipientCountsForOneFetch(fetches[0], feedDict);
      finalSorted = out.sorted;
      finalRecipientMap = out.recipientMap;
    } else {
      const visited = new Set();
      for (const fetch4 of fetches) {
        const { sorted, recipientMap } = getTopologicalSortAndRecipientCountsForOneFetch(fetch4, feedDict);
        for (const symbolicTensor of sorted) {
          if (!visited.has(symbolicTensor.name)) {
            finalSorted.push(symbolicTensor);
            visited.add(symbolicTensor.name);
          }
        }
        for (const name in recipientMap) {
          if (finalRecipientMap[name] == null) {
            finalRecipientMap[name] = new Set();
          }
          recipientMap[name].forEach((recipient) => finalRecipientMap[name].add(recipient));
        }
      }
    }
    return {
      sorted: finalSorted,
      recipientCounts: recipientMap2Counts(finalRecipientMap)
    };
  }
  function recipientMap2Counts(recipientMap) {
    const recipientCounts = {};
    for (const name in recipientMap) {
      recipientCounts[name] = recipientMap[name].size;
    }
    return recipientCounts;
  }
  function getTopologicalSortAndRecipientCountsForOneFetch(fetch4, feedDict) {
    const visited = new Set();
    const sorted = [];
    const recipientMap = {};
    for (const key of feedDict.names()) {
      visited.add(key);
    }
    const stack3 = [];
    const marks = [];
    stack3.push(fetch4);
    while (stack3.length > 0) {
      const top = stack3[stack3.length - 1];
      if (visited.has(top.name)) {
        stack3.pop();
        continue;
      }
      const topIsMarked = marks[marks.length - 1] === stack3.length - 1;
      if (top.inputs.length === 0 || topIsMarked) {
        stack3.pop();
        sorted.push(top);
        visited.add(top.name);
        if (topIsMarked) {
          marks.pop();
        }
      } else {
        marks.push(stack3.length - 1);
        for (const input2 of top.inputs) {
          if (recipientMap[input2.name] == null) {
            recipientMap[input2.name] = new Set();
          }
          recipientMap[input2.name].add(top.name);
          if (visited.has(input2.name)) {
            continue;
          }
          stack3.push(input2);
        }
      }
    }
    return { sorted, recipientMap };
  }
  function getNodeOutputs(fetch4) {
    let layerOutputs;
    if (fetch4.sourceLayer.inboundNodes.length === 1) {
      layerOutputs = fetch4.sourceLayer.output;
    } else {
      let nodeIndex = null;
      for (let i = 0; i < fetch4.sourceLayer.inboundNodes.length; ++i) {
        for (const outputTensor of fetch4.sourceLayer.inboundNodes[i].outputTensors) {
          if (outputTensor.id === fetch4.id) {
            nodeIndex = i;
            break;
          }
        }
      }
      layerOutputs = fetch4.sourceLayer.getOutputAt(nodeIndex);
    }
    return layerOutputs;
  }

  // node_modules/@tensorflow/tfjs-layers/dist/engine/container.js
  var Container = class extends Layer {
    constructor(args) {
      super({});
      this.containerNodes = new Set();
      this.name = args.name;
      if (this.name == null) {
        const prefix = this.getClassName().toLowerCase();
        this.name = getUid(prefix);
      }
      this.supportsMasking = false;
      this.trainable_ = true;
      if (Array.isArray(args.inputs)) {
        this.inputs = args.inputs.slice();
      } else {
        this.inputs = [args.inputs];
      }
      if (Array.isArray(args.outputs)) {
        this.outputs = args.outputs.slice();
      } else {
        this.outputs = [args.outputs];
      }
      if (unique2(this.inputs).length !== this.inputs.length) {
        throw new ValueError(`The list of inputs passed to the model is redundant. All inputs should only appear once. Found: ${this.inputs.map((x) => x.name)}`);
      }
      if (unique2(this.outputs).length !== this.outputs.length) {
        console.warn(`The list of outputs passed to the model is redundant. All outputs should only appear once. Found: ${this.outputs.map((x) => x.name)}`);
      }
      this.inputLayers = [];
      this.inputLayersNodeIndices = [];
      this.inputLayersTensorIndices = [];
      this.outputLayers = [];
      this.outputLayersNodeIndices = [];
      this.outputLayersTensorIndices = [];
      this.layers = [];
      this.internalContainerRefs = [];
      for (const x of this.outputs) {
        const layer = x.sourceLayer;
        const nodeIndex = x.nodeIndex;
        const tensorIndex = x.tensorIndex;
        this.outputLayers.push(layer);
        this.outputLayersNodeIndices.push(nodeIndex);
        this.outputLayersTensorIndices.push(tensorIndex);
      }
      for (const x of this.inputs) {
        const layer = x.sourceLayer;
        const nodeIndex = x.nodeIndex;
        const tensorIndex = x.tensorIndex;
        assert2(nodeIndex === 0, "input layer has >1 nodes");
        assert2(tensorIndex === 0, "input layer has >1 tensors");
        this.inputLayers.push(layer);
        this.inputLayersNodeIndices.push(nodeIndex);
        this.inputLayersTensorIndices.push(tensorIndex);
      }
      this.inputNames = [];
      this.outputNames = [];
      this.feedInputShapes = [];
      this.feedInputNames = [];
      this.feedOutputNames = [];
      for (let i = 0; i < this.inputLayers.length; i++) {
        const layer = this.inputLayers[i];
        if (!(layer instanceof InputLayer)) {
          throw new TypeError(`Input layers to a LayersModel must be InputLayer objects. Received inputs: ${args.inputs}. Input ${i} (0-based) originates from layer type ${layer.getClassName()}.`);
        }
        this.inputNames.push(layer.name);
        this.feedInputShapes.push(layer.batchInputShape);
        this.feedInputNames.push(layer.name);
      }
      for (const layer of this.outputLayers) {
        this.outputNames.push(layer.name);
      }
      this.internalInputShapes = this.inputs.map((x) => x.shape);
      this.internalOutputShapes = this.outputs.map((x) => x.shape);
      const nodesDepths = {};
      const nodeIDToNode = {};
      const layersDepths = {};
      const layerIDToLayer = {};
      const layerIndices = {};
      const nodesInDecreasingDepth = [];
      const buildMapOfGraph = (tensor2, finishedNodes2, nodesInProgress2, layer, nodeIndex, tensorIndex) => {
        if (layer == null || nodeIndex == null || tensorIndex == null) {
          layer = tensor2.sourceLayer;
          nodeIndex = tensor2.nodeIndex;
          tensorIndex = tensor2.tensorIndex;
        }
        const node = layer.inboundNodes[nodeIndex];
        if (nodesInProgress2.indexOf(node) !== -1) {
          throw new RuntimeError(`The tensor ${tensor2.name} at layer "${layer.name}" is part of a cycle.`);
        }
        if (finishedNodes2.indexOf(node) !== -1) {
          return;
        }
        this.containerNodes.add(Container.nodeKey(layer, nodeIndex));
        if (!(layer.id in layerIndices)) {
          layerIndices[layer.id] = Object.keys(layerIndices).length;
        }
        if (nodesInProgress2.indexOf(node) === -1) {
          nodesInProgress2.push(node);
        }
        const numInboundLayers = node.inboundLayers.length;
        for (let i = 0; i < numInboundLayers; i++) {
          const x = node.inputTensors[i];
          const layer2 = node.inboundLayers[i];
          const nodeIndex2 = node.nodeIndices[i];
          const tensorIndex2 = node.tensorIndices[i];
          buildMapOfGraph(x, finishedNodes2, nodesInProgress2, layer2, nodeIndex2, tensorIndex2);
        }
        finishedNodes2.push(node);
        while (nodesInProgress2.indexOf(node) >= 0) {
          nodesInProgress2.splice(nodesInProgress2.indexOf(node), 1);
        }
        nodesInDecreasingDepth.push(node);
      };
      const finishedNodes = [];
      const nodesInProgress = [];
      for (const x of this.outputs) {
        buildMapOfGraph(x, finishedNodes, nodesInProgress);
      }
      const reversedNodesInDecreasingDepth = nodesInDecreasingDepth.slice().reverse();
      for (const node of reversedNodesInDecreasingDepth) {
        nodeIDToNode[node.id] = node;
        if (!(node.id in nodesDepths)) {
          nodesDepths[node.id] = 0;
        }
        let depth = nodesDepths[node.id];
        const previousDepth = layersDepths[node.outboundLayer.id] == null ? 0 : layersDepths[node.outboundLayer.id];
        depth = Math.max(depth, previousDepth);
        layersDepths[node.outboundLayer.id] = depth;
        layerIDToLayer[node.outboundLayer.id] = node.outboundLayer;
        nodesDepths[node.id] = depth;
        for (let i = 0; i < node.inboundLayers.length; i++) {
          const inboundLayer = node.inboundLayers[i];
          const nodeIndex = node.nodeIndices[i];
          const inboundNode = inboundLayer.inboundNodes[nodeIndex];
          const previousDepth2 = nodesDepths[inboundNode.id] == null ? 0 : nodesDepths[inboundNode.id];
          nodesDepths[inboundNode.id] = Math.max(depth + 1, previousDepth2);
          nodeIDToNode[inboundNode.id] = inboundNode;
        }
      }
      const nodesByDepth = {};
      for (const nodeID in nodesDepths) {
        const depth = nodesDepths[nodeID];
        if (!(depth in nodesByDepth)) {
          nodesByDepth[depth] = [];
        }
        nodesByDepth[depth].push(nodeIDToNode[nodeID]);
      }
      const layersByDepth = {};
      for (const layerID in layersDepths) {
        const depth = layersDepths[layerID];
        if (!(depth in layersByDepth)) {
          layersByDepth[depth] = [];
        }
        layersByDepth[depth].push(layerIDToLayer[layerID]);
      }
      let depthKeys = Object.keys(layersByDepth).map((x) => parseInt(x, 10)).sort(reverseNumberCompare);
      this.layers = [];
      for (const depth of depthKeys) {
        const layersForDepth = layersByDepth[depth];
        layersForDepth.sort((a, b) => {
          const aIndex = layerIndices[a.id];
          const bIndex = layerIndices[b.id];
          if (aIndex < bIndex) {
            return -1;
          }
          if (aIndex > bIndex) {
            return 1;
          }
          return 0;
        });
        for (const layer of layersForDepth) {
          if (layer instanceof Container) {
            this.internalContainerRefs.push(layer);
          }
          this.layers.push(layer);
        }
      }
      this.layersByDepth = layersByDepth;
      depthKeys = Object.keys(nodesByDepth).map((x) => parseInt(x, 10)).sort(reverseNumberCompare);
      const computableTensors = this.inputs.slice();
      const layersWithCompleteInput = [];
      for (const depth of depthKeys) {
        for (const node of nodesByDepth[depth]) {
          const layer = node.outboundLayer;
          if (layer != null) {
            for (const x of node.inputTensors) {
              if (computableTensors.indexOf(x) === -1) {
                throw new RuntimeError(`Graph disconnected: cannot obtain value for tensor ${x} at layer "${layer.name}". The following previous layers were accessed without issue: ${layersWithCompleteInput}`);
              }
            }
            for (const x of node.outputTensors) {
              computableTensors.push(x);
            }
            layersWithCompleteInput.push(layer.name);
          }
        }
      }
      this.nodesByDepth = nodesByDepth;
      const allNames = this.layers.map((x) => x.name);
      for (const name of allNames) {
        const numOccurrences = allNames.filter((x) => x === name).length;
        if (numOccurrences !== 1) {
          throw new RuntimeError(`The name "${name}" is used ${numOccurrences} times in the model. All layer names should be unique. Layer names: ` + JSON.stringify(allNames));
        }
      }
      this.outboundNodes = [];
      this.inboundNodes = [];
      new Node({
        outboundLayer: this,
        inboundLayers: [],
        nodeIndices: [],
        tensorIndices: [],
        inputTensors: this.inputs,
        outputTensors: this.outputs,
        inputMasks: this.inputs.map((x) => null),
        outputMasks: this.outputs.map((x) => null),
        inputShapes: this.inputs.map((x) => x.shape),
        outputShapes: this.outputs.map((x) => x.shape)
      });
      this.built = true;
      this._refCount = 1;
    }
    assertNotDisposed() {
      if (this._refCount === 0) {
        throw new Error(`Container '${this.name}' is already disposed.`);
      }
    }
    dispose() {
      this.assertNotDisposed();
      const result = { refCountAfterDispose: null, numDisposedVariables: 0 };
      if (--this._refCount === 0) {
        for (const layer of this.layers) {
          result.numDisposedVariables += layer.dispose().numDisposedVariables;
        }
        for (const container of this.internalContainerRefs) {
          result.numDisposedVariables += container.dispose().numDisposedVariables;
        }
      }
      result.refCountAfterDispose = this._refCount;
      return result;
    }
    get trainable() {
      return this.trainable_;
    }
    set trainable(trainable) {
      this.layers.forEach((layer) => {
        layer._trainableWeights.forEach((w) => w.trainable = trainable);
      });
      this.trainable_ = trainable;
    }
    get trainableWeights() {
      if (this._trainableWeights.length > 0) {
        throw new ValueError("Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.");
      }
      if (!this.trainable) {
        return [];
      }
      let weights = [];
      for (const layer of this.layers) {
        weights = weights.concat(layer.trainableWeights);
      }
      return weights;
    }
    get nonTrainableWeights() {
      const weights = [];
      for (const layer of this.layers) {
        weights.push(...layer.nonTrainableWeights);
      }
      if (!this.trainable) {
        const trainableWeights = [];
        for (const layer of this.layers) {
          trainableWeights.push(...layer.trainableWeights);
        }
        return trainableWeights.concat(weights);
      }
      return weights;
    }
    get weights() {
      return this.trainableWeights.concat(this.nonTrainableWeights);
    }
    loadWeights(weights, strict = true) {
      const nameToWeight = {};
      let totalWeightsCount = 0;
      for (const layer of this.layers) {
        for (const weight of layer.weights) {
          if (nameToWeight[weight.originalName] != null) {
            throw new ValueError(`Duplicate weight name: ${weight.originalName}`);
          }
          nameToWeight[weight.originalName] = weight;
          totalWeightsCount++;
        }
      }
      const weightValueTuples = [];
      for (const name in weights) {
        let validatedName = name;
        if (nameToWeight[name] == null) {
          const tokens = name.split("/");
          const shortenNameArray = tokens.slice(0, -2).concat([tokens[tokens.length - 1]]);
          validatedName = shortenNameArray.join("/");
        }
        if (nameToWeight[validatedName] != null) {
          weightValueTuples.push([nameToWeight[validatedName], weights[name]]);
        } else if (strict) {
          throw new ValueError(`Provided weight data has no target variable: ${name}`);
        }
        delete nameToWeight[validatedName];
      }
      if (strict) {
        const unsetNames = [];
        for (const name in nameToWeight) {
          unsetNames.push(name);
        }
        if (unsetNames.length > 0) {
          throw new ValueError(`${unsetNames.length} of ${totalWeightsCount} weights are not set: ${unsetNames}`);
        }
      }
      batchSetValue(weightValueTuples);
    }
    updatedConfig() {
      const theConfig = this.getConfig();
      const modelConfig = {};
      modelConfig["className"] = this.getClassName();
      modelConfig["config"] = theConfig;
      modelConfig["kerasVersion"] = `tfjs-layers ${version2}`;
      modelConfig["backend"] = "TensorFlow.js";
      return modelConfig;
    }
    toJSON(unused, returnString = true) {
      const modelConfig = convertTsToPythonic(this.updatedConfig());
      return returnString ? JSON.stringify(modelConfig) : modelConfig;
    }
    call(inputs, kwargs) {
      return tidy(() => {
        inputs = toList(inputs);
        const feedDict = new FeedDict();
        for (let i = 0; i < this.inputs.length; ++i) {
          feedDict.add(this.inputs[i], inputs[i]);
        }
        return execute(this.outputs, feedDict, kwargs);
      });
    }
    computeMask(inputs, mask) {
      return tidy(() => {
        inputs = toList(inputs);
        let masks;
        if (mask == null) {
          masks = pyListRepeat(null, inputs.length);
        } else {
          masks = toList(mask);
        }
        return this.runInternalGraph(inputs, masks)[1];
      });
    }
    computeOutputShape(inputShape) {
      const inputShapes = normalizeShapeList(inputShape);
      if (inputShapes.length !== this.inputLayers.length) {
        throw new ValueError(`Invalid inputShape argument ${inputShape}: model has ${this.inputLayers.length} tensor inputs.`);
      }
      const layersToOutputShapes = {};
      for (let i = 0; i < inputShapes.length; i++) {
        const layer = this.inputLayers[i];
        const inputShape2 = inputShapes[i];
        const shapeKey = layer.name + "_0_0";
        layersToOutputShapes[shapeKey] = inputShape2;
      }
      const depthKeys = Object.keys(this.nodesByDepth).map((x) => parseInt(x, 10)).sort(reverseNumberCompare);
      if (depthKeys.length > 1) {
        for (const depth of depthKeys) {
          const nodes = this.nodesByDepth[depth];
          for (const node of nodes) {
            const layer = node.outboundLayer;
            if (this.inputLayers.map((x) => x.id).indexOf(layer.id) !== -1) {
              continue;
            }
            const inputShapes2 = [];
            for (let j = 0; j < node.inboundLayers.length; j++) {
              const inboundLayer = node.inboundLayers[j];
              const nodeIndex2 = node.nodeIndices[j];
              const tensorIndex = node.tensorIndices[j];
              const shapeKey = `${inboundLayer.name}_${nodeIndex2}_${tensorIndex}`;
              const inputShape2 = layersToOutputShapes[shapeKey];
              inputShapes2.push(inputShape2);
            }
            const outputShape = layer.computeOutputShape(singletonOrArray(inputShapes2));
            const outputShapes2 = normalizeShapeList(outputShape);
            const nodeIndex = layer.inboundNodes.indexOf(node);
            for (let j = 0; j < outputShapes2.length; j++) {
              const shapeKey = `${layer.name}_${nodeIndex}_${j}`;
              layersToOutputShapes[shapeKey] = outputShapes2[j];
            }
          }
        }
      }
      const outputShapes = [];
      const outputShapeKeys = [];
      for (let i = 0; i < this.outputLayers.length; i++) {
        const layer = this.outputLayers[i];
        const nodeIndex = this.outputLayersNodeIndices[i];
        const tensorIndex = this.outputLayersTensorIndices[i];
        const shapeKey = `${layer.name}_${nodeIndex}_${tensorIndex}`;
        outputShapeKeys.push(shapeKey);
      }
      for (let i = 0; i < outputShapeKeys.length; i++) {
        const key = outputShapeKeys[i];
        assert2(key in layersToOutputShapes);
        outputShapes.push(layersToOutputShapes[key]);
      }
      return singletonOrArray(outputShapes);
    }
    runInternalGraph(inputs, masks) {
      if (masks == null) {
        masks = pyListRepeat(null, inputs.length);
      }
      const tensorMap = {};
      for (let i = 0; i < this.inputs.length; ++i) {
        const x = this.inputs[i];
        const y = inputs[i];
        const mask = masks[i];
        tensorMap[x.id] = [y, mask];
      }
      const depthKeys = Object.keys(this.nodesByDepth).map((x) => parseInt(x, 10)).sort(reverseNumberCompare);
      for (const depth of depthKeys) {
        const nodes = this.nodesByDepth[depth];
        for (const node of nodes) {
          const layer = node.outboundLayer;
          const referenceInputTensors = node.inputTensors;
          const referenceOutputTensors = node.outputTensors;
          const computedData = new Array();
          for (const x of referenceInputTensors) {
            if (x.id in tensorMap) {
              computedData.push(tensorMap[x.id]);
            }
          }
          if (computedData.length === referenceInputTensors.length) {
            let kwargs = {};
            let computedTensors;
            let computedMasks;
            let outputTensors2;
            let outputMasks2;
            if (node.callArgs != null) {
              kwargs = node.callArgs;
            }
            if (computedData.length === 1) {
              const [computedTensor, computedMask] = computedData[0];
              if (kwargs["mask"] == null) {
                kwargs["mask"] = computedMask;
              }
              outputTensors2 = toList(layer.call(computedTensor, kwargs));
              outputMasks2 = toList(layer.computeMask(computedTensor, computedMask));
              computedTensors = [computedTensor];
              computedMasks = [computedMask];
            } else {
              computedTensors = computedData.map((x) => x[0]);
              computedMasks = computedData.map((x) => x[1]);
              if (kwargs["mask"] == null) {
                kwargs["mask"] = computedMasks;
              }
              outputTensors2 = toList(layer.call(computedTensors, kwargs));
              outputMasks2 = toList(layer.computeMask(computedTensors, computedMasks));
            }
            if (layer.activityRegularizer) {
              throw new NotImplementedError("LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.");
            }
            for (let i = 0; i < referenceOutputTensors.length; ++i) {
              const x = referenceOutputTensors[i];
              const y = outputTensors2[i];
              const mask = outputMasks2[i];
              tensorMap[x.id] = [y, mask];
            }
          }
        }
      }
      const outputTensors = [];
      const outputMasks = [];
      const outputShapes = [];
      for (const x of this.outputs) {
        assert2(x.id in tensorMap, `Could not compute output ${x.name} : ${x.id}`);
        const [tensor2, mask] = tensorMap[x.id];
        outputShapes.push(tensor2.shape);
        outputTensors.push(tensor2);
        outputMasks.push(mask);
      }
      return [outputTensors, outputMasks, outputShapes];
    }
    buildNodeConversionMap(layers) {
      const nodeConversionMap = {};
      let keptNodes;
      for (const layer of this.layers) {
        keptNodes = layer instanceof Container ? 1 : 0;
        for (let originalNodeIndex = 0; originalNodeIndex < layer.inboundNodes.length; originalNodeIndex++) {
          const nodeKey = Container.nodeKey(layer, originalNodeIndex);
          if (this.containerNodes.has(nodeKey)) {
            nodeConversionMap[nodeKey] = keptNodes;
            keptNodes += 1;
          }
        }
      }
      return nodeConversionMap;
    }
    getLayer(name, index) {
      if (index != null) {
        if (this.layers.length <= index) {
          throw new ValueError(`Was asked to retrieve layer at index ${index}, but model only has ${this.layers.length} layer(s).`);
        } else {
          return this.layers[index];
        }
      } else {
        if (name == null) {
          throw new ValueError("Provide either a layer name or layer index");
        }
      }
      for (const layer of this.layers) {
        if (layer.name === name) {
          return layer;
        }
      }
      throw new ValueError(`No such layer: ${name}`);
    }
    calculateLosses() {
      return tidy(() => {
        const losses3 = [];
        for (const layer of this.layers) {
          for (let nodeIndex = 0; nodeIndex < layer.inboundNodes.length; ++nodeIndex) {
            const nodeKey = Container.nodeKey(layer, nodeIndex);
            if (this.containerNodes.has(nodeKey)) {
              losses3.push(...layer.calculateLosses());
            }
          }
        }
        return losses3;
      });
    }
    getConfig() {
      const config = { name: this.name };
      const nodeConversionMap = this.buildNodeConversionMap(this.layers);
      const layerConfigs = [];
      for (const layer of this.layers) {
        const layerClassName = layer.getClassName();
        const layerConfig = layer.getConfig();
        const filteredInboundNodes = [];
        for (let originalNodeIndex = 0; originalNodeIndex < layer.inboundNodes.length; originalNodeIndex++) {
          const node = layer.inboundNodes[originalNodeIndex];
          const nodeKey = Container.nodeKey(layer, originalNodeIndex);
          let kwargs = {};
          if (this.containerNodes.has(nodeKey)) {
            if (node.callArgs) {
              try {
                JSON.stringify(node.callArgs);
                kwargs = node.callArgs;
              } catch (err) {
                console.warn(`Layer ${layer.name} was passed non-serializable keyword arguments: ${node.callArgs}. They will not be included in the serialized model (and thus will be missing at deserialization time).`);
                kwargs = {};
              }
            }
            if (node.inboundLayers.length > 0) {
              const nodeData = [];
              for (let i = 0; i < node.inboundLayers.length; i++) {
                const inboundLayer = node.inboundLayers[i];
                const nodeIndex = node.nodeIndices[i];
                const tensorIndex = node.tensorIndices[i];
                const nodeKey2 = Container.nodeKey(inboundLayer, nodeIndex);
                let newNodeIndex = nodeConversionMap[nodeKey2];
                if (newNodeIndex == null) {
                  newNodeIndex = 0;
                }
                nodeData.push([inboundLayer.name, newNodeIndex, tensorIndex, kwargs]);
              }
              filteredInboundNodes.push(nodeData);
            }
          }
        }
        const dict = {};
        dict["name"] = layer.name;
        dict["className"] = layerClassName;
        dict["config"] = layerConfig;
        dict["inboundNodes"] = filteredInboundNodes;
        layerConfigs.push(dict);
      }
      config["layers"] = layerConfigs;
      const modelInputs = [];
      for (let i = 0; i < this.inputLayers.length; i++) {
        const layer = this.inputLayers[i];
        const nodeIndex = this.inputLayersNodeIndices[i];
        const nodeKey = Container.nodeKey(layer, nodeIndex);
        if (!this.containerNodes.has(nodeKey)) {
          continue;
        }
        let newNodeIndex = nodeConversionMap[nodeKey];
        if (newNodeIndex === null || newNodeIndex === void 0) {
          newNodeIndex = 0;
        }
        const tensorIndex = this.inputLayersTensorIndices[i];
        modelInputs.push([layer.name, newNodeIndex, tensorIndex]);
      }
      config["inputLayers"] = modelInputs;
      const modelOutputs = [];
      for (let i = 0; i < this.outputLayers.length; i++) {
        const layer = this.outputLayers[i];
        const nodeIndex = this.outputLayersNodeIndices[i];
        const nodeKey = Container.nodeKey(layer, nodeIndex);
        if (!this.containerNodes.has(nodeKey)) {
          continue;
        }
        let newNodeIndex = nodeConversionMap[nodeKey];
        if (newNodeIndex === null || newNodeIndex === void 0) {
          newNodeIndex = 0;
        }
        const tensorIndex = this.outputLayersTensorIndices[i];
        modelOutputs.push([layer.name, newNodeIndex, tensorIndex]);
      }
      config["outputLayers"] = modelOutputs;
      return config;
    }
    static fromConfig(cls, config, customObjects = {}, fastWeightInit = false) {
      const createdLayers = {};
      const unprocessedNodes = {};
      function addUnprocessedNode(layer, nodeData) {
        if (!(layer.name in unprocessedNodes)) {
          unprocessedNodes[layer.name] = [nodeData];
        } else {
          unprocessedNodes[layer.name].push(nodeData);
        }
      }
      function processNode(layer, nodeData) {
        const inputTensors2 = [];
        let kwargs;
        for (const inputData of nodeData) {
          const inboundLayerName = inputData[0];
          const inboundNodeIndex = inputData[1];
          const inboundTensorIndex = inputData[2];
          kwargs = inputData[3] == null ? {} : inputData[3];
          if (!(inboundLayerName in createdLayers)) {
            addUnprocessedNode(layer, nodeData);
            return;
          }
          const inboundLayer = createdLayers[inboundLayerName];
          if (inboundLayer.inboundNodes.length <= inboundNodeIndex) {
            addUnprocessedNode(layer, nodeData);
            return;
          }
          const inboundNode = inboundLayer.inboundNodes[inboundNodeIndex];
          inputTensors2.push(inboundNode.outputTensors[inboundTensorIndex]);
        }
        if (inputTensors2.length > 0) {
          layer.apply(singletonOrArray(inputTensors2), kwargs);
        }
      }
      function processLayer(layerData) {
        const layerName = layerData["name"];
        const layer = deserialize(layerData, config["customObjects"] != null ? config["customObjects"] : {});
        layer.setFastWeightInitDuringBuild(fastWeightInit);
        createdLayers[layerName] = layer;
        const inboundNodesData = layerData["inboundNodes"];
        inboundNodesData.forEach((nodeData) => {
          if (!(nodeData instanceof Array)) {
            throw new ValueError(`Corrupted configuration, expected array for nodeData: ${nodeData}`);
          }
          addUnprocessedNode(layer, nodeData);
        });
      }
      const name = config["name"];
      const layersFromConfig = config["layers"];
      for (const layerData of layersFromConfig) {
        processLayer(layerData);
      }
      while (!isObjectEmpty(unprocessedNodes)) {
        for (const layerData of layersFromConfig) {
          const layer = createdLayers[layerData["name"]];
          if (layer.name in unprocessedNodes) {
            const currentUnprocessedNodesForLayer = unprocessedNodes[layer.name];
            delete unprocessedNodes[layer.name];
            for (const nodeData of currentUnprocessedNodesForLayer) {
              processNode(layer, nodeData);
            }
          }
        }
      }
      const inputTensors = [];
      const outputTensors = [];
      const inputLayersFromConfig = config["inputLayers"];
      for (const layerData of inputLayersFromConfig) {
        const layerName = layerData[0];
        const nodeIndex = layerData[1];
        const tensorIndex = layerData[2];
        assert2(layerName in createdLayers);
        const layer = createdLayers[layerName];
        const layerOutputTensors = layer.inboundNodes[nodeIndex].outputTensors;
        inputTensors.push(layerOutputTensors[tensorIndex]);
      }
      const outputLayersFromConfig = config["outputLayers"];
      for (const layerData of outputLayersFromConfig) {
        const layerName = layerData[0];
        const nodeIndex = layerData[1];
        const tensorIndex = layerData[2];
        assert2(layerName in createdLayers);
        const layer = createdLayers[layerName];
        const layerOutputTensors = layer.inboundNodes[nodeIndex].outputTensors;
        outputTensors.push(layerOutputTensors[tensorIndex]);
      }
      return new cls({ inputs: inputTensors, outputs: outputTensors, name });
    }
    get stateful() {
      if (this._stateful) {
        throw new ValueError("Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.");
      }
      for (const layer of this.layers) {
        if (layer.stateful) {
          return true;
        }
      }
      return false;
    }
    resetStates() {
      tidy(() => {
        this.layers.forEach((layer) => {
          if (layer.stateful) {
            layer.resetStates();
          }
        });
      });
    }
  };

  // node_modules/@tensorflow/tfjs-layers/dist/engine/training_utils.js
  function standardizeSampleOrClassWeights(xWeight, outputNames, weightType) {
    const numOutputs = outputNames.length;
    if (xWeight == null || Array.isArray(xWeight) && xWeight.length === 0) {
      return outputNames.map((name) => null);
    }
    if (numOutputs === 1) {
      if (Array.isArray(xWeight) && xWeight.length === 1) {
        return xWeight;
      } else if (typeof xWeight === "object" && outputNames[0] in xWeight) {
        return [xWeight[outputNames[0]]];
      } else {
        return [xWeight];
      }
    }
    if (Array.isArray(xWeight)) {
      if (xWeight.length !== numOutputs) {
        throw new Error(`Provided ${weightType} is an array of ${xWeight.length} element(s), but the model has ${numOutputs} outputs. Make sure a set of weights is provided for each model output.`);
      }
      return xWeight;
    } else if (typeof xWeight === "object" && Object.keys(xWeight).length > 0 && typeof xWeight[Object.keys(xWeight)[0]] === "object") {
      const output = [];
      outputNames.forEach((outputName) => {
        if (outputName in xWeight) {
          output.push(xWeight[outputName]);
        } else {
          output.push(null);
        }
      });
      return output;
    } else {
      throw new Error(`The model has multiple (${numOutputs}) outputs, so ${weightType} must be either an array with ${numOutputs} elements or an object with ${outputNames} keys. Provided ${weightType} not understood: ${JSON.stringify(xWeight)}`);
    }
  }
  function standardizeClassWeights(classWeight, outputNames) {
    return standardizeSampleOrClassWeights(classWeight, outputNames, "classWeight");
  }
  async function standardizeWeights(y, sampleWeight, classWeight, sampleWeightMode) {
    if (sampleWeight != null || sampleWeightMode != null) {
      throw new Error("Support sampleWeight is not implemented yet");
    }
    if (classWeight != null) {
      const yClasses = tidy(() => {
        if (y.shape.length === 1) {
          return clone(y);
        } else if (y.shape.length === 2) {
          if (y.shape[1] > 1) {
            const axis = 1;
            return argMax(y, axis);
          } else if (y.shape[1] === 1) {
            return reshape(y, [y.shape[0]]);
          } else {
            throw new Error(`Encountered unexpected last-dimension size (${y.shape[1]}) during handling of class weights. The size is expected to be >= 1.`);
          }
        } else {
          throw new Error(`Unexpected rank of target (y) tensor (${y.rank}) during handling of class weights. The rank is expected to be 1 or 2.`);
        }
      });
      const yClassIndices = Array.from(await yClasses.data());
      dispose(yClasses);
      const classSampleWeight = [];
      yClassIndices.forEach((classIndex) => {
        if (classWeight[classIndex] == null) {
          throw new Error(`classWeight must contain all classes in the training data. The class ${classIndex} exists in the data but not in classWeight`);
        } else {
          classSampleWeight.push(classWeight[classIndex]);
        }
      });
      return tensor1d(classSampleWeight, "float32");
    } else {
      return null;
    }
  }
  function computeWeightedLoss(losses3, sampleWeights) {
    return mul(losses3, sampleWeights);
  }

  // node_modules/@tensorflow/tfjs-layers/dist/engine/training_dataset.js
  var DEFAULT_VALIDATION_BATCH_SIZE = 32;
  function standardizeDataIteratorOutput(model2, iteratorOut) {
    let xs;
    let ys;
    const iteratorOutObj = iteratorOut;
    xs = iteratorOutObj["xs"];
    ys = iteratorOutObj["ys"];
    util_exports.assert(xs != null && ys != null, () => `A Dataset iterator for fitDataset() is expected to generate objects of the form \`{xs: xVal, ys: yVal}\`, where the two values may be \`tf.Tensor\`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates ${iteratorOut}`);
    const flattenedXs = flattenTensorOrArrayOrMap("input", model2.inputNames, xs);
    const flattenedYs = flattenTensorOrArrayOrMap("output", model2.outputNames, ys);
    const batchSize = flattenedXs[0].shape[0];
    util_exports.assert(flattenedXs.length === model2.inputs.length, () => `LayersModel has ${model2.inputs.length} inputs, but the dataset provides ${flattenedXs.length} inputs.  (Expected input keys: ${JSON.stringify(model2.inputNames)})`);
    util_exports.assert(flattenedYs.length === model2.outputs.length, () => `LayersModel has ${model2.outputs.length} outputs, but the dataset provides ${flattenedYs.length} outputs.  (Expected output keys: ${JSON.stringify(model2.outputNames)})`);
    for (let xIndex = 0; xIndex < flattenedXs.length; xIndex++) {
      util_exports.assert(flattenedXs[xIndex].shape[0] === batchSize, () => `Batch size mismatch: input ${model2.inputNames[xIndex]} has ${flattenedXs[xIndex].shape[0]}; expected  ${batchSize} based on input ${model2.inputNames[0]}.`);
    }
    for (let yIndex = 0; yIndex < flattenedYs.length; yIndex++) {
      util_exports.assert(flattenedYs[yIndex].shape[0] === batchSize, () => `Batch size mismatch: output ${model2.outputNames[yIndex]} has ${flattenedYs[yIndex].shape[0]}; expected  ${batchSize} based on input ${model2.inputNames[0]}.`);
    }
    return { xs: flattenedXs, ys: flattenedYs };
  }
  function flattenTensorOrArrayOrMap(inputOrOutput, names, values) {
    if (values instanceof Tensor) {
      return [values];
    } else if (Array.isArray(values)) {
      util_exports.assert(values.length === names.length, () => `Received an array of ${values.length} Tensors, but expected ${names.length} to match the ${inputOrOutput} keys ${names}.`);
      return values;
    } else {
      const result = [];
      for (const name of names) {
        if (values[name] == null) {
          throw new ValueError(`The feature data generated by the dataset lacks the required ${inputOrOutput} key '${name}'.`);
        }
        result.push(values[name]);
      }
      return result;
    }
  }
  function standardizeTensorValidationData(data) {
    if (data.length === 3) {
      throw new NotImplementedError("Validation with sample weights is not implemented yet.");
    }
    return { xs: data[0], ys: data[1] };
  }
  async function fitDataset(model2, dataset, args) {
    const hasBatchesPerEpoch = args.batchesPerEpoch != null;
    util_exports.assert(model2.optimizer != null, () => "You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig).");
    util_exports.assert(args != null, () => `For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call.`);
    util_exports.assert(args.epochs != null && args.epochs > 0 && Number.isInteger(args.epochs), () => `For fitDataset(), config.epochs is expected to be a positive integer, but got ${args.epochs}`);
    util_exports.assert(!hasBatchesPerEpoch || args.batchesPerEpoch > 0 && Number.isInteger(args.batchesPerEpoch), () => `For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got ${args.batchesPerEpoch}`);
    util_exports.assert(args["validationSplit"] == null, () => "`validationSplit` is not supported by `fitDataset()`. Use validationData instead.");
    if (model2.isTraining) {
      throw new Error("Cannot start training because another fit() call is ongoing.");
    }
    model2.isTraining = true;
    try {
      const doValidation = args.validationData != null;
      let valXs;
      let valYs;
      if (doValidation) {
        if (isDatasetObject(args.validationData)) {
          util_exports.assert(args.validationBatches == null || args.validationBatches > 0 && Number.isInteger(args.validationBatches), () => `For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got ${args.validationBatches}`);
        } else {
          const validationData = standardizeTensorValidationData(args.validationData);
          valXs = validationData.xs;
          valYs = validationData.ys;
        }
      }
      const trainFunction = model2.makeTrainFunction();
      const outLabels = model2.getDedupedMetricsNames();
      let callbackMetrics;
      if (doValidation) {
        callbackMetrics = outLabels.slice().concat(outLabels.map((n) => "val_" + n));
      } else {
        callbackMetrics = outLabels.slice();
      }
      const callbacks2 = standardizeCallbacks(args.callbacks, args.yieldEvery);
      const verbose = args.verbose == null ? 1 : args.verbose;
      const { callbackList, history } = configureCallbacks(callbacks2, verbose, args.epochs, null, null, getStepsPerEpoch(dataset, args), null, doValidation, callbackMetrics);
      callbackList.setModel(model2);
      model2.history = history;
      await callbackList.onTrainBegin();
      model2.stopTraining_ = false;
      let epoch = args.initialEpoch == null ? 0 : args.initialEpoch;
      let dataIterator = await dataset.iterator();
      while (epoch < args.epochs) {
        const epochLogs = {};
        await callbackList.onEpochBegin(epoch);
        let stepsDone = 0;
        let batchIndex = 0;
        if (!hasBatchesPerEpoch) {
          dataIterator = await dataset.iterator();
        }
        while (hasBatchesPerEpoch ? stepsDone < args.batchesPerEpoch : true) {
          const iteratorOut = await dataIterator.next();
          if (hasBatchesPerEpoch && iteratorOut.done) {
            console.warn(`You provided \`batchesPerEpoch\` as ${args.batchesPerEpoch}, but your dataset iterator ran out of data after ${stepsDone} batches; interrupting training. Make sure that your dataset can generate at least \`batchesPerEpoch * epochs\` batches (in this case, ${args.batchesPerEpoch * args.epochs} batches). You may need to use the repeat() function when building your dataset.`);
            break;
          }
          if (iteratorOut.value != null) {
            const { xs, ys } = standardizeDataIteratorOutput(model2, iteratorOut.value);
            const batchLogs = {};
            batchLogs["batch"] = batchIndex;
            batchLogs["size"] = xs[0].shape[0];
            await callbackList.onBatchBegin(batchIndex, batchLogs);
            const sampleWeights = [];
            if (args.classWeight != null) {
              const standardClassWeights = standardizeClassWeights(args.classWeight, model2.outputNames);
              for (let i = 0; i < standardClassWeights.length; ++i) {
                sampleWeights.push(await standardizeWeights(ys[i], null, standardClassWeights[i]));
              }
            }
            const ins = xs.concat(ys).concat(sampleWeights);
            const outs = trainFunction(ins);
            dispose(ins);
            for (let i = 0; i < outLabels.length; ++i) {
              const label = outLabels[i];
              const out = outs[i];
              batchLogs[label] = out;
              keep(out);
            }
            await callbackList.onBatchEnd(batchIndex, batchLogs);
            disposeTensorsInLogs(batchLogs);
            batchIndex++;
            stepsDone++;
          }
          if (hasBatchesPerEpoch ? stepsDone >= args.batchesPerEpoch : iteratorOut.done) {
            if (doValidation) {
              let valOuts;
              if (isDatasetObject(args.validationData)) {
                valOuts = toList(await model2.evaluateDataset(args.validationData, { batches: args.validationBatches }));
              } else {
                valOuts = toList(model2.evaluate(valXs, valYs, {
                  batchSize: args.validationBatchSize == null ? DEFAULT_VALIDATION_BATCH_SIZE : args.validationBatchSize,
                  verbose: 0
                }));
              }
              for (let i = 0; i < model2.metricsNames.length; ++i) {
                epochLogs[`val_${model2.metricsNames[i]}`] = valOuts[i];
              }
            }
            break;
          }
          if (model2.stopTraining_) {
            break;
          }
        }
        await callbackList.onEpochEnd(epoch, epochLogs);
        epoch++;
        if (model2.stopTraining_) {
          break;
        }
      }
      await callbackList.onTrainEnd();
      await model2.history.syncData();
      return model2.history;
    } finally {
      model2.isTraining = false;
    }
  }
  function getStepsPerEpoch(dataset, args) {
    let stepsPerEpoch = null;
    if (args.batchesPerEpoch != null) {
      stepsPerEpoch = args.batchesPerEpoch;
    } else if (Number.isFinite(dataset.size)) {
      stepsPerEpoch = dataset.size;
    }
    return stepsPerEpoch;
  }
  function isDatasetObject(dataset) {
    return typeof dataset.iterator === "function";
  }
  function isLazyIteratorObject(iterator) {
    return typeof iterator.next === "function";
  }
  async function evaluateDataset(model2, dataset, args) {
    args = args || {};
    const hasBatches = args.batches != null;
    const f = model2.testFunction;
    let outs = [];
    if (args.verbose > 0) {
      throw new NotImplementedError("Verbose mode is not implemented yet.");
    }
    util_exports.assert(!hasBatches || args.batches > 0 && Number.isInteger(args.batches), () => `Test loop expects \`batches\` to be a positive integer, but received ${JSON.stringify(args.batches)}`);
    const dataIterator = isLazyIteratorObject(dataset) ? dataset : await dataset.iterator();
    let numExamples = 0;
    let batch = 0;
    while (hasBatches ? batch < args.batches : true) {
      const iteratorOut = await dataIterator.next();
      outs = tidy(() => {
        if (iteratorOut.value) {
          const { xs, ys } = standardizeDataIteratorOutput(model2, iteratorOut.value);
          const xsAndYs = xs.concat(ys);
          const batchOuts = tidy(() => f(xsAndYs));
          dispose(xsAndYs);
          if (batch === 0) {
            for (let i = 0; i < batchOuts.length; ++i) {
              outs.push(scalar(0));
            }
          }
          const batchSize = xsAndYs[0].shape[0];
          for (let i = 0; i < batchOuts.length; ++i) {
            const batchOut = batchOuts[i];
            const oldScalar = outs[i];
            outs[i] = tidy(() => add3(outs[i], mul(batchSize, batchOut)));
            if (batch > 0) {
              dispose(oldScalar);
            }
          }
          dispose(batchOuts);
          numExamples += batchSize;
          ++batch;
        }
        return outs;
      });
      if (iteratorOut.done) {
        if (hasBatches) {
          console.warn(`Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least \`batches\` batches (in this case, ${args.batches} batches). You may need to use the repeat() function when building your dataset.`);
        }
        break;
      }
    }
    for (let i = 0; i < outs.length; ++i) {
      const oldScalar = outs[i];
      outs[i] = div(outs[i], numExamples);
      dispose(oldScalar);
    }
    return singletonOrArray(outs);
  }

  // node_modules/@tensorflow/tfjs-layers/dist/engine/training_tensors.js
  function checkBatchSize(batchSize) {
    util_exports.assert(batchSize > 0 && Number.isInteger(batchSize), () => `batchSize is required to be a positive integer, but got ${batchSize}`);
  }
  function sliceArrays(arrays, start, stop2) {
    if (arrays == null) {
      return [null];
    } else if (Array.isArray(arrays)) {
      return arrays.map((array2) => sliceAlongFirstAxis(array2, start, stop2 - start));
    } else {
      return sliceAlongFirstAxis(arrays, start, stop2 - start);
    }
  }
  function sliceArraysByIndices(arrays, indices) {
    return tidy(() => {
      if (arrays == null) {
        return null;
      } else if (Array.isArray(arrays)) {
        return arrays.map((array2) => sliceArraysByIndices(array2, indices));
      } else {
        return gather2(arrays, indices.dtype === "int32" ? indices : cast(indices, "int32"));
      }
    });
  }
  function makeBatches(size2, batchSize) {
    const output = [];
    let batchStart = 0;
    let batchEnd = null;
    while (batchStart < size2) {
      batchEnd = batchStart + batchSize;
      if (batchEnd >= size2) {
        batchEnd = size2;
      }
      output.push([batchStart, batchEnd]);
      batchStart = batchEnd;
    }
    return output;
  }
  async function fitLoop(model2, f, ins, outLabels, batchSize, epochs, verbose, callbacks2, valF, valIns, shuffle2, callbackMetrics, initialEpoch, stepsPerEpoch, validationSteps) {
    if (batchSize == null) {
      batchSize = 32;
    }
    if (epochs == null) {
      epochs = 1;
    }
    if (shuffle2 == null) {
      shuffle2 = true;
    }
    if (initialEpoch == null) {
      initialEpoch = 0;
    }
    let doValidation = false;
    if (valF != null && valIns != null) {
      doValidation = true;
    }
    if (validationSteps != null) {
      doValidation = true;
      if (stepsPerEpoch == null) {
        throw new ValueError("Can only use `validationSteps` when doing step-wise training, i.e., `stepsPerEpoch` must be set.");
      }
    }
    const numTrainSamples = model2.checkNumSamples(ins, batchSize, stepsPerEpoch, "steps_per_epoch");
    let indexArray;
    if (numTrainSamples != null) {
      indexArray = range2(0, numTrainSamples);
    }
    if (verbose == null) {
      verbose = 1;
    }
    const { callbackList, history } = configureCallbacks(callbacks2, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics);
    callbackList.setModel(model2);
    model2.history = history;
    await callbackList.onTrainBegin();
    model2.stopTraining_ = false;
    for (let epoch = initialEpoch; epoch < epochs; ++epoch) {
      await callbackList.onEpochBegin(epoch);
      const epochLogs = {};
      if (stepsPerEpoch != null) {
        throw new NotImplementedError("stepsPerEpoch mode is not implemented yet.");
      } else {
        if (shuffle2 === "batch") {
          throw new NotImplementedError("batch shuffling is not implemneted yet");
        } else if (shuffle2) {
          util_exports.shuffle(indexArray);
        }
        const epochIndexArray1D = tensor1d(indexArray);
        const batches = makeBatches(numTrainSamples, batchSize);
        for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {
          const batchLogs = {};
          await callbackList.onBatchBegin(batchIndex, batchLogs);
          tidy(() => {
            const batchStart = batches[batchIndex][0];
            const batchEnd = batches[batchIndex][1];
            const batchIds = sliceAlongFirstAxis(epochIndexArray1D, batchStart, batchEnd - batchStart);
            batchLogs["batch"] = batchIndex;
            batchLogs["size"] = batchEnd - batchStart;
            const insBatch = sliceArraysByIndices(ins, batchIds);
            const outs = f(insBatch);
            for (let i = 0; i < outLabels.length; ++i) {
              const label = outLabels[i];
              const out = outs[i];
              batchLogs[label] = out;
              keep(out);
            }
            if (batchIndex === batches.length - 1) {
              if (doValidation) {
                const valOuts = model2.testLoop(valF, valIns, batchSize);
                for (let i = 0; i < outLabels.length; ++i) {
                  const label = outLabels[i];
                  const out = valOuts[i];
                  keep(out);
                  epochLogs["val_" + label] = out;
                }
              }
            }
          });
          await callbackList.onBatchEnd(batchIndex, batchLogs);
          disposeTensorsInLogs(batchLogs);
          if (model2.stopTraining_) {
            break;
          }
        }
        epochIndexArray1D.dispose();
      }
      await callbackList.onEpochEnd(epoch, epochLogs);
      if (model2.stopTraining_) {
        break;
      }
    }
    await callbackList.onTrainEnd();
    await model2.history.syncData();
    return model2.history;
  }
  async function fitTensors(model2, x, y, args = {}) {
    if (model2.isTraining) {
      throw new Error("Cannot start training because another fit() call is ongoing.");
    }
    model2.isTraining = true;
    let inputs;
    let targets;
    let inputValX;
    let inputValY;
    let valX;
    let valY;
    let sampleWeights;
    try {
      const batchSize = args.batchSize == null ? 32 : args.batchSize;
      checkBatchSize(batchSize);
      const checkBatchAxis = false;
      const standardizedOuts = await model2.standardizeUserData(x, y, args.sampleWeight, args.classWeight, checkBatchAxis, batchSize);
      inputs = standardizedOuts[0];
      targets = standardizedOuts[1];
      sampleWeights = standardizedOuts[2];
      let doValidation = false;
      let valIns;
      if (args.validationData != null && args.validationData.length > 0) {
        doValidation = true;
        if (args.validationData.length === 2) {
          inputValX = args.validationData[0];
          inputValY = args.validationData[1];
        } else if (args.validationData.length === 3) {
          throw new NotImplementedError("validationData including sample weights is not supported yet.");
        } else {
          throw new ValueError(`When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; ${args.validationData} is invalid.`);
        }
        const checkBatchAxis2 = true;
        const valStandardized = await model2.standardizeUserData(inputValX, inputValY, null, null, checkBatchAxis2, batchSize);
        valX = valStandardized[0];
        valY = valStandardized[1];
        valIns = valX.concat(valY);
      } else if (args.validationSplit != null && args.validationSplit > 0 && args.validationSplit < 1) {
        doValidation = true;
        const splitAt = Math.floor(inputs[0].shape[0] * (1 - args.validationSplit));
        const originalBatchSize = inputs[0].shape[0];
        valX = sliceArrays(inputs, splitAt, originalBatchSize);
        inputs = sliceArrays(inputs, 0, splitAt);
        valY = sliceArrays(targets, splitAt, originalBatchSize);
        targets = sliceArrays(targets, 0, splitAt);
        valIns = valX.concat(valY);
      } else if (args.validationSteps != null) {
        doValidation = true;
      }
      const ins = inputs.concat(targets).concat(sampleWeights);
      model2.checkTrainableWeightsConsistency();
      const trainFunction = model2.makeTrainFunction();
      const outLabels = model2.getDedupedMetricsNames();
      let valFunction;
      let callbackMetrics;
      if (doValidation) {
        model2.makeTestFunction();
        valFunction = model2.testFunction;
        callbackMetrics = outLabels.slice().concat(outLabels.map((n) => "val_" + n));
      } else {
        valFunction = null;
        valIns = [];
        callbackMetrics = outLabels.slice();
      }
      const callbacks2 = standardizeCallbacks(args.callbacks, args.yieldEvery);
      const out = await fitLoop(model2, trainFunction, ins, outLabels, batchSize, args.epochs, args.verbose, callbacks2, valFunction, valIns, args.shuffle, callbackMetrics, args.initialEpoch, null, null);
      return out;
    } finally {
      model2.isTraining = false;
      disposeNewTensors(inputs, x);
      disposeNewTensors(targets, y);
      disposeNewTensors(valX, inputValX);
      disposeNewTensors(valY, inputValY);
      if (sampleWeights != null) {
        dispose(sampleWeights);
      }
    }
  }
  function ensureTensorsRank2OrHigher(tensors) {
    const outs = [];
    if (tensors instanceof Tensor) {
      tensors = [tensors];
    }
    for (let i = 0; i < tensors.length; ++i) {
      const tensor2 = tensors[i];
      if (tensor2.rank === 1) {
        outs.push(expandDims2(tensor2, 1));
      } else if (tensor2.rank === 0) {
        throw new Error("Expected tensor to be at least 1D, but received a 0D tensor (scalar).");
      } else {
        outs.push(tensor2);
      }
    }
    return outs;
  }
  function disposeNewTensors(tensors, refTensors) {
    if (tensors == null) {
      return;
    }
    const oldTensorIds = [];
    if (refTensors instanceof Tensor) {
      oldTensorIds.push(refTensors.id);
    } else if (Array.isArray(refTensors)) {
      refTensors.forEach((t) => oldTensorIds.push(t.id));
    } else if (refTensors != null) {
      for (const name in refTensors) {
        const oldTensor = refTensors[name];
        oldTensorIds.push(oldTensor.id);
      }
    }
    const tensorsToDispose = [];
    if (tensors instanceof Tensor) {
      if (oldTensorIds.indexOf(tensors.id) === -1) {
        tensorsToDispose.push(tensors);
      }
    } else if (Array.isArray(tensors)) {
      tensors.forEach((t) => {
        if (oldTensorIds.indexOf(t.id) === -1) {
          tensorsToDispose.push(t);
        }
      });
    } else if (tensors != null) {
      for (const name in tensors) {
        const tensor2 = tensors[name];
        if (oldTensorIds.indexOf(tensor2.id) === -1) {
          tensorsToDispose.push(tensor2);
        }
      }
    }
    tensorsToDispose.forEach((t) => {
      if (!t.isDisposed) {
        t.dispose();
      }
    });
  }

  // node_modules/@tensorflow/tfjs-layers/dist/engine/training.js
  function isDataTensor(x) {
    return x instanceof Tensor;
  }
  function isDataArray(x) {
    return Array.isArray(x);
  }
  function isDataDict(x) {
    return !isDataTensor(x) && !isDataArray(x);
  }
  function standardizeInputData(data, names, shapes, checkBatchAxis = true, exceptionPrefix = "") {
    if (names == null || names.length === 0) {
      if (data != null) {
        let gotUnexpectedData = false;
        if (isDataArray(data) && data.length > 0) {
          gotUnexpectedData = true;
        } else if (isDataDict(data)) {
          for (const key in data) {
            if (data.hasOwnProperty(key)) {
              gotUnexpectedData = true;
              break;
            }
          }
        } else {
          gotUnexpectedData = true;
        }
        if (gotUnexpectedData) {
          throw new ValueError(`Error when checking model ${exceptionPrefix} expected no data, but got ${data}`);
        }
      }
      return [];
    }
    if (data == null) {
      return names.map((name) => null);
    }
    let arrays;
    if (isDataDict(data)) {
      data = data;
      arrays = [];
      for (const name of names) {
        if (data[name] == null) {
          throw new ValueError(`No data provided for "${name}". Need data for each key in: ${names}`);
        }
        arrays.push(data[name]);
      }
    } else if (isDataArray(data)) {
      data = data;
      if (data.length !== names.length) {
        throw new ValueError(`Error when checking model ${exceptionPrefix}: the Array of Tensors that you are passing to your model is not the size the model expected. Expected to see ${names.length} Tensor(s), but instead got the following list of Tensor(s): ${data}`);
      }
      arrays = data;
    } else {
      data = data;
      if (names.length > 1) {
        throw new ValueError(`The model ${exceptionPrefix} expects ${names.length} Tensor(s), but only received one Tensor. Found: Tensor with shape ${data.shape}`);
      }
      arrays = [data];
    }
    arrays = ensureTensorsRank2OrHigher(arrays);
    if (shapes != null) {
      for (let i = 0; i < names.length; ++i) {
        if (shapes[i] == null) {
          continue;
        }
        const array2 = arrays[i];
        if (array2.shape.length !== shapes[i].length) {
          throw new ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} to have ${shapes[i].length} dimension(s). but got array with shape ${array2.shape}`);
        }
        for (let j = 0; j < shapes[i].length; ++j) {
          if (j === 0 && !checkBatchAxis) {
            continue;
          }
          const dim = array2.shape[j];
          const refDim = shapes[i][j];
          if (refDim != null && refDim >= 0 && dim !== refDim) {
            throw new ValueError(`${exceptionPrefix} expected a batch of elements where each example has shape [${shapes[i].slice(1, shapes[i].length)}] (i.e.,tensor shape [*,${shapes[i].slice(1, shapes[i].length)}]) but the ${exceptionPrefix} received an input with ${array2.shape[0]} examples, each with shape [${array2.shape.slice(1, array2.shape.length)}] (tensor shape [${array2.shape}])`);
          }
        }
      }
    }
    return arrays;
  }
  function checkArrayLengths(inputs, targets, weights) {
    const setX = unique2(inputs.map((input2) => input2.shape[0]));
    setX.sort();
    const setY = unique2(targets.map((target) => target.shape[0]));
    setY.sort();
    if (setX.length > 1) {
      throw new ValueError(`All input Tensors (x) should have the same number of samples. Got array shapes: ${JSON.stringify(inputs.map((input2) => input2.shape))}`);
    }
    if (setY.length > 1) {
      throw new ValueError(`All target Tensors (y) should have the same number of samples. Got array shapes: ${JSON.stringify(targets.map((target) => target.shape))}`);
    }
    if (setX.length > 0 && setY.length > 0 && !util_exports.arraysEqual(setX, setY)) {
      throw new ValueError(`Input Tensors should have the same number of samples as target Tensors. Found ${setX[0]} input sample(s) and ${setY[0]} target sample(s).`);
    }
  }
  function checkLossAndTargetCompatibility(targets, lossFns, outputShapes) {
    const keyLosses = [
      meanSquaredError,
      binaryCrossentropy,
      categoricalCrossentropy
    ];
    for (let i = 0; i < targets.length; ++i) {
      const y = targets[i];
      const loss = lossFns[i];
      const shape = outputShapes[i];
      if (loss == null) {
        continue;
      }
      if (loss === categoricalCrossentropy) {
        if (y.shape[y.shape.length - 1] === 1) {
          throw new ValueError(`You are passing a target array of shape ${y.shape} while using a loss 'categorical_crossentropy'. 'categorical_crossentropy'expects targets to be binary matrices (1s and 0s) of shape [samples, classes].`);
        }
      }
      if (keyLosses.indexOf(loss) !== -1) {
        const slicedYShape = y.shape.slice(1);
        const slicedShape = shape.slice(1);
        for (let j = 0; j < slicedYShape.length; ++j) {
          const targetDim = slicedYShape[j];
          const outDim = slicedShape[j];
          if (outDim != null && targetDim !== outDim) {
            throw new ValueError(`A target Tensor with shape ${y.shape} was passed for an output of shape ${shape}, while using a loss function that expects targets to have the same shape as the output.`);
          }
        }
      }
    }
  }
  function checkInputData(data, names, shapes, checkBatchAxis = true, exceptionPrefix = "") {
    let arrays;
    if (Array.isArray(data)) {
      if (data.length !== names.length) {
        throw new ValueError(`Error when checking model ${exceptionPrefix}: the Array of Tensors that you are passing to your model is not the size the the model expected. Expected to see ${names.length} Tensor(s), but instead got ${data.length} Tensors(s).`);
      }
      arrays = data;
    } else {
      if (names.length > 1) {
        throw new ValueError(`The model expects ${names.length} ${exceptionPrefix} Tensors, but only received one Tensor. Found: array with shape ${JSON.stringify(data.shape)}.`);
      }
      arrays = [data];
    }
    if (shapes != null) {
      for (let i = 0; i < names.length; ++i) {
        if (shapes[i] == null) {
          continue;
        }
        const array2 = arrays[i];
        if (array2.shape.length !== shapes[i].length) {
          throw new ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} to have ${shapes[i].length} dimension(s), but got array with shape ${JSON.stringify(array2.shape)}`);
        }
        for (let j = 0; j < shapes[i].length; ++j) {
          if (j === 0 && !checkBatchAxis) {
            continue;
          }
          const dim = array2.shape[j];
          const refDim = shapes[i][j];
          if (refDim != null) {
            if (refDim !== dim) {
              throw new ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} to have shape ${JSON.stringify(shapes[i])} but got array with shape ${JSON.stringify(array2.shape)}.`);
            }
          }
        }
      }
    }
  }
  function collectMetrics(metrics2, outputNames) {
    if (metrics2 == null || Array.isArray(metrics2) && metrics2.length === 0) {
      return outputNames.map((name) => []);
    }
    let wrappedMetrics;
    if (typeof metrics2 === "string" || typeof metrics2 === "function") {
      wrappedMetrics = [metrics2];
    } else if (Array.isArray(metrics2) || typeof metrics2 === "object") {
      wrappedMetrics = metrics2;
    } else {
      throw new TypeError(`Type of metrics argument not understood. Expected an string,function, Array, or Object, found: ${metrics2}`);
    }
    if (Array.isArray(wrappedMetrics)) {
      return outputNames.map((name) => wrappedMetrics);
    } else {
      const nestedMetrics = [];
      for (const name of outputNames) {
        let outputMetrics = wrappedMetrics.hasOwnProperty(name) ? wrappedMetrics[name] : [];
        if (!Array.isArray(outputMetrics)) {
          outputMetrics = [outputMetrics];
        }
        nestedMetrics.push(outputMetrics);
      }
      return nestedMetrics;
    }
  }
  var LAYERS_MODEL_FORMAT_NAME = "layers-model";
  var LayersModel = class extends Container {
    constructor(args) {
      super(args);
      this.isTraining = false;
    }
    summary(lineLength, positions, printFn = console.log) {
      if (!this.built) {
        throw new ValueError(`This model has never been called, thus its weights have not been created yet. So no summary can be displayed. Build the model first (e.g., by calling it on some test data).`);
      }
      printSummary(this, lineLength, positions, printFn);
    }
    compile(args) {
      if (args.loss == null) {
        args.loss = [];
      }
      this.loss = args.loss;
      if (typeof args.optimizer === "string") {
        this.optimizer_ = getOptimizer(args.optimizer);
        this.isOptimizerOwned = true;
      } else {
        if (!(args.optimizer instanceof Optimizer)) {
          throw new ValueError(`User-defined optimizer must be an instance of tf.Optimizer.`);
        }
        this.optimizer_ = args.optimizer;
        this.isOptimizerOwned = false;
      }
      let lossFunctions = [];
      if (!Array.isArray(args.loss) && typeof args.loss !== "string" && typeof args.loss !== "function") {
        args.loss = args.loss;
        for (const name in args.loss) {
          if (this.outputNames.indexOf(name) === -1) {
            throw new ValueError(`Unknown entry in loss dictionary: "${name}". Only expected the following keys: ${this.outputNames}`);
          }
        }
        for (const name of this.outputNames) {
          if (args.loss[name] == null) {
            console.warn(`Output "${name}" is missing from loss dictionary. We assume this was done on purpose, and we will not be expecting data to be passed to ${name} during training`);
          }
          lossFunctions.push(get2(args.loss[name]));
        }
      } else if (Array.isArray(args.loss)) {
        if (args.loss.length !== this.outputs.length) {
          throw new ValueError(`When passing an Array as loss, it should have one entry per model output. The model has ${this.outputs.length} output(s), but you passed loss=${args.loss}.`);
        }
        const theLosses = args.loss;
        lossFunctions = theLosses.map((l) => get2(l));
      } else {
        const lossFunction = get2(args.loss);
        this.outputs.forEach((_) => {
          lossFunctions.push(lossFunction);
        });
      }
      this.lossFunctions = lossFunctions;
      this.feedOutputNames = [];
      this.feedOutputShapes = [];
      this.feedLossFns = [];
      for (let i = 0; i < this.outputs.length; ++i) {
        const shape = this.internalOutputShapes[i];
        const name = this.outputNames[i];
        this.feedOutputNames.push(name);
        this.feedOutputShapes.push(shape);
        this.feedLossFns.push(this.lossFunctions[i]);
      }
      const skipTargetIndices = [];
      this.metrics = args.metrics;
      this.metricsNames = ["loss"];
      this.metricsTensors = [];
      nameScope("loss", () => {
        for (let i = 0; i < this.outputs.length; ++i) {
          if (skipTargetIndices.indexOf(i) !== -1) {
            continue;
          }
          const weightedLoss = this.lossFunctions[i];
          if (this.outputs.length > 1) {
            this.metricsTensors.push([weightedLoss, i]);
            this.metricsNames.push(this.outputNames[i] + "_loss");
          }
        }
      });
      const nestedMetrics = collectMetrics(args.metrics, this.outputNames);
      const appendMetric = (outputIndex, metricName, metricTensor) => {
        if (this.outputNames.length > 1) {
          metricName = this.outputNames[outputIndex] + "_" + metricName;
        }
        this.metricsNames.push(metricName);
        this.metricsTensors.push([metricTensor, outputIndex]);
      };
      nameScope("metric", () => {
        for (let i = 0; i < this.outputs.length; ++i) {
          if (skipTargetIndices.indexOf(i) !== -1) {
            continue;
          }
          const outputMetrics = nestedMetrics[i];
          const handleMetrics = (metrics2) => {
            const metricNamePrefix = "";
            let metricName;
            let accFn;
            let weightedMetricFn;
            for (const metric of metrics2) {
              if (typeof metric === "string" && ["accuracy", "acc", "crossentropy", "ce"].indexOf(metric) !== -1) {
                const outputShape = this.internalOutputShapes[i];
                if (outputShape[outputShape.length - 1] === 1 || this.lossFunctions[i] === binaryCrossentropy) {
                  if (["accuracy", "acc"].indexOf(metric) !== -1) {
                    accFn = binaryAccuracy;
                  } else if (["crossentropy", "ce"].indexOf(metric) !== -1) {
                    accFn = binaryCrossentropy2;
                  }
                } else if (this.lossFunctions[i] === sparseCategoricalCrossentropy) {
                  if (["accuracy", "acc"].indexOf(metric) !== -1) {
                    accFn = sparseCategoricalAccuracy;
                  } else if (["crossentropy", "ce"].indexOf(metric) !== -1) {
                    accFn = sparseCategoricalCrossentropy2;
                  }
                } else {
                  if (["accuracy", "acc"].indexOf(metric) !== -1) {
                    accFn = categoricalAccuracy;
                  } else if (["crossentropy", "ce"].indexOf(metric) !== -1) {
                    accFn = categoricalCrossentropy2;
                  }
                }
                let suffix;
                if (["accuracy", "acc"].indexOf(metric) !== -1) {
                  suffix = "acc";
                } else if (["crossentropy", "ce"].indexOf(metric) !== -1) {
                  suffix = "ce";
                }
                weightedMetricFn = accFn;
                metricName = metricNamePrefix + suffix;
              } else {
                const metricFn = get3(metric);
                weightedMetricFn = metricFn;
                metricName = metricNamePrefix + getLossOrMetricName(metric);
              }
              let metricResult;
              nameScope(metricName, () => {
                metricResult = weightedMetricFn;
              });
              appendMetric(i, metricName, metricResult);
            }
          };
          handleMetrics(outputMetrics);
        }
      });
      this.collectedTrainableWeights = this.trainableWeights;
    }
    checkTrainableWeightsConsistency() {
      if (this.collectedTrainableWeights == null) {
        return;
      }
      if (this.trainableWeights.length !== this.collectedTrainableWeights.length) {
        console.warn("Discrepancy between trainableweights and collected trainable weights. Did you set `model.trainable` without calling `model.compile()` afterwards?");
      }
    }
    evaluate(x, y, args = {}) {
      const batchSize = args.batchSize == null ? 32 : args.batchSize;
      checkBatchSize(batchSize);
      const checkBatchAxis = true;
      const standardizedOuts = this.standardizeUserDataXY(x, y, checkBatchAxis, batchSize);
      try {
        const ins = standardizedOuts[0].concat(standardizedOuts[1]);
        this.makeTestFunction();
        const f = this.testFunction;
        const testOuts = this.testLoop(f, ins, batchSize, args.verbose, args.steps);
        return singletonOrArray(testOuts);
      } finally {
        disposeNewTensors(standardizedOuts[0], x);
        disposeNewTensors(standardizedOuts[1], y);
      }
    }
    async evaluateDataset(dataset, args) {
      this.makeTestFunction();
      return evaluateDataset(this, dataset, args);
    }
    checkNumSamples(ins, batchSize, steps, stepsName = "steps") {
      let numSamples;
      if (steps != null) {
        numSamples = null;
        if (batchSize != null) {
          throw new ValueError(`If ${stepsName} is set, batchSize must be null or undefined.Got batchSize = ${batchSize}`);
        }
      } else if (ins != null) {
        if (Array.isArray(ins)) {
          numSamples = ins[0].shape[0];
        } else {
          numSamples = ins.shape[0];
        }
      } else {
        throw new ValueError(`Either the input data should have a defined shape, or ${stepsName} shoud be specified.`);
      }
      return numSamples;
    }
    execute(inputs, outputs) {
      if (Array.isArray(outputs) && outputs.length === 0) {
        throw new ValueError("`outputs` is an empty Array, which is not allowed.");
      }
      const outputsIsArray = Array.isArray(outputs);
      const outputNames = outputsIsArray ? outputs : [outputs];
      const outputSymbolicTensors = this.retrieveSymbolicTensors(outputNames);
      const feedDict = new FeedDict();
      if (inputs instanceof Tensor) {
        inputs = [inputs];
      }
      if (Array.isArray(inputs)) {
        if (inputs.length !== this.inputs.length) {
          throw new ValueError(`The number of inputs provided (${inputs.length}) does not match the number of inputs of this model (${this.inputs.length}).`);
        }
        for (let i = 0; i < this.inputs.length; ++i) {
          feedDict.add(this.inputs[i], inputs[i]);
        }
      } else {
        for (const input2 of this.inputs) {
          const tensorValue = inputs[input2.name];
          if (tensorValue == null) {
            throw new ValueError(`No value is provided for the model's input ${input2.name}`);
          }
          feedDict.add(input2, tensorValue);
        }
      }
      const executeOutputs = execute(outputSymbolicTensors, feedDict);
      return outputsIsArray ? executeOutputs : executeOutputs[0];
    }
    retrieveSymbolicTensors(symbolicTensorNames) {
      const outputSymbolicTensors = pyListRepeat(null, symbolicTensorNames.length);
      let outputsRemaining = symbolicTensorNames.length;
      for (const layer of this.layers) {
        const layerOutputs = Array.isArray(layer.output) ? layer.output : [layer.output];
        const layerOutputNames = layerOutputs.map((output) => output.name);
        for (let i = 0; i < symbolicTensorNames.length; ++i) {
          const index = layerOutputNames.indexOf(symbolicTensorNames[i]);
          if (index !== -1) {
            outputSymbolicTensors[i] = layerOutputs[index];
            outputsRemaining--;
          }
          if (outputsRemaining === 0) {
            break;
          }
        }
        if (outputsRemaining === 0) {
          break;
        }
      }
      if (outputsRemaining > 0) {
        const remainingNames = [];
        outputSymbolicTensors.forEach((tensor2, i) => {
          if (tensor2 == null) {
            remainingNames.push(symbolicTensorNames[i]);
          }
        });
        throw new ValueError(`Cannot find SymbolicTensors for output name(s): ${JSON.stringify(remainingNames)}`);
      }
      return outputSymbolicTensors;
    }
    predictLoop(ins, batchSize = 32, verbose = false) {
      return tidy(() => {
        const numSamples = this.checkNumSamples(ins);
        if (verbose) {
          throw new NotImplementedError("Verbose predictLoop() is not implemented yet.");
        }
        const batches = makeBatches(numSamples, batchSize);
        const outsBatches = this.outputs.map((output) => []);
        for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {
          const batchOuts = tidy(() => {
            const batchStart = batches[batchIndex][0];
            const batchEnd = batches[batchIndex][1];
            const insBatch = sliceArrays(ins, batchStart, batchEnd);
            const feeds = [];
            if (Array.isArray(insBatch)) {
              for (let i = 0; i < insBatch.length; ++i) {
                feeds.push({ key: this.inputs[i], value: insBatch[i] });
              }
            } else {
              feeds.push({ key: this.inputs[0], value: insBatch });
            }
            const feedDict = new FeedDict(feeds);
            return execute(this.outputs, feedDict);
          });
          batchOuts.forEach((batchOut, i) => outsBatches[i].push(batchOut));
        }
        return singletonOrArray(outsBatches.map((batches2) => concat(batches2, 0)));
      });
    }
    predict(x, args = {}) {
      const xsRank2OrHigher = ensureTensorsRank2OrHigher(x);
      checkInputData(xsRank2OrHigher, this.inputNames, this.feedInputShapes, false);
      try {
        const batchSize = args.batchSize == null ? 32 : args.batchSize;
        checkBatchSize(batchSize);
        return this.predictLoop(xsRank2OrHigher, batchSize);
      } finally {
        disposeNewTensors(xsRank2OrHigher, x);
      }
    }
    predictOnBatch(x) {
      checkInputData(x, this.inputNames, this.feedInputShapes, true);
      const batchSize = (Array.isArray(x) ? x[0] : x).shape[0];
      return this.predictLoop(x, batchSize);
    }
    standardizeUserDataXY(x, y, checkBatchAxis = true, batchSize) {
      if (this.optimizer_ == null) {
        throw new RuntimeError("You must compile a model before training/testing. Use LayersModel.compile(modelCompileArgs).");
      }
      const outputShapes = [];
      for (let i = 0; i < this.feedOutputShapes.length; ++i) {
        const outputShape = this.feedOutputShapes[i];
        const lossFn = this.feedLossFns[i];
        if (lossFn === sparseCategoricalCrossentropy) {
          outputShapes.push(outputShape.slice(0, outputShape.length - 1).concat([1]));
        } else {
          outputShapes.push(outputShape);
        }
      }
      x = standardizeInputData(x, this.feedInputNames, this.feedInputShapes, false, "input");
      y = standardizeInputData(y, this.feedOutputNames, outputShapes, false, "target");
      checkArrayLengths(x, y, null);
      checkLossAndTargetCompatibility(y, this.feedLossFns, this.feedOutputShapes);
      if (this.stateful && batchSize != null && batchSize > 0) {
        if (x[0].shape[0] % batchSize !== 0) {
          throw new ValueError(`In a stateful network, you should only pass inputs with a number of samples that is divisible by the batch size ${batchSize}. Found: ${x[0].shape[0]} sample(s).`);
        }
      }
      return [x, y];
    }
    async standardizeUserData(x, y, sampleWeight, classWeight, checkBatchAxis = true, batchSize) {
      const [standardXs, standardYs] = this.standardizeUserDataXY(x, y, checkBatchAxis, batchSize);
      if (sampleWeight != null) {
        throw new Error("sample weight is not supported yet.");
      }
      let standardSampleWeights = null;
      if (classWeight != null) {
        const classWeights = standardizeClassWeights(classWeight, this.outputNames);
        standardSampleWeights = [];
        for (let i = 0; i < classWeights.length; ++i) {
          standardSampleWeights.push(await standardizeWeights(standardYs[i], null, classWeights[i]));
        }
      }
      return [standardXs, standardYs, standardSampleWeights];
    }
    testLoop(f, ins, batchSize, verbose = 0, steps) {
      return tidy(() => {
        const numSamples = this.checkNumSamples(ins, batchSize, steps, "steps");
        const outs = [];
        if (verbose > 0) {
          throw new NotImplementedError("Verbose mode is not implemented yet.");
        }
        if (steps != null) {
          throw new NotImplementedError("steps mode in testLoop() is not implemented yet");
        } else {
          const batches = makeBatches(numSamples, batchSize);
          const indexArray = tensor1d(range2(0, numSamples));
          for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {
            const batchStart = batches[batchIndex][0];
            const batchEnd = batches[batchIndex][1];
            const batchIds = sliceAlongFirstAxis(indexArray, batchStart, batchEnd - batchStart);
            const insBatch = sliceArraysByIndices(ins, batchIds);
            const batchOuts = f(insBatch);
            if (batchIndex === 0) {
              for (let i = 0; i < batchOuts.length; ++i) {
                outs.push(scalar(0));
              }
            }
            for (let i = 0; i < batchOuts.length; ++i) {
              const batchOut = batchOuts[i];
              outs[i] = add3(outs[i], mul(batchEnd - batchStart, batchOut));
            }
          }
          for (let i = 0; i < outs.length; ++i) {
            outs[i] = div(outs[i], numSamples);
          }
        }
        return outs;
      });
    }
    getDedupedMetricsNames() {
      const outLabels = this.metricsNames;
      const dedupedOutLabels = [];
      for (let i = 0; i < outLabels.length; ++i) {
        const label = outLabels[i];
        let newLabel = label;
        if (count(outLabels, label) > 1) {
          const dupIndex = count(outLabels.slice(0, i), label);
          newLabel += `_${dupIndex}`;
        }
        dedupedOutLabels.push(newLabel);
      }
      return dedupedOutLabels;
    }
    makeTrainFunction() {
      return (data) => {
        const lossValues = [];
        const inputs = data.slice(0, this.inputs.length);
        const targets = data.slice(this.inputs.length, this.inputs.length + this.outputs.length);
        const sampleWeights = data.slice(this.inputs.length + this.outputs.length, this.inputs.length + this.outputs.length * 2);
        const metricsValues = [];
        const totalLossFunction = () => {
          const feeds = [];
          for (let i = 0; i < this.inputs.length; ++i) {
            feeds.push({ key: this.inputs[i], value: inputs[i] });
          }
          const feedDict = new FeedDict(feeds);
          const outputs = execute(this.outputs, feedDict, { "training": true });
          let totalLoss;
          for (let i = 0; i < this.lossFunctions.length; ++i) {
            const lossFunction = this.lossFunctions[i];
            let loss = lossFunction(targets[i], outputs[i]);
            if (sampleWeights[i] != null) {
              loss = computeWeightedLoss(loss, sampleWeights[i]);
            }
            const meanLoss = mean(loss);
            lossValues.push(meanLoss);
            if (i === 0) {
              totalLoss = loss;
            } else {
              totalLoss = add3(totalLoss, loss);
            }
          }
          for (let i = 0; i < this.metricsTensors.length; ++i) {
            let weightedMetric;
            if (this.outputs.length > 1 && i < this.outputs.length) {
              weightedMetric = lossValues[i];
            } else {
              const metric = this.metricsTensors[i][0];
              const outputIndex = this.metricsTensors[i][1];
              weightedMetric = mean(metric(targets[outputIndex], outputs[outputIndex]));
            }
            keep(weightedMetric);
            metricsValues.push(weightedMetric);
          }
          totalLoss = mean(totalLoss);
          this.calculateLosses().forEach((regularizerLoss) => {
            totalLoss = add3(totalLoss, regularizerLoss);
          });
          return totalLoss;
        };
        const variables = this.collectedTrainableWeights.map((param) => param.read());
        const returnCost = true;
        const totalLossValue = this.optimizer_.minimize(totalLossFunction, returnCost, variables);
        return [totalLossValue].concat(metricsValues);
      };
    }
    makeTestFunction() {
      this.testFunction = (data) => {
        return tidy(() => {
          const valOutputs = [];
          let totalLoss;
          const inputs = data.slice(0, this.inputs.length);
          const targets = data.slice(this.inputs.length, this.inputs.length + this.outputs.length);
          const feeds = [];
          for (let i = 0; i < this.inputs.length; ++i) {
            feeds.push({ key: this.inputs[i], value: inputs[i] });
          }
          const feedDict = new FeedDict(feeds);
          const outputs = execute(this.outputs, feedDict);
          for (let i = 0; i < this.lossFunctions.length; ++i) {
            const lossFunction = this.lossFunctions[i];
            const loss = mean(lossFunction(targets[i], outputs[i]));
            if (i === 0) {
              totalLoss = loss;
            } else {
              totalLoss = add3(totalLoss, loss);
            }
            valOutputs.push(totalLoss);
          }
          for (let i = 0; i < this.metricsTensors.length; ++i) {
            const metric = this.metricsTensors[i][0];
            const outputIndex = this.metricsTensors[i][1];
            const meanMetric = mean(metric(targets[outputIndex], outputs[outputIndex]));
            valOutputs.push(meanMetric);
          }
          return valOutputs;
        });
      };
    }
    async fit(x, y, args = {}) {
      return fitTensors(this, x, y, args);
    }
    async fitDataset(dataset, args) {
      return fitDataset(this, dataset, args);
    }
    async trainOnBatch(x, y) {
      const standardizeOut = await this.standardizeUserData(x, y);
      const inputs = standardizeOut[0];
      const targets = standardizeOut[1];
      const trainFunction = this.makeTrainFunction();
      const losses3 = trainFunction(inputs.concat(targets));
      const lossValues = [];
      for (const loss of losses3) {
        const v = await loss.data();
        lossValues.push(v[0]);
      }
      dispose(losses3);
      return singletonOrArray(lossValues);
    }
    getNamedWeights(config) {
      const namedWeights = [];
      const trainableOnly = config != null && config.trainableOnly;
      const weights = trainableOnly ? this.trainableWeights : this.weights;
      const weightValues = this.getWeights(trainableOnly);
      for (let i = 0; i < weights.length; ++i) {
        if (trainableOnly && !weights[i].trainable) {
          continue;
        }
        namedWeights.push({ name: weights[i].originalName, tensor: weightValues[i] });
      }
      return namedWeights;
    }
    set stopTraining(stop2) {
      this.stopTraining_ = stop2;
    }
    get stopTraining() {
      return this.stopTraining_;
    }
    get optimizer() {
      return this.optimizer_;
    }
    set optimizer(optimizer) {
      if (this.optimizer_ !== optimizer) {
        this.optimizer_ = optimizer;
        this.isOptimizerOwned = false;
      }
    }
    dispose() {
      const result = super.dispose();
      if (result.refCountAfterDispose === 0 && this.optimizer != null && this.isOptimizerOwned) {
        const numTensorsBeforeOptmizerDisposal = memory().numTensors;
        this.optimizer_.dispose();
        result.numDisposedVariables += numTensorsBeforeOptmizerDisposal - memory().numTensors;
      }
      return result;
    }
    getLossIdentifiers() {
      let lossNames;
      if (typeof this.loss === "string") {
        lossNames = toSnakeCase(this.loss);
      } else if (Array.isArray(this.loss)) {
        for (const loss of this.loss) {
          if (typeof loss !== "string") {
            throw new Error("Serialization of non-string loss is not supported.");
          }
        }
        lossNames = this.loss.map((name) => toSnakeCase(name));
      } else {
        const outputNames = Object.keys(this.loss);
        lossNames = {};
        const losses3 = this.loss;
        for (const outputName of outputNames) {
          if (typeof losses3[outputName] === "string") {
            lossNames[outputName] = toSnakeCase(losses3[outputName]);
          } else {
            throw new Error("Serialization of non-string loss is not supported.");
          }
        }
      }
      return lossNames;
    }
    getMetricIdentifiers() {
      if (typeof this.metrics === "string" || typeof this.metrics === "function") {
        return [toSnakeCase(getLossOrMetricName(this.metrics))];
      } else if (Array.isArray(this.metrics)) {
        return this.metrics.map((metric) => toSnakeCase(getLossOrMetricName(metric)));
      } else {
        const metricsIdentifiers = {};
        for (const key in this.metrics) {
          metricsIdentifiers[key] = toSnakeCase(getLossOrMetricName(this.metrics[key]));
        }
        return metricsIdentifiers;
      }
    }
    getTrainingConfig() {
      return {
        loss: this.getLossIdentifiers(),
        metrics: this.getMetricIdentifiers(),
        optimizer_config: {
          class_name: this.optimizer.getClassName(),
          config: this.optimizer.getConfig()
        }
      };
    }
    loadTrainingConfig(trainingConfig) {
      if (trainingConfig.weighted_metrics != null) {
        throw new Error("Loading weight_metrics is not supported yet.");
      }
      if (trainingConfig.loss_weights != null) {
        throw new Error("Loading loss_weights is not supported yet.");
      }
      if (trainingConfig.sample_weight_mode != null) {
        throw new Error("Loading sample_weight_mode is not supported yet.");
      }
      const tsConfig = convertPythonicToTs(trainingConfig.optimizer_config);
      const optimizer = deserialize(tsConfig);
      let loss;
      if (typeof trainingConfig.loss === "string") {
        loss = toCamelCase(trainingConfig.loss);
      } else if (Array.isArray(trainingConfig.loss)) {
        loss = trainingConfig.loss.map((lossEntry) => toCamelCase(lossEntry));
      } else if (trainingConfig.loss != null) {
        loss = {};
        for (const key in trainingConfig.loss) {
          loss[key] = toCamelCase(trainingConfig.loss[key]);
        }
      }
      let metrics2;
      if (Array.isArray(trainingConfig.metrics)) {
        metrics2 = trainingConfig.metrics.map((metric) => toCamelCase(metric));
      } else if (trainingConfig.metrics != null) {
        metrics2 = {};
        for (const key in trainingConfig.metrics) {
          metrics2[key] = toCamelCase(trainingConfig.metrics[key]);
        }
      }
      this.compile({ loss, metrics: metrics2, optimizer });
    }
    async save(handlerOrURL, config) {
      if (typeof handlerOrURL === "string") {
        const handlers = io_exports.getSaveHandlers(handlerOrURL);
        if (handlers.length === 0) {
          throw new ValueError(`Cannot find any save handlers for URL '${handlerOrURL}'`);
        } else if (handlers.length > 1) {
          throw new ValueError(`Found more than one (${handlers.length}) save handlers for URL '${handlerOrURL}'`);
        }
        handlerOrURL = handlers[0];
      }
      if (handlerOrURL.save == null) {
        throw new ValueError("LayersModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");
      }
      const weightDataAndSpecs = await io_exports.encodeWeights(this.getNamedWeights(config));
      const returnString = false;
      const unusedArg = null;
      const modelConfig = this.toJSON(unusedArg, returnString);
      const modelArtifacts = {
        modelTopology: modelConfig,
        format: LAYERS_MODEL_FORMAT_NAME,
        generatedBy: `TensorFlow.js tfjs-layers v${version2}`,
        convertedBy: null
      };
      const includeOptimizer = config == null ? false : config.includeOptimizer;
      if (includeOptimizer && this.optimizer != null) {
        modelArtifacts.trainingConfig = this.getTrainingConfig();
        const weightType = "optimizer";
        const { data: optimizerWeightData, specs: optimizerWeightSpecs } = await io_exports.encodeWeights(await this.optimizer.getWeights(), weightType);
        weightDataAndSpecs.specs.push(...optimizerWeightSpecs);
        weightDataAndSpecs.data = io_exports.concatenateArrayBuffers([weightDataAndSpecs.data, optimizerWeightData]);
      }
      if (this.userDefinedMetadata != null) {
        const checkSize = true;
        checkUserDefinedMetadata(this.userDefinedMetadata, this.name, checkSize);
        modelArtifacts.userDefinedMetadata = this.userDefinedMetadata;
      }
      modelArtifacts.weightData = weightDataAndSpecs.data;
      modelArtifacts.weightSpecs = weightDataAndSpecs.specs;
      return handlerOrURL.save(modelArtifacts);
    }
    setUserDefinedMetadata(userDefinedMetadata) {
      checkUserDefinedMetadata(userDefinedMetadata, this.name);
      this.userDefinedMetadata = userDefinedMetadata;
    }
    getUserDefinedMetadata() {
      return this.userDefinedMetadata;
    }
  };
  LayersModel.className = "Model";
  serialization_exports.registerClass(LayersModel);
  var Functional = class extends LayersModel {
  };
  Functional.className = "Functional";
  serialization_exports.registerClass(Functional);

  // node_modules/@tensorflow/tfjs-layers/dist/models.js
  var Sequential = class extends LayersModel {
    constructor(args) {
      super({ inputs: [], outputs: [] });
      args = args || {};
      this.trainable = true;
      this.built = false;
      this.name = args.name != null ? args.name : getUid("sequential_");
      if (args.layers != null) {
        for (const layer of args.layers) {
          this.add(layer);
        }
      }
    }
    checkShape(layer) {
      const shape = layer.inboundNodes[0].outputTensors[0].shape;
      if (shape.some((x) => x < 0)) {
        throw new ValueError(`Negative dimension size caused by adding layer ${layer.name} with input shape [${layer.inboundNodes[0].inputTensors[0].shape}]`);
      }
    }
    add(layer) {
      const isLayerModelInstance = layer instanceof Sequential || layer instanceof LayersModel;
      let modelLayer;
      if (isLayerModelInstance) {
        modelLayer = layer;
        if (modelLayer.outputs.length !== 1) {
          throw new ValueError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
        }
        if (modelLayer.inputs.length !== 1) {
          throw new ValueError("All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.");
        }
      }
      if (this.outputs.length === 0) {
        if (layer.inboundNodes.length === 0) {
          if (layer.batchInputShape == null) {
            throw new ValueError("The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.");
          }
          const x = Input({
            batchShape: layer.batchInputShape,
            dtype: layer.dtype,
            name: layer.name + "_input"
          });
          layer.apply(x);
        }
        if (isLayerModelInstance) {
          this.outputs = modelLayer.outputs;
          this.inputs = modelLayer.inputs;
        } else {
          if (layer.inboundNodes.length !== 1) {
            throw new ValueError(`A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer ${layer.name} which has ${layer.inboundNodes.length} pre-existing inbound connections.`);
          }
          if (layer.inboundNodes[0].outputTensors.length !== 1) {
            throw new ValueError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
          }
          this.checkShape(layer);
          this.outputs = [layer.inboundNodes[0].outputTensors[0]];
          this.inputs = getSourceInputs(this.outputs[0]);
        }
        this.inboundNodes = [];
        new Node({
          outboundLayer: this,
          inboundLayers: [],
          nodeIndices: [],
          tensorIndices: [],
          inputTensors: this.inputs,
          outputTensors: this.outputs,
          inputMasks: pyListRepeat(null, this.inputs.length),
          outputMasks: [null],
          inputShapes: this.inputs.map((x) => x.shape),
          outputShapes: this.outputs[0].shape
        });
      } else {
        const outputTensor = layer.apply(this.outputs[0]);
        if (Array.isArray(outputTensor)) {
          throw new TypeError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
        }
        this.checkShape(layer);
        this.outputs = [outputTensor];
        this.inboundNodes[0].outputTensors = this.outputs;
        this.inboundNodes[0].outputShapes = [this.outputs[0].shape];
      }
      this.layers.push(layer);
      this.built = false;
    }
    pop() {
      if (this.layers.length === 0) {
        throw new TypeError("There are no layers in the model.");
      }
      this.layers.pop();
      if (this.layers.length === 0) {
        this.outputs = [];
        this.inboundNodes = [];
        this.outboundNodes = [];
      } else {
        const lastLayerIndex = this.layers.length - 1;
        this.layers[lastLayerIndex].outboundNodes = [];
        this.outputs = [this.layers[lastLayerIndex].output];
        this.inboundNodes[0].outputTensors = this.outputs;
        this.inboundNodes[0].outputShapes = [this.outputs[0].shape];
      }
    }
    call(inputs, kwargs) {
      if (this.model == null) {
        this.build();
      }
      return this.model.call(inputs, kwargs);
    }
    build(inputShape) {
      getExactlyOneShape(inputShape);
      if (this.inputs.length === 0 || this.outputs.length === 0) {
        throw new TypeError("Sequential model cannot be built: model is empty. Add some layers first.");
      }
      this.model = new LayersModel({
        inputs: this.inputs,
        outputs: this.outputs[0],
        name: this.name + "_model"
      });
      this.model.trainable = this.trainable;
      this.supportsMasking = this.model.supportsMasking;
      this.inputLayers = this.model.inputLayers;
      this.inputLayersNodeIndices = this.model.inputLayersNodeIndices;
      this.inputLayersTensorIndices = this.model.inputLayersTensorIndices;
      this.outputLayers = this.model.outputLayers;
      this.outputLayersNodeIndices = this.model.outputLayersNodeIndices;
      this.outputLayersTensorIndices = this.model.outputLayersTensorIndices;
      this.nodesByDepth = this.model.nodesByDepth;
      this.containerNodes = this.model.containerNodes;
      this.outputNames = this.model.outputNames;
      this.inputNames = this.model.inputNames;
      this.built = true;
    }
    countParams() {
      if (!this.built) {
        this.build();
      }
      return super.countParams();
    }
    summary(lineLength, positions, printFn = console.log) {
      if (!this.built) {
        this.build();
      }
      super.summary(lineLength, positions, printFn);
    }
    setWeights(weights) {
      if (this.model == null) {
        this.build();
      }
      this.model.setWeights(weights);
    }
    evaluate(x, y, args = {}) {
      if (!this.built) {
        throw new RuntimeError("The model needs to be compiled before being used.");
      }
      return this.model.evaluate(x, y, args);
    }
    async evaluateDataset(dataset, args) {
      if (!this.built) {
        throw new RuntimeError("The model needs to be compiled before being used.");
      }
      return this.model.evaluateDataset(dataset, args);
    }
    predict(x, args = {}) {
      if (this.model == null) {
        this.build();
      }
      return this.model.predict(x, args);
    }
    predictOnBatch(x) {
      if (this.model == null) {
        this.build();
      }
      return this.model.predictOnBatch(x);
    }
    compile(args) {
      this.build();
      this.model.compile(args);
      this.optimizer_ = this.model.optimizer;
      this.isOptimizerOwned = this.model.isOptimizerOwned;
      this.loss = this.model.loss;
      this.metrics = this.model.metrics;
      this.metricsTensors = this.model.metricsTensors;
      this.metricsNames = this.model.metricsNames;
    }
    get optimizer() {
      return this.model == null ? void 0 : this.model.optimizer;
    }
    set optimizer(optimizer) {
      this.model.optimizer = optimizer;
    }
    async fit(x, y, args = {}) {
      if (!this.built) {
        throw new RuntimeError("The model needs to be compiled before being used.");
      }
      return this.model.fit(x, y, args);
    }
    async fitDataset(dataset, args) {
      if (!this.built) {
        throw new RuntimeError("The model needs to be compiled before being used.");
      }
      return this.model.fitDataset(dataset, args);
    }
    async trainOnBatch(x, y) {
      return this.model.trainOnBatch(x, y);
    }
    static fromConfig(cls, config, customObjects = {}, fastWeightInit = false) {
      let configArray;
      let extraModelConfig = {};
      if (config instanceof Array) {
        if (!(config[0].className != null) || config[0]["className"] === "Merge") {
          throw new ValueError("Legacy serialization format not supported yet.");
        }
        configArray = config;
      } else {
        util_exports.assert(config["layers"] != null, () => `When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field.`);
        configArray = config["layers"];
        delete config["layers"];
        extraModelConfig = config;
      }
      const model2 = new cls(extraModelConfig);
      if (!(model2 instanceof Sequential)) {
        throw new NotImplementedError(`Sequential.fromConfig called on non-Sequential input: ${model2}`);
      }
      for (const conf of configArray) {
        const customObjects2 = void 0;
        const layer = deserialize(conf, customObjects2, fastWeightInit);
        if (fastWeightInit) {
          layer.setFastWeightInitDuringBuild(true);
        }
        model2.add(layer);
      }
      return model2;
    }
    set stopTraining(stop2) {
      if (this.model == null) {
        throw new ValueError("Cannot set the stopTraining property of a sequential model before it is compiled.");
      }
      this.model.stopTraining = stop2;
    }
    get stopTraining() {
      if (this.model == null) {
        throw new ValueError("Cannot get the stopTraining property of a sequential model before it is compiled.");
      }
      return this.model.stopTraining;
    }
    getConfig() {
      const layers = [];
      for (const layer of this.layers) {
        const dict = {};
        dict["className"] = layer.getClassName();
        dict["config"] = layer.getConfig();
        layers.push(dict);
      }
      return { name: this.name, layers };
    }
  };
  Sequential.className = "Sequential";
  serialization_exports.registerClass(Sequential);

  // node_modules/@tensorflow/tfjs-layers/dist/activations.js
  var Activation = class extends serialization_exports.Serializable {
    getConfig() {
      return {};
    }
  };
  var Elu2 = class extends Activation {
    apply(x, alpha = 1) {
      return elu2(x, alpha);
    }
  };
  Elu2.className = "elu";
  serialization_exports.registerClass(Elu2);
  var Selu2 = class extends Activation {
    apply(x) {
      return selu(x);
    }
  };
  Selu2.className = "selu";
  serialization_exports.registerClass(Selu2);
  var Relu2 = class extends Activation {
    apply(x) {
      return relu(x);
    }
  };
  Relu2.className = "relu";
  serialization_exports.registerClass(Relu2);
  var Relu62 = class extends Activation {
    apply(x) {
      return tidy(() => minimum(6, relu(x)));
    }
  };
  Relu62.className = "relu6";
  serialization_exports.registerClass(Relu62);
  var Linear = class extends Activation {
    apply(x) {
      return x;
    }
  };
  Linear.className = "linear";
  serialization_exports.registerClass(Linear);
  var Sigmoid2 = class extends Activation {
    apply(x) {
      return sigmoid(x);
    }
  };
  Sigmoid2.className = "sigmoid";
  serialization_exports.registerClass(Sigmoid2);
  var HardSigmoid = class extends Activation {
    apply(x) {
      return hardSigmoid(x);
    }
  };
  HardSigmoid.className = "hardSigmoid";
  serialization_exports.registerClass(HardSigmoid);
  var Softplus2 = class extends Activation {
    apply(x) {
      return softplus(x);
    }
  };
  Softplus2.className = "softplus";
  serialization_exports.registerClass(Softplus2);
  var Softsign = class extends Activation {
    apply(x) {
      return softsign(x);
    }
  };
  Softsign.className = "softsign";
  serialization_exports.registerClass(Softsign);
  var Tanh2 = class extends Activation {
    apply(x) {
      return tanh2(x);
    }
  };
  Tanh2.className = "tanh";
  serialization_exports.registerClass(Tanh2);
  var Softmax2 = class extends Activation {
    apply(x, axis = -1) {
      return softmax(x, axis);
    }
  };
  Softmax2.className = "softmax";
  serialization_exports.registerClass(Softmax2);
  var LogSoftmax2 = class extends Activation {
    apply(x, axis = -1) {
      return logSoftmax(x, axis);
    }
  };
  LogSoftmax2.className = "logSoftmax";
  serialization_exports.registerClass(LogSoftmax2);
  var Swish = class extends Activation {
    apply(x, alpha = 1) {
      return tidy(() => mul(sigmoid(mul(x, alpha)), x));
    }
  };
  Swish.className = "swish";
  serialization_exports.registerClass(Swish);
  var Mish = class extends Activation {
    apply(x) {
      return tidy(() => mul(x, tanh2(softplus(x))));
    }
  };
  Mish.className = "mish";
  serialization_exports.registerClass(Mish);
  function serializeActivation(activation) {
    return activation.getClassName();
  }
  function deserializeActivation(config, customObjects = {}) {
    return deserializeKerasObject(config, serialization_exports.SerializationMap.getMap().classNameMap, customObjects, "activation");
  }
  function getActivation(identifier) {
    if (identifier == null) {
      const config = {};
      config["className"] = "linear";
      config["config"] = {};
      return deserializeActivation(config);
    }
    if (typeof identifier === "string") {
      const config = {};
      config["className"] = identifier;
      config["config"] = {};
      return deserializeActivation(config);
    } else if (identifier instanceof Activation) {
      return identifier;
    } else {
      return deserializeActivation(identifier);
    }
  }

  // node_modules/@tensorflow/tfjs-layers/dist/regularizers.js
  function assertObjectArgs(args) {
    if (args != null && typeof args !== "object") {
      throw new Error(`Argument to L1L2 regularizer's constructor is expected to be an object, but received: ${args}`);
    }
  }
  var Regularizer = class extends serialization_exports.Serializable {
  };
  var L1L2 = class extends Regularizer {
    constructor(args) {
      super();
      assertObjectArgs(args);
      this.l1 = args == null || args.l1 == null ? 0.01 : args.l1;
      this.l2 = args == null || args.l2 == null ? 0.01 : args.l2;
      this.hasL1 = this.l1 !== 0;
      this.hasL2 = this.l2 !== 0;
    }
    apply(x) {
      return tidy(() => {
        let regularization = zeros([1]);
        if (this.hasL1) {
          regularization = add3(regularization, sum2(mul(this.l1, abs(x))));
        }
        if (this.hasL2) {
          regularization = add3(regularization, sum2(mul(this.l2, square2(x))));
        }
        return reshape(regularization, []);
      });
    }
    getConfig() {
      return { "l1": this.l1, "l2": this.l2 };
    }
    static fromConfig(cls, config) {
      return new cls({ l1: config["l1"], l2: config["l2"] });
    }
  };
  L1L2.className = "L1L2";
  serialization_exports.registerClass(L1L2);
  var REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP = {
    "l1l2": "L1L2"
  };
  function serializeRegularizer(constraint) {
    return serializeKerasObject(constraint);
  }
  function deserializeRegularizer(config, customObjects = {}) {
    return deserializeKerasObject(config, serialization_exports.SerializationMap.getMap().classNameMap, customObjects, "regularizer");
  }
  function getRegularizer(identifier) {
    if (identifier == null) {
      return null;
    }
    if (typeof identifier === "string") {
      const className = identifier in REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP ? REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier] : identifier;
      const config = { className, config: {} };
      return deserializeRegularizer(config);
    } else if (identifier instanceof Regularizer) {
      return identifier;
    } else {
      return deserializeRegularizer(identifier);
    }
  }

  // node_modules/@tensorflow/tfjs-layers/dist/layers/advanced_activations.js
  var ReLU = class extends Layer {
    constructor(args) {
      super(args == null ? {} : args);
      this.supportsMasking = true;
      if (args != null) {
        this.maxValue = args.maxValue;
      }
    }
    call(inputs, kwargs) {
      inputs = getExactlyOneTensor(inputs);
      let output = relu(inputs);
      if (this.maxValue != null) {
        output = clipByValue(output, 0, this.maxValue);
      }
      return output;
    }
    computeOutputShape(inputShape) {
      return inputShape;
    }
    getConfig() {
      const config = { maxValue: this.maxValue };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  ReLU.className = "ReLU";
  serialization_exports.registerClass(ReLU);
  var LeakyReLU = class extends Layer {
    constructor(args) {
      super(args == null ? {} : args);
      this.DEFAULT_ALPHA = 0.3;
      if (args == null) {
        args = {};
      }
      this.alpha = args.alpha == null ? this.DEFAULT_ALPHA : args.alpha;
    }
    call(inputs, kwargs) {
      const x = getExactlyOneTensor(inputs);
      return leakyRelu(x, this.alpha);
    }
    computeOutputShape(inputShape) {
      return inputShape;
    }
    getConfig() {
      const config = { alpha: this.alpha };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  LeakyReLU.className = "LeakyReLU";
  serialization_exports.registerClass(LeakyReLU);
  var PReLU = class extends Layer {
    constructor(args) {
      super(args == null ? {} : args);
      this.DEFAULT_ALPHA_INITIALIZER = "zeros";
      if (args == null) {
        args = {};
      }
      this.supportsMasking = true;
      this.alphaInitializer = getInitializer(args.alphaInitializer || this.DEFAULT_ALPHA_INITIALIZER);
      this.alphaRegularizer = getRegularizer(args.alphaRegularizer);
      this.alphaConstraint = getConstraint(args.alphaConstraint);
      if (args.sharedAxes == null) {
        this.sharedAxes = null;
      } else if (Array.isArray(args.sharedAxes)) {
        this.sharedAxes = args.sharedAxes;
      } else if (typeof args.sharedAxes === "number") {
        this.sharedAxes = [args.sharedAxes];
      } else {
        throw new ValueError(`Expected sharedAxes to be a number or an array of numbers, but got ${args.sharedAxes}`);
      }
    }
    build(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      const paramShape = inputShape.slice(1);
      if (this.sharedAxes != null) {
        for (const i of this.sharedAxes) {
          paramShape[i - 1] = 1;
        }
      }
      this.alpha = this.addWeight("alpha", paramShape, "float32", this.alphaInitializer, this.alphaRegularizer, true, this.alphaConstraint);
      const axes = {};
      if (this.sharedAxes != null) {
        for (let i = 1; i < inputShape.length; ++i) {
          axes[i] = inputShape[i];
        }
      }
      this.inputSpec = [new InputSpec({
        ndim: inputShape.length,
        axes
      })];
      this.built = true;
    }
    call(inputs, kwargs) {
      inputs = getExactlyOneTensor(inputs);
      return prelu(inputs, this.alpha.read());
    }
    getConfig() {
      const config = {
        alphaInitializer: serializeInitializer(this.alphaInitializer),
        alphaRegularizer: serializeRegularizer(this.alphaRegularizer),
        alphaConstraint: serializeConstraint(this.alphaConstraint),
        sharedAxes: this.sharedAxes
      };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  PReLU.className = "PReLU";
  serialization_exports.registerClass(PReLU);
  var ELU = class extends Layer {
    constructor(args) {
      super(args == null ? {} : args);
      this.DEFAULT_ALPHA = 1;
      if (args == null) {
        args = {};
      }
      if (args.alpha != null && args.alpha !== this.DEFAULT_ALPHA) {
        throw new NotImplementedError(`Non-default alpha value (${args.alpha}) is not supported by the ELU layer yet.`);
      }
      this.alpha = args.alpha == null ? this.DEFAULT_ALPHA : args.alpha;
    }
    call(inputs, kwargs) {
      const x = getExactlyOneTensor(inputs);
      return elu(x);
    }
    computeOutputShape(inputShape) {
      return inputShape;
    }
    getConfig() {
      const config = { alpha: this.alpha };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  ELU.className = "ELU";
  serialization_exports.registerClass(ELU);
  var ThresholdedReLU = class extends Layer {
    constructor(args) {
      super(args == null ? {} : args);
      this.DEFAULT_THETA = 1;
      if (args == null) {
        args = {};
      }
      this.theta = args.theta == null ? this.DEFAULT_THETA : args.theta;
    }
    call(inputs, kwargs) {
      const x = getExactlyOneTensor(inputs);
      return mul(x, cast(greater(x, this.theta), "float32"));
    }
    computeOutputShape(inputShape) {
      return inputShape;
    }
    getConfig() {
      const config = { theta: this.theta };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  ThresholdedReLU.className = "ThresholdedReLU";
  serialization_exports.registerClass(ThresholdedReLU);
  var Softmax3 = class extends Layer {
    constructor(args) {
      super(args == null ? {} : args);
      this.DEFAULT_AXIS = 1;
      if (args == null) {
        args = {};
      }
      this.softmax = new Softmax2().apply;
      this.axis = args.axis == null ? this.DEFAULT_AXIS : args.axis;
    }
    call(inputs, kwargs) {
      const x = getExactlyOneTensor(inputs);
      return this.softmax(x, this.axis);
    }
    computeOutputShape(inputShape) {
      return inputShape;
    }
    getConfig() {
      const config = { axis: this.axis };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  Softmax3.className = "Softmax";
  serialization_exports.registerClass(Softmax3);

  // node_modules/@tensorflow/tfjs-layers/dist/utils/conv_utils.js
  function normalizeArray(value, n, name) {
    if (typeof value === "number") {
      return pyListRepeat(value, n);
    } else {
      if (value.length !== n) {
        throw new ValueError(`The ${name} argument must be an integer or tuple of ${n} integers. Received: ${value.length} elements.`);
      }
      for (let i = 0; i < n; ++i) {
        const singleValue = value[i];
        if (!isInteger(singleValue)) {
          throw new ValueError(`The ${name} argument must be an integer or tuple of ${n} integers. Received: ${JSON.stringify(value)} including a non-integer number ${singleValue}`);
        }
      }
      return value;
    }
  }
  function convOutputLength(inputLength, filterSize, padding, stride, dilation = 1) {
    if (inputLength == null) {
      return inputLength;
    }
    const dilatedFilterSize = filterSize + (filterSize - 1) * (dilation - 1);
    let outputLength;
    if (padding === "same") {
      outputLength = inputLength;
    } else {
      outputLength = inputLength - dilatedFilterSize + 1;
    }
    return Math.floor((outputLength + stride - 1) / stride);
  }
  function deconvLength(dimSize, strideSize, kernelSize, padding) {
    if (dimSize == null) {
      return null;
    }
    if (padding === "valid") {
      dimSize = dimSize * strideSize + max2([kernelSize - strideSize, 0]);
    } else if (padding === "same") {
      dimSize = dimSize * strideSize;
    } else {
      throw new ValueError(`Unsupport padding mode: ${padding}.`);
    }
    return dimSize;
  }

  // node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional.js
  function preprocessConv2DInput(x, dataFormat) {
    return tidy(() => {
      checkDataFormat(dataFormat);
      if (dataFormat === "channelsFirst") {
        return transpose(x, [0, 2, 3, 1]);
      } else {
        return x;
      }
    });
  }
  function preprocessConv3DInput(x, dataFormat) {
    return tidy(() => {
      checkDataFormat(dataFormat);
      if (dataFormat === "channelsFirst") {
        return transpose(x, [0, 2, 3, 4, 1]);
      } else {
        return x;
      }
    });
  }
  function conv1dWithBias(x, kernel, bias, strides = 1, padding = "valid", dataFormat, dilationRate = 1) {
    return tidy(() => {
      if (dataFormat == null) {
        dataFormat = imageDataFormat();
      }
      checkDataFormat(dataFormat);
      if (x.shape.length !== 3) {
        throw new ValueError(`The input of a conv1dWithBias operation should be 3, but is ${x.shape.length} instead.`);
      }
      if (kernel.shape.length !== 3) {
        throw new ValueError(`The kernel for a conv1dWithBias operation should be 3, but is ${kernel.shape.length} instead`);
      }
      if (bias != null && bias.shape.length !== 1) {
        throw new ValueError(`The bias for a conv1dWithBias operation should be 1, but is ${kernel.shape.length} instead`);
      }
      if (dataFormat === "channelsFirst") {
        x = transpose(x, [0, 2, 1]);
      }
      if (padding === "causal") {
        throw new NotImplementedError("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");
      }
      let y = conv1d(x, kernel, strides, padding === "same" ? "same" : "valid", "NWC", dilationRate);
      if (bias != null) {
        y = biasAdd(y, bias);
      }
      return y;
    });
  }
  function conv2dWithBiasActivation(x, kernel, bias, strides = [1, 1], padding = "valid", dataFormat, dilationRate, activation = null) {
    return tidy(() => {
      if (dataFormat == null) {
        dataFormat = imageDataFormat();
      }
      checkDataFormat(dataFormat);
      if (x.rank !== 3 && x.rank !== 4) {
        throw new ValueError(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${x.rank}.`);
      }
      if (kernel.rank !== 3 && kernel.rank !== 4) {
        throw new ValueError(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${x.rank}.`);
      }
      let y = preprocessConv2DInput(x, dataFormat);
      if (padding === "causal") {
        throw new NotImplementedError("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");
      }
      y = fused_ops_exports.conv2d({
        x: y,
        filter: kernel,
        strides,
        pad: padding === "same" ? "same" : "valid",
        dilations: dilationRate,
        dataFormat: "NHWC",
        bias,
        activation
      });
      if (dataFormat === "channelsFirst") {
        y = transpose(y, [0, 3, 1, 2]);
      }
      return y;
    });
  }
  function conv3dWithBias(x, kernel, bias, strides = [1, 1, 1], padding = "valid", dataFormat, dilationRate) {
    return tidy(() => {
      if (dataFormat == null) {
        dataFormat = imageDataFormat();
      }
      checkDataFormat(dataFormat);
      if (x.rank !== 4 && x.rank !== 5) {
        throw new ValueError(`conv3dWithBias expects input to be of rank 4 or 5, but received ${x.rank}.`);
      }
      if (kernel.rank !== 4 && kernel.rank !== 5) {
        throw new ValueError(`conv3dWithBias expects kernel to be of rank 4 or 5, but received ${x.rank}.`);
      }
      let y = preprocessConv3DInput(x, dataFormat);
      if (padding === "causal") {
        throw new NotImplementedError("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");
      }
      y = conv3d(y, kernel, strides, padding === "same" ? "same" : "valid", "NDHWC", dilationRate);
      if (bias != null) {
        y = biasAdd(y, bias);
      }
      if (dataFormat === "channelsFirst") {
        y = transpose(y, [0, 4, 1, 2, 3]);
      }
      return y;
    });
  }
  var BaseConv = class extends Layer {
    constructor(rank, args) {
      super(args);
      this.bias = null;
      this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal";
      this.DEFAULT_BIAS_INITIALIZER = "zeros";
      BaseConv.verifyArgs(args);
      this.rank = rank;
      assertPositiveInteger(this.rank, "rank");
      if (this.rank !== 1 && this.rank !== 2 && this.rank !== 3) {
        throw new NotImplementedError(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);
      }
      this.kernelSize = normalizeArray(args.kernelSize, rank, "kernelSize");
      this.strides = normalizeArray(args.strides == null ? 1 : args.strides, rank, "strides");
      this.padding = args.padding == null ? "valid" : args.padding;
      checkPaddingMode(this.padding);
      this.dataFormat = args.dataFormat == null ? "channelsLast" : args.dataFormat;
      checkDataFormat(this.dataFormat);
      this.activation = getActivation(args.activation);
      this.useBias = args.useBias == null ? true : args.useBias;
      this.biasInitializer = getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);
      this.biasConstraint = getConstraint(args.biasConstraint);
      this.biasRegularizer = getRegularizer(args.biasRegularizer);
      this.activityRegularizer = getRegularizer(args.activityRegularizer);
      this.dilationRate = normalizeArray(args.dilationRate == null ? 1 : args.dilationRate, rank, "dilationRate");
      if (this.rank === 1 && (Array.isArray(this.dilationRate) && this.dilationRate.length !== 1)) {
        throw new ValueError(`dilationRate must be a number or an array of a single number for 1D convolution, but received ${JSON.stringify(this.dilationRate)}`);
      } else if (this.rank === 2) {
        if (typeof this.dilationRate === "number") {
          this.dilationRate = [this.dilationRate, this.dilationRate];
        } else if (this.dilationRate.length !== 2) {
          throw new ValueError(`dilationRate must be a number or array of two numbers for 2D convolution, but received ${JSON.stringify(this.dilationRate)}`);
        }
      } else if (this.rank === 3) {
        if (typeof this.dilationRate === "number") {
          this.dilationRate = [this.dilationRate, this.dilationRate, this.dilationRate];
        } else if (this.dilationRate.length !== 3) {
          throw new ValueError(`dilationRate must be a number or array of three numbers for 3D convolution, but received ${JSON.stringify(this.dilationRate)}`);
        }
      }
    }
    static verifyArgs(args) {
      assert2("kernelSize" in args, `required key 'kernelSize' not in config`);
      if (typeof args.kernelSize !== "number" && !checkArrayTypeAndLength(args.kernelSize, "number", 1, 3)) {
        throw new ValueError(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(args.kernelSize)}.`);
      }
    }
    getConfig() {
      const config = {
        kernelSize: this.kernelSize,
        strides: this.strides,
        padding: this.padding,
        dataFormat: this.dataFormat,
        dilationRate: this.dilationRate,
        activation: serializeActivation(this.activation),
        useBias: this.useBias,
        biasInitializer: serializeInitializer(this.biasInitializer),
        biasRegularizer: serializeRegularizer(this.biasRegularizer),
        activityRegularizer: serializeRegularizer(this.activityRegularizer),
        biasConstraint: serializeConstraint(this.biasConstraint)
      };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  var Conv = class extends BaseConv {
    constructor(rank, args) {
      super(rank, args);
      this.kernel = null;
      Conv.verifyArgs(args);
      this.filters = args.filters;
      assertPositiveInteger(this.filters, "filters");
      this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);
      this.kernelConstraint = getConstraint(args.kernelConstraint);
      this.kernelRegularizer = getRegularizer(args.kernelRegularizer);
    }
    build(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      const channelAxis = this.dataFormat === "channelsFirst" ? 1 : inputShape.length - 1;
      if (inputShape[channelAxis] == null) {
        throw new ValueError(`The channel dimension of the input should be defined. Found ${inputShape[channelAxis]}`);
      }
      const inputDim = inputShape[channelAxis];
      const kernelShape = this.kernelSize.concat([inputDim, this.filters]);
      this.kernel = this.addWeight("kernel", kernelShape, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
      if (this.useBias) {
        this.bias = this.addWeight("bias", [this.filters], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);
      }
      this.inputSpec = [{ ndim: this.rank + 2, axes: { [channelAxis]: inputDim } }];
      this.built = true;
    }
    call(inputs, kwargs) {
      return tidy(() => {
        inputs = getExactlyOneTensor(inputs);
        let outputs;
        const biasValue = this.bias == null ? null : this.bias.read();
        const fusedActivationName = mapActivationToFusedKernel(this.activation.getClassName());
        if (fusedActivationName != null && this.rank === 2) {
          outputs = conv2dWithBiasActivation(inputs, this.kernel.read(), biasValue, this.strides, this.padding, this.dataFormat, this.dilationRate, fusedActivationName);
        } else {
          if (this.rank === 1) {
            outputs = conv1dWithBias(inputs, this.kernel.read(), biasValue, this.strides[0], this.padding, this.dataFormat, this.dilationRate[0]);
          } else if (this.rank === 2) {
            outputs = conv2dWithBiasActivation(inputs, this.kernel.read(), biasValue, this.strides, this.padding, this.dataFormat, this.dilationRate);
          } else if (this.rank === 3) {
            outputs = conv3dWithBias(inputs, this.kernel.read(), biasValue, this.strides, this.padding, this.dataFormat, this.dilationRate);
          } else {
            throw new NotImplementedError("convolutions greater than 3D are not implemented yet.");
          }
          if (this.activation != null) {
            outputs = this.activation.apply(outputs);
          }
        }
        return outputs;
      });
    }
    computeOutputShape(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      const newSpace = [];
      const space = this.dataFormat === "channelsLast" ? inputShape.slice(1, inputShape.length - 1) : inputShape.slice(2);
      for (let i = 0; i < space.length; ++i) {
        const newDim = convOutputLength(space[i], this.kernelSize[i], this.padding, this.strides[i], typeof this.dilationRate === "number" ? this.dilationRate : this.dilationRate[i]);
        newSpace.push(newDim);
      }
      let outputShape = [inputShape[0]];
      if (this.dataFormat === "channelsLast") {
        outputShape = outputShape.concat(newSpace);
        outputShape.push(this.filters);
      } else {
        outputShape.push(this.filters);
        outputShape = outputShape.concat(newSpace);
      }
      return outputShape;
    }
    getConfig() {
      const config = {
        filters: this.filters,
        kernelInitializer: serializeInitializer(this.kernelInitializer),
        kernelRegularizer: serializeRegularizer(this.kernelRegularizer),
        kernelConstraint: serializeConstraint(this.kernelConstraint)
      };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
    static verifyArgs(args) {
      if (!("filters" in args) || typeof args.filters !== "number" || args.filters < 1) {
        throw new ValueError(`Convolution layer expected config.filters to be a 'number' > 0 but got ${JSON.stringify(args.filters)}`);
      }
    }
  };
  var Conv2D2 = class extends Conv {
    constructor(args) {
      super(2, args);
      Conv2D2.verifyArgs(args);
    }
    getConfig() {
      const config = super.getConfig();
      delete config["rank"];
      return config;
    }
    static verifyArgs(args) {
      if (typeof args.kernelSize !== "number" && !checkArrayTypeAndLength(args.kernelSize, "number", 1, 2)) {
        throw new ValueError(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(args.kernelSize)}.`);
      }
    }
  };
  Conv2D2.className = "Conv2D";
  serialization_exports.registerClass(Conv2D2);
  var Conv3D2 = class extends Conv {
    constructor(args) {
      super(3, args);
      Conv3D2.verifyArgs(args);
    }
    getConfig() {
      const config = super.getConfig();
      delete config["rank"];
      return config;
    }
    static verifyArgs(args) {
      if (typeof args.kernelSize !== "number") {
        if (!(Array.isArray(args.kernelSize) && (args.kernelSize.length === 1 || args.kernelSize.length === 3))) {
          throw new ValueError(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(args.kernelSize)}.`);
        }
      }
    }
  };
  Conv3D2.className = "Conv3D";
  serialization_exports.registerClass(Conv3D2);
  var Conv2DTranspose = class extends Conv2D2 {
    constructor(args) {
      super(args);
      this.inputSpec = [new InputSpec({ ndim: 4 })];
      if (this.padding !== "same" && this.padding !== "valid") {
        throw new ValueError(`Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`);
      }
    }
    build(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      if (inputShape.length !== 4) {
        throw new ValueError("Input should have rank 4; Received input shape: " + JSON.stringify(inputShape));
      }
      const channelAxis = this.dataFormat === "channelsFirst" ? 1 : inputShape.length - 1;
      if (inputShape[channelAxis] == null) {
        throw new ValueError("The channel dimension of the inputs should be defined. Found `None`.");
      }
      const inputDim = inputShape[channelAxis];
      const kernelShape = this.kernelSize.concat([this.filters, inputDim]);
      this.kernel = this.addWeight("kernel", kernelShape, "float32", this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
      if (this.useBias) {
        this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);
      }
      this.inputSpec = [new InputSpec({ ndim: 4, axes: { [channelAxis]: inputDim } })];
      this.built = true;
    }
    call(inputs, kwargs) {
      return tidy(() => {
        let input2 = getExactlyOneTensor(inputs);
        if (input2.shape.length !== 4) {
          throw new ValueError(`Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${input2.shape.length}`);
        }
        const inputShape = input2.shape;
        const batchSize = inputShape[0];
        let hAxis;
        let wAxis;
        if (this.dataFormat === "channelsFirst") {
          hAxis = 2;
          wAxis = 3;
        } else {
          hAxis = 1;
          wAxis = 2;
        }
        const height = inputShape[hAxis];
        const width = inputShape[wAxis];
        const kernelH = this.kernelSize[0];
        const kernelW = this.kernelSize[1];
        const strideH = this.strides[0];
        const strideW = this.strides[1];
        const outHeight = deconvLength(height, strideH, kernelH, this.padding);
        const outWidth = deconvLength(width, strideW, kernelW, this.padding);
        const outputShape = [batchSize, outHeight, outWidth, this.filters];
        if (this.dataFormat !== "channelsLast") {
          input2 = transpose(input2, [0, 2, 3, 1]);
        }
        let outputs = conv2dTranspose(input2, this.kernel.read(), outputShape, this.strides, this.padding);
        if (this.dataFormat !== "channelsLast") {
          outputs = transpose(outputs, [0, 3, 1, 2]);
        }
        if (this.bias != null) {
          outputs = biasAdd(outputs, this.bias.read(), this.dataFormat);
        }
        if (this.activation != null) {
          outputs = this.activation.apply(outputs);
        }
        return outputs;
      });
    }
    computeOutputShape(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      const outputShape = inputShape.slice();
      let channelAxis;
      let heightAxis;
      let widthAxis;
      if (this.dataFormat === "channelsFirst") {
        channelAxis = 1;
        heightAxis = 2;
        widthAxis = 3;
      } else {
        channelAxis = 3;
        heightAxis = 1;
        widthAxis = 2;
      }
      const kernelH = this.kernelSize[0];
      const kernelW = this.kernelSize[1];
      const strideH = this.strides[0];
      const strideW = this.strides[1];
      outputShape[channelAxis] = this.filters;
      outputShape[heightAxis] = deconvLength(outputShape[heightAxis], strideH, kernelH, this.padding);
      outputShape[widthAxis] = deconvLength(outputShape[widthAxis], strideW, kernelW, this.padding);
      return outputShape;
    }
    getConfig() {
      const config = super.getConfig();
      delete config["dilationRate"];
      return config;
    }
  };
  Conv2DTranspose.className = "Conv2DTranspose";
  serialization_exports.registerClass(Conv2DTranspose);
  var Conv3DTranspose = class extends Conv3D2 {
    constructor(args) {
      super(args);
      this.inputSpec = [new InputSpec({ ndim: 5 })];
      if (this.padding !== "same" && this.padding !== "valid") {
        throw new ValueError(`Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`);
      }
    }
    build(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      if (inputShape.length !== 5) {
        throw new ValueError("Input should have rank 5; Received input shape: " + JSON.stringify(inputShape));
      }
      const channelAxis = this.dataFormat === "channelsFirst" ? 1 : inputShape.length - 1;
      if (inputShape[channelAxis] == null) {
        throw new ValueError("The channel dimension of the inputs should be defined. Found `None`.");
      }
      const inputDim = inputShape[channelAxis];
      const kernelShape = this.kernelSize.concat([this.filters, inputDim]);
      this.kernel = this.addWeight("kernel", kernelShape, "float32", this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
      if (this.useBias) {
        this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);
      }
      this.inputSpec = [new InputSpec({ ndim: 5, axes: { [channelAxis]: inputDim } })];
      this.built = true;
    }
    call(inputs, kwargs) {
      return tidy(() => {
        let input2 = getExactlyOneTensor(inputs);
        if (input2.shape.length !== 5) {
          throw new ValueError(`Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${input2.shape.length}`);
        }
        const inputShape = input2.shape;
        const batchSize = inputShape[0];
        let hAxis;
        let wAxis;
        let dAxis;
        if (this.dataFormat === "channelsFirst") {
          dAxis = 2;
          hAxis = 3;
          wAxis = 4;
        } else {
          dAxis = 1;
          hAxis = 2;
          wAxis = 3;
        }
        const depth = inputShape[dAxis];
        const height = inputShape[hAxis];
        const width = inputShape[wAxis];
        const kernelD = this.kernelSize[0];
        const kernelH = this.kernelSize[1];
        const kernelW = this.kernelSize[2];
        const strideD = this.strides[0];
        const strideH = this.strides[1];
        const strideW = this.strides[2];
        const outDepth = deconvLength(depth, strideD, kernelD, this.padding);
        const outHeight = deconvLength(height, strideH, kernelH, this.padding);
        const outWidth = deconvLength(width, strideW, kernelW, this.padding);
        const outputShape = [batchSize, outDepth, outHeight, outWidth, this.filters];
        if (this.dataFormat !== "channelsLast") {
          input2 = transpose(input2, [0, 2, 3, 4, 1]);
        }
        let outputs = conv3dTranspose(input2, this.kernel.read(), outputShape, this.strides, this.padding);
        if (this.dataFormat !== "channelsLast") {
          outputs = transpose(outputs, [0, 4, 1, 2, 3]);
        }
        if (this.bias !== null) {
          outputs = biasAdd(outputs, this.bias.read(), this.dataFormat);
        }
        if (this.activation !== null) {
          outputs = this.activation.apply(outputs);
        }
        return outputs;
      });
    }
    computeOutputShape(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      const outputShape = inputShape.slice();
      let channelAxis;
      let depthAxis;
      let heightAxis;
      let widthAxis;
      if (this.dataFormat === "channelsFirst") {
        channelAxis = 1;
        depthAxis = 2;
        heightAxis = 3;
        widthAxis = 4;
      } else {
        channelAxis = 4;
        depthAxis = 1;
        heightAxis = 2;
        widthAxis = 3;
      }
      const kernelD = this.kernelSize[0];
      const kernelH = this.kernelSize[1];
      const kernelW = this.kernelSize[2];
      const strideD = this.strides[0];
      const strideH = this.strides[1];
      const strideW = this.strides[2];
      outputShape[channelAxis] = this.filters;
      outputShape[depthAxis] = deconvLength(outputShape[depthAxis], strideD, kernelD, this.padding);
      outputShape[heightAxis] = deconvLength(outputShape[heightAxis], strideH, kernelH, this.padding);
      outputShape[widthAxis] = deconvLength(outputShape[widthAxis], strideW, kernelW, this.padding);
      return outputShape;
    }
    getConfig() {
      const config = super.getConfig();
      delete config["dilationRate"];
      return config;
    }
  };
  Conv3DTranspose.className = "Conv3DTranspose";
  serialization_exports.registerClass(Conv3DTranspose);
  var SeparableConv = class extends Conv {
    constructor(rank, config) {
      super(rank, config);
      this.DEFAULT_DEPTHWISE_INITIALIZER = "glorotUniform";
      this.DEFAULT_POINTWISE_INITIALIZER = "glorotUniform";
      this.depthwiseKernel = null;
      this.pointwiseKernel = null;
      if (config.filters == null) {
        throw new ValueError("The `filters` configuration field is required by SeparableConv, but is unspecified.");
      }
      if (config.kernelInitializer != null || config.kernelRegularizer != null || config.kernelConstraint != null) {
        throw new ValueError("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");
      }
      if (config.padding != null && config.padding !== "same" && config.padding !== "valid") {
        throw new ValueError(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received ${JSON.stringify(config.padding)}`);
      }
      this.depthMultiplier = config.depthMultiplier == null ? 1 : config.depthMultiplier;
      this.depthwiseInitializer = getInitializer(config.depthwiseInitializer || this.DEFAULT_DEPTHWISE_INITIALIZER);
      this.depthwiseRegularizer = getRegularizer(config.depthwiseRegularizer);
      this.depthwiseConstraint = getConstraint(config.depthwiseConstraint);
      this.pointwiseInitializer = getInitializer(config.depthwiseInitializer || this.DEFAULT_POINTWISE_INITIALIZER);
      this.pointwiseRegularizer = getRegularizer(config.pointwiseRegularizer);
      this.pointwiseConstraint = getConstraint(config.pointwiseConstraint);
    }
    build(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      if (inputShape.length < this.rank + 2) {
        throw new ValueError(`Inputs to SeparableConv${this.rank}D should have rank ${this.rank + 2}, but received input shape: ${JSON.stringify(inputShape)}`);
      }
      const channelAxis = this.dataFormat === "channelsFirst" ? 1 : inputShape.length - 1;
      if (inputShape[channelAxis] == null || inputShape[channelAxis] < 0) {
        throw new ValueError(`The channel dimension of the inputs should be defined, but found ${JSON.stringify(inputShape[channelAxis])}`);
      }
      const inputDim = inputShape[channelAxis];
      const depthwiseKernelShape = this.kernelSize.concat([inputDim, this.depthMultiplier]);
      const pointwiseKernelShape = [];
      for (let i = 0; i < this.rank; ++i) {
        pointwiseKernelShape.push(1);
      }
      pointwiseKernelShape.push(inputDim * this.depthMultiplier, this.filters);
      const trainable = true;
      this.depthwiseKernel = this.addWeight("depthwise_kernel", depthwiseKernelShape, "float32", this.depthwiseInitializer, this.depthwiseRegularizer, trainable, this.depthwiseConstraint);
      this.pointwiseKernel = this.addWeight("pointwise_kernel", pointwiseKernelShape, "float32", this.pointwiseInitializer, this.pointwiseRegularizer, trainable, this.pointwiseConstraint);
      if (this.useBias) {
        this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, trainable, this.biasConstraint);
      } else {
        this.bias = null;
      }
      this.inputSpec = [new InputSpec({ ndim: this.rank + 2, axes: { [channelAxis]: inputDim } })];
      this.built = true;
    }
    call(inputs, kwargs) {
      return tidy(() => {
        inputs = getExactlyOneTensor(inputs);
        let output;
        if (this.rank === 1) {
          throw new NotImplementedError("1D separable convolution is not implemented yet.");
        } else if (this.rank === 2) {
          if (this.dataFormat === "channelsFirst") {
            inputs = transpose(inputs, [0, 2, 3, 1]);
          }
          output = separableConv2d(inputs, this.depthwiseKernel.read(), this.pointwiseKernel.read(), this.strides, this.padding, this.dilationRate, "NHWC");
        }
        if (this.useBias) {
          output = biasAdd(output, this.bias.read(), this.dataFormat);
        }
        if (this.activation != null) {
          output = this.activation.apply(output);
        }
        if (this.dataFormat === "channelsFirst") {
          output = transpose(output, [0, 3, 1, 2]);
        }
        return output;
      });
    }
    getConfig() {
      const config = super.getConfig();
      delete config["rank"];
      delete config["kernelInitializer"];
      delete config["kernelRegularizer"];
      delete config["kernelConstraint"];
      config["depthwiseInitializer"] = serializeInitializer(this.depthwiseInitializer);
      config["pointwiseInitializer"] = serializeInitializer(this.pointwiseInitializer);
      config["depthwiseRegularizer"] = serializeRegularizer(this.depthwiseRegularizer);
      config["pointwiseRegularizer"] = serializeRegularizer(this.pointwiseRegularizer);
      config["depthwiseConstraint"] = serializeConstraint(this.depthwiseConstraint);
      config["pointwiseConstraint"] = serializeConstraint(this.pointwiseConstraint);
      return config;
    }
  };
  SeparableConv.className = "SeparableConv";
  var SeparableConv2D = class extends SeparableConv {
    constructor(args) {
      super(2, args);
    }
  };
  SeparableConv2D.className = "SeparableConv2D";
  serialization_exports.registerClass(SeparableConv2D);
  var Conv1D = class extends Conv {
    constructor(args) {
      super(1, args);
      Conv1D.verifyArgs(args);
      this.inputSpec = [{ ndim: 3 }];
    }
    getConfig() {
      const config = super.getConfig();
      delete config["rank"];
      delete config["dataFormat"];
      return config;
    }
    static verifyArgs(args) {
      if (typeof args.kernelSize !== "number" && !checkArrayTypeAndLength(args.kernelSize, "number", 1, 1)) {
        throw new ValueError(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(args.kernelSize)}.`);
      }
    }
  };
  Conv1D.className = "Conv1D";
  serialization_exports.registerClass(Conv1D);
  var Cropping2D = class extends Layer {
    constructor(args) {
      super(args);
      if (typeof args.cropping === "number") {
        this.cropping = [[args.cropping, args.cropping], [args.cropping, args.cropping]];
      } else if (typeof args.cropping[0] === "number") {
        this.cropping = [
          [args.cropping[0], args.cropping[0]],
          [args.cropping[1], args.cropping[1]]
        ];
      } else {
        this.cropping = args.cropping;
      }
      this.dataFormat = args.dataFormat === void 0 ? "channelsLast" : args.dataFormat;
      this.inputSpec = [{ ndim: 4 }];
    }
    computeOutputShape(inputShape) {
      if (this.dataFormat === "channelsFirst") {
        return [
          inputShape[0],
          inputShape[1],
          inputShape[2] - this.cropping[0][0] - this.cropping[0][1],
          inputShape[3] - this.cropping[1][0] - this.cropping[1][1]
        ];
      } else {
        return [
          inputShape[0],
          inputShape[1] - this.cropping[0][0] - this.cropping[0][1],
          inputShape[2] - this.cropping[1][0] - this.cropping[1][1],
          inputShape[3]
        ];
      }
    }
    call(inputs, kwargs) {
      return tidy(() => {
        inputs = getExactlyOneTensor(inputs);
        if (this.dataFormat === "channelsLast") {
          const hSliced = sliceAlongAxis(inputs, this.cropping[0][0], inputs.shape[1] - this.cropping[0][0] - this.cropping[0][1], 2);
          return sliceAlongAxis(hSliced, this.cropping[1][0], inputs.shape[2] - this.cropping[1][1] - this.cropping[1][0], 3);
        } else {
          const hSliced = sliceAlongAxis(inputs, this.cropping[0][0], inputs.shape[2] - this.cropping[0][0] - this.cropping[0][1], 3);
          return sliceAlongAxis(hSliced, this.cropping[1][0], inputs.shape[3] - this.cropping[1][1] - this.cropping[1][0], 4);
        }
      });
    }
    getConfig() {
      const config = { cropping: this.cropping, dataFormat: this.dataFormat };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  Cropping2D.className = "Cropping2D";
  serialization_exports.registerClass(Cropping2D);
  var UpSampling2D = class extends Layer {
    constructor(args) {
      super(args);
      this.DEFAULT_SIZE = [2, 2];
      this.inputSpec = [{ ndim: 4 }];
      this.size = args.size == null ? this.DEFAULT_SIZE : args.size;
      this.dataFormat = args.dataFormat == null ? "channelsLast" : args.dataFormat;
      checkDataFormat(this.dataFormat);
      this.interpolation = args.interpolation == null ? "nearest" : args.interpolation;
      checkInterpolationFormat(this.interpolation);
    }
    computeOutputShape(inputShape) {
      if (this.dataFormat === "channelsFirst") {
        const height = inputShape[2] == null ? null : this.size[0] * inputShape[2];
        const width = inputShape[3] == null ? null : this.size[1] * inputShape[3];
        return [inputShape[0], inputShape[1], height, width];
      } else {
        const height = inputShape[1] == null ? null : this.size[0] * inputShape[1];
        const width = inputShape[2] == null ? null : this.size[1] * inputShape[2];
        return [inputShape[0], height, width, inputShape[3]];
      }
    }
    call(inputs, kwargs) {
      return tidy(() => {
        let input2 = getExactlyOneTensor(inputs);
        const inputShape = input2.shape;
        if (this.dataFormat === "channelsFirst") {
          input2 = transpose(input2, [0, 2, 3, 1]);
          const height = this.size[0] * inputShape[2];
          const width = this.size[1] * inputShape[3];
          const resized = this.interpolation === "nearest" ? image.resizeNearestNeighbor(input2, [height, width]) : image.resizeBilinear(input2, [height, width]);
          return transpose(resized, [0, 3, 1, 2]);
        } else {
          const height = this.size[0] * inputShape[1];
          const width = this.size[1] * inputShape[2];
          return this.interpolation === "nearest" ? image.resizeNearestNeighbor(input2, [height, width]) : image.resizeBilinear(input2, [height, width]);
        }
      });
    }
    getConfig() {
      const config = { size: this.size, dataFormat: this.dataFormat };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  UpSampling2D.className = "UpSampling2D";
  serialization_exports.registerClass(UpSampling2D);

  // node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional_depthwise.js
  function depthwiseConv2d3(x, depthwiseKernel, strides = [1, 1], padding = "valid", dataFormat, dilationRate) {
    return tidy(() => {
      if (dataFormat == null) {
        dataFormat = imageDataFormat();
      }
      checkDataFormat(dataFormat);
      let y = preprocessConv2DInput(x, dataFormat);
      if (x.rank !== 4) {
        throw new ValueError(`Input for depthwiseConv2d is required to be 4-D, but is instead ${x.rank}-D`);
      }
      if (depthwiseKernel.rank !== 4) {
        throw new ValueError(`depthwiseKernel is required to be 4-D, but is instead ${depthwiseKernel.rank}-D`);
      }
      y = depthwiseConv2d(y, depthwiseKernel, strides, padding === "same" ? "same" : "valid", "NHWC", dilationRate);
      if (dataFormat === "channelsFirst") {
        y = transpose(y, [0, 3, 1, 2]);
      }
      return y;
    });
  }
  var DepthwiseConv2D = class extends BaseConv {
    constructor(args) {
      super(2, args);
      this.depthwiseKernel = null;
      this.depthMultiplier = args.depthMultiplier == null ? 1 : args.depthMultiplier;
      this.depthwiseInitializer = getInitializer(args.depthwiseInitializer || this.DEFAULT_KERNEL_INITIALIZER);
      this.depthwiseConstraint = getConstraint(args.depthwiseConstraint);
      this.depthwiseRegularizer = getRegularizer(args.depthwiseRegularizer);
    }
    build(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      if (inputShape.length < 4) {
        throw new ValueError(`Inputs to DepthwiseConv2D should have rank 4. Received input shape: ${JSON.stringify(inputShape)}.`);
      }
      const channelAxis = this.dataFormat === "channelsFirst" ? 1 : 3;
      if (inputShape[channelAxis] == null || inputShape[channelAxis] < 0) {
        throw new ValueError(`The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (${inputShape[channelAxis]}).`);
      }
      const inputDim = inputShape[channelAxis];
      const depthwiseKernelShape = [
        this.kernelSize[0],
        this.kernelSize[1],
        inputDim,
        this.depthMultiplier
      ];
      this.depthwiseKernel = this.addWeight("depthwise_kernel", depthwiseKernelShape, null, this.depthwiseInitializer, this.depthwiseRegularizer, true, this.depthwiseConstraint);
      if (this.useBias) {
        this.bias = this.addWeight("bias", [inputDim * this.depthMultiplier], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);
      } else {
        this.bias = null;
      }
      this.built = true;
    }
    call(inputs, kwargs) {
      return tidy(() => {
        inputs = getExactlyOneTensor(inputs);
        let outputs = depthwiseConv2d3(inputs, this.depthwiseKernel.read(), this.strides, this.padding, this.dataFormat, null);
        if (this.useBias) {
          outputs = biasAdd(outputs, this.bias.read(), this.dataFormat);
        }
        if (this.activation != null) {
          outputs = this.activation.apply(outputs);
        }
        return outputs;
      });
    }
    computeOutputShape(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      const rows = this.dataFormat === "channelsFirst" ? inputShape[2] : inputShape[1];
      const cols = this.dataFormat === "channelsFirst" ? inputShape[3] : inputShape[2];
      const outFilters = this.dataFormat === "channelsFirst" ? inputShape[1] * this.depthMultiplier : inputShape[3] * this.depthMultiplier;
      const outRows = convOutputLength(rows, this.kernelSize[0], this.padding, this.strides[0]);
      const outCols = convOutputLength(cols, this.kernelSize[1], this.padding, this.strides[1]);
      if (this.dataFormat === "channelsFirst") {
        return [inputShape[0], outFilters, outRows, outCols];
      } else {
        return [inputShape[0], outRows, outCols, outFilters];
      }
    }
    getConfig() {
      const config = super.getConfig();
      config["depthMultiplier"] = this.depthMultiplier;
      config["depthwiseInitializer"] = serializeInitializer(this.depthwiseInitializer);
      config["depthwiseRegularizer"] = serializeRegularizer(this.depthwiseRegularizer);
      config["depthwiseConstraint"] = serializeConstraint(this.depthwiseRegularizer);
      return config;
    }
  };
  DepthwiseConv2D.className = "DepthwiseConv2D";
  serialization_exports.registerClass(DepthwiseConv2D);

  // node_modules/@tensorflow/tfjs-layers/dist/layers/recurrent.js
  function standardizeArgs(inputs, initialState, constants, numConstants) {
    if (Array.isArray(inputs)) {
      if (initialState != null || constants != null) {
        throw new ValueError("When inputs is an array, neither initialState or constants should be provided");
      }
      if (numConstants != null) {
        constants = inputs.slice(inputs.length - numConstants, inputs.length);
        inputs = inputs.slice(0, inputs.length - numConstants);
      }
      if (inputs.length > 1) {
        initialState = inputs.slice(1, inputs.length);
      }
      inputs = inputs[0];
    }
    function toListOrNull(x) {
      if (x == null || Array.isArray(x)) {
        return x;
      } else {
        return [x];
      }
    }
    initialState = toListOrNull(initialState);
    constants = toListOrNull(constants);
    return { inputs, initialState, constants };
  }
  function rnn(stepFunction, inputs, initialStates, goBackwards = false, mask, constants, unroll = false, needPerStepOutputs = false) {
    return tidy(() => {
      const ndim = inputs.shape.length;
      if (ndim < 3) {
        throw new ValueError(`Input should be at least 3D, but is ${ndim}D.`);
      }
      const axes = [1, 0].concat(range2(2, ndim));
      inputs = transpose(inputs, axes);
      if (constants != null) {
        throw new NotImplementedError("The rnn() functoin of the deeplearn.js backend does not support constants yet.");
      }
      if (unroll) {
        console.warn("Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend.");
      }
      if (mask != null) {
        mask = cast(cast(mask, "bool"), "float32");
        if (mask.rank === ndim - 1) {
          mask = expandDims(mask, -1);
        }
        mask = transpose(mask, axes);
      }
      if (goBackwards) {
        inputs = reverse(inputs, 0);
        if (mask != null) {
          mask = reverse(mask, 0);
        }
      }
      const perStepOutputs = [];
      let lastOutput;
      let states = initialStates;
      const timeSteps = inputs.shape[0];
      const perStepInputs = unstack(inputs);
      let perStepMasks;
      if (mask != null) {
        perStepMasks = unstack(mask);
      }
      for (let t = 0; t < timeSteps; ++t) {
        const currentInput = perStepInputs[t];
        const stepOutputs = tidy(() => stepFunction(currentInput, states));
        if (mask == null) {
          lastOutput = stepOutputs[0];
          states = stepOutputs[1];
        } else {
          const maskedOutputs = tidy(() => {
            const stepMask = perStepMasks[t];
            const negStepMask = sub(onesLike(stepMask), stepMask);
            const output = add3(mul(stepOutputs[0], stepMask), mul(states[0], negStepMask));
            const newStates = states.map((state, i) => {
              return add3(mul(stepOutputs[1][i], stepMask), mul(state, negStepMask));
            });
            return { output, newStates };
          });
          lastOutput = maskedOutputs.output;
          states = maskedOutputs.newStates;
        }
        if (needPerStepOutputs) {
          perStepOutputs.push(lastOutput);
        }
      }
      let outputs;
      if (needPerStepOutputs) {
        const axis = 1;
        outputs = stack2(perStepOutputs, axis);
      }
      return [lastOutput, outputs, states];
    });
  }
  var RNN = class extends Layer {
    constructor(args) {
      super(args);
      let cell;
      if (args.cell == null) {
        throw new ValueError("cell property is missing for the constructor of RNN.");
      } else if (Array.isArray(args.cell)) {
        cell = new StackedRNNCells({ cells: args.cell });
      } else {
        cell = args.cell;
      }
      if (cell.stateSize == null) {
        throw new ValueError("The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).");
      }
      this.cell = cell;
      this.returnSequences = args.returnSequences == null ? false : args.returnSequences;
      this.returnState = args.returnState == null ? false : args.returnState;
      this.goBackwards = args.goBackwards == null ? false : args.goBackwards;
      this._stateful = args.stateful == null ? false : args.stateful;
      this.unroll = args.unroll == null ? false : args.unroll;
      this.supportsMasking = true;
      this.inputSpec = [new InputSpec({ ndim: 3 })];
      this.stateSpec = null;
      this.states_ = null;
      this.numConstants = null;
      this.keptStates = [];
    }
    getStates() {
      if (this.states_ == null) {
        const numStates = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;
        return range2(0, numStates).map((x) => null);
      } else {
        return this.states_;
      }
    }
    setStates(states) {
      this.states_ = states;
    }
    computeOutputShape(inputShape) {
      if (isArrayOfShapes(inputShape)) {
        inputShape = inputShape[0];
      }
      inputShape = inputShape;
      let stateSize = this.cell.stateSize;
      if (!Array.isArray(stateSize)) {
        stateSize = [stateSize];
      }
      const outputDim = stateSize[0];
      let outputShape;
      if (this.returnSequences) {
        outputShape = [inputShape[0], inputShape[1], outputDim];
      } else {
        outputShape = [inputShape[0], outputDim];
      }
      if (this.returnState) {
        const stateShape = [];
        for (const dim of stateSize) {
          stateShape.push([inputShape[0], dim]);
        }
        return [outputShape].concat(stateShape);
      } else {
        return outputShape;
      }
    }
    computeMask(inputs, mask) {
      return tidy(() => {
        if (Array.isArray(mask)) {
          mask = mask[0];
        }
        const outputMask = this.returnSequences ? mask : null;
        if (this.returnState) {
          const stateMask = this.states.map((s) => null);
          return [outputMask].concat(stateMask);
        } else {
          return outputMask;
        }
      });
    }
    get states() {
      if (this.states_ == null) {
        const numStates = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;
        const output = [];
        for (let i = 0; i < numStates; ++i) {
          output.push(null);
        }
        return output;
      } else {
        return this.states_;
      }
    }
    set states(s) {
      this.states_ = s;
    }
    build(inputShape) {
      const constantShape = null;
      if (this.numConstants != null) {
        throw new NotImplementedError("Constants support is not implemented in RNN yet.");
      }
      if (isArrayOfShapes(inputShape)) {
        inputShape = inputShape[0];
      }
      inputShape = inputShape;
      const batchSize = this.stateful ? inputShape[0] : null;
      const inputDim = inputShape.slice(2);
      this.inputSpec[0] = new InputSpec({ shape: [batchSize, null, ...inputDim] });
      const stepInputShape = [inputShape[0]].concat(inputShape.slice(2));
      if (constantShape != null) {
        throw new NotImplementedError("Constants support is not implemented in RNN yet.");
      } else {
        this.cell.build(stepInputShape);
      }
      let stateSize;
      if (Array.isArray(this.cell.stateSize)) {
        stateSize = this.cell.stateSize;
      } else {
        stateSize = [this.cell.stateSize];
      }
      if (this.stateSpec != null) {
        if (!util_exports.arraysEqual(this.stateSpec.map((spec) => spec.shape[spec.shape.length - 1]), stateSize)) {
          throw new ValueError(`An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=${this.stateSpec}; However cell.stateSize is ${this.cell.stateSize}`);
        }
      } else {
        this.stateSpec = stateSize.map((dim) => new InputSpec({ shape: [null, dim] }));
      }
      if (this.stateful) {
        this.resetStates();
      }
    }
    resetStates(states, training = false) {
      tidy(() => {
        if (!this.stateful) {
          throw new AttributeError("Cannot call resetStates() on an RNN Layer that is not stateful.");
        }
        const batchSize = this.inputSpec[0].shape[0];
        if (batchSize == null) {
          throw new ValueError("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");
        }
        if (this.states_ == null) {
          if (Array.isArray(this.cell.stateSize)) {
            this.states_ = this.cell.stateSize.map((dim) => zeros([batchSize, dim]));
          } else {
            this.states_ = [zeros([batchSize, this.cell.stateSize])];
          }
        } else if (states == null) {
          dispose(this.states_);
          if (this.keptStates != null) {
            dispose(this.keptStates);
            this.keptStates = [];
          }
          if (Array.isArray(this.cell.stateSize)) {
            this.states_ = this.cell.stateSize.map((dim) => zeros([batchSize, dim]));
          } else {
            this.states_[0] = zeros([batchSize, this.cell.stateSize]);
          }
        } else {
          if (!Array.isArray(states)) {
            states = [states];
          }
          if (states.length !== this.states_.length) {
            throw new ValueError(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${states.length} state value(s). Input received: ${states}`);
          }
          if (training === true) {
            this.keptStates.push(this.states_.slice());
          } else {
            dispose(this.states_);
          }
          for (let index = 0; index < this.states_.length; ++index) {
            const value = states[index];
            const dim = Array.isArray(this.cell.stateSize) ? this.cell.stateSize[index] : this.cell.stateSize;
            const expectedShape = [batchSize, dim];
            if (!util_exports.arraysEqual(value.shape, expectedShape)) {
              throw new ValueError(`State ${index} is incompatible with layer ${this.name}: expected shape=${expectedShape}, received shape=${value.shape}`);
            }
            this.states_[index] = value;
          }
        }
        this.states_ = this.states_.map((state) => keep(state.clone()));
      });
    }
    apply(inputs, kwargs) {
      let initialState = kwargs == null ? null : kwargs["initialState"];
      let constants = kwargs == null ? null : kwargs["constants"];
      if (kwargs == null) {
        kwargs = {};
      }
      const standardized = standardizeArgs(inputs, initialState, constants, this.numConstants);
      inputs = standardized.inputs;
      initialState = standardized.initialState;
      constants = standardized.constants;
      let additionalInputs = [];
      let additionalSpecs = [];
      if (initialState != null) {
        kwargs["initialState"] = initialState;
        additionalInputs = additionalInputs.concat(initialState);
        this.stateSpec = [];
        for (const state of initialState) {
          this.stateSpec.push(new InputSpec({ shape: state.shape }));
        }
        additionalSpecs = additionalSpecs.concat(this.stateSpec);
      }
      if (constants != null) {
        kwargs["constants"] = constants;
        additionalInputs = additionalInputs.concat(constants);
        this.numConstants = constants.length;
      }
      const isTensor = additionalInputs[0] instanceof SymbolicTensor;
      if (isTensor) {
        const fullInput = [inputs].concat(additionalInputs);
        const fullInputSpec = this.inputSpec.concat(additionalSpecs);
        const originalInputSpec = this.inputSpec;
        this.inputSpec = fullInputSpec;
        const output = super.apply(fullInput, kwargs);
        this.inputSpec = originalInputSpec;
        return output;
      } else {
        return super.apply(inputs, kwargs);
      }
    }
    call(inputs, kwargs) {
      return tidy(() => {
        const mask = kwargs == null ? null : kwargs["mask"];
        const training = kwargs == null ? null : kwargs["training"];
        let initialState = kwargs == null ? null : kwargs["initialState"];
        inputs = getExactlyOneTensor(inputs);
        if (initialState == null) {
          if (this.stateful) {
            initialState = this.states_;
          } else {
            initialState = this.getInitialState(inputs);
          }
        }
        const numStates = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;
        if (initialState.length !== numStates) {
          throw new ValueError(`RNN Layer has ${numStates} state(s) but was passed ${initialState.length} initial state(s).`);
        }
        if (this.unroll) {
          console.warn("Ignoring unroll = true for RNN layer, due to imperative backend.");
        }
        const cellCallKwargs = { training };
        const step4 = (inputs2, states2) => {
          const outputs2 = this.cell.call([inputs2].concat(states2), cellCallKwargs);
          return [outputs2[0], outputs2.slice(1)];
        };
        const rnnOutputs = rnn(step4, inputs, initialState, this.goBackwards, mask, null, this.unroll, this.returnSequences);
        const lastOutput = rnnOutputs[0];
        const outputs = rnnOutputs[1];
        const states = rnnOutputs[2];
        if (this.stateful) {
          this.resetStates(states, training);
        }
        const output = this.returnSequences ? outputs : lastOutput;
        if (this.returnState) {
          return [output].concat(states);
        } else {
          return output;
        }
      });
    }
    getInitialState(inputs) {
      return tidy(() => {
        let initialState = zeros(inputs.shape);
        initialState = sum2(initialState, [1, 2]);
        initialState = expandDims2(initialState);
        if (Array.isArray(this.cell.stateSize)) {
          return this.cell.stateSize.map((dim) => dim > 1 ? tile2(initialState, [1, dim]) : initialState);
        } else {
          return this.cell.stateSize > 1 ? [tile2(initialState, [1, this.cell.stateSize])] : [initialState];
        }
      });
    }
    get trainableWeights() {
      if (!this.trainable) {
        return [];
      }
      return this.cell.trainableWeights;
    }
    get nonTrainableWeights() {
      if (!this.trainable) {
        return this.cell.weights;
      }
      return this.cell.nonTrainableWeights;
    }
    setFastWeightInitDuringBuild(value) {
      super.setFastWeightInitDuringBuild(value);
      if (this.cell != null) {
        this.cell.setFastWeightInitDuringBuild(value);
      }
    }
    getConfig() {
      const baseConfig = super.getConfig();
      const config = {
        returnSequences: this.returnSequences,
        returnState: this.returnState,
        goBackwards: this.goBackwards,
        stateful: this.stateful,
        unroll: this.unroll
      };
      if (this.numConstants != null) {
        config["numConstants"] = this.numConstants;
      }
      const cellConfig = this.cell.getConfig();
      if (this.getClassName() === RNN.className) {
        config["cell"] = {
          "className": this.cell.getClassName(),
          "config": cellConfig
        };
      }
      return Object.assign({}, cellConfig, baseConfig, config);
    }
    static fromConfig(cls, config, customObjects = {}) {
      const cellConfig = config["cell"];
      const cell = deserialize(cellConfig, customObjects);
      return new cls(Object.assign(config, { cell }));
    }
  };
  RNN.className = "RNN";
  serialization_exports.registerClass(RNN);
  var RNNCell = class extends Layer {
  };
  var SimpleRNNCell = class extends RNNCell {
    constructor(args) {
      super(args);
      this.DEFAULT_ACTIVATION = "tanh";
      this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal";
      this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal";
      this.DEFAULT_BIAS_INITIALIZER = "zeros";
      this.units = args.units;
      assertPositiveInteger(this.units, `units`);
      this.activation = getActivation(args.activation == null ? this.DEFAULT_ACTIVATION : args.activation);
      this.useBias = args.useBias == null ? true : args.useBias;
      this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);
      this.recurrentInitializer = getInitializer(args.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER);
      this.biasInitializer = getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);
      this.kernelRegularizer = getRegularizer(args.kernelRegularizer);
      this.recurrentRegularizer = getRegularizer(args.recurrentRegularizer);
      this.biasRegularizer = getRegularizer(args.biasRegularizer);
      this.kernelConstraint = getConstraint(args.kernelConstraint);
      this.recurrentConstraint = getConstraint(args.recurrentConstraint);
      this.biasConstraint = getConstraint(args.biasConstraint);
      this.dropout = min2([1, max2([0, args.dropout == null ? 0 : args.dropout])]);
      this.recurrentDropout = min2([
        1,
        max2([0, args.recurrentDropout == null ? 0 : args.recurrentDropout])
      ]);
      this.dropoutFunc = args.dropoutFunc;
      this.stateSize = this.units;
      this.dropoutMask = null;
      this.recurrentDropoutMask = null;
    }
    build(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      this.kernel = this.addWeight("kernel", [inputShape[inputShape.length - 1], this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
      this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, this.units], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);
      if (this.useBias) {
        this.bias = this.addWeight("bias", [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);
      } else {
        this.bias = null;
      }
      this.built = true;
    }
    call(inputs, kwargs) {
      return tidy(() => {
        inputs = inputs;
        if (inputs.length !== 2) {
          throw new ValueError(`SimpleRNNCell expects 2 input Tensors, got ${inputs.length}.`);
        }
        let prevOutput = inputs[1];
        inputs = inputs[0];
        const training = kwargs["training"] == null ? false : kwargs["training"];
        if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {
          this.dropoutMask = generateDropoutMask({
            ones: () => onesLike(inputs),
            rate: this.dropout,
            training,
            dropoutFunc: this.dropoutFunc
          });
        }
        if (0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null) {
          this.recurrentDropoutMask = generateDropoutMask({
            ones: () => onesLike(prevOutput),
            rate: this.recurrentDropout,
            training,
            dropoutFunc: this.dropoutFunc
          });
        }
        let h2;
        const dpMask = this.dropoutMask;
        const recDpMask = this.recurrentDropoutMask;
        if (dpMask != null) {
          h2 = dot2(mul(inputs, dpMask), this.kernel.read());
        } else {
          h2 = dot2(inputs, this.kernel.read());
        }
        if (this.bias != null) {
          h2 = biasAdd(h2, this.bias.read());
        }
        if (recDpMask != null) {
          prevOutput = mul(prevOutput, recDpMask);
        }
        let output = add3(h2, dot2(prevOutput, this.recurrentKernel.read()));
        if (this.activation != null) {
          output = this.activation.apply(output);
        }
        return [output, output];
      });
    }
    getConfig() {
      const baseConfig = super.getConfig();
      const config = {
        units: this.units,
        activation: serializeActivation(this.activation),
        useBias: this.useBias,
        kernelInitializer: serializeInitializer(this.kernelInitializer),
        recurrentInitializer: serializeInitializer(this.recurrentInitializer),
        biasInitializer: serializeInitializer(this.biasInitializer),
        kernelRegularizer: serializeRegularizer(this.kernelRegularizer),
        recurrentRegularizer: serializeRegularizer(this.recurrentRegularizer),
        biasRegularizer: serializeRegularizer(this.biasRegularizer),
        activityRegularizer: serializeRegularizer(this.activityRegularizer),
        kernelConstraint: serializeConstraint(this.kernelConstraint),
        recurrentConstraint: serializeConstraint(this.recurrentConstraint),
        biasConstraint: serializeConstraint(this.biasConstraint),
        dropout: this.dropout,
        recurrentDropout: this.recurrentDropout
      };
      return Object.assign({}, baseConfig, config);
    }
  };
  SimpleRNNCell.className = "SimpleRNNCell";
  serialization_exports.registerClass(SimpleRNNCell);
  var SimpleRNN = class extends RNN {
    constructor(args) {
      args.cell = new SimpleRNNCell(args);
      super(args);
    }
    call(inputs, kwargs) {
      return tidy(() => {
        if (this.cell.dropoutMask != null) {
          dispose(this.cell.dropoutMask);
          this.cell.dropoutMask = null;
        }
        if (this.cell.recurrentDropoutMask != null) {
          dispose(this.cell.recurrentDropoutMask);
          this.cell.recurrentDropoutMask = null;
        }
        const mask = kwargs == null ? null : kwargs["mask"];
        const training = kwargs == null ? null : kwargs["training"];
        const initialState = kwargs == null ? null : kwargs["initialState"];
        return super.call(inputs, { mask, training, initialState });
      });
    }
    static fromConfig(cls, config) {
      return new cls(config);
    }
  };
  SimpleRNN.className = "SimpleRNN";
  serialization_exports.registerClass(SimpleRNN);
  var GRUCell = class extends RNNCell {
    constructor(args) {
      super(args);
      this.DEFAULT_ACTIVATION = "tanh";
      this.DEFAULT_RECURRENT_ACTIVATION = "hardSigmoid";
      this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal";
      this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal";
      this.DEFAULT_BIAS_INITIALIZER = "zeros";
      if (args.resetAfter) {
        throw new ValueError(`GRUCell does not support reset_after parameter set to true.`);
      }
      this.units = args.units;
      assertPositiveInteger(this.units, "units");
      this.activation = getActivation(args.activation === void 0 ? this.DEFAULT_ACTIVATION : args.activation);
      this.recurrentActivation = getActivation(args.recurrentActivation === void 0 ? this.DEFAULT_RECURRENT_ACTIVATION : args.recurrentActivation);
      this.useBias = args.useBias == null ? true : args.useBias;
      this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);
      this.recurrentInitializer = getInitializer(args.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER);
      this.biasInitializer = getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);
      this.kernelRegularizer = getRegularizer(args.kernelRegularizer);
      this.recurrentRegularizer = getRegularizer(args.recurrentRegularizer);
      this.biasRegularizer = getRegularizer(args.biasRegularizer);
      this.kernelConstraint = getConstraint(args.kernelConstraint);
      this.recurrentConstraint = getConstraint(args.recurrentConstraint);
      this.biasConstraint = getConstraint(args.biasConstraint);
      this.dropout = min2([1, max2([0, args.dropout == null ? 0 : args.dropout])]);
      this.recurrentDropout = min2([
        1,
        max2([0, args.recurrentDropout == null ? 0 : args.recurrentDropout])
      ]);
      this.dropoutFunc = args.dropoutFunc;
      this.implementation = args.implementation;
      this.stateSize = this.units;
      this.dropoutMask = null;
      this.recurrentDropoutMask = null;
    }
    build(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      const inputDim = inputShape[inputShape.length - 1];
      this.kernel = this.addWeight("kernel", [inputDim, this.units * 3], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
      this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, this.units * 3], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);
      if (this.useBias) {
        this.bias = this.addWeight("bias", [this.units * 3], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);
      } else {
        this.bias = null;
      }
      this.built = true;
    }
    call(inputs, kwargs) {
      return tidy(() => {
        inputs = inputs;
        if (inputs.length !== 2) {
          throw new ValueError(`GRUCell expects 2 input Tensors (inputs, h, c), got ${inputs.length}.`);
        }
        const training = kwargs["training"] == null ? false : kwargs["training"];
        let hTMinus1 = inputs[1];
        inputs = inputs[0];
        if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {
          this.dropoutMask = generateDropoutMask({
            ones: () => onesLike(inputs),
            rate: this.dropout,
            training,
            count: 3,
            dropoutFunc: this.dropoutFunc
          });
        }
        if (0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null) {
          this.recurrentDropoutMask = generateDropoutMask({
            ones: () => onesLike(hTMinus1),
            rate: this.recurrentDropout,
            training,
            count: 3,
            dropoutFunc: this.dropoutFunc
          });
        }
        const dpMask = this.dropoutMask;
        const recDpMask = this.recurrentDropoutMask;
        let z;
        let r;
        let hh;
        if (0 < this.dropout && this.dropout < 1) {
          inputs = mul(inputs, dpMask[0]);
        }
        let matrixX = dot2(inputs, this.kernel.read());
        if (this.useBias) {
          matrixX = biasAdd(matrixX, this.bias.read());
        }
        if (0 < this.recurrentDropout && this.recurrentDropout < 1) {
          hTMinus1 = mul(hTMinus1, recDpMask[0]);
        }
        const recurrentKernelValue = this.recurrentKernel.read();
        const [rk1, rk2] = split(recurrentKernelValue, [2 * this.units, this.units], recurrentKernelValue.rank - 1);
        const matrixInner = dot2(hTMinus1, rk1);
        const [xZ, xR, xH] = split(matrixX, 3, matrixX.rank - 1);
        const [recurrentZ, recurrentR] = split(matrixInner, 2, matrixInner.rank - 1);
        z = this.recurrentActivation.apply(add3(xZ, recurrentZ));
        r = this.recurrentActivation.apply(add3(xR, recurrentR));
        const recurrentH = dot2(mul(r, hTMinus1), rk2);
        hh = this.activation.apply(add3(xH, recurrentH));
        const h2 = add3(mul(z, hTMinus1), mul(add3(1, neg(z)), hh));
        return [h2, h2];
      });
    }
    getConfig() {
      const baseConfig = super.getConfig();
      const config = {
        units: this.units,
        activation: serializeActivation(this.activation),
        recurrentActivation: serializeActivation(this.recurrentActivation),
        useBias: this.useBias,
        kernelInitializer: serializeInitializer(this.kernelInitializer),
        recurrentInitializer: serializeInitializer(this.recurrentInitializer),
        biasInitializer: serializeInitializer(this.biasInitializer),
        kernelRegularizer: serializeRegularizer(this.kernelRegularizer),
        recurrentRegularizer: serializeRegularizer(this.recurrentRegularizer),
        biasRegularizer: serializeRegularizer(this.biasRegularizer),
        activityRegularizer: serializeRegularizer(this.activityRegularizer),
        kernelConstraint: serializeConstraint(this.kernelConstraint),
        recurrentConstraint: serializeConstraint(this.recurrentConstraint),
        biasConstraint: serializeConstraint(this.biasConstraint),
        dropout: this.dropout,
        recurrentDropout: this.recurrentDropout,
        implementation: this.implementation,
        resetAfter: false
      };
      return Object.assign({}, baseConfig, config);
    }
  };
  GRUCell.className = "GRUCell";
  serialization_exports.registerClass(GRUCell);
  var GRU = class extends RNN {
    constructor(args) {
      if (args.implementation === 0) {
        console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call.");
      }
      args.cell = new GRUCell(args);
      super(args);
    }
    call(inputs, kwargs) {
      return tidy(() => {
        if (this.cell.dropoutMask != null) {
          dispose(this.cell.dropoutMask);
          this.cell.dropoutMask = null;
        }
        if (this.cell.recurrentDropoutMask != null) {
          dispose(this.cell.recurrentDropoutMask);
          this.cell.recurrentDropoutMask = null;
        }
        const mask = kwargs == null ? null : kwargs["mask"];
        const training = kwargs == null ? null : kwargs["training"];
        const initialState = kwargs == null ? null : kwargs["initialState"];
        return super.call(inputs, { mask, training, initialState });
      });
    }
    static fromConfig(cls, config) {
      if (config["implmentation"] === 0) {
        config["implementation"] = 1;
      }
      return new cls(config);
    }
  };
  GRU.className = "GRU";
  serialization_exports.registerClass(GRU);
  var LSTMCell = class extends RNNCell {
    constructor(args) {
      super(args);
      this.DEFAULT_ACTIVATION = "tanh";
      this.DEFAULT_RECURRENT_ACTIVATION = "hardSigmoid";
      this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal";
      this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal";
      this.DEFAULT_BIAS_INITIALIZER = "zeros";
      this.units = args.units;
      assertPositiveInteger(this.units, "units");
      this.activation = getActivation(args.activation === void 0 ? this.DEFAULT_ACTIVATION : args.activation);
      this.recurrentActivation = getActivation(args.recurrentActivation === void 0 ? this.DEFAULT_RECURRENT_ACTIVATION : args.recurrentActivation);
      this.useBias = args.useBias == null ? true : args.useBias;
      this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);
      this.recurrentInitializer = getInitializer(args.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER);
      this.biasInitializer = getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);
      this.unitForgetBias = args.unitForgetBias;
      this.kernelRegularizer = getRegularizer(args.kernelRegularizer);
      this.recurrentRegularizer = getRegularizer(args.recurrentRegularizer);
      this.biasRegularizer = getRegularizer(args.biasRegularizer);
      this.kernelConstraint = getConstraint(args.kernelConstraint);
      this.recurrentConstraint = getConstraint(args.recurrentConstraint);
      this.biasConstraint = getConstraint(args.biasConstraint);
      this.dropout = min2([1, max2([0, args.dropout == null ? 0 : args.dropout])]);
      this.recurrentDropout = min2([
        1,
        max2([0, args.recurrentDropout == null ? 0 : args.recurrentDropout])
      ]);
      this.dropoutFunc = args.dropoutFunc;
      this.implementation = args.implementation;
      this.stateSize = [this.units, this.units];
      this.dropoutMask = null;
      this.recurrentDropoutMask = null;
    }
    build(inputShape) {
      var _a2;
      inputShape = getExactlyOneShape(inputShape);
      const inputDim = inputShape[inputShape.length - 1];
      this.kernel = this.addWeight("kernel", [inputDim, this.units * 4], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
      this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, this.units * 4], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);
      let biasInitializer;
      if (this.useBias) {
        if (this.unitForgetBias) {
          const capturedBiasInit = this.biasInitializer;
          const capturedUnits = this.units;
          biasInitializer = new (_a2 = class CustomInit extends Initializer {
            apply(shape, dtype) {
              const bI = capturedBiasInit.apply([capturedUnits]);
              const bF = new Ones().apply([capturedUnits]);
              const bCAndH = capturedBiasInit.apply([capturedUnits * 2]);
              return concatAlongFirstAxis(concatAlongFirstAxis(bI, bF), bCAndH);
            }
          }, _a2.className = "CustomInit", _a2)();
        } else {
          biasInitializer = this.biasInitializer;
        }
        this.bias = this.addWeight("bias", [this.units * 4], null, biasInitializer, this.biasRegularizer, true, this.biasConstraint);
      } else {
        this.bias = null;
      }
      this.built = true;
    }
    call(inputs, kwargs) {
      return tidy(() => {
        const training = kwargs["training"] == null ? false : kwargs["training"];
        inputs = inputs;
        if (inputs.length !== 3) {
          throw new ValueError(`LSTMCell expects 3 input Tensors (inputs, h, c), got ${inputs.length}.`);
        }
        let hTMinus1 = inputs[1];
        const cTMinus1 = inputs[2];
        inputs = inputs[0];
        if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {
          this.dropoutMask = generateDropoutMask({
            ones: () => onesLike(inputs),
            rate: this.dropout,
            training,
            count: 4,
            dropoutFunc: this.dropoutFunc
          });
        }
        if (0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null) {
          this.recurrentDropoutMask = generateDropoutMask({
            ones: () => onesLike(hTMinus1),
            rate: this.recurrentDropout,
            training,
            count: 4,
            dropoutFunc: this.dropoutFunc
          });
        }
        const dpMask = this.dropoutMask;
        const recDpMask = this.recurrentDropoutMask;
        let i;
        let f;
        let c;
        let o;
        if (0 < this.dropout && this.dropout < 1) {
          inputs = mul(inputs, dpMask[0]);
        }
        let z = dot2(inputs, this.kernel.read());
        if (0 < this.recurrentDropout && this.recurrentDropout < 1) {
          hTMinus1 = mul(hTMinus1, recDpMask[0]);
        }
        z = add3(z, dot2(hTMinus1, this.recurrentKernel.read()));
        if (this.useBias) {
          z = biasAdd(z, this.bias.read());
        }
        const [z0, z1, z2, z3] = split(z, 4, z.rank - 1);
        i = this.recurrentActivation.apply(z0);
        f = this.recurrentActivation.apply(z1);
        c = add3(mul(f, cTMinus1), mul(i, this.activation.apply(z2)));
        o = this.recurrentActivation.apply(z3);
        const h2 = mul(o, this.activation.apply(c));
        return [h2, h2, c];
      });
    }
    getConfig() {
      const baseConfig = super.getConfig();
      const config = {
        units: this.units,
        activation: serializeActivation(this.activation),
        recurrentActivation: serializeActivation(this.recurrentActivation),
        useBias: this.useBias,
        kernelInitializer: serializeInitializer(this.kernelInitializer),
        recurrentInitializer: serializeInitializer(this.recurrentInitializer),
        biasInitializer: serializeInitializer(this.biasInitializer),
        unitForgetBias: this.unitForgetBias,
        kernelRegularizer: serializeRegularizer(this.kernelRegularizer),
        recurrentRegularizer: serializeRegularizer(this.recurrentRegularizer),
        biasRegularizer: serializeRegularizer(this.biasRegularizer),
        activityRegularizer: serializeRegularizer(this.activityRegularizer),
        kernelConstraint: serializeConstraint(this.kernelConstraint),
        recurrentConstraint: serializeConstraint(this.recurrentConstraint),
        biasConstraint: serializeConstraint(this.biasConstraint),
        dropout: this.dropout,
        recurrentDropout: this.recurrentDropout,
        implementation: this.implementation
      };
      return Object.assign({}, baseConfig, config);
    }
  };
  LSTMCell.className = "LSTMCell";
  serialization_exports.registerClass(LSTMCell);
  var LSTM = class extends RNN {
    constructor(args) {
      if (args.implementation === 0) {
        console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call.");
      }
      args.cell = new LSTMCell(args);
      super(args);
    }
    call(inputs, kwargs) {
      return tidy(() => {
        if (this.cell.dropoutMask != null) {
          dispose(this.cell.dropoutMask);
          this.cell.dropoutMask = null;
        }
        if (this.cell.recurrentDropoutMask != null) {
          dispose(this.cell.recurrentDropoutMask);
          this.cell.recurrentDropoutMask = null;
        }
        const mask = kwargs == null ? null : kwargs["mask"];
        const training = kwargs == null ? null : kwargs["training"];
        const initialState = kwargs == null ? null : kwargs["initialState"];
        return super.call(inputs, { mask, training, initialState });
      });
    }
    static fromConfig(cls, config) {
      if (config["implmentation"] === 0) {
        config["implementation"] = 1;
      }
      return new cls(config);
    }
  };
  LSTM.className = "LSTM";
  serialization_exports.registerClass(LSTM);
  var StackedRNNCells = class extends RNNCell {
    constructor(args) {
      super(args);
      this.cells = args.cells;
    }
    get stateSize() {
      const stateSize = [];
      for (const cell of this.cells.slice().reverse()) {
        if (Array.isArray(cell.stateSize)) {
          stateSize.push(...cell.stateSize);
        } else {
          stateSize.push(cell.stateSize);
        }
      }
      return stateSize;
    }
    call(inputs, kwargs) {
      return tidy(() => {
        inputs = inputs;
        let states = inputs.slice(1);
        const nestedStates = [];
        for (const cell of this.cells.slice().reverse()) {
          if (Array.isArray(cell.stateSize)) {
            nestedStates.push(states.splice(0, cell.stateSize.length));
          } else {
            nestedStates.push(states.splice(0, 1));
          }
        }
        nestedStates.reverse();
        const newNestedStates = [];
        let callInputs;
        for (let i = 0; i < this.cells.length; ++i) {
          const cell = this.cells[i];
          states = nestedStates[i];
          if (i === 0) {
            callInputs = [inputs[0]].concat(states);
          } else {
            callInputs = [callInputs[0]].concat(states);
          }
          callInputs = cell.call(callInputs, kwargs);
          newNestedStates.push(callInputs.slice(1));
        }
        states = [];
        for (const cellStates of newNestedStates.slice().reverse()) {
          states.push(...cellStates);
        }
        return [callInputs[0]].concat(states);
      });
    }
    build(inputShape) {
      if (isArrayOfShapes(inputShape)) {
        inputShape = inputShape[0];
      }
      inputShape = inputShape;
      let outputDim;
      this.cells.forEach((cell, i) => {
        nameScope(`RNNCell_${i}`, () => {
          cell.build(inputShape);
          if (Array.isArray(cell.stateSize)) {
            outputDim = cell.stateSize[0];
          } else {
            outputDim = cell.stateSize;
          }
          inputShape = [inputShape[0], outputDim];
        });
      });
      this.built = true;
    }
    getConfig() {
      const baseConfig = super.getConfig();
      const getCellConfig = (cell) => {
        return {
          "className": cell.getClassName(),
          "config": cell.getConfig()
        };
      };
      const cellConfigs = this.cells.map(getCellConfig);
      const config = { "cells": cellConfigs };
      return Object.assign({}, baseConfig, config);
    }
    static fromConfig(cls, config, customObjects = {}) {
      const cells = [];
      for (const cellConfig of config["cells"]) {
        cells.push(deserialize(cellConfig, customObjects));
      }
      return new cls({ cells });
    }
    get trainableWeights() {
      if (!this.trainable) {
        return [];
      }
      const weights = [];
      for (const cell of this.cells) {
        weights.push(...cell.trainableWeights);
      }
      return weights;
    }
    get nonTrainableWeights() {
      const weights = [];
      for (const cell of this.cells) {
        weights.push(...cell.nonTrainableWeights);
      }
      if (!this.trainable) {
        const trainableWeights = [];
        for (const cell of this.cells) {
          trainableWeights.push(...cell.trainableWeights);
        }
        return trainableWeights.concat(weights);
      }
      return weights;
    }
    getWeights() {
      const weights = [];
      for (const cell of this.cells) {
        weights.push(...cell.weights);
      }
      return batchGetValue(weights);
    }
    setWeights(weights) {
      const tuples = [];
      for (const cell of this.cells) {
        const numParams = cell.weights.length;
        const inputWeights = weights.splice(numParams);
        for (let i = 0; i < cell.weights.length; ++i) {
          tuples.push([cell.weights[i], inputWeights[i]]);
        }
      }
      batchSetValue(tuples);
    }
  };
  StackedRNNCells.className = "StackedRNNCells";
  serialization_exports.registerClass(StackedRNNCells);
  function generateDropoutMask(args) {
    const { ones: ones3, rate, training = false, count: count2 = 1, dropoutFunc } = args;
    const droppedInputs = () => dropoutFunc != null ? dropoutFunc(ones3(), rate) : dropout2(ones3(), rate);
    const createMask = () => inTrainPhase(droppedInputs, ones3, training);
    if (!count2 || count2 <= 1) {
      return keep(createMask().clone());
    }
    const masks = Array(count2).fill(void 0).map(createMask);
    return masks.map((m) => keep(m.clone()));
  }

  // node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional_recurrent.js
  var __rest = function(s, e) {
    var t = {};
    for (var p3 in s)
      if (Object.prototype.hasOwnProperty.call(s, p3) && e.indexOf(p3) < 0)
        t[p3] = s[p3];
    if (s != null && typeof Object.getOwnPropertySymbols === "function")
      for (var i = 0, p3 = Object.getOwnPropertySymbols(s); i < p3.length; i++) {
        if (e.indexOf(p3[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p3[i]))
          t[p3[i]] = s[p3[i]];
      }
    return t;
  };
  var ConvRNN2D = class extends RNN {
    constructor(args) {
      if (args.unroll) {
        throw new NotImplementedError("Unrolling is not possible with convolutional RNNs.");
      }
      if (Array.isArray(args.cell)) {
        throw new NotImplementedError("It is not possible at the moment to stack convolutional cells.");
      }
      super(args);
      this.inputSpec = [new InputSpec({ ndim: 5 })];
    }
    call(inputs, kwargs) {
      return tidy(() => {
        if (this.cell.dropoutMask != null) {
          dispose(this.cell.dropoutMask);
          this.cell.dropoutMask = null;
        }
        if (this.cell.recurrentDropoutMask != null) {
          dispose(this.cell.recurrentDropoutMask);
          this.cell.recurrentDropoutMask = null;
        }
        if (kwargs && kwargs["constants"]) {
          throw new ValueError("ConvRNN2D cell does not support constants");
        }
        const mask = kwargs == null ? null : kwargs["mask"];
        const training = kwargs == null ? null : kwargs["training"];
        const initialState = kwargs == null ? null : kwargs["initialState"];
        return super.call(inputs, { mask, training, initialState });
      });
    }
    computeOutputShape(inputShape) {
      let outShape = this.computeSingleOutputShape(inputShape);
      if (!this.returnSequences) {
        outShape = [outShape[0], ...outShape.slice(2)];
      }
      if (this.returnState) {
        outShape = [outShape, ...Array(2).fill([inputShape[0], ...outShape.slice(-3)])];
      }
      return outShape;
    }
    getInitialState(inputs) {
      return tidy(() => {
        const { stateSize } = this.cell;
        const inputShape = inputs.shape;
        const outputShape = this.computeSingleOutputShape(inputShape);
        const stateShape = [outputShape[0], ...outputShape.slice(2)];
        const initialState = zeros(stateShape);
        if (Array.isArray(stateSize)) {
          return Array(stateSize.length).fill(initialState);
        }
        return [initialState];
      });
    }
    resetStates(states, training = false) {
      tidy(() => {
        if (!this.stateful) {
          throw new AttributeError("Cannot call resetStates() on an RNN Layer that is not stateful.");
        }
        const inputShape = this.inputSpec[0].shape;
        const outputShape = this.computeSingleOutputShape(inputShape);
        const stateShape = [outputShape[0], ...outputShape.slice(2)];
        const batchSize = inputShape[0];
        if (batchSize == null) {
          throw new ValueError("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");
        }
        if (this.getStates() == null) {
          if (Array.isArray(this.cell.stateSize)) {
            this.states_ = this.cell.stateSize.map(() => zeros(stateShape));
          } else {
            this.states_ = [zeros(stateShape)];
          }
        } else if (states == null) {
          dispose(this.states_);
          if (this.keptStates != null) {
            dispose(this.keptStates);
            this.keptStates = [];
          }
          if (Array.isArray(this.cell.stateSize)) {
            this.states_ = this.cell.stateSize.map(() => zeros(stateShape));
          } else {
            this.states_[0] = zeros(stateShape);
          }
        } else {
          if (!Array.isArray(states)) {
            states = [states];
          }
          if (states.length !== this.states_.length) {
            throw new ValueError(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${states.length} state value(s). Input received: ${states}`);
          }
          if (training) {
            this.keptStates.push(this.states_.slice());
          } else {
            dispose(this.states_);
          }
          for (let index = 0; index < this.states_.length; ++index) {
            const value = states[index];
            const expectedShape = stateShape;
            if (!util_exports.arraysEqual(value.shape, expectedShape)) {
              throw new ValueError(`State ${index} is incompatible with layer ${this.name}: expected shape=${expectedShape}, received shape=${value.shape}`);
            }
            this.states_[index] = value;
          }
        }
        this.states_ = this.states_.map((state) => keep(state.clone()));
      });
    }
    computeSingleOutputShape(inputShape) {
      const { dataFormat, filters, kernelSize, padding, strides, dilationRate } = this.cell;
      const isChannelsFirst = dataFormat === "channelsFirst";
      const h2 = inputShape[isChannelsFirst ? 3 : 2];
      const w = inputShape[isChannelsFirst ? 4 : 3];
      const hOut = convOutputLength(h2, kernelSize[0], padding, strides[0], dilationRate[0]);
      const wOut = convOutputLength(w, kernelSize[1], padding, strides[1], dilationRate[1]);
      const outShape = [
        ...inputShape.slice(0, 2),
        ...isChannelsFirst ? [filters, hOut, wOut] : [hOut, wOut, filters]
      ];
      return outShape;
    }
  };
  ConvRNN2D.className = "ConvRNN2D";
  var ConvLSTM2DCell = class extends LSTMCell {
    constructor(args) {
      const { filters, kernelSize, strides, padding, dataFormat, dilationRate } = args;
      super(Object.assign({}, args, { units: filters }));
      this.filters = filters;
      assertPositiveInteger(this.filters, "filters");
      this.kernelSize = normalizeArray(kernelSize, 2, "kernelSize");
      this.kernelSize.forEach((size2) => assertPositiveInteger(size2, "kernelSize"));
      this.strides = normalizeArray(strides || 1, 2, "strides");
      this.strides.forEach((stride) => assertPositiveInteger(stride, "strides"));
      this.padding = padding || "valid";
      checkPaddingMode(this.padding);
      this.dataFormat = dataFormat || "channelsLast";
      checkDataFormat(this.dataFormat);
      this.dilationRate = normalizeArray(dilationRate || 1, 2, "dilationRate");
      this.dilationRate.forEach((rate) => assertPositiveInteger(rate, "dilationRate"));
    }
    build(inputShape) {
      var _a2;
      inputShape = getExactlyOneShape(inputShape);
      const channelAxis = this.dataFormat === "channelsFirst" ? 1 : inputShape.length - 1;
      if (inputShape[channelAxis] == null) {
        throw new ValueError(`The channel dimension of the input should be defined. Found ${inputShape[channelAxis]}`);
      }
      const inputDim = inputShape[channelAxis];
      const numOfKernels = 4;
      const kernelShape = this.kernelSize.concat([inputDim, this.filters * numOfKernels]);
      this.kernel = this.addWeight("kernel", kernelShape, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
      const recurrentKernelShape = this.kernelSize.concat([this.filters, this.filters * numOfKernels]);
      this.recurrentKernel = this.addWeight("recurrent_kernel", recurrentKernelShape, null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);
      if (this.useBias) {
        let biasInitializer;
        if (this.unitForgetBias) {
          const init = this.biasInitializer;
          const filters = this.filters;
          biasInitializer = new (_a2 = class CustomInit extends Initializer {
            apply(shape, dtype) {
              const biasI = init.apply([filters]);
              const biasF = ones2([filters]);
              const biasCAndO = init.apply([filters * 2]);
              return concatenate([biasI, biasF, biasCAndO]);
            }
          }, _a2.className = "CustomInit", _a2)();
        } else {
          biasInitializer = this.biasInitializer;
        }
        this.bias = this.addWeight("bias", [this.filters * numOfKernels], null, biasInitializer, this.biasRegularizer, true, this.biasConstraint);
      }
      this.built = true;
    }
    call(inputs, kwargs) {
      return tidy(() => {
        if (inputs.length !== 3) {
          throw new ValueError(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ${inputs.length}.`);
        }
        const training = kwargs["training"] || false;
        const x = inputs[0];
        const hTMinus1 = inputs[1];
        const cTMinus1 = inputs[2];
        const numOfKernels = 4;
        if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {
          this.dropoutMask = generateDropoutMask({
            ones: () => onesLike(x),
            rate: this.dropout,
            training,
            count: numOfKernels,
            dropoutFunc: this.dropoutFunc
          });
        }
        const dropoutMask = this.dropoutMask;
        const applyDropout = (x2, mask, index) => {
          if (!mask || !mask[index]) {
            return x2;
          }
          return mul(mask[index], x2);
        };
        let xI = applyDropout(x, dropoutMask, 0);
        let xF = applyDropout(x, dropoutMask, 1);
        let xC = applyDropout(x, dropoutMask, 2);
        let xO = applyDropout(x, dropoutMask, 3);
        if (0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null) {
          this.recurrentDropoutMask = generateDropoutMask({
            ones: () => onesLike(hTMinus1),
            rate: this.recurrentDropout,
            training,
            count: numOfKernels,
            dropoutFunc: this.dropoutFunc
          });
        }
        const recDropoutMask = this.recurrentDropoutMask;
        let hI = applyDropout(hTMinus1, recDropoutMask, 0);
        let hF = applyDropout(hTMinus1, recDropoutMask, 1);
        let hC = applyDropout(hTMinus1, recDropoutMask, 2);
        let hO = applyDropout(hTMinus1, recDropoutMask, 3);
        const kernelChannelAxis = 3;
        const [kernelI, kernelF, kernelC, kernelO] = split(this.kernel.read(), numOfKernels, kernelChannelAxis);
        const [biasI, biasF, biasC, biasO] = this.useBias ? split(this.bias.read(), numOfKernels) : [null, null, null, null];
        xI = this.inputConv(xI, kernelI, biasI, this.padding);
        xF = this.inputConv(xF, kernelF, biasF, this.padding);
        xC = this.inputConv(xC, kernelC, biasC, this.padding);
        xO = this.inputConv(xO, kernelO, biasO, this.padding);
        const [recKernelI, recKernelF, recKernelC, recKernelO] = split(this.recurrentKernel.read(), numOfKernels, kernelChannelAxis);
        hI = this.recurrentConv(hI, recKernelI);
        hF = this.recurrentConv(hF, recKernelF);
        hC = this.recurrentConv(hC, recKernelC);
        hO = this.recurrentConv(hO, recKernelO);
        const i = this.recurrentActivation.apply(add3(xI, hI));
        const f = this.recurrentActivation.apply(add3(xF, hF));
        const c = add3(mul(f, cTMinus1), mul(i, this.activation.apply(add3(xC, hC))));
        const h2 = mul(this.recurrentActivation.apply(add3(xO, hO)), this.activation.apply(c));
        return [h2, h2, c];
      });
    }
    getConfig() {
      const _a2 = super.getConfig(), { "units": _ } = _a2, baseConfig = __rest(_a2, ["units"]);
      const config = {
        filters: this.filters,
        kernelSize: this.kernelSize,
        padding: this.padding,
        dataFormat: this.dataFormat,
        dilationRate: this.dilationRate,
        strides: this.strides
      };
      return Object.assign({}, baseConfig, config);
    }
    inputConv(x, w, b, padding) {
      const out = conv2d(x, w, this.strides, padding || "valid", this.dataFormat === "channelsFirst" ? "NCHW" : "NHWC", this.dilationRate);
      if (b) {
        return biasAdd(out, b, this.dataFormat);
      }
      return out;
    }
    recurrentConv(x, w) {
      const strides = 1;
      return conv2d(x, w, strides, "same", this.dataFormat === "channelsFirst" ? "NCHW" : "NHWC");
    }
  };
  ConvLSTM2DCell.className = "ConvLSTM2DCell";
  serialization_exports.registerClass(ConvLSTM2DCell);
  var ConvLSTM2D = class extends ConvRNN2D {
    constructor(args) {
      const cell = new ConvLSTM2DCell(args);
      super(Object.assign({}, args, { cell }));
    }
    static fromConfig(cls, config) {
      return new cls(config);
    }
  };
  ConvLSTM2D.className = "ConvLSTM2D";
  serialization_exports.registerClass(ConvLSTM2D);

  // node_modules/@tensorflow/tfjs-layers/dist/layers/core.js
  var Dropout = class extends Layer {
    constructor(args) {
      super(args);
      this.rate = Math.max(Math.min(args.rate, 1), 0);
      this.noiseShape = args.noiseShape;
      this.seed = args.seed;
      this.supportsMasking = true;
    }
    getNoiseShape(input2) {
      if (this.noiseShape == null) {
        return this.noiseShape;
      }
      const inputShape = input2.shape;
      const noiseShape = [];
      for (let i = 0; i < this.noiseShape.length; ++i) {
        noiseShape.push(this.noiseShape[i] == null ? inputShape[i] : this.noiseShape[i]);
      }
      return noiseShape;
    }
    call(inputs, kwargs) {
      return tidy(() => {
        this.invokeCallHook(inputs, kwargs);
        const input2 = getExactlyOneTensor(inputs);
        if (0 < this.rate && this.rate < 1) {
          const training = kwargs["training"] == null ? false : kwargs["training"];
          const noiseShape = this.getNoiseShape(input2);
          const output = inTrainPhase(() => dropout2(input2, this.rate, noiseShape, this.seed), () => input2, training);
          return output;
        }
        return inputs;
      });
    }
    getConfig() {
      const config = {
        rate: this.rate,
        noiseShape: this.noiseShape,
        seed: this.seed
      };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
    dispose() {
      return super.dispose();
    }
  };
  Dropout.className = "Dropout";
  serialization_exports.registerClass(Dropout);
  var SpatialDropout1D = class extends Dropout {
    constructor(args) {
      super(args);
      this.inputSpec = [{ ndim: 3 }];
    }
    getNoiseShape(input2) {
      const inputShape = input2.shape;
      return [inputShape[0], 1, inputShape[2]];
    }
  };
  SpatialDropout1D.className = "SpatialDropout1D";
  serialization_exports.registerClass(SpatialDropout1D);
  var Dense = class extends Layer {
    constructor(args) {
      super(args);
      this.activation = null;
      this.useBias = true;
      this.kernel = null;
      this.bias = null;
      this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal";
      this.DEFAULT_BIAS_INITIALIZER = "zeros";
      if (args.batchInputShape == null && args.inputShape == null && args.inputDim != null) {
        let batchSize = null;
        if (args.batchSize != null) {
          batchSize = args.batchSize;
        }
        this.batchInputShape = [batchSize, args.inputDim];
      }
      this.units = args.units;
      assertPositiveInteger(this.units, "units");
      this.activation = getActivation(args.activation);
      if (args.useBias != null) {
        this.useBias = args.useBias;
      }
      this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);
      this.biasInitializer = getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);
      this.kernelConstraint = getConstraint(args.kernelConstraint);
      this.biasConstraint = getConstraint(args.biasConstraint);
      this.kernelRegularizer = getRegularizer(args.kernelRegularizer);
      this.biasRegularizer = getRegularizer(args.biasRegularizer);
      this.activityRegularizer = getRegularizer(args.activityRegularizer);
      this.supportsMasking = true;
      this.inputSpec = [{ minNDim: 2 }];
    }
    build(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      const inputLastDim = inputShape[inputShape.length - 1];
      if (this.kernel == null) {
        this.kernel = this.addWeight("kernel", [inputLastDim, this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
        if (this.useBias) {
          this.bias = this.addWeight("bias", [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);
        }
      }
      this.inputSpec = [{ minNDim: 2, axes: { [-1]: inputLastDim } }];
      this.built = true;
    }
    computeOutputShape(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      const outputShape = inputShape.slice();
      outputShape[outputShape.length - 1] = this.units;
      return outputShape;
    }
    call(inputs, kwargs) {
      return tidy(() => {
        this.invokeCallHook(inputs, kwargs);
        const input2 = getExactlyOneTensor(inputs);
        const fusedActivationName = mapActivationToFusedKernel(this.activation.getClassName());
        let output;
        if (fusedActivationName != null) {
          output = dot2(input2, this.kernel.read(), fusedActivationName, this.bias ? this.bias.read() : null);
        } else {
          output = dot2(input2, this.kernel.read());
          if (this.bias != null) {
            output = biasAdd(output, this.bias.read());
          }
          if (this.activation != null) {
            output = this.activation.apply(output);
          }
        }
        return output;
      });
    }
    getConfig() {
      const config = {
        units: this.units,
        activation: serializeActivation(this.activation),
        useBias: this.useBias,
        kernelInitializer: serializeInitializer(this.kernelInitializer),
        biasInitializer: serializeInitializer(this.biasInitializer),
        kernelRegularizer: serializeRegularizer(this.kernelRegularizer),
        biasRegularizer: serializeRegularizer(this.biasRegularizer),
        activityRegularizer: serializeRegularizer(this.activityRegularizer),
        kernelConstraint: serializeConstraint(this.kernelConstraint),
        biasConstraint: serializeConstraint(this.biasConstraint)
      };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  Dense.className = "Dense";
  serialization_exports.registerClass(Dense);
  var Flatten = class extends Layer {
    constructor(args) {
      args = args || {};
      super(args);
      this.inputSpec = [{ minNDim: 3 }];
      this.dataFormat = args.dataFormat;
    }
    computeOutputShape(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      for (const dim of inputShape.slice(1)) {
        if (dim == null) {
          throw new ValueError(`The shape of the input to "Flatten" is not fully defined (got ${inputShape.slice(1)}). Make sure to pass a complete "input_shape" or "batch_input_shape" argument to the first layer in your model.`);
        }
      }
      return [inputShape[0], arrayProd(inputShape, 1)];
    }
    call(inputs, kwargs) {
      return tidy(() => {
        this.invokeCallHook(inputs, kwargs);
        let input2 = getExactlyOneTensor(inputs);
        if (this.dataFormat === "channelsFirst" && input2.rank > 1) {
          const permutation = [0];
          for (let i = 2; i < input2.rank; ++i) {
            permutation.push(i);
          }
          permutation.push(1);
          input2 = transpose(input2, permutation);
        }
        return batchFlatten(input2);
      });
    }
    getConfig() {
      const config = {};
      if (this.dataFormat != null) {
        config["dataFormat"] = this.dataFormat;
      }
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  Flatten.className = "Flatten";
  serialization_exports.registerClass(Flatten);
  var Activation2 = class extends Layer {
    constructor(args) {
      super(args);
      this.supportsMasking = true;
      this.activation = getActivation(args.activation);
    }
    call(inputs, kwargs) {
      return tidy(() => {
        this.invokeCallHook(inputs, kwargs);
        const input2 = getExactlyOneTensor(inputs);
        return this.activation.apply(input2);
      });
    }
    getConfig() {
      const config = { activation: serializeActivation(this.activation) };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  Activation2.className = "Activation";
  serialization_exports.registerClass(Activation2);
  var RepeatVector = class extends Layer {
    constructor(args) {
      super(args);
      this.n = args.n;
      this.inputSpec = [{ ndim: 2 }];
    }
    computeOutputShape(inputShape) {
      return [inputShape[0], this.n, inputShape[1]];
    }
    call(inputs, kwargs) {
      return tidy(() => {
        inputs = getExactlyOneTensor(inputs);
        return repeat(inputs, this.n);
      });
    }
    getConfig() {
      const config = {
        n: this.n
      };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  RepeatVector.className = "RepeatVector";
  serialization_exports.registerClass(RepeatVector);
  var Reshape2 = class extends Layer {
    constructor(args) {
      super(args);
      this.targetShape = args.targetShape;
      for (let i = 0; i < this.targetShape.length; ++i) {
        if (this.isUnknown(this.targetShape[i])) {
          this.targetShape[i] = null;
        }
      }
    }
    isUnknown(dim) {
      return dim < 0 || dim == null;
    }
    fixUnknownDimension(inputShape, outputShape) {
      const errorMsg = "Total size of new array must be unchanged.";
      const finalShape = outputShape.slice();
      let known = 1;
      let unknown = null;
      for (let i = 0; i < finalShape.length; ++i) {
        const dim = finalShape[i];
        if (this.isUnknown(dim)) {
          if (unknown === null) {
            unknown = i;
          } else {
            throw new ValueError("Can only specifiy one unknown dimension.");
          }
        } else {
          known *= dim;
        }
      }
      const originalSize = arrayProd(inputShape);
      if (unknown !== null) {
        if (known === 0 || originalSize % known !== 0) {
          throw new ValueError(errorMsg);
        }
        finalShape[unknown] = originalSize / known;
      } else if (originalSize !== known) {
        throw new ValueError(errorMsg);
      }
      return finalShape;
    }
    computeOutputShape(inputShape) {
      let anyUnknownDims = false;
      for (let i = 0; i < inputShape.length; ++i) {
        if (this.isUnknown(inputShape[i])) {
          anyUnknownDims = true;
          break;
        }
      }
      if (anyUnknownDims) {
        return inputShape.slice(0, 1).concat(this.targetShape);
      } else {
        return inputShape.slice(0, 1).concat(this.fixUnknownDimension(inputShape.slice(1), this.targetShape));
      }
    }
    call(inputs, kwargs) {
      return tidy(() => {
        this.invokeCallHook(inputs, kwargs);
        const input2 = getExactlyOneTensor(inputs);
        const inputShape = input2.shape;
        const outputShape = inputShape.slice(0, 1).concat(this.fixUnknownDimension(inputShape.slice(1), this.targetShape));
        return reshape(input2, outputShape);
      });
    }
    getConfig() {
      const config = {
        targetShape: this.targetShape
      };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  Reshape2.className = "Reshape";
  serialization_exports.registerClass(Reshape2);
  var Permute = class extends Layer {
    constructor(args) {
      super(args);
      if (args.dims == null) {
        throw new Error("Required configuration field `dims` is missing during Permute constructor call.");
      }
      if (!Array.isArray(args.dims)) {
        throw new Error(`Permute constructor requires \`dims\` to be an Array, but received ${args.dims} instead.`);
      }
      const expectedSortedIndices = range2(1, args.dims.length + 1);
      if (!util_exports.arraysEqual(args.dims.slice().sort(), expectedSortedIndices)) {
        throw new Error("Invalid permutation `dims`: " + JSON.stringify(args.dims) + " `dims` must contain consecutive integers starting from 1.");
      }
      this.dims = args.dims;
      this.dimsIncludingBatch = [0].concat(this.dims);
      this.inputSpec = [new InputSpec({ ndim: this.dims.length + 1 })];
    }
    computeOutputShape(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      const outputShape = inputShape.slice();
      this.dims.forEach((dim, i) => {
        outputShape[i + 1] = inputShape[dim];
      });
      return outputShape;
    }
    call(inputs, kwargs) {
      return transpose(getExactlyOneTensor(inputs), this.dimsIncludingBatch);
    }
    getConfig() {
      const config = {
        dims: this.dims
      };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  Permute.className = "Permute";
  serialization_exports.registerClass(Permute);
  var Masking = class extends Layer {
    constructor(args) {
      super(args == null ? {} : args);
      this.supportsMasking = true;
      if (args != null) {
        this.maskValue = args.maskValue == null ? 0 : args.maskValue;
      } else {
        this.maskValue = 0;
      }
    }
    computeOutputShape(inputShape) {
      return inputShape;
    }
    getConfig() {
      const baseConfig = super.getConfig();
      const config = { maskValue: this.maskValue };
      Object.assign(config, baseConfig);
      return config;
    }
    computeMask(inputs, mask) {
      const input2 = getExactlyOneTensor(inputs);
      const axis = -1;
      return any(notEqual(input2, this.maskValue), axis);
    }
    call(inputs, kwargs) {
      return tidy(() => {
        this.invokeCallHook(inputs, kwargs);
        const input2 = getExactlyOneTensor(inputs);
        const axis = -1;
        const keepDims = true;
        const booleanMask = any(notEqual(input2, this.maskValue), axis, keepDims);
        const output = mul(input2, cast(booleanMask, input2.dtype));
        return output;
      });
    }
  };
  Masking.className = "Masking";
  serialization_exports.registerClass(Masking);

  // node_modules/@tensorflow/tfjs-layers/dist/layers/embeddings.js
  var Embedding = class extends Layer {
    constructor(args) {
      super(args);
      this.embeddings = null;
      this.DEFAULT_EMBEDDINGS_INITIALIZER = "randomUniform";
      if (args.batchInputShape == null && args.inputShape == null) {
        let batchSize = null;
        if (args.batchSize != null) {
          batchSize = args.batchSize;
        }
        if (args.inputLength == null) {
          this.batchInputShape = [batchSize, null];
        } else {
          this.batchInputShape = [batchSize].concat(toList(args.inputLength));
        }
      }
      this.inputDim = args.inputDim;
      assertPositiveInteger(this.inputDim, "inputDim");
      this.outputDim = args.outputDim;
      assertPositiveInteger(this.outputDim, "outputDim");
      this.embeddingsInitializer = getInitializer(args.embeddingsInitializer || this.DEFAULT_EMBEDDINGS_INITIALIZER);
      this.embeddingsRegularizer = getRegularizer(args.embeddingsRegularizer);
      this.activityRegularizer = getRegularizer(args.activityRegularizer);
      this.embeddingsConstraint = getConstraint(args.embeddingsConstraint);
      this.maskZero = args.maskZero;
      this.supportsMasking = args.maskZero;
      this.inputLength = args.inputLength;
    }
    build(inputShape) {
      this.embeddings = this.addWeight("embeddings", [this.inputDim, this.outputDim], this.dtype, this.embeddingsInitializer, this.embeddingsRegularizer, true, this.embeddingsConstraint);
      this.built = true;
    }
    warnOnIncompatibleInputShape(inputShape) {
    }
    computeMask(inputs, mask) {
      return tidy(() => {
        if (!this.maskZero) {
          return null;
        } else {
          inputs = getExactlyOneTensor(inputs);
          return notEqual(inputs, zerosLike(inputs));
        }
      });
    }
    computeOutputShape(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      if (this.inputLength == null) {
        return [...inputShape, this.outputDim];
      }
      const inLens = toList(this.inputLength);
      if (inLens.length !== inputShape.length - 1) {
        throw new ValueError(`"inputLength" is ${this.inputLength}, but received input shape has shape ${inputShape}`);
      } else {
        let i = 0;
        for (let k = 0; k < inLens.length; ++k) {
          const s1 = inLens[k];
          const s2 = inputShape[k + 1];
          if (s1 != null && s2 != null && s1 !== s2) {
            throw new ValueError(`"inputLength" is ${this.inputLength}, but received input shape has shape ${inputShape}`);
          } else if (s1 == null) {
            inLens[i] = s2;
          }
          i++;
        }
      }
      return [inputShape[0], ...inLens, this.outputDim];
    }
    call(inputs, kwargs) {
      return tidy(() => {
        this.invokeCallHook(inputs, kwargs);
        let input2 = getExactlyOneTensor(inputs);
        if (input2.dtype !== "int32") {
          input2 = cast2(input2, "int32");
        }
        const output = gather2(this.embeddings.read(), reshape(input2, [input2.size]));
        return reshape(output, getExactlyOneShape(this.computeOutputShape(input2.shape)));
      });
    }
    getConfig() {
      const config = {
        inputDim: this.inputDim,
        outputDim: this.outputDim,
        embeddingsInitializer: serializeInitializer(this.embeddingsInitializer),
        embeddingsRegularizer: serializeRegularizer(this.embeddingsRegularizer),
        activityRegularizer: serializeRegularizer(this.activityRegularizer),
        embeddingsConstraint: serializeConstraint(this.embeddingsConstraint),
        maskZero: this.maskZero,
        inputLength: this.inputLength
      };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  Embedding.className = "Embedding";
  serialization_exports.registerClass(Embedding);

  // node_modules/@tensorflow/tfjs-layers/dist/layers/merge.js
  var Merge = class extends Layer {
    constructor(args) {
      super(args || {});
      this.supportsMasking = true;
    }
    mergeFunction(inputs) {
      throw new NotImplementedError();
    }
    computeElementwiseOpOutputShape(shape1, shape2) {
      if (shape1 == null || shape2 == null) {
        return null;
      } else if (shape1.length < shape2.length) {
        return this.computeElementwiseOpOutputShape(shape2, shape1);
      } else if (shape2.length === 0) {
        return shape1;
      }
      const outputShape = shape1.slice(0, shape1.length - shape2.length);
      for (let k = 0; k < shape2.length; ++k) {
        const i = shape1[shape1.length - shape2.length + k];
        const j = shape2[k];
        if (i == null || j == null || i < 0 || j < 0) {
          outputShape.push(null);
        } else if (i === 1) {
          outputShape.push(j);
        } else if (j === 1) {
          outputShape.push(i);
        } else {
          if (i !== j) {
            throw new ValueError("Operands could not be broadcast together with shapes " + JSON.stringify(shape1) + " " + JSON.stringify(shape2));
          }
          outputShape.push(i);
        }
      }
      return outputShape;
    }
    build(inputShape) {
      if (Array.isArray(inputShape) && !Array.isArray(inputShape[0])) {
        inputShape = [getExactlyOneShape(inputShape)];
      }
      inputShape = inputShape;
      if (inputShape.length < 2) {
        throw new ValueError(`A merge layer should be called on an Array of at least 2 inputs. Got ${inputShape.length} input(s).`);
      }
      let batchSizes = [];
      for (const shape of inputShape) {
        if (shape != null && shape[0] !== null) {
          batchSizes.push(shape[0]);
        }
      }
      batchSizes = unique2(batchSizes);
      if (batchSizes.length > 1) {
        throw new ValueError(`Can not merge tensors with different batch sizes. Got tensors with shapes: ${JSON.stringify(inputShape)}.`);
      }
      let outputShape = inputShape[0] == null ? null : inputShape[0].slice(1);
      for (let i = 1; i < inputShape.length; ++i) {
        const shape = inputShape[i] == null ? null : inputShape[i].slice(1);
        outputShape = this.computeElementwiseOpOutputShape(outputShape, shape);
      }
      const allRanks = inputShape.map((shape) => shape.length);
      if (inputShape.indexOf(null) === -1 && unique2(allRanks).length === 1) {
        this.reshapeRequired = false;
      } else {
        this.reshapeRequired = true;
      }
    }
    call(inputs, kwargs) {
      return tidy(() => {
        inputs = inputs;
        if (this.reshapeRequired) {
          const reshapedInputs = [];
          const inputDims = inputs.map((input2) => input2.rank);
          if (inputDims.indexOf(null) === -1) {
            const maxNDim = max2(inputDims);
            for (let x of inputs) {
              const xNDim = x.rank;
              for (let k = 0; k < maxNDim - xNDim; ++k) {
                x = expandDims2(x, 1);
              }
              reshapedInputs.push(x);
            }
            return this.mergeFunction(reshapedInputs);
          } else {
            let transposed = false;
            for (const x of inputs) {
              const xNDim = x.rank;
              if (xNDim == null) {
                const xShape = x.shape;
                const batchSize = xShape[0];
                const newShape = xShape.slice(1).concat([batchSize]);
                let xTransposed = reshape(x, [batchSize].concat(arrayProd(xShape.slice(1))));
                xTransposed = transpose(xTransposed, [1, 0]);
                xTransposed = reshape(xTransposed, newShape);
                reshapedInputs.push(xTransposed);
                transposed = true;
              } else if (xNDim > 1) {
                const dims = range2(1, xNDim).concat([0]);
                reshapedInputs.push(transpose(x, dims));
                transposed = true;
              } else {
                reshapedInputs.push(x);
              }
            }
            let y = this.mergeFunction(reshapedInputs);
            const yNDim = y.rank;
            if (transposed) {
              if (yNDim == null) {
                const yShape = y.shape;
                const yNDim2 = yShape.length;
                const batchSize = yShape[yNDim2 - 1];
                const newShape = [batchSize].concat(yShape.slice(0, yShape.length - 1));
                y = reshape(transpose(reshape(y, [-1, batchSize]), [1, 0]), newShape);
              } else if (yNDim > 1) {
                const dims = [yNDim - 1].concat(range2(0, yNDim - 1));
                y = transpose(y, dims);
              }
            }
            return y;
          }
        } else {
          return this.mergeFunction(inputs);
        }
      });
    }
    computeOutputShape(inputShape) {
      inputShape = inputShape;
      let outputShape;
      if (inputShape[0] == null) {
        outputShape = null;
      } else {
        outputShape = inputShape[0].slice(1);
      }
      for (let i = 1; i < inputShape.length; ++i) {
        const shape = inputShape[i] == null ? null : inputShape[i].slice(1);
        outputShape = this.computeElementwiseOpOutputShape(outputShape, shape);
      }
      let batchSizes = [];
      for (const shape of inputShape) {
        if (shape != null && shape[0] !== null) {
          batchSizes.push(shape[0]);
        }
      }
      batchSizes = unique2(batchSizes);
      if (batchSizes.length === 1) {
        outputShape = batchSizes.concat(outputShape);
      } else {
        outputShape = [null].concat(outputShape);
      }
      return outputShape;
    }
    computeMask(inputs, mask) {
      return tidy(() => {
        if (mask == null) {
          return null;
        }
        if (!Array.isArray(mask)) {
          throw new ValueError("`mask` should be an Array");
        }
        if (!Array.isArray(inputs)) {
          throw new ValueError("`inputs` should be an Array");
        }
        if (mask.length !== inputs.length) {
          throw new ValueError(`The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (${inputs.length} vs ${mask.length})`);
        }
        if (mask.every((m) => m == null)) {
          return null;
        }
        mask = mask.map((m) => m == null ? m : expandDims(m, 0));
        let output = mask[0];
        for (let i = 1; i < mask.length - 1; ++i) {
          output = logicalAnd(output, mask[i]);
        }
        return output;
      });
    }
  };
  var Add2 = class extends Merge {
    constructor(args) {
      super(args);
    }
    mergeFunction(inputs) {
      return tidy(() => {
        let output = inputs[0].clone();
        for (let i = 1; i < inputs.length; ++i) {
          output = add3(output, inputs[i]);
        }
        return output;
      });
    }
  };
  Add2.className = "Add";
  serialization_exports.registerClass(Add2);
  var Multiply2 = class extends Merge {
    constructor(args) {
      super(args);
    }
    mergeFunction(inputs) {
      return tidy(() => {
        let output = inputs[0].clone();
        for (let i = 1; i < inputs.length; ++i) {
          output = mul(output, inputs[i]);
        }
        return output;
      });
    }
  };
  Multiply2.className = "Multiply";
  serialization_exports.registerClass(Multiply2);
  var Average = class extends Merge {
    constructor(args) {
      super(args);
    }
    mergeFunction(inputs) {
      return tidy(() => {
        let output = inputs[0].clone();
        for (let i = 1; i < inputs.length; ++i) {
          output = add3(output, inputs[i]);
        }
        return mul(1 / inputs.length, output);
      });
    }
  };
  Average.className = "Average";
  serialization_exports.registerClass(Average);
  var Maximum2 = class extends Merge {
    constructor(args) {
      super(args);
    }
    mergeFunction(inputs) {
      return tidy(() => {
        let output = inputs[0];
        for (let i = 1; i < inputs.length; ++i) {
          output = maximum(output, inputs[i]);
        }
        return output;
      });
    }
  };
  Maximum2.className = "Maximum";
  serialization_exports.registerClass(Maximum2);
  var Minimum2 = class extends Merge {
    constructor(args) {
      super(args);
    }
    mergeFunction(inputs) {
      return tidy(() => {
        let output = inputs[0];
        for (let i = 1; i < inputs.length; ++i) {
          output = minimum(output, inputs[i]);
        }
        return output;
      });
    }
  };
  Minimum2.className = "Minimum";
  serialization_exports.registerClass(Minimum2);
  var Concatenate = class extends Merge {
    constructor(args) {
      super(args);
      this.DEFAULT_AXIS = -1;
      if (args == null) {
        args = {};
      }
      this.axis = args.axis == null ? this.DEFAULT_AXIS : args.axis;
      this.supportsMasking = true;
      this.reshapeRequired = false;
    }
    build(inputShape) {
      if (!(Array.isArray(inputShape) && Array.isArray(inputShape[0])) || inputShape.length === 1) {
        throw new ValueError("A `Concatenate` layer should be called on a list of at least 2 inputs");
      }
      inputShape = inputShape;
      let allNoneShape = true;
      for (const shape of inputShape) {
        if (shape != null) {
          allNoneShape = false;
          break;
        }
      }
      if (allNoneShape) {
        return;
      }
      const shapeSet = [];
      for (let i = 0; i < inputShape.length; ++i) {
        const shapeWithoutConcatAxis = inputShape[i].slice();
        shapeWithoutConcatAxis.splice(this.axis, 1);
        let exists = false;
        for (const shape of shapeSet) {
          if (util_exports.arraysEqual(shape, shapeWithoutConcatAxis)) {
            exists = true;
            break;
          }
        }
        if (!exists) {
          shapeSet.push(shapeWithoutConcatAxis);
        }
      }
      if (shapeSet.length > 1) {
        throw new ValueError("A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: " + JSON.stringify(inputShape));
      }
    }
    mergeFunction(inputs) {
      return tidy(() => {
        return concatenate(inputs, this.axis);
      });
    }
    computeOutputShape(inputShape) {
      if (!(Array.isArray(inputShape) && Array.isArray(inputShape[0]))) {
        throw new ValueError("A `Concatenate` layer should be called on a list of inputs.");
      }
      const inputShapes = inputShape;
      const outputShape = inputShapes[0].slice();
      const axis = this.axis < 0 ? outputShape.length + this.axis : this.axis;
      for (const shape of inputShapes.slice(1)) {
        if (outputShape[axis] == null || shape[axis] == null) {
          outputShape[axis] = null;
          break;
        }
        outputShape[axis] += shape[axis];
      }
      return outputShape;
    }
    computeMask(inputs, mask) {
      if (mask == null) {
        return null;
      }
      if (!Array.isArray(mask)) {
        throw new ValueError("`mask` should be an array for Concatenate");
      }
      if (!Array.isArray(inputs)) {
        throw new ValueError("`inputs` should be an array for Concatenate");
      }
      if (mask.length !== inputs.length) {
        throw new ValueError(`Mismatch in the length of mask (${mask.length}) and the legnth of inputs (${inputs.length})`);
      }
      return tidy(() => {
        let allNullMasks = true;
        mask.forEach((m) => {
          if (m != null) {
            allNullMasks = false;
            return;
          }
        });
        if (allNullMasks) {
          return null;
        }
        const outputMasks = [];
        for (let i = 0; i < inputs.length; ++i) {
          if (mask[i] == null) {
            outputMasks.push(cast(onesLike(inputs[i]), "bool"));
          } else if (mask[i].rank < inputs[i].rank) {
            outputMasks.push(expandDims(mask[i], -1));
          } else {
            outputMasks.push(mask[i]);
          }
        }
        const concatenatedMasks = concat(outputMasks, this.axis);
        return all(concatenatedMasks, -1, false);
      });
    }
    getConfig() {
      const config = {
        "axis": this.axis
      };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  Concatenate.className = "Concatenate";
  serialization_exports.registerClass(Concatenate);
  function interpretAxis(axis, dim) {
    while (axis < 0) {
      axis += dim;
    }
    return axis;
  }
  function batchDot(x, y, axes) {
    if (x.shape.length > 3 || y.shape.length > 3) {
      throw new NotImplementedError("batchDot is not implemented for tensors of 4D or higher rank yet");
    }
    util_exports.assert(x.shape.length >= 2, () => `batchDot requires the rank of x to be >= 2, but got ${x.shape.length}`);
    util_exports.assert(x.shape.length >= 2, () => `batchDot requires the rank of y to be >= 2, but got ${y.shape.length}`);
    if (typeof axes === "number") {
      axes = [axes, axes];
    }
    if (x.dtype === "complex64" || y.dtype === "complex64") {
      throw new NotImplementedError("batchDot is not implemented for complex64-type Tensors yet.");
    }
    const xNDim = x.shape.length;
    const yNDim = y.shape.length;
    if (axes == null) {
      axes = [xNDim - 1, yNDim - 2];
    }
    const axesArray = axes;
    return tidy(() => {
      let diff;
      if (xNDim > yNDim) {
        diff = xNDim - yNDim;
        const diffShape = [];
        for (let i = 0; i < diff; ++i) {
          diffShape.push(1);
        }
        y = reshape(y, y.shape.concat(diffShape));
      } else if (yNDim > xNDim) {
        diff = yNDim - xNDim;
        const diffShape = [];
        for (let i = 0; i < diff; ++i) {
          diffShape.push(1);
        }
        x = reshape(x, x.shape.concat(diffShape));
      } else {
        diff = 0;
      }
      let out;
      if (x.shape.length === 2 && y.shape.length === 2) {
        if (axesArray[0] === axesArray[1]) {
          out = sum2(mul(x, y), axesArray[0]);
        } else {
          out = sum2(mul(transpose(x, [1, 0]), y), axesArray[1]);
        }
      } else {
        const adjX = axesArray[0] !== x.shape.length - 1;
        const adjY = axesArray[1] === y.shape.length - 1;
        out = matMul(x, y, adjX, adjY);
      }
      if (diff > 0) {
        let idx;
        if (xNDim > yNDim) {
          idx = xNDim + yNDim - 3;
        } else {
          idx = xNDim - 1;
        }
        const squeezeAxes = [];
        for (let i = idx; i < idx + diff; ++i) {
          squeezeAxes.push(i);
        }
        out = squeeze(out, squeezeAxes);
      }
      if (out.shape.length === 1) {
        out = expandDims(out, 1);
      }
      return out;
    });
  }
  var Dot = class extends Merge {
    constructor(args) {
      super(args);
      this.axes = args.axes;
      this.normalize = args.normalize == null ? false : args.normalize;
      this.supportsMasking = true;
      this.reshapeRequired = false;
    }
    build(inputShape) {
      util_exports.assert(Array.isArray(inputShape) && inputShape.length === 2 && Array.isArray(inputShape[0]) && Array.isArray(inputShape[1]), () => "A `Dot` layer should be called on a list of exactly 2 inputs.");
      const shape1 = inputShape[0];
      const shape2 = inputShape[1];
      if (shape1.length > 3 || shape2.length > 3) {
        throw new NotImplementedError("Dot layer does not support tensors of 4D or higher rank yet.");
      }
      const axes = this.interpretAxes(shape1, shape2);
      if (shape1[axes[0]] !== shape2[axes[1]]) {
        throw new ValueError(`Dimension incompatibility: ${shape1[axes[0]]} !== ${shape2[axes[1]]}`);
      }
    }
    mergeFunction(inputs) {
      if (inputs.length !== 2) {
        throw new ValueError(`A \`Dot\` layer must be called on exactly 2 inputs, but received ${inputs.length} input(s).`);
      }
      let x1 = inputs[0];
      let x2 = inputs[1];
      let axes;
      if (!Array.isArray(this.axes)) {
        axes = [
          interpretAxis(this.axes, x1.shape.length),
          interpretAxis(this.axes, x2.shape.length)
        ];
      } else {
        axes = this.axes.map((axis, i) => interpretAxis(axis, inputs[i].shape.length));
      }
      if (this.normalize) {
        x1 = l2Normalize(x1, axes[0]);
        x2 = l2Normalize(x2, axes[1]);
      }
      return batchDot(x1, x2, axes);
    }
    interpretAxes(shape1, shape2) {
      let axes;
      if (!Array.isArray(this.axes)) {
        axes = [
          interpretAxis(this.axes, shape1.length),
          interpretAxis(this.axes, shape2.length)
        ];
      } else {
        axes = this.axes;
      }
      return axes;
    }
    computeOutputShape(inputShape) {
      util_exports.assert(Array.isArray(inputShape) && inputShape.length === 2 && Array.isArray(inputShape[0]) && Array.isArray(inputShape[1]), () => "A `Dot` layer should be called on a list of exactly 2 inputs.");
      const shape1 = inputShape[0].slice();
      const shape2 = inputShape[1].slice();
      if (shape1.length > 3 || shape2.length > 3) {
        throw new NotImplementedError("Dot layer does not support tensors of 4D or higher rank yet.");
      }
      const axes = this.interpretAxes(shape1, shape2);
      shape1.splice(axes[0], 1);
      shape2.splice(axes[1], 1);
      shape2.splice(0, 1);
      const outputShape = shape1.concat(shape2);
      if (outputShape.length === 1) {
        outputShape.push(1);
      }
      return outputShape;
    }
    computeMask(inputs, mask) {
      return null;
    }
    getConfig() {
      const config = {
        "axes": this.axes,
        "normalize": this.normalize
      };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  Dot.className = "Dot";
  serialization_exports.registerClass(Dot);

  // node_modules/@tensorflow/tfjs-layers/dist/layers/noise.js
  var GaussianNoise = class extends Layer {
    constructor(args) {
      super(args);
      this.supportsMasking = true;
      this.stddev = args.stddev;
    }
    computeOutputShape(inputShape) {
      return inputShape;
    }
    getConfig() {
      const baseConfig = super.getConfig();
      const config = { stddev: this.stddev };
      Object.assign(config, baseConfig);
      return config;
    }
    call(inputs, kwargs) {
      return tidy(() => {
        this.invokeCallHook(inputs, kwargs);
        const input2 = getExactlyOneTensor(inputs);
        const noised = () => add3(randomNormal2(input2.shape, 0, this.stddev), input2);
        const output = inTrainPhase(noised, () => input2, kwargs["training"] || false);
        return output;
      });
    }
  };
  GaussianNoise.className = "GaussianNoise";
  serialization_exports.registerClass(GaussianNoise);
  var GaussianDropout = class extends Layer {
    constructor(args) {
      super(args);
      this.supportsMasking = true;
      this.rate = args.rate;
    }
    computeOutputShape(inputShape) {
      return inputShape;
    }
    getConfig() {
      const baseConfig = super.getConfig();
      const config = { rate: this.rate };
      Object.assign(config, baseConfig);
      return config;
    }
    call(inputs, kwargs) {
      return tidy(() => {
        this.invokeCallHook(inputs, kwargs);
        const input2 = getExactlyOneTensor(inputs);
        if (this.rate > 0 && this.rate < 1) {
          const noised = () => {
            const stddev = Math.sqrt(this.rate / (1 - this.rate));
            return mul(input2, randomNormal2(input2.shape, 1, stddev));
          };
          return inTrainPhase(noised, () => input2, kwargs["training"] || false);
        }
        return input2;
      });
    }
  };
  GaussianDropout.className = "GaussianDropout";
  serialization_exports.registerClass(GaussianDropout);
  var AlphaDropout = class extends Layer {
    constructor(args) {
      super(args);
      this.supportsMasking = true;
      this.rate = args.rate;
      this.noiseShape = args.noiseShape;
    }
    _getNoiseShape(inputs) {
      return this.noiseShape || getExactlyOneTensor(inputs).shape;
    }
    computeOutputShape(inputShape) {
      return inputShape;
    }
    getConfig() {
      const baseConfig = super.getConfig();
      const config = { rate: this.rate };
      Object.assign(config, baseConfig);
      return config;
    }
    call(inputs, kwargs) {
      return tidy(() => {
        if (this.rate < 1 && this.rate > 0) {
          const noiseShape = this._getNoiseShape(inputs);
          const droppedInputs = () => {
            const input2 = getExactlyOneTensor(inputs);
            const alpha = 1.6732632423543772;
            const scale2 = 1.0507009873554805;
            const alphaP = -alpha * scale2;
            let keptIdx = greaterEqual(randomUniform(noiseShape), this.rate);
            keptIdx = cast2(keptIdx, "float32");
            const a = ((1 - this.rate) * (1 + this.rate * alphaP ** 2)) ** -0.5;
            const b = -a * alphaP * this.rate;
            const x = add3(mul(input2, keptIdx), mul(add3(keptIdx, -1), alphaP));
            return add3(mul(x, a), b);
          };
          return inTrainPhase(droppedInputs, () => getExactlyOneTensor(inputs), kwargs["training"] || false);
        }
        return inputs;
      });
    }
  };
  AlphaDropout.className = "AlphaDropout";
  serialization_exports.registerClass(AlphaDropout);

  // node_modules/@tensorflow/tfjs-layers/dist/layers/normalization.js
  function batchNormalization(x, mean3, variance, beta, gamma, epsilon3 = 1e-3) {
    let out;
    if (x.rank === 2) {
      out = batchNorm2d(x, mean3, variance, beta, gamma, epsilon3);
    } else if (x.rank === 3) {
      out = batchNorm3d(x, mean3, variance, beta, gamma, epsilon3);
    } else if (x.rank === 4) {
      out = batchNorm4d(x, mean3, variance, beta, gamma, epsilon3);
    } else {
      throw new NotImplementedError(`batchNormalization is not implemented for array of rank ${x.rank} yet`);
    }
    return out;
  }
  function regularNormalizeBatchInTraining(x, gamma, beta, reductionAxes, epsilon3 = 1e-3) {
    return tidy(() => {
      const meanAndVariance = moments(x, reductionAxes);
      const mean3 = meanAndVariance.mean;
      const variance = meanAndVariance.variance;
      const normed = batchNormalization(x, mean3, variance, beta, gamma, epsilon3);
      return [normed, mean3, variance];
    });
  }
  function broadcastNormalizeBatchInTraining(x, gamma, beta, reductionAxes, epsilon3 = 1e-3) {
    return tidy(() => {
      const meanAndVariance = moments(x, reductionAxes);
      const mean3 = meanAndVariance.mean;
      const variance = meanAndVariance.variance;
      const targetShape = [];
      for (const axis of range2(0, x.rank)) {
        if (reductionAxes.indexOf(axis) !== -1) {
          targetShape.push(1);
        } else {
          targetShape.push(x.shape[axis]);
        }
      }
      const broadcastMean = reshape(mean3, targetShape);
      const broadcastVariance = reshape(variance, targetShape);
      const broadcastGamma = gamma == null ? null : reshape(gamma, targetShape);
      const broadcastBeta = beta == null ? null : reshape(beta, targetShape);
      const normed = batchNormalization(x, broadcastMean, broadcastVariance, broadcastBeta, broadcastGamma, epsilon3);
      return [normed, mean3, variance];
    });
  }
  function normalizeBatchInTraining(x, gamma, beta, reductionAxes, epsilon3 = 1e-3) {
    if (util_exports.arraysEqual(reductionAxes.slice().sort(), range2(0, x.rank - 1))) {
      return regularNormalizeBatchInTraining(x, gamma, beta, reductionAxes, epsilon3);
    } else {
      return broadcastNormalizeBatchInTraining(x, gamma, beta, reductionAxes, epsilon3);
    }
  }
  var BatchNormalization = class extends Layer {
    constructor(args) {
      if (args == null) {
        args = {};
      }
      super(args);
      this.supportsMasking = true;
      this.axis = args.axis == null ? -1 : args.axis;
      this.momentum = args.momentum == null ? 0.99 : args.momentum;
      this.epsilon = args.epsilon == null ? 1e-3 : args.epsilon;
      this.center = args.center == null ? true : args.center;
      this.scale = args.scale == null ? true : args.scale;
      this.betaInitializer = getInitializer(args.betaInitializer || "zeros");
      this.gammaInitializer = getInitializer(args.gammaInitializer || "ones");
      this.movingMeanInitializer = getInitializer(args.movingMeanInitializer || "zeros");
      this.movingVarianceInitializer = getInitializer(args.movingVarianceInitializer || "ones");
      this.betaConstraint = getConstraint(args.betaConstraint);
      this.gammaConstraint = getConstraint(args.gammaConstraint);
      this.betaRegularizer = getRegularizer(args.betaRegularizer);
      this.gammaRegularizer = getRegularizer(args.gammaRegularizer);
    }
    build(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      const axis = this.axis >= 0 ? this.axis : this.axis + inputShape.length;
      const dim = inputShape[axis];
      if (dim == null) {
        throw new ValueError(`Axis ${axis} of input tensor should have a defined dimension but the layer received an input with shape ${JSON.stringify(inputShape)}.`);
      }
      this.inputSpec = [new InputSpec({ ndim: inputShape.length, axes: { [axis]: dim } })];
      const shape = [dim];
      if (this.scale) {
        this.gamma = this.addWeight("gamma", shape, null, this.gammaInitializer, this.gammaRegularizer, true, this.gammaConstraint);
      }
      if (this.center) {
        this.beta = this.addWeight("beta", shape, null, this.betaInitializer, this.betaRegularizer, true, this.betaConstraint);
      }
      this.movingMean = this.addWeight("moving_mean", shape, null, this.movingMeanInitializer, null, false);
      this.movingVariance = this.addWeight("moving_variance", shape, null, this.movingVarianceInitializer, null, false);
      this.built = true;
    }
    call(inputs, kwargs) {
      return tidy(() => {
        const training = kwargs["training"] == null ? false : kwargs["training"];
        const input2 = getExactlyOneTensor(inputs);
        const inputShape = input2.shape;
        const ndim = inputShape.length;
        const reductionAxes = range2(0, ndim);
        const axis = this.axis >= 0 ? this.axis : this.axis + ndim;
        reductionAxes.splice(axis, 1);
        const broadcastShape = pyListRepeat(1, ndim);
        broadcastShape[axis] = inputShape[axis];
        const sortedReductionAxes = reductionAxes.slice();
        sortedReductionAxes.sort();
        const needsBroadcasting = !util_exports.arraysEqual(sortedReductionAxes, range2(0, ndim).slice(0, ndim - 1));
        const normalizeInference = () => {
          if (needsBroadcasting) {
            const broadcastMovingMean = reshape(this.movingMean.read(), broadcastShape);
            const broadcastMovingVariance = reshape(this.movingVariance.read(), broadcastShape);
            const broadcastBeta = this.center ? reshape(this.beta.read(), broadcastShape) : null;
            const broadcastGamma = this.scale ? reshape(this.gamma.read(), broadcastShape) : null;
            return batchNormalization(input2, broadcastMovingMean, broadcastMovingVariance, broadcastBeta, broadcastGamma, this.epsilon);
          } else {
            return batchNormalization(input2, this.movingMean.read(), this.movingVariance.read(), this.beta == null ? null : this.beta.read(), this.gamma == null ? null : this.gamma.read(), this.epsilon);
          }
        };
        if (!training) {
          return normalizeInference();
        }
        const [normedTraining, mean3, variance] = normalizeBatchInTraining(input2, this.gamma.read(), this.beta.read(), reductionAxes, this.epsilon);
        const doMovingAverage = (variable2, value, momentum) => {
          tidy(() => {
            const decay = 1 - momentum;
            const origValue = variable2.read();
            const updateDelta = mul(sub(origValue, value), decay);
            variable2.write(sub(origValue, updateDelta));
          });
        };
        const updateMovingMeanAndVariance = () => {
          doMovingAverage(this.movingMean, mean3, this.momentum);
          doMovingAverage(this.movingVariance, variance, this.momentum);
        };
        updateMovingMeanAndVariance();
        return normedTraining;
      });
    }
    getConfig() {
      const config = {
        axis: this.axis,
        momentum: this.momentum,
        epsilon: this.epsilon,
        center: this.center,
        scale: this.scale,
        betaInitializer: serializeInitializer(this.betaInitializer),
        gammaInitializer: serializeInitializer(this.gammaInitializer),
        movingMeanInitializer: serializeInitializer(this.movingMeanInitializer),
        movingVarianceInitializer: serializeInitializer(this.movingVarianceInitializer),
        betaRegularizer: serializeRegularizer(this.betaRegularizer),
        gammaRegularizer: serializeRegularizer(this.gammaRegularizer),
        betaConstraint: serializeConstraint(this.betaConstraint),
        gammaConstraint: serializeConstraint(this.gammaConstraint)
      };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  BatchNormalization.className = "BatchNormalization";
  serialization_exports.registerClass(BatchNormalization);
  var LayerNormalization = class extends Layer {
    constructor(args) {
      if (args == null) {
        args = {};
      }
      super(args);
      this.axis = args.axis == null ? -1 : args.axis;
      if (typeof this.axis === "number") {
        if (!Number.isInteger(this.axis)) {
          throw new Error(`Expected axis to be an integer, but received ${this.axis}`);
        }
      } else if (Array.isArray(this.axis)) {
        for (const axis of this.axis) {
          if (!Number.isInteger(axis)) {
            throw new Error(`Expected axis to be an array of integers, but received ${JSON.stringify(this.axis)}`);
          }
        }
      } else {
        throw new Error(`Expected axis to be an integer or an array of integers, but received ${JSON.stringify(this.axis)}`);
      }
      this.epsilon = args.epsilon == null ? 1e-3 : args.epsilon;
      this.center = args.center == null ? true : args.center;
      this.scale = args.scale == null ? true : args.scale;
      this.betaInitializer = getInitializer(args.betaInitializer || "zeros");
      this.gammaInitializer = getInitializer(args.gammaInitializer || "ones");
      this.betaRegularizer = getRegularizer(args.betaRegularizer);
      this.gammaRegularizer = getRegularizer(args.gammaRegularizer);
      this.supportsMasking = true;
    }
    build(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      const nDims = inputShape.length;
      if (typeof this.axis === "number") {
        this.axis = [this.axis];
      }
      for (let i = 0; i < this.axis.length; ++i) {
        if (this.axis[i] < 0) {
          this.axis[i] += nDims;
        }
      }
      for (const axis of this.axis) {
        if (axis < 0 || axis >= nDims) {
          throw new Error(`Invalid axis: ${axis}`);
        }
      }
      if (this.axis.length !== unique2(this.axis).length) {
        throw new Error(`Found duplicate axes in: ${this.axis}`);
      }
      const paramShape = this.axis.map((axis) => inputShape[axis]);
      const trainable = true;
      if (this.scale) {
        this.gamma = this.addWeight("gamma", paramShape, "float32", this.gammaInitializer, this.gammaRegularizer, trainable);
      } else {
        this.gamma = null;
      }
      if (this.center) {
        this.beta = this.addWeight("beta", paramShape, "float32", this.betaInitializer, this.betaRegularizer, trainable);
      } else {
        this.beta = null;
      }
      this.built = true;
    }
    call(inputs, kwargs) {
      const input2 = getExactlyOneTensor(inputs);
      const inputShape = input2.shape;
      const nDims = inputShape.length;
      return tidy(() => {
        const keepDims = true;
        let { mean: mean3, variance } = moments(input2, this.axis, keepDims);
        const broadcastShape = pyListRepeat(1, nDims);
        for (const dim of this.axis) {
          broadcastShape[dim] = inputShape[dim];
        }
        const broadcast = (v) => {
          if (v != null && v.shape.length !== nDims) {
            return reshape(v, broadcastShape);
          } else {
            return v;
          }
        };
        let scale2 = broadcast(this.gamma.read());
        let offset = broadcast(this.beta.read());
        const momentsTiling = [];
        const scaleOffsetTiling = [];
        for (let i = 0; i < nDims; ++i) {
          if (this.axis.indexOf(i) !== -1) {
            momentsTiling.push(inputShape[i]);
            scaleOffsetTiling.push(1);
          } else {
            momentsTiling.push(1);
            scaleOffsetTiling.push(inputShape[i]);
          }
        }
        mean3 = tile(mean3, momentsTiling);
        variance = tile(variance, momentsTiling);
        scale2 = tile(scale2, scaleOffsetTiling);
        offset = tile(offset, scaleOffsetTiling);
        return batchNormalization(input2, mean3, variance, offset, scale2, this.epsilon);
      });
    }
    getConfig() {
      const config = {
        axis: this.axis,
        epsilon: this.epsilon,
        center: this.center,
        scale: this.scale,
        betaInitializer: serializeInitializer(this.betaInitializer),
        gammaInitializer: serializeInitializer(this.gammaInitializer),
        betaRegularizer: serializeRegularizer(this.betaRegularizer),
        gammaRegularizer: serializeRegularizer(this.gammaRegularizer)
      };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  LayerNormalization.className = "LayerNormalization";
  serialization_exports.registerClass(LayerNormalization);

  // node_modules/@tensorflow/tfjs-layers/dist/layers/padding.js
  function spatial2dPadding(x, padding, dataFormat) {
    return tidy(() => {
      if (x.rank !== 4) {
        throw new ValueError(`temporalPadding expects input tensor to be 4-D, but received a ${x.rank}-D tensor.`);
      }
      if (padding == null) {
        padding = [[1, 1], [1, 1]];
      }
      if (padding.length !== 2 || padding[0].length !== 2 || padding[1].length !== 2) {
        throw new ValueError("spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.");
      }
      if (dataFormat == null) {
        dataFormat = imageDataFormat();
      }
      if (dataFormat !== "channelsLast" && dataFormat !== "channelsFirst") {
        throw new ValueError(`Unknown data format: ${dataFormat}. Supported data formats are 'channelsLast' and 'channelsFirst.`);
      }
      let pattern;
      if (dataFormat === "channelsFirst") {
        pattern = [[0, 0], [0, 0], padding[0], padding[1]];
      } else {
        pattern = [[0, 0], padding[0], padding[1], [0, 0]];
      }
      return pad(x, pattern);
    });
  }
  var ZeroPadding2D = class extends Layer {
    constructor(args) {
      if (args == null) {
        args = {};
      }
      super(args);
      this.dataFormat = args.dataFormat == null ? imageDataFormat() : args.dataFormat;
      if (args.padding == null) {
        this.padding = [[1, 1], [1, 1]];
      } else if (typeof args.padding === "number") {
        this.padding = [[args.padding, args.padding], [args.padding, args.padding]];
      } else {
        args.padding = args.padding;
        if (args.padding.length !== 2) {
          throw new ValueError(`ZeroPadding2D expects padding to be a length-2 array, but received a length-${args.padding.length} array.`);
        }
        let heightPadding;
        let widthPadding;
        if (typeof args.padding[0] === "number") {
          heightPadding = [args.padding[0], args.padding[0]];
          widthPadding = [args.padding[1], args.padding[1]];
        } else {
          args.padding = args.padding;
          if (args.padding[0].length !== 2) {
            throw new ValueError(`ZeroPadding2D expects height padding to be a length-2 array, but received a length-${args.padding[0].length} array.`);
          }
          heightPadding = args.padding[0];
          if (args.padding[1].length !== 2) {
            throw new ValueError(`ZeroPadding2D expects width padding to be a length-2 array, but received a length-${args.padding[1].length} array.`);
          }
          widthPadding = args.padding[1];
        }
        this.padding = [heightPadding, widthPadding];
      }
      this.inputSpec = [new InputSpec({ ndim: 4 })];
    }
    computeOutputShape(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      let rows;
      let cols;
      if (this.dataFormat === "channelsFirst") {
        if (inputShape[2] != null && inputShape[2] >= 0) {
          rows = inputShape[2] + this.padding[0][0] + this.padding[0][1];
        } else {
          rows = null;
        }
        if (inputShape[3] != null && inputShape[3] >= 0) {
          cols = inputShape[3] + this.padding[1][0] + this.padding[1][1];
        } else {
          cols = null;
        }
        return [inputShape[0], inputShape[1], rows, cols];
      } else {
        if (inputShape[1] != null && inputShape[1] >= 0) {
          rows = inputShape[1] + this.padding[0][0] + this.padding[0][1];
        } else {
          rows = null;
        }
        if (inputShape[2] != null && inputShape[2] >= 0) {
          cols = inputShape[2] + this.padding[1][0] + this.padding[1][1];
        } else {
          cols = null;
        }
        return [inputShape[0], rows, cols, inputShape[3]];
      }
    }
    call(inputs, kwargs) {
      return tidy(() => spatial2dPadding(getExactlyOneTensor(inputs), this.padding, this.dataFormat));
    }
    getConfig() {
      const config = {
        padding: this.padding,
        dataFormat: this.dataFormat
      };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  ZeroPadding2D.className = "ZeroPadding2D";
  serialization_exports.registerClass(ZeroPadding2D);

  // node_modules/@tensorflow/tfjs-layers/dist/layers/pooling.js
  function pool2d(x, poolSize, strides, padding, dataFormat, poolMode) {
    return tidy(() => {
      checkDataFormat(dataFormat);
      checkPoolMode(poolMode);
      checkPaddingMode(padding);
      if (strides == null) {
        strides = [1, 1];
      }
      if (padding == null) {
        padding = "valid";
      }
      if (dataFormat == null) {
        dataFormat = imageDataFormat();
      }
      if (poolMode == null) {
        poolMode = "max";
      }
      x = preprocessConv2DInput(x, dataFormat);
      let y;
      const paddingString = padding === "same" ? "same" : "valid";
      if (poolMode === "max") {
        y = maxPool(x, poolSize, strides, paddingString);
      } else {
        y = avgPool(x, poolSize, strides, paddingString);
      }
      if (dataFormat === "channelsFirst") {
        y = transpose(y, [0, 3, 1, 2]);
      }
      return y;
    });
  }
  function pool3d(x, poolSize, strides, padding, dataFormat, poolMode) {
    return tidy(() => {
      checkDataFormat(dataFormat);
      checkPoolMode(poolMode);
      checkPaddingMode(padding);
      if (strides == null) {
        strides = [1, 1, 1];
      }
      if (padding == null) {
        padding = "valid";
      }
      if (dataFormat == null) {
        dataFormat = imageDataFormat();
      }
      if (poolMode == null) {
        poolMode = "max";
      }
      x = preprocessConv3DInput(x, dataFormat);
      let y;
      const paddingString = padding === "same" ? "same" : "valid";
      if (poolMode === "max") {
        y = maxPool3d(x, poolSize, strides, paddingString);
      } else {
        y = avgPool3d(x, poolSize, strides, paddingString);
      }
      if (dataFormat === "channelsFirst") {
        y = transpose(y, [0, 4, 1, 2, 3]);
      }
      return y;
    });
  }
  var Pooling1D = class extends Layer {
    constructor(args) {
      if (args.poolSize == null) {
        args.poolSize = 2;
      }
      super(args);
      if (typeof args.poolSize === "number") {
        this.poolSize = [args.poolSize];
      } else if (Array.isArray(args.poolSize) && args.poolSize.length === 1 && typeof args.poolSize[0] === "number") {
        this.poolSize = args.poolSize;
      } else {
        throw new ValueError(`poolSize for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(args.poolSize)}`);
      }
      assertPositiveInteger(this.poolSize, "poolSize");
      if (args.strides == null) {
        this.strides = this.poolSize;
      } else {
        if (typeof args.strides === "number") {
          this.strides = [args.strides];
        } else if (Array.isArray(args.strides) && args.strides.length === 1 && typeof args.strides[0] === "number") {
          this.strides = args.strides;
        } else {
          throw new ValueError(`strides for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(args.strides)}`);
        }
      }
      assertPositiveInteger(this.strides, "strides");
      this.padding = args.padding == null ? "valid" : args.padding;
      checkPaddingMode(this.padding);
      this.inputSpec = [new InputSpec({ ndim: 3 })];
    }
    computeOutputShape(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      const length = convOutputLength(inputShape[1], this.poolSize[0], this.padding, this.strides[0]);
      return [inputShape[0], length, inputShape[2]];
    }
    call(inputs, kwargs) {
      return tidy(() => {
        this.invokeCallHook(inputs, kwargs);
        inputs = expandDims2(getExactlyOneTensor(inputs), 2);
        const output = this.poolingFunction(getExactlyOneTensor(inputs), [this.poolSize[0], 1], [this.strides[0], 1], this.padding, "channelsLast");
        return squeeze(output, [2]);
      });
    }
    getConfig() {
      const config = {
        poolSize: this.poolSize,
        padding: this.padding,
        strides: this.strides
      };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  var MaxPooling1D = class extends Pooling1D {
    constructor(args) {
      super(args);
    }
    poolingFunction(inputs, poolSize, strides, padding, dataFormat) {
      checkDataFormat(dataFormat);
      checkPaddingMode(padding);
      return pool2d(inputs, poolSize, strides, padding, dataFormat, "max");
    }
  };
  MaxPooling1D.className = "MaxPooling1D";
  serialization_exports.registerClass(MaxPooling1D);
  var AveragePooling1D = class extends Pooling1D {
    constructor(args) {
      super(args);
    }
    poolingFunction(inputs, poolSize, strides, padding, dataFormat) {
      checkDataFormat(dataFormat);
      checkPaddingMode(padding);
      return pool2d(inputs, poolSize, strides, padding, dataFormat, "avg");
    }
  };
  AveragePooling1D.className = "AveragePooling1D";
  serialization_exports.registerClass(AveragePooling1D);
  var Pooling2D = class extends Layer {
    constructor(args) {
      if (args.poolSize == null) {
        args.poolSize = [2, 2];
      }
      super(args);
      this.poolSize = Array.isArray(args.poolSize) ? args.poolSize : [args.poolSize, args.poolSize];
      if (args.strides == null) {
        this.strides = this.poolSize;
      } else if (Array.isArray(args.strides)) {
        if (args.strides.length !== 2) {
          throw new ValueError(`If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length ${args.strides.length}.`);
        }
        this.strides = args.strides;
      } else {
        this.strides = [args.strides, args.strides];
      }
      assertPositiveInteger(this.poolSize, "poolSize");
      assertPositiveInteger(this.strides, "strides");
      this.padding = args.padding == null ? "valid" : args.padding;
      this.dataFormat = args.dataFormat == null ? "channelsLast" : args.dataFormat;
      checkDataFormat(this.dataFormat);
      checkPaddingMode(this.padding);
      this.inputSpec = [new InputSpec({ ndim: 4 })];
    }
    computeOutputShape(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      let rows = this.dataFormat === "channelsFirst" ? inputShape[2] : inputShape[1];
      let cols = this.dataFormat === "channelsFirst" ? inputShape[3] : inputShape[2];
      rows = convOutputLength(rows, this.poolSize[0], this.padding, this.strides[0]);
      cols = convOutputLength(cols, this.poolSize[1], this.padding, this.strides[1]);
      if (this.dataFormat === "channelsFirst") {
        return [inputShape[0], inputShape[1], rows, cols];
      } else {
        return [inputShape[0], rows, cols, inputShape[3]];
      }
    }
    call(inputs, kwargs) {
      return tidy(() => {
        this.invokeCallHook(inputs, kwargs);
        return this.poolingFunction(getExactlyOneTensor(inputs), this.poolSize, this.strides, this.padding, this.dataFormat);
      });
    }
    getConfig() {
      const config = {
        poolSize: this.poolSize,
        padding: this.padding,
        strides: this.strides,
        dataFormat: this.dataFormat
      };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  var MaxPooling2D = class extends Pooling2D {
    constructor(args) {
      super(args);
    }
    poolingFunction(inputs, poolSize, strides, padding, dataFormat) {
      checkDataFormat(dataFormat);
      checkPaddingMode(padding);
      return pool2d(inputs, poolSize, strides, padding, dataFormat, "max");
    }
  };
  MaxPooling2D.className = "MaxPooling2D";
  serialization_exports.registerClass(MaxPooling2D);
  var AveragePooling2D = class extends Pooling2D {
    constructor(args) {
      super(args);
    }
    poolingFunction(inputs, poolSize, strides, padding, dataFormat) {
      checkDataFormat(dataFormat);
      checkPaddingMode(padding);
      return pool2d(inputs, poolSize, strides, padding, dataFormat, "avg");
    }
  };
  AveragePooling2D.className = "AveragePooling2D";
  serialization_exports.registerClass(AveragePooling2D);
  var Pooling3D = class extends Layer {
    constructor(args) {
      if (args.poolSize == null) {
        args.poolSize = [2, 2, 2];
      }
      super(args);
      this.poolSize = Array.isArray(args.poolSize) ? args.poolSize : [args.poolSize, args.poolSize, args.poolSize];
      if (args.strides == null) {
        this.strides = this.poolSize;
      } else if (Array.isArray(args.strides)) {
        if (args.strides.length !== 3) {
          throw new ValueError(`If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length ${args.strides.length}.`);
        }
        this.strides = args.strides;
      } else {
        this.strides = [args.strides, args.strides, args.strides];
      }
      assertPositiveInteger(this.poolSize, "poolSize");
      assertPositiveInteger(this.strides, "strides");
      this.padding = args.padding == null ? "valid" : args.padding;
      this.dataFormat = args.dataFormat == null ? "channelsLast" : args.dataFormat;
      checkDataFormat(this.dataFormat);
      checkPaddingMode(this.padding);
      this.inputSpec = [new InputSpec({ ndim: 5 })];
    }
    computeOutputShape(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      let depths = this.dataFormat === "channelsFirst" ? inputShape[2] : inputShape[1];
      let rows = this.dataFormat === "channelsFirst" ? inputShape[3] : inputShape[2];
      let cols = this.dataFormat === "channelsFirst" ? inputShape[4] : inputShape[3];
      depths = convOutputLength(depths, this.poolSize[0], this.padding, this.strides[0]);
      rows = convOutputLength(rows, this.poolSize[1], this.padding, this.strides[1]);
      cols = convOutputLength(cols, this.poolSize[2], this.padding, this.strides[2]);
      if (this.dataFormat === "channelsFirst") {
        return [inputShape[0], inputShape[1], depths, rows, cols];
      } else {
        return [inputShape[0], depths, rows, cols, inputShape[4]];
      }
    }
    call(inputs, kwargs) {
      return tidy(() => {
        this.invokeCallHook(inputs, kwargs);
        return this.poolingFunction(getExactlyOneTensor(inputs), this.poolSize, this.strides, this.padding, this.dataFormat);
      });
    }
    getConfig() {
      const config = {
        poolSize: this.poolSize,
        padding: this.padding,
        strides: this.strides,
        dataFormat: this.dataFormat
      };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  var MaxPooling3D = class extends Pooling3D {
    constructor(args) {
      super(args);
    }
    poolingFunction(inputs, poolSize, strides, padding, dataFormat) {
      checkDataFormat(dataFormat);
      checkPaddingMode(padding);
      return pool3d(inputs, poolSize, strides, padding, dataFormat, "max");
    }
  };
  MaxPooling3D.className = "MaxPooling3D";
  serialization_exports.registerClass(MaxPooling3D);
  var AveragePooling3D = class extends Pooling3D {
    constructor(args) {
      super(args);
    }
    poolingFunction(inputs, poolSize, strides, padding, dataFormat) {
      checkDataFormat(dataFormat);
      checkPaddingMode(padding);
      return pool3d(inputs, poolSize, strides, padding, dataFormat, "avg");
    }
  };
  AveragePooling3D.className = "AveragePooling3D";
  serialization_exports.registerClass(AveragePooling3D);
  var GlobalPooling1D = class extends Layer {
    constructor(args) {
      super(args);
      this.inputSpec = [new InputSpec({ ndim: 3 })];
    }
    computeOutputShape(inputShape) {
      return [inputShape[0], inputShape[2]];
    }
    call(inputs, kwargs) {
      throw new NotImplementedError();
    }
  };
  var GlobalAveragePooling1D = class extends GlobalPooling1D {
    constructor(args) {
      super(args || {});
    }
    call(inputs, kwargs) {
      return tidy(() => {
        const input2 = getExactlyOneTensor(inputs);
        return mean(input2, 1);
      });
    }
  };
  GlobalAveragePooling1D.className = "GlobalAveragePooling1D";
  serialization_exports.registerClass(GlobalAveragePooling1D);
  var GlobalMaxPooling1D = class extends GlobalPooling1D {
    constructor(args) {
      super(args || {});
    }
    call(inputs, kwargs) {
      return tidy(() => {
        const input2 = getExactlyOneTensor(inputs);
        return max(input2, 1);
      });
    }
  };
  GlobalMaxPooling1D.className = "GlobalMaxPooling1D";
  serialization_exports.registerClass(GlobalMaxPooling1D);
  var GlobalPooling2D = class extends Layer {
    constructor(args) {
      super(args);
      this.dataFormat = args.dataFormat == null ? "channelsLast" : args.dataFormat;
      checkDataFormat(this.dataFormat);
      this.inputSpec = [new InputSpec({ ndim: 4 })];
    }
    computeOutputShape(inputShape) {
      inputShape = inputShape;
      if (this.dataFormat === "channelsLast") {
        return [inputShape[0], inputShape[3]];
      } else {
        return [inputShape[0], inputShape[1]];
      }
    }
    call(inputs, kwargs) {
      throw new NotImplementedError();
    }
    getConfig() {
      const config = { dataFormat: this.dataFormat };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
  };
  var GlobalAveragePooling2D = class extends GlobalPooling2D {
    call(inputs, kwargs) {
      return tidy(() => {
        const input2 = getExactlyOneTensor(inputs);
        if (this.dataFormat === "channelsLast") {
          return mean(input2, [1, 2]);
        } else {
          return mean(input2, [2, 3]);
        }
      });
    }
  };
  GlobalAveragePooling2D.className = "GlobalAveragePooling2D";
  serialization_exports.registerClass(GlobalAveragePooling2D);
  var GlobalMaxPooling2D = class extends GlobalPooling2D {
    call(inputs, kwargs) {
      return tidy(() => {
        const input2 = getExactlyOneTensor(inputs);
        if (this.dataFormat === "channelsLast") {
          return max(input2, [1, 2]);
        } else {
          return max(input2, [2, 3]);
        }
      });
    }
  };
  GlobalMaxPooling2D.className = "GlobalMaxPooling2D";
  serialization_exports.registerClass(GlobalMaxPooling2D);

  // node_modules/@tensorflow/tfjs-layers/dist/layers/wrappers.js
  var Wrapper = class extends Layer {
    constructor(args) {
      super(args);
      this.layer = args.layer;
    }
    build(inputShape) {
      this.built = true;
    }
    get trainable() {
      if (this.layer != null) {
        return this.layer.trainable;
      } else {
        return false;
      }
    }
    set trainable(value) {
      if (this.layer != null) {
        this.layer.trainable = value;
      }
    }
    get trainableWeights() {
      return this.layer.trainableWeights;
    }
    get nonTrainableWeights() {
      return this.layer.nonTrainableWeights;
    }
    get updates() {
      return this.layer._updates;
    }
    get losses() {
      return this.layer.losses;
    }
    getWeights() {
      return this.layer.getWeights();
    }
    setWeights(weights) {
      this.layer.setWeights(weights);
    }
    getConfig() {
      const config = {
        "layer": {
          "className": this.layer.getClassName(),
          "config": this.layer.getConfig()
        }
      };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
    setFastWeightInitDuringBuild(value) {
      super.setFastWeightInitDuringBuild(value);
      if (this.layer != null) {
        this.layer.setFastWeightInitDuringBuild(value);
      }
    }
    static fromConfig(cls, config, customObjects = {}) {
      const layerConfig = config["layer"];
      const layer = deserialize(layerConfig, customObjects);
      delete config["layer"];
      const newConfig = { layer };
      Object.assign(newConfig, config);
      return new cls(newConfig);
    }
  };
  var TimeDistributed = class extends Wrapper {
    constructor(args) {
      super(args);
      this.supportsMasking = true;
    }
    build(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      if (inputShape.length < 3) {
        throw new ValueError(`TimeDistributed layer expects an input shape >= 3D, but received input shape ${JSON.stringify(inputShape)}`);
      }
      this.inputSpec = [{ shape: inputShape }];
      const childInputShape = [inputShape[0]].concat(inputShape.slice(2));
      if (!this.layer.built) {
        this.layer.build(childInputShape);
        this.layer.built = true;
      }
      super.build(inputShape);
    }
    computeOutputShape(inputShape) {
      inputShape = getExactlyOneShape(inputShape);
      const childInputShape = [inputShape[0]].concat(inputShape.slice(2));
      const childOutputShape = this.layer.computeOutputShape(childInputShape);
      const timesteps = inputShape[1];
      return [childOutputShape[0], timesteps].concat(childOutputShape.slice(1));
    }
    call(inputs, kwargs) {
      return tidy(() => {
        inputs = getExactlyOneTensor(inputs);
        const step4 = (inputs2, states) => {
          const output = getExactlyOneTensor(this.layer.call(inputs2, kwargs));
          return [output, []];
        };
        const rnnOutputs = rnn(step4, inputs, [], false, null, null, false, true);
        const y = rnnOutputs[1];
        return y;
      });
    }
  };
  TimeDistributed.className = "TimeDistributed";
  serialization_exports.registerClass(TimeDistributed);
  function checkBidirectionalMergeMode(value) {
    checkStringTypeUnionValue(VALID_BIDIRECTIONAL_MERGE_MODES, "BidirectionalMergeMode", value);
  }
  var DEFAULT_BIDIRECTIONAL_MERGE_MODE = "concat";
  var Bidirectional = class extends Wrapper {
    constructor(args) {
      super(args);
      const layerConfig = args.layer.getConfig();
      const forwDict = {};
      forwDict["className"] = args.layer.getClassName();
      forwDict["config"] = layerConfig;
      this.forwardLayer = deserialize(forwDict);
      layerConfig["goBackwards"] = layerConfig["goBackwards"] === true ? false : true;
      const backDict = {};
      backDict["className"] = args.layer.getClassName();
      backDict["config"] = layerConfig;
      this.backwardLayer = deserialize(backDict);
      this.forwardLayer.name = "forward_" + this.forwardLayer.name;
      this.backwardLayer.name = "backward_" + this.backwardLayer.name;
      this.mergeMode = args.mergeMode === void 0 ? DEFAULT_BIDIRECTIONAL_MERGE_MODE : args.mergeMode;
      checkBidirectionalMergeMode(this.mergeMode);
      if (args.weights) {
        throw new NotImplementedError("weights support is not implemented for Bidirectional layer yet.");
      }
      this._stateful = args.layer.stateful;
      this.returnSequences = args.layer.returnSequences;
      this.returnState = args.layer.returnState;
      this.supportsMasking = true;
      this._trainable = true;
      this.inputSpec = args.layer.inputSpec;
      this.numConstants = null;
    }
    get trainable() {
      return this._trainable;
    }
    set trainable(value) {
      this._trainable = value;
      if (this.forwardLayer != null) {
        this.forwardLayer.trainable = value;
      }
      if (this.backwardLayer != null) {
        this.backwardLayer.trainable = value;
      }
    }
    getWeights() {
      return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights());
    }
    setWeights(weights) {
      const numWeights = weights.length;
      const numeightsOver2 = Math.floor(numWeights / 2);
      this.forwardLayer.setWeights(weights.slice(0, numeightsOver2));
      this.backwardLayer.setWeights(weights.slice(numeightsOver2));
    }
    computeOutputShape(inputShape) {
      let layerShapes = this.forwardLayer.computeOutputShape(inputShape);
      if (!(Array.isArray(layerShapes) && Array.isArray(layerShapes[0]))) {
        layerShapes = [layerShapes];
      }
      layerShapes = layerShapes;
      let outputShape;
      let outputShapes;
      let stateShape;
      if (this.returnState) {
        stateShape = layerShapes.slice(1);
        outputShape = layerShapes[0];
      } else {
        outputShape = layerShapes[0];
      }
      outputShape = outputShape;
      if (this.mergeMode === "concat") {
        outputShape[outputShape.length - 1] *= 2;
        outputShapes = [outputShape];
      } else if (this.mergeMode == null) {
        outputShapes = [outputShape, outputShape.slice()];
      } else {
        outputShapes = [outputShape];
      }
      if (this.returnState) {
        if (this.mergeMode == null) {
          return outputShapes.concat(stateShape).concat(stateShape.slice());
        }
        return [outputShape].concat(stateShape).concat(stateShape.slice());
      }
      return singletonOrArray(outputShapes);
    }
    apply(inputs, kwargs) {
      let initialState = kwargs == null ? null : kwargs["initialState"];
      let constants = kwargs == null ? null : kwargs["constants"];
      if (kwargs == null) {
        kwargs = {};
      }
      const standardized = standardizeArgs(inputs, initialState, constants, this.numConstants);
      inputs = standardized.inputs;
      initialState = standardized.initialState;
      constants = standardized.constants;
      if (Array.isArray(inputs)) {
        initialState = inputs.slice(1);
        inputs = inputs[0];
      }
      if ((initialState == null || initialState.length === 0) && constants == null) {
        return super.apply(inputs, kwargs);
      }
      const additionalInputs = [];
      const additionalSpecs = [];
      if (initialState != null) {
        const numStates = initialState.length;
        if (numStates % 2 > 0) {
          throw new ValueError("When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.");
        }
        kwargs["initialState"] = initialState;
        additionalInputs.push(...initialState);
        const stateSpecs = initialState.map((state) => new InputSpec({ shape: state.shape }));
        this.forwardLayer.stateSpec = stateSpecs.slice(0, numStates / 2);
        this.backwardLayer.stateSpec = stateSpecs.slice(numStates / 2);
        additionalSpecs.push(...stateSpecs);
      }
      if (constants != null) {
        throw new NotImplementedError("Support for constants in Bidirectional layers is not implemented yet.");
      }
      const isSymbolicTensor = additionalInputs[0] instanceof SymbolicTensor;
      for (const tensor2 of additionalInputs) {
        if (tensor2 instanceof SymbolicTensor !== isSymbolicTensor) {
          throw new ValueError("The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors");
        }
      }
      if (isSymbolicTensor) {
        const fullInput = [inputs].concat(additionalInputs);
        const fullInputSpec = this.inputSpec.concat(additionalSpecs);
        const originalInputSpec = this.inputSpec;
        this.inputSpec = fullInputSpec;
        const output = super.apply(fullInput, kwargs);
        this.inputSpec = originalInputSpec;
        return output;
      } else {
        return super.apply(inputs, kwargs);
      }
    }
    call(inputs, kwargs) {
      return tidy(() => {
        const initialState = kwargs["initialState"];
        let y;
        let yRev;
        if (initialState == null) {
          y = this.forwardLayer.call(inputs, kwargs);
          yRev = this.backwardLayer.call(inputs, kwargs);
        } else {
          const forwardState = initialState.slice(0, initialState.length / 2);
          const backwardState = initialState.slice(initialState.length / 2);
          y = this.forwardLayer.call(inputs, Object.assign(kwargs, { initialState: forwardState }));
          yRev = this.backwardLayer.call(inputs, Object.assign(kwargs, { initialState: backwardState }));
        }
        let states;
        if (this.returnState) {
          if (Array.isArray(y)) {
            states = y.slice(1).concat(yRev.slice(1));
          } else {
          }
          y = y[0];
          yRev = yRev[0];
        }
        if (this.returnSequences) {
          yRev = reverse(yRev, 1);
        }
        let output;
        if (this.mergeMode === "concat") {
          output = concatenate([y, yRev]);
        } else if (this.mergeMode === "sum") {
          output = add3(y, yRev);
        } else if (this.mergeMode === "ave") {
          output = mul(0.5, add3(y, yRev));
        } else if (this.mergeMode === "mul") {
          output = mul(y, yRev);
        } else if (this.mergeMode == null) {
          output = [y, yRev];
        }
        if (this.returnState) {
          if (this.mergeMode == null) {
            return output.concat(states);
          }
          return [output].concat(states);
        }
        return output;
      });
    }
    resetStates(states) {
      this.forwardLayer.resetStates();
      this.backwardLayer.resetStates();
    }
    build(inputShape) {
      nameScope(this.forwardLayer.name, () => {
        this.forwardLayer.build(inputShape);
      });
      nameScope(this.backwardLayer.name, () => {
        this.backwardLayer.build(inputShape);
      });
      this.built = true;
    }
    computeMask(inputs, mask) {
      if (Array.isArray(mask)) {
        mask = mask[0];
      }
      let outputMask;
      if (this.returnSequences) {
        if (this.mergeMode == null) {
          outputMask = [mask, mask];
        } else {
          outputMask = mask;
        }
      } else {
        if (this.mergeMode == null) {
          outputMask = [null, null];
        } else {
          outputMask = null;
        }
      }
      if (this.returnState) {
        const states = this.forwardLayer.states;
        const stateMask = states.map((state) => null);
        if (Array.isArray(outputMask)) {
          return outputMask.concat(stateMask).concat(stateMask);
        } else {
          return [outputMask].concat(stateMask).concat(stateMask);
        }
      } else {
        return outputMask;
      }
    }
    get trainableWeights() {
      return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights);
    }
    get nonTrainableWeights() {
      return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights);
    }
    setFastWeightInitDuringBuild(value) {
      super.setFastWeightInitDuringBuild(value);
      if (this.forwardLayer != null) {
        this.forwardLayer.setFastWeightInitDuringBuild(value);
      }
      if (this.backwardLayer != null) {
        this.backwardLayer.setFastWeightInitDuringBuild(value);
      }
    }
    getConfig() {
      const config = {
        "mergeMode": this.mergeMode
      };
      const baseConfig = super.getConfig();
      Object.assign(config, baseConfig);
      return config;
    }
    static fromConfig(cls, config) {
      const rnnLayer = deserialize(config["layer"]);
      delete config["layer"];
      if (config["numConstants"] != null) {
        throw new NotImplementedError(`Deserialization of a Bidirectional layer with numConstants present is not supported yet.`);
      }
      const newConfig = config;
      newConfig["layer"] = rnnLayer;
      return new cls(newConfig);
    }
  };
  Bidirectional.className = "Bidirectional";
  serialization_exports.registerClass(Bidirectional);

  // node_modules/@tensorflow/tfjs-converter/dist/data/compiled_api.js
  var DataType;
  (function(DataType2) {
    DataType2[DataType2["DT_INVALID"] = 0] = "DT_INVALID";
    DataType2[DataType2["DT_FLOAT"] = 1] = "DT_FLOAT";
    DataType2[DataType2["DT_DOUBLE"] = 2] = "DT_DOUBLE";
    DataType2[DataType2["DT_INT32"] = 3] = "DT_INT32";
    DataType2[DataType2["DT_UINT8"] = 4] = "DT_UINT8";
    DataType2[DataType2["DT_INT16"] = 5] = "DT_INT16";
    DataType2[DataType2["DT_INT8"] = 6] = "DT_INT8";
    DataType2[DataType2["DT_STRING"] = 7] = "DT_STRING";
    DataType2[DataType2["DT_COMPLEX64"] = 8] = "DT_COMPLEX64";
    DataType2[DataType2["DT_INT64"] = 9] = "DT_INT64";
    DataType2[DataType2["DT_BOOL"] = 10] = "DT_BOOL";
    DataType2[DataType2["DT_QINT8"] = 11] = "DT_QINT8";
    DataType2[DataType2["DT_QUINT8"] = 12] = "DT_QUINT8";
    DataType2[DataType2["DT_QINT32"] = 13] = "DT_QINT32";
    DataType2[DataType2["DT_BFLOAT16"] = 14] = "DT_BFLOAT16";
    DataType2[DataType2["DT_FLOAT_REF"] = 101] = "DT_FLOAT_REF";
    DataType2[DataType2["DT_DOUBLE_REF"] = 102] = "DT_DOUBLE_REF";
    DataType2[DataType2["DT_INT32_REF"] = 103] = "DT_INT32_REF";
    DataType2[DataType2["DT_UINT8_REF"] = 104] = "DT_UINT8_REF";
    DataType2[DataType2["DT_INT16_REF"] = 105] = "DT_INT16_REF";
    DataType2[DataType2["DT_INT8_REF"] = 106] = "DT_INT8_REF";
    DataType2[DataType2["DT_STRING_REF"] = 107] = "DT_STRING_REF";
    DataType2[DataType2["DT_COMPLEX64_REF"] = 108] = "DT_COMPLEX64_REF";
    DataType2[DataType2["DT_INT64_REF"] = 109] = "DT_INT64_REF";
    DataType2[DataType2["DT_BOOL_REF"] = 110] = "DT_BOOL_REF";
    DataType2[DataType2["DT_QINT8_REF"] = 111] = "DT_QINT8_REF";
    DataType2[DataType2["DT_QUINT8_REF"] = 112] = "DT_QUINT8_REF";
    DataType2[DataType2["DT_QINT32_REF"] = 113] = "DT_QINT32_REF";
    DataType2[DataType2["DT_BFLOAT16_REF"] = 114] = "DT_BFLOAT16_REF";
  })(DataType || (DataType = {}));
  var SaverDef;
  (function(SaverDef2) {
    let CheckpointFormatVersion;
    (function(CheckpointFormatVersion2) {
      CheckpointFormatVersion2[CheckpointFormatVersion2["LEGACY"] = 0] = "LEGACY";
      CheckpointFormatVersion2[CheckpointFormatVersion2["V1"] = 1] = "V1";
      CheckpointFormatVersion2[CheckpointFormatVersion2["V2"] = 2] = "V2";
    })(CheckpointFormatVersion = SaverDef2.CheckpointFormatVersion || (SaverDef2.CheckpointFormatVersion = {}));
  })(SaverDef || (SaverDef = {}));

  // node_modules/@tensorflow/tfjs-data/dist/dataset.js
  var seedrandom3 = __toModule(require_seedrandom4());

  // node_modules/@tensorflow/tfjs-data/dist/iterators/lazy_iterator.js
  var seedrandom2 = __toModule(require_seedrandom4());

  // node_modules/@tensorflow/tfjs-data/dist/util/deep_map.js
  function deepMap(input2, mapFn) {
    return deepMapInternal(input2, mapFn);
  }
  function deepMapInternal(input2, mapFn, seen = new Map(), containedIn = new Set()) {
    if (input2 == null) {
      return null;
    }
    if (typeof Blob === "function" && input2 instanceof Blob) {
      return input2.slice();
    }
    if (containedIn.has(input2)) {
      throw new Error("Circular references are not supported.");
    }
    if (seen.has(input2)) {
      return seen.get(input2);
    }
    const result = mapFn(input2);
    if (result.recurse && result.value !== null) {
      throw new Error("A deep map function may not return both a value and recurse=true.");
    }
    if (!result.recurse) {
      seen.set(input2, result.value);
      return result.value;
    } else if (isIterable2(input2)) {
      const mappedIterable = Array.isArray(input2) ? [] : {};
      containedIn.add(input2);
      for (const k in input2) {
        const child = input2[k];
        const childResult = deepMapInternal(child, mapFn, seen, containedIn);
        mappedIterable[k] = childResult;
      }
      containedIn.delete(input2);
      if (input2.__proto__) {
        mappedIterable.__proto__ = input2.__proto__;
      }
      return mappedIterable;
    } else {
      throw new Error(`Can't recurse into non-iterable type: ${input2}`);
    }
  }
  function deepZip(inputs, zipFn = zipToList) {
    return deepZipInternal(inputs, zipFn);
  }
  function deepZipInternal(inputs, zipFn, containedIn = new Set()) {
    const input2 = inputs[0];
    if (containedIn.has(input2)) {
      throw new Error("Circular references are not supported.");
    }
    const result = zipFn(inputs);
    if (result.recurse && result.value !== null) {
      throw new Error("A deep zip function may not return both a value and recurse=true.");
    }
    if (!result.recurse) {
      return result.value;
    } else if (isIterable2(input2)) {
      const mappedIterable = Array.isArray(input2) ? [] : {};
      containedIn.add(input2);
      for (const k in input2) {
        const children = inputs.map((x) => x[k]);
        const childResult = deepZipInternal(children, zipFn, containedIn);
        mappedIterable[k] = childResult;
      }
      containedIn.delete(input2);
      return mappedIterable;
    } else {
      throw new Error(`Can't recurse into non-iterable type: ${input2}`);
    }
  }
  function zipToList(x) {
    if (x === null) {
      return null;
    }
    if (isIterable2(x[0])) {
      return { value: null, recurse: true };
    } else {
      return { value: x, recurse: false };
    }
  }
  function isIterable2(obj) {
    let isTextDecoder = false;
    if (env().get("IS_BROWSER")) {
      isTextDecoder = obj instanceof TextDecoder;
    } else {
      const { StringDecoder } = require_string_decoder();
      isTextDecoder = obj instanceof StringDecoder;
    }
    return obj != null && !ArrayBuffer.isView(obj) && (Array.isArray(obj) || typeof obj === "object" && !(obj instanceof Tensor) && !(obj instanceof Promise) && !isTextDecoder);
  }
  function canTensorify(obj) {
    return obj == null || isPrimitive(obj) || Array.isArray(obj) || typeof obj === "object" && obj instanceof Tensor || util_exports.isTypedArray(obj);
  }
  function isPrimitive(value) {
    return value === null || typeof value !== "object" && typeof value !== "function";
  }

  // node_modules/@tensorflow/tfjs-data/dist/util/deep_clone.js
  function deepClone(container) {
    return deepMap(container, cloneIfTensor);
  }
  function cloneIfTensor(item) {
    if (item instanceof Tensor) {
      return { value: item.clone(), recurse: false };
    } else if (isIterable2(item)) {
      return { value: null, recurse: true };
    } else {
      return { value: item, recurse: false };
    }
  }

  // node_modules/@tensorflow/tfjs-data/dist/util/ring_buffer.js
  var RingBuffer = class {
    constructor(capacity) {
      this.capacity = capacity;
      this.begin = 0;
      this.end = 0;
      if (capacity == null) {
        throw new RangeError("Can't create a ring buffer of unknown capacity.");
      }
      if (capacity < 1) {
        throw new RangeError("Can't create ring buffer of capacity < 1.");
      }
      this.data = new Array(capacity);
      this.doubledCapacity = 2 * capacity;
    }
    wrap(index) {
      while (index < 0) {
        index += this.doubledCapacity;
      }
      return index % this.doubledCapacity;
    }
    get(index) {
      if (index < 0) {
        throw new RangeError("Can't get item at a negative index.");
      }
      return this.data[index % this.capacity];
    }
    set(index, value) {
      if (index < 0) {
        throw new RangeError("Can't set item at a negative index.");
      }
      this.data[index % this.capacity] = value;
    }
    length() {
      let length = this.end - this.begin;
      if (length < 0) {
        length = this.doubledCapacity + length;
      }
      return length;
    }
    isFull() {
      return this.length() === this.capacity;
    }
    isEmpty() {
      return this.length() === 0;
    }
    push(value) {
      if (this.isFull()) {
        throw new RangeError("Ring buffer is full.");
      }
      this.set(this.end, value);
      this.end = this.wrap(this.end + 1);
    }
    pushAll(values) {
      for (const value of values) {
        this.push(value);
      }
    }
    pop() {
      if (this.isEmpty()) {
        throw new RangeError("Ring buffer is empty.");
      }
      this.end = this.wrap(this.end - 1);
      const result = this.get(this.end);
      this.set(this.end, void 0);
      return result;
    }
    unshift(value) {
      if (this.isFull()) {
        throw new RangeError("Ring buffer is full.");
      }
      this.begin = this.wrap(this.begin - 1);
      this.set(this.begin, value);
    }
    shift() {
      if (this.isEmpty()) {
        throw new RangeError("Ring buffer is empty.");
      }
      const result = this.get(this.begin);
      this.set(this.begin, void 0);
      this.begin = this.wrap(this.begin + 1);
      return result;
    }
    shuffleExcise(relativeIndex) {
      if (this.isEmpty()) {
        throw new RangeError("Ring buffer is empty.");
      }
      const index = this.wrap(this.begin + relativeIndex);
      const result = this.get(index);
      this.set(index, this.pop());
      return result;
    }
  };

  // node_modules/@tensorflow/tfjs-data/dist/util/growing_ring_buffer.js
  var GrowingRingBuffer = class extends RingBuffer {
    constructor() {
      super(GrowingRingBuffer.INITIAL_CAPACITY);
    }
    isFull() {
      return false;
    }
    push(value) {
      if (super.isFull()) {
        this.expand();
      }
      super.push(value);
    }
    unshift(value) {
      if (super.isFull()) {
        this.expand();
      }
      super.unshift(value);
    }
    expand() {
      const newCapacity = this.capacity * 2;
      const newData = new Array(newCapacity);
      const len = this.length();
      for (let i = 0; i < len; i++) {
        newData[i] = this.get(this.wrap(this.begin + i));
      }
      this.data = newData;
      this.capacity = newCapacity;
      this.doubledCapacity = 2 * this.capacity;
      this.begin = 0;
      this.end = len;
    }
  };
  GrowingRingBuffer.INITIAL_CAPACITY = 32;

  // node_modules/@tensorflow/tfjs-data/dist/iterators/lazy_iterator.js
  function iteratorFromItems(items) {
    return new ArrayIterator(items);
  }
  function iteratorFromFunction(func2) {
    return new FunctionCallIterator(func2);
  }
  function iteratorFromConcatenated(baseIterators, baseErrorHandler) {
    return new ChainedIterator(baseIterators, baseErrorHandler);
  }
  var LazyIterator = class {
    async toArray() {
      const result = [];
      let x = await this.next();
      while (!x.done) {
        result.push(x.value);
        x = await this.next();
      }
      return result;
    }
    async toArrayForTest() {
      const stream = this.prefetch(100);
      const result = [];
      let x = await stream.next();
      while (!x.done) {
        result.push(x.value);
        x = await stream.next();
      }
      return result;
    }
    async resolveFully() {
      let x = await this.next();
      while (!x.done) {
        x = await this.next();
      }
    }
    async resolveWhile(predicate) {
      let x = await this.next();
      let shouldContinue = predicate(x.value);
      while (!x.done && shouldContinue) {
        x = await this.next();
        shouldContinue = predicate(x.value);
      }
    }
    handleErrors(handler) {
      return new ErrorHandlingLazyIterator(this, handler);
    }
    filter(predicate) {
      return new FilterIterator(this, predicate);
    }
    map(transform4) {
      return new MapIterator(this, transform4);
    }
    mapAsync(transform4) {
      return new AsyncMapIterator(this, transform4);
    }
    serialMapAsync(transform4) {
      return new AsyncMapIterator(this, transform4).serial();
    }
    flatmap(transform4) {
      return new FlatmapIterator(this, transform4);
    }
    async forEachAsync(f) {
      return this.map(f).resolveFully();
    }
    async serialForEach(f) {
      return this.serialMapAsync(f).resolveWhile((x) => x === true);
    }
    rowMajorBatch(batchSize, smallLastBatch = true) {
      return new RowMajorBatchIterator(this, batchSize, smallLastBatch);
    }
    columnMajorBatch(batchSize, smallLastBatch = true, zipFn = zipToList) {
      const rowBatches = this.rowMajorBatch(batchSize, smallLastBatch);
      return rowBatches.map((x) => deepZip(x, zipFn));
    }
    concatenate(iterator, baseErrorHandler) {
      return new ChainedIterator(iteratorFromItems([this, iterator]), baseErrorHandler);
    }
    take(count2) {
      if (count2 < 0 || count2 == null) {
        return this;
      }
      return new TakeIterator(this, count2);
    }
    skip(count2) {
      if (count2 < 0 || count2 == null) {
        return this;
      }
      return new SkipIterator(this, count2);
    }
    prefetch(bufferSize) {
      return new PrefetchIterator(this, bufferSize);
    }
    shuffle(windowSize, seed) {
      return new ShuffleIterator(this, windowSize, seed);
    }
    serial() {
      return new SerialIterator(this);
    }
  };
  var ArrayIterator = class extends LazyIterator {
    constructor(items) {
      super();
      this.items = items;
      this.trav = 0;
    }
    summary() {
      return `Array of ${this.items.length} items`;
    }
    async next() {
      if (this.trav >= this.items.length) {
        return { value: null, done: true };
      }
      const item = this.items[this.trav];
      this.trav++;
      return { value: deepClone(item), done: false };
    }
  };
  var FunctionCallIterator = class extends LazyIterator {
    constructor(nextFn) {
      super();
      this.nextFn = nextFn;
    }
    summary() {
      return `Function call`;
    }
    async next() {
      try {
        return this.nextFn();
      } catch (e) {
        e.message = `Error thrown while iterating through a dataset: ${e.message}`;
        throw e;
      }
    }
  };
  var SerialIterator = class extends LazyIterator {
    constructor(upstream) {
      super();
      this.upstream = upstream;
      this.lastRead = Promise.resolve({ value: null, done: false });
    }
    summary() {
      return `${this.upstream.summary()} -> Serial`;
    }
    async next() {
      this.lastRead = this.lastRead.then(() => this.serialNext());
      return this.lastRead;
    }
    async serialNext() {
      return this.upstream.next();
    }
  };
  var SkipIterator = class extends LazyIterator {
    constructor(upstream, maxCount) {
      super();
      this.upstream = upstream;
      this.maxCount = maxCount;
      this.count = 0;
      this.lastRead = Promise.resolve({ value: null, done: false });
    }
    summary() {
      return `${this.upstream.summary()} -> Skip`;
    }
    async next() {
      this.lastRead = this.lastRead.then(() => this.serialNext());
      return this.lastRead;
    }
    async serialNext() {
      while (this.count++ < this.maxCount) {
        const skipped = await this.upstream.next();
        if (skipped.done) {
          return skipped;
        }
        dispose(skipped.value);
      }
      return this.upstream.next();
    }
  };
  var TakeIterator = class extends LazyIterator {
    constructor(upstream, maxCount) {
      super();
      this.upstream = upstream;
      this.maxCount = maxCount;
      this.count = 0;
    }
    summary() {
      return `${this.upstream.summary()} -> Take`;
    }
    async next() {
      if (this.count++ >= this.maxCount) {
        return { value: null, done: true };
      }
      return this.upstream.next();
    }
  };
  var RowMajorBatchIterator = class extends LazyIterator {
    constructor(upstream, batchSize, enableSmallLastBatch = true) {
      super();
      this.upstream = upstream;
      this.batchSize = batchSize;
      this.enableSmallLastBatch = enableSmallLastBatch;
      this.lastRead = Promise.resolve({ value: null, done: false });
    }
    summary() {
      return `${this.upstream.summary()} -> RowMajorBatch`;
    }
    async next() {
      this.lastRead = this.lastRead.then(() => this.serialNext());
      return this.lastRead;
    }
    async serialNext() {
      const batch = [];
      while (batch.length < this.batchSize) {
        const item = await this.upstream.next();
        if (item.done) {
          if (this.enableSmallLastBatch && batch.length > 0) {
            return { value: batch, done: false };
          }
          return { value: null, done: true };
        }
        batch.push(item.value);
      }
      return { value: batch, done: false };
    }
  };
  var FilterIterator = class extends LazyIterator {
    constructor(upstream, predicate) {
      super();
      this.upstream = upstream;
      this.predicate = predicate;
      this.lastRead = Promise.resolve({ value: null, done: false });
    }
    summary() {
      return `${this.upstream.summary()} -> Filter`;
    }
    async next() {
      this.lastRead = this.lastRead.then(() => this.serialNext());
      return this.lastRead;
    }
    async serialNext() {
      while (true) {
        const item = await this.upstream.next();
        if (item.done || this.predicate(item.value)) {
          return item;
        }
        dispose(item.value);
      }
    }
  };
  var MapIterator = class extends LazyIterator {
    constructor(upstream, transform4) {
      super();
      this.upstream = upstream;
      this.transform = transform4;
    }
    summary() {
      return `${this.upstream.summary()} -> Map`;
    }
    async next() {
      const item = await this.upstream.next();
      if (item.done) {
        return { value: null, done: true };
      }
      const inputTensors = tensor_util_exports.getTensorsInContainer(item.value);
      const mapped = this.transform(item.value);
      const outputTensors = tensor_util_exports.getTensorsInContainer(mapped);
      for (const t of inputTensors) {
        if (!tensor_util_exports.isTensorInList(t, outputTensors)) {
          t.dispose();
        }
      }
      return { value: mapped, done: false };
    }
  };
  var ErrorHandlingLazyIterator = class extends LazyIterator {
    constructor(upstream, handler) {
      super();
      this.upstream = upstream;
      this.handler = handler;
      this.count = 0;
      this.lastRead = Promise.resolve({ value: null, done: false });
    }
    summary() {
      return `${this.upstream.summary()} -> handleErrors`;
    }
    async next() {
      this.lastRead = this.lastRead.then(() => this.serialNext());
      return this.lastRead;
    }
    async serialNext() {
      while (true) {
        try {
          return await this.upstream.next();
        } catch (e) {
          if (!this.handler(e)) {
            return { value: null, done: true };
          }
        }
      }
    }
  };
  var AsyncMapIterator = class extends LazyIterator {
    constructor(upstream, transform4) {
      super();
      this.upstream = upstream;
      this.transform = transform4;
    }
    summary() {
      return `${this.upstream.summary()} -> AsyncMap`;
    }
    async next() {
      const item = await this.upstream.next();
      if (item.done) {
        return { value: null, done: true };
      }
      const inputTensors = tensor_util_exports.getTensorsInContainer(item.value);
      const mapped = await this.transform(item.value);
      const outputTensors = tensor_util_exports.getTensorsInContainer(mapped);
      for (const t of inputTensors) {
        if (!tensor_util_exports.isTensorInList(t, outputTensors)) {
          t.dispose();
        }
      }
      return { value: mapped, done: false };
    }
  };
  var OneToManyIterator = class extends LazyIterator {
    constructor() {
      super();
      this.outputQueue = new GrowingRingBuffer();
      this.lastRead = Promise.resolve({ value: null, done: false });
    }
    async next() {
      this.lastRead = this.lastRead.then(() => this.serialNext());
      return this.lastRead;
    }
    async serialNext() {
      while (this.outputQueue.length() === 0) {
        if (!await this.pump()) {
          return { value: null, done: true };
        }
      }
      return { value: this.outputQueue.shift(), done: false };
    }
  };
  var FlatmapIterator = class extends OneToManyIterator {
    constructor(upstream, transform4) {
      super();
      this.upstream = upstream;
      this.transform = transform4;
    }
    summary() {
      return `${this.upstream.summary()} -> Flatmap`;
    }
    async pump() {
      const item = await this.upstream.next();
      if (item.done) {
        return false;
      }
      const inputTensors = tensor_util_exports.getTensorsInContainer(item.value);
      const mappedArray = this.transform(item.value);
      const outputTensors = tensor_util_exports.getTensorsInContainer(mappedArray);
      this.outputQueue.pushAll(mappedArray);
      for (const t of inputTensors) {
        if (!tensor_util_exports.isTensorInList(t, outputTensors)) {
          t.dispose();
        }
      }
      return true;
    }
  };
  var ChainedIterator = class extends LazyIterator {
    constructor(iterators, baseErrorHandler) {
      super();
      this.baseErrorHandler = baseErrorHandler;
      this.lastRead = null;
      this.iterator = null;
      this.moreIterators = iterators;
    }
    summary() {
      const upstreamSummaries = "TODO: fill in upstream of chained summaries";
      return `${upstreamSummaries} -> Chained`;
    }
    async next() {
      this.lastRead = this.readFromChain(this.lastRead);
      return this.lastRead;
    }
    async readFromChain(lastRead) {
      await lastRead;
      if (this.iterator == null) {
        const iteratorResult = await this.moreIterators.next();
        if (iteratorResult.done) {
          return { value: null, done: true };
        }
        this.iterator = iteratorResult.value;
        if (this.baseErrorHandler != null) {
          this.iterator = this.iterator.handleErrors(this.baseErrorHandler);
        }
      }
      const itemResult = await this.iterator.next();
      if (itemResult.done) {
        this.iterator = null;
        return this.readFromChain(lastRead);
      }
      return itemResult;
    }
  };
  var ZipMismatchMode;
  (function(ZipMismatchMode2) {
    ZipMismatchMode2[ZipMismatchMode2["FAIL"] = 0] = "FAIL";
    ZipMismatchMode2[ZipMismatchMode2["SHORTEST"] = 1] = "SHORTEST";
    ZipMismatchMode2[ZipMismatchMode2["LONGEST"] = 2] = "LONGEST";
  })(ZipMismatchMode || (ZipMismatchMode = {}));
  var PrefetchIterator = class extends LazyIterator {
    constructor(upstream, bufferSize) {
      super();
      this.upstream = upstream;
      this.bufferSize = bufferSize;
      this.buffer = new RingBuffer(bufferSize);
    }
    summary() {
      return `${this.upstream.summary()} -> Prefetch`;
    }
    refill() {
      while (!this.buffer.isFull()) {
        const v = this.upstream.next();
        this.buffer.push(v);
      }
    }
    next() {
      this.refill();
      return this.buffer.shift();
    }
  };
  var ShuffleIterator = class extends PrefetchIterator {
    constructor(upstream, windowSize, seed) {
      super(upstream, windowSize);
      this.upstream = upstream;
      this.windowSize = windowSize;
      this.upstreamExhausted = false;
      this.random = seedrandom2.alea(seed || util_exports.now().toString());
      this.lastRead = Promise.resolve({ value: null, done: false });
    }
    async next() {
      this.lastRead = this.lastRead.then(() => this.serialNext());
      return this.lastRead;
    }
    randomInt(max5) {
      return Math.floor(this.random() * max5);
    }
    chooseIndex() {
      return this.randomInt(this.buffer.length());
    }
    async serialNext() {
      if (!this.upstreamExhausted) {
        this.refill();
      }
      while (!this.buffer.isEmpty()) {
        const chosenIndex = this.chooseIndex();
        const result = await this.buffer.shuffleExcise(chosenIndex);
        if (result.done) {
          this.upstreamExhausted = true;
        } else {
          this.refill();
          return result;
        }
      }
      return { value: null, done: true };
    }
  };

  // node_modules/@tensorflow/tfjs-data/dist/dataset.js
  var Dataset = class {
    constructor() {
      this.size = null;
    }
    batch(batchSize, smallLastBatch = true) {
      const base2 = this;
      util_exports.assert(batchSize > 0, () => `batchSize needs to be positive, but it is
      ${batchSize}`);
      let size2;
      if (this.size === Infinity || this.size == null) {
        size2 = this.size;
      } else if (smallLastBatch) {
        size2 = Math.ceil(this.size / batchSize);
      } else {
        size2 = Math.floor(this.size / batchSize);
      }
      return datasetFromIteratorFn(async () => {
        return (await base2.iterator()).columnMajorBatch(batchSize, smallLastBatch, deepBatchConcat);
      }, size2);
    }
    concatenate(dataset) {
      const base2 = this;
      let size2;
      if (this.size === Infinity || dataset.size === Infinity) {
        size2 = Infinity;
      } else if (this.size != null && dataset.size != null) {
        size2 = this.size + dataset.size;
      } else {
        size2 = null;
      }
      return datasetFromIteratorFn(async () => (await base2.iterator()).concatenate(await dataset.iterator()), size2);
    }
    filter(predicate) {
      const base2 = this;
      let size2;
      if (this.size === Infinity) {
        size2 = Infinity;
      } else {
        size2 = null;
      }
      return datasetFromIteratorFn(async () => {
        return (await base2.iterator()).filter((x) => tidy(() => predicate(x)));
      }, size2);
    }
    async forEachAsync(f) {
      return (await this.iterator()).forEachAsync(f);
    }
    map(transform4) {
      const base2 = this;
      return datasetFromIteratorFn(async () => {
        return (await base2.iterator()).map((x) => tidy(() => transform4(x)));
      }, this.size);
    }
    mapAsync(transform4) {
      const base2 = this;
      return datasetFromIteratorFn(async () => {
        return (await base2.iterator()).mapAsync(transform4);
      }, this.size);
    }
    prefetch(bufferSize) {
      if (bufferSize == null) {
        throw new RangeError("`Dataset.prefetch()` requires bufferSize to be specified.");
      }
      const base2 = this;
      return datasetFromIteratorFn(async () => (await base2.iterator()).prefetch(bufferSize), this.size);
    }
    repeat(count2) {
      const base2 = this;
      let size2;
      if (this.size != null && count2 > 0) {
        size2 = this.size * count2;
      } else if (count2 === 0) {
        size2 = 0;
      } else if (this.size != null && (count2 === void 0 || count2 < 0)) {
        size2 = Infinity;
      } else {
        size2 = null;
      }
      return datasetFromIteratorFn(async () => {
        const iteratorIterator = iteratorFromFunction(async () => ({ value: await base2.iterator(), done: false }));
        return iteratorFromConcatenated(iteratorIterator.take(count2));
      }, size2);
    }
    skip(count2) {
      const base2 = this;
      let size2;
      if (this.size != null && count2 >= 0 && this.size >= count2) {
        size2 = this.size - count2;
      } else if (this.size != null && (this.size < count2 || count2 === void 0 || count2 < 0)) {
        size2 = 0;
      } else {
        size2 = null;
      }
      return datasetFromIteratorFn(async () => (await base2.iterator()).skip(count2), size2);
    }
    shuffle(bufferSize, seed, reshuffleEachIteration = true) {
      if (bufferSize == null || bufferSize < 0) {
        if (this.size == null) {
          throw new RangeError("`Dataset.shuffle()` requires bufferSize to be specified.");
        } else {
          throw new RangeError(`\`Dataset.shuffle()\` requires bufferSize to be specified.  If your data fits in main memory (for regular JS objects), and/or GPU memory (for \`tf.Tensor\`s), consider setting bufferSize to the dataset size (${this.size} elements)`);
        }
      }
      const base2 = this;
      const random = seedrandom3.alea(seed || util_exports.now().toString());
      return datasetFromIteratorFn(async () => {
        let seed2 = random.int32();
        if (reshuffleEachIteration) {
          seed2 += random.int32();
        }
        return (await base2.iterator()).shuffle(bufferSize, seed2.toString());
      }, this.size);
    }
    take(count2) {
      const base2 = this;
      let size2;
      if (this.size != null && this.size > count2) {
        size2 = count2;
      } else if (this.size != null && this.size <= count2) {
        size2 = this.size;
      } else {
        size2 = null;
      }
      return datasetFromIteratorFn(async () => (await base2.iterator()).take(count2), size2);
    }
    async toArray() {
      if (this.size === Infinity) {
        throw new Error("Can not convert infinite data stream to array.");
      }
      return (await this.iterator()).toArray();
    }
    async toArrayForTest() {
      if (this.size === Infinity) {
        throw new Error("Can not convert infinite data stream to array.");
      }
      return (await this.iterator()).toArrayForTest();
    }
  };
  Dataset.MAX_BUFFER_SIZE = 1e4;
  function datasetFromIteratorFn(iteratorFn, size2 = null) {
    return new class extends Dataset {
      constructor() {
        super(...arguments);
        this.size = size2;
      }
      async iterator() {
        return iteratorFn();
      }
    }();
  }
  function deepBatchConcat(rows) {
    if (rows === null) {
      return null;
    }
    const exampleRow = rows[0];
    if (canTensorify(exampleRow)) {
      const value = batchConcat(rows);
      return { value, recurse: false };
    }
    return { value: null, recurse: true };
  }
  function batchConcat(arrays) {
    if (arrays.length === 0) {
      throw new Error("Can't make a batch of zero elements.");
    }
    if (arrays[0] instanceof Tensor) {
      return stack2(arrays);
    } else {
      return tensor(arrays);
    }
  }

  // node_modules/@tensorflow/tfjs-data/dist/datasets/csv_dataset.js
  var STATE_OUT = Symbol("out");
  var STATE_FIELD = Symbol("field");
  var STATE_QUOTE = Symbol("quote");
  var STATE_QUOTE_AFTER_QUOTE = Symbol("quoteafterquote");
  var STATE_WITHIN_QUOTE_IN_QUOTE = Symbol("quoteinquote");

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/cpu_util.js
  function assertNotComplex(tensor2, opName) {
    if (!Array.isArray(tensor2)) {
      tensor2 = [tensor2];
    }
    tensor2.forEach((t) => {
      if (t != null) {
        util_exports.assert(t.dtype !== "complex64", () => `${opName} does not support complex64 tensors in the CPU backend.`);
      }
    });
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/backend_cpu.js
  var whereImpl2 = kernel_impls_exports.whereImpl;
  var MathBackendCPU = class extends KernelBackend {
    constructor() {
      super();
      this.blockSize = 48;
      this.firstUse = true;
      this.data = new DataStorage(this, engine());
    }
    nextDataId() {
      return MathBackendCPU.nextDataId++;
    }
    write(values, shape, dtype) {
      if (this.firstUse) {
        this.firstUse = false;
        if (env().get("IS_NODE")) {
          backend_util_exports.warn("\n============================\nHi there \u{1F44B}. Looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, which binds to TensorFlow C++, by running npm i @tensorflow/tfjs-node, or npm i @tensorflow/tfjs-node-gpu if you have CUDA. Then call require('@tensorflow/tfjs-node'); (-gpu suffix for CUDA) at the start of your program. Visit https://github.com/tensorflow/tfjs-node for more details.\n============================");
        }
      }
      const dataId = { id: this.nextDataId() };
      this.data.set(dataId, { values, dtype, refCount: 1 });
      return dataId;
    }
    makeTensorInfo(shape, dtype, values) {
      let outId;
      if (dtype === "string" && values != null && values.length > 0 && util_exports.isString(values[0])) {
        const encodedValues = values.map((d) => util_exports.encodeString(d));
        outId = this.write(encodedValues, shape, dtype);
      } else {
        outId = this.write(values, shape, dtype);
      }
      return { dataId: outId, shape, dtype };
    }
    refCount(dataId) {
      if (this.data.has(dataId)) {
        const tensorData = this.data.get(dataId);
        return tensorData.refCount;
      }
      return 0;
    }
    incRef(dataId) {
      const tensorData = this.data.get(dataId);
      tensorData.refCount++;
    }
    decRef(dataId) {
      if (this.data.has(dataId)) {
        const tensorData = this.data.get(dataId);
        tensorData.refCount--;
      }
    }
    move(dataId, values, shape, dtype, refCount) {
      this.data.set(dataId, { values, dtype, refCount });
    }
    numDataIds() {
      return this.data.numDataIds();
    }
    async read(dataId) {
      return this.readSync(dataId);
    }
    readSync(dataId) {
      const { dtype, complexTensorInfos } = this.data.get(dataId);
      if (dtype === "complex64") {
        const realValues = this.readSync(complexTensorInfos.real.dataId);
        const imagValues = this.readSync(complexTensorInfos.imag.dataId);
        return backend_util_exports.mergeRealAndImagArrays(realValues, imagValues);
      }
      return this.data.get(dataId).values;
    }
    bufferSync(t) {
      const data = this.readSync(t.dataId);
      let decodedData = data;
      if (t.dtype === "string") {
        try {
          decodedData = data.map((d) => util_exports.decodeString(d));
        } catch (_a2) {
          throw new Error("Failed to decode encoded string bytes into utf-8");
        }
      }
      return buffer2(t.shape, t.dtype, decodedData);
    }
    makeOutput(values, shape, dtype) {
      const dataId = this.write(values, shape, dtype);
      return engine().makeTensorFromDataId(dataId, shape, dtype, this);
    }
    disposeData(dataId, force = false) {
      if (this.data.has(dataId)) {
        this.data.get(dataId).refCount--;
        if (!force && this.data.get(dataId).refCount > 0) {
          return false;
        }
        const { complexTensorInfos } = this.data.get(dataId);
        if (complexTensorInfos != null) {
          this.disposeData(complexTensorInfos.real.dataId, true);
          this.disposeData(complexTensorInfos.imag.dataId, true);
        }
        this.data.delete(dataId);
      }
      return true;
    }
    disposeIntermediateTensorInfo(tensorInfo) {
      this.disposeData(tensorInfo.dataId);
    }
    async time(f) {
      const start = util_exports.now();
      f();
      const kernelMs = util_exports.now() - start;
      return { kernelMs };
    }
    memory() {
      return {
        unreliable: true,
        reasons: ["The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less."]
      };
    }
    where(condition) {
      assertNotComplex([condition], "where");
      const condVals = this.readSync(condition.dataId);
      return whereImpl2(condition.shape, condVals);
    }
    dispose() {
    }
    floatPrecision() {
      return 32;
    }
    epsilon() {
      return super.epsilon();
    }
  };
  MathBackendCPU.nextDataId = 0;

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/shared.js
  var shared_exports = {};
  __export(shared_exports, {
    addImpl: () => addImpl,
    bincountImpl: () => bincountImpl,
    bincountReduceImpl: () => bincountReduceImpl,
    ceilImpl: () => ceilImpl,
    concatImpl: () => concatImpl,
    equalImpl: () => equalImpl,
    expImpl: () => expImpl,
    expm1Impl: () => expm1Impl,
    floorImpl: () => floorImpl,
    gatherNdImpl: () => gatherNdImpl,
    gatherV2Impl: () => gatherV2Impl,
    greaterEqualImpl: () => greaterEqualImpl,
    greaterImpl: () => greaterImpl,
    lessEqualImpl: () => lessEqualImpl,
    lessImpl: () => lessImpl,
    linSpaceImpl: () => linSpaceImpl,
    logImpl: () => logImpl,
    maxImpl: () => maxImpl,
    maximumImpl: () => maximumImpl,
    minimumImpl: () => minimumImpl,
    multiplyImpl: () => multiplyImpl,
    negImpl: () => negImpl,
    notEqualImpl: () => notEqualImpl,
    prodImpl: () => prodImpl,
    rangeImpl: () => rangeImpl,
    rsqrtImpl: () => rsqrtImpl,
    sigmoidImpl: () => sigmoidImpl,
    simpleAbsImpl: () => simpleAbsImpl,
    sliceImpl: () => sliceImpl,
    sparseFillEmptyRowsImpl: () => sparseFillEmptyRowsImpl,
    sparseReshapeImpl: () => sparseReshapeImpl,
    sparseSegmentReductionImpl: () => sparseSegmentReductionImpl,
    sqrtImpl: () => sqrtImpl,
    squaredDifferenceImpl: () => squaredDifferenceImpl,
    stridedSliceImpl: () => stridedSliceImpl,
    stringNGramsImpl: () => stringNGramsImpl,
    stringSplitImpl: () => stringSplitImpl,
    stringToHashBucketFastImpl: () => stringToHashBucketFastImpl,
    subImpl: () => subImpl,
    tileImpl: () => tileImpl,
    topKImpl: () => topKImpl,
    transposeImpl: () => transposeImpl,
    uniqueImpl: () => uniqueImpl
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Abs.js
  function simpleAbsImpl(vals) {
    const resultValues = new Float32Array(vals.length);
    for (let i = 0; i < vals.length; ++i) {
      resultValues[i] = Math.abs(vals[i]);
    }
    return resultValues;
  }
  var abs2 = (args) => {
    const { x } = args.inputs;
    const cpuBackend = args.backend;
    assertNotComplex(x, "abs");
    let resultValues = new Float32Array(util_exports.sizeFromShape(x.shape));
    const values = cpuBackend.data.get(x.dataId).values;
    resultValues = simpleAbsImpl(values);
    return cpuBackend.makeOutput(resultValues, x.shape, x.dtype);
  };
  var absConfig = {
    kernelName: Abs,
    backendName: "cpu",
    kernelFunc: abs2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/binary_impl.js
  function createSimpleBinaryKernelImpl(op2) {
    return (aShape, bShape, aVals, bVals, dtype) => {
      const newShape = backend_util_exports.assertAndGetBroadcastShape(aShape, bShape);
      const resultRank = newShape.length;
      const resultStrides = util_exports.computeStrides(newShape);
      const resultSize = util_exports.sizeFromShape(newShape);
      const result = util_exports.getTypedArrayFromDType(dtype, resultSize);
      const aRank = aShape.length;
      const bRank = bShape.length;
      const aStrides = util_exports.computeStrides(aShape);
      const bStrides = util_exports.computeStrides(bShape);
      const aBroadcastDims = backend_util_exports.getBroadcastDims(aShape, newShape);
      const bBroadcastDims = backend_util_exports.getBroadcastDims(bShape, newShape);
      if (aBroadcastDims.length + bBroadcastDims.length === 0) {
        for (let i = 0; i < result.length; ++i) {
          result[i] = op2(aVals[i % aVals.length], bVals[i % bVals.length]);
        }
      } else {
        for (let i = 0; i < result.length; ++i) {
          const loc = util_exports.indexToLoc(i, resultRank, resultStrides);
          const aLoc = loc.slice(-aRank);
          aBroadcastDims.forEach((d) => aLoc[d] = 0);
          const aIndex = util_exports.locToIndex(aLoc, aRank, aStrides);
          const bLoc = loc.slice(-bRank);
          bBroadcastDims.forEach((d) => bLoc[d] = 0);
          const bIndex = util_exports.locToIndex(bLoc, bRank, bStrides);
          result[i] = op2(aVals[aIndex], bVals[bIndex]);
        }
      }
      return [result, newShape];
    };
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Complex.js
  function complex2(args) {
    const { inputs, backend: backend2 } = args;
    const { real: real4, imag: imag4 } = inputs;
    const realVals = backend2.data.get(real4.dataId).values;
    const imagVals = backend2.data.get(imag4.dataId).values;
    const complexInfo = backend2.makeTensorInfo(real4.shape, "complex64");
    const complex4 = backend2.data.get(complexInfo.dataId);
    complex4.complexTensorInfos = {
      real: backend2.makeTensorInfo(real4.shape, "float32", realVals),
      imag: backend2.makeTensorInfo(imag4.shape, "float32", imagVals)
    };
    return complexInfo;
  }
  var complexConfig = {
    kernelName: Complex,
    backendName: "cpu",
    kernelFunc: complex2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/zeros_impl.js
  function zeros2(backend2, shape, dtype = "float32") {
    if (dtype === "complex64") {
      const real4 = zeros2(backend2, shape, "float32");
      const imag4 = zeros2(backend2, shape, "float32");
      return complex2({ inputs: { real: real4, imag: imag4 }, backend: backend2 });
    }
    const values = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(shape), dtype);
    return backend2.makeTensorInfo(shape, dtype, values);
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Identity.js
  function identity(args) {
    const { inputs, backend: backend2 } = args;
    const { x } = inputs;
    backend2.incRef(x.dataId);
    return { dataId: x.dataId, shape: x.shape, dtype: x.dtype };
  }
  var identityConfig = {
    kernelName: Identity,
    backendName: "cpu",
    kernelFunc: identity
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Real.js
  function real2(args) {
    const { inputs, backend: backend2 } = args;
    const { input: input2 } = inputs;
    const real4 = backend2.data.get(input2.dataId).complexTensorInfos.real;
    const realVal = backend2.data.get(real4.dataId).values;
    return backend2.makeTensorInfo(real4.shape, real4.dtype, realVal);
  }
  var realConfig = {
    kernelName: Real,
    backendName: "cpu",
    kernelFunc: real2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cast.js
  function cast3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { dtype } = attrs;
    if (dtype === "complex64") {
      if (x.dtype === "complex64") {
        return identity({ inputs: { x }, backend: backend2 });
      }
      const zerosTensorInfo = zeros2(backend2, x.shape, x.dtype);
      const floatX = cast3({ inputs: { x }, backend: backend2, attrs: { dtype: "float32" } });
      const result = complex2({ inputs: { real: floatX, imag: zerosTensorInfo }, backend: backend2 });
      backend2.disposeIntermediateTensorInfo(zerosTensorInfo);
      backend2.disposeIntermediateTensorInfo(floatX);
      return result;
    }
    if (x.dtype === "complex64") {
      const realPart = real2({ inputs: { input: x }, backend: backend2 });
      const result = cast3({ inputs: { x: realPart }, backend: backend2, attrs: { dtype } });
      backend2.disposeIntermediateTensorInfo(realPart);
      return result;
    }
    if (!util_exports.hasEncodingLoss(x.dtype, dtype)) {
      const result = identity({ inputs: { x }, backend: backend2 });
      return { dataId: result.dataId, shape: result.shape, dtype };
    }
    if (dtype === "int32") {
      const values = backend2.data.get(x.dataId).values;
      const resultValues = Int32Array.from(values);
      return backend2.makeTensorInfo(x.shape, "int32", resultValues);
    }
    if (dtype === "bool") {
      const xVals = backend2.data.get(x.dataId).values;
      const zero = util_exports.toTypedArray([0], x.dtype);
      const [resultData, resultShape] = createSimpleBinaryKernelImpl((a, b) => a !== b ? 1 : 0)(x.shape, [], xVals, zero, "bool");
      return backend2.makeTensorInfo(resultShape, "bool", resultData);
    }
    throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);
  }
  var castConfig = {
    kernelName: Cast,
    backendName: "cpu",
    kernelFunc: cast3
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/binary_utils.js
  function binaryKernelFunc(name, simpleImpl, complexImpl, dtype) {
    if (complexImpl == null) {
      return ({ inputs, backend: backend2 }) => {
        const { a, b } = inputs;
        const cpuBackend = backend2;
        assertNotComplex([a, b], name);
        const aVals = cpuBackend.data.get(a.dataId).values;
        const bVals = cpuBackend.data.get(b.dataId).values;
        const decodedAVals = a.dtype === "string" ? backend_util_exports.fromUint8ToStringArray(aVals) : aVals;
        const decodedBVals = a.dtype === "string" ? backend_util_exports.fromUint8ToStringArray(bVals) : bVals;
        const $dtype = dtype || a.dtype;
        const [resultData, resultShape] = simpleImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype);
        return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);
      };
    }
    return ({ inputs, backend: backend2 }) => {
      const { a, b } = inputs;
      const cpuBackend = backend2;
      if (a.dtype === "complex64" || b.dtype === "complex64") {
        const $aComplex = cast3({ inputs: { x: a }, backend: cpuBackend, attrs: { dtype: "complex64" } });
        const $aComplexVals = cpuBackend.data.get($aComplex.dataId);
        const aReal = $aComplexVals.complexTensorInfos.real;
        const aImag = $aComplexVals.complexTensorInfos.imag;
        const aRealVals = cpuBackend.data.get(aReal.dataId).values;
        const aImagVals = cpuBackend.data.get(aImag.dataId).values;
        const $bComplex = cast3({ inputs: { x: b }, backend: cpuBackend, attrs: { dtype: "complex64" } });
        const $bComplexVals = cpuBackend.data.get($bComplex.dataId);
        const bReal = $bComplexVals.complexTensorInfos.real;
        const bImag = $bComplexVals.complexTensorInfos.imag;
        const bRealVals = cpuBackend.data.get(bReal.dataId).values;
        const bImagVals = cpuBackend.data.get(bImag.dataId).values;
        const [resultRealData, resultImagData, resultShape] = complexImpl(a.shape, b.shape, aRealVals, aImagVals, bRealVals, bImagVals);
        const resultReal = cpuBackend.makeTensorInfo(resultShape, "float32", resultRealData);
        const resultImag = cpuBackend.makeTensorInfo(resultShape, "float32", resultImagData);
        const result = complex2({ inputs: { real: resultReal, imag: resultImag }, backend: cpuBackend });
        cpuBackend.disposeIntermediateTensorInfo($aComplex);
        cpuBackend.disposeIntermediateTensorInfo($bComplex);
        cpuBackend.disposeIntermediateTensorInfo(resultReal);
        cpuBackend.disposeIntermediateTensorInfo(resultImag);
        return result;
      } else {
        const aVals = cpuBackend.data.get(a.dataId).values;
        const bVals = cpuBackend.data.get(b.dataId).values;
        const $dtype = dtype || a.dtype;
        const [resultData, resultShape] = simpleImpl(a.shape, b.shape, aVals, bVals, $dtype);
        return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);
      }
    };
  }
  function createComplexBinaryKernelImpl(op2) {
    return (aShape, bShape, aRealVals, aImagVals, bRealVals, bImagVals) => {
      const resultShape = backend_util_exports.assertAndGetBroadcastShape(aShape, bShape);
      const resultSize = util_exports.sizeFromShape(resultShape);
      const resultRank = resultShape.length;
      const resultStrides = util_exports.computeStrides(resultShape);
      const resultRealVals = util_exports.getTypedArrayFromDType("float32", resultSize);
      const resultImagVals = util_exports.getTypedArrayFromDType("float32", resultSize);
      const aBroadcastDims = backend_util_exports.getBroadcastDims(aShape, resultShape);
      const bBroadcastDims = backend_util_exports.getBroadcastDims(bShape, resultShape);
      const aVals = backend_util_exports.mergeRealAndImagArrays(aRealVals, aImagVals);
      const bVals = backend_util_exports.mergeRealAndImagArrays(bRealVals, bImagVals);
      const aRank = aShape.length;
      const aStrides = util_exports.computeStrides(aShape);
      const bRank = bShape.length;
      const bStrides = util_exports.computeStrides(bShape);
      if (aBroadcastDims.length + bBroadcastDims.length === 0) {
        for (let i = 0; i < resultRealVals.length; i++) {
          const aIdx = i % aVals.length;
          const bIdx = i % bVals.length;
          const result = op2(aVals[aIdx * 2], aVals[aIdx * 2 + 1], bVals[bIdx * 2], bVals[bIdx * 2 + 1]);
          resultRealVals[i] = result.real;
          resultImagVals[i] = result.imag;
        }
      } else {
        for (let i = 0; i < resultRealVals.length; i++) {
          const loc = util_exports.indexToLoc(i, resultRank, resultStrides);
          const aLoc = loc.slice(-aRank);
          aBroadcastDims.forEach((d) => aLoc[d] = 0);
          const aIndex = util_exports.locToIndex(aLoc, aRank, aStrides);
          const bLoc = loc.slice(-bRank);
          bBroadcastDims.forEach((d) => bLoc[d] = 0);
          const bIndex = util_exports.locToIndex(bLoc, bRank, bStrides);
          const opResult = op2(aVals[aIndex * 2], aVals[aIndex * 2 + 1], bVals[bIndex * 2], bVals[bIndex * 2 + 1]);
          resultRealVals[i] = opResult.real;
          resultImagVals[i] = opResult.imag;
        }
      }
      return [resultRealVals, resultImagVals, resultShape];
    };
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Add.js
  var addImpl = createSimpleBinaryKernelImpl((a, b) => a + b);
  var addComplexImpl = createComplexBinaryKernelImpl((aReal, aImag, bReal, bImag) => {
    return { real: aReal + bReal, imag: aImag + bImag };
  });
  var add4 = binaryKernelFunc(Add, addImpl, addComplexImpl);
  var addConfig = {
    kernelName: Add,
    backendName: "cpu",
    kernelFunc: add4
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Bincount_impl.js
  function bincountImpl(xVals, weightsVals, weightsDtype, weightsShape, size2) {
    const weightsSize = util_exports.sizeFromShape(weightsShape);
    const outVals = util_exports.makeZerosTypedArray(size2, weightsDtype);
    for (let i = 0; i < xVals.length; i++) {
      const value = xVals[i];
      if (value < 0) {
        throw new Error("Input x must be non-negative!");
      }
      if (value >= size2) {
        continue;
      }
      if (weightsSize > 0) {
        outVals[value] += weightsVals[i];
      } else {
        outVals[value] += 1;
      }
    }
    return outVals;
  }
  function bincountReduceImpl(xBuf, weightsBuf, size2, binaryOutput = false) {
    const numRows = xBuf.shape[0];
    const numCols = xBuf.shape[1];
    const outBuf = buffer2([numRows, size2], weightsBuf.dtype);
    for (let i = 0; i < numRows; i++) {
      for (let j = 0; j < numCols; j++) {
        const value = xBuf.get(i, j);
        if (value < 0) {
          throw new Error("Input x must be non-negative!");
        }
        if (value >= size2) {
          continue;
        }
        if (binaryOutput) {
          outBuf.set(1, i, value);
        } else {
          if (weightsBuf.size > 0) {
            outBuf.set(outBuf.get(i, value) + weightsBuf.get(i, j), i, value);
          } else {
            outBuf.set(outBuf.get(i, value) + 1, i, value);
          }
        }
      }
    }
    return outBuf;
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/unary_impl.js
  function createSimpleUnaryImpl(op2) {
    return (values, dtype, attrs) => {
      const newValues = util_exports.getTypedArrayFromDType(dtype, values.length);
      for (let i = 0; i < values.length; ++i) {
        newValues[i] = op2(values[i], attrs);
      }
      return newValues;
    };
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/unary_utils.js
  function unaryKernelFunc(name, op2, dtype) {
    return ({ inputs, attrs, backend: backend2 }) => {
      const { x } = inputs;
      assertNotComplex(x, name);
      if (x.dtype === "string" || dtype === "string") {
        throw new Error("unaryKernelFunc does not support string input/output");
      }
      const cpuBackend = backend2;
      const values = cpuBackend.data.get(x.dataId).values;
      const xSize = util_exports.sizeFromShape(x.shape);
      const $dtype = dtype || x.dtype;
      const newValues = util_exports.getArrayFromDType($dtype, xSize);
      for (let i = 0; i < xSize; ++i) {
        newValues[i] = op2(values[i], attrs);
      }
      return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);
    };
  }
  function unaryKernelFuncFromImpl(name, unaryImpl, dtype) {
    return ({ inputs, attrs, backend: backend2 }) => {
      const { x } = inputs;
      assertNotComplex(x, name);
      if (x.dtype === "string" || dtype === "string") {
        throw new Error("unaryKernelFunc does not support string input/output");
      }
      const cpuBackend = backend2;
      const values = cpuBackend.data.get(x.dataId).values;
      const $dtype = dtype || x.dtype;
      const newValues = unaryImpl(values, $dtype, attrs);
      return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);
    };
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Ceil.js
  var ceilImpl = createSimpleUnaryImpl((xi) => Math.ceil(xi));
  var ceil2 = unaryKernelFuncFromImpl(Ceil, ceilImpl);
  var ceilConfig = {
    kernelName: Ceil,
    backendName: "cpu",
    kernelFunc: ceil2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Concat_impl.js
  function concatImpl(inputs, outShape, dtype, simplyConcat) {
    const outVals = util_exports.getArrayFromDType(dtype, util_exports.sizeFromShape(outShape));
    if (simplyConcat && dtype !== "string") {
      let offset = 0;
      inputs.forEach((input2) => {
        const size2 = util_exports.sizeFromShape(input2.shape);
        outVals.set(input2.vals, offset);
        offset += size2;
      });
    } else {
      let colOffset = 0;
      inputs.forEach((input2) => {
        const decodedData = dtype === "string" ? backend_util_exports.fromUint8ToStringArray(input2.vals) : input2.vals;
        let tIdx = 0;
        for (let row = 0; row < input2.shape[0]; ++row) {
          const resIdx = row * outShape[1] + colOffset;
          for (let col = 0; col < input2.shape[1]; ++col) {
            outVals[resIdx + col] = decodedData[tIdx++];
          }
        }
        colOffset += input2.shape[1];
      });
    }
    return outVals;
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Equal.js
  var equalImpl = createSimpleBinaryKernelImpl((a, b) => a === b ? 1 : 0);
  var equal2 = binaryKernelFunc(Equal, equalImpl, null, "bool");
  var equalConfig = {
    kernelName: Equal,
    backendName: "cpu",
    kernelFunc: equal2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Exp.js
  var expImpl = createSimpleUnaryImpl((xi) => Math.exp(xi));
  var exp2 = unaryKernelFuncFromImpl(Exp, expImpl, "float32");
  var expConfig = {
    kernelName: Exp,
    backendName: "cpu",
    kernelFunc: exp2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Expm1.js
  var expm1Impl = createSimpleUnaryImpl((xi) => Math.expm1(xi));
  var expm12 = unaryKernelFuncFromImpl(Expm1, expm1Impl);
  var expm1Config = {
    kernelName: Expm1,
    backendName: "cpu",
    kernelFunc: expm12
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Floor.js
  var floorImpl = createSimpleUnaryImpl((xi) => Math.floor(xi));
  var floor2 = unaryKernelFuncFromImpl(Floor, floorImpl);
  var floorConfig = {
    kernelName: Floor,
    backendName: "cpu",
    kernelFunc: floor2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GatherNd_Impl.js
  function gatherNdImpl(indicesData, paramsBuf, dtype, numSlices, sliceRank, sliceSize, strides, paramsShape, paramsSize) {
    const outBuf = buffer2([numSlices, sliceSize], dtype);
    for (let i = 0; i < numSlices; i++) {
      const index = [];
      let flattenIndex = 0;
      for (let j = 0; j < sliceRank; j++) {
        const dim = indicesData[i * sliceRank + j];
        flattenIndex += dim * strides[j];
        index.push(dim);
      }
      if (flattenIndex < 0 || flattenIndex >= paramsSize / sliceSize) {
        throw new Error(`Invalid indices: ${index} does not index into ${paramsShape}`);
      }
      for (let k = 0; k < sliceSize; k++) {
        outBuf.values[i * sliceSize + k] = paramsBuf.get(...paramsBuf.indexToLoc(flattenIndex * sliceSize + k));
      }
    }
    return outBuf;
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GatherV2_impl.js
  function gatherV2Impl(xBuf, indicesBuf, flattenOutputShape) {
    const outBuf = buffer2(flattenOutputShape, xBuf.dtype);
    for (let i = 0; i < outBuf.size; ++i) {
      const newLoc = outBuf.indexToLoc(i);
      const originalLoc = newLoc.slice();
      const batchIdx = originalLoc[0];
      const indicesIdx = originalLoc[2];
      const indicesIndex = indicesBuf.locToIndex([batchIdx, indicesIdx]);
      originalLoc[2] = indicesBuf.values[indicesIndex];
      const originalIndex = xBuf.locToIndex(originalLoc);
      outBuf.values[i] = xBuf.values[originalIndex];
    }
    return outBuf;
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Greater.js
  var greaterImpl = createSimpleBinaryKernelImpl((a, b) => a > b ? 1 : 0);
  var greater2 = binaryKernelFunc(Greater, greaterImpl, null, "bool");
  var greaterConfig = {
    kernelName: Greater,
    backendName: "cpu",
    kernelFunc: greater2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GreaterEqual.js
  var greaterEqualImpl = createSimpleBinaryKernelImpl((a, b) => a >= b ? 1 : 0);
  var greaterEqual2 = binaryKernelFunc(GreaterEqual, greaterEqualImpl, null, "bool");
  var greaterEqualConfig = {
    kernelName: GreaterEqual,
    backendName: "cpu",
    kernelFunc: greaterEqual2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Less.js
  var lessImpl = createSimpleBinaryKernelImpl((a, b) => a < b ? 1 : 0);
  var less2 = binaryKernelFunc(Less, lessImpl, null, "bool");
  var lessConfig = {
    kernelName: Less,
    backendName: "cpu",
    kernelFunc: less2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LessEqual.js
  var lessEqualImpl = createSimpleBinaryKernelImpl((a, b) => a <= b ? 1 : 0);
  var lessEqual2 = binaryKernelFunc(LessEqual, lessEqualImpl, null, "bool");
  var lessEqualConfig = {
    kernelName: LessEqual,
    backendName: "cpu",
    kernelFunc: lessEqual2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LinSpace_impl.js
  function linSpaceImpl(start, stop2, num) {
    const step4 = (stop2 - start) / (num - 1);
    const values = util_exports.makeZerosTypedArray(num, "float32");
    values[0] = start;
    for (let i = 1; i < values.length; i++) {
      values[i] = values[i - 1] + step4;
    }
    return values;
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Log.js
  var logImpl = createSimpleUnaryImpl((xi) => Math.log(xi));
  var log6 = unaryKernelFuncFromImpl(Log, logImpl);
  var logConfig = {
    kernelName: Log,
    backendName: "cpu",
    kernelFunc: log6
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Max_impl.js
  function maxImpl(aVals, reduceSize, outShape, dtype) {
    const vals = util_exports.getTypedArrayFromDType(dtype, util_exports.sizeFromShape(outShape));
    for (let i = 0; i < vals.length; ++i) {
      const offset = i * reduceSize;
      let max5 = aVals[offset];
      for (let j = 0; j < reduceSize; ++j) {
        const value = aVals[offset + j];
        if (Number.isNaN(value) || value > max5) {
          max5 = value;
        }
      }
      vals[i] = max5;
    }
    return vals;
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Maximum.js
  var maximumImpl = createSimpleBinaryKernelImpl((aValue, bValue) => Math.max(aValue, bValue));
  var maximum2 = binaryKernelFunc(Maximum, maximumImpl);
  var maximumConfig = {
    kernelName: Maximum,
    backendName: "cpu",
    kernelFunc: maximum2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Minimum.js
  var minimumImpl = createSimpleBinaryKernelImpl((aValue, bValue) => Math.min(aValue, bValue));
  var minimum2 = binaryKernelFunc(Minimum, minimumImpl);
  var minimumConfig = {
    kernelName: Minimum,
    backendName: "cpu",
    kernelFunc: minimum2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Multiply.js
  var multiplyImpl = createSimpleBinaryKernelImpl((aValue, bValue) => aValue * bValue);
  var multiplyComplexImpl = createComplexBinaryKernelImpl((aReal, aImag, bReal, bImag) => {
    return {
      real: aReal * bReal - aImag * bImag,
      imag: aReal * bImag + aImag * bReal
    };
  });
  var multiply = binaryKernelFunc(Multiply, multiplyImpl, multiplyComplexImpl);
  var multiplyConfig = {
    kernelName: Multiply,
    backendName: "cpu",
    kernelFunc: multiply
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Neg.js
  function negImpl(xVals, xShape, xDtype) {
    const minusOne = util_exports.createScalarValue(-1, xDtype);
    return multiplyImpl([], xShape, minusOne, xVals, xDtype);
  }
  function neg2(args) {
    const { inputs, backend: backend2 } = args;
    const { x } = inputs;
    assertNotComplex(x, "neg");
    const xVals = backend2.data.get(x.dataId).values;
    const [res, newShape] = negImpl(xVals, x.shape, x.dtype);
    return backend2.makeTensorInfo(newShape, x.dtype, res);
  }
  var negConfig = {
    kernelName: Neg,
    backendName: "cpu",
    kernelFunc: neg2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/NotEqual.js
  var notEqualImpl = createSimpleBinaryKernelImpl((a, b) => a !== b ? 1 : 0);
  var notEqual2 = binaryKernelFunc(NotEqual, notEqualImpl, null, "bool");
  var notEqualConfig = {
    kernelName: NotEqual,
    backendName: "cpu",
    kernelFunc: notEqual2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Transpose_impl.js
  function transposeImpl(xVals, xShape, dtype, perm, newShape) {
    const xRank = xShape.length;
    const xSize = util_exports.sizeFromShape(xShape);
    const xStrides = util_exports.computeStrides(xShape);
    const newStrides = util_exports.computeStrides(newShape);
    const result = util_exports.getTypedArrayFromDType(dtype, util_exports.sizeFromShape(newShape));
    for (let i = 0; i < xSize; ++i) {
      const loc = util_exports.indexToLoc(i, xRank, xStrides);
      const newLoc = new Array(loc.length);
      for (let i2 = 0; i2 < newLoc.length; i2++) {
        newLoc[i2] = loc[perm[i2]];
      }
      const newIndex = util_exports.locToIndex(newLoc, xRank, newStrides);
      result[newIndex] = xVals[i];
    }
    return result;
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Transpose.js
  function transpose2(args) {
    const { inputs, attrs, backend: backend2 } = args;
    const { x } = inputs;
    const { perm } = attrs;
    assertNotComplex(x, "transpose");
    const xRank = x.shape.length;
    const newShape = new Array(xRank);
    for (let i = 0; i < newShape.length; i++) {
      newShape[i] = x.shape[perm[i]];
    }
    const values = backend2.data.get(x.dataId).values;
    const result = transposeImpl(values, x.shape, x.dtype, perm, newShape);
    const dataId = backend2.write(result, newShape, x.dtype);
    return { dataId, shape: newShape, dtype: x.dtype };
  }
  var transposeConfig = {
    kernelName: Transpose,
    backendName: "cpu",
    kernelFunc: transpose2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Prod.js
  function prodImpl(xShape, xDtype, xVals, reductionAxes) {
    const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(xShape, reductionAxes);
    const outDtype = upcastType(xDtype, "int32");
    const outVals = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(outShape), outDtype);
    const reduceSize = util_exports.sizeFromShape(reduceShape);
    for (let i = 0; i < outVals.length; ++i) {
      const offset = i * reduceSize;
      let prod4 = 1;
      for (let j = 0; j < reduceSize; ++j) {
        prod4 *= xVals[offset + j];
      }
      outVals[i] = prod4;
    }
    return { outVals, outShape, outDtype };
  }
  function prod2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { axis, keepDims } = attrs;
    assertNotComplex(x, "prod");
    const xRank = x.shape.length;
    const axes = util_exports.parseAxisParam(axis, x.shape);
    const permutation = backend_util_exports.getAxesPermutation(axes, xRank);
    let reductionAxes = axes;
    let permutedX = x;
    const intermediateTensorInfos = [];
    if (permutation != null) {
      permutedX = transpose2({ inputs: { x }, backend: backend2, attrs: { perm: permutation } });
      intermediateTensorInfos.push(permutedX);
      reductionAxes = backend_util_exports.getInnerMostAxes(reductionAxes.length, xRank);
    }
    const xVals = backend2.data.get(permutedX.dataId).values;
    const { outVals, outShape, outDtype } = prodImpl(permutedX.shape, permutedX.dtype, xVals, reductionAxes);
    let resultShape = outShape;
    if (keepDims) {
      resultShape = backend_util_exports.expandShapeToKeepDim(outShape, axes);
    }
    intermediateTensorInfos.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
    return backend2.makeTensorInfo(resultShape, outDtype, outVals);
  }
  var prodConfig = {
    kernelName: Prod,
    backendName: "cpu",
    kernelFunc: prod2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Range_impl.js
  function rangeImpl(start, stop2, step4, dtype) {
    const sameStartStop = start === stop2;
    const increasingRangeNegativeStep = start < stop2 && step4 < 0;
    const decreasingRangePositiveStep = stop2 < start && step4 > 1;
    if (sameStartStop || increasingRangeNegativeStep || decreasingRangePositiveStep) {
      return util_exports.makeZerosTypedArray(0, dtype);
    }
    const numElements = Math.abs(Math.ceil((stop2 - start) / step4));
    const values = util_exports.makeZerosTypedArray(numElements, dtype);
    if (stop2 < start && step4 === 1) {
      step4 = -1;
    }
    values[0] = start;
    for (let i = 1; i < values.length; i++) {
      values[i] = values[i - 1] + step4;
    }
    return values;
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Rsqrt.js
  var rsqrtImpl = createSimpleUnaryImpl((xi) => 1 / Math.sqrt(xi));
  var rsqrt2 = unaryKernelFuncFromImpl(Rsqrt, rsqrtImpl);
  var rsqrtConfig = {
    kernelName: Rsqrt,
    backendName: "cpu",
    kernelFunc: rsqrt2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sigmoid.js
  var sigmoidImpl = createSimpleUnaryImpl((xi) => 1 / (1 + Math.exp(-xi)));
  var sigmoid2 = unaryKernelFunc(Sigmoid, (xi) => 1 / (1 + Math.exp(-xi)));
  var sigmoidConfig = {
    kernelName: Sigmoid,
    backendName: "cpu",
    kernelFunc: sigmoid2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Slice.js
  function sliceImpl(vals, begin, size2, shape, dtype) {
    const isContinous = slice_util_exports.isSliceContinous(shape, begin, size2);
    const length = util_exports.sizeFromShape(size2);
    const xStrides = util_exports.computeStrides(shape);
    if (isContinous) {
      const flatOffset = slice_util_exports.computeFlatOffset(begin, xStrides);
      if (dtype === "string") {
        return vals.slice(flatOffset, flatOffset + length);
      }
      return vals.subarray(flatOffset, flatOffset + length);
    }
    const decodedData = dtype === "string" ? backend_util_exports.fromUint8ToStringArray(vals) : vals;
    const inBuf = buffer2(shape, dtype, decodedData);
    const outBuf = buffer2(size2, dtype);
    for (let i = 0; i < outBuf.size; ++i) {
      const outLoc = outBuf.indexToLoc(i);
      const inLoc = outLoc.map((idx, j) => idx + begin[j]);
      outBuf.set(inBuf.get(...inLoc), ...outLoc);
    }
    if (dtype === "string") {
      return backend_util_exports.fromStringArrayToUint8(outBuf.values);
    }
    return outBuf.values;
  }
  function slice2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { begin, size: size2 } = attrs;
    assertNotComplex(x, "slice");
    const [$begin, $size] = slice_util_exports.parseSliceParams(x, begin, size2);
    slice_util_exports.assertParamsValid(x, $begin, $size);
    const vals = backend2.data.get(x.dataId).values;
    const outVals = sliceImpl(vals, $begin, $size, x.shape, x.dtype);
    return backend2.makeTensorInfo($size, x.dtype, outVals);
  }
  var sliceConfig = {
    kernelName: Slice,
    backendName: "cpu",
    kernelFunc: slice2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseFillEmptyRows_impl.js
  function sparseFillEmptyRowsImpl(indices, indicesShape, indicesDType, values, valuesDType, denseShape, defaultValue) {
    const indicesCount = indicesShape[0];
    const denseRows = denseShape[0];
    const emptyRowIndicator = new Array(denseRows);
    const reverseIndexMap = new Array(indicesCount);
    const rank = indicesShape[1];
    if (denseRows === 0) {
      if (indicesCount !== 0) {
        throw new Error(`Received SparseTensor with denseShape[0] = 0 but
         indices.shape[0] = ${indicesCount}`);
      }
      const outputIndices = util_exports.getArrayFromDType(indicesDType, 0);
      const outputValues = util_exports.getArrayFromDType(valuesDType, 0);
      return [
        outputIndices,
        [0, rank],
        outputValues,
        emptyRowIndicator,
        reverseIndexMap
      ];
    }
    let rowsAreOrdered = true;
    let lastIndicesRow = 0;
    const csrOffset = new Array(denseRows).fill(0);
    for (let i = 0; i < indicesCount; ++i) {
      const row = indices[i * rank];
      if (row < 0) {
        throw new Error(`indices(${i}, 0) is invalid: ${row} < 0`);
      }
      if (row >= denseRows) {
        throw new Error(`indices(${i}, 0) is invalid: ${row} >= ${denseRows}`);
      }
      ++csrOffset[row];
      rowsAreOrdered = rowsAreOrdered && row >= lastIndicesRow;
      lastIndicesRow = row;
    }
    let allRowsFull = true;
    for (let row = 0; row < denseRows; ++row) {
      const rowEmpty = csrOffset[row] === 0;
      emptyRowIndicator[row] = rowEmpty;
      allRowsFull = allRowsFull && !rowEmpty;
      csrOffset[row] = Math.max(csrOffset[row], 1);
      if (row > 0) {
        csrOffset[row] += csrOffset[row - 1];
      }
    }
    if (allRowsFull && rowsAreOrdered) {
      const outputIndices = indices;
      const outputValues = values;
      for (let i = 0; i < indicesCount; ++i) {
        reverseIndexMap[i] = i;
      }
      return [
        outputIndices,
        [indicesCount, rank],
        outputValues,
        emptyRowIndicator,
        reverseIndexMap
      ];
    } else {
      const fullIndicesCount = csrOffset[denseRows - 1];
      const outputIndices = util_exports.getArrayFromDType(indicesDType, fullIndicesCount * rank);
      const outputValues = util_exports.getArrayFromDType(valuesDType, fullIndicesCount);
      const filledCount = new Array(denseRows).fill(0);
      for (let i = 0; i < indicesCount; ++i) {
        const row = indices[i * rank];
        const offset = filledCount[row];
        const outputI = (row === 0 ? 0 : csrOffset[row - 1]) + offset;
        filledCount[row]++;
        for (let j = 0; j < rank; ++j) {
          outputIndices[outputI * rank + j] = indices[i * rank + j];
        }
        outputValues[outputI] = values[i];
        reverseIndexMap[i] = outputI;
      }
      for (let row = 0; row < denseRows; ++row) {
        const rowCount = filledCount[row];
        if (rowCount === 0) {
          const startingIndex = row === 0 ? 0 : csrOffset[row - 1];
          outputIndices[startingIndex * rank + 0] = row;
          for (let col = 1; col < rank; ++col) {
            outputIndices[startingIndex * rank + col] = 0;
          }
          outputValues[startingIndex] = defaultValue;
        }
      }
      return [
        outputIndices,
        [fullIndicesCount, rank],
        outputValues,
        emptyRowIndicator,
        reverseIndexMap
      ];
    }
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseReshape_impl.js
  function sparseReshapeImpl(inputIndices, inputIndicesShape, inputDType, inputShape, targetShape) {
    const denseSize = util_exports.sizeFromShape(inputShape);
    const nnz = inputIndicesShape[0];
    const outputRank = targetShape.length;
    const outputShape = [];
    let product = 1;
    let unknownIndex = -1;
    for (let d = 0; d < outputRank; ++d) {
      const size2 = targetShape[d];
      if (size2 === -1) {
        if (unknownIndex !== -1) {
          throw new Error(`only one output dimension may be -1, not both ${unknownIndex} and ${d}`);
        }
        unknownIndex = d;
        outputShape.push(1);
      } else {
        if (size2 < 0) {
          throw new Error(`size ${d} must be non-negative, not ${size2}`);
        }
        product *= size2;
        outputShape.push(size2);
      }
    }
    if (unknownIndex !== -1) {
      if (product <= 0) {
        throw new Error("reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero");
      }
      const missing = Math.trunc(denseSize / product);
      if (product * missing !== denseSize) {
        throw new Error(`Input to reshape is a SparseTensor with ${denseSize}
          dense values, but the requested shape requires a multiple of ${product}. inputShape=${inputShape} outputShape= ${outputShape}`);
      }
      outputShape[unknownIndex] = missing;
    }
    const outputSize = util_exports.sizeFromShape(outputShape);
    if (outputSize !== denseSize) {
      throw new Error(`Input to reshape is a tensor with ${denseSize} dense values, but the requested shape has ${outputSize}. inputShape=${inputShape} outputShape=${outputShape}`);
    }
    const inputRank = inputShape.length;
    const inputStrides = [];
    if (inputRank > 0) {
      inputStrides[inputRank - 1] = 1;
      for (let d = inputRank - 2; d >= 0; --d) {
        inputStrides[d] = inputStrides[d + 1] * inputShape[d + 1];
      }
    }
    const outputStrides = [];
    if (outputRank > 0) {
      outputStrides[outputRank - 1] = 1;
      for (let d = outputRank - 2; d >= 0; --d) {
        outputStrides[d] = outputStrides[d + 1] * outputShape[d + 1];
      }
    }
    const newIndices = util_exports.getArrayFromDType(inputDType, nnz * outputRank);
    for (let i = 0; i < nnz; ++i) {
      let id = 0;
      for (let j = 0; j < inputRank; ++j) {
        id += inputIndices[i * inputRank + j] * inputStrides[j];
      }
      for (let j = 0; j < outputRank; ++j) {
        newIndices[i * outputRank + j] = Math.trunc(id / outputStrides[j]);
        id %= outputStrides[j];
      }
    }
    return [newIndices, [nnz, outputRank], outputShape];
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentReduction_impl.js
  function sparseSegmentReductionImpl(input2, inputShape, inputDType, indices, segmentIds, isMean = false, defaultValue = 0) {
    const numIndices = indices.length;
    if (numIndices !== segmentIds.length) {
      throw new Error(`segmentIds and indices should have same size.`);
    }
    const inputFlat = [inputShape[0], input2.length / inputShape[0]];
    const numCol = inputFlat[1];
    const lastSegmentIdPlusOne = numIndices > 0 ? segmentIds[numIndices - 1] + 1 : 0;
    const outputRows = lastSegmentIdPlusOne;
    if (outputRows < 0) {
      throw new Error(`segment ids must be >= 0`);
    }
    const outputShape = inputShape.slice();
    outputShape[0] = outputRows;
    const outputLength = outputShape.reduce((product, value) => product * value, 1);
    const output = util_exports.getArrayFromDType(inputDType, outputLength);
    if (numIndices === 0) {
      if (outputRows > 0) {
        output.fill(defaultValue);
      }
      return [output, outputShape];
    }
    if (outputRows <= 0) {
      throw new Error(`segment ids must be >= 0`);
    }
    let start = 0, end = 1;
    let uninitializedIndex = 0;
    let outIndex = segmentIds[start];
    while (true) {
      let nextIndex = 0;
      if (end < numIndices) {
        nextIndex = segmentIds[end];
        if (outIndex === nextIndex) {
          ++end;
          continue;
        }
        if (outIndex >= nextIndex) {
          throw new Error(`segment ids are not increasing`);
        }
      }
      if (outIndex < 0 || outIndex >= outputRows) {
        throw new Error(`Segment id ${outIndex} out of range [0, ${outputRows}), possibly because segmentIds input is not sorted.`);
      }
      if (outIndex > uninitializedIndex) {
        output.fill(defaultValue, uninitializedIndex * numCol, outIndex * numCol);
      }
      for (let i = start; i < end; ++i) {
        const index = indices[i];
        if (index < 0 || index >= inputFlat[0]) {
          throw new Error(`Bad: indices[${i}] == ${indices[i]} out of range [0, ${inputFlat[0]})`);
        }
        for (let j = 0; j < numCol; j++) {
          output[outIndex * numCol + j] += input2[index * numCol + j];
        }
      }
      if (isMean) {
        for (let j = 0; j < numCol; j++) {
          output[outIndex * numCol + j] /= end - start;
        }
      }
      start = end;
      ++end;
      uninitializedIndex = outIndex + 1;
      outIndex = nextIndex;
      if (end > numIndices) {
        break;
      }
    }
    if (uninitializedIndex < outputRows) {
      output.fill(defaultValue, uninitializedIndex * numCol, outputRows * numCol);
    }
    return [output, outputShape];
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sqrt.js
  var sqrtImpl = createSimpleUnaryImpl((xi) => Math.sqrt(xi));
  var sqrt2 = unaryKernelFunc(Sqrt, (xi) => Math.sqrt(xi));
  var sqrtConfig = {
    kernelName: Sqrt,
    backendName: "cpu",
    kernelFunc: sqrt2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SquaredDifference.js
  var squaredDifferenceImpl = createSimpleBinaryKernelImpl((a, b) => {
    const diff = a - b;
    return diff * diff;
  });
  var squaredDifference2 = binaryKernelFunc(SquaredDifference, squaredDifferenceImpl);
  var squaredDifferenceConfig = {
    kernelName: SquaredDifference,
    backendName: "cpu",
    kernelFunc: squaredDifference2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StridedSlice_impl.js
  function stridedSliceImpl(outShape, xBuf, strides, begin) {
    const outBuf = buffer2(outShape, xBuf.dtype);
    for (let i = 0; i < outBuf.size; i++) {
      const loc = outBuf.indexToLoc(i);
      const newLoc = new Array(loc.length);
      for (let j = 0; j < newLoc.length; j++) {
        newLoc[j] = loc[j] * strides[j] + begin[j];
      }
      outBuf.set(xBuf.get(...newLoc), ...loc);
    }
    return outBuf;
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringNGrams_impl.js
  var StringNGramsOp = class {
    constructor(separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences) {
      this.separator = util_exports.encodeString(separator);
      this.nGramWidths = nGramWidths;
      this.leftPad = util_exports.encodeString(leftPad);
      this.rightPad = util_exports.encodeString(rightPad2);
      this.padWidth = padWidth;
      this.preserveShort = preserveShortSequences;
    }
    getPadWidth(nGramWidth) {
      return Math.min(this.padWidth < 0 ? nGramWidth - 1 : this.padWidth, nGramWidth - 1);
    }
    getNumNGrams(length, nGramWidth) {
      const padWidth = this.getPadWidth(nGramWidth);
      return Math.max(0, length + 2 * padWidth - nGramWidth + 1);
    }
    createNGrams(data, splitIndex, output, outputStartIndex, numNGrams, nGramWidth) {
      for (let nGramIndex = 0; nGramIndex < numNGrams; ++nGramIndex) {
        const padWidth = this.getPadWidth(nGramWidth);
        const leftPadding = Math.max(0, padWidth - nGramIndex);
        const rightPadding = Math.max(0, padWidth - (numNGrams - (nGramIndex + 1)));
        const numTokens = nGramWidth - (leftPadding + rightPadding);
        const dataStartIndex = splitIndex + (leftPadding > 0 ? 0 : nGramIndex - padWidth);
        let nGramSize = 0;
        nGramSize += leftPadding * this.leftPad.length;
        for (let n = 0; n < numTokens; ++n) {
          nGramSize += data[dataStartIndex + n].length;
        }
        nGramSize += rightPadding * this.rightPad.length;
        const numSeparators = leftPadding + rightPadding + numTokens - 1;
        nGramSize += numSeparators * this.separator.length;
        output[outputStartIndex + nGramIndex] = new Uint8Array(nGramSize);
        const nGram = output[outputStartIndex + nGramIndex];
        let nextNGramIndex = 0;
        const appendToNGram = (str) => str.forEach((value) => nGram[nextNGramIndex++] = value);
        for (let n = 0; n < leftPadding; ++n) {
          appendToNGram(this.leftPad);
          appendToNGram(this.separator);
        }
        for (let n = 0; n < numTokens - 1; ++n) {
          appendToNGram(data[dataStartIndex + n]);
          appendToNGram(this.separator);
        }
        if (numTokens > 0) {
          appendToNGram(data[dataStartIndex + numTokens - 1]);
          for (let n = 0; n < rightPadding; ++n) {
            appendToNGram(this.separator);
            appendToNGram(this.rightPad);
          }
        } else {
          for (let n = 0; n < rightPadding - 1; ++n) {
            appendToNGram(this.rightPad);
            appendToNGram(this.separator);
          }
          appendToNGram(this.rightPad);
        }
      }
    }
    compute(data, splits) {
      const inputDataSize = data.length;
      const splitsSize = splits.length;
      if (splitsSize > 0) {
        let prevSplit = splits[0];
        if (prevSplit !== 0) {
          throw new Error(`First split value must be 0, got ${prevSplit}`);
        }
        for (let i = 1; i < splitsSize; ++i) {
          let validSplits = splits[i] >= prevSplit;
          validSplits = validSplits && splits[i] <= inputDataSize;
          if (!validSplits) {
            throw new Error(`Invalid split value ${splits[i]}, must be in [${prevSplit}, ${inputDataSize}]`);
          }
          prevSplit = splits[i];
        }
        if (prevSplit !== inputDataSize) {
          throw new Error(`Last split value must be data size. Expected ${inputDataSize}, got ${prevSplit}`);
        }
      }
      const numBatchItems = splitsSize - 1;
      const nGramsSplits = util_exports.getArrayFromDType("int32", splitsSize);
      if (inputDataSize === 0 || splitsSize === 0) {
        const empty = new Array(inputDataSize);
        for (let i = 0; i <= numBatchItems; ++i) {
          nGramsSplits[i] = 0;
        }
        return [empty, nGramsSplits];
      }
      nGramsSplits[0] = 0;
      for (let i = 1; i <= numBatchItems; ++i) {
        const length = splits[i] - splits[i - 1];
        let numNGrams = 0;
        this.nGramWidths.forEach((nGramWidth) => {
          numNGrams += this.getNumNGrams(length, nGramWidth);
        });
        if (this.preserveShort && length > 0 && numNGrams === 0) {
          numNGrams = 1;
        }
        nGramsSplits[i] = nGramsSplits[i - 1] + numNGrams;
      }
      const nGrams = new Array(nGramsSplits[numBatchItems]);
      for (let i = 0; i < numBatchItems; ++i) {
        const splitIndex = splits[i];
        let outputStartIdx = nGramsSplits[i];
        this.nGramWidths.forEach((nGramWidth) => {
          const length = splits[i + 1] - splits[i];
          const numNGrams = this.getNumNGrams(length, nGramWidth);
          this.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);
          outputStartIdx += numNGrams;
        });
        if (this.preserveShort && outputStartIdx === nGramsSplits[i]) {
          const dataLength = splits[i + 1] - splits[i];
          if (dataLength === 0) {
            continue;
          }
          const nGramWidth = dataLength + 2 * this.padWidth;
          const numNGrams = 1;
          this.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);
        }
      }
      return [nGrams, nGramsSplits];
    }
  };
  function stringNGramsImpl(data, dataSplits, separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences) {
    return new StringNGramsOp(separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences).compute(data, dataSplits);
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringSplit_impl.js
  function split3(str, delimiters, skipEmpty, result) {
    if (!str.length) {
      return;
    }
    if (delimiters.length === 0) {
      for (let i = 0; i < str.length; ++i) {
        result.push(str.subarray(i, i + 1));
      }
      return;
    }
    if (delimiters.length === 1) {
      const delimiter = delimiters[0];
      let f = str.indexOf(delimiter);
      while (f !== -1) {
        const token = str.subarray(0, f);
        if (!skipEmpty || token.length !== 0) {
          result.push(token);
        }
        str = str.subarray(f + 1);
        f = str.indexOf(delimiter);
      }
      if (!skipEmpty || str.length !== 0) {
        result.push(str);
      }
      return;
    }
    let tokenStart = 0;
    for (let i = 0; i < str.length + 1; i++) {
      if (i === str.length || delimiters.indexOf(str[i]) !== -1) {
        const token = str.subarray(tokenStart, i);
        if (!skipEmpty || token.length !== 0) {
          result.push(token);
        }
        tokenStart = i + 1;
      }
    }
  }
  function stringSplitImpl(input2, delimiter, skipEmpty) {
    const batchSize = input2.length;
    const tokens = [];
    let outputSize = 0;
    let maxNumEntries = 0;
    const numIndices = new Array(batchSize);
    for (let i = 0; i < batchSize; ++i) {
      const prevTokensLength = tokens.length;
      split3(input2[i], delimiter, skipEmpty, tokens);
      const nEntries = tokens.length - prevTokensLength;
      numIndices[i] = nEntries;
      outputSize += nEntries;
      maxNumEntries = Math.max(maxNumEntries, nEntries);
    }
    const indices = util_exports.getArrayFromDType("int32", outputSize * 2);
    const values = new Array(outputSize);
    const shape = [batchSize, maxNumEntries];
    let c = 0;
    for (let i = 0; i < batchSize; ++i) {
      for (let j = 0; j < numIndices[i]; ++j) {
        indices[c * 2] = i;
        indices[c * 2 + 1] = j;
        values[c] = tokens[c];
        ++c;
      }
    }
    return [indices, values, shape];
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringToHashBucketFast_impl.js
  function stringToHashBucketFastImpl(input2, numBuckets) {
    const output = util_exports.getArrayFromDType("int32", input2.length);
    for (let i = 0; i < input2.length; ++i) {
      output[i] = util_exports.fingerPrint64(input2[i]).modulo(numBuckets).getLowBitsUnsigned();
    }
    return output;
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sub.js
  var subImpl = createSimpleBinaryKernelImpl((aValue, bValue) => aValue - bValue);
  var subComplexImpl = createComplexBinaryKernelImpl((aReal, aImag, bReal, bImag) => {
    return { real: aReal - bReal, imag: aImag - bImag };
  });
  var sub2 = binaryKernelFunc(Sub, subImpl, subComplexImpl);
  var subConfig = {
    kernelName: Sub,
    backendName: "cpu",
    kernelFunc: sub2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Tile_impl.js
  function tileImpl(xBuf, reps) {
    const newShape = new Array(xBuf.rank);
    for (let i = 0; i < newShape.length; i++) {
      newShape[i] = xBuf.shape[i] * reps[i];
    }
    const result = buffer2(newShape, xBuf.dtype);
    for (let i = 0; i < result.values.length; ++i) {
      const newLoc = result.indexToLoc(i);
      const originalLoc = new Array(xBuf.rank);
      for (let j = 0; j < originalLoc.length; j++) {
        originalLoc[j] = newLoc[j] % xBuf.shape[j];
      }
      const originalIndex = xBuf.locToIndex(originalLoc);
      result.values[i] = xBuf.values[originalIndex];
    }
    return result;
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/TopK_impl.js
  var comparePair = (a, b) => {
    const valueDiff = b.value - a.value;
    return valueDiff === 0 ? a.index - b.index : valueDiff;
  };
  function select(array2, k, left = 0, right = array2.length - 1) {
    while (right > left) {
      if (right - left > 600) {
        const n = right - left + 1;
        const i2 = k - left + 1;
        const z = Math.log(n);
        const s = 0.5 * Math.exp(2 * z / 3);
        const sd = 0.5 * Math.sqrt(z * s * (n - s) / n) * Math.sign(i2 - n / 2);
        const newLeft = Math.max(left, Math.floor(k - i2 * s / n + sd));
        const newRight = Math.min(right, Math.floor(k + (n - i2) * s / n + sd));
        select(array2, k, newLeft, newRight);
      }
      const t = array2[k];
      let i = left;
      let j = right;
      util_exports.swap(array2, left, k);
      if (comparePair(array2[right], t) > 0) {
        util_exports.swap(array2, left, right);
      }
      while (i < j) {
        util_exports.swap(array2, i, j);
        i++;
        j--;
        while (comparePair(array2[i], t) < 0) {
          i = i + 1;
        }
        while (comparePair(array2[j], t) > 0) {
          j = j - 1;
        }
      }
      if (comparePair(array2[left], t) === 0) {
        util_exports.swap(array2, left, j);
      } else {
        j = j + 1;
        util_exports.swap(array2, j, right);
      }
      if (j <= k) {
        left = j + 1;
      }
      if (k <= j) {
        right = j - 1;
      }
    }
  }
  function topKImpl(x, xShape, xDtype, k, sorted) {
    const lastDim = xShape[xShape.length - 1];
    const [batch, size2] = [x.length / lastDim, lastDim];
    const allTopKVals = util_exports.getTypedArrayFromDType(xDtype, batch * k);
    const allTopKIndices = util_exports.getTypedArrayFromDType("int32", batch * k);
    for (let b = 0; b < batch; b++) {
      const offset = b * size2;
      const vals = x.subarray(offset, offset + size2);
      let valAndInd = new Array(vals.length);
      vals.forEach((value, index) => valAndInd[index] = { value, index });
      if (k < valAndInd.length) {
        select(valAndInd, k);
        valAndInd = valAndInd.slice(0, k);
      }
      if (sorted) {
        valAndInd.sort(comparePair);
      }
      const outOffset = b * k;
      const topKVals = allTopKVals.subarray(outOffset, outOffset + k);
      const topKIndices = allTopKIndices.subarray(outOffset, outOffset + k);
      for (let i = 0; i < k; i++) {
        topKVals[i] = valAndInd[i].value;
        topKIndices[i] = valAndInd[i].index;
      }
    }
    const outputShape = xShape.slice();
    outputShape[outputShape.length - 1] = k;
    return [
      buffer2(outputShape, xDtype, allTopKVals),
      buffer2(outputShape, "int32", allTopKIndices)
    ];
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Unique_impl.js
  function uniqueImpl(values, axis, shape, dtype) {
    const $axis = util_exports.parseAxisParam(axis, shape)[0];
    const newShape = [1, shape[0], 1];
    for (let i = 0; i < $axis; i++) {
      newShape[0] *= shape[i];
    }
    newShape[1] = shape[$axis];
    for (let i = $axis + 1; i < shape.length; i++) {
      newShape[2] *= shape[i];
    }
    const uniqueElements = {};
    const indices = new Int32Array(shape[$axis]);
    const inputBuffer = new TensorBuffer(newShape, dtype, values);
    const uniqueIndices = [];
    const is1DTensor = newShape[0] === 1 && newShape[2] === 1;
    for (let i = 0; i < shape[$axis]; i++) {
      let element;
      if (is1DTensor) {
        element = values[i].toString();
      } else {
        const axisValues = [];
        for (let m = 0; m < newShape[0]; m++) {
          for (let n = 0; n < newShape[2]; n++) {
            axisValues.push(inputBuffer.get(m, i, n));
          }
        }
        element = axisValues.join(",");
      }
      if (uniqueElements[element] !== void 0) {
        indices[i] = uniqueElements[element];
      } else {
        const uniqueIndex = Object.keys(uniqueElements).length;
        uniqueElements[element] = uniqueIndex;
        indices[i] = uniqueIndex;
        uniqueIndices.push(i);
      }
    }
    const outputTmpShape = newShape.slice();
    outputTmpShape[1] = Object.keys(uniqueElements).length;
    const outputBuffer = new TensorBuffer(outputTmpShape, dtype);
    uniqueIndices.forEach((uniqueElementIndex, i) => {
      for (let m = 0; m < newShape[0]; m++) {
        for (let n = 0; n < newShape[2]; n++) {
          outputBuffer.set(inputBuffer.get(m, uniqueElementIndex, n), m, i, n);
        }
      }
    });
    const outputShape = shape.slice();
    outputShape[$axis] = outputTmpShape[1];
    return {
      outputValues: outputBuffer.values,
      outputShape,
      indices
    };
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/base.js
  registerBackend("cpu", () => new MathBackendCPU(), 1);

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Elu.js
  var elu3 = unaryKernelFunc(Elu, (xi) => xi >= 0 ? xi : Math.exp(xi) - 1);
  var eluConfig = {
    kernelName: Elu,
    backendName: "cpu",
    kernelFunc: elu3
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LeakyRelu.js
  function leakyRelu2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { alpha } = attrs;
    assertNotComplex([x], "leakyRelu");
    const xSize = util_exports.sizeFromShape(x.shape);
    const xVals = backend2.data.get(x.dataId).values;
    const outVals = util_exports.getTypedArrayFromDType("float32", xSize);
    for (let i = 0; i < xVals.length; i++) {
      outVals[i] = xVals[i] < 0 ? alpha * xVals[i] : xVals[i];
    }
    return backend2.makeTensorInfo(x.shape, "float32", outVals);
  }
  var leakyReluConfig = {
    kernelName: LeakyRelu,
    backendName: "cpu",
    kernelFunc: leakyRelu2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Prelu.js
  var preluImpl = createSimpleBinaryKernelImpl((xValue, aValue) => xValue < 0 ? aValue * xValue : xValue);
  function prelu2(args) {
    const { inputs, backend: backend2 } = args;
    const { x, alpha } = inputs;
    assertNotComplex([x, alpha], "prelu");
    const aVals = backend2.data.get(x.dataId).values;
    const bVals = backend2.data.get(alpha.dataId).values;
    const [resultData, resultShape] = preluImpl(x.shape, alpha.shape, aVals, bVals, "float32");
    return backend2.makeTensorInfo(resultShape, "float32", resultData);
  }
  var preluConfig = {
    kernelName: Prelu,
    backendName: "cpu",
    kernelFunc: prelu2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Relu.js
  var relu2 = unaryKernelFunc(Relu, (xi) => Math.max(0, xi));
  var reluConfig = {
    kernelName: Relu,
    backendName: "cpu",
    kernelFunc: relu2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Relu6.js
  var relu62 = unaryKernelFunc(Relu6, (xi) => Math.min(Math.max(0, xi), 6));
  var relu6Config = {
    kernelName: Relu6,
    backendName: "cpu",
    kernelFunc: relu62
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/fused_utils.js
  function applyActivation2(backend2, x, activation, preluActivationWeights, leakyreluAlpha) {
    if (activation === "linear") {
      return identity({ inputs: { x }, backend: backend2 });
    } else if (activation === "relu") {
      return relu2({ inputs: { x }, backend: backend2 });
    } else if (activation === "elu") {
      return elu3({ inputs: { x }, backend: backend2 });
    } else if (activation === "relu6") {
      return relu62({ inputs: { x }, backend: backend2 });
    } else if (activation === "prelu") {
      return prelu2({ inputs: { x, alpha: preluActivationWeights }, backend: backend2 });
    } else if (activation === "leakyrelu") {
      return leakyRelu2({ inputs: { x }, backend: backend2, attrs: { alpha: leakyreluAlpha } });
    } else if (activation === "sigmoid") {
      return sigmoid2({ inputs: { x }, backend: backend2 });
    }
    throw new Error(`Activation ${activation} has not been implemented for the CPU backend.`);
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Reshape.js
  function reshape2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { shape } = attrs;
    const xSize = util_exports.sizeFromShape(x.shape);
    const $shape = util_exports.inferFromImplicitShape(shape, xSize);
    const $xSize = util_exports.sizeFromShape($shape);
    util_exports.assert(xSize === $xSize, () => `The new shape (${$shape}) has ${$xSize} elements and the old shape (${x.shape}) has ${xSize} elements. The new shape and old shape must have the same number of elements.`);
    backend2.incRef(x.dataId);
    const xData = backend2.data.get(x.dataId);
    if (xData.complexTensorInfos != null) {
      const real4 = xData.complexTensorInfos.real;
      const imag4 = xData.complexTensorInfos.imag;
      real4.shape = $shape;
      imag4.shape = $shape;
    }
    return { dataId: x.dataId, shape: $shape, dtype: x.dtype };
  }
  var reshapeConfig = {
    kernelName: Reshape,
    backendName: "cpu",
    kernelFunc: reshape2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/BatchMatMul.js
  function batchMatMul(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { a, b } = inputs;
    const { transposeA, transposeB } = attrs;
    assertNotComplex([a, b], "matMul");
    const aRank = a.shape.length;
    const bRank = b.shape.length;
    const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];
    const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];
    const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];
    const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];
    const outerDimsA = a.shape.slice(0, -2);
    const outerDimsB = b.shape.slice(0, -2);
    const batchDimA = util_exports.sizeFromShape(outerDimsA);
    const batchDimB = util_exports.sizeFromShape(outerDimsB);
    const batchDimsCompatible = batchDimA === batchDimB || batchDimA === 1 || batchDimB === 1;
    util_exports.assert(aRank >= 2 && bRank >= 2 && batchDimsCompatible, () => `Error in matMul: the input batch dimensions must either be the same or at least one input batch dimension must be 1. Got input batch dimensions of (${outerDimsA}) and (${outerDimsB}).`);
    const outShapeOuterDims = batchDimA > batchDimB ? a.shape.slice(0, -2) : b.shape.slice(0, -2);
    const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);
    util_exports.assert(innerShapeA === innerShapeB, () => `Error in matMul: inner shapes (${innerShapeA}) and (${innerShapeB}) of Tensors with shapes ${a.shape} and ${b.shape} and transposeA=${transposeA} and transposeB=${transposeB} must match.`);
    const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] : [batchDimA, outerShapeA, innerShapeA];
    const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] : [batchDimB, innerShapeB, outerShapeB];
    const a3d = reshape2({ inputs: { x: a }, backend: backend2, attrs: { shape: a3dShape } });
    const b3d = reshape2({ inputs: { x: b }, backend: backend2, attrs: { shape: b3dShape } });
    const sharedDim = transposeA ? a3d.shape[1] : a3d.shape[2];
    const leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];
    const rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];
    const batchDim = Math.max(batchDimA, batchDimB);
    const a3dValues = backend2.data.get(a3d.dataId).values;
    const b3dValues = backend2.data.get(b3d.dataId).values;
    const a3dStrides = util_exports.computeStrides(a3d.shape);
    const b3dStrides = util_exports.computeStrides(b3d.shape);
    const [aBatch, aOuterStep, aInnerStep] = transposeA ? [a3dStrides[0], 1, a3dStrides[1]] : [a3dStrides[0], a3dStrides[1], 1];
    const [bInnerStep, bOuterStep, bBatch] = transposeB ? [1, b3dStrides[1], b3dStrides[0]] : [b3dStrides[1], 1, b3dStrides[0]];
    const size2 = leftDim * rightDim;
    const result = buffer2([batchDim, leftDim, rightDim], a3d.dtype);
    const resVals = result.values;
    const blockSize = backend2.blockSize;
    for (let bi = 0; bi < batchDim; bi++) {
      for (let i0 = 0; i0 < leftDim; i0 += blockSize) {
        for (let j0 = 0; j0 < rightDim; j0 += blockSize) {
          for (let k02 = 0; k02 < sharedDim; k02 += blockSize) {
            const iBlock = Math.min(i0 + blockSize, leftDim);
            const jBlock = Math.min(j0 + blockSize, rightDim);
            const kBlock = Math.min(k02 + blockSize, sharedDim);
            for (let i = i0; i < iBlock; i++) {
              for (let j = j0; j < jBlock; j++) {
                let sum5 = 0;
                for (let k = k02; k < kBlock; k++) {
                  const batchOffsetA = Math.min(bi, batchDimA - 1) * aBatch;
                  const batchOffsetB = Math.min(bi, batchDimB - 1) * bBatch;
                  const aVal = a3dValues[batchOffsetA + i * aOuterStep + k * aInnerStep];
                  const bVal = b3dValues[k * bInnerStep + j * bOuterStep + batchOffsetB];
                  sum5 += aVal * bVal;
                }
                resVals[bi * size2 + (i * rightDim + j)] += sum5;
              }
            }
          }
        }
      }
    }
    backend2.disposeIntermediateTensorInfo(a3d);
    backend2.disposeIntermediateTensorInfo(b3d);
    return backend2.makeTensorInfo(outShape, result.dtype, result.values);
  }
  var batchMatMulConfig = {
    kernelName: BatchMatMul,
    backendName: "cpu",
    kernelFunc: batchMatMul
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/_FusedMatMul.js
  function _fusedMatMul(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { a, b, bias, preluActivationWeights } = inputs;
    const { transposeA, transposeB, activation, leakyreluAlpha } = attrs;
    let current;
    let addRes;
    let activationRes;
    const intermediates = [];
    const matMulRes = batchMatMul({ inputs: { a, b }, attrs: { transposeA, transposeB }, backend: backend2 });
    current = matMulRes;
    if (bias) {
      addRes = add4({ inputs: { a: current, b: bias }, backend: backend2 });
      intermediates.push(current);
      current = addRes;
    }
    if (activation) {
      activationRes = applyActivation2(backend2, current, activation, preluActivationWeights, leakyreluAlpha);
      intermediates.push(current);
      current = activationRes;
    }
    for (const i of intermediates) {
      backend2.disposeIntermediateTensorInfo(i);
    }
    return current;
  }
  var _fusedMatMulConfig = {
    kernelName: _FusedMatMul,
    backendName: "cpu",
    kernelFunc: _fusedMatMul
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Acos.js
  var acos2 = unaryKernelFunc(Acos, (xi) => Math.acos(xi));
  var acosConfig = {
    kernelName: Acos,
    backendName: "cpu",
    kernelFunc: acos2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Acosh.js
  var acosh2 = unaryKernelFunc(Acosh, (xi) => Math.acosh(xi));
  var acoshConfig = {
    kernelName: Acosh,
    backendName: "cpu",
    kernelFunc: acosh2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/AddN.js
  function addN(args) {
    const { inputs, backend: backend2 } = args;
    const tensors = inputs;
    assertNotComplex(inputs, "addN");
    const vals = tensors.map((t) => backend2.data.get(t.dataId).values);
    const outBuf = buffer2(tensors[0].shape, tensors[0].dtype);
    const outVals = outBuf.values;
    for (let i = 0; i < tensors.length; i++) {
      const currVals = vals[i];
      for (let j = 0; j < outVals.length; j++) {
        outVals[j] += currVals[j];
      }
    }
    return backend2.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
  }
  var addNConfig = {
    kernelName: AddN,
    backendName: "cpu",
    kernelFunc: addN
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/All.js
  function all2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { axis, keepDims } = attrs;
    assertNotComplex(x, "all");
    const origAxes = util_exports.parseAxisParam(axis, x.shape);
    let axes = origAxes;
    const permutedAxes = backend_util_exports.getAxesPermutation(axes, x.shape.length);
    let $x = x;
    if (permutedAxes != null) {
      $x = transpose2({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
      axes = backend_util_exports.getInnerMostAxes(axes.length, x.shape.length);
    }
    backend_util_exports.assertAxesAreInnerMostDims("all", axes, $x.shape.length);
    const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes($x.shape, axes);
    const reduceSize = util_exports.sizeFromShape(reduceShape);
    const vals = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(outShape), $x.dtype);
    const aVals = backend2.data.get($x.dataId).values;
    for (let i = 0; i < vals.length; ++i) {
      const offset = i * reduceSize;
      let all4 = aVals[offset];
      for (let j = 0; j < reduceSize; ++j) {
        const value = aVals[offset + j];
        all4 = all4 && value;
      }
      vals[i] = all4;
    }
    if (permutedAxes != null) {
      backend2.disposeIntermediateTensorInfo($x);
    }
    const result = backend2.makeTensorInfo(outShape, $x.dtype, vals);
    if (keepDims) {
      const expandedShape = backend_util_exports.expandShapeToKeepDim(outShape, origAxes);
      const reshapedResult = reshape2({ inputs: { x: result }, backend: backend2, attrs: { shape: expandedShape } });
      backend2.disposeIntermediateTensorInfo(result);
      return reshapedResult;
    }
    return result;
  }
  var allConfig = {
    kernelName: All,
    backendName: "cpu",
    kernelFunc: all2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Any.js
  function any2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { axis, keepDims } = attrs;
    assertNotComplex(x, "any");
    const origAxes = util_exports.parseAxisParam(axis, x.shape);
    let axes = origAxes;
    const permutedAxes = backend_util_exports.getAxesPermutation(axes, x.shape.length);
    let $x = x;
    if (permutedAxes != null) {
      $x = transpose2({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
      axes = backend_util_exports.getInnerMostAxes(axes.length, x.shape.length);
    }
    backend_util_exports.assertAxesAreInnerMostDims("any", axes, $x.shape.length);
    const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes($x.shape, axes);
    const reduceSize = util_exports.sizeFromShape(reduceShape);
    const vals = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(outShape), $x.dtype);
    const aVals = backend2.data.get($x.dataId).values;
    for (let i = 0; i < vals.length; ++i) {
      const offset = i * reduceSize;
      let anyVal = aVals[offset];
      for (let j = 0; j < reduceSize; ++j) {
        const value = aVals[offset + j];
        anyVal = anyVal || value;
      }
      vals[i] = anyVal;
    }
    if (permutedAxes != null) {
      backend2.disposeIntermediateTensorInfo($x);
    }
    const result = backend2.makeTensorInfo(outShape, $x.dtype, vals);
    if (keepDims) {
      const expandedShape = backend_util_exports.expandShapeToKeepDim(outShape, origAxes);
      const reshapedResult = reshape2({ inputs: { x: result }, backend: backend2, attrs: { shape: expandedShape } });
      backend2.disposeIntermediateTensorInfo(result);
      return reshapedResult;
    }
    return result;
  }
  var anyConfig = {
    kernelName: Any,
    backendName: "cpu",
    kernelFunc: any2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ArgMax.js
  function argMax2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { axis } = attrs;
    assertNotComplex(x, "argMax");
    let axes = util_exports.parseAxisParam(axis, x.shape);
    const permutedAxes = backend_util_exports.getAxesPermutation(axes, x.shape.length);
    let $x = x;
    const intermediateTensorInfos = [];
    if (permutedAxes != null) {
      $x = transpose2({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
      intermediateTensorInfos.push($x);
      axes = backend_util_exports.getInnerMostAxes(axes.length, $x.shape.length);
    }
    axes = [axes[0]];
    backend_util_exports.assertAxesAreInnerMostDims("argMax", axes, $x.shape.length);
    const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes($x.shape, axes);
    const outSize = util_exports.sizeFromShape(outShape);
    const vals = util_exports.makeZerosTypedArray(outSize, "int32");
    const reduceSize = util_exports.sizeFromShape(reduceShape);
    const aVals = backend2.data.get($x.dataId).values;
    for (let i = 0; i < vals.length; ++i) {
      const offset = i * reduceSize;
      let max5 = aVals[offset];
      let maxIndex = 0;
      for (let j = 0; j < reduceSize; ++j) {
        const value = aVals[offset + j];
        if (value > max5) {
          max5 = value;
          maxIndex = j;
        }
      }
      vals[i] = maxIndex;
    }
    intermediateTensorInfos.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
    return backend2.makeTensorInfo(outShape, "int32", vals);
  }
  var argMaxConfig = {
    kernelName: ArgMax,
    backendName: "cpu",
    kernelFunc: argMax2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ArgMin.js
  function argMin2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { axis } = attrs;
    assertNotComplex(x, "argMin");
    let axes = util_exports.parseAxisParam(axis, x.shape);
    const permutedAxes = backend_util_exports.getAxesPermutation(axes, x.shape.length);
    let $x = x;
    const intermediateTensorInfos = [];
    if (permutedAxes != null) {
      $x = transpose2({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
      intermediateTensorInfos.push($x);
      axes = backend_util_exports.getInnerMostAxes(axes.length, $x.shape.length);
    }
    axes = [axes[0]];
    backend_util_exports.assertAxesAreInnerMostDims("argMin", axes, $x.shape.length);
    const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes($x.shape, axes);
    const outSize = util_exports.sizeFromShape(outShape);
    const vals = util_exports.makeZerosTypedArray(outSize, "int32");
    const reduceSize = util_exports.sizeFromShape(reduceShape);
    const aVals = backend2.data.get($x.dataId).values;
    for (let i = 0; i < vals.length; ++i) {
      const offset = i * reduceSize;
      let min5 = aVals[offset];
      let minIndex = 0;
      for (let j = 0; j < reduceSize; ++j) {
        const value = aVals[offset + j];
        if (value < min5) {
          min5 = value;
          minIndex = j;
        }
      }
      vals[i] = minIndex;
    }
    intermediateTensorInfos.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
    return backend2.makeTensorInfo(outShape, "int32", vals);
  }
  var argMinConfig = {
    kernelName: ArgMin,
    backendName: "cpu",
    kernelFunc: argMin2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Asin.js
  var asin2 = unaryKernelFunc(Asin, (xi) => Math.asin(xi));
  var asinConfig = {
    kernelName: Asin,
    backendName: "cpu",
    kernelFunc: asin2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Asinh.js
  var asinh2 = unaryKernelFunc(Asinh, (xi) => Math.asinh(xi));
  var asinhConfig = {
    kernelName: Asinh,
    backendName: "cpu",
    kernelFunc: asinh2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Atan.js
  var atan3 = unaryKernelFunc(Atan, (xi) => Math.atan(xi));
  var atanConfig = {
    kernelName: Atan,
    backendName: "cpu",
    kernelFunc: atan3
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Atan2.js
  var atan2Impl = createSimpleBinaryKernelImpl((aValue, bValue) => Math.atan2(aValue, bValue));
  var atan22 = binaryKernelFunc(Atan2, atan2Impl);
  var atan2Config = {
    kernelName: Atan2,
    backendName: "cpu",
    kernelFunc: atan22
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Atanh.js
  var atanh2 = unaryKernelFunc(Atanh, (xi) => Math.atanh(xi));
  var atanhConfig = {
    kernelName: Atanh,
    backendName: "cpu",
    kernelFunc: atanh2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/pool_utils.js
  function pool2(xValues, xShape, dtype, strides, convInfo, poolType) {
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padTop = convInfo.padInfo.top;
    const padLeft = convInfo.padInfo.left;
    const initialValue = poolType === "max" ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY;
    const output = buffer2(convInfo.outShape, dtype);
    const outputVals = output.values;
    const outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] * convInfo.outShape[3];
    const outputRowStrides = convInfo.outShape[2] * convInfo.outShape[3];
    const outputColStrides = convInfo.outShape[3];
    for (let b = 0; b < convInfo.batchSize; ++b) {
      const outputBatchOffset = b * outputBatchStrides;
      const inputBatchOffset = b * strides[0];
      for (let d = 0; d < convInfo.inChannels; ++d) {
        for (let yR = 0; yR < convInfo.outHeight; ++yR) {
          const xRCorner = yR * strideHeight - padTop;
          const xRMin = Math.max(0, xRCorner);
          const xRMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);
          const outputRowOffset = outputBatchOffset + yR * outputRowStrides;
          for (let yC = 0; yC < convInfo.outWidth; ++yC) {
            const xCCorner = yC * strideWidth - padLeft;
            const xCMin = Math.max(0, xCCorner);
            const xCMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);
            let minMaxValue = initialValue;
            let avgValue = 0;
            let count2 = 0;
            for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {
              const xROffset = inputBatchOffset + xR * strides[1];
              for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {
                const xCOffset = xROffset + xC * strides[2];
                const pixel = xValues[xCOffset + d];
                if (poolType === "max" && pixel > minMaxValue) {
                  minMaxValue = pixel;
                } else if (poolType === "avg") {
                  avgValue += pixel;
                  count2++;
                }
              }
              if (isNaN(minMaxValue)) {
                break;
              }
            }
            const outputOffset = outputRowOffset + yC * outputColStrides + d;
            outputVals[outputOffset] = poolType === "avg" ? avgValue / count2 : minMaxValue;
          }
        }
      }
    }
    return output;
  }
  function maxPoolPositions(xValues, xShape, dtype, convInfo, flattenPositions = false, includeBatchInIndex = false) {
    const maxPositions = buffer2(convInfo.outShape, "int32");
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padTop = convInfo.padInfo.top;
    const padLeft = convInfo.padInfo.left;
    const xBuf = buffer2(xShape, dtype, xValues);
    for (let b = 0; b < convInfo.batchSize; ++b) {
      for (let d = 0; d < convInfo.inChannels; ++d) {
        for (let yR = 0; yR < convInfo.outHeight; ++yR) {
          const xRCorner = yR * strideHeight - padTop;
          let xRMin = xRCorner;
          while (xRMin < 0) {
            xRMin += dilationHeight;
          }
          const xRMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);
          for (let yC = 0; yC < convInfo.outWidth; ++yC) {
            const xCCorner = yC * strideWidth - padLeft;
            let xCMin = xCCorner;
            while (xCMin < 0) {
              xCMin += dilationWidth;
            }
            const xCMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);
            let maxValue = Number.NEGATIVE_INFINITY;
            let maxPosition = -1;
            for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {
              const wR = xR - xRCorner;
              for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {
                const wC = xC - xCCorner;
                const pixel = xBuf.get(b, xR, xC, d);
                if (pixel > maxValue) {
                  maxValue = pixel;
                  if (flattenPositions) {
                    maxPosition = includeBatchInIndex ? ((b * convInfo.inHeight + xR) * convInfo.inWidth + xC) * convInfo.inChannels + d : (xR * convInfo.inWidth + xC) * convInfo.inChannels + d;
                  } else {
                    maxPosition = wR * effectiveFilterWidth + wC;
                  }
                }
              }
            }
            maxPositions.set(maxPosition, b, yR, yC, d);
          }
        }
      }
    }
    return maxPositions;
  }
  function pool3d2(xValues, xShape, dtype, strides, convInfo, poolType) {
    const strideDepth = convInfo.strideDepth;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationDepth = convInfo.dilationDepth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const effectiveFilterDepth = convInfo.effectiveFilterDepth;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padFront = convInfo.padInfo.front;
    const padTop = convInfo.padInfo.top;
    const padLeft = convInfo.padInfo.left;
    const initialValue = poolType === "max" ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY;
    const output = buffer2(convInfo.outShape, dtype);
    const outputVals = output.values;
    const outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] * convInfo.outShape[3] * convInfo.outShape[4];
    const outputDepthStrides = convInfo.outShape[2] * convInfo.outShape[3] * convInfo.outShape[4];
    const outputRowStrides = convInfo.outShape[3] * convInfo.outShape[4];
    const outputColStrides = convInfo.outShape[4];
    for (let batch = 0; batch < convInfo.batchSize; ++batch) {
      const outputBatchOffset = batch * outputBatchStrides;
      const inputBatchOffset = batch * strides[0];
      for (let channel = 0; channel < convInfo.inChannels; ++channel) {
        for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {
          const xDepthCorner = yDepth * strideDepth - padFront;
          let xDepthMin = xDepthCorner;
          while (xDepthMin < 0) {
            xDepthMin += dilationDepth;
          }
          const xDepthMax = Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);
          const outputDepthOffset = outputBatchOffset + yDepth * outputDepthStrides;
          for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {
            const xRowCorner = yRow * strideHeight - padTop;
            let xRowMin = xRowCorner;
            while (xRowMin < 0) {
              xRowMin += dilationHeight;
            }
            const xRowMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);
            const outputRowOffset = outputDepthOffset + yRow * outputRowStrides;
            for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {
              const xColCorner = yCol * strideWidth - padLeft;
              let xColMin = xColCorner;
              while (xColMin < 0) {
                xColMin += dilationWidth;
              }
              const xColMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);
              const outputColOffset = outputRowOffset + yCol * outputColStrides;
              let minMaxValue = initialValue;
              let avgValue = 0;
              let count2 = 0;
              for (let xDepth = xDepthMin; xDepth < xDepthMax; xDepth += dilationDepth) {
                const xDepthOffset = inputBatchOffset + xDepth * strides[1];
                for (let xRow = xRowMin; xRow < xRowMax; xRow += dilationHeight) {
                  const xRowOffset = xDepthOffset + xRow * strides[2];
                  for (let xCol = xColMin; xCol < xColMax; xCol += dilationWidth) {
                    const xColOffset = xRowOffset + xCol * strides[3];
                    const pixel = xValues[xColOffset + channel];
                    if (poolType === "max" && pixel > minMaxValue) {
                      minMaxValue = pixel;
                    } else if (poolType === "avg") {
                      avgValue += pixel;
                      count2++;
                    }
                    if (isNaN(minMaxValue)) {
                      break;
                    }
                  }
                  if (isNaN(minMaxValue)) {
                    break;
                  }
                }
                if (isNaN(minMaxValue)) {
                  break;
                }
              }
              const outputOffset = outputColOffset + channel;
              outputVals[outputOffset] = poolType === "avg" ? avgValue / count2 : minMaxValue;
            }
          }
        }
      }
    }
    return output;
  }
  function maxPool3dPositions(xBuf, convInfo) {
    const maxPositions = buffer2(convInfo.outShape, "int32");
    const strideDepth = convInfo.strideDepth;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationDepth = convInfo.dilationDepth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const effectiveFilterDepth = convInfo.effectiveFilterDepth;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padFront = convInfo.padInfo.front;
    const padTop = convInfo.padInfo.top;
    const padLeft = convInfo.padInfo.left;
    for (let batch = 0; batch < convInfo.batchSize; ++batch) {
      for (let channel = 0; channel < convInfo.inChannels; ++channel) {
        for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {
          const xDepthCorner = yDepth * strideDepth - padFront;
          let xDepthMin = xDepthCorner;
          while (xDepthMin < 0) {
            xDepthMin += dilationDepth;
          }
          const xDepthMax = Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);
          for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {
            const xRowCorner = yRow * strideHeight - padTop;
            let xRowMin = xRowCorner;
            while (xRowMin < 0) {
              xRowMin += dilationHeight;
            }
            const xRowMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);
            for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {
              const xColCorner = yCol * strideWidth - padLeft;
              let xColMin = xColCorner;
              while (xColMin < 0) {
                xColMin += dilationWidth;
              }
              const xColMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);
              let maxValue = Number.NEGATIVE_INFINITY;
              let maxPosition = -1;
              for (let xDepth = xDepthMin; xDepth < xDepthMax; xDepth += dilationDepth) {
                const wDepth = xDepth - xDepthCorner;
                for (let xRow = xRowMin; xRow < xRowMax; xRow += dilationHeight) {
                  const wRow = xRow - xRowCorner;
                  for (let xCol = xColMin; xCol < xColMax; xCol += dilationWidth) {
                    const wCol = xCol - xColCorner;
                    const pixel = xBuf.get(batch, xDepth, xRow, xCol, channel);
                    if (pixel >= maxValue) {
                      maxValue = pixel;
                      maxPosition = wDepth * effectiveFilterHeight * effectiveFilterWidth + wRow * effectiveFilterHeight + wCol;
                    }
                  }
                }
              }
              maxPositions.set(maxPosition, batch, yDepth, yRow, yCol, channel);
            }
          }
        }
      }
    }
    return maxPositions;
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPool.js
  function avgPool2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    assertNotComplex(x, "avgPool");
    const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
    const dilations = 1;
    util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
    const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode);
    let res;
    if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 && util_exports.arraysEqual(convInfo.inShape, convInfo.outShape)) {
      res = identity({ inputs: { x }, backend: backend2 });
    } else {
      const xValues = backend2.data.get(x.dataId).values;
      const strides2 = util_exports.computeStrides(x.shape);
      const buffer3 = pool2(xValues, x.shape, x.dtype, strides2, convInfo, "avg");
      res = backend2.makeTensorInfo(convInfo.outShape, x.dtype, buffer3.values);
    }
    return res;
  }
  var avgPoolConfig = {
    kernelName: AvgPool,
    backendName: "cpu",
    kernelFunc: avgPool2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPool3D.js
  function avgPool3D(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat } = attrs;
    assertNotComplex(x, "avgPool3d");
    const convInfo = backend_util_exports.computePool3DInfo(x.shape, filterSize, strides, 1, pad2, dimRoundingMode, dataFormat);
    const xValues = backend2.data.get(x.dataId).values;
    const outBuf = pool3d2(xValues, x.shape, x.dtype, util_exports.computeStrides(x.shape), convInfo, "avg");
    return backend2.makeTensorInfo(outBuf.shape, "float32", outBuf.values);
  }
  var avgPool3DConfig = {
    kernelName: AvgPool3D,
    backendName: "cpu",
    kernelFunc: avgPool3D
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPool3DGrad.js
  function avgPool3DGrad(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { dy, input: input2 } = inputs;
    const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
    assertNotComplex([dy, input2], "avgPool3DGrad");
    const convInfo = backend_util_exports.computePool3DInfo(input2.shape, filterSize, strides, 1, pad2, dimRoundingMode);
    const strideDepth = convInfo.strideDepth;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const filterDepth = convInfo.filterDepth;
    const filterHeight = convInfo.filterHeight;
    const filterWidth = convInfo.filterWidth;
    const dilationDepth = convInfo.dilationDepth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const effectiveFilterDepth = convInfo.effectiveFilterDepth;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;
    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
    const dx = buffer2(input2.shape, "float32");
    const avgMultiplier = 1 / (filterDepth * filterHeight * filterWidth);
    const dyBuf = backend2.bufferSync(dy);
    for (let batch = 0; batch < convInfo.batchSize; ++batch) {
      for (let channel = 0; channel < convInfo.inChannels; ++channel) {
        for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {
          for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {
            for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {
              const dyDepthCorner = dxDepth - padFront;
              const dyRowCorner = dxRow - padTop;
              const dyColCorner = dxCol - padLeft;
              let dotProd = 0;
              for (let wDepth = 0; wDepth < effectiveFilterDepth; wDepth += dilationDepth) {
                const dyDepth = (dyDepthCorner + wDepth) / strideDepth;
                if (dyDepth < 0 || dyDepth >= convInfo.outDepth || Math.floor(dyDepth) !== dyDepth) {
                  continue;
                }
                for (let wRow = 0; wRow < effectiveFilterHeight; wRow += dilationHeight) {
                  const dyRow = (dyRowCorner + wRow) / strideHeight;
                  if (dyRow < 0 || dyRow >= convInfo.outHeight || Math.floor(dyRow) !== dyRow) {
                    continue;
                  }
                  for (let wCol = 0; wCol < effectiveFilterWidth; wCol += dilationWidth) {
                    const dyCol = (dyColCorner + wCol) / strideWidth;
                    if (dyCol < 0 || dyCol >= convInfo.outWidth || Math.floor(dyCol) !== dyCol) {
                      continue;
                    }
                    const pixel = dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);
                    dotProd += pixel;
                  }
                }
              }
              dx.set(dotProd * avgMultiplier, batch, dxDepth, dxRow, dxCol, channel);
            }
          }
        }
      }
    }
    return backend2.makeTensorInfo(dx.shape, dx.dtype, dx.values);
  }
  var avgPool3DGradConfig2 = {
    kernelName: AvgPool3DGrad,
    backendName: "cpu",
    kernelFunc: avgPool3DGrad
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPoolGrad.js
  function avgPoolGrad2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { dy, input: input2 } = inputs;
    const x = input2;
    assertNotComplex([dy, input2], "avgPoolGrad");
    const { filterSize, strides, pad: pad2 } = attrs;
    const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, 1, pad2);
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const filterHeight = convInfo.filterHeight;
    const filterWidth = convInfo.filterWidth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
    const dx = buffer2(x.shape, "float32");
    const avgMultiplier = 1 / (filterHeight * filterWidth);
    const dyData = backend2.data.get(dy.dataId).values;
    const dyBuf = buffer2(dy.shape, "float32", dyData);
    for (let b = 0; b < convInfo.batchSize; ++b) {
      for (let d = 0; d < convInfo.inChannels; ++d) {
        for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {
          for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {
            const dyRCorner = dxR - padTop;
            const dyCCorner = dxC - padLeft;
            let dotProd = 0;
            for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {
              const dyR = (dyRCorner + wR) / strideHeight;
              if (dyR < 0 || dyR >= convInfo.outHeight || Math.floor(dyR) !== dyR) {
                continue;
              }
              for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {
                const dyC = (dyCCorner + wC) / strideWidth;
                if (dyC < 0 || dyC >= convInfo.outWidth || Math.floor(dyC) !== dyC) {
                  continue;
                }
                const pixel = dyBuf.get(b, dyR, dyC, d);
                dotProd += pixel;
              }
            }
            dx.set(dotProd * avgMultiplier, b, dxR, dxC, d);
          }
        }
      }
    }
    return backend2.makeTensorInfo(dx.shape, dx.dtype, dx.values);
  }
  var avgPoolGradConfig2 = {
    kernelName: AvgPoolGrad,
    backendName: "cpu",
    kernelFunc: avgPoolGrad2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/BatchNorm.js
  function batchNorm2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, scale: scale2, offset, mean: mean3, variance } = inputs;
    util_exports.assert(mean3.shape.length === variance.shape.length, () => "Batch normalization gradient requires mean and variance to have equal ranks.");
    util_exports.assert(offset == null || mean3.shape.length === offset.shape.length, () => "Batch normalization gradient requires mean and offset to have equal ranks.");
    util_exports.assert(scale2 == null || mean3.shape.length === scale2.shape.length, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
    assertNotComplex([x, mean3, variance, scale2, offset], "batchNorm");
    let { varianceEpsilon } = attrs;
    if (varianceEpsilon == null) {
      varianceEpsilon = 1e-3;
    }
    const xVals = backend2.data.get(x.dataId).values;
    const mVals = backend2.data.get(mean3.dataId).values;
    const varVals = backend2.data.get(variance.dataId).values;
    const sVals = scale2 ? backend2.data.get(scale2.dataId).values : new Float32Array([1]);
    const offVals = offset ? backend2.data.get(offset.dataId).values : new Float32Array([0]);
    const outVals = new Float32Array(xVals.length);
    const offValsLength = offVals.length;
    const sValsLength = sVals.length;
    const varValsLength = varVals.length;
    const mValsLength = mVals.length;
    let offi = 0;
    let mi = 0;
    let si = 0;
    let vi = 0;
    for (let i = 0; i < xVals.length; ++i) {
      outVals[i] = offVals[offi++] + (xVals[i] - mVals[mi++]) * sVals[si++] / Math.sqrt(varVals[vi++] + varianceEpsilon);
      if (offi >= offValsLength) {
        offi = 0;
      }
      if (mi >= mValsLength) {
        mi = 0;
      }
      if (si >= sValsLength) {
        si = 0;
      }
      if (vi >= varValsLength) {
        vi = 0;
      }
    }
    return backend2.makeTensorInfo(x.shape, x.dtype, outVals);
  }
  var batchNormConfig = {
    kernelName: FusedBatchNorm,
    backendName: "cpu",
    kernelFunc: batchNorm2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/BatchToSpaceND.js
  function batchToSpaceND2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { blockShape, crops } = attrs;
    assertNotComplex([x], "batchToSpaceND");
    const prod4 = blockShape.reduce((a, b) => a * b);
    const reshaped = backend_util_exports.getReshaped(x.shape, blockShape, prod4);
    const permuted = backend_util_exports.getPermuted(reshaped.length, blockShape.length);
    const reshapedPermuted = backend_util_exports.getReshapedPermuted(x.shape, blockShape, prod4);
    const sliceBeginCoords = backend_util_exports.getSliceBeginCoords(crops, blockShape.length);
    const sliceSize = backend_util_exports.getSliceSize(reshapedPermuted, crops, blockShape.length);
    const xReshaped = reshape2({ inputs: { x }, backend: backend2, attrs: { shape: reshaped } });
    const xTransposed = transpose2({ inputs: { x: xReshaped }, backend: backend2, attrs: { perm: permuted } });
    const xTransposedReshaped = reshape2({ inputs: { x: xTransposed }, backend: backend2, attrs: { shape: reshapedPermuted } });
    const result = slice2({
      inputs: { x: xTransposedReshaped },
      backend: backend2,
      attrs: { begin: sliceBeginCoords, size: sliceSize }
    });
    backend2.disposeIntermediateTensorInfo(xReshaped);
    backend2.disposeIntermediateTensorInfo(xTransposed);
    backend2.disposeIntermediateTensorInfo(xTransposedReshaped);
    return result;
  }
  var batchToSpaceNDConfig = {
    kernelName: BatchToSpaceND,
    backendName: "cpu",
    kernelFunc: batchToSpaceND2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Bincount.js
  function bincount2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, weights } = inputs;
    const { size: size2 } = attrs;
    const xVals = backend2.data.get(x.dataId).values;
    const weightsVals = backend2.data.get(weights.dataId).values;
    const outVals = bincountImpl(xVals, weightsVals, weights.dtype, weights.shape, size2);
    return backend2.makeTensorInfo([size2], weights.dtype, outVals);
  }
  var bincountConfig = {
    kernelName: Bincount,
    backendName: "cpu",
    kernelFunc: bincount2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/BroadcastArgs.js
  function broadcastArgs(args) {
    const { inputs, backend: backend2 } = args;
    const { s0, s1 } = inputs;
    const s0Vals = backend2.data.get(s0.dataId).values;
    const s1Vals = backend2.data.get(s1.dataId).values;
    const broadcastShape = backend_util_exports.assertAndGetBroadcastShape(Array.from(s0Vals), Array.from(s1Vals));
    return backend2.makeTensorInfo([broadcastShape.length], "int32", Int32Array.from(broadcastShape));
  }
  var broadcastArgsConfig = {
    kernelName: BroadcastArgs,
    backendName: "cpu",
    kernelFunc: broadcastArgs
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Clip.js
  var clip = unaryKernelFunc(ClipByValue, (xi, attrs) => {
    const clipAttrs = attrs;
    if (xi > clipAttrs.clipValueMax) {
      return clipAttrs.clipValueMax;
    }
    return xi < clipAttrs.clipValueMin ? clipAttrs.clipValueMin : xi;
  });
  var clipConfig = {
    kernelName: ClipByValue,
    backendName: "cpu",
    kernelFunc: clip
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ComplexAbs.js
  var complexAbs = (args) => {
    const { x } = args.inputs;
    const cpuBackend = args.backend;
    const resultValues = new Float32Array(util_exports.sizeFromShape(x.shape));
    const complexVals = cpuBackend.data.get(x.dataId);
    const real4 = complexVals.complexTensorInfos.real;
    const imag4 = complexVals.complexTensorInfos.imag;
    const realVals = cpuBackend.data.get(real4.dataId).values;
    const imagVals = cpuBackend.data.get(imag4.dataId).values;
    for (let i = 0; i < realVals.length; i++) {
      const real5 = realVals[i];
      const imag5 = imagVals[i];
      resultValues[i] = Math.hypot(real5, imag5);
    }
    return cpuBackend.makeOutput(resultValues, x.shape, "float32");
  };
  var complexAbsConfig = {
    kernelName: ComplexAbs,
    backendName: "cpu",
    kernelFunc: complexAbs
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Imag.js
  function imag2(args) {
    const { inputs, backend: backend2 } = args;
    const { input: input2 } = inputs;
    const imag4 = backend2.data.get(input2.dataId).complexTensorInfos.imag;
    const imagVal = backend2.data.get(imag4.dataId).values;
    return backend2.makeTensorInfo(imag4.shape, imag4.dtype, imagVal);
  }
  var imagConfig = {
    kernelName: Imag,
    backendName: "cpu",
    kernelFunc: imag2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Concat.js
  function concat2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { axis } = attrs;
    const $axis = util_exports.parseAxisParam(axis, inputs[0].shape)[0];
    let outShape = backend_util_exports.computeOutShape(inputs.map((t) => t.shape), $axis);
    if (util_exports.sizeFromShape(outShape) === 0) {
      return backend2.makeTensorInfo(outShape, inputs[0].dtype, []);
    }
    const $inputs = inputs.filter((t) => util_exports.sizeFromShape(t.shape) > 0);
    if ($inputs.length === 1) {
      return identity({ inputs: { x: $inputs[0] }, backend: backend2 });
    }
    const shapes = $inputs.map((t) => t.shape);
    backend_util_exports.assertParamsConsistent(shapes, $axis);
    if ($inputs[0].dtype === "complex64") {
      const reals = $inputs.map((t) => real2({ inputs: { input: t }, backend: backend2 }));
      const imags = $inputs.map((t) => imag2({ inputs: { input: t }, backend: backend2 }));
      const realConcated = concat2({ inputs: reals, backend: backend2, attrs: { axis: $axis } });
      const imagConcated = concat2({ inputs: imags, backend: backend2, attrs: { axis: $axis } });
      const result = complex2({ inputs: { real: realConcated, imag: imagConcated }, backend: backend2 });
      reals.forEach((r) => backend2.disposeIntermediateTensorInfo(r));
      imags.forEach((i) => backend2.disposeIntermediateTensorInfo(i));
      backend2.disposeIntermediateTensorInfo(realConcated);
      backend2.disposeIntermediateTensorInfo(imagConcated);
      return result;
    }
    const inputs2D = $inputs.map((t) => {
      const innerSize = util_exports.sizeFromShape(t.shape.slice($axis));
      const shape = [-1, innerSize];
      return reshape2({ inputs: { x: t }, backend: backend2, attrs: { shape } });
    });
    const inputsValShapes = inputs2D.map((t) => {
      return { vals: backend2.data.get(t.dataId).values, shape: t.shape };
    });
    outShape = backend_util_exports.computeOutShape(inputs2D.map((t) => t.shape), 1);
    const simplyConcat = inputs2D[0].shape[0] === 1;
    const outVals = concatImpl(inputsValShapes, outShape, inputs[0].dtype, simplyConcat);
    const finalOutShape = backend_util_exports.computeOutShape($inputs.map((t) => t.shape), $axis);
    const outInfo = backend2.makeTensorInfo(finalOutShape, inputs[0].dtype, outVals);
    inputs2D.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
    return outInfo;
  }
  var concatConfig = {
    kernelName: Concat,
    backendName: "cpu",
    kernelFunc: concat2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv2D.js
  function conv2D(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, filter } = inputs;
    const { strides, pad: pad2, dataFormat, dilations, dimRoundingMode } = attrs;
    assertNotComplex([x, filter], "conv2d");
    const $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
    const convInfo = backend_util_exports.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad2, dimRoundingMode, false, $dataFormat);
    const filterHeight = convInfo.filterHeight;
    const filterWidth = convInfo.filterWidth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const padLeft = convInfo.padInfo.left;
    const padTop = convInfo.padInfo.top;
    const isChannelsLast = convInfo.dataFormat === "channelsLast";
    const y = new TensorBuffer(convInfo.outShape, x.dtype);
    const xStrides = util_exports.computeStrides(x.shape);
    const filterStrides = util_exports.computeStrides(filter.shape);
    const xBatchStride = xStrides[0];
    const xRowStride = isChannelsLast ? xStrides[1] : xStrides[2];
    const xColStride = isChannelsLast ? xStrides[2] : 1;
    const xChannelStride = isChannelsLast ? 1 : xStrides[1];
    const yBatchStride = y.strides[0];
    const yRowStride = isChannelsLast ? y.strides[1] : y.strides[2];
    const yColStride = isChannelsLast ? y.strides[2] : 1;
    const yChannelStride = isChannelsLast ? 1 : y.strides[1];
    const xVals = backend2.data.get(x.dataId).values;
    const wVals = backend2.data.get(filter.dataId).values;
    const yVals = y.values;
    for (let b = 0; b < convInfo.batchSize; ++b) {
      const xOffset1 = b * xBatchStride;
      const yOffset1 = b * yBatchStride;
      for (let yR = 0; yR < convInfo.outHeight; ++yR) {
        const yOffset2 = yOffset1 + yR * yRowStride;
        const xRCorner = yR * convInfo.strideHeight - padTop;
        for (let wR = 0; wR < filterHeight; ++wR) {
          const xR = xRCorner + wR * dilationHeight;
          if (xR < 0 || xR >= convInfo.inHeight) {
            continue;
          }
          const wOffset1 = wR * filterStrides[0];
          const xOffset2 = xOffset1 + xR * xRowStride;
          for (let yC = 0; yC < convInfo.outWidth; ++yC) {
            const yOffset3 = yOffset2 + yC * yColStride;
            const xCCorner = yC * convInfo.strideWidth - padLeft;
            for (let wC = 0; wC < filterWidth; ++wC) {
              const xC = xCCorner + wC * dilationWidth;
              if (xC < 0 || xC >= convInfo.inWidth) {
                continue;
              }
              const wOffset2 = wOffset1 + wC * filterStrides[1];
              const xOffset3 = xOffset2 + xC * xColStride;
              let wOffset3 = wOffset2;
              for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {
                const xVal = xVals[xOffset3 + d1 * xChannelStride];
                for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {
                  yVals[yOffset3 + d2 * yChannelStride] += xVal * wVals[wOffset3 + d2];
                }
                wOffset3 += convInfo.outChannels;
              }
            }
          }
        }
      }
    }
    return backend2.makeTensorInfo(y.shape, y.dtype, yVals);
  }
  var conv2DConfig = {
    kernelName: Conv2D,
    backendName: "cpu",
    kernelFunc: conv2D
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv2DBackpropFilter.js
  function conv2DBackpropFilter2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, dy } = inputs;
    const { strides, pad: pad2, dataFormat, dimRoundingMode, filterShape } = attrs;
    assertNotComplex([x, dy], "conv2dBackpropFilter");
    const $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
    const convInfo = backend_util_exports.computeConv2DInfo(x.shape, filterShape, strides, 1, pad2, dimRoundingMode, false, $dataFormat);
    const { strideHeight, strideWidth, filterHeight, filterWidth } = convInfo;
    const isChannelsLast = convInfo.dataFormat === "channelsLast";
    const dW = new TensorBuffer(convInfo.filterShape, "float32");
    const leftPad = convInfo.padInfo.left;
    const topPad = convInfo.padInfo.top;
    const xVals = backend2.data.get(x.dataId).values;
    const dyVals = backend2.data.get(dy.dataId).values;
    const xBuf = new TensorBuffer(x.shape, x.dtype, xVals);
    const dyBuf = new TensorBuffer(dy.shape, dy.dtype, dyVals);
    for (let wR = 0; wR < filterHeight; ++wR) {
      const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));
      const yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);
      for (let wC = 0; wC < filterWidth; ++wC) {
        const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));
        const yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);
        for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {
          for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {
            let dotProd = 0;
            for (let b = 0; b < convInfo.batchSize; ++b) {
              for (let yR = yRMin; yR < yRMax; ++yR) {
                const xR = wR + yR * strideHeight - topPad;
                for (let yC = yCMin; yC < yCMax; ++yC) {
                  const xC = wC + yC * strideWidth - leftPad;
                  if (isChannelsLast) {
                    dotProd += xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);
                  } else {
                    dotProd += xBuf.get(b, d1, xR, xC) * dyBuf.get(b, d2, yR, yC);
                  }
                }
              }
            }
            dW.set(dotProd, wR, wC, d1, d2);
          }
        }
      }
    }
    return backend2.makeTensorInfo(dW.shape, dW.dtype, dW.values);
  }
  var conv2DBackpropFilterConfig = {
    kernelName: Conv2DBackpropFilter,
    backendName: "cpu",
    kernelFunc: conv2DBackpropFilter2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv2DBackpropInput.js
  function conv2DBackpropInput2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { dy, filter } = inputs;
    const { inputShape, strides, pad: pad2, dataFormat, dimRoundingMode } = attrs;
    assertNotComplex([dy, filter], "conv2dBackpropInput");
    const filterStrides = util_exports.computeStrides(filter.shape);
    const dyStrides = util_exports.computeStrides(dy.shape);
    let $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
    const convInfo = backend_util_exports.computeConv2DInfo(inputShape, filter.shape, strides, 1, pad2, dimRoundingMode, false, $dataFormat);
    const dx = new TensorBuffer(convInfo.inShape, "float32");
    const dxValues = dx.values;
    const dyValues = backend2.data.get(dy.dataId).values;
    const fltValues = backend2.data.get(filter.dataId).values;
    const [fltS0, fltS1, fltS2] = filterStrides;
    const { batchSize, filterHeight, filterWidth, inChannels, inHeight, inWidth, outChannels, outHeight, outWidth, strideHeight, strideWidth } = convInfo;
    $dataFormat = convInfo.dataFormat;
    const topPad = filterHeight - 1 - convInfo.padInfo.top;
    const leftPad = filterWidth - 1 - convInfo.padInfo.left;
    const isChannelsLast = $dataFormat === "channelsLast";
    const xBatchStride = dx.strides[0];
    const xRowStride = isChannelsLast ? dx.strides[1] : dx.strides[2];
    const xColStride = isChannelsLast ? dx.strides[2] : 1;
    const xChannelStride = isChannelsLast ? 1 : dx.strides[1];
    const yBatchStride = dyStrides[0];
    const yRowStride = isChannelsLast ? dyStrides[1] : dyStrides[2];
    const yColStride = isChannelsLast ? dyStrides[2] : 1;
    const yChannelStride = isChannelsLast ? 1 : dyStrides[1];
    for (let b = 0; b < batchSize; ++b) {
      for (let d1 = 0; d1 < inChannels; ++d1) {
        for (let xR = 0; xR < inHeight; ++xR) {
          const xRCorner = xR - topPad;
          const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));
          const yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);
          for (let xC = 0; xC < inWidth; ++xC) {
            const xCCorner = xC - leftPad;
            const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));
            const yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);
            let dotProd = 0;
            for (let yR = xRMin; yR < yRMax; ++yR) {
              const wR = yR * strideHeight - xRCorner;
              for (let yC = xCMin; yC < yCMax; ++yC) {
                const wC = yC * strideWidth - xCCorner;
                const dyOffset = yBatchStride * b + yRowStride * yR + yColStride * yC;
                const fltOffset = fltS0 * (filterHeight - 1 - wR) + fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;
                for (let d2 = 0; d2 < outChannels; ++d2) {
                  const pixel = dyValues[dyOffset + yChannelStride * d2];
                  const weight = fltValues[fltOffset + d2];
                  dotProd += pixel * weight;
                }
              }
            }
            const dxOffset = xBatchStride * b + xRowStride * xR + xColStride * xC + xChannelStride * d1;
            dxValues[dxOffset] = dotProd;
          }
        }
      }
    }
    return backend2.makeTensorInfo(dx.shape, dx.dtype, dx.values);
  }
  var conv2DBackpropInputConfig = {
    kernelName: Conv2DBackpropInput,
    backendName: "cpu",
    kernelFunc: conv2DBackpropInput2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv3D.js
  function conv3D(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, filter } = inputs;
    const { strides, pad: pad2, dilations } = attrs;
    assertNotComplex([x, filter], "conv3d");
    const convInfo = backend_util_exports.computeConv3DInfo(x.shape, filter.shape, strides, dilations, pad2);
    const { filterDepth, filterHeight, filterWidth, dilationDepth, dilationHeight, dilationWidth, padInfo } = convInfo;
    const padFront = padInfo.front;
    const padLeft = padInfo.left;
    const padTop = padInfo.top;
    const y = new TensorBuffer(convInfo.outShape, x.dtype);
    const xVals = backend2.data.get(x.dataId).values;
    const wVals = backend2.data.get(filter.dataId).values;
    const yVals = y.values;
    const xStrides = util_exports.computeStrides(x.shape);
    const filterStrides = util_exports.computeStrides(filter.shape);
    for (let b = 0; b < convInfo.batchSize; ++b) {
      const xOffset1 = b * xStrides[0];
      const yOffset1 = b * y.strides[0];
      for (let yF = 0; yF < convInfo.outDepth; ++yF) {
        const yOffset2 = yOffset1 + yF * y.strides[1];
        const xFCorner = yF * convInfo.strideDepth - padFront;
        for (let wF = 0; wF < filterDepth; ++wF) {
          const xF = xFCorner + wF * dilationDepth;
          if (xF < 0 || xF >= convInfo.inDepth) {
            continue;
          }
          const wOffset1 = wF * filterStrides[0];
          const xOffset2 = xOffset1 + xF * xStrides[1];
          for (let yR = 0; yR < convInfo.outHeight; ++yR) {
            const yOffset3 = yOffset2 + yR * y.strides[2];
            const xRCorner = yR * convInfo.strideHeight - padTop;
            for (let wR = 0; wR < filterHeight; ++wR) {
              const xR = xRCorner + wR * dilationHeight;
              if (xR < 0 || xR >= convInfo.inHeight) {
                continue;
              }
              const wOffset2 = wOffset1 + wR * filterStrides[1];
              const xOffset3 = xOffset2 + xR * xStrides[2];
              for (let yC = 0; yC < convInfo.outWidth; ++yC) {
                const yOffset4 = yOffset3 + yC * convInfo.outChannels;
                const xCCorner = yC * convInfo.strideWidth - padLeft;
                for (let wC = 0; wC < filterWidth; ++wC) {
                  const xC = xCCorner + wC * dilationWidth;
                  if (xC < 0 || xC >= convInfo.inWidth) {
                    continue;
                  }
                  const wOffset3 = wOffset2 + wC * filterStrides[2];
                  const xOffset4 = xOffset3 + xC * convInfo.inChannels;
                  let wOffset4 = wOffset3;
                  for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {
                    const xVal = xVals[xOffset4 + d1];
                    for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {
                      yVals[yOffset4 + d2] += xVal * wVals[wOffset4 + d2];
                    }
                    wOffset4 += convInfo.outChannels;
                  }
                }
              }
            }
          }
        }
      }
    }
    return backend2.makeTensorInfo(y.shape, y.dtype, y.values);
  }
  var conv3DConfig = {
    kernelName: Conv3D,
    backendName: "cpu",
    kernelFunc: conv3D
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv3DBackpropFilterV2.js
  function conv3DBackpropFilterV2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, dy } = inputs;
    const { strides, pad: pad2, filterShape } = attrs;
    assertNotComplex([x, dy], "conv3dBackpropFilterV2");
    const xStrides = util_exports.computeStrides(x.shape);
    const dyStrides = util_exports.computeStrides(dy.shape);
    const convInfo = backend_util_exports.computeConv3DInfo(x.shape, filterShape, strides, 1, pad2);
    const strideDepth = convInfo.strideDepth;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const filterDepth = convInfo.filterDepth;
    const filterHeight = convInfo.filterHeight;
    const filterWidth = convInfo.filterWidth;
    const dw = new TensorBuffer(convInfo.filterShape, "float32");
    const dwValues = dw.values;
    const [dwS0, dwS1, dwS2, dwS3] = dw.strides;
    const dyValues = backend2.data.get(dy.dataId).values;
    const [dyS0, dyS1, dyS2, dyS3] = dyStrides;
    const xValues = backend2.data.get(x.dataId).values;
    const [xS0, xS1, xS2, xS3] = xStrides;
    const frontPad = convInfo.padInfo.front;
    const leftPad = convInfo.padInfo.left;
    const topPad = convInfo.padInfo.top;
    for (let wF = 0; wF < filterDepth; ++wF) {
      const yFMin = Math.max(0, Math.ceil((frontPad - wF) / strideDepth));
      const yFMax = Math.min(convInfo.outDepth, (convInfo.inDepth + frontPad - wF) / strideDepth);
      const wOffset1 = wF * dwS0;
      for (let wR = 0; wR < filterHeight; ++wR) {
        const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));
        const yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);
        const wOffset2 = wR * dwS1 + wOffset1;
        for (let wC = 0; wC < filterWidth; ++wC) {
          const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));
          const yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);
          const wOffset3 = wC * dwS2 + wOffset2;
          for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {
            const wOffset4 = d1 * dwS3 + wOffset3;
            for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {
              let dotProd = 0;
              for (let b = 0; b < convInfo.batchSize; ++b) {
                const xOffset1 = b * xS0;
                const yOffset1 = b * dyS0;
                for (let yF = yFMin; yF < yFMax; ++yF) {
                  const xF = wF + yF * strideDepth - frontPad;
                  const xOffset2 = xF * xS1 + xOffset1;
                  const yOffset2 = yF * dyS1 + yOffset1;
                  for (let yR = yRMin; yR < yRMax; ++yR) {
                    const xR = wR + yR * strideHeight - topPad;
                    const xOffset3 = xR * xS2 + xOffset2;
                    const yOffset3 = yR * dyS2 + yOffset2;
                    for (let yC = yCMin; yC < yCMax; ++yC) {
                      const xC = wC + yC * strideWidth - leftPad;
                      const xOffset4 = xC * xS3 + xOffset3;
                      const yOffset4 = yC * dyS3 + yOffset3;
                      dotProd += xValues[xOffset4 + d1] * dyValues[yOffset4 + d2];
                    }
                  }
                }
              }
              dwValues[wOffset4 + d2] = dotProd;
            }
          }
        }
      }
    }
    return backend2.makeTensorInfo(dw.shape, dw.dtype, dw.values);
  }
  var conv3DBackpropFilterV2Config = {
    kernelName: Conv3DBackpropFilterV2,
    backendName: "cpu",
    kernelFunc: conv3DBackpropFilterV2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv3DBackpropInputV2.js
  function conv3DBackpropInputV2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { dy, filter } = inputs;
    const { pad: pad2, strides, inputShape } = attrs;
    assertNotComplex([dy], "conv3dBackpropInputV2");
    const dyStrides = util_exports.computeStrides(dy.shape);
    const filterStrides = util_exports.computeStrides(filter.shape);
    const convInfo = backend_util_exports.computeConv3DInfo(inputShape, filter.shape, strides, 1, pad2);
    const dx = new TensorBuffer(convInfo.inShape, "float32");
    const dxValues = dx.values;
    const [dxS0, dxS1, dxS2, dxS3] = dx.strides;
    const dyValues = backend2.data.get(dy.dataId).values;
    const [dyS0, dyS1, dyS2, dyS3] = dyStrides;
    const fltValues = backend2.data.get(filter.dataId).values;
    const [fltS0, fltS1, fltS2, fltS3] = filterStrides;
    const { batchSize, filterDepth, filterHeight, filterWidth, inChannels, inDepth, inHeight, inWidth, outChannels, outDepth, outHeight, outWidth, strideDepth, strideHeight, strideWidth } = convInfo;
    const frontPad = filterDepth - 1 - convInfo.padInfo.front;
    const topPad = filterHeight - 1 - convInfo.padInfo.top;
    const leftPad = filterWidth - 1 - convInfo.padInfo.left;
    for (let b = 0; b < batchSize; ++b) {
      for (let d1 = 0; d1 < inChannels; ++d1) {
        for (let xF = 0; xF < inDepth; ++xF) {
          const xFCorner = xF - frontPad;
          const xFMin = Math.max(0, Math.ceil(xFCorner / strideDepth));
          const yFMax = Math.min(outDepth, (filterDepth + xFCorner) / strideDepth);
          for (let xR = 0; xR < inHeight; ++xR) {
            const xRCorner = xR - topPad;
            const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));
            const yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);
            for (let xC = 0; xC < inWidth; ++xC) {
              const xCCorner = xC - leftPad;
              const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));
              const yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);
              let dotProd = 0;
              for (let yF = xFMin; yF < yFMax; ++yF) {
                const wF = yF * strideDepth - xFCorner;
                for (let yR = xRMin; yR < yRMax; ++yR) {
                  const wR = yR * strideHeight - xRCorner;
                  for (let yC = xCMin; yC < yCMax; ++yC) {
                    const wC = yC * strideWidth - xCCorner;
                    const dyOffset = dyS0 * b + dyS1 * yF + dyS2 * yR + dyS3 * yC;
                    const fltOffset = fltS0 * (filterDepth - 1 - wF) + fltS1 * (filterHeight - 1 - wR) + fltS2 * (filterWidth - 1 - wC) + fltS3 * d1;
                    for (let d2 = 0; d2 < outChannels; ++d2) {
                      const pixel = dyValues[dyOffset + d2];
                      const weight = fltValues[fltOffset + d2];
                      dotProd += pixel * weight;
                    }
                  }
                }
              }
              dxValues[dxS0 * b + dxS1 * xF + dxS2 * xR + dxS3 * xC + d1] = dotProd;
            }
          }
        }
      }
    }
    return backend2.makeTensorInfo(dx.shape, dx.dtype, dx.values);
  }
  var conv3DBackpropInputV2Config = {
    kernelName: Conv3DBackpropInputV2,
    backendName: "cpu",
    kernelFunc: conv3DBackpropInputV2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cos.js
  var cos2 = unaryKernelFunc(Cos, (xi) => Math.cos(xi));
  var cosConfig = {
    kernelName: Cos,
    backendName: "cpu",
    kernelFunc: cos2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cosh.js
  var cosh2 = unaryKernelFunc(Cosh, (xi) => Math.cosh(xi));
  var coshConfig = {
    kernelName: Cosh,
    backendName: "cpu",
    kernelFunc: cosh2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/CropAndResize.js
  function cropAndResize2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { image: image3, boxes, boxInd } = inputs;
    const { cropSize, method, extrapolationValue } = attrs;
    const [batch, imageHeight, imageWidth, numChannels] = image3.shape;
    const numBoxes = boxes.shape[0];
    const [cropHeight, cropWidth] = cropSize;
    const output = buffer2([numBoxes, cropHeight, cropWidth, numChannels], "float32");
    const boxVals = backend2.data.get(boxes.dataId).values;
    const boxIndVals = backend2.data.get(boxInd.dataId).values;
    const imageVals = backend2.data.get(image3.dataId).values;
    const inStride = util_exports.computeStrides(image3.shape);
    const outStride = util_exports.computeStrides(output.shape);
    for (let b = 0; b < numBoxes; b++) {
      const startInd = b * 4;
      const y1 = boxVals[startInd];
      const x1 = boxVals[startInd + 1];
      const y2 = boxVals[startInd + 2];
      const x2 = boxVals[startInd + 3];
      const bInd = boxIndVals[b];
      if (bInd >= batch) {
        continue;
      }
      const heightScale = cropHeight > 1 ? (y2 - y1) * (imageHeight - 1) / (cropHeight - 1) : 0;
      const widthScale = cropWidth > 1 ? (x2 - x1) * (imageWidth - 1) / (cropWidth - 1) : 0;
      for (let y = 0; y < cropHeight; y++) {
        const yInd = cropHeight > 1 ? y1 * (imageHeight - 1) + y * heightScale : 0.5 * (y1 + y2) * (imageHeight - 1);
        if (yInd < 0 || yInd > imageHeight - 1) {
          for (let x = 0; x < cropWidth; x++) {
            for (let c = 0; c < numChannels; c++) {
              const ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
              output.values[ind] = extrapolationValue;
            }
          }
          continue;
        }
        if (method === "bilinear") {
          const topInd = Math.floor(yInd);
          const bottomInd = Math.ceil(yInd);
          const yLerp = yInd - topInd;
          for (let x = 0; x < cropWidth; x++) {
            const xInd = cropWidth > 1 ? x1 * (imageWidth - 1) + x * widthScale : 0.5 * (x1 + x2) * (imageWidth - 1);
            if (xInd < 0 || xInd > imageWidth - 1) {
              for (let c = 0; c < numChannels; c++) {
                const ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
                output.values[ind] = extrapolationValue;
              }
              continue;
            }
            const leftInd = Math.floor(xInd);
            const rightInd = Math.ceil(xInd);
            const xLerp = xInd - leftInd;
            for (let c = 0; c < numChannels; c++) {
              let ind = c + leftInd * inStride[2] + topInd * inStride[1] + bInd * inStride[0];
              const topLeft = imageVals[ind];
              ind = c + rightInd * inStride[2] + topInd * inStride[1] + bInd * inStride[0];
              const topRight = imageVals[ind];
              ind = c + leftInd * inStride[2] + bottomInd * inStride[1] + bInd * inStride[0];
              const bottomLeft = imageVals[ind];
              ind = c + rightInd * inStride[2] + bottomInd * inStride[1] + bInd * inStride[0];
              const bottomRight = imageVals[ind];
              const top = topLeft + (topRight - topLeft) * xLerp;
              const bottom = bottomLeft + (bottomRight - bottomLeft) * xLerp;
              ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
              output.values[ind] = top + (bottom - top) * yLerp;
            }
          }
        } else {
          for (let x = 0; x < cropWidth; ++x) {
            const xInd = cropWidth > 1 ? x1 * (imageWidth - 1) + x * widthScale : 0.5 * (x1 + x2) * (imageWidth - 1);
            if (xInd < 0 || xInd > imageWidth - 1) {
              for (let c = 0; c < numChannels; c++) {
                const ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
                output.values[ind] = extrapolationValue;
              }
              continue;
            }
            const closestX = Math.round(xInd);
            const closestY = Math.round(yInd);
            for (let c = 0; c < numChannels; c++) {
              const inInd = c + closestX * inStride[2] + closestY * inStride[1] + bInd * inStride[0];
              const outInd = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
              output.values[outInd] = imageVals[inInd];
            }
          }
        }
      }
    }
    return backend2.makeTensorInfo(output.shape, output.dtype, output.values);
  }
  var cropAndResizeConfig = {
    kernelName: CropAndResize,
    backendName: "cpu",
    kernelFunc: cropAndResize2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cumsum.js
  function cumsum2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { axis, exclusive, reverse: reverse4 } = attrs;
    assertNotComplex(x, "cumsum");
    const permutation = backend_util_exports.getAxesPermutation([axis], x.shape.length);
    let $x = x;
    if (permutation != null) {
      $x = transpose2({ inputs: { x }, backend: backend2, attrs: { perm: permutation } });
    }
    const permutedAxis = backend_util_exports.getInnerMostAxes(1, x.shape.length)[0];
    if (permutedAxis !== $x.shape.length - 1) {
      throw new Error(`backend.cumsum in CPU expects an inner-most axis=${$x.shape.length - 1} but got axis=${permutedAxis}`);
    }
    const resultDtype = upcastType($x.dtype, "int32");
    const vals = util_exports.makeZerosTypedArray(util_exports.sizeFromShape($x.shape), resultDtype);
    const aVals = backend2.data.get($x.dataId).values;
    const finalDim = $x.shape[$x.shape.length - 1];
    const indexAdjuster = reverse4 ? (i, j) => i + finalDim - j - 1 : (i, j) => i + j;
    for (let i = 0; i < aVals.length; i += finalDim) {
      for (let j = 0; j < finalDim; j++) {
        const idx = indexAdjuster(i, j);
        if (j === 0) {
          vals[idx] = exclusive ? 0 : aVals[idx];
        } else {
          const prevIdx = indexAdjuster(i, j - 1);
          vals[idx] = exclusive ? aVals[prevIdx] + vals[prevIdx] : aVals[idx] + vals[prevIdx];
        }
      }
    }
    const result = backend2.makeTensorInfo($x.shape, resultDtype, vals);
    if (permutation != null) {
      const reversePermutation = backend_util_exports.getUndoAxesPermutation(permutation);
      const reverseTransposedResult = transpose2({ inputs: { x: result }, backend: backend2, attrs: { perm: reversePermutation } });
      backend2.disposeIntermediateTensorInfo(result);
      backend2.disposeIntermediateTensorInfo($x);
      return reverseTransposedResult;
    }
    return result;
  }
  var cumsumConfig = {
    kernelName: Cumsum,
    backendName: "cpu",
    kernelFunc: cumsum2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/DenseBincount.js
  function denseBincount(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, weights } = inputs;
    const { size: size2, binaryOutput } = attrs;
    if (x.shape.length === 1) {
      const xVals = backend2.data.get(x.dataId).values;
      const weightsVals = backend2.data.get(weights.dataId).values;
      const outVals = bincountImpl(xVals, weightsVals, weights.dtype, weights.shape, size2);
      return backend2.makeTensorInfo([size2], weights.dtype, outVals);
    } else if (x.shape.length === 2) {
      const xBuf = backend2.bufferSync(x);
      const weightsBuf = backend2.bufferSync(weights);
      const outBuf = bincountReduceImpl(xBuf, weightsBuf, size2, binaryOutput);
      return backend2.makeTensorInfo(outBuf.shape, weights.dtype, outBuf.values);
    }
    throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${x.shape.length}.`);
  }
  var denseBincountConfig = {
    kernelName: DenseBincount,
    backendName: "cpu",
    kernelFunc: denseBincount
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/DepthToSpace.js
  function depthToSpace2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { blockSize, dataFormat } = attrs;
    util_exports.assert(dataFormat === "NHWC", () => `Only NHWC dataFormat supported on CPU for depthToSpace. Got ${dataFormat}`);
    const batchSize = x.shape[0];
    const inputHeight = x.shape[1];
    const inputWidth = x.shape[2];
    const inputDepth = x.shape[3];
    const outputHeight = inputHeight * blockSize;
    const outputWidth = inputWidth * blockSize;
    const outputDepth = inputDepth / (blockSize * blockSize);
    const xValues = backend2.data.get(x.dataId).values;
    const result = new Float32Array(batchSize * outputHeight * outputWidth * outputDepth);
    let outputIdx = 0;
    for (let b = 0; b < batchSize; ++b) {
      for (let h2 = 0; h2 < outputHeight; ++h2) {
        const inH = Math.floor(h2 / blockSize);
        const offsetH = h2 % blockSize;
        for (let w = 0; w < outputWidth; ++w) {
          const inW = Math.floor(w / blockSize);
          const offsetW = w % blockSize;
          const offsetD = (offsetH * blockSize + offsetW) * outputDepth;
          for (let d = 0; d < outputDepth; ++d) {
            const inD = d + offsetD;
            const inputIdx = inD + inputDepth * (inW + inputWidth * (inH + inputHeight * b));
            result[outputIdx++] = xValues[inputIdx];
          }
        }
      }
    }
    return backend2.makeTensorInfo([batchSize, outputHeight, outputWidth, outputDepth], x.dtype, result);
  }
  var depthToSpaceConfig = {
    kernelName: DepthToSpace,
    backendName: "cpu",
    kernelFunc: depthToSpace2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/DepthwiseConv2dNative.js
  function depthwiseConv2dNative(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, filter } = inputs;
    const { strides, pad: pad2, dilations, dimRoundingMode } = attrs;
    assertNotComplex([x, filter], "depthwiseConv2DNative");
    const xStrides = util_exports.computeStrides(x.shape);
    const filterStrides = util_exports.computeStrides(filter.shape);
    let $dilations = dilations;
    if ($dilations == null) {
      $dilations = [1, 1];
    }
    util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(strides, $dilations), () => `Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${strides} and dilations '${$dilations}'`);
    const convInfo = backend_util_exports.computeConv2DInfo(x.shape, filter.shape, strides, $dilations, pad2, dimRoundingMode, true);
    const { filterHeight, filterWidth, dilationHeight, dilationWidth, padInfo } = convInfo;
    const padLeft = padInfo.left;
    const padTop = padInfo.top;
    const chMul = convInfo.outChannels / convInfo.inChannels;
    const y = new TensorBuffer(convInfo.outShape, x.dtype);
    const xVals = backend2.data.get(x.dataId).values;
    const wVals = backend2.data.get(filter.dataId).values;
    const yVals = y.values;
    for (let b = 0; b < convInfo.batchSize; ++b) {
      const xOffset1 = b * xStrides[0];
      const yOffset1 = b * y.strides[0];
      for (let yR = 0; yR < convInfo.outHeight; ++yR) {
        const yOffset2 = yOffset1 + yR * y.strides[1];
        const xRCorner = yR * convInfo.strideHeight - padTop;
        for (let wR = 0; wR < filterHeight; ++wR) {
          const xR = xRCorner + wR * dilationHeight;
          if (xR < 0 || xR >= convInfo.inHeight) {
            continue;
          }
          const wOffset1 = wR * filterStrides[0];
          const xOffset2 = xOffset1 + xR * xStrides[1];
          for (let yC = 0; yC < convInfo.outWidth; ++yC) {
            const yOffset3 = yOffset2 + yC * y.strides[2];
            const xCCorner = yC * convInfo.strideWidth - padLeft;
            for (let wC = 0; wC < filterWidth; ++wC) {
              const xC = xCCorner + wC * dilationWidth;
              if (xC < 0 || xC >= convInfo.inWidth) {
                continue;
              }
              const wOffset2 = wOffset1 + wC * filterStrides[1];
              const xOffset3 = xOffset2 + xC * convInfo.inChannels;
              let yOffset4 = yOffset3;
              let wOffset3 = wOffset2;
              for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {
                const xVal = xVals[xOffset3 + d1];
                for (let q = 0; q < chMul; ++q) {
                  yVals[yOffset4 + q] += xVal * wVals[wOffset3 + q];
                }
                yOffset4 += chMul;
                wOffset3 += chMul;
              }
            }
          }
        }
      }
    }
    return backend2.makeTensorInfo(y.shape, y.dtype, y.values);
  }
  var depthwiseConv2dNativeConfig = {
    kernelName: DepthwiseConv2dNative,
    backendName: "cpu",
    kernelFunc: depthwiseConv2dNative
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/DepthwiseConv2dNativeBackpropFilter.js
  function depthwiseConv2dNativeBackpropFilter2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, dy } = inputs;
    const { strides, dilations, pad: pad2, dimRoundingMode, filterShape } = attrs;
    assertNotComplex([x, dy], "depthwiseConv2dNativeBackpropFilter");
    const convInfo = backend_util_exports.computeConv2DInfo(x.shape, filterShape, strides, dilations, pad2, dimRoundingMode, true);
    const { strideHeight, strideWidth, filterHeight, filterWidth } = convInfo;
    const dW = new TensorBuffer(convInfo.filterShape, "float32");
    const leftPad = convInfo.padInfo.left;
    const topPad = convInfo.padInfo.top;
    const chMul = convInfo.outChannels / convInfo.inChannels;
    const xVals = backend2.data.get(x.dataId).values;
    const xBuf = new TensorBuffer(x.shape, x.dtype, xVals);
    const dyVals = backend2.data.get(dy.dataId).values;
    const dyBuf = new TensorBuffer(dy.shape, dy.dtype, dyVals);
    for (let wR = 0; wR < filterHeight; ++wR) {
      const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));
      const yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);
      for (let wC = 0; wC < filterWidth; ++wC) {
        const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));
        const yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);
        for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {
          const d1 = Math.trunc(d2 / chMul);
          const dm = d2 % chMul;
          let dotProd = 0;
          for (let b = 0; b < convInfo.batchSize; ++b) {
            for (let yR = yRMin; yR < yRMax; ++yR) {
              const xR = wR + yR * strideHeight - topPad;
              for (let yC = yCMin; yC < yCMax; ++yC) {
                const xC = wC + yC * strideWidth - leftPad;
                dotProd += xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);
              }
            }
          }
          dW.set(dotProd, wR, wC, d1, dm);
        }
      }
    }
    return backend2.makeTensorInfo(dW.shape, dW.dtype, dW.values);
  }
  var depthwiseConv2dNativeBackpropFilterConfig = {
    kernelName: DepthwiseConv2dNativeBackpropFilter,
    backendName: "cpu",
    kernelFunc: depthwiseConv2dNativeBackpropFilter2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/DepthwiseConv2dNativeBackpropInput.js
  function depthwiseConv2dNativeBackpropInput2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { dy, filter } = inputs;
    const { strides, dilations, pad: pad2, dimRoundingMode, inputShape } = attrs;
    assertNotComplex([dy, filter], "depthwiseConv2DNativeBackpropInput");
    const dyStrides = util_exports.computeStrides(dy.shape);
    const filterStrides = util_exports.computeStrides(filter.shape);
    const convInfo = backend_util_exports.computeConv2DInfo(inputShape, filter.shape, strides, dilations, pad2, dimRoundingMode, true);
    const dx = new TensorBuffer(convInfo.inShape, "float32");
    const dxValues = dx.values;
    const [dxS0, dxS1, dxS2] = dx.strides;
    const dyValues = backend2.data.get(dy.dataId).values;
    const [dyS0, dyS1, dyS2] = dyStrides;
    const fltValues = backend2.data.get(filter.dataId).values;
    const [fltS0, fltS1, fltS2] = filterStrides;
    const { batchSize, filterHeight, filterWidth, inChannels, inHeight, inWidth, outChannels, outHeight, outWidth, strideHeight, strideWidth } = convInfo;
    const topPad = filterHeight - 1 - convInfo.padInfo.top;
    const leftPad = filterWidth - 1 - convInfo.padInfo.left;
    const chMul = outChannels / inChannels;
    for (let b = 0; b < batchSize; ++b) {
      for (let d1 = 0; d1 < inChannels; ++d1) {
        for (let xR = 0; xR < inHeight; ++xR) {
          const xRCorner = xR - topPad;
          const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));
          const yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);
          for (let xC = 0; xC < inWidth; ++xC) {
            const xCCorner = xC - leftPad;
            const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));
            const yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);
            let dotProd = 0;
            for (let yR = xRMin; yR < yRMax; ++yR) {
              const wR = yR * strideHeight - xRCorner;
              for (let yC = xCMin; yC < yCMax; ++yC) {
                const wC = yC * strideWidth - xCCorner;
                const dyOffset = dyS0 * b + dyS1 * yR + dyS2 * yC;
                const fltOffset = fltS0 * (filterHeight - 1 - wR) + fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;
                for (let dm = 0; dm < chMul; ++dm) {
                  const d2 = d1 * chMul + dm;
                  const pixel = dyValues[dyOffset + d2];
                  const weight = fltValues[fltOffset + dm];
                  dotProd += pixel * weight;
                }
              }
            }
            dxValues[dxS0 * b + dxS1 * xR + dxS2 * xC + d1] = dotProd;
          }
        }
      }
    }
    return backend2.makeTensorInfo(dx.shape, dx.dtype, dx.values);
  }
  var depthwiseConv2dNativeBackpropInputConfig = {
    kernelName: DepthwiseConv2dNativeBackpropInput,
    backendName: "cpu",
    kernelFunc: depthwiseConv2dNativeBackpropInput2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Diag.js
  function diag(args) {
    const { inputs, backend: backend2 } = args;
    const { x } = inputs;
    const xSize = util_exports.sizeFromShape(x.shape);
    const xVals = backend2.data.get(x.dataId).values;
    const outBuf = buffer2([xSize, xSize], x.dtype);
    const vals = outBuf.values;
    for (let i = 0; i < xVals.length; i++) {
      vals[i * xSize + i] = xVals[i];
    }
    const outShape = [...x.shape, ...x.shape];
    return backend2.makeTensorInfo(outShape, outBuf.dtype, outBuf.values);
  }
  var diagConfig = {
    kernelName: Diag,
    backendName: "cpu",
    kernelFunc: diag
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2D.js
  var dilation2dConfig = {
    kernelName: Dilation2D,
    backendName: "cpu",
    kernelFunc: ({ inputs, backend: backend2, attrs }) => {
      const { x, filter } = inputs;
      const { strides, pad: pad2, dilations } = attrs;
      const cpuBackend = backend2;
      const xVals = cpuBackend.data.get(x.dataId).values;
      const xRank = x.shape.length;
      const filterVals = cpuBackend.data.get(filter.dataId).values;
      const filterRank = filter.shape.length;
      const { batchSize, inHeight, inWidth, inChannels, outHeight, outWidth, padInfo, strideHeight, strideWidth, filterHeight, filterWidth, dilationHeight, dilationWidth, outShape } = backend_util_exports.computeDilation2DInfo(x.shape, filter.shape, strides, pad2, "NHWC", dilations);
      const outSize = util_exports.sizeFromShape(outShape);
      const outRank = outShape.length;
      const outputVals = util_exports.getArrayFromDType(x.dtype, outSize);
      for (let b = 0; b < batchSize; ++b) {
        for (let hOut = 0; hOut < outHeight; ++hOut) {
          const hBeg = hOut * strideHeight - padInfo.top;
          for (let wOut = 0; wOut < outWidth; ++wOut) {
            const wBeg = wOut * strideWidth - padInfo.left;
            for (let d = 0; d < inChannels; ++d) {
              let curVal = Number.MIN_SAFE_INTEGER;
              for (let h2 = 0; h2 < filterHeight; ++h2) {
                const hIn = hBeg + h2 * dilationHeight;
                if (hIn >= 0 && hIn < inHeight) {
                  for (let w = 0; w < filterWidth; ++w) {
                    const wIn = wBeg + w * dilationWidth;
                    if (wIn >= 0 && wIn < inWidth) {
                      const xIndex = util_exports.locToIndex([b, hIn, wIn, d], xRank, util_exports.computeStrides(x.shape));
                      const filterIndex = util_exports.locToIndex([h2, w, d], filterRank, util_exports.computeStrides(filter.shape));
                      const val = xVals[xIndex] + filterVals[filterIndex];
                      if (val > curVal) {
                        curVal = val;
                      }
                    }
                  }
                }
              }
              const outputIndex = util_exports.locToIndex([b, hOut, wOut, d], outRank, util_exports.computeStrides(outShape));
              outputVals[outputIndex] = curVal;
            }
          }
        }
      }
      const dataId = cpuBackend.write(util_exports.toTypedArray(outputVals, x.dtype), outShape, x.dtype);
      return { dataId, shape: outShape, dtype: x.dtype };
    }
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2DBackpropFilter.js
  var dilation2dBackpropFilterConfig = {
    kernelName: Dilation2DBackpropFilter,
    backendName: "cpu",
    kernelFunc: ({ inputs, backend: backend2, attrs }) => {
      const { x, filter, dy } = inputs;
      const { strides, pad: pad2, dilations } = attrs;
      const cpuBackend = backend2;
      const $x = util_exports.toNestedArray(x.shape, cpuBackend.data.get(x.dataId).values);
      const $filter = util_exports.toNestedArray(filter.shape, cpuBackend.data.get(filter.dataId).values);
      const { batchSize, inHeight, inWidth, inChannels, outHeight, outWidth, padInfo, strideHeight, strideWidth, filterHeight, filterWidth, dilationHeight, dilationWidth, outShape } = backend_util_exports.computeDilation2DInfo(x.shape, filter.shape, strides, pad2, "NHWC", dilations);
      util_exports.assert(dy.rank === outShape.length, () => `Error in ${Dilation2DBackpropFilter}, dy must have the same rank as output ${outShape.length}, but got ${dy.rank}`);
      const $dy = util_exports.toNestedArray(outShape, cpuBackend.data.get(dy.dataId).values);
      const gradients = util_exports.makeZerosNestedTypedArray(filter.shape, filter.dtype);
      for (let b = 0; b < batchSize; ++b) {
        for (let hOut = 0; hOut < outHeight; ++hOut) {
          const hBeg = hOut * strideHeight - padInfo.top;
          for (let wOut = 0; wOut < outWidth; ++wOut) {
            const wBeg = wOut * strideWidth - padInfo.left;
            for (let d = 0; d < inChannels; ++d) {
              let curVal = Number.MIN_SAFE_INTEGER;
              let hMax = 0;
              let wMax = 0;
              for (let h2 = 0; h2 < filterHeight; ++h2) {
                const hIn = hBeg + h2 * dilationHeight;
                if (hIn >= 0 && hIn < inHeight) {
                  for (let w = 0; w < filterWidth; ++w) {
                    const wIn = wBeg + w * dilationWidth;
                    if (wIn >= 0 && wIn < inWidth) {
                      const val = $x[b][hIn][wIn][d] + $filter[h2][w][d];
                      if (val > curVal) {
                        curVal = val;
                        hMax = h2;
                        wMax = w;
                      }
                    }
                  }
                }
              }
              gradients[hMax][wMax][d] += $dy[b][hOut][wOut][d];
            }
          }
        }
      }
      const dataId = cpuBackend.write(util_exports.toTypedArray(gradients, x.dtype), filter.shape, filter.dtype);
      return { dataId, shape: filter.shape, dtype: filter.dtype };
    }
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2DBackpropInput.js
  var dilation2dBackpropInputConfig = {
    kernelName: Dilation2DBackpropInput,
    backendName: "cpu",
    kernelFunc: ({ inputs, backend: backend2, attrs }) => {
      const { x, filter, dy } = inputs;
      const { strides, pad: pad2, dilations } = attrs;
      const cpuBackend = backend2;
      const $x = util_exports.toNestedArray(x.shape, cpuBackend.data.get(x.dataId).values);
      const $filter = util_exports.toNestedArray(filter.shape, cpuBackend.data.get(filter.dataId).values);
      const { batchSize, inHeight, inWidth, inChannels, outHeight, outWidth, padInfo, strideHeight, strideWidth, filterHeight, filterWidth, dilationHeight, dilationWidth, outShape } = backend_util_exports.computeDilation2DInfo(x.shape, filter.shape, strides, pad2, "NHWC", dilations);
      util_exports.assert(dy.rank === outShape.length, () => `Error in ${Dilation2DBackpropInput}, dy must have the same rank as output ${outShape.length}, but got ${dy.rank}`);
      const $dy = util_exports.toNestedArray(outShape, cpuBackend.data.get(dy.dataId).values);
      const gradients = util_exports.makeZerosNestedTypedArray(x.shape, x.dtype);
      for (let b = 0; b < batchSize; ++b) {
        for (let hOut = 0; hOut < outHeight; ++hOut) {
          const hBeg = hOut * strideHeight - padInfo.top;
          for (let wOut = 0; wOut < outWidth; ++wOut) {
            const wBeg = wOut * strideWidth - padInfo.left;
            for (let d = 0; d < inChannels; ++d) {
              let curVal = Number.MIN_SAFE_INTEGER;
              let hInMax = hBeg < 0 ? 0 : hBeg;
              let wInMax = wBeg < 0 ? 0 : wBeg;
              for (let h2 = 0; h2 < filterHeight; ++h2) {
                const hIn = hBeg + h2 * dilationHeight;
                if (hIn >= 0 && hIn < inHeight) {
                  for (let w = 0; w < filterWidth; ++w) {
                    const wIn = wBeg + w * dilationWidth;
                    if (wIn >= 0 && wIn < inWidth) {
                      const val = $x[b][hIn][wIn][d] + $filter[h2][w][d];
                      if (val > curVal) {
                        curVal = val;
                        hInMax = hIn;
                        wInMax = wIn;
                      }
                    }
                  }
                }
              }
              gradients[b][hInMax][wInMax][d] += $dy[b][hOut][wOut][d];
            }
          }
        }
      }
      const dataId = cpuBackend.write(util_exports.toTypedArray(gradients, x.dtype), x.shape, x.dtype);
      return { dataId, shape: x.shape, dtype: x.dtype };
    }
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sum.js
  function sum3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { axis, keepDims } = attrs;
    assertNotComplex(x, "sum");
    let $x;
    if (x.dtype === "bool") {
      $x = cast3({ inputs: { x }, backend: backend2, attrs: { dtype: "int32" } });
    } else {
      $x = identity({ inputs: { x }, backend: backend2 });
    }
    const xRank = $x.shape.length;
    const axes = util_exports.parseAxisParam(axis, $x.shape);
    const permutation = backend_util_exports.getAxesPermutation(axes, xRank);
    let reductionAxes = axes;
    let permutedX = $x;
    if (permutation != null) {
      permutedX = transpose2({ inputs: { x: $x }, backend: backend2, attrs: { perm: permutation } });
      reductionAxes = backend_util_exports.getInnerMostAxes(reductionAxes.length, xRank);
    }
    backend_util_exports.assertAxesAreInnerMostDims("sum", reductionAxes, permutedX.shape.length);
    const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(permutedX.shape, reductionAxes);
    const resultDtype = backend_util_exports.upcastType(permutedX.dtype, "int32");
    let result = zeros2(backend2, outShape, resultDtype);
    const reduceSize = util_exports.sizeFromShape(reduceShape);
    const vals = backend2.data.get(result.dataId).values;
    const aVals = backend2.data.get(permutedX.dataId).values;
    for (let i = 0; i < vals.length; ++i) {
      const offset = i * reduceSize;
      let sum5 = 0;
      for (let j = 0; j < reduceSize; ++j) {
        sum5 += aVals[offset + j];
      }
      vals[i] = sum5;
    }
    if (keepDims) {
      const newShape = backend_util_exports.expandShapeToKeepDim(result.shape, axes);
      const oldResult = result;
      result = reshape2({ inputs: { x: result }, backend: backend2, attrs: { shape: newShape } });
      backend2.disposeIntermediateTensorInfo(oldResult);
    }
    backend2.disposeIntermediateTensorInfo($x);
    if (permutation != null) {
      backend2.disposeIntermediateTensorInfo(permutedX);
    }
    return result;
  }
  var sumConfig = {
    kernelName: Sum,
    backendName: "cpu",
    kernelFunc: sum3
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Einsum.js
  function einsum(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { equation } = attrs;
    const tensors = inputs;
    const { allDims, summedDims, idDims } = backend_util_exports.decodeEinsumEquation(equation, tensors.length);
    backend_util_exports.checkEinsumDimSizes(allDims.length, idDims, tensors);
    const { path, steps } = backend_util_exports.getEinsumComputePath(summedDims, idDims);
    const nSteps = steps.length;
    let out = null;
    let numDimsRemaining = allDims.length;
    const tensorsToDispose = [];
    for (let i = 0; i < nSteps; ++i) {
      for (const idTerm of steps[i]) {
        const { permutationIndices: perm, expandDims: dimsToExpand } = backend_util_exports.getEinsumPermutation(numDimsRemaining, idDims[idTerm]);
        let x;
        if (backend_util_exports.isIdentityPermutation(perm)) {
          x = tensors[idTerm];
        } else {
          x = transpose2({ inputs: { x: tensors[idTerm] }, backend: backend2, attrs: { perm } });
          tensorsToDispose.push(x);
        }
        const targetShape = x.shape.slice();
        for (let k = 0; k < dimsToExpand.length; ++k) {
          targetShape.splice(dimsToExpand[k], 0, 1);
        }
        if (!util_exports.arraysEqual(x.shape, targetShape)) {
          x = reshape2({ inputs: { x }, backend: backend2, attrs: { shape: targetShape } });
          tensorsToDispose.push(x);
        }
        if (out === null) {
          out = x;
        } else {
          out = multiply({ inputs: { a: x, b: out }, backend: backend2 });
          tensorsToDispose.push(out);
        }
      }
      if (i < nSteps - 1) {
        if (path[i] >= 0) {
          out = sum3({
            inputs: { x: out },
            backend: backend2,
            attrs: {
              axis: path[i] - (allDims.length - numDimsRemaining),
              keepDims: false
            }
          });
          tensorsToDispose.push(out);
        }
        numDimsRemaining--;
      }
    }
    for (const tensorInfo of tensorsToDispose) {
      if (tensorInfo === out) {
        continue;
      }
      backend2.disposeIntermediateTensorInfo(tensorInfo);
    }
    return out;
  }
  var einsumConfig = {
    kernelName: Einsum,
    backendName: "cpu",
    kernelFunc: einsum
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/EluGrad.js
  function eluGrad(args) {
    const { inputs, backend: backend2 } = args;
    const { dy, y } = inputs;
    assertNotComplex([dy, y], "eluGrad");
    const resultValues = new Float32Array(util_exports.sizeFromShape(y.shape));
    const values = backend2.data.get(y.dataId).values;
    const dyValues = backend2.data.get(dy.dataId).values;
    for (let i = 0; i < values.length; ++i) {
      const v = values[i];
      if (v >= 1) {
        resultValues[i] = dyValues[i];
      } else {
        resultValues[i] = dyValues[i] * (v + 1);
      }
    }
    return backend2.makeTensorInfo(y.shape, "float32", resultValues);
  }
  var eluGradConfig2 = {
    kernelName: EluGrad,
    backendName: "cpu",
    kernelFunc: eluGrad
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Erf.js
  var p2 = backend_util_exports.ERF_P;
  var a1 = backend_util_exports.ERF_A1;
  var a2 = backend_util_exports.ERF_A2;
  var a3 = backend_util_exports.ERF_A3;
  var a4 = backend_util_exports.ERF_A4;
  var a5 = backend_util_exports.ERF_A5;
  var erf2 = unaryKernelFunc(Erf, (xi) => {
    const sign4 = Math.sign(xi);
    const v = Math.abs(xi);
    const t = 1 / (1 + p2 * v);
    return sign4 * (1 - ((((a5 * t + a4) * t + a3) * t + a2) * t + a1) * t * Math.exp(-v * v));
  });
  var erfConfig = {
    kernelName: Erf,
    backendName: "cpu",
    kernelFunc: erf2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ExpandDims.js
  function expandDims3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { input: input2 } = inputs;
    const { dim } = attrs;
    const inputRank = input2.shape.length;
    const newShape = input2.shape.slice();
    let $dim = dim;
    if (dim < 0) {
      util_exports.assert(-(inputRank + 1) <= dim, () => `Axis must be in the interval [${-(inputRank + 1)}, ${inputRank}]`);
      $dim = inputRank + dim + 1;
    }
    newShape.splice($dim, 0, 1);
    return reshape2({ inputs: { x: input2 }, backend: backend2, attrs: { shape: newShape } });
  }
  var expandDimsConfig = {
    kernelName: ExpandDims,
    backendName: "cpu",
    kernelFunc: expandDims3
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RealDiv.js
  var realDivImpl = createSimpleBinaryKernelImpl((a, b) => a / b);
  var div2 = binaryKernelFunc(RealDiv, realDivImpl);
  var realDivConfig = {
    kernelName: RealDiv,
    backendName: "cpu",
    kernelFunc: div2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/fft_utils.js
  function fftBatch(input2, inverse, cpuBackend) {
    const inputShape = input2.shape;
    const batch = inputShape[0];
    const innerDim = inputShape[1];
    const inputVals = cpuBackend.data.get(input2.dataId);
    const real2D = inputVals.complexTensorInfos.real;
    const imag2D = inputVals.complexTensorInfos.imag;
    const resultShape = [batch, innerDim];
    const resultSize = util_exports.sizeFromShape(resultShape);
    const resultReal = util_exports.getTypedArrayFromDType("float32", resultSize);
    const resultImag = util_exports.getTypedArrayFromDType("float32", resultSize);
    for (let b = 0; b < batch; b++) {
      const r = slice2({
        inputs: { x: real2D },
        backend: cpuBackend,
        attrs: { begin: [b, 0], size: [1, innerDim] }
      });
      const i = slice2({
        inputs: { x: imag2D },
        backend: cpuBackend,
        attrs: { begin: [b, 0], size: [1, innerDim] }
      });
      const input3 = complex2({ inputs: { real: r, imag: i }, backend: cpuBackend });
      const { real: real4, imag: imag4 } = fftImpl(input3, inverse, cpuBackend);
      const res = backend_util_exports.mergeRealAndImagArrays(real4, imag4);
      for (let d = 0; d < innerDim; d++) {
        const c = backend_util_exports.getComplexWithIndex(res, d);
        resultReal[b * innerDim + d] = c.real;
        resultImag[b * innerDim + d] = c.imag;
      }
      cpuBackend.disposeIntermediateTensorInfo(r);
      cpuBackend.disposeIntermediateTensorInfo(i);
      cpuBackend.disposeIntermediateTensorInfo(input3);
    }
    const $realInfo = cpuBackend.makeTensorInfo(resultShape, "float32", resultReal);
    const $imagInfo = cpuBackend.makeTensorInfo(resultShape, "float32", resultImag);
    const result = complex2({ inputs: { real: $realInfo, imag: $imagInfo }, backend: cpuBackend });
    cpuBackend.disposeIntermediateTensorInfo($realInfo);
    cpuBackend.disposeIntermediateTensorInfo($imagInfo);
    return result;
  }
  function fftImpl(input2, inverse, cpuBackend) {
    const inputSize = util_exports.sizeFromShape(input2.shape);
    const inputVals = cpuBackend.data.get(input2.dataId);
    const realVals = cpuBackend.data.get(inputVals.complexTensorInfos.real.dataId).values;
    const imagVals = cpuBackend.data.get(inputVals.complexTensorInfos.imag.dataId).values;
    if (isExponentOf2(inputSize)) {
      const result = fftRadix2(realVals, imagVals, inputSize, inverse, cpuBackend);
      const resultShape = [input2.shape[0], input2.shape[1]];
      if (inverse) {
        const realInfo = cpuBackend.makeTensorInfo(resultShape, "float32", result.real);
        const imagInfo = cpuBackend.makeTensorInfo(resultShape, "float32", result.imag);
        const sizeInfo = cpuBackend.makeTensorInfo([], "float32", util_exports.createScalarValue(inputSize, "float32"));
        const sizeInfoCopy = identity({ inputs: { x: sizeInfo }, backend: cpuBackend });
        const divRealInfo = realDivConfig.kernelFunc({ inputs: { a: realInfo, b: sizeInfo }, backend: cpuBackend });
        const divImagInfo = realDivConfig.kernelFunc({ inputs: { a: imagInfo, b: sizeInfoCopy }, backend: cpuBackend });
        const divRealVals = cpuBackend.data.get(divRealInfo.dataId).values;
        const divImagVals = cpuBackend.data.get(divImagInfo.dataId).values;
        cpuBackend.disposeIntermediateTensorInfo(realInfo);
        cpuBackend.disposeIntermediateTensorInfo(imagInfo);
        cpuBackend.disposeIntermediateTensorInfo(sizeInfo);
        cpuBackend.disposeIntermediateTensorInfo(sizeInfoCopy);
        cpuBackend.disposeIntermediateTensorInfo(divRealInfo);
        cpuBackend.disposeIntermediateTensorInfo(divImagInfo);
        return { real: divRealVals, imag: divImagVals };
      }
      return result;
    } else {
      const data = backend_util_exports.mergeRealAndImagArrays(realVals, imagVals);
      const rawOutput = fourierTransformByMatmul(data, inputSize, inverse);
      return backend_util_exports.splitRealAndImagArrays(rawOutput);
    }
  }
  function isExponentOf2(size2) {
    return (size2 & size2 - 1) === 0;
  }
  function fftRadix2(realVals, imagVals, size2, inverse, cpuBackend) {
    if (size2 === 1) {
      return { real: realVals, imag: imagVals };
    }
    const data = backend_util_exports.mergeRealAndImagArrays(realVals, imagVals);
    const half = size2 / 2;
    const evenComplex = backend_util_exports.complexWithEvenIndex(data);
    const evenRealVals = evenComplex.real;
    const evenImagVals = evenComplex.imag;
    const evenShape = [evenRealVals.length];
    const evenRealInfo = cpuBackend.makeTensorInfo(evenShape, "float32", evenRealVals);
    const evenImagInfo = cpuBackend.makeTensorInfo(evenShape, "float32", evenImagVals);
    const evenTensorInfo = complex2({ inputs: { real: evenRealInfo, imag: evenImagInfo }, backend: cpuBackend });
    const oddComplex = backend_util_exports.complexWithOddIndex(data);
    const oddRealVals = oddComplex.real;
    const oddImagVals = oddComplex.imag;
    const oddShape = [oddRealVals.length];
    const oddRealInfo = cpuBackend.makeTensorInfo(oddShape, "float32", oddRealVals);
    const oddImagInfo = cpuBackend.makeTensorInfo(oddShape, "float32", oddImagVals);
    const oddTensorInfo = complex2({ inputs: { real: oddRealInfo, imag: oddImagInfo }, backend: cpuBackend });
    const $evenComplex = fftRadix2(evenRealVals, evenImagVals, half, inverse, cpuBackend);
    const $evenRealVals = $evenComplex.real;
    const $evenImagVals = $evenComplex.imag;
    const $evenShape = [$evenRealVals.length];
    const $evenRealInfo = cpuBackend.makeTensorInfo($evenShape, "float32", $evenRealVals);
    const $evenImagInfo = cpuBackend.makeTensorInfo($evenShape, "float32", $evenImagVals);
    const $evenTensorInfo = complex2({
      inputs: { real: $evenRealInfo, imag: $evenImagInfo },
      backend: cpuBackend
    });
    const $oddComplex = fftRadix2(oddRealVals, oddImagVals, half, inverse, cpuBackend);
    const $oddRealVals = $oddComplex.real;
    const $oddImagVals = $oddComplex.imag;
    const $oddShape = [$oddRealVals.length];
    const $oddRealInfo = cpuBackend.makeTensorInfo($oddShape, "float32", $oddRealVals);
    const $oddImagInfo = cpuBackend.makeTensorInfo($oddShape, "float32", $oddImagVals);
    const $oddTensorInfo = complex2({ inputs: { real: $oddRealInfo, imag: $oddImagInfo }, backend: cpuBackend });
    const e = backend_util_exports.exponents(size2, inverse);
    const eShape = [e.real.length];
    const eRealInfo = cpuBackend.makeTensorInfo(eShape, "float32", e.real);
    const eImagInfo = cpuBackend.makeTensorInfo(eShape, "float32", e.imag);
    const complexInfo = complex2({ inputs: { real: eRealInfo, imag: eImagInfo }, backend: cpuBackend });
    const exponentInfo = multiply({ inputs: { a: complexInfo, b: $oddTensorInfo }, backend: cpuBackend });
    const addPart = add4({
      inputs: { a: $evenTensorInfo, b: exponentInfo },
      backend: cpuBackend
    });
    const subPart = sub2({
      inputs: { a: $evenTensorInfo, b: exponentInfo },
      backend: cpuBackend
    });
    const addPartReal = real2({ inputs: { input: addPart }, backend: cpuBackend });
    const subPartReal = real2({ inputs: { input: subPart }, backend: cpuBackend });
    const addPartImag = imag2({ inputs: { input: addPart }, backend: cpuBackend });
    const subPartImag = imag2({ inputs: { input: subPart }, backend: cpuBackend });
    const $real = concat2({
      inputs: [addPartReal, subPartReal],
      backend: cpuBackend,
      attrs: { axis: 0 }
    });
    const $imag = concat2({
      inputs: [addPartImag, subPartImag],
      backend: cpuBackend,
      attrs: { axis: 0 }
    });
    const $realVals = cpuBackend.data.get($real.dataId).values;
    const $imagVals = cpuBackend.data.get($imag.dataId).values;
    cpuBackend.disposeIntermediateTensorInfo(evenRealInfo);
    cpuBackend.disposeIntermediateTensorInfo(evenImagInfo);
    cpuBackend.disposeIntermediateTensorInfo(evenTensorInfo);
    cpuBackend.disposeIntermediateTensorInfo(oddRealInfo);
    cpuBackend.disposeIntermediateTensorInfo(oddImagInfo);
    cpuBackend.disposeIntermediateTensorInfo(oddTensorInfo);
    cpuBackend.disposeIntermediateTensorInfo($evenRealInfo);
    cpuBackend.disposeIntermediateTensorInfo($evenImagInfo);
    cpuBackend.disposeIntermediateTensorInfo($evenTensorInfo);
    cpuBackend.disposeIntermediateTensorInfo($oddRealInfo);
    cpuBackend.disposeIntermediateTensorInfo($oddImagInfo);
    cpuBackend.disposeIntermediateTensorInfo($oddTensorInfo);
    cpuBackend.disposeIntermediateTensorInfo(eRealInfo);
    cpuBackend.disposeIntermediateTensorInfo(eImagInfo);
    cpuBackend.disposeIntermediateTensorInfo(complexInfo);
    cpuBackend.disposeIntermediateTensorInfo(exponentInfo);
    cpuBackend.disposeIntermediateTensorInfo(addPart);
    cpuBackend.disposeIntermediateTensorInfo(subPart);
    cpuBackend.disposeIntermediateTensorInfo(addPartReal);
    cpuBackend.disposeIntermediateTensorInfo(addPartImag);
    cpuBackend.disposeIntermediateTensorInfo(subPartReal);
    cpuBackend.disposeIntermediateTensorInfo(subPartImag);
    cpuBackend.disposeIntermediateTensorInfo($real);
    cpuBackend.disposeIntermediateTensorInfo($imag);
    return { real: $realVals, imag: $imagVals };
  }
  function fourierTransformByMatmul(data, size2, inverse) {
    const ret = new Float32Array(size2 * 2);
    for (let r = 0; r < size2; r++) {
      let real4 = 0;
      let imag4 = 0;
      for (let c = 0; c < size2; c++) {
        const e = backend_util_exports.exponent(r * c, size2, inverse);
        const term = backend_util_exports.getComplexWithIndex(data, c);
        real4 += term.real * e.real - term.imag * e.imag;
        imag4 += term.real * e.imag + term.imag * e.real;
      }
      if (inverse) {
        real4 /= size2;
        imag4 /= size2;
      }
      backend_util_exports.assignToTypedArray(ret, real4, imag4, r);
    }
    return ret;
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FFT.js
  function fft2(args) {
    const { inputs, backend: backend2 } = args;
    const { input: input2 } = inputs;
    const inputSize = util_exports.sizeFromShape(input2.shape);
    const innerDimensionSize = input2.shape[input2.shape.length - 1];
    const batch = inputSize / innerDimensionSize;
    const input2D = reshape2({
      inputs: { x: input2 },
      backend: backend2,
      attrs: { shape: [batch, innerDimensionSize] }
    });
    const result = fftBatch(input2D, false, backend2);
    const resultReshaped = reshape2({ inputs: { x: result }, backend: backend2, attrs: { shape: input2.shape } });
    backend2.disposeIntermediateTensorInfo(input2D);
    backend2.disposeIntermediateTensorInfo(result);
    return resultReshaped;
  }
  var fftConfig = {
    kernelName: FFT,
    backendName: "cpu",
    kernelFunc: fft2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Fill.js
  function fill2(args) {
    const { backend: backend2, attrs } = args;
    const { shape, value, dtype } = attrs;
    const $dtype = dtype || util_exports.inferDtype(value);
    const values = util_exports.getArrayFromDType($dtype, util_exports.sizeFromShape(shape));
    fillValues(values, value, $dtype);
    return backend2.makeTensorInfo(shape, $dtype, values);
  }
  var fillConfig = {
    kernelName: Fill,
    backendName: "cpu",
    kernelFunc: fill2
  };
  function fillValues(values, value, dtype) {
    if (dtype === "string") {
      values.fill(value);
    } else {
      values.fill(value);
    }
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FlipLeftRight.js
  var flipLeftRightConfig = {
    kernelName: FlipLeftRight,
    backendName: "cpu",
    kernelFunc: ({ inputs, attrs, backend: backend2 }) => {
      const { image: image3 } = inputs;
      const cpuBackend = backend2;
      const output = util_exports.getTypedArrayFromDType(image3.dtype, util_exports.sizeFromShape(image3.shape));
      const [batch, imageHeight, imageWidth, numChannels] = image3.shape;
      const imageVals = cpuBackend.data.get(image3.dataId).values;
      for (let batchIdx = 0; batchIdx < batch; batchIdx++) {
        const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;
        for (let row = 0; row < imageHeight; row++) {
          const rowOffset = row * (imageWidth * numChannels);
          for (let col = 0; col < imageWidth; col++) {
            const colOffset = col * numChannels;
            for (let channel = 0; channel < numChannels; channel++) {
              const coordX = Math.round(imageWidth - col - 1);
              const outIdx = batchOffset + rowOffset + colOffset + channel;
              let outputValue = imageVals[outIdx];
              if (coordX >= 0 && coordX < imageWidth) {
                const rotatedColOffset = coordX * numChannels;
                const imageIdx = batchOffset + rowOffset + rotatedColOffset + channel;
                outputValue = imageVals[imageIdx];
              }
              output[outIdx] = outputValue;
            }
          }
        }
      }
      const dataId = cpuBackend.write(output, image3.shape, image3.dtype);
      return { dataId, shape: image3.shape, dtype: image3.dtype };
    }
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FloorDiv.js
  var floorDivImpl = createSimpleBinaryKernelImpl((a, b) => Math.floor(a / b));
  var floorDiv2 = binaryKernelFunc(FloorDiv, floorDivImpl, null, "int32");
  var floorDivConfig = {
    kernelName: FloorDiv,
    backendName: "cpu",
    kernelFunc: floorDiv2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FusedConv2D.js
  function fusedConv2D(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, filter, bias, preluActivationWeights } = inputs;
    const { strides, pad: pad2, dataFormat, dilations, dimRoundingMode, activation, leakyreluAlpha } = attrs;
    let result = conv2D({
      inputs: { x, filter },
      backend: backend2,
      attrs: { strides, pad: pad2, dataFormat, dilations, dimRoundingMode }
    });
    if (bias) {
      const resultOld = result;
      result = add4({ inputs: { a: result, b: bias }, backend: backend2 });
      backend2.disposeIntermediateTensorInfo(resultOld);
    }
    if (activation) {
      const resultOld = result;
      result = applyActivation2(backend2, result, activation, preluActivationWeights, leakyreluAlpha);
      backend2.disposeIntermediateTensorInfo(resultOld);
    }
    return result;
  }
  var fusedConv2DConfig = {
    kernelName: FusedConv2D,
    backendName: "cpu",
    kernelFunc: fusedConv2D
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FusedDepthwiseConv2D.js
  function fusedDepthwiseConv2D(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, filter, bias, preluActivationWeights } = inputs;
    const { strides, pad: pad2, dataFormat, dilations, dimRoundingMode, activation, leakyreluAlpha } = attrs;
    let result = depthwiseConv2dNative({
      inputs: { x, filter },
      backend: backend2,
      attrs: { strides, pad: pad2, dataFormat, dilations, dimRoundingMode }
    });
    if (bias) {
      const oldResult = result;
      result = add4({ inputs: { a: result, b: bias }, backend: backend2 });
      backend2.disposeIntermediateTensorInfo(oldResult);
    }
    if (activation) {
      const oldResult = result;
      result = applyActivation2(backend2, result, activation, preluActivationWeights, leakyreluAlpha);
      backend2.disposeIntermediateTensorInfo(oldResult);
    }
    return result;
  }
  var fusedDepthwiseConv2DConfig = {
    kernelName: FusedDepthwiseConv2D,
    backendName: "cpu",
    kernelFunc: fusedDepthwiseConv2D
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GatherNd.js
  function gatherNd(args) {
    const { inputs, backend: backend2 } = args;
    const { params, indices } = inputs;
    const paramsSize = util_exports.sizeFromShape(params.shape);
    const indicesShape = indices.shape;
    const sliceRank = indicesShape[indicesShape.length - 1];
    const [resultShape, numSlices, sliceSize, strides] = backend_util_exports.prepareAndValidate(params, indices);
    if (numSlices === 0) {
      return backend2.makeTensorInfo(resultShape, params.dtype, []);
    }
    const indicesData = backend2.data.get(indices.dataId).values;
    const paramsBuf = backend2.bufferSync(params);
    const outBuf = gatherNdImpl(indicesData, paramsBuf, params.dtype, numSlices, sliceRank, sliceSize, strides, params.shape, paramsSize);
    return backend2.makeTensorInfo(resultShape, params.dtype, outBuf.values);
  }
  var gatherNdConfig = {
    kernelName: GatherNd,
    backendName: "cpu",
    kernelFunc: gatherNd
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GatherV2.js
  function gatherV2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, indices } = inputs;
    const { axis, batchDims } = attrs;
    assertNotComplex([x, indices], "gatherV2");
    const parsedAxis = util_exports.parseAxisParam(axis, x.shape)[0];
    const indicesVals = backend2.data.get(indices.dataId).values;
    const axisDim = x.shape[parsedAxis];
    for (let i = 0; i < indicesVals.length; ++i) {
      const index = indicesVals[i];
      util_exports.assert(index <= axisDim - 1 && index >= 0, () => `GatherV2: the index value ${index} is not in [0, ${axisDim - 1}]`);
    }
    let $batchDims = batchDims;
    if (batchDims == null) {
      $batchDims = 0;
    }
    const indicesSize = util_exports.sizeFromShape(indices.shape);
    const shapeInfo = backend_util_exports.segment_util.collectGatherOpShapeInfo(x, indices, parsedAxis, $batchDims);
    const flattenX = reshape2({
      inputs: { x },
      backend: backend2,
      attrs: {
        shape: [
          shapeInfo.batchSize,
          shapeInfo.outerSize,
          shapeInfo.dimSize,
          shapeInfo.sliceSize
        ]
      }
    });
    const flattenIndex = reshape2({
      inputs: { x: indices },
      backend: backend2,
      attrs: { shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize] }
    });
    const flattenOutputShape = [
      shapeInfo.batchSize,
      shapeInfo.outerSize,
      indicesSize / shapeInfo.batchSize,
      shapeInfo.sliceSize
    ];
    const indicesBuf = backend2.bufferSync(flattenIndex);
    const xBuf = backend2.bufferSync(flattenX);
    const outBuf = gatherV2Impl(xBuf, indicesBuf, flattenOutputShape);
    backend2.disposeIntermediateTensorInfo(flattenX);
    backend2.disposeIntermediateTensorInfo(flattenIndex);
    return backend2.makeTensorInfo(shapeInfo.outputShape, outBuf.dtype, outBuf.values);
  }
  var gatherV2Config = {
    kernelName: GatherV2,
    backendName: "cpu",
    kernelFunc: gatherV2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/IFFT.js
  function ifft2(args) {
    const { inputs, backend: backend2 } = args;
    const { input: input2 } = inputs;
    const inputSize = util_exports.sizeFromShape(input2.shape);
    const innerDimensionSize = input2.shape[input2.shape.length - 1];
    const batch = inputSize / innerDimensionSize;
    const input2D = reshape2({
      inputs: { x: input2 },
      backend: backend2,
      attrs: { shape: [batch, innerDimensionSize] }
    });
    const result = fftBatch(input2D, true, backend2);
    const resultReshaped = reshape2({ inputs: { x: result }, backend: backend2, attrs: { shape: input2.shape } });
    backend2.disposeIntermediateTensorInfo(input2D);
    backend2.disposeIntermediateTensorInfo(result);
    return resultReshaped;
  }
  var ifftConfig = {
    kernelName: IFFT,
    backendName: "cpu",
    kernelFunc: ifft2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/IsFinite.js
  var isFinite3 = unaryKernelFunc(IsFinite, (xi) => Number.isFinite(xi) ? 1 : 0, "bool");
  var isFiniteConfig = {
    kernelName: IsFinite,
    backendName: "cpu",
    kernelFunc: isFinite3
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/IsInf.js
  var isInf2 = unaryKernelFunc(IsInf, (xi) => Math.abs(xi) === Infinity ? 1 : 0, "bool");
  var isInfConfig = {
    kernelName: IsInf,
    backendName: "cpu",
    kernelFunc: isInf2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/IsNaN.js
  var isNaN3 = unaryKernelFunc(IsNan, (xi) => Number.isNaN(xi) ? 1 : 0, "bool");
  var isNaNConfig = {
    kernelName: IsNan,
    backendName: "cpu",
    kernelFunc: isNaN3
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LinSpace.js
  function linSpace(args) {
    const { backend: backend2, attrs } = args;
    const { start, stop: stop2, num } = attrs;
    const outVals = linSpaceImpl(start, stop2, num);
    return backend2.makeTensorInfo([outVals.length], "float32", outVals);
  }
  var linSpaceConfig = {
    kernelName: LinSpace,
    backendName: "cpu",
    kernelFunc: linSpace
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Log1p.js
  var log1p2 = unaryKernelFunc(Log1p, (xi) => Math.log1p(xi));
  var log1pConfig = {
    kernelName: Log1p,
    backendName: "cpu",
    kernelFunc: log1p2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LogicalAnd.js
  var logicalAndImpl = createSimpleBinaryKernelImpl((a, b) => a && b);
  var logicalAnd2 = binaryKernelFunc(LogicalAnd, logicalAndImpl, null, "bool");
  var logicalAndConfig = {
    kernelName: LogicalAnd,
    backendName: "cpu",
    kernelFunc: logicalAnd2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LogicalNot.js
  var logicalNot2 = unaryKernelFunc(LogicalNot, (xi) => xi ? 0 : 1, "bool");
  var logicalNotConfig = {
    kernelName: LogicalNot,
    backendName: "cpu",
    kernelFunc: logicalNot2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LogicalOr.js
  var logicalOrImpl = createSimpleBinaryKernelImpl((a, b) => a || b);
  var logicalOr2 = binaryKernelFunc(LogicalOr, logicalOrImpl, null, "bool");
  var logicalOrConfig = {
    kernelName: LogicalOr,
    backendName: "cpu",
    kernelFunc: logicalOr2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LRN.js
  function lRN(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { depthRadius, bias, alpha, beta } = attrs;
    assertNotComplex(x, "LRN");
    const channels = x.shape[3];
    const maxD = channels - 1;
    const xValues = backend2.data.get(x.dataId).values;
    const size2 = util_exports.sizeFromShape(x.shape);
    const result = new Float32Array(size2);
    function sumAcrossChannels(offset) {
      const currentChannel = offset % channels;
      let beginSumOffset = offset - currentChannel + Math.max(0, currentChannel - depthRadius);
      const endSumOffset = offset - currentChannel + Math.min(currentChannel + depthRadius, maxD);
      let sum5 = 0;
      for (; beginSumOffset <= endSumOffset; beginSumOffset++) {
        const z = xValues[beginSumOffset];
        sum5 += z * z;
      }
      return sum5;
    }
    for (let offset = 0; offset < size2; offset++) {
      const sum5 = sumAcrossChannels(offset);
      const val = xValues[offset] * Math.pow(bias + alpha * sum5, -beta);
      result[offset] = val;
    }
    return backend2.makeTensorInfo(x.shape, x.dtype, result);
  }
  var lRNConfig = {
    kernelName: LRN,
    backendName: "cpu",
    kernelFunc: lRN
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LRNGrad.js
  function lRNGrad(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, y, dy } = inputs;
    const { depthRadius, bias, alpha, beta } = attrs;
    assertNotComplex(dy, "LRNGrad");
    const dySize = util_exports.sizeFromShape(dy.shape);
    const channels = dy.shape[3];
    const dyValues = backend2.data.get(dy.dataId).values;
    const xValues = backend2.data.get(x.dataId).values;
    const yValues = backend2.data.get(y.dataId).values;
    const result = new Float32Array(dySize);
    const size2 = dySize;
    for (let offset = 0; offset < size2; offset++) {
      const currentChannel = offset % channels;
      const depthBegin = offset - currentChannel + Math.max(0, currentChannel - depthRadius);
      const depthEnd = offset - currentChannel + Math.min(channels, currentChannel + depthRadius + 1);
      let norm2 = 0;
      for (let k = depthBegin; k < depthEnd; k++) {
        norm2 += Math.pow(xValues[k], 2);
      }
      norm2 = alpha * norm2 + bias;
      for (let k = depthBegin; k < depthEnd; k++) {
        let dyi = -2 * alpha * beta * xValues[k] * yValues[offset] / norm2;
        if (offset === k) {
          dyi += Math.pow(norm2, -beta);
        }
        dyi *= dyValues[offset];
        result[k] += dyi;
      }
    }
    return backend2.makeTensorInfo(dy.shape, x.dtype, result);
  }
  var lRNGradConfig = {
    kernelName: LRNGrad,
    backendName: "cpu",
    kernelFunc: lRNGrad
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Max.js
  function max3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { reductionIndices, keepDims } = attrs;
    const cpuBackend = backend2;
    let xShape = x.shape;
    const xRank = xShape.length;
    const origAxes = util_exports.parseAxisParam(reductionIndices, xShape);
    let axes = origAxes;
    const permutedAxes = backend_util_exports.getAxesPermutation(axes, xRank);
    let xVals = cpuBackend.data.get(x.dataId).values;
    if (permutedAxes != null) {
      const newShape = new Array(xRank);
      for (let i = 0; i < newShape.length; i++) {
        newShape[i] = xShape[permutedAxes[i]];
      }
      xVals = transposeImpl(xVals, xShape, x.dtype, permutedAxes, newShape);
      axes = backend_util_exports.getInnerMostAxes(axes.length, xRank);
      xShape = newShape;
    }
    assertNotComplex(x, "max");
    backend_util_exports.assertAxesAreInnerMostDims("max", axes, xRank);
    const [maxOutShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(xShape, axes);
    const reduceSize = util_exports.sizeFromShape(reduceShape);
    const result = maxImpl(xVals, reduceSize, maxOutShape, x.dtype);
    const dataId = cpuBackend.write(result, maxOutShape, x.dtype);
    let outShape = maxOutShape;
    if (keepDims) {
      const newShape = backend_util_exports.expandShapeToKeepDim(maxOutShape, origAxes);
      outShape = newShape;
    }
    return { dataId, shape: outShape, dtype: x.dtype };
  }
  var maxConfig = {
    kernelName: Max,
    backendName: "cpu",
    kernelFunc: max3
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPool.js
  function maxPool2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    assertNotComplex(x, "maxPool");
    const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
    const dilations = 1;
    util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
    const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode);
    let res;
    if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 && util_exports.arraysEqual(convInfo.inShape, convInfo.outShape)) {
      res = identity({ inputs: { x }, backend: backend2 });
    } else {
      const xValues = backend2.data.get(x.dataId).values;
      const strides2 = util_exports.computeStrides(x.shape);
      const buffer3 = pool2(xValues, x.shape, x.dtype, strides2, convInfo, "max");
      res = backend2.makeTensorInfo(convInfo.outShape, x.dtype, buffer3.values);
    }
    return res;
  }
  var maxPoolConfig = {
    kernelName: MaxPool,
    backendName: "cpu",
    kernelFunc: maxPool2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPool3D.js
  function maxPool3D(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat } = attrs;
    assertNotComplex(x, "maxPool3d");
    const convInfo = backend_util_exports.computePool3DInfo(x.shape, filterSize, strides, 1, pad2, dimRoundingMode, dataFormat);
    const xValues = backend2.data.get(x.dataId).values;
    const outBuf = pool3d2(xValues, x.shape, x.dtype, util_exports.computeStrides(x.shape), convInfo, "max");
    return backend2.makeTensorInfo(outBuf.shape, "float32", outBuf.values);
  }
  var maxPool3DConfig = {
    kernelName: MaxPool3D,
    backendName: "cpu",
    kernelFunc: maxPool3D
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPool3DGrad.js
  function maxPool3DGrad(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { dy, input: input2 } = inputs;
    const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
    assertNotComplex([dy, input2], "maxPool3DGrad");
    const convInfo = backend_util_exports.computePool3DInfo(input2.shape, filterSize, strides, 1, pad2, dimRoundingMode);
    const inputBuf = backend2.bufferSync(input2);
    const maxPosBuf = maxPool3dPositions(inputBuf, convInfo);
    const strideDepth = convInfo.strideDepth;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationDepth = convInfo.dilationDepth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const effectiveFilterDepth = convInfo.effectiveFilterDepth;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;
    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
    const dx = buffer2(input2.shape, "float32");
    const dyBuf = backend2.bufferSync(dy);
    for (let batch = 0; batch < convInfo.batchSize; ++batch) {
      for (let channel = 0; channel < convInfo.inChannels; ++channel) {
        for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {
          for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {
            for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {
              const dyDepthCorner = dxDepth - padFront;
              const dyRowCorner = dxRow - padTop;
              const dyColCorner = dxCol - padLeft;
              let dotProd = 0;
              for (let wDepth = 0; wDepth < effectiveFilterDepth; wDepth += dilationDepth) {
                const dyDepth = (dyDepthCorner + wDepth) / strideDepth;
                if (dyDepth < 0 || dyDepth >= convInfo.outDepth || Math.floor(dyDepth) !== dyDepth) {
                  continue;
                }
                for (let wRow = 0; wRow < effectiveFilterHeight; wRow += dilationHeight) {
                  const dyRow = (dyRowCorner + wRow) / strideHeight;
                  if (dyRow < 0 || dyRow >= convInfo.outHeight || Math.floor(dyRow) !== dyRow) {
                    continue;
                  }
                  for (let wCol = 0; wCol < effectiveFilterWidth; wCol += dilationWidth) {
                    const dyCol = (dyColCorner + wCol) / strideWidth;
                    if (dyCol < 0 || dyCol >= convInfo.outWidth || Math.floor(dyCol) !== dyCol) {
                      continue;
                    }
                    const maxPos = effectiveFilterDepth * effectiveFilterHeight * effectiveFilterWidth - 1 - maxPosBuf.get(batch, dyDepth, dyRow, dyCol, channel);
                    const curPos = wDepth * effectiveFilterHeight * effectiveFilterWidth + wRow * effectiveFilterWidth + wCol;
                    const mask = maxPos === curPos ? 1 : 0;
                    if (mask === 0) {
                      continue;
                    }
                    const pixel = dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);
                    dotProd += pixel * mask;
                  }
                }
              }
              dx.set(dotProd, batch, dxDepth, dxRow, dxCol, channel);
            }
          }
        }
      }
    }
    return backend2.makeTensorInfo(dx.shape, dx.dtype, dx.values);
  }
  var maxPool3DGradConfig2 = {
    kernelName: MaxPool3DGrad,
    backendName: "cpu",
    kernelFunc: maxPool3DGrad
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPoolGrad.js
  function maxPoolGrad2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { dy, input: input2, output } = inputs;
    const x = input2;
    assertNotComplex([input2, output], "maxPoolGrad");
    const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
    const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, 1, pad2, dimRoundingMode);
    const xValues = backend2.data.get(x.dataId).values;
    const maxPosBuf = buffer2(convInfo.outShape, x.dtype, maxPoolPositions(xValues, x.shape, x.dtype, convInfo).values);
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
    const dx = buffer2(x.shape, "float32");
    const dyData = backend2.data.get(dy.dataId).values;
    const dyBuf = buffer2(dy.shape, "float32", dyData);
    for (let b = 0; b < convInfo.batchSize; ++b) {
      for (let d = 0; d < convInfo.inChannels; ++d) {
        for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {
          for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {
            const dyRCorner = dxR - padTop;
            const dyCCorner = dxC - padLeft;
            let dotProd = 0;
            for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {
              const dyR = (dyRCorner + wR) / strideHeight;
              if (dyR < 0 || dyR >= convInfo.outHeight || Math.floor(dyR) !== dyR) {
                continue;
              }
              for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {
                const dyC = (dyCCorner + wC) / strideWidth;
                if (dyC < 0 || dyC >= convInfo.outWidth || Math.floor(dyC) !== dyC) {
                  continue;
                }
                const maxPos = effectiveFilterHeight * effectiveFilterWidth - 1 - maxPosBuf.get(b, dyR, dyC, d);
                const curPos = wR * effectiveFilterWidth + wC;
                const mask = maxPos === curPos ? 1 : 0;
                if (mask === 0) {
                  continue;
                }
                const pixel = dyBuf.get(b, dyR, dyC, d);
                dotProd += pixel * mask;
              }
            }
            dx.set(dotProd, b, dxR, dxC, d);
          }
        }
      }
    }
    return backend2.makeTensorInfo(dx.shape, dx.dtype, dx.values);
  }
  var maxPoolGradConfig2 = {
    kernelName: MaxPoolGrad,
    backendName: "cpu",
    kernelFunc: maxPoolGrad2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPoolWithArgmax_impl.js
  function maxPoolWithArgmaxImpl(xValues, xShape, dtype, includeBatchInIndex, convInfo) {
    const strides = util_exports.computeStrides(xShape);
    const maxPools = pool2(xValues, xShape, dtype, strides, convInfo, "max");
    const maxPositions = maxPoolPositions(xValues, xShape, dtype, convInfo, true, includeBatchInIndex);
    return [maxPools.values, maxPositions.values];
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPoolWithArgmax.js
  var maxPoolWithArgmaxConfig = {
    kernelName: MaxPoolWithArgmax,
    backendName: "cpu",
    kernelFunc: ({ inputs, attrs, backend: backend2 }) => {
      const { x } = inputs;
      const { filterSize, strides, pad: pad2, includeBatchInIndex } = attrs;
      const cpuBackend = backend2;
      assertNotComplex(x, "MaxPoolWithArgmax");
      const values = cpuBackend.data.get(x.dataId).values;
      const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, [1, 1], pad2);
      const [pooled, indexes] = maxPoolWithArgmaxImpl(values, x.shape, x.dtype, includeBatchInIndex, convInfo);
      const pooledDataId = cpuBackend.write(pooled, convInfo.outShape, x.dtype);
      const indexesDataId = cpuBackend.write(indexes, convInfo.outShape, x.dtype);
      return [
        { dataId: pooledDataId, shape: convInfo.outShape, dtype: x.dtype },
        { dataId: indexesDataId, shape: convInfo.outShape, dtype: "int32" }
      ];
    }
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Mean.js
  function mean2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { axis, keepDims } = attrs;
    const axes = util_exports.parseAxisParam(axis, x.shape);
    const shapes = backend_util_exports.computeOutAndReduceShapes(x.shape, axes);
    const reduceShape = shapes[1];
    const reduceSize = util_exports.sizeFromShape(reduceShape);
    const toDispose = [];
    const reduceSizeScalar = backend2.makeTensorInfo([], "float32", new Float32Array([reduceSize]));
    toDispose.push(reduceSizeScalar);
    const $x = cast3({ inputs: { x }, backend: backend2, attrs: { dtype: "float32" } });
    toDispose.push($x);
    const res = div2({ inputs: { a: $x, b: reduceSizeScalar }, backend: backend2 });
    toDispose.push(res);
    const result = sum3({ inputs: { x: res }, backend: backend2, attrs: { axis, keepDims } });
    toDispose.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
    return result;
  }
  var meanConfig = {
    kernelName: Mean,
    backendName: "cpu",
    kernelFunc: mean2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Min.js
  function min3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { axis, keepDims } = attrs;
    assertNotComplex(x, "min");
    const origAxes = util_exports.parseAxisParam(axis, x.shape);
    let axes = origAxes;
    const permutedAxes = backend_util_exports.getAxesPermutation(axes, x.shape.length);
    let $x = x;
    if (permutedAxes != null) {
      $x = transpose2({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
      axes = backend_util_exports.getInnerMostAxes(axes.length, x.shape.length);
    }
    backend_util_exports.assertAxesAreInnerMostDims("min", axes, $x.shape.length);
    const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes($x.shape, axes);
    const reduceSize = util_exports.sizeFromShape(reduceShape);
    const vals = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(outShape), $x.dtype);
    const aVals = backend2.data.get($x.dataId).values;
    for (let i = 0; i < vals.length; ++i) {
      const offset = i * reduceSize;
      let min5 = aVals[offset];
      for (let j = 0; j < reduceSize; ++j) {
        const value = aVals[offset + j];
        if (Number.isNaN(value) || value < min5) {
          min5 = value;
        }
      }
      vals[i] = min5;
    }
    if (permutedAxes != null) {
      backend2.disposeIntermediateTensorInfo($x);
    }
    const result = backend2.makeTensorInfo(outShape, $x.dtype, vals);
    if (keepDims) {
      const expandedShape = backend_util_exports.expandShapeToKeepDim(outShape, origAxes);
      const reshapedResult = reshape2({ inputs: { x: result }, backend: backend2, attrs: { shape: expandedShape } });
      backend2.disposeIntermediateTensorInfo(result);
      return reshapedResult;
    }
    return result;
  }
  var minConfig = {
    kernelName: Min,
    backendName: "cpu",
    kernelFunc: min3
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MirrorPad.js
  function mirrorPad2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { paddings, mode } = attrs;
    assertNotComplex(x, "mirrorPad");
    const outShape = paddings.map((p3, i) => p3[0] + x.shape[i] + p3[1]);
    const start = paddings.map((p3) => p3[0]);
    const end = paddings.map((p3, i) => p3[0] + x.shape[i]);
    const offset = mode === "reflect" ? 0 : 1;
    const xVals = backend2.data.get(x.dataId).values;
    const xRank = x.shape.length;
    const xStrides = util_exports.computeStrides(x.shape);
    const resultSize = util_exports.sizeFromShape(outShape);
    const resultRank = outShape.length;
    const resultStrides = util_exports.computeStrides(outShape);
    const resVals = util_exports.getTypedArrayFromDType(x.dtype, resultSize);
    for (let i = 0; i < resultSize; i++) {
      let coords2 = util_exports.indexToLoc(i, resultRank, resultStrides);
      for (let i2 = 0; i2 < resultRank; i2++) {
        if (coords2[i2] < start[i2]) {
          coords2[i2] = start[i2] * 2 - coords2[i2] - offset;
        } else if (coords2[i2] >= end[i2]) {
          coords2[i2] = (end[i2] - 1) * 2 - coords2[i2] + offset;
        }
      }
      coords2 = coords2.map((c, i2) => c - start[i2]);
      const inIndex = util_exports.locToIndex(coords2, xRank, xStrides);
      resVals[i] = xVals[inIndex];
    }
    const outId = backend2.write(resVals, outShape, x.dtype);
    return { dataId: outId, shape: outShape, dtype: x.dtype };
  }
  var mirrorPadConfig = {
    kernelName: MirrorPad,
    backendName: "cpu",
    kernelFunc: mirrorPad2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Mod.js
  var modImpl = createSimpleBinaryKernelImpl((aValue, bValue) => {
    const rem = aValue % bValue;
    if (aValue < 0 && bValue < 0 || aValue >= 0 && bValue >= 0) {
      return rem;
    } else {
      return (rem + bValue) % bValue;
    }
  });
  var mod2 = binaryKernelFunc(Mod, modImpl);
  var modConfig = {
    kernelName: Mod,
    backendName: "cpu",
    kernelFunc: mod2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Multinomial.js
  var seedrandom4 = __toModule(require_seedrandom6());

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Softmax.js
  function softmax2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { logits } = inputs;
    const { dim } = attrs;
    const logitsRank = logits.shape.length;
    let $dim = dim;
    if ($dim === -1) {
      $dim = logitsRank - 1;
    }
    if ($dim !== logitsRank - 1) {
      throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${logitsRank} and dim was ${$dim}`);
    }
    const axes = util_exports.parseAxisParam([$dim], logits.shape);
    const maxLogit = max3({
      inputs: { x: logits },
      backend: backend2,
      attrs: { reductionIndices: axes, keepDims: false }
    });
    const expandedShape = backend_util_exports.expandShapeToKeepDim(maxLogit.shape, axes);
    const maxLogitReshaped = reshape2({ inputs: { x: maxLogit }, backend: backend2, attrs: { shape: expandedShape } });
    const a = sub2({ inputs: { a: logits, b: maxLogitReshaped }, backend: backend2 });
    const b = exp2({ inputs: { x: a }, backend: backend2 });
    const sumExp = sum3({ inputs: { x: b }, backend: backend2, attrs: { axis: axes, keepDims: false } });
    const sumReshaped = reshape2({ inputs: { x: sumExp }, backend: backend2, attrs: { shape: expandedShape } });
    const result = div2({ inputs: { a: b, b: sumReshaped }, backend: backend2 });
    backend2.disposeIntermediateTensorInfo(maxLogit);
    backend2.disposeIntermediateTensorInfo(maxLogitReshaped);
    backend2.disposeIntermediateTensorInfo(a);
    backend2.disposeIntermediateTensorInfo(b);
    backend2.disposeIntermediateTensorInfo(sumExp);
    backend2.disposeIntermediateTensorInfo(sumReshaped);
    return result;
  }
  var softmaxConfig = {
    kernelName: Softmax,
    backendName: "cpu",
    kernelFunc: softmax2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Multinomial.js
  function multinomial(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { logits } = inputs;
    const { numSamples, seed, normalized } = attrs;
    assertNotComplex(logits, "multinomial");
    const probabilities = normalized ? logits : softmax2({ inputs: { logits }, backend: backend2, attrs: { dim: -1 } });
    const batchSize = probabilities.shape[0];
    const numEvents = probabilities.shape[1];
    const probVals = backend2.data.get(probabilities.dataId).values;
    const resShape = [batchSize, numSamples];
    const resVals = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(resShape), "int32");
    for (let b = 0; b < batchSize; ++b) {
      const offset = b * numEvents;
      const cdf = new Float32Array(numEvents - 1);
      cdf[0] = probVals[offset];
      for (let event = 1; event < cdf.length; ++event) {
        cdf[event] = cdf[event - 1] + probVals[offset + event];
      }
      const random = seedrandom4.alea(seed.toString());
      const outOffset = b * numSamples;
      for (let sampleId = 0; sampleId < numSamples; ++sampleId) {
        const r = random();
        resVals[outOffset + sampleId] = cdf.length;
        for (let event = 0; event < cdf.length; event++) {
          if (r < cdf[event]) {
            resVals[outOffset + sampleId] = event;
            break;
          }
        }
      }
    }
    if (!normalized) {
      backend2.disposeIntermediateTensorInfo(probabilities);
    }
    return backend2.makeTensorInfo(resShape, "int32", resVals);
  }
  var multinomialConfig = {
    kernelName: Multinomial,
    backendName: "cpu",
    kernelFunc: multinomial
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/NonMaxSuppressionV3.js
  var nonMaxSuppressionV3Impl2 = kernel_impls_exports.nonMaxSuppressionV3Impl;
  function nonMaxSuppressionV3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { boxes, scores } = inputs;
    const { maxOutputSize, iouThreshold, scoreThreshold } = attrs;
    assertNotComplex(boxes, "NonMaxSuppression");
    const boxesVals = backend2.data.get(boxes.dataId).values;
    const scoresVals = backend2.data.get(scores.dataId).values;
    const { selectedIndices } = nonMaxSuppressionV3Impl2(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);
    return backend2.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices));
  }
  var nonMaxSuppressionV3Config = {
    kernelName: NonMaxSuppressionV3,
    backendName: "cpu",
    kernelFunc: nonMaxSuppressionV3
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/NonMaxSuppressionV4.js
  var nonMaxSuppressionV4Impl2 = kernel_impls_exports.nonMaxSuppressionV4Impl;
  function nonMaxSuppressionV4(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { boxes, scores } = inputs;
    const { maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize } = attrs;
    assertNotComplex(boxes, "NonMaxSuppressionPadded");
    const boxesVals = backend2.data.get(boxes.dataId).values;
    const scoresVals = backend2.data.get(scores.dataId).values;
    const { selectedIndices, validOutputs } = nonMaxSuppressionV4Impl2(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize);
    return [
      backend2.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices)),
      backend2.makeTensorInfo([], "int32", new Int32Array([validOutputs]))
    ];
  }
  var nonMaxSuppressionV4Config = {
    kernelName: NonMaxSuppressionV4,
    backendName: "cpu",
    kernelFunc: nonMaxSuppressionV4
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/NonMaxSuppressionV5.js
  var nonMaxSuppressionV5Impl2 = kernel_impls_exports.nonMaxSuppressionV5Impl;
  function nonMaxSuppressionV5(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { boxes, scores } = inputs;
    const { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma } = attrs;
    assertNotComplex(boxes, "NonMaxSuppressionWithScore");
    const boxesVals = backend2.data.get(boxes.dataId).values;
    const scoresVals = backend2.data.get(scores.dataId).values;
    const maxOutputSizeVal = maxOutputSize;
    const iouThresholdVal = iouThreshold;
    const scoreThresholdVal = scoreThreshold;
    const softNmsSigmaVal = softNmsSigma;
    const { selectedIndices, selectedScores } = nonMaxSuppressionV5Impl2(boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal, scoreThresholdVal, softNmsSigmaVal);
    return [
      backend2.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices)),
      backend2.makeTensorInfo([selectedScores.length], "float32", new Float32Array(selectedScores))
    ];
  }
  var nonMaxSuppressionV5Config = {
    kernelName: NonMaxSuppressionV5,
    backendName: "cpu",
    kernelFunc: nonMaxSuppressionV5
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/OneHot.js
  function oneHot2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { indices } = inputs;
    const { depth, onValue, offValue } = attrs;
    assertNotComplex(indices, "oneHot");
    const indicesSize = util_exports.sizeFromShape(indices.shape);
    const res = new Float32Array(indicesSize * depth);
    res.fill(offValue);
    const indicesVal = backend2.data.get(indices.dataId).values;
    for (let event = 0; event < indicesSize; ++event) {
      if (indicesVal[event] >= 0 && indicesVal[event] < depth) {
        res[event * depth + indicesVal[event]] = onValue;
      }
    }
    return backend2.makeTensorInfo([...indices.shape, depth], "int32", res);
  }
  var oneHotConfig = {
    kernelName: OneHot,
    backendName: "cpu",
    kernelFunc: oneHot2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ZerosLike.js
  function zerosLike2(args) {
    const { inputs, backend: backend2 } = args;
    const { x } = inputs;
    if (x.dtype === "string") {
      throw new Error("zerosLike is not supported for string tensors");
    } else if (x.dtype === "complex64") {
      const realPart = real2({ inputs: { input: x }, backend: backend2 });
      const r = zerosLike2({ inputs: { x: realPart }, backend: backend2 });
      const imagPart = imag2({ inputs: { input: x }, backend: backend2 });
      const i = zerosLike2({ inputs: { x: imagPart }, backend: backend2 });
      const result = complex2({ inputs: { real: r, imag: i }, backend: backend2 });
      backend2.disposeIntermediateTensorInfo(realPart);
      backend2.disposeIntermediateTensorInfo(r);
      backend2.disposeIntermediateTensorInfo(imagPart);
      backend2.disposeIntermediateTensorInfo(i);
      return result;
    } else {
      return fill2({ backend: backend2, attrs: { shape: x.shape, value: 0, dtype: x.dtype } });
    }
  }
  var zerosLikeConfig = {
    kernelName: ZerosLike,
    backendName: "cpu",
    kernelFunc: zerosLike2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/OnesLike.js
  function onesLike2(args) {
    const { inputs, backend: backend2 } = args;
    const { x } = inputs;
    if (x.dtype === "string") {
      throw new Error("onesLike is not supported for string tensors");
    } else if (x.dtype === "complex64") {
      const realPart = real2({ inputs: { input: x }, backend: backend2 });
      const r = onesLike2({ inputs: { x: realPart }, backend: backend2 });
      const imagPart = imag2({ inputs: { input: x }, backend: backend2 });
      const i = zerosLike2({ inputs: { x: imagPart }, backend: backend2 });
      const result = complex2({ inputs: { real: r, imag: i }, backend: backend2 });
      backend2.disposeIntermediateTensorInfo(realPart);
      backend2.disposeIntermediateTensorInfo(r);
      backend2.disposeIntermediateTensorInfo(imagPart);
      backend2.disposeIntermediateTensorInfo(i);
      return result;
    } else {
      return fill2({ backend: backend2, attrs: { shape: x.shape, value: 1, dtype: x.dtype } });
    }
  }
  var onesLikeConfig = {
    kernelName: OnesLike,
    backendName: "cpu",
    kernelFunc: onesLike2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Pack.js
  function pack(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { axis } = attrs;
    if (inputs.length === 1) {
      return expandDims3({ inputs: { input: inputs[0] }, backend: backend2, attrs: { dim: axis } });
    }
    const shape = inputs[0].shape;
    const dtype = inputs[0].dtype;
    inputs.forEach((t) => {
      util_exports.assertShapesMatch(shape, t.shape, "All tensors passed to stack must have matching shapes");
      util_exports.assert(dtype === t.dtype, () => "All tensors passed to stack must have matching dtypes");
    });
    const intermediateTensorInfos = [];
    const expandedTensors = inputs.map((t) => {
      const expandedT = expandDims3({ inputs: { input: t }, backend: backend2, attrs: { dim: axis } });
      intermediateTensorInfos.push(expandedT);
      return expandedT;
    });
    const result = concat2({ inputs: expandedTensors, backend: backend2, attrs: { axis } });
    intermediateTensorInfos.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
    return result;
  }
  var packConfig = {
    kernelName: Pack,
    backendName: "cpu",
    kernelFunc: pack
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/PadV2.js
  function padV2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { paddings, constantValue } = attrs;
    assertNotComplex(x, "pad");
    const outShape = paddings.map((p3, i) => p3[0] + x.shape[i] + p3[1]);
    const start = paddings.map((p3) => p3[0]);
    const xVals = backend2.data.get(x.dataId).values;
    const xSize = util_exports.sizeFromShape(x.shape);
    const xRank = x.shape.length;
    const xStrides = util_exports.computeStrides(x.shape);
    const resultSize = util_exports.sizeFromShape(outShape);
    const resultRank = outShape.length;
    const resultStrides = util_exports.computeStrides(outShape);
    const resVals = util_exports.getTypedArrayFromDType(x.dtype, resultSize);
    if (constantValue !== 0) {
      resVals.fill(constantValue);
    }
    for (let i = 0; i < xSize; i++) {
      const coords2 = util_exports.indexToLoc(i, xRank, xStrides);
      const outCoords = coords2.map((c, i2) => c + start[i2]);
      const outIndex = util_exports.locToIndex(outCoords, resultRank, resultStrides);
      resVals[outIndex] = xVals[i];
    }
    const outId = backend2.write(resVals, outShape, x.dtype);
    return { dataId: outId, shape: outShape, dtype: x.dtype };
  }
  var padV2Config = {
    kernelName: PadV2,
    backendName: "cpu",
    kernelFunc: padV2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Pow.js
  var powImpl = createSimpleBinaryKernelImpl((a, b) => Math.pow(a, b));
  var pow2 = binaryKernelFunc(Pow, powImpl);
  var powConfig = {
    kernelName: Pow,
    backendName: "cpu",
    kernelFunc: pow2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Range.js
  function range3(args) {
    const { backend: backend2, attrs } = args;
    const { start, stop: stop2, dtype, step: step4 } = attrs;
    const values = rangeImpl(start, stop2, step4, dtype);
    return backend2.makeTensorInfo([values.length], dtype, values);
  }
  var rangeConfig = {
    kernelName: Range,
    backendName: "cpu",
    kernelFunc: range3
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Reciprocal.js
  var reciprocal2 = unaryKernelFunc(Reciprocal, (xi) => 1 / xi);
  var reciprocalConfig = {
    kernelName: Reciprocal,
    backendName: "cpu",
    kernelFunc: reciprocal2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeBilinear.js
  function resizeBilinear2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { images } = inputs;
    const { alignCorners, halfPixelCenters, size: size2 } = attrs;
    assertNotComplex(images, "resizeBilinear");
    const imagesStrides = util_exports.computeStrides(images.shape);
    const [newHeight, newWidth] = size2;
    const [batch, oldHeight, oldWidth, numChannels] = images.shape;
    const xValues = backend2.data.get(images.dataId).values;
    const result = new Float32Array(util_exports.sizeFromShape([batch, newHeight, newWidth, numChannels]));
    const effectiveInputSize = [
      alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
      alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
    ];
    const effectiveOutputSize = [
      alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
      alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
    ];
    let outputIdx = 0;
    const effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];
    const effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];
    for (let b = 0; b < batch; b++) {
      for (let r = 0; r < newHeight; r++) {
        let sourceFracRow;
        if (halfPixelCenters) {
          sourceFracRow = effectiveRowSizeRatio * (r + 0.5) - 0.5;
        } else {
          sourceFracRow = effectiveRowSizeRatio * r;
        }
        const sourceRowFloor = Math.max(0, Math.floor(sourceFracRow));
        const rowFrac = sourceFracRow - sourceRowFloor;
        const sourceRowCeil = Math.min(oldHeight - 1, Math.ceil(sourceFracRow));
        const topRowOffset = b * imagesStrides[0] + sourceRowFloor * imagesStrides[1];
        const botRowOffset = b * imagesStrides[0] + sourceRowCeil * imagesStrides[1];
        for (let c = 0; c < newWidth; c++) {
          let sourceFracCol;
          if (halfPixelCenters) {
            sourceFracCol = effectiveColSizeRatio * (c + 0.5) - 0.5;
          } else {
            sourceFracCol = effectiveColSizeRatio * c;
          }
          const sourceColFloor = Math.max(0, Math.floor(sourceFracCol));
          const colFrac = sourceFracCol - sourceColFloor;
          const sourceColCeil = Math.min(oldWidth - 1, Math.ceil(sourceFracCol));
          const topLeftOffest = topRowOffset + sourceColFloor * imagesStrides[2];
          const botLeftOffset = botRowOffset + sourceColFloor * imagesStrides[2];
          const topRightOffset = topRowOffset + sourceColCeil * imagesStrides[2];
          const botRightOffest = botRowOffset + sourceColCeil * imagesStrides[2];
          for (let d = 0; d < numChannels; d++) {
            const topLeft = xValues[topLeftOffest + d];
            const bottomLeft = xValues[botLeftOffset + d];
            const topRight = xValues[topRightOffset + d];
            const bottomRight = xValues[botRightOffest + d];
            const top = topLeft + (topRight - topLeft) * colFrac;
            const bottom = bottomLeft + (bottomRight - bottomLeft) * colFrac;
            const newValue = top + (bottom - top) * rowFrac;
            result[outputIdx++] = newValue;
          }
        }
      }
    }
    return backend2.makeTensorInfo([batch, newHeight, newWidth, numChannels], "float32", result);
  }
  var resizeBilinearConfig = {
    kernelName: ResizeBilinear,
    backendName: "cpu",
    kernelFunc: resizeBilinear2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeBilinearGrad.js
  function resizeBilinearGrad(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { images, dy } = inputs;
    const { alignCorners } = attrs;
    assertNotComplex([dy, images], "resizeBilinearGrad");
    const imagesStrides = util_exports.computeStrides(images.shape);
    const [batch, xHeight, xWidth, depth] = images.shape;
    const [, yHeight, yWidth] = dy.shape;
    const output = new Float32Array(batch * xHeight * xWidth * depth);
    const effectiveXSize = [
      alignCorners && yHeight > 1 ? xHeight - 1 : xHeight,
      alignCorners && yWidth > 1 ? xWidth - 1 : xWidth
    ];
    const effectiveYSize = [
      alignCorners && yHeight > 1 ? yHeight - 1 : yHeight,
      alignCorners && yWidth > 1 ? yWidth - 1 : yWidth
    ];
    const heightScale = effectiveXSize[0] / effectiveYSize[0];
    const widthScale = effectiveXSize[1] / effectiveYSize[1];
    const dyValues = backend2.data.get(dy.dataId).values;
    let offset = 0;
    for (let b = 0; b < batch; b++) {
      const bOffset = b * imagesStrides[0];
      for (let r = 0; r < yHeight; r++) {
        const dxR = r * heightScale;
        const topDxRIndex = Math.floor(dxR);
        const bottomDxRIndex = Math.min(Math.ceil(dxR), xHeight - 1);
        const topDxROffset = bOffset + topDxRIndex * imagesStrides[1];
        const bottomDxROffset = bOffset + bottomDxRIndex * imagesStrides[1];
        const dxRLerp = dxR - topDxRIndex;
        const inverseDxRLerp = 1 - dxRLerp;
        for (let c = 0; c < yWidth; c++) {
          const dxC = c * widthScale;
          const leftDxCIndex = Math.floor(dxC);
          const rightDxCIndex = Math.min(Math.ceil(dxC), xWidth - 1);
          const dxCLerp = dxC - leftDxCIndex;
          const inverseDxCLerp = 1 - dxCLerp;
          const topLeftRCOffset = topDxROffset + leftDxCIndex * imagesStrides[2];
          const topRightRCOffset = topDxROffset + rightDxCIndex * imagesStrides[2];
          const bottomLeftRCOffset = bottomDxROffset + leftDxCIndex * imagesStrides[2];
          const bottomRightRCOffset = bottomDxROffset + rightDxCIndex * imagesStrides[2];
          const inverseDxRLerpTimesInverseDxCLerp = inverseDxRLerp * inverseDxCLerp;
          const inverseDxRLerpTimesDxCLerp = inverseDxRLerp * dxCLerp;
          const dxRLerpTimesInverseDxCLerp = dxRLerp * inverseDxCLerp;
          const dxRLerpTimesDxCLerp = dxRLerp * dxCLerp;
          for (let d = 0; d < depth; d++) {
            const dyVal = dyValues[offset++];
            output[topLeftRCOffset + d] += dyVal * inverseDxRLerpTimesInverseDxCLerp;
            output[topRightRCOffset + d] += dyVal * inverseDxRLerpTimesDxCLerp;
            output[bottomLeftRCOffset + d] += dyVal * dxRLerpTimesInverseDxCLerp;
            output[bottomRightRCOffset + d] += dyVal * dxRLerpTimesDxCLerp;
          }
        }
      }
    }
    return backend2.makeTensorInfo([batch, xWidth, xHeight, depth], "float32", output);
  }
  var resizeBilinearGradConfig2 = {
    kernelName: ResizeBilinearGrad,
    backendName: "cpu",
    kernelFunc: resizeBilinearGrad
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeNearestNeighbor.js
  function resizeNearestNeighbor2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { images } = inputs;
    const { alignCorners, halfPixelCenters, size: size2 } = attrs;
    assertNotComplex(images, "resizeNearestNeighbor");
    const imagesStrides = util_exports.computeStrides(images.shape);
    const [newHeight, newWidth] = size2;
    const [batch, oldHeight, oldWidth, numChannels] = images.shape;
    const xValues = backend2.data.get(images.dataId).values;
    const output = new Float32Array(batch * newHeight * newWidth * numChannels);
    const effectiveInputSize = [
      alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
      alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
    ];
    const effectiveOutputSize = [
      alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
      alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
    ];
    const effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];
    const effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];
    let outputOffset = 0;
    for (let b = 0; b < batch; b++) {
      const batchOffset = b * imagesStrides[0];
      for (let r = 0; r < newHeight; r++) {
        const sourceFracRow = halfPixelCenters ? effectiveRowSizeRatio * (r + 0.5) : effectiveRowSizeRatio * r;
        let sourceNearestRow = Math.min(oldHeight - 1, alignCorners ? Math.round(sourceFracRow) : Math.floor(sourceFracRow));
        if (halfPixelCenters) {
          sourceNearestRow = Math.max(0, sourceNearestRow);
        }
        const rowOffset = batchOffset + sourceNearestRow * imagesStrides[1];
        for (let c = 0; c < newWidth; c++) {
          const sourceFracCol = halfPixelCenters ? effectiveColSizeRatio * (c + 0.5) : effectiveColSizeRatio * c;
          let sourceNearestCol = Math.min(oldWidth - 1, alignCorners ? Math.round(sourceFracCol) : Math.floor(sourceFracCol));
          if (halfPixelCenters) {
            sourceNearestCol = Math.max(0, sourceNearestCol);
          }
          const colOffset = rowOffset + sourceNearestCol * imagesStrides[2];
          for (let d = 0; d < numChannels; d++) {
            const newVal = xValues[colOffset + d];
            output[outputOffset++] = newVal;
          }
        }
      }
    }
    return backend2.makeTensorInfo([batch, newHeight, newWidth, numChannels], images.dtype, output);
  }
  var resizeNearestNeighborConfig = {
    kernelName: ResizeNearestNeighbor,
    backendName: "cpu",
    kernelFunc: resizeNearestNeighbor2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeNearestNeighborGrad.js
  function resizeNearestNeighborGrad(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { images, dy } = inputs;
    const { alignCorners } = attrs;
    assertNotComplex([dy, images], "resizeNearestNeighborGrad");
    const imagesStrides = util_exports.computeStrides(images.shape);
    const dyStrides = util_exports.computeStrides(dy.shape);
    const [batch, xHeight, xWidth, depth] = images.shape;
    const [, yHeight, yWidth] = dy.shape;
    const output = new Float32Array(batch * xHeight * xWidth * depth);
    const dyValues = backend2.data.get(dy.dataId).values;
    const effectiveXSize = [
      alignCorners && yHeight > 1 ? xHeight - 1 : xHeight,
      alignCorners && yWidth > 1 ? xWidth - 1 : xWidth
    ];
    const effectiveYSize = [
      alignCorners && yHeight > 1 ? yHeight - 1 : yHeight,
      alignCorners && yWidth > 1 ? yWidth - 1 : yWidth
    ];
    const heightScale = effectiveXSize[0] / effectiveYSize[0];
    const widthScale = effectiveXSize[1] / effectiveYSize[1];
    const invHeightScale = 1 / heightScale;
    const invWidthScale = 1 / widthScale;
    const winHeight = Math.ceil(invHeightScale) * 2 + 2;
    const winWidth = Math.ceil(invWidthScale) * 2 + 2;
    for (let b = 0; b < batch; b++) {
      const batchOffset = b * imagesStrides[0];
      for (let r = 0; r < xHeight; r++) {
        const rowOffset = batchOffset + r * imagesStrides[1];
        const startRLerp = Math.floor(r * invHeightScale);
        const startDyR = Math.floor(startRLerp - winHeight / 2);
        for (let c = 0; c < xWidth; c++) {
          const colOffset = rowOffset + c * imagesStrides[2];
          const startCLerp = Math.floor(c * invWidthScale);
          const startDyC = Math.floor(startCLerp - winWidth / 2);
          for (let d = 0; d < depth; d++) {
            let accum = 0;
            for (let dyRIndex = 0; dyRIndex < winHeight; dyRIndex++) {
              const dyR = dyRIndex + startDyR;
              if (dyR < 0 || dyR >= yHeight) {
                continue;
              }
              const dyROffset = batchOffset + dyR * dyStrides[1];
              const sourceFracRow = dyR * heightScale;
              const sourceNearestRow = Math.min(xHeight - 1, alignCorners ? Math.round(sourceFracRow) : Math.floor(sourceFracRow));
              if (r !== sourceNearestRow) {
                continue;
              }
              for (let dyCIndex = 0; dyCIndex < winWidth; dyCIndex++) {
                const dyC = dyCIndex + startDyC;
                if (dyC < 0 || dyC >= yWidth) {
                  continue;
                }
                const dyCOffset = dyROffset + dyC * dyStrides[2];
                const sourceFracCol = dyC * widthScale;
                const sourceNearestCol = Math.min(xWidth - 1, alignCorners ? Math.round(sourceFracCol) : Math.floor(sourceFracCol));
                if (c === sourceNearestCol) {
                  accum += dyValues[dyCOffset + d];
                }
              }
            }
            output[colOffset + d] = accum;
          }
        }
      }
    }
    return backend2.makeTensorInfo(images.shape, images.dtype, output);
  }
  var resizeNearestNeighborGradConfig2 = {
    kernelName: ResizeNearestNeighborGrad,
    backendName: "cpu",
    kernelFunc: resizeNearestNeighborGrad
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Reverse.js
  function reverse2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { dims } = attrs;
    assertNotComplex(x, "reverse");
    const xRank = x.shape.length;
    const $dims = util_exports.parseAxisParam(dims, x.shape);
    if (xRank === 0) {
      return identity({ inputs: { x }, backend: backend2 });
    }
    const outBuf = new TensorBuffer(x.shape, x.dtype);
    const xBuf = backend2.bufferSync(x);
    for (let i = 0; i < outBuf.size; i++) {
      const outLoc = outBuf.indexToLoc(i);
      const inLoc = outLoc.slice();
      $dims.forEach((d) => inLoc[d] = x.shape[d] - 1 - inLoc[d]);
      outBuf.set(xBuf.get(...inLoc), ...outLoc);
    }
    return backend2.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
  }
  var reverseConfig = {
    kernelName: Reverse,
    backendName: "cpu",
    kernelFunc: reverse2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RotateWithOffset.js
  var rotateWithOffsetConfig = {
    kernelName: RotateWithOffset,
    backendName: "cpu",
    kernelFunc: ({ inputs, attrs, backend: backend2 }) => {
      const { image: image3 } = inputs;
      const { radians, fillValue, center } = attrs;
      const cpuBackend = backend2;
      const output = util_exports.getTypedArrayFromDType(image3.dtype, util_exports.sizeFromShape(image3.shape));
      const [batch, imageHeight, imageWidth, numChannels] = image3.shape;
      const [centerX, centerY] = backend_util_exports.getImageCenter(center, imageHeight, imageWidth);
      const fullOpacityValue = 255;
      const sinFactor = Math.sin(radians);
      const cosFactor = Math.cos(radians);
      const imageVals = cpuBackend.data.get(image3.dataId).values;
      for (let batchIdx = 0; batchIdx < batch; batchIdx++) {
        const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;
        for (let row = 0; row < imageHeight; row++) {
          const rowOffset = row * (imageWidth * numChannels);
          for (let col = 0; col < imageWidth; col++) {
            const colOffset = col * numChannels;
            for (let channel = 0; channel < numChannels; channel++) {
              const coords2 = [batch, row, col, channel];
              const x = coords2[2];
              const y = coords2[1];
              let coordX = (x - centerX) * cosFactor - (y - centerY) * sinFactor;
              let coordY = (x - centerX) * sinFactor + (y - centerY) * cosFactor;
              coordX = Math.round(coordX + centerX);
              coordY = Math.round(coordY + centerY);
              let outputValue = fillValue;
              if (typeof fillValue !== "number") {
                if (channel === 3) {
                  outputValue = fullOpacityValue;
                } else {
                  outputValue = fillValue[channel];
                }
              }
              if (coordX >= 0 && coordX < imageWidth && coordY >= 0 && coordY < imageHeight) {
                const rotatedRowOffset = coordY * (imageWidth * numChannels);
                const rotatedColOffset = coordX * numChannels;
                const imageIdx = batchOffset + rotatedRowOffset + rotatedColOffset + channel;
                outputValue = imageVals[imageIdx];
              }
              const outIdx = batchOffset + rowOffset + colOffset + channel;
              output[outIdx] = outputValue;
            }
          }
        }
      }
      const dataId = cpuBackend.write(output, image3.shape, image3.dtype);
      return { dataId, shape: image3.shape, dtype: image3.dtype };
    }
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Round.js
  var round3 = unaryKernelFunc(Round, (xi) => {
    const base2 = Math.floor(xi);
    if (xi - base2 < 0.5) {
      return Math.floor(xi);
    } else if (xi - base2 > 0.5) {
      return Math.ceil(xi);
    } else {
      if (base2 % 2 === 0) {
        return base2;
      } else {
        return base2 + 1;
      }
    }
  });
  var roundConfig = {
    kernelName: Round,
    backendName: "cpu",
    kernelFunc: round3
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Scatter_impl.js
  function scatterImpl(indices, updates, shape, outputSize, sliceSize, numUpdates, sliceRank, strides, defaultValue, sumDupeIndices) {
    const flattenShape = [outputSize / sliceSize, sliceSize];
    const indicesData = indices.values;
    const updatesData = updates.values;
    if (outputSize === 0) {
      return buffer2(shape, updates.dtype);
    }
    const outBuf = buffer2(flattenShape, updates.dtype);
    outBuf.values.fill(defaultValue);
    for (let i = 0; i < numUpdates; i++) {
      const index = [];
      let flattenIndex = 0;
      for (let j = 0; j < sliceRank; j++) {
        const dim = indicesData[i * sliceRank + j];
        index.push(dim);
        flattenIndex += dim * strides[j];
      }
      if (flattenIndex < 0 || flattenIndex >= outputSize / sliceSize) {
        throw new Error(`Invalid indices: ${index} does not index into ${shape}`);
      }
      for (let k = 0; k < sliceSize; k++) {
        if (sumDupeIndices) {
          outBuf.values[flattenIndex * sliceSize + k] += updatesData[i * sliceSize + k];
        } else {
          outBuf.values[flattenIndex * sliceSize + k] = updates.rank === 0 ? updatesData[0] : updatesData[i * sliceSize + k];
        }
      }
    }
    return outBuf;
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ScatterNd.js
  function scatterNd(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { indices, updates } = inputs;
    const { shape } = attrs;
    const { sliceRank, numUpdates, sliceSize, strides, outputSize } = backend_util_exports.calculateShapes(updates, indices, shape);
    const sumDupeIndices = true;
    const indicesBuf = backend2.bufferSync(indices);
    const updatesBuf = backend2.bufferSync(updates);
    const outBuf = scatterImpl(indicesBuf, updatesBuf, shape, outputSize, sliceSize, numUpdates, sliceRank, strides, 0, sumDupeIndices);
    return backend2.makeTensorInfo(shape, outBuf.dtype, outBuf.values);
  }
  var scatterNdConfig = {
    kernelName: ScatterNd,
    backendName: "cpu",
    kernelFunc: scatterNd
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Select.js
  function select2(args) {
    const { inputs, backend: backend2 } = args;
    const { condition, t, e } = inputs;
    assertNotComplex([condition, t, e], "select");
    const conditionRank = condition.shape.length;
    const values = backend2.data.get(condition.dataId).values;
    const tValues = backend2.data.get(t.dataId).values;
    const eValues = backend2.data.get(e.dataId).values;
    const resultDtype = upcastType(t.dtype, e.dtype);
    const newValues = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(t.shape), resultDtype);
    let index = 0;
    const offset = conditionRank === 0 || conditionRank > 1 || t.shape.length === 1 ? 1 : util_exports.sizeFromShape(t.shape.slice(1));
    for (let i = 0; i < values.length; i++) {
      for (let j = 0; j < offset; j++) {
        if (values[i] === 1) {
          newValues[index++] = tValues[i];
        } else {
          newValues[index++] = eValues[i];
        }
      }
    }
    return backend2.makeTensorInfo(t.shape, resultDtype, newValues);
  }
  var selectConfig = {
    kernelName: Select,
    backendName: "cpu",
    kernelFunc: select2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Selu.js
  var scaleAlpha = backend_util_exports.SELU_SCALEALPHA;
  var scale = backend_util_exports.SELU_SCALE;
  var selu2 = unaryKernelFunc(Selu, (xi) => {
    if (xi >= 0) {
      return scale * xi;
    } else {
      return scaleAlpha * (Math.exp(xi) - 1);
    }
  });
  var seluConfig = {
    kernelName: Selu,
    backendName: "cpu",
    kernelFunc: selu2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sign.js
  var sign2 = unaryKernelFunc(Sign, (xi) => {
    if (xi < 0) {
      return -1;
    } else if (xi > 0) {
      return 1;
    } else {
      return 0;
    }
  });
  var signConfig = {
    kernelName: Sign,
    backendName: "cpu",
    kernelFunc: sign2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sin.js
  var sin2 = unaryKernelFunc(Sin, (xi) => Math.sin(xi));
  var sinConfig = {
    kernelName: Sin,
    backendName: "cpu",
    kernelFunc: sin2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sinh.js
  var sinh2 = unaryKernelFunc(Sinh, (xi) => Math.sinh(xi));
  var sinhConfig = {
    kernelName: Sinh,
    backendName: "cpu",
    kernelFunc: sinh2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Softplus.js
  var epsilon2 = 11920928955078125e-23;
  var threshold2 = Math.log(epsilon2) + 2;
  var softplus2 = unaryKernelFunc(Softplus, (xi) => {
    const tooLarge = xi > -threshold2;
    const tooSmall = xi < threshold2;
    const expX = Math.exp(xi);
    let result;
    if (tooSmall) {
      result = expX;
    } else if (tooLarge) {
      result = xi;
    } else {
      result = Math.log(1 + expX);
    }
    return result;
  });
  var softplusConfig = {
    kernelName: Softplus,
    backendName: "cpu",
    kernelFunc: softplus2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SpaceToBatchND.js
  function spaceToBatchND2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { blockShape, paddings } = attrs;
    assertNotComplex([x], "spaceToBatchND");
    const prod4 = util_exports.sizeFromShape(blockShape);
    const completePaddings = [[0, 0]];
    completePaddings.push(...paddings);
    for (let i = 1 + blockShape.length; i < x.shape.length; ++i) {
      completePaddings.push([0, 0]);
    }
    const paddedX = padV2Config.kernelFunc({
      inputs: { x },
      backend: backend2,
      attrs: { paddings: completePaddings, constantValue: 0 }
    });
    const reshapedPaddedShape = backend_util_exports.getReshaped(paddedX.shape, blockShape, prod4, false);
    const permutedReshapedPaddedPermutation = backend_util_exports.getPermuted(reshapedPaddedShape.length, blockShape.length, false);
    const flattenShape = backend_util_exports.getReshapedPermuted(paddedX.shape, blockShape, prod4, false);
    const reshapeInputs = { x: paddedX };
    const reshapeAttrs = { shape: reshapedPaddedShape };
    const paddedXReshaped = reshape2({ inputs: reshapeInputs, backend: backend2, attrs: reshapeAttrs });
    const transposeInputs = { x: paddedXReshaped };
    const transposeAttrs = { perm: permutedReshapedPaddedPermutation };
    const paddedXT = transpose2({ inputs: transposeInputs, backend: backend2, attrs: transposeAttrs });
    const resultReshapeInputs = { x: paddedXT };
    const resultReshapeAttrs = { shape: flattenShape };
    const result = reshape2({ inputs: resultReshapeInputs, backend: backend2, attrs: resultReshapeAttrs });
    backend2.disposeIntermediateTensorInfo(paddedX);
    backend2.disposeIntermediateTensorInfo(paddedXReshaped);
    backend2.disposeIntermediateTensorInfo(paddedXT);
    return result;
  }
  var spaceToBatchNDConfig = {
    kernelName: SpaceToBatchND,
    backendName: "cpu",
    kernelFunc: spaceToBatchND2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseFillEmptyRows.js
  function sparseFillEmptyRows(args) {
    const { inputs, backend: backend2 } = args;
    const { indices, values, denseShape, defaultValue } = inputs;
    if (denseShape.shape.length !== 1) {
      throw new Error(`Dense shape must be a vector, saw:
        ${denseShape.shape}`);
    }
    if (indices.shape.length !== 2) {
      throw new Error(`Indices must be a matrix, saw:
        ${indices.shape}`);
    }
    if (values.shape.length !== 1) {
      throw new Error(`Values must be a vector, saw:
        ${values.shape}`);
    }
    if (defaultValue.shape.length !== 0) {
      throw new Error(`Default value must be a scalar, saw:
        ${defaultValue.shape}`);
    }
    const $indices = backend2.data.get(indices.dataId).values;
    const $values = backend2.data.get(values.dataId).values;
    const $denseShape = backend2.data.get(denseShape.dataId).values;
    const $defaultValue = backend2.data.get(defaultValue.dataId).values[0];
    const [outputIndices, outputIndicesShape, outputValues, emptyRowIndicator, reverseIndexMap] = sparseFillEmptyRowsImpl($indices, indices.shape, indices.dtype, $values, values.dtype, $denseShape, $defaultValue);
    return [
      backend2.makeTensorInfo(outputIndicesShape, indices.dtype, outputIndices),
      backend2.makeTensorInfo([outputIndicesShape[0]], values.dtype, outputValues),
      backend2.makeTensorInfo([emptyRowIndicator.length], "bool", new Uint8Array(emptyRowIndicator.map((value) => Number(value)))),
      backend2.makeTensorInfo([reverseIndexMap.length], indices.dtype, new Int32Array(reverseIndexMap))
    ];
  }
  var sparseFillEmptyRowsConfig = {
    kernelName: SparseFillEmptyRows,
    backendName: "cpu",
    kernelFunc: sparseFillEmptyRows
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseReshape.js
  function sparseReshape(args) {
    const { inputs, backend: backend2 } = args;
    const { inputIndices, inputShape, newShape } = inputs;
    if (inputIndices.shape.length !== 2) {
      throw new Error(`Input indices should be a matrix but received shape
        ${inputIndices.shape}`);
    }
    if (inputShape.shape.length !== 1) {
      throw new Error(`Input shape should be a vector but received shape
        ${inputShape.shape}`);
    }
    if (newShape.shape.length !== 1) {
      throw new Error(`Target shape should be a vector but received shape ${newShape.shape}`);
    }
    const $inputShape = Array.from(backend2.data.get(inputShape.dataId).values);
    const $inputIndices = backend2.data.get(inputIndices.dataId).values;
    const targetShape = Array.from(backend2.data.get(newShape.dataId).values);
    const [newIndices, indicesShape, outputShape] = sparseReshapeImpl($inputIndices, inputIndices.shape, inputIndices.dtype, $inputShape, targetShape);
    return [
      backend2.makeTensorInfo(indicesShape, inputIndices.dtype, newIndices),
      backend2.makeTensorInfo([outputShape.length], newShape.dtype, new Int32Array(outputShape))
    ];
  }
  var sparseReshapeConfig = {
    kernelName: SparseReshape,
    backendName: "cpu",
    kernelFunc: sparseReshape
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentMean.js
  function sparseSegmentMean(args) {
    const { inputs, backend: backend2 } = args;
    const { data, indices, segmentIds } = inputs;
    if (data.shape.length < 1) {
      throw new Error(`Data should be at least 1 dimensional but received scalar`);
    }
    if (indices.shape.length !== 1) {
      throw new Error(`Indices should be a vector but received shape
          ${indices.shape}`);
    }
    if (segmentIds.shape.length !== 1) {
      throw new Error(`Segment ids should be a vector but received shape
          ${segmentIds.shape}`);
    }
    const $data = backend2.data.get(data.dataId).values;
    const $indices = backend2.data.get(indices.dataId).values;
    const $segmentIds = backend2.data.get(segmentIds.dataId).values;
    const [outputData, outputDataShape] = sparseSegmentReductionImpl($data, data.shape, data.dtype, $indices, $segmentIds, true);
    return backend2.makeTensorInfo(outputDataShape, data.dtype, outputData);
  }
  var sparseSegmentMeanConfig = {
    kernelName: SparseSegmentMean,
    backendName: "cpu",
    kernelFunc: sparseSegmentMean
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentSum.js
  function sparseSegmentSum(args) {
    const { inputs, backend: backend2 } = args;
    const { data, indices, segmentIds } = inputs;
    if (data.shape.length < 1) {
      throw new Error(`Data should be at least 1 dimensional but received scalar`);
    }
    if (indices.shape.length !== 1) {
      throw new Error(`Indices should be a vector but received shape
         ${indices.shape}`);
    }
    if (segmentIds.shape.length !== 1) {
      throw new Error(`Segment ids should be a vector but received shape
         ${segmentIds.shape}`);
    }
    const $data = backend2.data.get(data.dataId).values;
    const $indices = backend2.data.get(indices.dataId).values;
    const $segmentIds = backend2.data.get(segmentIds.dataId).values;
    const [outputData, outputDataShape] = sparseSegmentReductionImpl($data, data.shape, data.dtype, $indices, $segmentIds);
    return backend2.makeTensorInfo(outputDataShape, data.dtype, outputData);
  }
  var sparseSegmentSumConfig = {
    kernelName: SparseSegmentSum,
    backendName: "cpu",
    kernelFunc: sparseSegmentSum
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseToDense.js
  function sparseToDense(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { sparseIndices, sparseValues, defaultValue } = inputs;
    const { outputShape } = attrs;
    const { sliceRank, numUpdates, sliceSize, strides, outputSize } = backend_util_exports.calculateShapes(sparseValues, sparseIndices, outputShape);
    const sumDupeIndices = false;
    const indicesBuf = backend2.bufferSync(sparseIndices);
    const updatesBuf = backend2.bufferSync(sparseValues);
    const $defaultValue = backend2.data.get(defaultValue.dataId).values[0];
    const outBuf = scatterImpl(indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);
    return backend2.makeTensorInfo(outputShape, outBuf.dtype, outBuf.values);
  }
  var sparseToDenseConfig = {
    kernelName: SparseToDense,
    backendName: "cpu",
    kernelFunc: sparseToDense
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SplitV.js
  function splitV(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { numOrSizeSplits, axis } = attrs;
    const $axis = util_exports.parseAxisParam(axis, x.shape)[0];
    const splitSizes = backend_util_exports.prepareSplitSize(x, numOrSizeSplits, $axis);
    const begin = new Array(x.shape.length).fill(0);
    const size2 = x.shape.slice();
    return splitSizes.map((s) => {
      const sliceSize = [...size2];
      sliceSize[$axis] = s;
      const sliceT = slice2({ inputs: { x }, backend: backend2, attrs: { begin, size: sliceSize } });
      begin[$axis] += s;
      return sliceT;
    });
  }
  var splitVConfig = {
    kernelName: SplitV,
    backendName: "cpu",
    kernelFunc: splitV
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Square.js
  var squareConfig = {
    kernelName: Square,
    backendName: "cpu",
    kernelFunc: ({ inputs, backend: backend2 }) => {
      const { x } = inputs;
      const cpuBackend = backend2;
      assertNotComplex(x, "square");
      const values = cpuBackend.data.get(x.dataId).values;
      const newValues = new Float32Array(values.length);
      for (let i = 0; i < values.length; ++i) {
        const value = values[i];
        newValues[i] = value * value;
      }
      const dataId = cpuBackend.write(newValues, x.shape, x.dtype);
      return { dataId, shape: x.shape, dtype: x.dtype };
    }
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Step.js
  var step2 = unaryKernelFunc(Step, (xi, attrs) => {
    const stepAttrs = attrs;
    if (isNaN(xi)) {
      return NaN;
    } else {
      return xi > 0 ? 1 : stepAttrs.alpha;
    }
  });
  var stepConfig = {
    kernelName: Step,
    backendName: "cpu",
    kernelFunc: step2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StridedSlice.js
  function stridedSlice2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask } = attrs;
    assertNotComplex(x, "stridedSlice");
    const { finalShapeSparse, finalShape, isIdentity, sliceDim0, isSimpleSlice, begin: $begin, end: $end, strides: $strides } = slice_util_exports.sliceInfo(x.shape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask);
    let result;
    if (isIdentity) {
      result = reshape2({ inputs: { x }, backend: backend2, attrs: { shape: finalShape } });
    } else if (sliceDim0 || isSimpleSlice) {
      util_exports.assert(x.shape.length >= 1, () => `Input must have rank at least 1, got: ${x.shape.length}`);
      const size2 = slice_util_exports.computeOutShape($begin, $end, $strides);
      const sliced = slice2({ inputs: { x }, backend: backend2, attrs: { begin: $begin, size: size2 } });
      result = reshape2({ inputs: { x: sliced }, backend: backend2, attrs: { shape: finalShape } });
      backend2.disposeIntermediateTensorInfo(sliced);
    } else {
      const xBuf = backend2.bufferSync(x);
      const outBuf = stridedSliceImpl(finalShapeSparse, xBuf, $strides, $begin);
      result = backend2.makeTensorInfo(finalShape, outBuf.dtype, outBuf.values);
    }
    return result;
  }
  var stridedSliceConfig = {
    kernelName: StridedSlice,
    backendName: "cpu",
    kernelFunc: stridedSlice2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringNGrams.js
  function stringNGrams(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { separator, nGramWidths, leftPad, rightPad: rightPad2, padWidth, preserveShortSequences } = attrs;
    const { data, dataSplits } = inputs;
    const $data = backend2.data.get(data.dataId).values;
    const $dataSplits = backend2.data.get(dataSplits.dataId).values;
    const [nGrams, nGramsSplits] = stringNGramsImpl($data, $dataSplits, separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences);
    return [
      backend2.makeTensorInfo([nGrams.length], "string", nGrams),
      backend2.makeTensorInfo(dataSplits.shape, "int32", nGramsSplits)
    ];
  }
  var stringNGramsConfig = {
    kernelName: StringNGrams,
    backendName: "cpu",
    kernelFunc: stringNGrams
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringSplit.js
  function stringSplit(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { skipEmpty } = attrs;
    const { input: input2, delimiter } = inputs;
    if (input2.dtype !== "string") {
      throw new Error("Input must be of datatype string");
    }
    if (input2.shape.length !== 1) {
      throw new Error(`Input must be a vector, got shape: ${input2.shape}`);
    }
    if (delimiter.shape.length !== 0) {
      throw new Error(`Delimiter must be a scalar, got shape: ${delimiter.shape}`);
    }
    const $input = backend2.data.get(input2.dataId).values;
    const $delimiter = backend2.data.get(delimiter.dataId).values[0];
    const [indices, values, shape] = stringSplitImpl($input, $delimiter, skipEmpty);
    const outputSize = values.length;
    return [
      backend2.makeTensorInfo([outputSize, 2], "int32", indices),
      backend2.makeTensorInfo([outputSize], "string", values),
      backend2.makeTensorInfo([2], "int32", new Int32Array(shape))
    ];
  }
  var stringSplitConfig = {
    kernelName: StringSplit,
    backendName: "cpu",
    kernelFunc: stringSplit
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringToHashBucketFast.js
  function stringToHashBucketFast(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { numBuckets } = attrs;
    const { input: input2 } = inputs;
    if (input2.dtype !== "string") {
      throw new Error("Input must be of datatype string");
    }
    if (numBuckets <= 0) {
      throw new Error(`Number of buckets must be at least 1`);
    }
    const $input = backend2.data.get(input2.dataId).values;
    const output = stringToHashBucketFastImpl($input, numBuckets);
    return backend2.makeTensorInfo(input2.shape, "int32", output);
  }
  var stringToHashBucketFastConfig = {
    kernelName: StringToHashBucketFast,
    backendName: "cpu",
    kernelFunc: stringToHashBucketFast
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Tan.js
  var tan2 = unaryKernelFunc(Tan, (xi) => Math.tan(xi));
  var tanConfig = {
    kernelName: Tan,
    backendName: "cpu",
    kernelFunc: tan2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Tanh.js
  var tanh3 = unaryKernelFunc(Tanh, (xi) => Math.tanh(xi));
  var tanhConfig = {
    kernelName: Tanh,
    backendName: "cpu",
    kernelFunc: tanh3
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Tile.js
  function tile3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { reps } = attrs;
    assertNotComplex(x, "tile");
    const outBuf = tileImpl(backend2.bufferSync(x), reps);
    return backend2.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
  }
  var tileConfig = {
    kernelName: Tile,
    backendName: "cpu",
    kernelFunc: tile3
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/TopK.js
  function topK(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { k, sorted } = attrs;
    assertNotComplex(x, "topk");
    const xVals = backend2.data.get(x.dataId).values;
    const [allTopKVals, allTopKIndices] = topKImpl(xVals, x.shape, x.dtype, k, sorted);
    return [
      backend2.makeTensorInfo(allTopKVals.shape, allTopKVals.dtype, allTopKVals.values),
      backend2.makeTensorInfo(allTopKIndices.shape, allTopKIndices.dtype, allTopKIndices.values)
    ];
  }
  var topKConfig = {
    kernelName: TopK,
    backendName: "cpu",
    kernelFunc: topK
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Transform.js
  function transform2(args) {
    const { inputs, attrs, backend: backend2 } = args;
    const { image: image3, transforms } = inputs;
    const { interpolation, fillMode, fillValue, outputShape } = attrs;
    const [batch, imageHeight, imageWidth, numChannels] = image3.shape;
    const [outHeight, outWidth] = outputShape != null ? outputShape : [imageHeight, imageWidth];
    const outShape = [batch, outHeight, outWidth, numChannels];
    const strides = util_exports.computeStrides(image3.shape);
    const batchStride = strides[0];
    const rowStride = strides[1];
    const colStride = strides[2];
    const outVals = util_exports.getTypedArrayFromDType(image3.dtype, util_exports.sizeFromShape(outShape));
    outVals.fill(fillValue);
    const imageVals = backend2.data.get(image3.dataId).values;
    const transformVals = backend2.data.get(transforms.dataId).values;
    for (let b = 0; b < batch; ++b) {
      const transform4 = transforms.shape[0] === 1 ? transformVals : transformVals.subarray(b * 8, b * 8 + 8);
      for (let outY = 0; outY < outHeight; ++outY) {
        for (let outX = 0; outX < outWidth; ++outX) {
          for (let channel = 0; channel < numChannels; ++channel) {
            let val;
            const projection = transform4[6] * outX + transform4[7] * outY + 1;
            if (projection === 0) {
              continue;
            }
            const inX = (transform4[0] * outX + transform4[1] * outY + transform4[2]) / projection;
            const inY = (transform4[3] * outX + transform4[4] * outY + transform4[5]) / projection;
            const x = mapCoord(inX, imageWidth, fillMode);
            const y = mapCoord(inY, imageHeight, fillMode);
            switch (interpolation) {
              case "nearest":
                val = nearestInterpolation(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, b, y, x, channel, fillValue);
                break;
              case "bilinear":
                val = bilinearInterpolation(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, b, y, x, channel, fillValue);
                break;
              default:
                throw new Error(`Error in Transform: Expect 'nearest' or 'bilinear', but got ${interpolation}`);
            }
            const ind = b * batchStride + outY * rowStride + outX * colStride + channel;
            outVals[ind] = val;
          }
        }
      }
      return backend2.makeTensorInfo(outShape, image3.dtype, outVals);
    }
    const dataId = backend2.write(outVals, outShape, image3.dtype);
    return { dataId, shape: image3.shape, dtype: image3.dtype };
  }
  var transformConfig = {
    kernelName: Transform,
    backendName: "cpu",
    kernelFunc: transform2
  };
  function mapCoord(outCoord, len, mode) {
    switch (mode) {
      case "reflect":
        return mapCoordReflect(outCoord, len);
      case "wrap":
        return mapCoordWrap(outCoord, len);
      case "nearest":
        return mapCoordNearest(outCoord, len);
      case "constant":
      default:
        return mapCoordConstant(outCoord, len);
    }
  }
  function mapCoordReflect(outCoord, len) {
    let inCoord = outCoord;
    if (inCoord < 0) {
      if (len <= 1) {
        inCoord = 0;
      } else {
        const sz2 = 2 * len;
        if (inCoord < sz2) {
          inCoord = sz2 * Math.trunc(-inCoord / sz2) + inCoord;
        }
        inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1;
      }
    } else if (inCoord > len - 1) {
      if (len <= 1) {
        inCoord = 0;
      } else {
        const sz2 = 2 * len;
        inCoord -= sz2 * Math.trunc(inCoord / sz2);
        if (inCoord >= len) {
          inCoord = sz2 - inCoord - 1;
        }
      }
    }
    return util_exports.clamp(0, inCoord, len - 1);
  }
  function mapCoordWrap(outCoord, len) {
    let inCoord = outCoord;
    if (inCoord < 0) {
      if (len <= 1) {
        inCoord = 0;
      } else {
        const sz = len - 1;
        inCoord += len * (Math.trunc(-inCoord / sz) + 1);
      }
    } else if (inCoord > len - 1) {
      if (len <= 1) {
        inCoord = 0;
      } else {
        const sz = len - 1;
        inCoord -= len * Math.trunc(inCoord / sz);
      }
    }
    return util_exports.clamp(0, inCoord, len - 1);
  }
  function mapCoordConstant(outCoord, len) {
    return outCoord;
  }
  function mapCoordNearest(outCoord, len) {
    return util_exports.clamp(0, outCoord, len - 1);
  }
  function readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, y, x, channel, fillValue) {
    const ind = batch * batchStride + y * rowStride + x * colStride + channel;
    if (0 <= y && y < imageHeight && 0 <= x && x < imageWidth) {
      return imageVals[ind];
    } else {
      return fillValue;
    }
  }
  function nearestInterpolation(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, y, x, channel, fillValue) {
    const $y = Math.round(y);
    const $x = Math.round(x);
    return readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, $y, $x, channel, fillValue);
  }
  function bilinearInterpolation(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, y, x, channel, fillValue) {
    const yFloor = Math.floor(y);
    const xFloor = Math.floor(x);
    const yCeil = yFloor + 1;
    const xCeil = xFloor + 1;
    const valueYFloor = (xCeil - x) * readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yFloor, xFloor, channel, fillValue) + (x - xFloor) * readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yFloor, xCeil, channel, fillValue);
    const valueYCeil = (xCeil - x) * readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yCeil, xFloor, channel, fillValue) + (x - xFloor) * readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yCeil, xCeil, channel, fillValue);
    return (yCeil - y) * valueYFloor + (y - yFloor) * valueYCeil;
  }

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Unique.js
  function unique3(args) {
    const { inputs, attrs, backend: backend2 } = args;
    const { axis } = attrs;
    const { x } = inputs;
    assertNotComplex(x, "unique");
    const values = backend2.data.get(x.dataId).values;
    const { outputValues, outputShape, indices } = uniqueImpl(values, axis, x.shape, x.dtype);
    return [
      backend2.makeTensorInfo(outputShape, x.dtype, outputValues),
      backend2.makeTensorInfo([indices.length], "int32", indices)
    ];
  }
  var uniqueConfig = {
    kernelName: Unique,
    backendName: "cpu",
    kernelFunc: unique3
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Unpack.js
  function unpack(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { value } = inputs;
    let { axis } = attrs;
    if (axis < 0) {
      axis += value.shape.length;
    }
    const valueRank = value.shape.length;
    const num = value.shape[axis];
    const outShape = new Array(valueRank - 1);
    let outIndex = 0;
    for (let i = 0; i < valueRank; i++) {
      if (i !== axis) {
        outShape[outIndex++] = value.shape[i];
      }
    }
    const begin = new Array(valueRank).fill(0);
    const size2 = value.shape.slice();
    size2[axis] = 1;
    const res = new Array(num);
    for (let i = 0; i < res.length; i++) {
      begin[axis] = i;
      const tempRes = slice2({ inputs: { x: value }, backend: backend2, attrs: { begin, size: size2 } });
      res[i] = reshape2({ inputs: { x: tempRes }, backend: backend2, attrs: { shape: outShape } });
      backend2.disposeIntermediateTensorInfo(tempRes);
    }
    return res;
  }
  var unpackConfig = {
    kernelName: Unpack,
    backendName: "cpu",
    kernelFunc: unpack
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/UnsortedSegmentSum.js
  function unsortedSegmentSum2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, segmentIds } = inputs;
    const { numSegments } = attrs;
    assertNotComplex(x, "unsortedSegmentSum");
    const xRank = x.shape.length;
    const segmentIdsRank = segmentIds.shape.length;
    const res = [];
    const intermediates = [];
    const numIters = xRank - segmentIdsRank;
    let $segmentIds = segmentIds;
    for (let i = 0; i < numIters; ++i) {
      const expanded = expandDims3({ inputs: { input: $segmentIds }, backend: backend2, attrs: { dim: i + 1 } });
      $segmentIds = expanded;
      intermediates.push(expanded);
    }
    for (let i = 0; i < numSegments; ++i) {
      const scalarValue = util_exports.createScalarValue(i, "int32");
      const segmentId = backend2.makeTensorInfo([], "int32", scalarValue);
      const mask = equal2({ inputs: { a: segmentId, b: $segmentIds }, backend: backend2 });
      const maskCasted = cast3({ inputs: { x: mask }, backend: backend2, attrs: { dtype: "float32" } });
      const mul2 = multiply({ inputs: { a: maskCasted, b: x }, backend: backend2 });
      const sumTensorInfo = sum3({ inputs: { x: mul2 }, backend: backend2, attrs: { axis: 0, keepDims: false } });
      res.push(sumTensorInfo);
      intermediates.push(segmentId);
      intermediates.push(mask);
      intermediates.push(maskCasted);
      intermediates.push(mul2);
      intermediates.push(sumTensorInfo);
    }
    const result = pack({ inputs: res, backend: backend2, attrs: { axis: 0 } });
    intermediates.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
    return result;
  }
  var unsortedSegmentSumConfig = {
    kernelName: UnsortedSegmentSum,
    backendName: "cpu",
    kernelFunc: unsortedSegmentSum2
  };

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/register_all_kernels.js
  var kernelConfigs = [
    _fusedMatMulConfig,
    absConfig,
    acosConfig,
    acoshConfig,
    addConfig,
    addNConfig,
    allConfig,
    anyConfig,
    argMaxConfig,
    argMinConfig,
    asinConfig,
    asinhConfig,
    atanConfig,
    atan2Config,
    atanhConfig,
    avgPoolConfig,
    avgPool3DConfig,
    avgPool3DGradConfig2,
    avgPoolGradConfig2,
    batchMatMulConfig,
    batchNormConfig,
    batchToSpaceNDConfig,
    bincountConfig,
    broadcastArgsConfig,
    castConfig,
    ceilConfig,
    clipConfig,
    complexConfig,
    complexAbsConfig,
    concatConfig,
    conv2DBackpropFilterConfig,
    conv2DBackpropInputConfig,
    conv2DConfig,
    conv3DBackpropFilterV2Config,
    conv3DBackpropInputV2Config,
    conv3DConfig,
    cosConfig,
    coshConfig,
    cropAndResizeConfig,
    cumsumConfig,
    denseBincountConfig,
    depthToSpaceConfig,
    depthwiseConv2dNativeConfig,
    depthwiseConv2dNativeBackpropFilterConfig,
    depthwiseConv2dNativeBackpropInputConfig,
    diagConfig,
    dilation2dConfig,
    dilation2dBackpropInputConfig,
    dilation2dBackpropFilterConfig,
    realDivConfig,
    einsumConfig,
    eluConfig,
    eluGradConfig2,
    equalConfig,
    erfConfig,
    expConfig,
    expandDimsConfig,
    expm1Config,
    fftConfig,
    fillConfig,
    flipLeftRightConfig,
    floorConfig,
    floorDivConfig,
    fusedConv2DConfig,
    fusedDepthwiseConv2DConfig,
    gatherNdConfig,
    gatherV2Config,
    greaterConfig,
    greaterEqualConfig,
    identityConfig,
    ifftConfig,
    imagConfig,
    isFiniteConfig,
    isInfConfig,
    isNaNConfig,
    leakyReluConfig,
    lessConfig,
    lessEqualConfig,
    linSpaceConfig,
    logConfig,
    log1pConfig,
    logicalAndConfig,
    logicalNotConfig,
    logicalOrConfig,
    lRNConfig,
    lRNGradConfig,
    maximumConfig,
    maxPoolConfig,
    maxPool3DConfig,
    maxPool3DGradConfig2,
    maxPoolGradConfig2,
    maxPoolWithArgmaxConfig,
    maxConfig,
    meanConfig,
    minConfig,
    minimumConfig,
    mirrorPadConfig,
    modConfig,
    multinomialConfig,
    multiplyConfig,
    negConfig,
    nonMaxSuppressionV3Config,
    nonMaxSuppressionV4Config,
    nonMaxSuppressionV5Config,
    notEqualConfig,
    oneHotConfig,
    onesLikeConfig,
    packConfig,
    padV2Config,
    powConfig,
    preluConfig,
    prodConfig,
    rangeConfig,
    realConfig,
    reciprocalConfig,
    reluConfig,
    relu6Config,
    reshapeConfig,
    resizeBilinearConfig,
    resizeBilinearGradConfig2,
    resizeNearestNeighborConfig,
    resizeNearestNeighborGradConfig2,
    reverseConfig,
    rotateWithOffsetConfig,
    roundConfig,
    rsqrtConfig,
    scatterNdConfig,
    selectConfig,
    seluConfig,
    sigmoidConfig,
    signConfig,
    sinConfig,
    sinhConfig,
    sliceConfig,
    softmaxConfig,
    softplusConfig,
    spaceToBatchNDConfig,
    sparseFillEmptyRowsConfig,
    sparseReshapeConfig,
    sparseSegmentMeanConfig,
    sparseSegmentSumConfig,
    sparseToDenseConfig,
    splitVConfig,
    sqrtConfig,
    squareConfig,
    squaredDifferenceConfig,
    stepConfig,
    stridedSliceConfig,
    stringNGramsConfig,
    stringSplitConfig,
    stringToHashBucketFastConfig,
    subConfig,
    sumConfig,
    tanConfig,
    tanhConfig,
    tileConfig,
    topKConfig,
    transposeConfig,
    transformConfig,
    uniqueConfig,
    unpackConfig,
    unsortedSegmentSumConfig,
    zerosLikeConfig
  ];
  for (const kernelConfig of kernelConfigs) {
    registerKernel(kernelConfig);
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/canvas_util.js
  var contexts = {};
  var WEBGL_ATTRIBUTES = {
    alpha: false,
    antialias: false,
    premultipliedAlpha: false,
    preserveDrawingBuffer: false,
    depth: false,
    stencil: false,
    failIfMajorPerformanceCaveat: true
  };
  function setWebGLContext(webGLVersion, gl) {
    contexts[webGLVersion] = gl;
  }
  function getWebGLContext(webGLVersion) {
    if (!(webGLVersion in contexts)) {
      const newCtx = getWebGLRenderingContext(webGLVersion);
      if (newCtx !== null) {
        contexts[webGLVersion] = newCtx;
      } else {
        console.log("Could not get context for WebGL version", webGLVersion);
        return null;
      }
    }
    const gl = contexts[webGLVersion];
    if (gl.isContextLost()) {
      delete contexts[webGLVersion];
      return getWebGLContext(webGLVersion);
    }
    gl.disable(gl.DEPTH_TEST);
    gl.disable(gl.STENCIL_TEST);
    gl.disable(gl.BLEND);
    gl.disable(gl.DITHER);
    gl.disable(gl.POLYGON_OFFSET_FILL);
    gl.disable(gl.SAMPLE_COVERAGE);
    gl.enable(gl.SCISSOR_TEST);
    gl.enable(gl.CULL_FACE);
    gl.cullFace(gl.BACK);
    return contexts[webGLVersion];
  }
  function createCanvas(webGLVersion) {
    if (typeof OffscreenCanvas !== "undefined" && webGLVersion === 2) {
      return new OffscreenCanvas(300, 150);
    } else if (typeof document !== "undefined") {
      return document.createElement("canvas");
    } else {
      throw new Error("Cannot create a canvas in this context");
    }
  }
  function getWebGLRenderingContext(webGLVersion) {
    if (webGLVersion !== 1 && webGLVersion !== 2) {
      throw new Error("Cannot get WebGL rendering context, WebGL is disabled.");
    }
    const canvas = createCanvas(webGLVersion);
    canvas.addEventListener("webglcontextlost", (ev) => {
      ev.preventDefault();
      delete contexts[webGLVersion];
    }, false);
    if (webGLVersion === 1) {
      return canvas.getContext("webgl", WEBGL_ATTRIBUTES) || canvas.getContext("experimental-webgl", WEBGL_ATTRIBUTES);
    }
    return canvas.getContext("webgl2", WEBGL_ATTRIBUTES);
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/tex_util.js
  var PackingScheme;
  (function(PackingScheme2) {
    PackingScheme2[PackingScheme2["DENSE"] = 0] = "DENSE";
    PackingScheme2[PackingScheme2["SHARED_BATCH"] = 1] = "SHARED_BATCH";
  })(PackingScheme || (PackingScheme = {}));
  var TextureUsage;
  (function(TextureUsage2) {
    TextureUsage2[TextureUsage2["RENDER"] = 0] = "RENDER";
    TextureUsage2[TextureUsage2["UPLOAD"] = 1] = "UPLOAD";
    TextureUsage2[TextureUsage2["PIXELS"] = 2] = "PIXELS";
    TextureUsage2[TextureUsage2["DOWNLOAD"] = 3] = "DOWNLOAD";
  })(TextureUsage || (TextureUsage = {}));
  var PhysicalTextureType;
  (function(PhysicalTextureType2) {
    PhysicalTextureType2[PhysicalTextureType2["UNPACKED_FLOAT16"] = 0] = "UNPACKED_FLOAT16";
    PhysicalTextureType2[PhysicalTextureType2["UNPACKED_FLOAT32"] = 1] = "UNPACKED_FLOAT32";
    PhysicalTextureType2[PhysicalTextureType2["PACKED_4X1_UNSIGNED_BYTE"] = 2] = "PACKED_4X1_UNSIGNED_BYTE";
    PhysicalTextureType2[PhysicalTextureType2["PACKED_2X2_FLOAT32"] = 3] = "PACKED_2X2_FLOAT32";
    PhysicalTextureType2[PhysicalTextureType2["PACKED_2X2_FLOAT16"] = 4] = "PACKED_2X2_FLOAT16";
  })(PhysicalTextureType || (PhysicalTextureType = {}));
  function getUnpackedMatrixTextureShapeWidthHeight(rows, columns) {
    return [columns, rows];
  }
  function getUnpackedArraySizeFromMatrixSize(matrixSize, channelsPerTexture) {
    return matrixSize * channelsPerTexture;
  }
  function getDenseTexShape(shape) {
    const size2 = util_exports.sizeFromShape(shape);
    const texelsNeeded = Math.ceil(size2 / 4);
    return util_exports.sizeToSquarishShape(texelsNeeded);
  }
  function getPackedMatrixTextureShapeWidthHeight(rows, columns) {
    return [
      Math.max(1, Math.ceil(columns / 2)),
      Math.max(1, Math.ceil(rows / 2))
    ];
  }
  function getPackedRGBAArraySizeFromMatrixShape(rows, columns) {
    const [w, h2] = getPackedMatrixTextureShapeWidthHeight(rows, columns);
    return w * h2 * 4;
  }
  function getTextureConfig(gl, textureHalfFloatExtension) {
    const glany = gl;
    let internalFormatFloat;
    let internalFormatHalfFloat;
    let internalFormatPackedHalfFloat;
    let internalFormatPackedFloat;
    let textureFormatFloat;
    let downloadTextureFormat;
    let downloadUnpackNumChannels;
    let defaultNumChannels;
    let textureTypeHalfFloat;
    let textureTypeFloat;
    if (env().getNumber("WEBGL_VERSION") === 2) {
      internalFormatFloat = glany.R32F;
      internalFormatHalfFloat = glany.R16F;
      internalFormatPackedHalfFloat = glany.RGBA16F;
      internalFormatPackedFloat = glany.RGBA32F;
      textureFormatFloat = glany.RED;
      downloadUnpackNumChannels = 4;
      defaultNumChannels = 1;
      textureTypeHalfFloat = glany.HALF_FLOAT;
      textureTypeFloat = glany.FLOAT;
    } else {
      internalFormatFloat = gl.RGBA;
      internalFormatHalfFloat = gl.RGBA;
      internalFormatPackedHalfFloat = gl.RGBA;
      internalFormatPackedFloat = glany.RGBA;
      textureFormatFloat = gl.RGBA;
      downloadUnpackNumChannels = 4;
      defaultNumChannels = 4;
      textureTypeHalfFloat = textureHalfFloatExtension != null ? textureHalfFloatExtension.HALF_FLOAT_OES : null;
      textureTypeFloat = gl.FLOAT;
    }
    downloadTextureFormat = gl.RGBA;
    return {
      internalFormatFloat,
      internalFormatHalfFloat,
      internalFormatPackedHalfFloat,
      internalFormatPackedFloat,
      textureFormatFloat,
      downloadTextureFormat,
      downloadUnpackNumChannels,
      defaultNumChannels,
      textureTypeHalfFloat,
      textureTypeFloat
    };
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/webgl_util.js
  function callAndCheck(gl, func2) {
    const returnValue = func2();
    if (env().getBool("DEBUG")) {
      checkWebGLError(gl);
    }
    return returnValue;
  }
  function checkWebGLError(gl) {
    const error = gl.getError();
    if (error !== gl.NO_ERROR) {
      throw new Error("WebGL Error: " + getWebGLErrorMessage(gl, error));
    }
  }
  var MIN_FLOAT16 = 596e-10;
  var MAX_FLOAT16 = 65504;
  function canBeRepresented(num) {
    if (env().getBool("WEBGL_RENDER_FLOAT32_ENABLED") || num === 0 || MIN_FLOAT16 < Math.abs(num) && Math.abs(num) < MAX_FLOAT16) {
      return true;
    }
    return false;
  }
  function getWebGLErrorMessage(gl, status) {
    switch (status) {
      case gl.NO_ERROR:
        return "NO_ERROR";
      case gl.INVALID_ENUM:
        return "INVALID_ENUM";
      case gl.INVALID_VALUE:
        return "INVALID_VALUE";
      case gl.INVALID_OPERATION:
        return "INVALID_OPERATION";
      case gl.INVALID_FRAMEBUFFER_OPERATION:
        return "INVALID_FRAMEBUFFER_OPERATION";
      case gl.OUT_OF_MEMORY:
        return "OUT_OF_MEMORY";
      case gl.CONTEXT_LOST_WEBGL:
        return "CONTEXT_LOST_WEBGL";
      default:
        return `Unknown error code ${status}`;
    }
  }
  function getExtensionOrThrow(gl, extensionName) {
    return throwIfNull(gl, () => gl.getExtension(extensionName), 'Extension "' + extensionName + '" not supported on this browser.');
  }
  function createVertexShader(gl, vertexShaderSource) {
    const vertexShader = throwIfNull(gl, () => gl.createShader(gl.VERTEX_SHADER), "Unable to create vertex WebGLShader.");
    callAndCheck(gl, () => gl.shaderSource(vertexShader, vertexShaderSource));
    callAndCheck(gl, () => gl.compileShader(vertexShader));
    if (gl.getShaderParameter(vertexShader, gl.COMPILE_STATUS) === false) {
      console.log(gl.getShaderInfoLog(vertexShader));
      throw new Error("Failed to compile vertex shader.");
    }
    return vertexShader;
  }
  function createFragmentShader(gl, fragmentShaderSource) {
    const fragmentShader = throwIfNull(gl, () => gl.createShader(gl.FRAGMENT_SHADER), "Unable to create fragment WebGLShader.");
    callAndCheck(gl, () => gl.shaderSource(fragmentShader, fragmentShaderSource));
    callAndCheck(gl, () => gl.compileShader(fragmentShader));
    if (gl.getShaderParameter(fragmentShader, gl.COMPILE_STATUS) === false) {
      logShaderSourceAndInfoLog(fragmentShaderSource, gl.getShaderInfoLog(fragmentShader));
      throw new Error("Failed to compile fragment shader.");
    }
    return fragmentShader;
  }
  var lineNumberRegex = /ERROR: [0-9]+:([0-9]+):/g;
  function logShaderSourceAndInfoLog(shaderSource, shaderInfoLog) {
    const lineNumberRegexResult = lineNumberRegex.exec(shaderInfoLog);
    if (lineNumberRegexResult == null) {
      console.log(`Couldn't parse line number in error: ${shaderInfoLog}`);
      console.log(shaderSource);
      return;
    }
    const lineNumber = +lineNumberRegexResult[1];
    const shaderLines = shaderSource.split("\n");
    const pad2 = shaderLines.length.toString().length + 2;
    const linesWithLineNumbers = shaderLines.map((line, lineNumber2) => util_exports.rightPad((lineNumber2 + 1).toString(), pad2) + line);
    let maxLineLength = 0;
    for (let i = 0; i < linesWithLineNumbers.length; i++) {
      maxLineLength = Math.max(linesWithLineNumbers[i].length, maxLineLength);
    }
    const beforeErrorLines = linesWithLineNumbers.slice(0, lineNumber - 1);
    const errorLine = linesWithLineNumbers.slice(lineNumber - 1, lineNumber);
    const afterErrorLines = linesWithLineNumbers.slice(lineNumber);
    console.log(beforeErrorLines.join("\n"));
    console.log(shaderInfoLog.split("\n")[0]);
    console.log(`%c ${util_exports.rightPad(errorLine[0], maxLineLength)}`, "border:1px solid red; background-color:#e3d2d2; color:#a61717");
    console.log(afterErrorLines.join("\n"));
  }
  function createProgram(gl) {
    return throwIfNull(gl, () => gl.createProgram(), "Unable to create WebGLProgram.");
  }
  function linkProgram(gl, program) {
    callAndCheck(gl, () => gl.linkProgram(program));
    if (gl.getProgramParameter(program, gl.LINK_STATUS) === false) {
      console.log(gl.getProgramInfoLog(program));
      throw new Error("Failed to link vertex and fragment shaders.");
    }
  }
  function validateProgram(gl, program) {
    callAndCheck(gl, () => gl.validateProgram(program));
    if (gl.getProgramParameter(program, gl.VALIDATE_STATUS) === false) {
      console.log(gl.getProgramInfoLog(program));
      throw new Error("Shader program validation failed.");
    }
  }
  function createStaticVertexBuffer(gl, data) {
    const buffer3 = throwIfNull(gl, () => gl.createBuffer(), "Unable to create WebGLBuffer");
    callAndCheck(gl, () => gl.bindBuffer(gl.ARRAY_BUFFER, buffer3));
    callAndCheck(gl, () => gl.bufferData(gl.ARRAY_BUFFER, data, gl.STATIC_DRAW));
    return buffer3;
  }
  function createStaticIndexBuffer(gl, data) {
    const buffer3 = throwIfNull(gl, () => gl.createBuffer(), "Unable to create WebGLBuffer");
    callAndCheck(gl, () => gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, buffer3));
    callAndCheck(gl, () => gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, data, gl.STATIC_DRAW));
    return buffer3;
  }
  function createTexture(gl) {
    return throwIfNull(gl, () => gl.createTexture(), "Unable to create WebGLTexture.");
  }
  function validateTextureSize(width, height) {
    const maxTextureSize = env().getNumber("WEBGL_MAX_TEXTURE_SIZE");
    if (width <= 0 || height <= 0) {
      const requested = `[${width}x${height}]`;
      throw new Error("Requested texture size " + requested + " is invalid.");
    }
    if (width > maxTextureSize || height > maxTextureSize) {
      const requested = `[${width}x${height}]`;
      const max5 = `[${maxTextureSize}x${maxTextureSize}]`;
      throw new Error("Requested texture size " + requested + " greater than WebGL maximum on this browser / GPU " + max5 + ".");
    }
  }
  function createFramebuffer(gl) {
    return throwIfNull(gl, () => gl.createFramebuffer(), "Unable to create WebGLFramebuffer.");
  }
  function bindVertexBufferToProgramAttribute(gl, program, attribute, buffer3, arrayEntriesPerItem, itemStrideInBytes, itemOffsetInBytes) {
    const loc = gl.getAttribLocation(program, attribute);
    if (loc === -1) {
      return false;
    }
    callAndCheck(gl, () => gl.bindBuffer(gl.ARRAY_BUFFER, buffer3));
    callAndCheck(gl, () => gl.vertexAttribPointer(loc, arrayEntriesPerItem, gl.FLOAT, false, itemStrideInBytes, itemOffsetInBytes));
    callAndCheck(gl, () => gl.enableVertexAttribArray(loc));
    return true;
  }
  function bindTextureUnit(gl, texture, textureUnit) {
    validateTextureUnit(gl, textureUnit);
    callAndCheck(gl, () => gl.activeTexture(gl.TEXTURE0 + textureUnit));
    callAndCheck(gl, () => gl.bindTexture(gl.TEXTURE_2D, texture));
  }
  function getProgramUniformLocationOrThrow(gl, program, uniformName) {
    return throwIfNull(gl, () => gl.getUniformLocation(program, uniformName), 'uniform "' + uniformName + '" not present in program.');
  }
  function getProgramUniformLocation(gl, program, uniformName) {
    return gl.getUniformLocation(program, uniformName);
  }
  function bindTextureToProgramUniformSampler(gl, texture, uniformSamplerLocation, textureUnit) {
    callAndCheck(gl, () => bindTextureUnit(gl, texture, textureUnit));
    callAndCheck(gl, () => gl.uniform1i(uniformSamplerLocation, textureUnit));
  }
  function bindColorTextureToFramebuffer(gl, texture, framebuffer) {
    callAndCheck(gl, () => gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer));
    callAndCheck(gl, () => gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0));
  }
  function unbindColorTextureFromFramebuffer(gl, framebuffer) {
    callAndCheck(gl, () => gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer));
    callAndCheck(gl, () => gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, null, 0));
  }
  function validateFramebuffer(gl) {
    const status = gl.checkFramebufferStatus(gl.FRAMEBUFFER);
    if (status !== gl.FRAMEBUFFER_COMPLETE) {
      throw new Error("Error binding framebuffer: " + getFramebufferErrorMessage(gl, status));
    }
  }
  function getFramebufferErrorMessage(gl, status) {
    switch (status) {
      case gl.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:
        return "FRAMEBUFFER_INCOMPLETE_ATTACHMENT";
      case gl.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:
        return "FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT";
      case gl.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:
        return "FRAMEBUFFER_INCOMPLETE_DIMENSIONS";
      case gl.FRAMEBUFFER_UNSUPPORTED:
        return "FRAMEBUFFER_UNSUPPORTED";
      default:
        return `unknown error ${status}`;
    }
  }
  function throwIfNull(gl, returnTOrNull, failureMessage) {
    const tOrNull = callAndCheck(gl, () => returnTOrNull());
    if (tOrNull == null) {
      throw new Error(failureMessage);
    }
    return tOrNull;
  }
  function validateTextureUnit(gl, textureUnit) {
    const maxTextureUnit = gl.MAX_COMBINED_TEXTURE_IMAGE_UNITS - 1;
    const glTextureUnit = textureUnit + gl.TEXTURE0;
    if (glTextureUnit < gl.TEXTURE0 || glTextureUnit > maxTextureUnit) {
      const textureUnitRange = `[gl.TEXTURE0, gl.TEXTURE${maxTextureUnit}]`;
      throw new Error(`textureUnit must be in ${textureUnitRange}.`);
    }
  }
  function getBatchDim(shape, dimsToSkip = 2) {
    return util_exports.sizeFromShape(shape.slice(0, shape.length - dimsToSkip));
  }
  function getRowsCols(shape) {
    if (shape.length === 0) {
      throw Error("Cannot get rows and columns of an empty shape array.");
    }
    return [
      shape.length > 1 ? shape[shape.length - 2] : 1,
      shape[shape.length - 1]
    ];
  }
  function getShapeAs3D(shape) {
    let shapeAs3D = [1, 1, 1];
    const isScalar = shape.length === 0 || shape.length === 1 && shape[0] === 1;
    if (!isScalar) {
      shapeAs3D = [getBatchDim(shape), ...getRowsCols(shape)];
    }
    return shapeAs3D;
  }
  function getTextureShapeFromLogicalShape(logShape, isPacked = false) {
    let maxTexSize = env().getNumber("WEBGL_MAX_TEXTURE_SIZE");
    if (isPacked) {
      maxTexSize = maxTexSize * 2;
      logShape = logShape.map((d, i) => i >= logShape.length - 2 ? util_exports.nearestLargerEven(logShape[i]) : logShape[i]);
      if (logShape.length === 1) {
        logShape = [2, logShape[0]];
      }
    }
    if (logShape.length !== 2) {
      const squeezeResult = util_exports.squeezeShape(logShape);
      logShape = squeezeResult.newShape;
    }
    let size2 = util_exports.sizeFromShape(logShape);
    if (logShape.length <= 1 && size2 <= maxTexSize) {
      return [1, size2];
    } else if (logShape.length === 2 && logShape[0] <= maxTexSize && logShape[1] <= maxTexSize) {
      return logShape;
    } else if (logShape.length === 3 && logShape[0] * logShape[1] <= maxTexSize && logShape[2] <= maxTexSize) {
      return [logShape[0] * logShape[1], logShape[2]];
    } else if (logShape.length === 3 && logShape[0] <= maxTexSize && logShape[1] * logShape[2] <= maxTexSize) {
      return [logShape[0], logShape[1] * logShape[2]];
    } else if (logShape.length === 4 && logShape[0] * logShape[1] * logShape[2] <= maxTexSize && logShape[3] <= maxTexSize) {
      return [logShape[0] * logShape[1] * logShape[2], logShape[3]];
    } else if (logShape.length === 4 && logShape[0] <= maxTexSize && logShape[1] * logShape[2] * logShape[3] <= maxTexSize) {
      return [logShape[0], logShape[1] * logShape[2] * logShape[3]];
    } else {
      if (isPacked) {
        const batchDim = getBatchDim(logShape);
        let rows = 2, cols = 2;
        if (logShape.length) {
          [rows, cols] = getRowsCols(logShape);
        }
        size2 = batchDim * (rows / 2) * (cols / 2);
        return util_exports.sizeToSquarishShape(size2).map((d) => d * 2);
      }
      return util_exports.sizeToSquarishShape(size2);
    }
  }
  function isEven(n) {
    return n % 2 === 0;
  }
  function isReshapeFree(shape1, shape2) {
    shape1 = shape1.slice(-2);
    shape2 = shape2.slice(-2);
    if (util_exports.arraysEqual(shape1, shape2)) {
      return true;
    }
    if (!shape1.length || !shape2.length) {
      return true;
    }
    if (shape1[0] === 0 || shape1[1] === 0 || shape2[0] === 0 || shape2[1] === 0) {
      return true;
    }
    if (shape1.length !== shape2.length) {
      const shape1Cols = shape1.slice(-1)[0];
      const shape2Cols = shape2.slice(-1)[0];
      if (shape1Cols === shape2Cols) {
        return true;
      }
      if (isEven(shape1Cols) && isEven(shape2Cols) && (shape1[0] === 1 || shape2[0] === 1)) {
        return true;
      }
    }
    return shape1[1] === shape2[1] && isEven(shape1[0]) && isEven(shape2[0]);
  }
  var MAX_TEXTURE_SIZE;
  var MAX_TEXTURES_IN_SHADER;
  function getWebGLMaxTextureSize(webGLVersion) {
    if (MAX_TEXTURE_SIZE == null) {
      const gl = getWebGLContext(webGLVersion);
      MAX_TEXTURE_SIZE = gl.getParameter(gl.MAX_TEXTURE_SIZE);
    }
    return MAX_TEXTURE_SIZE;
  }
  function getMaxTexturesInShader(webGLVersion) {
    if (MAX_TEXTURES_IN_SHADER == null) {
      const gl = getWebGLContext(webGLVersion);
      MAX_TEXTURES_IN_SHADER = gl.getParameter(gl.MAX_TEXTURE_IMAGE_UNITS);
    }
    return Math.min(16, MAX_TEXTURES_IN_SHADER);
  }
  function getWebGLDisjointQueryTimerVersion(webGLVersion) {
    if (webGLVersion === 0) {
      return 0;
    }
    let queryTimerVersion;
    const gl = getWebGLContext(webGLVersion);
    if (hasExtension(gl, "EXT_disjoint_timer_query_webgl2") && webGLVersion === 2) {
      queryTimerVersion = 2;
    } else if (hasExtension(gl, "EXT_disjoint_timer_query")) {
      queryTimerVersion = 1;
    } else {
      queryTimerVersion = 0;
    }
    return queryTimerVersion;
  }
  function hasExtension(gl, extensionName) {
    const ext = gl.getExtension(extensionName);
    return ext != null;
  }
  function isWebGLVersionEnabled(webGLVersion) {
    try {
      const gl = getWebGLContext(webGLVersion);
      if (gl != null) {
        return true;
      }
    } catch (e) {
      console.log("Error when getting WebGL context: ", e);
      return false;
    }
    return false;
  }
  function isCapableOfRenderingToFloatTexture(webGLVersion) {
    if (webGLVersion === 0) {
      return false;
    }
    const gl = getWebGLContext(webGLVersion);
    if (webGLVersion === 1) {
      if (!hasExtension(gl, "OES_texture_float")) {
        return false;
      }
    } else {
      if (!hasExtension(gl, "EXT_color_buffer_float")) {
        return false;
      }
    }
    const isFrameBufferComplete = createFloatTextureAndBindToFramebuffer(gl);
    return isFrameBufferComplete;
  }
  function isDownloadFloatTextureEnabled(webGLVersion) {
    if (webGLVersion === 0) {
      return false;
    }
    const gl = getWebGLContext(webGLVersion);
    if (webGLVersion === 1) {
      if (!hasExtension(gl, "OES_texture_float")) {
        return false;
      }
      if (!hasExtension(gl, "WEBGL_color_buffer_float")) {
        return false;
      }
    } else {
      if (hasExtension(gl, "EXT_color_buffer_float")) {
        return createFloatTextureAndBindToFramebuffer(gl);
      }
      const COLOR_BUFFER_HALF_FLOAT = "EXT_color_buffer_half_float";
      if (hasExtension(gl, COLOR_BUFFER_HALF_FLOAT)) {
        const textureHalfFloatExtension = gl.getExtension(COLOR_BUFFER_HALF_FLOAT);
        return createHalfFloatTextureAndBindToFramebuffer(gl, textureHalfFloatExtension);
      }
      return false;
    }
    const isFrameBufferComplete = createFloatTextureAndBindToFramebuffer(gl);
    return isFrameBufferComplete;
  }
  function createFloatTextureAndBindToFramebuffer(gl) {
    const texConfig = getTextureConfig(gl);
    const texture = gl.createTexture();
    gl.bindTexture(gl.TEXTURE_2D, texture);
    const width = 1;
    const height = 1;
    gl.texImage2D(gl.TEXTURE_2D, 0, texConfig.internalFormatFloat, width, height, 0, texConfig.textureFormatFloat, texConfig.textureTypeFloat, null);
    const frameBuffer = gl.createFramebuffer();
    gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer);
    gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0);
    const isFrameBufferComplete = gl.checkFramebufferStatus(gl.FRAMEBUFFER) === gl.FRAMEBUFFER_COMPLETE;
    gl.bindTexture(gl.TEXTURE_2D, null);
    gl.bindFramebuffer(gl.FRAMEBUFFER, null);
    gl.deleteTexture(texture);
    gl.deleteFramebuffer(frameBuffer);
    return isFrameBufferComplete;
  }
  function createHalfFloatTextureAndBindToFramebuffer(gl, textureHalfFloatExtension) {
    const texConfig = getTextureConfig(gl, textureHalfFloatExtension);
    const texture = gl.createTexture();
    gl.bindTexture(gl.TEXTURE_2D, texture);
    const width = 1;
    const height = 1;
    gl.texImage2D(gl.TEXTURE_2D, 0, texConfig.internalFormatHalfFloat, width, height, 0, texConfig.textureFormatFloat, texConfig.textureTypeHalfFloat, null);
    const frameBuffer = gl.createFramebuffer();
    gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer);
    gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0);
    const isFrameBufferComplete = gl.checkFramebufferStatus(gl.FRAMEBUFFER) === gl.FRAMEBUFFER_COMPLETE;
    gl.bindTexture(gl.TEXTURE_2D, null);
    gl.bindFramebuffer(gl.FRAMEBUFFER, null);
    gl.deleteTexture(texture);
    gl.deleteFramebuffer(frameBuffer);
    return isFrameBufferComplete;
  }
  function isWebGLFenceEnabled(webGLVersion) {
    if (webGLVersion !== 2) {
      return false;
    }
    const gl = getWebGLContext(webGLVersion);
    const isEnabled = gl.fenceSync != null;
    return isEnabled;
  }
  function assertNotComplex2(tensor2, opName) {
    if (!Array.isArray(tensor2)) {
      tensor2 = [tensor2];
    }
    tensor2.forEach((t) => {
      if (t != null) {
        util_exports.assert(t.dtype !== "complex64", () => `${opName} does not support complex64 tensors in the WebGL backend.`);
      }
    });
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/flags_webgl.js
  var ENV3 = env();
  ENV3.registerFlag("HAS_WEBGL", () => ENV3.getNumber("WEBGL_VERSION") > 0);
  ENV3.registerFlag("WEBGL_VERSION", () => {
    if (isWebGLVersionEnabled(2)) {
      return 2;
    } else if (isWebGLVersionEnabled(1)) {
      return 1;
    }
    return 0;
  });
  ENV3.registerFlag("WEBGL_CHECK_NUMERICAL_PROBLEMS", () => false);
  ENV3.registerFlag("WEBGL_BUFFER_SUPPORTED", () => ENV3.get("WEBGL_VERSION") === 2);
  ENV3.registerFlag("WEBGL_CPU_FORWARD", () => true);
  ENV3.registerFlag("WEBGL_FORCE_F16_TEXTURES", () => false);
  ENV3.registerFlag("WEBGL_PACK", () => ENV3.getBool("HAS_WEBGL"));
  ENV3.registerFlag("WEBGL_PACK_NORMALIZATION", () => ENV3.getBool("WEBGL_PACK"));
  ENV3.registerFlag("WEBGL_PACK_CLIP", () => ENV3.getBool("WEBGL_PACK"));
  ENV3.registerFlag("WEBGL_PACK_DEPTHWISECONV", () => ENV3.getBool("WEBGL_PACK"));
  ENV3.registerFlag("WEBGL_PACK_BINARY_OPERATIONS", () => ENV3.getBool("WEBGL_PACK"));
  ENV3.registerFlag("WEBGL_PACK_UNARY_OPERATIONS", () => ENV3.getBool("WEBGL_PACK"));
  ENV3.registerFlag("WEBGL_PACK_ARRAY_OPERATIONS", () => ENV3.getBool("WEBGL_PACK"));
  ENV3.registerFlag("WEBGL_PACK_IMAGE_OPERATIONS", () => ENV3.getBool("WEBGL_PACK"));
  ENV3.registerFlag("WEBGL_PACK_REDUCE", () => ENV3.getBool("WEBGL_PACK"));
  ENV3.registerFlag("WEBGL_LAZILY_UNPACK", () => ENV3.getBool("WEBGL_PACK"));
  ENV3.registerFlag("WEBGL_CONV_IM2COL", () => ENV3.getBool("WEBGL_PACK"));
  ENV3.registerFlag("WEBGL_MAX_TEXTURE_SIZE", () => getWebGLMaxTextureSize(ENV3.getNumber("WEBGL_VERSION")));
  ENV3.registerFlag("WEBGL_MAX_TEXTURES_IN_SHADER", () => getMaxTexturesInShader(ENV3.getNumber("WEBGL_VERSION")));
  ENV3.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION", () => {
    const webGLVersion = ENV3.getNumber("WEBGL_VERSION");
    if (webGLVersion === 0) {
      return 0;
    }
    return getWebGLDisjointQueryTimerVersion(webGLVersion);
  });
  ENV3.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE", () => ENV3.getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") > 0 && !device_util_exports.isMobile());
  ENV3.registerFlag("WEBGL_RENDER_FLOAT32_CAPABLE", () => isCapableOfRenderingToFloatTexture(ENV3.getNumber("WEBGL_VERSION")));
  ENV3.registerFlag("WEBGL_RENDER_FLOAT32_ENABLED", () => {
    return ENV3.getBool("WEBGL_FORCE_F16_TEXTURES") ? false : ENV3.getBool("WEBGL_RENDER_FLOAT32_CAPABLE");
  });
  ENV3.registerFlag("WEBGL_DOWNLOAD_FLOAT_ENABLED", () => isDownloadFloatTextureEnabled(ENV3.getNumber("WEBGL_VERSION")));
  ENV3.registerFlag("WEBGL_FENCE_API_ENABLED", () => isWebGLFenceEnabled(ENV3.getNumber("WEBGL_VERSION")));
  ENV3.registerFlag("WEBGL_SIZE_UPLOAD_UNIFORM", () => {
    const useUniforms = ENV3.getBool("WEBGL_RENDER_FLOAT32_ENABLED");
    return useUniforms ? 4 : 0;
  });
  ENV3.registerFlag("WEBGL_DELETE_TEXTURE_THRESHOLD", () => {
    return -1;
  }, (threshold3) => {
    if (threshold3 < 0 && threshold3 !== -1) {
      throw new Error(`WEBGL_DELETE_TEXTURE_THRESHOLD must be -1 (indicating never delete) or at least 0, but got ${threshold3}.`);
    }
  });
  ENV3.registerFlag("WEBGL_FLUSH_THRESHOLD", () => {
    return device_util_exports.isMobile() ? 1 : -1;
  }, (threshold3) => {
    if (threshold3 < 0 && threshold3 !== -1) {
      throw new Error(`WEBGL_FLUSH_THRESHOLD must be -1 (indicating never manual flush) or at least 0, but got ${threshold3}.`);
    }
  });
  ENV3.registerFlag("CPU_HANDOFF_SIZE_THRESHOLD", () => 128);
  ENV3.registerFlag("WEBGL_USE_SHAPES_UNIFORMS", () => false);
  ENV3.registerFlag("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD", () => 1e5);
  ENV3.registerFlag("TOPK_K_CPU_HANDOFF_THRESHOLD", () => 128);

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/glsl_version.js
  function getGlslDifferences() {
    let version9;
    let attribute;
    let varyingVs;
    let varyingFs;
    let texture2D;
    let output;
    let defineOutput;
    let defineSpecialNaN;
    let defineSpecialInf;
    let defineRound;
    if (env().getNumber("WEBGL_VERSION") === 2) {
      version9 = "#version 300 es";
      attribute = "in";
      varyingVs = "out";
      varyingFs = "in";
      texture2D = "texture";
      output = "outputColor";
      defineOutput = "out vec4 outputColor;";
      defineSpecialNaN = `
      bool isnan_custom(float val) {
        return (val > 0.0 || val < 0.0) ? false : val != 0.0;
      }

      bvec4 isnan_custom(vec4 val) {
        return bvec4(isnan_custom(val.x),
          isnan_custom(val.y), isnan_custom(val.z), isnan_custom(val.w));
      }

      #define isnan(value) isnan_custom(value)
    `;
      defineSpecialInf = ``;
      defineRound = `
      #define round(value) newRound(value)
      int newRound(float value) {
        return int(floor(value + 0.5));
      }

      ivec4 newRound(vec4 value) {
        return ivec4(floor(value + vec4(0.5)));
      }
    `;
    } else {
      version9 = "";
      attribute = "attribute";
      varyingVs = "varying";
      varyingFs = "varying";
      texture2D = "texture2D";
      output = "gl_FragColor";
      defineOutput = "";
      defineSpecialNaN = `
      #define isnan(value) isnan_custom(value)
      bool isnan_custom(float val) {
        return (val > 0. || val < 1. || val == 0.) ? false : true;
      }
      bvec4 isnan_custom(vec4 val) {
        return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));
      }
    `;
      defineSpecialInf = `
      uniform float INFINITY;

      bool isinf(float val) {
        return abs(val) == INFINITY;
      }
      bvec4 isinf(vec4 val) {
        return equal(abs(val), vec4(INFINITY));
      }
    `;
      defineRound = `
      int round(float value) {
        return int(floor(value + 0.5));
      }

      ivec4 round(vec4 value) {
        return ivec4(floor(value + vec4(0.5)));
      }
    `;
    }
    return {
      version: version9,
      attribute,
      varyingVs,
      varyingFs,
      texture2D,
      output,
      defineOutput,
      defineSpecialNaN,
      defineSpecialInf,
      defineRound
    };
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/shader_compiler_util.js
  function getLogicalCoordinatesFromFlatIndex(coords2, shape, index = "index") {
    const strides = util_exports.computeStrides(shape);
    return strides.map((stride, i) => {
      const line1 = `int ${coords2[i]} = ${index} / ${stride}`;
      const line2 = i === strides.length - 1 ? `int ${coords2[i + 1]} = ${index} - ${coords2[i]} * ${stride}` : `index -= ${coords2[i]} * ${stride}`;
      return `${line1}; ${line2};`;
    }).join("");
  }
  function getOutputLogicalCoordinatesFromFlatIndexByUniform(coords2, shape, index = "index") {
    const strides = util_exports.computeStrides(shape);
    return strides.map((_, i) => {
      const line1 = `int ${coords2[i]} = ${index} / outShapeStrides[${i}]`;
      const line2 = i === strides.length - 1 ? `int ${coords2[i + 1]} = ${index} - ${coords2[i]} * outShapeStrides[${i}]` : `index -= ${coords2[i]} * outShapeStrides[${i}]`;
      return `${line1}; ${line2};`;
    }).join("");
  }
  function symbolicallyComputeStrides(indicesArr, variableName) {
    const numCoords = indicesArr.length;
    const shape = indicesArr.map((d) => `${variableName}[${d}]`);
    const strides = new Array(numCoords - 1);
    strides[numCoords - 2] = shape[numCoords - 1];
    for (let i = numCoords - 3; i >= 0; --i) {
      strides[i] = `(${strides[i + 1]} * ${shape[i + 1]})`;
    }
    return strides;
  }
  function getLogicalCoordinatesFromFlatIndexByUniform(coords2, variableName, index = "index") {
    const indicesArray = coords2.map((_, i) => i);
    const strides = symbolicallyComputeStrides(indicesArray, variableName);
    return strides.map((_, i) => {
      const line1 = `int ${coords2[i]} = ${index} / ${strides[i]}`;
      const line2 = i === strides.length - 1 ? `int ${coords2[i + 1]} = ${index} - ${coords2[i]} * ${strides[i]}` : `index -= ${coords2[i]} * ${strides[i]}`;
      return `${line1}; ${line2};`;
    }).join("");
  }
  function getFlatIndexFrom3D(shape) {
    const strides = util_exports.computeStrides(shape).map((d) => d.toString());
    return `
  int getFlatIndex(ivec3 coords) {
    return coords.x * ${strides[0]} + coords.y * ${strides[1]} + coords.z;
  }
`;
  }
  function getFlatIndexFrom3DOutput() {
    return `
  int getFlatIndex(ivec3 coords) {
    return coords.x * outShapeStrides[0] + coords.y * outShapeStrides[1] + coords.z;
  }
`;
  }
  var ENCODE_FLOAT_SNIPPET = `
  const float FLOAT_MAX = 1.70141184e38;
  const float FLOAT_MIN = 1.17549435e-38;

  lowp vec4 encode_float(highp float v) {
    if (isnan(v)) {
      return vec4(255, 255, 255, 255);
    }

    highp float av = abs(v);

    if(av < FLOAT_MIN) {
      return vec4(0.0, 0.0, 0.0, 0.0);
    } else if(v > FLOAT_MAX) {
      return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;
    } else if(v < -FLOAT_MAX) {
      return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;
    }

    highp vec4 c = vec4(0,0,0,0);

    highp float e = floor(log2(av));
    highp float m = exp2(fract(log2(av))) - 1.0;

    c[2] = floor(128.0 * m);
    m -= c[2] / 128.0;
    c[1] = floor(32768.0 * m);
    m -= c[1] / 32768.0;
    c[0] = floor(8388608.0 * m);

    highp float ebias = e + 127.0;
    c[3] = floor(ebias / 2.0);
    ebias -= c[3] * 2.0;
    c[2] += floor(ebias) * 128.0;

    c[3] += 128.0 * step(0.0, -v);

    return c / 255.0;
  }
`;

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/shader_compiler.js
  var { getBroadcastDims: getBroadcastDims2 } = backend_util_exports;
  function makeShader(inputsInfo, outputShape, program) {
    const prefixSnippets = [];
    inputsInfo.forEach((x) => {
      const size2 = util_exports.sizeFromShape(x.shapeInfo.logicalShape);
      if (x.shapeInfo.isUniform) {
        prefixSnippets.push(`uniform float ${x.name}${size2 > 1 ? `[${size2}]` : ""};`);
      } else {
        prefixSnippets.push(`uniform sampler2D ${x.name};`);
        prefixSnippets.push(`uniform int offset${x.name};`);
      }
      if (program.enableShapeUniforms) {
        const { uniformShape } = getUniformInfoFromShape(program.packedInputs, x.shapeInfo.logicalShape, x.shapeInfo.texShape);
        switch (uniformShape.length) {
          case 1:
            prefixSnippets.push(`uniform int ${x.name}Shape;`);
            break;
          case 2:
            prefixSnippets.push(`uniform ivec2 ${x.name}Shape;`);
            break;
          case 3:
            prefixSnippets.push(`uniform ivec3 ${x.name}Shape;`);
            break;
          case 4:
            prefixSnippets.push(`uniform ivec4 ${x.name}Shape;`);
            break;
          default:
            break;
        }
        prefixSnippets.push(`uniform ivec2 ${x.name}TexShape;`);
      }
    });
    if (program.enableShapeUniforms) {
      switch (outputShape.logicalShape.length) {
        case 1:
          prefixSnippets.push(`uniform int outShape;`);
          break;
        case 2:
          prefixSnippets.push(`uniform ivec2 outShape;`);
          prefixSnippets.push(`uniform int outShapeStrides;`);
          break;
        case 3:
          prefixSnippets.push(`uniform ivec3 outShape;`);
          prefixSnippets.push(`uniform ivec2 outShapeStrides;`);
          break;
        case 4:
          prefixSnippets.push(`uniform ivec4 outShape;`);
          prefixSnippets.push(`uniform ivec3 outShapeStrides;`);
          break;
        default:
          break;
      }
      prefixSnippets.push(`uniform ivec2 outTexShape;`);
    }
    if (program.customUniforms) {
      program.customUniforms.forEach((d) => {
        prefixSnippets.push(`uniform ${d.type} ${d.name}${d.arrayIndex ? `[${d.arrayIndex}]` : ""};`);
      });
    }
    const inputPrefixSnippet = prefixSnippets.join("\n");
    const inputSamplingSnippet = inputsInfo.map((x) => getInputSamplingSnippet(x, outputShape, program.packedInputs, program.enableShapeUniforms)).join("\n");
    const outTexShape = outputShape.texShape;
    const glsl = getGlslDifferences();
    const floatTextureSampleSnippet = getFloatTextureSampleSnippet(glsl);
    let outputSamplingSnippet;
    let floatTextureSetOutputSnippet;
    let shaderPrefix = getShaderPrefix(glsl);
    if (outputShape.isPacked) {
      outputSamplingSnippet = getPackedOutputSamplingSnippet(outputShape.logicalShape, outTexShape, program.enableShapeUniforms);
      floatTextureSetOutputSnippet = getFloatTextureSetRGBASnippet(glsl);
    } else {
      outputSamplingSnippet = getOutputSamplingSnippet(outputShape.logicalShape, outTexShape, program.enableShapeUniforms);
      floatTextureSetOutputSnippet = getFloatTextureSetRSnippet(glsl);
    }
    if (program.packedInputs) {
      shaderPrefix += SHADER_PACKED_PREFIX;
    }
    const source = [
      shaderPrefix,
      floatTextureSampleSnippet,
      floatTextureSetOutputSnippet,
      inputPrefixSnippet,
      outputSamplingSnippet,
      inputSamplingSnippet,
      program.userCode
    ].join("\n");
    return source;
  }
  function getSamplerFromInInfo(inInfo, enableShapeUniforms = false) {
    const shape = inInfo.shapeInfo.logicalShape;
    switch (shape.length) {
      case 0:
        return getSamplerScalar(inInfo, enableShapeUniforms);
      case 1:
        return getSampler1D(inInfo, enableShapeUniforms);
      case 2:
        return getSampler2D(inInfo, enableShapeUniforms);
      case 3:
        return getSampler3D(inInfo, enableShapeUniforms);
      case 4:
        return getSampler4D(inInfo, enableShapeUniforms);
      case 5:
        return getSampler5D(inInfo);
      case 6:
        return getSampler6D(inInfo);
      default:
        throw new Error(`${shape.length}-D input sampling is not yet supported`);
    }
  }
  function getPackedSamplerFromInInfo(inInfo, enableShapeUniforms) {
    const shape = inInfo.shapeInfo.logicalShape;
    switch (shape.length) {
      case 0:
        return getPackedSamplerScalar(inInfo);
      case 1:
        return getPackedSampler1D(inInfo, enableShapeUniforms);
      case 2:
        return getPackedSampler2D(inInfo, enableShapeUniforms);
      case 3:
        return getPackedSampler3D(inInfo, enableShapeUniforms);
      default:
        return getPackedSamplerND(inInfo, enableShapeUniforms);
    }
  }
  function getInputSamplingSnippet(inInfo, outShapeInfo, usesPackedTextures = false, enableShapeUniforms) {
    let res = "";
    if (usesPackedTextures) {
      res += getPackedSamplerFromInInfo(inInfo, enableShapeUniforms);
    } else {
      res += getSamplerFromInInfo(inInfo, enableShapeUniforms);
    }
    const inShape = inInfo.shapeInfo.logicalShape;
    const outShape = outShapeInfo.logicalShape;
    if (inShape.length <= outShape.length) {
      if (usesPackedTextures) {
        res += getPackedSamplerAtOutputCoords(inInfo, outShapeInfo);
      } else {
        res += getSamplerAtOutputCoords(inInfo, outShapeInfo);
      }
    }
    return res;
  }
  function getPackedOutputSamplingSnippet(outShape, outTexShape, enableShapeUniforms) {
    switch (outShape.length) {
      case 0:
        return getOutputScalarCoords();
      case 1:
        return getOutputPacked1DCoords(outShape, outTexShape, enableShapeUniforms);
      case 2:
        return getOutputPacked2DCoords(outShape, outTexShape, enableShapeUniforms);
      case 3:
        return getOutputPacked3DCoords(outShape, outTexShape, enableShapeUniforms);
      default:
        return getOutputPackedNDCoords(outShape, outTexShape, enableShapeUniforms);
    }
  }
  function getOutputSamplingSnippet(outShape, outTexShape, enableShapeUniforms) {
    switch (outShape.length) {
      case 0:
        return getOutputScalarCoords();
      case 1:
        return getOutput1DCoords(outShape, outTexShape, enableShapeUniforms);
      case 2:
        return getOutput2DCoords(outShape, outTexShape, enableShapeUniforms);
      case 3:
        return getOutput3DCoords(outShape, outTexShape, enableShapeUniforms);
      case 4:
        return getOutput4DCoords(outShape, outTexShape, enableShapeUniforms);
      case 5:
        return getOutput5DCoords(outShape, outTexShape);
      case 6:
        return getOutput6DCoords(outShape, outTexShape);
      default:
        throw new Error(`${outShape.length}-D output sampling is not yet supported`);
    }
  }
  function getFloatTextureSampleSnippet(glsl) {
    return `
    float sampleTexture(sampler2D textureSampler, vec2 uv) {
      return ${glsl.texture2D}(textureSampler, uv).r;
    }
  `;
  }
  function getFloatTextureSetRSnippet(glsl) {
    return `
    void setOutput(float val) {
      ${glsl.output} = vec4(val, 0, 0, 0);
    }
  `;
  }
  function getFloatTextureSetRGBASnippet(glsl) {
    return `
    void setOutput(vec4 val) {
      ${glsl.output} = val;
    }
  `;
  }
  function getShaderPrefix(glsl) {
    const SHADER_PREFIX = `${glsl.version}
    precision highp float;
    precision highp int;
    precision highp sampler2D;
    ${glsl.varyingFs} vec2 resultUV;
    ${glsl.defineOutput}
    const vec2 halfCR = vec2(0.5, 0.5);

    struct ivec5
    {
      int x;
      int y;
      int z;
      int w;
      int u;
    };

    struct ivec6
    {
      int x;
      int y;
      int z;
      int w;
      int u;
      int v;
    };

    uniform float NAN;
    ${glsl.defineSpecialNaN}
    ${glsl.defineSpecialInf}
    ${glsl.defineRound}

    int imod(int x, int y) {
      return x - y * (x / y);
    }

    int idiv(int a, int b, float sign) {
      int res = a / b;
      int mod = imod(a, b);
      if (sign < 0. && mod != 0) {
        res -= 1;
      }
      return res;
    }

    //Based on the work of Dave Hoskins
    //https://www.shadertoy.com/view/4djSRW
    #define HASHSCALE1 443.8975
    float random(float seed){
      vec2 p = resultUV * seed;
      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);
      p3 += dot(p3, p3.yzx + 19.19);
      return fract((p3.x + p3.y) * p3.z);
    }

    ${SAMPLE_1D_SNIPPET}
    ${SAMPLE_2D_SNIPPET}
    ${SAMPLE_3D_SNIPPET}
  `;
    return SHADER_PREFIX;
  }
  var SAMPLE_1D_SNIPPET = `
vec2 uvFromFlat(int texNumR, int texNumC, int index) {
  int texR = index / texNumC;
  int texC = index - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
vec2 packedUVfrom1D(int texNumR, int texNumC, int index) {
  int texelIndex = index / 2;
  int texR = texelIndex / texNumC;
  int texC = texelIndex - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
`;
  var SAMPLE_2D_SNIPPET = `
vec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,
  int texNumC, int row, int col) {
  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);
  int texR = texelIndex / texNumC;
  int texC = texelIndex - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
`;
  var SAMPLE_3D_SNIPPET = `
vec2 packedUVfrom3D(int texNumR, int texNumC,
    int texelsInBatch, int texelsInLogicalRow, int b,
    int row, int col) {
  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);
  int texR = index / texNumC;
  int texC = index - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
`;
  var SHADER_PACKED_PREFIX = `
  float getChannel(vec4 frag, vec2 innerDims) {
    vec2 modCoord = mod(innerDims, 2.);
    return modCoord.x == 0. ?
      (modCoord.y == 0. ? frag.r : frag.g) :
      (modCoord.y == 0. ? frag.b : frag.a);
  }
  float getChannel(vec4 frag, int dim) {
    float modCoord = mod(float(dim), 2.);
    return modCoord == 0. ? frag.r : frag.g;
  }
`;
  function getOutputScalarCoords() {
    return `
    int getOutputCoords() {
      return 0;
    }
  `;
  }
  function getOutputPacked1DCoords(shape, texShape, enableShapeUniforms) {
    const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
    if (packedTexShape[0] === 1) {
      if (enableShapeUniforms) {
        return `
      int getOutputCoords() {
        return 2 * int(resultUV.x * ceil(float(outTexShape[1]) / 2.0));
      }
    `;
      }
      return `
      int getOutputCoords() {
        return 2 * int(resultUV.x * ${packedTexShape[1]}.0);
      }
    `;
    }
    if (packedTexShape[1] === 1) {
      if (enableShapeUniforms) {
        return `
      int getOutputCoords() {
        return 2 * int(resultUV.y * ceil(float(outTexShape[0]) / 2.0));
      }
    `;
      }
      return `
      int getOutputCoords() {
        return 2 * int(resultUV.y * ${packedTexShape[0]}.0);
      }
    `;
    }
    if (enableShapeUniforms) {
      return `
    int getOutputCoords() {
      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(packedTexShape[0], packedTexShape[1]));
      return 2 * (resTexRC.x * packedTexShape[1] + resTexRC.y);
    }
  `;
    }
    return `
    int getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${packedTexShape[0]}, ${packedTexShape[1]}));
      return 2 * (resTexRC.x * ${packedTexShape[1]} + resTexRC.y);
    }
  `;
  }
  function getOutput1DCoords(shape, texShape, enableShapeUniforms) {
    if (texShape[0] === 1) {
      if (enableShapeUniforms) {
        return `
      int getOutputCoords() {
        return int(resultUV.x * float(outTexShape[1]));
      }
    `;
      }
      return `
      int getOutputCoords() {
        return int(resultUV.x * ${texShape[1]}.0);
      }
    `;
    }
    if (texShape[1] === 1) {
      if (enableShapeUniforms) {
        return `
      int getOutputCoords() {
        return int(resultUV.y * float(outTexShape[0]));
      }
    `;
      }
      return `
      int getOutputCoords() {
        return int(resultUV.y * ${texShape[0]}.0);
      }
    `;
    }
    if (enableShapeUniforms) {
      return `
    int getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(outTexShape[0], outTexShape[1]));
      return resTexRC.x * outTexShape[1] + resTexRC.y;
    }
  `;
    }
    return `
    int getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${texShape[0]}, ${texShape[1]}));
      return resTexRC.x * ${texShape[1]} + resTexRC.y;
    }
  `;
  }
  function getOutputPacked3DCoords(shape, texShape, enableShapeUniforms) {
    if (enableShapeUniforms) {
      return `
    ivec3 getOutputCoords() {
      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
      int texelsInLogicalRow = int(ceil(float(outShape[2]) / 2.0));
      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[1]) / 2.0));
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(packedTexShape[0], packedTexShape[1]));
      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;

      int b = index / texelsInBatch;
      index -= b * texelsInBatch;

      int r = 2 * (index / texelsInLogicalRow);
      int c = imod(index, texelsInLogicalRow) * 2;

      return ivec3(b, r, c);
    }
  `;
    }
    const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
    const texelsInLogicalRow = Math.ceil(shape[2] / 2);
    const texelsInBatch = texelsInLogicalRow * Math.ceil(shape[1] / 2);
    return `
    ivec3 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${packedTexShape[0]}, ${packedTexShape[1]}));
      int index = resTexRC.x * ${packedTexShape[1]} + resTexRC.y;

      int b = index / ${texelsInBatch};
      index -= b * ${texelsInBatch};

      int r = 2 * (index / ${texelsInLogicalRow});
      int c = imod(index, ${texelsInLogicalRow}) * 2;

      return ivec3(b, r, c);
    }
  `;
  }
  function getOutput3DCoords(shape, texShape, enableShapeUniforms) {
    if (enableShapeUniforms) {
      const coordsFromIndexSnippet2 = getOutputLogicalCoordinatesFromFlatIndexByUniform(["r", "c", "d"], shape);
      return `
  ivec3 getOutputCoords() {
    ivec2 resTexRC = ivec2(resultUV.yx *
                           vec2(outTexShape[0], outTexShape[1]));
    int index = resTexRC.x * outTexShape[1] + resTexRC.y;
    ${coordsFromIndexSnippet2}
    return ivec3(r, c, d);
  }
`;
    }
    const coordsFromIndexSnippet = getLogicalCoordinatesFromFlatIndex(["r", "c", "d"], shape);
    return `
    ivec3 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${texShape[0]}, ${texShape[1]}));
      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;
      ${coordsFromIndexSnippet}
      return ivec3(r, c, d);
    }
  `;
  }
  function getOutputPackedNDCoords(shape, texShape, enableShapeUniforms) {
    if (enableShapeUniforms) {
      return `
    ivec4 getOutputCoords() {
      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(packedTexShape[0], packedTexShape[1]));
      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;

      int texelsInLogicalRow = int(ceil(float(outShape[3]) / 2.0));
      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[2]) / 2.0));
      int texelsInBatchN = texelsInBatch * outShape[1];

      int b2 = index / texelsInBatchN;
      index -= b2 * texelsInBatchN;

      int b = index / texelsInBatch;
      index -= b * texelsInBatch;

      int r = 2 * (index / texelsInLogicalRow);
      int c = imod(index, texelsInLogicalRow) * 2;

      return ivec4(b2, b, r, c);
    }
  `;
    }
    const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
    const texelsInLogicalRow = Math.ceil(shape[shape.length - 1] / 2);
    const texelsInBatch = texelsInLogicalRow * Math.ceil(shape[shape.length - 2] / 2);
    let texelsInBatchN = texelsInBatch;
    let batches = ``;
    let coords2 = "b, r, c";
    for (let b = 2; b < shape.length - 1; b++) {
      texelsInBatchN *= shape[shape.length - b - 1];
      batches = `
      int b${b} = index / ${texelsInBatchN};
      index -= b${b} * ${texelsInBatchN};
    ` + batches;
      coords2 = `b${b}, ` + coords2;
    }
    return `
    ivec${shape.length} getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${packedTexShape[0]}, ${packedTexShape[1]}));
      int index = resTexRC.x * ${packedTexShape[1]} + resTexRC.y;

      ${batches}

      int b = index / ${texelsInBatch};
      index -= b * ${texelsInBatch};

      int r = 2 * (index / ${texelsInLogicalRow});
      int c = imod(index, ${texelsInLogicalRow}) * 2;

      return ivec${shape.length}(${coords2});
    }
  `;
  }
  function getOutput4DCoords(shape, texShape, enableShapeUniforms) {
    if (enableShapeUniforms) {
      const coordsFromIndexSnippet2 = getOutputLogicalCoordinatesFromFlatIndexByUniform(["r", "c", "d", "d2"], shape);
      return `
    ivec4 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
        vec2(outTexShape[0], outTexShape[1]));
      int index = resTexRC.x * outTexShape[1] + resTexRC.y;
      ${coordsFromIndexSnippet2}
      return ivec4(r, c, d, d2);
    }
  `;
    }
    const coordsFromIndexSnippet = getLogicalCoordinatesFromFlatIndex(["r", "c", "d", "d2"], shape);
    return `
    ivec4 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
        vec2(${texShape[0]}, ${texShape[1]}));
      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;
      ${coordsFromIndexSnippet}
      return ivec4(r, c, d, d2);
    }
  `;
  }
  function getOutput5DCoords(shape, texShape) {
    const coordsFromIndexSnippet = getLogicalCoordinatesFromFlatIndex(["r", "c", "d", "d2", "d3"], shape);
    return `
    ivec5 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx * vec2(${texShape[0]},
                             ${texShape[1]}));

      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;

      ${coordsFromIndexSnippet}

      ivec5 outShape = ivec5(r, c, d, d2, d3);
      return outShape;
    }
  `;
  }
  function getOutput6DCoords(shape, texShape) {
    const coordsFromIndexSnippet = getLogicalCoordinatesFromFlatIndex(["r", "c", "d", "d2", "d3", "d4"], shape);
    return `
    ivec6 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
        vec2(${texShape[0]}, ${texShape[1]}));
      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;

      ${coordsFromIndexSnippet}

      ivec6 result = ivec6(r, c, d, d2, d3, d4);
      return result;
    }
  `;
  }
  function getOutputPacked2DCoords(shape, texShape, enableShapeUniforms) {
    const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
    if (util_exports.arraysEqual(shape, texShape)) {
      if (enableShapeUniforms) {
        return `
      ivec2 getOutputCoords() {
        ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
        return 2 * ivec2(resultUV.yx * vec2(packedTexShape[0], packedTexShape[1]));
      }
    `;
      }
      return `
      ivec2 getOutputCoords() {
        return 2 * ivec2(resultUV.yx * vec2(${packedTexShape[0]}, ${packedTexShape[1]}));
      }
    `;
    }
    const texelsInLogicalRow = Math.ceil(shape[1] / 2);
    if (enableShapeUniforms) {
      return `
    ivec2 getOutputCoords() {
      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
      int texelsInLogicalRow = int(ceil(float(outShape[1]) / 2.0));
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(packedTexShape[0], packedTexShape[1]));

      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;
      int r = 2 * (index / texelsInLogicalRow);
      int c = imod(index, texelsInLogicalRow) * 2;

      return ivec2(r, c);
    }
  `;
    }
    return `
    ivec2 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${packedTexShape[0]}, ${packedTexShape[1]}));

      int index = resTexRC.x * ${packedTexShape[1]} + resTexRC.y;
      int r = 2 * (index / ${texelsInLogicalRow});
      int c = imod(index, ${texelsInLogicalRow}) * 2;

      return ivec2(r, c);
    }
  `;
  }
  function getOutput2DCoords(shape, texShape, enableShapeUniforms) {
    if (util_exports.arraysEqual(shape, texShape)) {
      if (enableShapeUniforms) {
        return `
      ivec2 getOutputCoords() {
        return ivec2(resultUV.yx * vec2(outTexShape[0], outTexShape[1]));
      }
    `;
      }
      return `
      ivec2 getOutputCoords() {
        return ivec2(resultUV.yx * vec2(${texShape[0]}, ${texShape[1]}));
      }
    `;
    }
    if (shape[1] === 1) {
      if (enableShapeUniforms) {
        return `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(outTexShape[0], outTexShape[1]));
        int index = resTexRC.x * outTexShape[1] + resTexRC.y;
        return ivec2(index, 0);
      }
    `;
      }
      return `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(${texShape[0]}, ${texShape[1]}));
        int index = resTexRC.x * ${texShape[1]} + resTexRC.y;
        return ivec2(index, 0);
      }
    `;
    }
    if (shape[0] === 1) {
      if (enableShapeUniforms) {
        return `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(outTexShape[0], outTexShape[1]));
        int index = resTexRC.x * outTexShape[1] + resTexRC.y;
        return ivec2(0, index);
      }
    `;
      }
      return `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(${texShape[0]}, ${texShape[1]}));
        int index = resTexRC.x * ${texShape[1]} + resTexRC.y;
        return ivec2(0, index);
      }
    `;
    }
    if (enableShapeUniforms) {
      return `
    ivec2 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(outTexShape[0], outTexShape[1]));
      int index = resTexRC.x * outTexShape[1] + resTexRC.y;
      int r = index / outShape[1];
      int c = index - r * outShape[1];
      return ivec2(r, c);
    }
  `;
    }
    return `
    ivec2 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${texShape[0]}, ${texShape[1]}));
      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;
      int r = index / ${shape[1]};
      int c = index - r * ${shape[1]};
      return ivec2(r, c);
    }
  `;
  }
  function getFlatOffsetUniformName(texName) {
    return `offset${texName}`;
  }
  function getPackedSamplerScalar(inputInfo) {
    const texName = inputInfo.name;
    const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
    const glsl = getGlslDifferences();
    return `
    vec4 ${funcName}() {
      return ${glsl.texture2D}(${texName}, halfCR);
    }
  `;
  }
  function getSamplerScalar(inputInfo, enableShapeUniforms) {
    const texName = inputInfo.name;
    const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
    if (inputInfo.shapeInfo.isUniform) {
      return `float ${funcName}() {return ${texName};}`;
    }
    const [texNumR, texNumC] = inputInfo.shapeInfo.texShape;
    if (texNumR === 1 && texNumC === 1) {
      return `
      float ${funcName}() {
        return sampleTexture(${texName}, halfCR);
      }
    `;
    }
    const offset = getFlatOffsetUniformName(texName);
    if (enableShapeUniforms) {
      return `
    float ${funcName}() {
      vec2 uv = uvFromFlat(${texName}TexShape[0], ${texName}TexShape[1], ${offset});
      return sampleTexture(${texName}, uv);
    }
  `;
    }
    const [tNumR, tNumC] = inputInfo.shapeInfo.texShape;
    return `
    float ${funcName}() {
      vec2 uv = uvFromFlat(${tNumR}, ${tNumC}, ${offset});
      return sampleTexture(${texName}, uv);
    }
  `;
  }
  function getPackedSampler1D(inputInfo, enableShapeUniforms) {
    const texName = inputInfo.name;
    const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
    const texShape = inputInfo.shapeInfo.texShape;
    const glsl = getGlslDifferences();
    if (enableShapeUniforms) {
      return `
    vec4 ${funcName}(int index) {
      ivec2 packedTexShape = ivec2(ceil(float(${texName}TexShape[0]) / 2.0), ceil(float(${texName}TexShape[1]) / 2.0));
      vec2 uv = packedUVfrom1D(
        packedTexShape[0], packedTexShape[1], index);
      return ${glsl.texture2D}(${texName}, uv);
    }
  `;
    }
    const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
    return `
    vec4 ${funcName}(int index) {
      vec2 uv = packedUVfrom1D(
        ${packedTexShape[0]}, ${packedTexShape[1]}, index);
      return ${glsl.texture2D}(${texName}, uv);
    }
  `;
  }
  function getSampler1D(inputInfo, enableShapeUniforms) {
    const texName = inputInfo.name;
    const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
    if (inputInfo.shapeInfo.isUniform) {
      return `
      float ${funcName}(int index) {
        ${getUniformSampler(inputInfo)}
      }
    `;
    }
    const texShape = inputInfo.shapeInfo.texShape;
    const tNumR = texShape[0];
    const tNumC = texShape[1];
    if (tNumC === 1 && tNumR === 1) {
      return `
      float ${funcName}(int index) {
        return sampleTexture(${texName}, halfCR);
      }
    `;
    }
    const offset = getFlatOffsetUniformName(texName);
    if (tNumC === 1) {
      if (enableShapeUniforms) {
        return `
      float ${funcName}(int index) {
        vec2 uv = vec2(0.5, (float(index + ${offset}) + 0.5) / float(${texName}TexShape[0]));
        return sampleTexture(${texName}, uv);
      }
    `;
      }
      return `
      float ${funcName}(int index) {
        vec2 uv = vec2(0.5, (float(index + ${offset}) + 0.5) / ${tNumR}.0);
        return sampleTexture(${texName}, uv);
      }
    `;
    }
    if (tNumR === 1) {
      if (enableShapeUniforms) {
        return `
      float ${funcName}(int index) {
        vec2 uv = vec2((float(index + ${offset}) + 0.5) / float(${texName}TexShape[1]), 0.5);
        return sampleTexture(${texName}, uv);
      }
    `;
      }
      return `
      float ${funcName}(int index) {
        vec2 uv = vec2((float(index + ${offset}) + 0.5) / ${tNumC}.0, 0.5);
        return sampleTexture(${texName}, uv);
      }
    `;
    }
    if (enableShapeUniforms) {
      return `
    float ${funcName}(int index) {
      vec2 uv = uvFromFlat(${texName}TexShape[0], ${texName}TexShape[1], index + ${offset});
      return sampleTexture(${texName}, uv);
    }
  `;
    }
    return `
    float ${funcName}(int index) {
      vec2 uv = uvFromFlat(${tNumR}, ${tNumC}, index + ${offset});
      return sampleTexture(${texName}, uv);
    }
  `;
  }
  function getPackedSampler2D(inputInfo, enableShapeUniforms) {
    const shape = inputInfo.shapeInfo.logicalShape;
    const texName = inputInfo.name;
    const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
    const texShape = inputInfo.shapeInfo.texShape;
    const texNumR = texShape[0];
    const texNumC = texShape[1];
    const glsl = getGlslDifferences();
    if (texShape != null && util_exports.arraysEqual(shape, texShape)) {
      if (enableShapeUniforms) {
        return `
      vec4 ${funcName}(int row, int col) {
        vec2 uv = (vec2(col, row) + halfCR) / vec2(${texName}TexShape[1], ${texName}TexShape[0]);

        return ${glsl.texture2D}(${texName}, uv);
      }
    `;
      }
      return `
      vec4 ${funcName}(int row, int col) {
        vec2 uv = (vec2(col, row) + halfCR) / vec2(${texNumC}.0, ${texNumR}.0);

        return ${glsl.texture2D}(${texName}, uv);
      }
    `;
    }
    if (enableShapeUniforms) {
      return `
    vec4 ${funcName}(int row, int col) {
      ivec2 packedTexShape = ivec2(ceil(float(${texName}TexShape[0]) / 2.0), ceil(float(${texName}TexShape[1]) / 2.0));
      int valuesPerRow = int(ceil(float(${texName}Shape[1]) / 2.0));
      vec2 uv = packedUVfrom2D(valuesPerRow, packedTexShape[0], packedTexShape[1], row, col);
      return ${glsl.texture2D}(${texName}, uv);
    }
  `;
    }
    const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
    const valuesPerRow = Math.ceil(shape[1] / 2);
    return `
    vec4 ${funcName}(int row, int col) {
      vec2 uv = packedUVfrom2D(${valuesPerRow}, ${packedTexShape[0]}, ${packedTexShape[1]}, row, col);
      return ${glsl.texture2D}(${texName}, uv);
    }
  `;
  }
  function getSampler2D(inputInfo, enableShapeUniforms) {
    const shape = inputInfo.shapeInfo.logicalShape;
    const texName = inputInfo.name;
    const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
    const texShape = inputInfo.shapeInfo.texShape;
    if (texShape != null && util_exports.arraysEqual(shape, texShape)) {
      if (enableShapeUniforms) {
        return `
      float ${funcName}(int row, int col) {
        vec2 uv = (vec2(col, row) + halfCR) / vec2(${texName}TexShape[1], ${texName}TexShape[0]);
        return sampleTexture(${texName}, uv);
      }
    `;
      }
      const texNumR2 = texShape[0];
      const texNumC2 = texShape[1];
      return `
    float ${funcName}(int row, int col) {
      vec2 uv = (vec2(col, row) + halfCR) / vec2(${texNumC2}.0, ${texNumR2}.0);
      return sampleTexture(${texName}, uv);
    }
  `;
    }
    const { newShape, keptDims } = util_exports.squeezeShape(shape);
    const squeezedShape = newShape;
    if (squeezedShape.length < shape.length) {
      const newInputInfo = squeezeInputInfo(inputInfo, squeezedShape);
      const params = ["row", "col"];
      return `
      ${getSamplerFromInInfo(newInputInfo, enableShapeUniforms)}
      float ${funcName}(int row, int col) {
        return ${funcName}(${getSqueezedParams(params, keptDims)});
      }
    `;
    }
    if (inputInfo.shapeInfo.isUniform) {
      return `
      float ${funcName}(int row, int col) {
        int index = round(dot(vec2(row, col), vec2(${shape[1]}, 1)));
        ${getUniformSampler(inputInfo)}
      }
    `;
    }
    const texNumR = texShape[0];
    const texNumC = texShape[1];
    const offset = getFlatOffsetUniformName(texName);
    if (texNumC === 1) {
      if (enableShapeUniforms) {
        return `
      float ${funcName}(int row, int col) {
        float index = dot(vec3(row, col, ${offset}), vec3(${texName}Shape[1], 1, 1));
        vec2 uv = vec2(0.5, (index + 0.5) / float(${texName}TexShape[0]));
        return sampleTexture(${texName}, uv);
      }
    `;
      }
      return `
    float ${funcName}(int row, int col) {
      float index = dot(vec3(row, col, ${offset}), vec3(${shape[1]}, 1, 1));
      vec2 uv = vec2(0.5, (index + 0.5) / ${texNumR}.0);
      return sampleTexture(${texName}, uv);
    }
  `;
    }
    if (texNumR === 1) {
      if (enableShapeUniforms) {
        return `
      float ${funcName}(int row, int col) {
        float index = dot(vec3(row, col, ${offset}), vec3(${texName}Shape[1], 1, 1));
        vec2 uv = vec2((index + 0.5) / float(${texName}TexShape[1]), 0.5);
        return sampleTexture(${texName}, uv);
      }
    `;
      }
      return `
    float ${funcName}(int row, int col) {
      float index = dot(vec3(row, col, ${offset}), vec3(${shape[1]}, 1, 1));
      vec2 uv = vec2((index + 0.5) / ${texNumC}.0, 0.5);
      return sampleTexture(${texName}, uv);
    }
  `;
    }
    if (enableShapeUniforms) {
      return `
      float ${funcName}(int row, int col) {
        // Explicitly use integer operations as dot() only works on floats.
        int index = row * ${texName}Shape[1] + col + ${offset};
        vec2 uv = uvFromFlat(${texName}TexShape[0], ${texName}TexShape[1], index);
        return sampleTexture(${texName}, uv);
      }
    `;
    }
    return `
  float ${funcName}(int row, int col) {
    // Explicitly use integer operations as dot() only works on floats.
    int index = row * ${shape[1]} + col + ${offset};
    vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index);
    return sampleTexture(${texName}, uv);
  }
`;
  }
  function getPackedSampler3D(inputInfo, enableShapeUniforms) {
    const shape = inputInfo.shapeInfo.logicalShape;
    const texName = inputInfo.name;
    const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
    const texShape = inputInfo.shapeInfo.texShape;
    const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
    if (shape[0] === 1) {
      const squeezedShape = shape.slice(1);
      const keptDims = [1, 2];
      const newInputInfo = squeezeInputInfo(inputInfo, squeezedShape);
      const params = ["b", "row", "col"];
      return `
        ${getPackedSamplerFromInInfo(newInputInfo, enableShapeUniforms)}
        vec4 ${funcName}(int b, int row, int col) {
          return ${funcName}(${getSqueezedParams(params, keptDims)});
        }
      `;
    }
    const glsl = getGlslDifferences();
    if (enableShapeUniforms) {
      return `
    vec4 ${funcName}(int b, int row, int col) {
      ivec2 packedTexShape = ivec2(ceil(float(${texName}TexShape[0]) / 2.0), ceil(float(${texName}TexShape[1]) / 2.0));
      int valuesPerRow = int(ceil(float(${texName}Shape[2]) / 2.0));
      int texelsInBatch = valuesPerRow * int(ceil(float(${texName}Shape[1]) / 2.0));
      vec2 uv = packedUVfrom3D(
        packedTexShape[0], packedTexShape[1], texelsInBatch, valuesPerRow, b, row, col);
      return ${glsl.texture2D}(${texName}, uv);
    }
  `;
    }
    const texNumR = packedTexShape[0];
    const texNumC = packedTexShape[1];
    const valuesPerRow = Math.ceil(shape[2] / 2);
    const texelsInBatch = valuesPerRow * Math.ceil(shape[1] / 2);
    return `
    vec4 ${funcName}(int b, int row, int col) {
      vec2 uv = packedUVfrom3D(
        ${texNumR}, ${texNumC}, ${texelsInBatch}, ${valuesPerRow}, b, row, col);
      return ${glsl.texture2D}(${texName}, uv);
    }
  `;
  }
  function getSampler3D(inputInfo, enableShapeUniforms) {
    const shape = inputInfo.shapeInfo.logicalShape;
    const texName = inputInfo.name;
    const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
    const stride0 = shape[1] * shape[2];
    const stride1 = shape[2];
    const { newShape, keptDims } = util_exports.squeezeShape(shape);
    const squeezedShape = newShape;
    if (squeezedShape.length < shape.length) {
      const newInputInfo = squeezeInputInfo(inputInfo, squeezedShape);
      const params = ["row", "col", "depth"];
      return `
        ${getSamplerFromInInfo(newInputInfo, enableShapeUniforms)}
        float ${funcName}(int row, int col, int depth) {
          return ${funcName}(${getSqueezedParams(params, keptDims)});
        }
      `;
    }
    if (inputInfo.shapeInfo.isUniform) {
      return `
      float ${funcName}(int row, int col, int depth) {
        int index = round(dot(vec3(row, col, depth),
                          vec3(${stride0}, ${stride1}, 1)));
        ${getUniformSampler(inputInfo)}
      }
    `;
    }
    const texShape = inputInfo.shapeInfo.texShape;
    const texNumR = texShape[0];
    const texNumC = texShape[1];
    const flatOffset = inputInfo.shapeInfo.flatOffset;
    if (texNumC === stride0 && flatOffset == null) {
      if (enableShapeUniforms) {
        return `
      float ${funcName}(int row, int col, int depth) {
        int stride1 = ${texName}Shape[2];
        float texR = float(row);
        float texC = dot(vec2(col, depth), vec2(stride1, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${texName}TexShape[1], ${texName}TexShape[0]);
        return sampleTexture(${texName}, uv);
      }
    `;
      }
      return `
        float ${funcName}(int row, int col, int depth) {
          float texR = float(row);
          float texC = dot(vec2(col, depth), vec2(${stride1}, 1));
          vec2 uv = (vec2(texC, texR) + halfCR) /
                     vec2(${texNumC}.0, ${texNumR}.0);
          return sampleTexture(${texName}, uv);
        }
      `;
    }
    if (texNumC === stride1 && flatOffset == null) {
      if (enableShapeUniforms) {
        return `
      float ${funcName}(int row, int col, int depth) {
        float texR = dot(vec2(row, col), vec2(${texName}Shape[1], 1));
        float texC = float(depth);
        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${texName}TexShape[1], ${texName}TexShape[0]);
        return sampleTexture(${texName}, uv);
      }
    `;
      }
      return `
    float ${funcName}(int row, int col, int depth) {
      float texR = dot(vec2(row, col), vec2(${shape[1]}, 1));
      float texC = float(depth);
      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${texNumC}.0, ${texNumR}.0);
      return sampleTexture(${texName}, uv);
    }
  `;
    }
    const offset = getFlatOffsetUniformName(texName);
    if (enableShapeUniforms) {
      return `
    float ${funcName}(int row, int col, int depth) {
      // Explicitly use integer operations as dot() only works on floats.
      int stride0 = ${texName}Shape[1] * ${texName}Shape[2];
      int stride1 = ${texName}Shape[2];
      int index = row * ${stride0} + col * ${stride1} + depth + ${offset};
      vec2 uv = uvFromFlat(${texName}TexShape[0], ${texName}TexShape[1], index);
      return sampleTexture(${texName}, uv);
    }
    `;
    }
    return `
      float ${funcName}(int row, int col, int depth) {
        // Explicitly use integer operations as dot() only works on floats.
        int index = row * ${stride0} + col * ${stride1} + depth + ${offset};
        vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index);
        return sampleTexture(${texName}, uv);
      }
  `;
  }
  function getPackedSamplerND(inputInfo, enableShapeUniforms) {
    const texName = inputInfo.name;
    const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
    const glsl = getGlslDifferences();
    if (enableShapeUniforms) {
      return `
    vec4 ${funcName}(int b2, int b, int row, int col) {
      int valuesPerRow = int(ceil(float(${texName}Shape[3]) / 2.0));
      int texelsInBatch = valuesPerRow * int(ceil(float(${texName}Shape[2]) / 2.0));
      int index = b * texelsInBatch + (row / 2) * valuesPerRow + (col / 2);
      texelsInBatch *= ${texName}Shape[1];
      index = b2 * texelsInBatch + index;
      ivec2 packedTexShape = ivec2(ceil(float(${texName}TexShape[0]) / 2.0), ceil(float(${texName}TexShape[1]) / 2.0));
      int texR = index / packedTexShape[1];
      int texC = index - texR * packedTexShape[1];
      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(packedTexShape[1], packedTexShape[0]); return ${glsl.texture2D}(${texName}, uv);
    }
  `;
    }
    const shape = inputInfo.shapeInfo.logicalShape;
    const rank = shape.length;
    const texShape = inputInfo.shapeInfo.texShape;
    const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
    const texNumR = packedTexShape[0];
    const texNumC = packedTexShape[1];
    const valuesPerRow = Math.ceil(shape[rank - 1] / 2);
    let texelsInBatch = valuesPerRow * Math.ceil(shape[rank - 2] / 2);
    let params = `int b, int row, int col`;
    let index = `b * ${texelsInBatch} + (row / 2) * ${valuesPerRow} + (col / 2)`;
    for (let b = 2; b < rank - 1; b++) {
      params = `int b${b}, ` + params;
      texelsInBatch *= shape[rank - b - 1];
      index = `b${b} * ${texelsInBatch} + ` + index;
    }
    return `
    vec4 ${funcName}(${params}) {
      int index = ${index};
      int texR = index / ${texNumC};
      int texC = index - texR * ${texNumC};
      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${texNumC}, ${texNumR});
      return ${glsl.texture2D}(${texName}, uv);
    }
  `;
  }
  function getSampler4D(inputInfo, enableShapeUniforms) {
    const shape = inputInfo.shapeInfo.logicalShape;
    const texName = inputInfo.name;
    const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
    const stride2 = shape[3];
    const stride1 = shape[2] * stride2;
    const stride0 = shape[1] * stride1;
    const { newShape, keptDims } = util_exports.squeezeShape(shape);
    if (newShape.length < shape.length) {
      const newInputInfo = squeezeInputInfo(inputInfo, newShape);
      const params = ["row", "col", "depth", "depth2"];
      return `
      ${getSamplerFromInInfo(newInputInfo, enableShapeUniforms)}
      float ${funcName}(int row, int col, int depth, int depth2) {
        return ${funcName}(${getSqueezedParams(params, keptDims)});
      }
    `;
    }
    if (inputInfo.shapeInfo.isUniform) {
      return `
      float ${funcName}(int row, int col, int depth, int depth2) {
        int index = round(dot(vec4(row, col, depth, depth2),
                          vec4(${stride0}, ${stride1}, ${stride2}, 1)));
        ${getUniformSampler(inputInfo)}
      }
    `;
    }
    const flatOffset = inputInfo.shapeInfo.flatOffset;
    const texShape = inputInfo.shapeInfo.texShape;
    const texNumR = texShape[0];
    const texNumC = texShape[1];
    const stride2Str = `int stride2 = ${texName}Shape[3];`;
    const stride1Str = `int stride1 = ${texName}Shape[2] * stride2;`;
    const stride0Str = `int stride0 = ${texName}Shape[1] * stride1;`;
    if (texNumC === stride0 && flatOffset == null) {
      if (enableShapeUniforms) {
        return `
      float ${funcName}(int row, int col, int depth, int depth2) {
        ${stride2Str}
        ${stride1Str}
        float texR = float(row);
        float texC =
            dot(vec3(col, depth, depth2),
                vec3(stride1, stride2, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${texName}TexShape[1], ${texName}TexShape[0]);
        return sampleTexture(${texName}, uv);
      }
    `;
      }
      return `
      float ${funcName}(int row, int col, int depth, int depth2) {
        float texR = float(row);
        float texC =
            dot(vec3(col, depth, depth2),
                vec3(${stride1}, ${stride2}, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${texNumC}.0, ${texNumR}.0);
        return sampleTexture(${texName}, uv);
      }
    `;
    }
    if (texNumC === stride2 && flatOffset == null) {
      if (enableShapeUniforms) {
        return `
      float ${funcName}(int row, int col, int depth, int depth2) {
        float texR = dot(vec3(row, col, depth),
                         vec3(${texName}Shape[1] * ${texName}Shape[2], ${texName}Shape[2], 1));
        float texC = float(depth2);
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${texName}TexShape[1], ${texName}TexShape[0]);
        return sampleTexture(${texName}, uv);
      }
    `;
      }
      return `
      float ${funcName}(int row, int col, int depth, int depth2) {
        float texR = dot(vec3(row, col, depth),
                         vec3(${shape[1] * shape[2]}, ${shape[2]}, 1));
        float texC = float(depth2);
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${texNumC}.0, ${texNumR}.0);
        return sampleTexture(${texName}, uv);
      }
    `;
    }
    const offset = getFlatOffsetUniformName(texName);
    if (enableShapeUniforms) {
      return `
    float ${funcName}(int row, int col, int depth, int depth2) {
      // Explicitly use integer operations as dot() only works on floats.
      ${stride2Str}
      ${stride1Str}
      ${stride0Str}
      int index = row * stride0 + col * stride1 +
          depth * stride2 + depth2;
      vec2 uv = uvFromFlat(${texName}TexShape[0], ${texName}TexShape[1], index + ${offset});
      return sampleTexture(${texName}, uv);
    }
  `;
    }
    return `
    float ${funcName}(int row, int col, int depth, int depth2) {
      // Explicitly use integer operations as dot() only works on floats.
      int index = row * ${stride0} + col * ${stride1} +
          depth * ${stride2} + depth2;
      vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index + ${offset});
      return sampleTexture(${texName}, uv);
    }
  `;
  }
  function getSampler5D(inputInfo) {
    const shape = inputInfo.shapeInfo.logicalShape;
    const texName = inputInfo.name;
    const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
    const stride3 = shape[4];
    const stride2 = shape[3] * stride3;
    const stride1 = shape[2] * stride2;
    const stride0 = shape[1] * stride1;
    const { newShape, keptDims } = util_exports.squeezeShape(shape);
    if (newShape.length < shape.length) {
      const newInputInfo = squeezeInputInfo(inputInfo, newShape);
      const params = ["row", "col", "depth", "depth2", "depth3"];
      return `
      ${getSamplerFromInInfo(newInputInfo)}
      float ${funcName}(int row, int col, int depth, int depth2, int depth3) {
        return ${funcName}(${getSqueezedParams(params, keptDims)});
      }
    `;
    }
    if (inputInfo.shapeInfo.isUniform) {
      return `
      float ${funcName}(int row, int col, int depth, int depth2, int depth3) {
        float index = dot(
          vec4(row, col, depth, depth2),
          vec4(${stride0}, ${stride1}, ${stride2}, ${stride3})) +
          depth3;
        ${getUniformSampler(inputInfo)}
      }
    `;
    }
    const flatOffset = inputInfo.shapeInfo.flatOffset;
    const texShape = inputInfo.shapeInfo.texShape;
    const texNumR = texShape[0];
    const texNumC = texShape[1];
    if (texNumC === stride0 && flatOffset == null) {
      return `
      float ${funcName}(int row, int col, int depth, int depth2, int depth3) {
        int texR = row;
        float texC = dot(vec4(col, depth, depth2, depth3),
                         vec4(${stride1}, ${stride2}, ${stride3}, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${texNumC}.0, ${texNumR}.0);
        return sampleTexture(${texName}, uv);
      }
    `;
    }
    if (texNumC === stride3 && flatOffset == null) {
      return `
      float ${funcName}(int row, int col, int depth, int depth2, int depth3) {
        float texR = dot(
          vec4(row, col, depth, depth2),
          vec4(${shape[1] * shape[2] * shape[3]},
               ${shape[2] * shape[3]}, ${shape[3]}, 1));
        int texC = depth3;
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${texNumC}.0, ${texNumR}.0);
        return sampleTexture(${texName}, uv);
      }
    `;
    }
    const offset = getFlatOffsetUniformName(texName);
    return `
    float ${funcName}(int row, int col, int depth, int depth2, int depth3) {
      // Explicitly use integer operations as dot() only works on floats.
      int index = row * ${stride0} + col * ${stride1} + depth * ${stride2} +
          depth2 * ${stride3} + depth3 + ${offset};
      vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index);
      return sampleTexture(${texName}, uv);
    }
  `;
  }
  function getSampler6D(inputInfo) {
    const shape = inputInfo.shapeInfo.logicalShape;
    const texName = inputInfo.name;
    const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
    const { newShape, keptDims } = util_exports.squeezeShape(shape);
    if (newShape.length < shape.length) {
      const newInputInfo = squeezeInputInfo(inputInfo, newShape);
      const params = ["row", "col", "depth", "depth2", "depth3", "depth4"];
      return `
      ${getSamplerFromInInfo(newInputInfo)}
      float ${funcName}(int row, int col, int depth,
                    int depth2, int depth3, int depth4) {
        return ${funcName}(${getSqueezedParams(params, keptDims)});
      }
    `;
    }
    const stride4 = shape[5];
    const stride3 = shape[4] * stride4;
    const stride2 = shape[3] * stride3;
    const stride1 = shape[2] * stride2;
    const stride0 = shape[1] * stride1;
    if (inputInfo.shapeInfo.isUniform) {
      return `
      float ${funcName}(int row, int col, int depth,
                  int depth2, int depth3, int depth4) {
        int index = round(dot(
          vec4(row, col, depth, depth2),
          vec4(${stride0}, ${stride1}, ${stride2}, ${stride3})) +
          dot(
            vec2(depth3, depth4),
            vec2(${stride4}, 1)));
        ${getUniformSampler(inputInfo)}
      }
    `;
    }
    const flatOffset = inputInfo.shapeInfo.flatOffset;
    const texShape = inputInfo.shapeInfo.texShape;
    const texNumR = texShape[0];
    const texNumC = texShape[1];
    if (texNumC === stride0 && flatOffset == null) {
      return `
      float ${funcName}(int row, int col, int depth,
                    int depth2, int depth3, int depth4) {
        int texR = row;
        float texC = dot(vec4(col, depth, depth2, depth3),
          vec4(${stride1}, ${stride2}, ${stride3}, ${stride4})) +
               float(depth4);
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${texNumC}.0, ${texNumR}.0);
        return sampleTexture(${texName}, uv);
      }
    `;
    }
    if (texNumC === stride4 && flatOffset == null) {
      return `
      float ${funcName}(int row, int col, int depth,
                    int depth2, int depth3, int depth4) {
        float texR = dot(vec4(row, col, depth, depth2),
          vec4(${shape[1] * shape[2] * shape[3] * shape[4]},
               ${shape[2] * shape[3] * shape[4]},
               ${shape[3] * shape[4]},
               ${shape[4]})) + float(depth3);
        int texC = depth4;
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${texNumC}.0, ${texNumR}.0);
        return sampleTexture(${texName}, uv);
      }
    `;
    }
    const offset = getFlatOffsetUniformName(texName);
    return `
    float ${funcName}(int row, int col, int depth,
                  int depth2, int depth3, int depth4) {
      // Explicitly use integer operations as dot() only works on floats.
      int index = row * ${stride0} + col * ${stride1} + depth * ${stride2} +
          depth2 * ${stride3} + depth3 * ${stride4} + depth4 + ${offset};
      vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index);
      return sampleTexture(${texName}, uv);
    }
  `;
  }
  function getUniformSampler(inputInfo) {
    const texName = inputInfo.name;
    const inSize = util_exports.sizeFromShape(inputInfo.shapeInfo.logicalShape);
    if (inSize < 2) {
      return `return ${texName};`;
    }
    return `
    for (int i = 0; i < ${inSize}; i++) {
      if (i == index) {
        return ${texName}[i];
      }
    }
  `;
  }
  function getPackedSamplerAtOutputCoords(inputInfo, outShapeInfo) {
    const texName = inputInfo.name;
    const texFuncSnippet = texName.charAt(0).toUpperCase() + texName.slice(1);
    const funcName = "get" + texFuncSnippet + "AtOutCoords";
    const inRank = inputInfo.shapeInfo.logicalShape.length;
    const outRank = outShapeInfo.logicalShape.length;
    const broadcastDims = getBroadcastDims2(inputInfo.shapeInfo.logicalShape, outShapeInfo.logicalShape);
    const type = getCoordsDataType(outRank);
    const rankDiff = outRank - inRank;
    let coordsSnippet;
    const fields = ["x", "y", "z", "w", "u", "v"];
    if (inRank === 0) {
      coordsSnippet = "";
    } else if (outRank < 2 && broadcastDims.length >= 1) {
      coordsSnippet = "coords = 0;";
    } else {
      coordsSnippet = broadcastDims.map((d) => `coords.${fields[d + rankDiff]} = 0;`).join("\n");
    }
    let unpackedCoordsSnippet = "";
    if (outRank < 2 && inRank > 0) {
      unpackedCoordsSnippet = "coords";
    } else {
      unpackedCoordsSnippet = inputInfo.shapeInfo.logicalShape.map((s, i) => `coords.${fields[i + rankDiff]}`).join(", ");
    }
    let output = `return outputValue;`;
    const inSize = util_exports.sizeFromShape(inputInfo.shapeInfo.logicalShape);
    const isInputScalar = inSize === 1;
    const outSize = util_exports.sizeFromShape(outShapeInfo.logicalShape);
    const isOutputScalar = outSize === 1;
    if (inRank === 1 && !isInputScalar && !isOutputScalar) {
      output = `
      return vec4(outputValue.xy, outputValue.xy);
    `;
    } else if (isInputScalar && !isOutputScalar) {
      if (outRank === 1) {
        output = `
        return vec4(outputValue.x, outputValue.x, 0., 0.);
      `;
      } else {
        output = `
        return vec4(outputValue.x);
      `;
      }
    } else if (broadcastDims.length) {
      const rows = inRank - 2;
      const cols = inRank - 1;
      if (broadcastDims.indexOf(rows) > -1 && broadcastDims.indexOf(cols) > -1) {
        output = `return vec4(outputValue.x);`;
      } else if (broadcastDims.indexOf(rows) > -1) {
        output = `return vec4(outputValue.x, outputValue.y, outputValue.x, outputValue.y);`;
      } else if (broadcastDims.indexOf(cols) > -1) {
        output = `return vec4(outputValue.xx, outputValue.zz);`;
      }
    }
    return `
    vec4 ${funcName}() {
      ${type} coords = getOutputCoords();
      ${coordsSnippet}
      vec4 outputValue = get${texFuncSnippet}(${unpackedCoordsSnippet});
      ${output}
    }
  `;
  }
  function getSamplerAtOutputCoords(inputInfo, outShapeInfo) {
    const texName = inputInfo.name;
    const texFuncSnippet = texName.charAt(0).toUpperCase() + texName.slice(1);
    const funcName = "get" + texFuncSnippet + "AtOutCoords";
    const outTexShape = outShapeInfo.texShape;
    const inTexShape = inputInfo.shapeInfo.texShape;
    const inRank = inputInfo.shapeInfo.logicalShape.length;
    const outRank = outShapeInfo.logicalShape.length;
    if (!inputInfo.shapeInfo.isUniform && inRank === outRank && inputInfo.shapeInfo.flatOffset == null && util_exports.arraysEqual(inTexShape, outTexShape)) {
      return `
      float ${funcName}() {
        return sampleTexture(${texName}, resultUV);
      }
    `;
    }
    const type = getCoordsDataType(outRank);
    const broadcastDims = getBroadcastDims2(inputInfo.shapeInfo.logicalShape, outShapeInfo.logicalShape);
    const rankDiff = outRank - inRank;
    let coordsSnippet;
    const fields = ["x", "y", "z", "w", "u", "v"];
    if (inRank === 0) {
      coordsSnippet = "";
    } else if (outRank < 2 && broadcastDims.length >= 1) {
      coordsSnippet = "coords = 0;";
    } else {
      coordsSnippet = broadcastDims.map((d) => `coords.${fields[d + rankDiff]} = 0;`).join("\n");
    }
    let unpackedCoordsSnippet = "";
    if (outRank < 2 && inRank > 0) {
      unpackedCoordsSnippet = "coords";
    } else {
      unpackedCoordsSnippet = inputInfo.shapeInfo.logicalShape.map((s, i) => `coords.${fields[i + rankDiff]}`).join(", ");
    }
    return `
    float ${funcName}() {
      ${type} coords = getOutputCoords();
      ${coordsSnippet}
      return get${texFuncSnippet}(${unpackedCoordsSnippet});
    }
  `;
  }
  function getCoordsDataType(rank) {
    if (rank <= 1) {
      return "int";
    } else if (rank === 2) {
      return "ivec2";
    } else if (rank === 3) {
      return "ivec3";
    } else if (rank === 4) {
      return "ivec4";
    } else if (rank === 5) {
      return "ivec5";
    } else if (rank === 6) {
      return "ivec6";
    } else {
      throw Error(`GPU for rank ${rank} is not yet supported`);
    }
  }
  function getUniformInfoFromShape(isPacked, shape, texShape) {
    const { newShape, keptDims } = util_exports.squeezeShape(shape);
    const rank = shape.length;
    const useSqueezePackedShape = isPacked && rank === 3 && shape[0] === 1;
    const squeezeShape2 = useSqueezePackedShape ? shape.slice(1) : newShape;
    const useSqueezeShape = !isPacked && rank > 1 && !util_exports.arraysEqual(shape, texShape) && newShape.length < rank || useSqueezePackedShape;
    const uniformShape = useSqueezeShape ? squeezeShape2 : shape;
    return { useSqueezeShape, uniformShape, keptDims };
  }
  function squeezeInputInfo(inInfo, squeezedShape) {
    const newInputInfo = JSON.parse(JSON.stringify(inInfo));
    newInputInfo.shapeInfo.logicalShape = squeezedShape;
    return newInputInfo;
  }
  function getSqueezedParams(params, keptDims) {
    return keptDims.map((d) => params[d]).join(", ");
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/gpgpu_math.js
  function compileProgram(gpgpu, program, inputs, output) {
    const inputInfos = inputs.map((input2, i) => {
      const shapeInfo = {
        logicalShape: input2.shape,
        texShape: input2.isUniform ? null : input2.texData.texShape,
        isUniform: input2.isUniform,
        isPacked: input2.isUniform ? false : input2.texData.isPacked,
        flatOffset: null
      };
      if (input2.texData != null && input2.texData.slice != null && input2.texData.slice.flatOffset > 0) {
        shapeInfo.flatOffset = input2.texData.slice.flatOffset;
      }
      return { name: program.variableNames[i], shapeInfo };
    });
    const inShapeInfos = inputInfos.map((x) => x.shapeInfo);
    const outShapeInfo = {
      logicalShape: output.shape,
      texShape: output.texData.texShape,
      isUniform: false,
      isPacked: output.texData.isPacked,
      flatOffset: null
    };
    const source = makeShader(inputInfos, outShapeInfo, program);
    const webGLProgram = gpgpu.createProgram(source);
    let infLoc = null;
    const nanLoc = gpgpu.getUniformLocation(webGLProgram, "NAN", false);
    if (env().getNumber("WEBGL_VERSION") === 1) {
      infLoc = gpgpu.getUniformLocation(webGLProgram, "INFINITY", false);
    }
    const shouldThrow = false;
    const uniformLocations = {};
    const inShapesLocations = {};
    const inTexShapesLocations = {};
    for (let i = 0; i < program.variableNames.length; i++) {
      const varName = program.variableNames[i];
      uniformLocations[varName] = gpgpu.getUniformLocation(webGLProgram, varName, shouldThrow);
      uniformLocations[`offset${varName}`] = gpgpu.getUniformLocation(webGLProgram, `offset${varName}`, shouldThrow);
      if (program.enableShapeUniforms) {
        inShapesLocations[`${varName}Shape`] = gpgpu.getUniformLocation(webGLProgram, `${varName}Shape`, shouldThrow);
        inTexShapesLocations[`${varName}TexShape`] = gpgpu.getUniformLocation(webGLProgram, `${varName}TexShape`, shouldThrow);
      }
    }
    let outShapeLocation;
    let outTexShapeLocation;
    let outShapeStridesLocation;
    if (program.enableShapeUniforms) {
      outShapeLocation = gpgpu.getUniformLocation(webGLProgram, "outShape", shouldThrow);
      outShapeStridesLocation = gpgpu.getUniformLocation(webGLProgram, "outShapeStrides", shouldThrow);
      outTexShapeLocation = gpgpu.getUniformLocation(webGLProgram, "outTexShape", shouldThrow);
    }
    const customUniformLocations = [];
    if (program.customUniforms) {
      program.customUniforms.forEach((d, i) => {
        customUniformLocations[i] = gpgpu.getUniformLocation(webGLProgram, d.name, shouldThrow);
      });
    }
    return {
      program,
      source,
      webGLProgram,
      uniformLocations,
      customUniformLocations,
      inShapeInfos,
      outShapeInfo,
      infLoc,
      nanLoc,
      inShapesLocations,
      inTexShapesLocations,
      outShapeLocation,
      outShapeStridesLocation,
      outTexShapeLocation
    };
  }
  function validateBinaryAndProgram(shapeInfos, inputs) {
    if (shapeInfos.length !== inputs.length) {
      throw Error(`Binary was compiled with ${shapeInfos.length} inputs, but was executed with ${inputs.length} inputs`);
    }
    shapeInfos.forEach((s, i) => {
      const shapeA = s.logicalShape;
      const input2 = inputs[i];
      const shapeB = input2.shape;
      if (!util_exports.arraysEqual(shapeA, shapeB)) {
        throw Error(`Binary was compiled with different shapes than the current args. Shapes ${shapeA} and ${shapeB} must match`);
      }
      if (s.isUniform && input2.isUniform) {
        return;
      }
      const texShapeA = s.texShape;
      const texShapeB = input2.isUniform ? null : input2.texData.texShape;
      if (!util_exports.arraysEqual(texShapeA, texShapeB)) {
        throw Error(`Binary was compiled with different texture shapes than the current args. Shape ${texShapeA} and ${texShapeB} must match`);
      }
    });
  }
  function runProgram(gpgpu, binary, inputs, output, customUniformValues) {
    if (!binary.program.enableShapeUniforms) {
      validateBinaryAndProgram(binary.inShapeInfos, inputs);
      validateBinaryAndProgram([binary.outShapeInfo], [output]);
    }
    const outTex = output.texData.texture;
    const outTexShape = output.texData.texShape;
    if (output.texData.isPacked) {
      gpgpu.setOutputPackedMatrixTexture(outTex, outTexShape[0], outTexShape[1]);
    } else {
      gpgpu.setOutputMatrixTexture(outTex, outTexShape[0], outTexShape[1]);
    }
    gpgpu.setProgram(binary.webGLProgram);
    if (env().getNumber("WEBGL_VERSION") === 1) {
      if (binary.infLoc !== null) {
        gpgpu.gl.uniform1f(binary.infLoc, Infinity);
      }
    }
    if (binary.nanLoc !== null) {
      gpgpu.gl.uniform1f(binary.nanLoc, NaN);
    }
    inputs.forEach((input2, i) => {
      const varName = binary.program.variableNames[i];
      const varLoc = binary.uniformLocations[varName];
      const varOffsetLoc = binary.uniformLocations[`offset${varName}`];
      const varShapeLoc = binary.inShapesLocations[`${varName}Shape`];
      const varTexShapeLoc = binary.inTexShapesLocations[`${varName}TexShape`];
      if (varShapeLoc) {
        const { uniformShape } = getUniformInfoFromShape(binary.program.packedInputs, input2.shape, input2.texData.texShape);
        switch (uniformShape.length) {
          case 1:
            gpgpu.gl.uniform1iv(varShapeLoc, new Int32Array(uniformShape));
            break;
          case 2:
            gpgpu.gl.uniform2iv(varShapeLoc, new Int32Array(uniformShape));
            break;
          case 3:
            gpgpu.gl.uniform3iv(varShapeLoc, new Int32Array(uniformShape));
            break;
          case 4:
            gpgpu.gl.uniform4iv(varShapeLoc, new Int32Array(uniformShape));
            break;
          default:
            break;
        }
      }
      if (varTexShapeLoc) {
        gpgpu.gl.uniform2i(varTexShapeLoc, input2.texData.texShape[0], input2.texData.texShape[1]);
      }
      if (varLoc == null) {
        return;
      }
      if (input2.isUniform) {
        if (util_exports.sizeFromShape(input2.shape) < 2) {
          gpgpu.gl.uniform1f(varLoc, input2.uniformValues[0]);
        } else {
          let vals = input2.uniformValues;
          if (!(vals instanceof Float32Array)) {
            vals = new Float32Array(vals);
          }
          gpgpu.gl.uniform1fv(varLoc, vals);
        }
        return;
      }
      if (input2.texData.slice != null && varOffsetLoc != null) {
        gpgpu.gl.uniform1i(varOffsetLoc, input2.texData.slice.flatOffset);
      }
      gpgpu.setInputMatrixTexture(input2.texData.texture, varLoc, i);
    });
    const outShapeLoc = binary.outShapeLocation;
    if (outShapeLoc) {
      switch (output.shape.length) {
        case 1:
          gpgpu.gl.uniform1iv(outShapeLoc, new Int32Array(output.shape));
          break;
        case 2:
          gpgpu.gl.uniform2iv(outShapeLoc, new Int32Array(output.shape));
          break;
        case 3:
          gpgpu.gl.uniform3iv(outShapeLoc, new Int32Array(output.shape));
          break;
        case 4:
          gpgpu.gl.uniform4iv(outShapeLoc, new Int32Array(output.shape));
          break;
        default:
          break;
      }
    }
    if (binary.outShapeStridesLocation) {
      const strides = util_exports.computeStrides(output.shape);
      switch (output.shape.length) {
        case 2:
          gpgpu.gl.uniform1iv(binary.outShapeStridesLocation, new Int32Array(strides));
          break;
        case 3:
          gpgpu.gl.uniform2iv(binary.outShapeStridesLocation, new Int32Array(strides));
          break;
        case 4:
          gpgpu.gl.uniform3iv(binary.outShapeStridesLocation, new Int32Array(strides));
          break;
        default:
          break;
      }
    }
    if (binary.outTexShapeLocation) {
      gpgpu.gl.uniform2i(binary.outTexShapeLocation, output.texData.texShape[0], output.texData.texShape[1]);
    }
    if (binary.program.customUniforms && customUniformValues) {
      binary.program.customUniforms.forEach((d, i) => {
        const customLoc = binary.customUniformLocations[i];
        const customValue = customUniformValues[i];
        if (d.type === "float") {
          gpgpu.gl.uniform1fv(customLoc, customValue);
        } else if (d.type === "vec2") {
          gpgpu.gl.uniform2fv(customLoc, customValue);
        } else if (d.type === "vec3") {
          gpgpu.gl.uniform3fv(customLoc, customValue);
        } else if (d.type === "vec4") {
          gpgpu.gl.uniform4fv(customLoc, customValue);
        } else if (d.type === "int") {
          gpgpu.gl.uniform1iv(customLoc, customValue);
        } else if (d.type === "ivec2") {
          gpgpu.gl.uniform2iv(customLoc, customValue);
        } else if (d.type === "ivec3") {
          gpgpu.gl.uniform3iv(customLoc, customValue);
        } else if (d.type === "ivec4") {
          gpgpu.gl.uniform4iv(customLoc, customValue);
        } else {
          throw Error(`uniform type ${d.type} is not supported yet.`);
        }
      });
    }
    gpgpu.executeProgram();
  }
  function makeShaderKey(program, inputs, output) {
    let keyInputs = "";
    inputs.concat(output).forEach((x) => {
      const hasOffset = x.texData != null && x.texData.slice != null && x.texData.slice.flatOffset > 0;
      if (program.enableShapeUniforms && !x.isUniform) {
        const xTexShape = x.texData.texShape;
        const { useSqueezeShape, uniformShape, keptDims } = getUniformInfoFromShape(program.packedInputs, x.shape, xTexShape);
        let rank1 = "", rank2 = "", rank34 = "";
        if (uniformShape.length === 1 && program.packedInputs) {
          const packedTexShape = [Math.ceil(xTexShape[0] / 2), Math.ceil(xTexShape[1] / 2)];
          rank1 = `${packedTexShape[0] > 1}_${packedTexShape[1] > 1}`;
        } else if (uniformShape.length === 2 && !program.packedInputs) {
          rank2 = `${uniformShape[0] > 1}_${uniformShape[1] > 1}`;
        } else if (uniformShape.length > 2 && !program.packedInputs) {
          const strides = util_exports.computeStrides(uniformShape);
          rank34 = `${strides[0] === xTexShape[1]}_${strides[strides.length - 1] === xTexShape[1]}`;
        }
        const xRank = x.shape.length;
        const isLogicalShapTexShapeEqual = uniformShape.length === 2 && util_exports.arraysEqual(x.shape, xTexShape);
        const isScalar = util_exports.sizeFromShape(x.shape) === 1;
        const broadcastDims = backend_util_exports.getBroadcastDims(x.shape, output.shape);
        const isInOutTexShapeEqual = !program.packedInputs && xRank === output.shape.length && util_exports.arraysEqual(xTexShape, output.texData.texShape);
        const isTexShapeGreaterThanOne = program.packedInputs || uniformShape.length > 2 ? "" : `${xTexShape[0] > 1}_${xTexShape[1] > 1}`;
        keyInputs += `${xRank}_${isInOutTexShapeEqual}_${useSqueezeShape ? keptDims : ""}_${uniformShape.length}_${isScalar}_${broadcastDims}_${isLogicalShapTexShapeEqual}_${rank1}_${rank2}_${rank34}_${isTexShapeGreaterThanOne}_${hasOffset}`;
      } else {
        const texShape = x.isUniform ? "uniform" : x.texData.texShape;
        keyInputs += `${x.shape}_${texShape}_${hasOffset}`;
      }
    });
    const keyUserCode = program.userCode;
    let key = program.constructor.name;
    key += "_" + keyInputs + "_" + keyUserCode + `${env().getNumber("WEBGL_VERSION")}`;
    return key;
  }
  function useShapeUniforms(rank) {
    return env().getBool("WEBGL_USE_SHAPES_UNIFORMS") && rank <= 4;
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/decode_matrix_gpu.js
  var DecodeMatrixProgram = class {
    constructor(outputShape) {
      this.variableNames = ["A"];
      this.packedInputs = false;
      this.packedOutput = true;
      this.outPackingScheme = PackingScheme.DENSE;
      this.customUniforms = [{ name: "texShape", type: "ivec2" }];
      const glsl = getGlslDifferences();
      this.outputShape = outputShape;
      this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
      this.userCode = `
      ivec3 outCoordsFromFlatIndex(int index) {
        ${this.enableShapeUniforms ? getOutputLogicalCoordinatesFromFlatIndexByUniform(["r", "c", "d"], outputShape) : getLogicalCoordinatesFromFlatIndex(["r", "c", "d"], outputShape)}
        return ivec3(r, c, d);
      }

      void main() {
        ivec2 resTexRC = ivec2(resultUV.yx * vec2(texShape[0], texShape[1]));
        int index = 4 * (resTexRC.x * texShape[1] + resTexRC.y);

        vec4 result = vec4(0.);

        for (int i=0; i<4; i++) {
          int flatIndex = index + i;
          ivec3 rc = outCoordsFromFlatIndex(flatIndex);
          result[i] = getA(rc.x, rc.y, rc.z);
        }

        ${glsl.output} = result;
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/decode_matrix_packed_gpu.js
  var DecodeMatrixPackedProgram = class {
    constructor(outputShape) {
      this.variableNames = ["A"];
      this.packedInputs = true;
      this.packedOutput = true;
      this.outPackingScheme = PackingScheme.DENSE;
      this.customUniforms = [{ name: "texShape", type: "ivec2" }];
      const glsl = getGlslDifferences();
      this.outputShape = outputShape;
      this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
      this.userCode = `
      ivec3 outCoordsFromFlatIndex(int index) {
        ${this.enableShapeUniforms ? getOutputLogicalCoordinatesFromFlatIndexByUniform(["r", "c", "d"], outputShape) : getLogicalCoordinatesFromFlatIndex(["r", "c", "d"], outputShape)}
        return ivec3(r, c, d);
      }

      void main() {
        ivec2 resTexRC = ivec2(resultUV.yx * vec2(texShape[0], texShape[1]));
        int index = 4 * (resTexRC.x * texShape[1] + resTexRC.y);

        vec4 result = vec4(0.);

        for (int i=0; i<4; i++) {
          int flatIndex = index + i;
          ivec3 rc = outCoordsFromFlatIndex(flatIndex);
          result[i] = getChannel(getA(rc.x, rc.y, rc.z), vec2(rc.y, rc.z));
        }

        ${glsl.output} = result;
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/encode_float_gpu.js
  var EncodeFloatProgram = class {
    constructor(outputShape) {
      this.variableNames = ["A"];
      this.outTexUsage = TextureUsage.DOWNLOAD;
      const glsl = getGlslDifferences();
      this.outputShape = outputShape;
      this.userCode = `
      ${ENCODE_FLOAT_SNIPPET}

      void main() {
        float x = getAAtOutCoords();
        ${glsl.output} = encode_float(x);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/encode_float_packed_gpu.js
  var EncodeFloatPackedProgram = class {
    constructor(outputShape) {
      this.variableNames = ["A"];
      this.packedInputs = true;
      this.packedOutput = false;
      this.outTexUsage = TextureUsage.DOWNLOAD;
      const glsl = getGlslDifferences();
      this.outputShape = outputShape;
      this.userCode = `
      ${ENCODE_FLOAT_SNIPPET}

      void main() {
        ivec3 coords = getOutputCoords();
        float x = getChannel(getAAtOutCoords(), vec2(coords.y, coords.z));
        ${glsl.output} = encode_float(x);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/encode_matrix_gpu.js
  var EncodeMatrixProgram = class {
    constructor(outputShape, inputIsUnsignedByte = false) {
      this.variableNames = ["A"];
      this.customUniforms = [{ name: "texShape", type: "ivec2" }];
      const glsl = getGlslDifferences();
      this.outputShape = outputShape;
      this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
      let output = `result`;
      if (inputIsUnsignedByte) {
        output = `floor(result * 255. + 0.5)`;
      }
      this.userCode = `
      ${this.enableShapeUniforms ? getFlatIndexFrom3DOutput() : getFlatIndexFrom3D(outputShape)}

      void main() {
        ivec3 coords = getOutputCoords();

        int flatIndex = getFlatIndex(coords);
        int offset = imod(flatIndex, 4);

        flatIndex = idiv(flatIndex, 4, 1.);

        int r = flatIndex / texShape[1];
        int c = imod(flatIndex, texShape[1]);
        vec2 uv = (vec2(c, r) + halfCR) / vec2(texShape[1], texShape[0]);
        vec4 values = ${glsl.texture2D}(A, uv);

        float result;

        if(offset == 0) {
          result = values[0];
        } else if(offset == 1) {
          result = values[1];
        } else if(offset == 2) {
          result = values[2];
        } else {
          result = values[3];
        }

        ${glsl.output} = vec4(${output}, 0., 0., 0.);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/encode_matrix_packed_gpu.js
  var EncodeMatrixPackedProgram = class {
    constructor(outputShape, inputIsUnsignedByte = false) {
      this.variableNames = ["A"];
      this.packedInputs = false;
      this.packedOutput = true;
      this.customUniforms = [{ name: "texShape", type: "ivec2" }];
      const glsl = getGlslDifferences();
      this.outputShape = outputShape;
      this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
      let mainLoop = "";
      let output = "result";
      if (inputIsUnsignedByte) {
        output = "floor(result * 255. + 0.5)";
      }
      for (let row = 0; row <= 1; row++) {
        for (let col = 0; col <= 1; col++) {
          const channel = row * 2 + col;
          mainLoop += `
          localCoords = coords;
          if(localCoords[2] + ${col} < ${this.enableShapeUniforms ? "outShape[2]" : `${outputShape[2]}`}) {
          localCoords[2] += ${col};
          if (localCoords[1] + ${row} < ${this.enableShapeUniforms ? "outShape[1]" : `${outputShape[1]}`}) {
            localCoords[1] += ${row};

            flatIndex = getFlatIndex(localCoords);
            offset = imod(flatIndex, 4);

            flatIndex = idiv(flatIndex, 4, 1.);

            int r = flatIndex / texShape[1];
            int c = imod(flatIndex, texShape[1]);
            vec2 uv = (vec2(c, r) + halfCR) / vec2(texShape[1], texShape[0]);
            values = ${glsl.texture2D}(A, uv);

            if (offset == 0) {
              result[${channel}] = values[0];
            } else if (offset == 1) {
              result[${channel}] = values[1];
            } else if (offset == 2) {
              result[${channel}] = values[2];
            } else {
              result[${channel}] = values[3];
            }
          }
        }
        `;
        }
      }
      this.userCode = `
        ${this.enableShapeUniforms ? getFlatIndexFrom3DOutput() : getFlatIndexFrom3D(outputShape)}

        void main() {
          ivec3 coords = getOutputCoords();

          vec4 result = vec4(0.);
          int flatIndex, r, c, offset;
          ivec3 localCoords;
          vec2 uv;
          vec4 values;

          ${mainLoop}

          ${glsl.output} = ${output};
        }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/gpgpu_util.js
  function createVertexShader2(gl) {
    const glsl = getGlslDifferences();
    const vertexShaderSource = `${glsl.version}
    precision highp float;
    ${glsl.attribute} vec3 clipSpacePos;
    ${glsl.attribute} vec2 uv;
    ${glsl.varyingVs} vec2 resultUV;

    void main() {
      gl_Position = vec4(clipSpacePos, 1);
      resultUV = uv;
    }`;
    return createVertexShader(gl, vertexShaderSource);
  }
  function createVertexBuffer(gl) {
    const vertexArray = new Float32Array([-1, 1, 0, 0, 1, -1, -1, 0, 0, 0, 1, 1, 0, 1, 1, 1, -1, 0, 1, 0]);
    return createStaticVertexBuffer(gl, vertexArray);
  }
  function createIndexBuffer(gl) {
    const triangleVertexIndices = new Uint16Array([0, 1, 2, 2, 1, 3]);
    return createStaticIndexBuffer(gl, triangleVertexIndices);
  }
  function createAndConfigureTexture(gl, width, height, internalFormat, textureFormat, textureType) {
    validateTextureSize(width, height);
    const texture = createTexture(gl);
    const tex2d = gl.TEXTURE_2D;
    callAndCheck(gl, () => gl.bindTexture(tex2d, texture));
    callAndCheck(gl, () => gl.texParameteri(tex2d, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE));
    callAndCheck(gl, () => gl.texParameteri(tex2d, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE));
    callAndCheck(gl, () => gl.texParameteri(tex2d, gl.TEXTURE_MIN_FILTER, gl.NEAREST));
    callAndCheck(gl, () => gl.texParameteri(tex2d, gl.TEXTURE_MAG_FILTER, gl.NEAREST));
    callAndCheck(gl, () => gl.texImage2D(tex2d, 0, internalFormat, width, height, 0, textureFormat, textureType, null));
    callAndCheck(gl, () => gl.bindTexture(gl.TEXTURE_2D, null));
    return texture;
  }
  function getInternalFormatForFloat32MatrixTexture(textureConfig) {
    return textureConfig.internalFormatFloat;
  }
  function createFloat32MatrixTexture(gl, rows, columns, textureConfig) {
    const [width, height] = getUnpackedMatrixTextureShapeWidthHeight(rows, columns);
    return createAndConfigureTexture(gl, width, height, getInternalFormatForFloat32MatrixTexture(textureConfig), textureConfig.textureFormatFloat, gl.FLOAT);
  }
  function getInternalFormatForFloat16MatrixTexture(textureConfig) {
    return textureConfig.internalFormatHalfFloat;
  }
  function createFloat16MatrixTexture(gl, rows, columns, textureConfig) {
    const [width, height] = getUnpackedMatrixTextureShapeWidthHeight(rows, columns);
    return createAndConfigureTexture(gl, width, height, getInternalFormatForFloat16MatrixTexture(textureConfig), textureConfig.textureFormatFloat, textureConfig.textureTypeHalfFloat);
  }
  function getInternalFormatForUnsignedBytesMatrixTexture(textureConfig) {
    return textureConfig.downloadTextureFormat;
  }
  function createUnsignedBytesMatrixTexture(gl, rows, columns, textureConfig) {
    const [width, height] = getUnpackedMatrixTextureShapeWidthHeight(rows, columns);
    return createAndConfigureTexture(gl, width, height, getInternalFormatForUnsignedBytesMatrixTexture(textureConfig), gl.RGBA, gl.UNSIGNED_BYTE);
  }
  function getInternalFormatForPackedMatrixTexture(textureConfig) {
    return textureConfig.internalFormatPackedFloat;
  }
  function createPackedMatrixTexture(gl, rows, columns, textureConfig) {
    const [width, height] = getPackedMatrixTextureShapeWidthHeight(rows, columns);
    return createAndConfigureTexture(gl, width, height, getInternalFormatForPackedMatrixTexture(textureConfig), gl.RGBA, gl.FLOAT);
  }
  function getInternalFormatForFloat16PackedMatrixTexture(textureConfig) {
    return textureConfig.internalFormatPackedHalfFloat;
  }
  function createFloat16PackedMatrixTexture(gl, rows, columns, textureConfig) {
    const [width, height] = getPackedMatrixTextureShapeWidthHeight(rows, columns);
    return createAndConfigureTexture(gl, width, height, getInternalFormatForFloat16PackedMatrixTexture(textureConfig), gl.RGBA, textureConfig.textureTypeHalfFloat);
  }
  function bindVertexProgramAttributeStreams(gl, program, vertexBuffer) {
    const posOffset = 0;
    const uvOffset = 3 * 4;
    const stride = 3 * 4 + 2 * 4;
    callAndCheck(gl, () => gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer));
    const success = bindVertexBufferToProgramAttribute(gl, program, "clipSpacePos", vertexBuffer, 3, stride, posOffset);
    return success && bindVertexBufferToProgramAttribute(gl, program, "uv", vertexBuffer, 2, stride, uvOffset);
  }
  function uploadDenseMatrixToTexture(gl, texture, width, height, data, textureConfig) {
    callAndCheck(gl, () => gl.bindTexture(gl.TEXTURE_2D, texture));
    let dataForUpload, texelDataType, internalFormat;
    if (data instanceof Uint8Array) {
      dataForUpload = new Uint8Array(width * height * 4);
      texelDataType = gl.UNSIGNED_BYTE;
      internalFormat = gl.RGBA;
    } else {
      dataForUpload = new Float32Array(width * height * 4);
      texelDataType = gl.FLOAT;
      internalFormat = textureConfig.internalFormatPackedFloat;
    }
    dataForUpload.set(data);
    callAndCheck(gl, () => gl.texImage2D(gl.TEXTURE_2D, 0, internalFormat, width, height, 0, gl.RGBA, texelDataType, dataForUpload));
    callAndCheck(gl, () => gl.bindTexture(gl.TEXTURE_2D, null));
  }
  function uploadPixelDataToTexture(gl, texture, pixels) {
    callAndCheck(gl, () => gl.bindTexture(gl.TEXTURE_2D, texture));
    if (pixels.data instanceof Uint8Array) {
      callAndCheck(gl, () => gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, pixels.width, pixels.height, 0, gl.RGBA, gl.UNSIGNED_BYTE, pixels.data));
    } else {
      callAndCheck(gl, () => gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, pixels));
    }
    callAndCheck(gl, () => gl.bindTexture(gl.TEXTURE_2D, null));
  }
  function createBufferFromOutputTexture(gl2, rows, columns, textureConfig) {
    const buffer3 = gl2.createBuffer();
    callAndCheck(gl2, () => gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, buffer3));
    const bytesPerFloat = 4;
    const valuesPerTexel = 4;
    const bufferSizeBytes = bytesPerFloat * valuesPerTexel * rows * columns;
    callAndCheck(gl2, () => gl2.bufferData(gl2.PIXEL_PACK_BUFFER, bufferSizeBytes, gl2.STREAM_READ));
    callAndCheck(gl2, () => gl2.readPixels(0, 0, columns, rows, gl2.RGBA, gl2.FLOAT, 0));
    callAndCheck(gl2, () => gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, null));
    return buffer3;
  }
  function downloadFloat32MatrixFromBuffer(gl, buffer3, size2) {
    const gl2 = gl;
    const downloadTarget = new Float32Array(size2);
    gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, buffer3);
    gl2.getBufferSubData(gl2.PIXEL_PACK_BUFFER, 0, downloadTarget);
    gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, null);
    return downloadTarget;
  }
  function downloadByteEncodedFloatMatrixFromOutputTexture(gl, rows, columns, textureConfig) {
    const [w, h2] = getUnpackedMatrixTextureShapeWidthHeight(rows, columns);
    const numChannels = 4;
    const downloadTarget = new Uint8Array(getUnpackedArraySizeFromMatrixSize(rows * columns, numChannels));
    callAndCheck(gl, () => gl.readPixels(0, 0, w, h2, textureConfig.downloadTextureFormat, gl.UNSIGNED_BYTE, downloadTarget));
    return new Float32Array(downloadTarget.buffer);
  }
  function downloadPackedMatrixFromBuffer(gl, buffer3, batch, rows, cols, physicalRows, physicalCols, textureConfig) {
    const gl2 = gl;
    const downloadTarget = new Float32Array(getPackedRGBAArraySizeFromMatrixShape(physicalRows, physicalCols));
    gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, buffer3);
    gl2.getBufferSubData(gl2.PIXEL_PACK_BUFFER, 0, downloadTarget);
    gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, null);
    return downloadTarget;
  }
  function downloadMatrixFromPackedOutputTexture(gl, physicalRows, physicalCols) {
    const packedRGBA = new Float32Array(physicalRows * physicalCols * 4);
    callAndCheck(gl, () => gl.readPixels(0, 0, physicalCols, physicalRows, gl.RGBA, gl.FLOAT, packedRGBA));
    return packedRGBA;
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/gpgpu_context.js
  var GPGPUContext = class {
    constructor(gl) {
      this.outputTexture = null;
      this.program = null;
      this.disposed = false;
      this.vertexAttrsAreBound = false;
      this.itemsToPoll = [];
      const glVersion = env().getNumber("WEBGL_VERSION");
      if (gl != null) {
        this.gl = gl;
        setWebGLContext(glVersion, gl);
      } else {
        this.gl = getWebGLContext(glVersion);
      }
      let COLOR_BUFFER_FLOAT = "WEBGL_color_buffer_float";
      const COLOR_BUFFER_HALF_FLOAT = "EXT_color_buffer_half_float";
      if (env().getNumber("WEBGL_VERSION") === 1) {
        const TEXTURE_FLOAT = "OES_texture_float";
        const TEXTURE_HALF_FLOAT = "OES_texture_half_float";
        this.textureFloatExtension = getExtensionOrThrow(this.gl, TEXTURE_FLOAT);
        if (hasExtension(this.gl, TEXTURE_HALF_FLOAT)) {
          this.textureHalfFloatExtension = getExtensionOrThrow(this.gl, TEXTURE_HALF_FLOAT);
        } else if (env().get("WEBGL_FORCE_F16_TEXTURES")) {
          throw new Error("GL context does not support half float textures, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");
        }
        this.colorBufferFloatExtension = this.gl.getExtension(COLOR_BUFFER_FLOAT);
        if (hasExtension(this.gl, COLOR_BUFFER_HALF_FLOAT)) {
          this.colorBufferHalfFloatExtension = getExtensionOrThrow(this.gl, COLOR_BUFFER_HALF_FLOAT);
        } else if (env().get("WEBGL_FORCE_F16_TEXTURES")) {
          throw new Error("GL context does not support color renderable half floats, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");
        }
      } else {
        COLOR_BUFFER_FLOAT = "EXT_color_buffer_float";
        if (hasExtension(this.gl, COLOR_BUFFER_FLOAT)) {
          this.colorBufferFloatExtension = this.gl.getExtension(COLOR_BUFFER_FLOAT);
        } else if (hasExtension(this.gl, COLOR_BUFFER_HALF_FLOAT)) {
          this.colorBufferHalfFloatExtension = this.gl.getExtension(COLOR_BUFFER_HALF_FLOAT);
        } else {
          throw new Error("GL context does not support color renderable floats");
        }
      }
      this.vertexBuffer = createVertexBuffer(this.gl);
      this.indexBuffer = createIndexBuffer(this.gl);
      this.framebuffer = createFramebuffer(this.gl);
      this.textureConfig = getTextureConfig(this.gl, this.textureHalfFloatExtension);
    }
    get debug() {
      return env().getBool("DEBUG");
    }
    dispose() {
      if (this.disposed) {
        return;
      }
      if (this.program != null) {
        console.warn("Disposing a GPGPUContext that still has a bound WebGLProgram. This is probably a resource leak, delete the program with GPGPUContext.deleteProgram before disposing.");
      }
      if (this.outputTexture != null) {
        console.warn("Disposing a GPGPUContext that still has a bound output matrix texture.  This is probably a resource leak, delete the output matrix texture with GPGPUContext.deleteMatrixTexture before disposing.");
      }
      const gl = this.gl;
      callAndCheck(gl, () => gl.finish());
      callAndCheck(gl, () => gl.bindFramebuffer(gl.FRAMEBUFFER, null));
      callAndCheck(gl, () => gl.deleteFramebuffer(this.framebuffer));
      callAndCheck(gl, () => gl.bindBuffer(gl.ARRAY_BUFFER, null));
      callAndCheck(gl, () => gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, null));
      callAndCheck(gl, () => gl.deleteBuffer(this.indexBuffer));
      this.disposed = true;
    }
    createFloat32MatrixTexture(rows, columns) {
      this.throwIfDisposed();
      return createFloat32MatrixTexture(this.gl, rows, columns, this.textureConfig);
    }
    createFloat16MatrixTexture(rows, columns) {
      this.throwIfDisposed();
      return createFloat16MatrixTexture(this.gl, rows, columns, this.textureConfig);
    }
    createUnsignedBytesMatrixTexture(rows, columns) {
      this.throwIfDisposed();
      return createUnsignedBytesMatrixTexture(this.gl, rows, columns, this.textureConfig);
    }
    uploadPixelDataToTexture(texture, pixels) {
      this.throwIfDisposed();
      uploadPixelDataToTexture(this.gl, texture, pixels);
    }
    uploadDenseMatrixToTexture(texture, width, height, data) {
      this.throwIfDisposed();
      uploadDenseMatrixToTexture(this.gl, texture, width, height, data, this.textureConfig);
    }
    createFloat16PackedMatrixTexture(rows, columns) {
      this.throwIfDisposed();
      return createFloat16PackedMatrixTexture(this.gl, rows, columns, this.textureConfig);
    }
    createPackedMatrixTexture(rows, columns) {
      this.throwIfDisposed();
      return createPackedMatrixTexture(this.gl, rows, columns, this.textureConfig);
    }
    deleteMatrixTexture(texture) {
      this.throwIfDisposed();
      if (this.outputTexture === texture) {
        unbindColorTextureFromFramebuffer(this.gl, this.framebuffer);
        this.outputTexture = null;
      }
      callAndCheck(this.gl, () => this.gl.deleteTexture(texture));
    }
    downloadByteEncodedFloatMatrixFromOutputTexture(texture, rows, columns) {
      return this.downloadMatrixDriver(texture, () => downloadByteEncodedFloatMatrixFromOutputTexture(this.gl, rows, columns, this.textureConfig));
    }
    downloadPackedMatrixFromBuffer(buffer3, batch, rows, columns, physicalRows, physicalCols) {
      return downloadPackedMatrixFromBuffer(this.gl, buffer3, batch, rows, columns, physicalRows, physicalCols, this.textureConfig);
    }
    downloadFloat32MatrixFromBuffer(buffer3, size2) {
      return downloadFloat32MatrixFromBuffer(this.gl, buffer3, size2);
    }
    createBufferFromTexture(texture, rows, columns) {
      this.bindTextureToFrameBuffer(texture);
      const result = createBufferFromOutputTexture(this.gl, rows, columns, this.textureConfig);
      this.unbindTextureToFrameBuffer();
      return result;
    }
    createAndWaitForFence() {
      const fenceContext = this.createFence(this.gl);
      return this.pollFence(fenceContext);
    }
    createFence(gl) {
      let query;
      let isFencePassed;
      if (env().getBool("WEBGL_FENCE_API_ENABLED")) {
        const gl2 = gl;
        const sync = gl2.fenceSync(gl2.SYNC_GPU_COMMANDS_COMPLETE, 0);
        gl.flush();
        isFencePassed = () => {
          const status = gl2.clientWaitSync(sync, 0, 0);
          return status === gl2.ALREADY_SIGNALED || status === gl2.CONDITION_SATISFIED;
        };
        query = sync;
      } else if (env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") > 0) {
        query = this.beginQuery();
        this.endQuery();
        isFencePassed = () => this.isQueryAvailable(query, env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"));
      } else {
        isFencePassed = () => true;
      }
      return { query, isFencePassed };
    }
    downloadMatrixFromPackedTexture(texture, physicalRows, physicalCols) {
      return this.downloadMatrixDriver(texture, () => downloadMatrixFromPackedOutputTexture(this.gl, physicalRows, physicalCols));
    }
    createProgram(fragmentShaderSource) {
      this.throwIfDisposed();
      const gl = this.gl;
      const fragmentShader = createFragmentShader(gl, fragmentShaderSource);
      if (this.vertexShader == null) {
        this.vertexShader = createVertexShader2(gl);
      }
      const program = createProgram(gl);
      callAndCheck(gl, () => gl.attachShader(program, this.vertexShader));
      callAndCheck(gl, () => gl.attachShader(program, fragmentShader));
      linkProgram(gl, program);
      if (this.debug) {
        validateProgram(gl, program);
      }
      if (!this.vertexAttrsAreBound) {
        this.setProgram(program);
        this.vertexAttrsAreBound = bindVertexProgramAttributeStreams(gl, this.program, this.vertexBuffer);
      }
      return program;
    }
    deleteProgram(program) {
      this.throwIfDisposed();
      if (program === this.program) {
        this.program = null;
      }
      if (program != null) {
        callAndCheck(this.gl, () => this.gl.deleteProgram(program));
      }
    }
    setProgram(program) {
      this.throwIfDisposed();
      this.program = program;
      if (this.program != null && this.debug) {
        validateProgram(this.gl, this.program);
      }
      callAndCheck(this.gl, () => this.gl.useProgram(program));
    }
    getUniformLocation(program, uniformName, shouldThrow = true) {
      this.throwIfDisposed();
      if (shouldThrow) {
        return getProgramUniformLocationOrThrow(this.gl, program, uniformName);
      } else {
        return getProgramUniformLocation(this.gl, program, uniformName);
      }
    }
    getAttributeLocation(program, attribute) {
      this.throwIfDisposed();
      return callAndCheck(this.gl, () => this.gl.getAttribLocation(program, attribute));
    }
    getUniformLocationNoThrow(program, uniformName) {
      this.throwIfDisposed();
      return this.gl.getUniformLocation(program, uniformName);
    }
    setInputMatrixTexture(inputMatrixTexture, uniformLocation, textureUnit) {
      this.throwIfDisposed();
      this.throwIfNoProgram();
      bindTextureToProgramUniformSampler(this.gl, inputMatrixTexture, uniformLocation, textureUnit);
    }
    setOutputMatrixTexture(outputMatrixTexture, rows, columns) {
      this.setOutputMatrixTextureDriver(outputMatrixTexture, columns, rows);
    }
    setOutputPackedMatrixTexture(outputPackedMatrixTexture, rows, columns) {
      this.throwIfDisposed();
      const [width, height] = getPackedMatrixTextureShapeWidthHeight(rows, columns);
      this.setOutputMatrixTextureDriver(outputPackedMatrixTexture, width, height);
    }
    setOutputMatrixWriteRegion(startRow, numRows, startColumn, numColumns) {
      this.setOutputMatrixWriteRegionDriver(startColumn, startRow, numColumns, numRows);
    }
    setOutputPackedMatrixWriteRegion(startRow, numRows, startColumn, numColumns) {
      throw new Error("setOutputPackedMatrixWriteRegion not implemented.");
    }
    debugValidate() {
      if (this.program != null) {
        validateProgram(this.gl, this.program);
      }
      validateFramebuffer(this.gl);
    }
    executeProgram() {
      this.throwIfDisposed();
      this.throwIfNoProgram();
      const gl = this.gl;
      if (this.debug) {
        this.debugValidate();
      }
      callAndCheck(gl, () => gl.drawElements(gl.TRIANGLES, 6, gl.UNSIGNED_SHORT, 0));
    }
    blockUntilAllProgramsCompleted() {
      this.throwIfDisposed();
      callAndCheck(this.gl, () => this.gl.finish());
    }
    getQueryTimerExtension() {
      if (this.disjointQueryTimerExtension == null) {
        this.disjointQueryTimerExtension = getExtensionOrThrow(this.gl, env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") === 2 ? "EXT_disjoint_timer_query_webgl2" : "EXT_disjoint_timer_query");
      }
      return this.disjointQueryTimerExtension;
    }
    getQueryTimerExtensionWebGL2() {
      return this.getQueryTimerExtension();
    }
    getQueryTimerExtensionWebGL1() {
      return this.getQueryTimerExtension();
    }
    beginQuery() {
      if (env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") === 2) {
        const gl2 = this.gl;
        const ext2 = this.getQueryTimerExtensionWebGL2();
        const query2 = gl2.createQuery();
        gl2.beginQuery(ext2.TIME_ELAPSED_EXT, query2);
        return query2;
      }
      const ext = this.getQueryTimerExtensionWebGL1();
      const query = ext.createQueryEXT();
      ext.beginQueryEXT(ext.TIME_ELAPSED_EXT, query);
      return query;
    }
    endQuery() {
      if (env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") === 2) {
        const gl2 = this.gl;
        const ext2 = this.getQueryTimerExtensionWebGL2();
        gl2.endQuery(ext2.TIME_ELAPSED_EXT);
        return;
      }
      const ext = this.getQueryTimerExtensionWebGL1();
      ext.endQueryEXT(ext.TIME_ELAPSED_EXT);
    }
    async waitForQueryAndGetTime(query) {
      await util_exports.repeatedTry(() => this.disposed || this.isQueryAvailable(query, env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")));
      return this.getQueryTime(query, env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"));
    }
    getQueryTime(query, queryTimerVersion) {
      if (queryTimerVersion === 0) {
        return null;
      }
      if (queryTimerVersion === 2) {
        const gl2 = this.gl;
        const timeElapsedNanos = gl2.getQueryParameter(query, gl2.QUERY_RESULT);
        return timeElapsedNanos / 1e6;
      } else {
        const ext = this.getQueryTimerExtensionWebGL1();
        const timeElapsedNanos = ext.getQueryObjectEXT(query, ext.QUERY_RESULT_EXT);
        return timeElapsedNanos / 1e6;
      }
    }
    isQueryAvailable(query, queryTimerVersion) {
      if (queryTimerVersion === 0) {
        return true;
      }
      if (queryTimerVersion === 2) {
        const gl2 = this.gl;
        const ext = this.getQueryTimerExtensionWebGL2();
        const available = gl2.getQueryParameter(query, gl2.QUERY_RESULT_AVAILABLE);
        if (this.disjoint == null) {
          this.disjoint = this.gl.getParameter(ext.GPU_DISJOINT_EXT);
        }
        return available && !this.disjoint;
      } else {
        const ext = this.getQueryTimerExtensionWebGL1();
        const available = ext.getQueryObjectEXT(query, ext.QUERY_RESULT_AVAILABLE_EXT);
        if (this.disjoint == null) {
          this.disjoint = this.gl.getParameter(ext.GPU_DISJOINT_EXT);
        }
        return available && !this.disjoint;
      }
    }
    pollFence(fenceContext) {
      return new Promise((resolve) => {
        this.addItemToPoll(() => fenceContext.isFencePassed(), () => resolve());
      });
    }
    pollItems() {
      const index = linearSearchLastTrue(this.itemsToPoll.map((x) => x.isDoneFn));
      for (let i = 0; i <= index; ++i) {
        const { resolveFn } = this.itemsToPoll[i];
        resolveFn();
      }
      this.itemsToPoll = this.itemsToPoll.slice(index + 1);
    }
    addItemToPoll(isDoneFn, resolveFn) {
      this.itemsToPoll.push({ isDoneFn, resolveFn });
      if (this.itemsToPoll.length > 1) {
        return;
      }
      util_exports.repeatedTry(() => {
        this.pollItems();
        return this.itemsToPoll.length === 0;
      });
    }
    bindTextureToFrameBuffer(texture) {
      this.throwIfDisposed();
      bindColorTextureToFramebuffer(this.gl, texture, this.framebuffer);
      if (this.debug) {
        validateFramebuffer(this.gl);
      }
    }
    unbindTextureToFrameBuffer() {
      if (this.outputTexture != null) {
        bindColorTextureToFramebuffer(this.gl, this.outputTexture, this.framebuffer);
        if (this.debug) {
          validateFramebuffer(this.gl);
        }
      } else {
        unbindColorTextureFromFramebuffer(this.gl, this.framebuffer);
      }
    }
    downloadMatrixDriver(texture, downloadAndDecode) {
      this.bindTextureToFrameBuffer(texture);
      const result = downloadAndDecode();
      this.unbindTextureToFrameBuffer();
      return result;
    }
    setOutputMatrixTextureDriver(outputMatrixTextureMaybePacked, width, height) {
      this.throwIfDisposed();
      const gl = this.gl;
      bindColorTextureToFramebuffer(gl, outputMatrixTextureMaybePacked, this.framebuffer);
      if (this.debug) {
        validateFramebuffer(gl);
      }
      this.outputTexture = outputMatrixTextureMaybePacked;
      callAndCheck(gl, () => gl.viewport(0, 0, width, height));
      callAndCheck(gl, () => gl.scissor(0, 0, width, height));
    }
    setOutputMatrixWriteRegionDriver(x, y, width, height) {
      this.throwIfDisposed();
      callAndCheck(this.gl, () => this.gl.scissor(x, y, width, height));
    }
    throwIfDisposed() {
      if (this.disposed) {
        throw new Error("Attempted to use disposed GPGPUContext.");
      }
    }
    throwIfNoProgram() {
      if (this.program == null) {
        throw new Error("No GPU program is currently set.");
      }
    }
  };
  function linearSearchLastTrue(arr) {
    let i = 0;
    for (; i < arr.length; ++i) {
      const isDone = arr[i]();
      if (!isDone) {
        break;
      }
    }
    return i - 1;
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernel_utils/shared.js
  var { addImpl: addImplCPU, bincountImpl: bincountImplCPU, bincountReduceImpl: bincountReduceImplCPU, ceilImpl: ceilImplCPU, concatImpl: concatImplCPU, equalImpl: equalImplCPU, expImpl: expImplCPU, expm1Impl: expm1ImplCPU, floorImpl: floorImplCPU, gatherNdImpl: gatherNdImplCPU, gatherV2Impl: gatherV2ImplCPU, greaterImpl: greaterImplCPU, greaterEqualImpl: greaterEqualImplCPU, lessImpl: lessImplCPU, lessEqualImpl: lessEqualImplCPU, linSpaceImpl: linSpaceImplCPU, logImpl: logImplCPU, maxImpl: maxImplCPU, maximumImpl: maximumImplCPU, minimumImpl: minimumImplCPU, multiplyImpl: multiplyImplCPU, negImpl: negImplCPU, notEqualImpl: notEqualImplCPU, prodImpl: prodImplCPU, rangeImpl: rangeImplCPU, rsqrtImpl: rsqrtImplCPU, sigmoidImpl: sigmoidImplCPU, simpleAbsImpl: simpleAbsImplCPU, sliceImpl: sliceImplCPU, sparseFillEmptyRowsImpl: sparseFillEmptyRowsImplCPU, sparseReshapeImpl: sparseReshapeImplCPU, sparseSegmentReductionImpl: sparseSegmentReductionImplCPU, sqrtImpl: sqrtImplCPU, stridedSliceImpl: stridedSliceImplCPU, stringNGramsImpl: stringNGramsImplCPU, stringSplitImpl: stringSplitImplCPU, stringToHashBucketFastImpl: stringToHashBucketFastImplCPU, subImpl: subImplCPU, tileImpl: tileImplCPU, topKImpl: topKImplCPU, transposeImpl: transposeImplCPU, uniqueImpl: uniqueImplCPU } = shared_exports;

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/packing_util.js
  function getVecChannels(name, rank) {
    return ["x", "y", "z", "w", "u", "v"].slice(0, rank).map((d) => `${name}.${d}`);
  }
  function getChannels(name, rank) {
    if (rank === 1) {
      return [name];
    }
    return getVecChannels(name, rank);
  }
  function getSourceCoords(rank, dims) {
    if (rank === 1) {
      return "rc";
    }
    let coords2 = "";
    for (let i = 0; i < rank; i++) {
      coords2 += dims[i];
      if (i < rank - 1) {
        coords2 += ",";
      }
    }
    return coords2;
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/pack_gpu.js
  var PackProgram = class {
    constructor(outputShape) {
      this.variableNames = ["A"];
      this.packedInputs = false;
      this.packedOutput = true;
      this.outputShape = outputShape;
      const rank = outputShape.length;
      if (rank === 0) {
        this.userCode = `
        void main() {
          setOutput(vec4(getA(), 0., 0., 0.));
        }
      `;
      } else {
        const channels = getChannels("rc", rank);
        const dtype = getCoordsDataType(rank);
        const outOfBoundsCondition = getOutOfBoundsCondition(rank, outputShape, channels);
        const setup = getSetup(rank, outputShape[outputShape.length - 1], outputShape[outputShape.length - 2], channels);
        const output = getOutput(outputShape, channels);
        this.userCode = `
        void main() {
          ${dtype} rc = getOutputCoords();

          if(${outOfBoundsCondition}) {
            setOutput(vec4(0));
          } else {
            ${setup}

            setOutput(vec4(${output}));
          }
        }
      `;
      }
    }
  };
  function getSourceCoordsArr(rank, dims) {
    const coords2 = [];
    for (let row = 0; row <= 1; row++) {
      for (let col = 0; col <= 1; col++) {
        let coord = `${row === 0 ? "r" : "rp1"}, ${col === 0 ? "c" : "cp1"}`;
        for (let d = 2; d < rank; d++) {
          coord = `${dims[dims.length - 1 - d]},` + coord;
        }
        coords2.push(coord);
      }
    }
    return coords2;
  }
  function getOutOfBoundsCondition(rank, shape, dims) {
    if (rank === 1) {
      return `rc > ${shape[0]}`;
    }
    let cond = "";
    for (let i = rank - 2; i < rank; i++) {
      cond += `${dims[i]} >= ${shape[i]}`;
      if (i < rank - 1) {
        cond += "||";
      }
    }
    return cond;
  }
  function getSetup(rank, cols, rows, dims) {
    if (rank === 1) {
      return "";
    }
    const innerDims = dims.slice(-2);
    return `
    int r = ${innerDims[0]};
    int c = ${innerDims[1]};
    int rp1 = r + 1;
    int cp1 = c + 1;

    bool cEdge = cp1 >= ${cols};
    bool rEdge = rp1 >= ${rows};
  `;
  }
  function getOutput(shape, dims) {
    const rank = shape.length;
    const sourceCoords = getSourceCoordsArr(rank, dims);
    if (rank === 1) {
      return `getA(rc),
            rc + 1 >= ${shape[0]} ? 0. : getA(rc + 1),
            0, 0`;
    }
    return `getA(${sourceCoords[0]}),
          cEdge ? 0. : getA(${sourceCoords[1]}),
          rEdge ? 0. : getA(${sourceCoords[2]}),
          rEdge || cEdge ? 0. : getA(${sourceCoords[3]})`;
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/reshape_packed_gpu.js
  var ReshapePackedProgram = class {
    constructor(outputShape, inputShape) {
      this.variableNames = ["A"];
      this.packedInputs = true;
      this.packedOutput = true;
      this.customUniforms = [{ name: "inputShape", type: "ivec3" }];
      this.outputShape = outputShape;
      this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
      let mainLoop = ``;
      for (let i = 0; i < 4; i++) {
        let thisRC = `thisRC = rc;`;
        if (i % 2 === 1) {
          thisRC += `thisRC.z += 1;`;
        }
        if (i > 1) {
          thisRC += `thisRC.y += 1;`;
        }
        mainLoop += `
        ${thisRC}
        ${i > 0 ? `if(thisRC.y < rows && thisRC.z < cols){` : ""}
          int flatIndex = getFlatIndex(thisRC);

          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);
          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));

          result[${i}] =
            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);
        ${i > 0 ? "}" : ""}
      `;
      }
      this.userCode = `
      ${getReshapedInputCoords(inputShape, this.enableShapeUniforms)}
      ${this.enableShapeUniforms ? getFlatIndexFrom3DOutput() : getFlatIndexFrom3D(outputShape)}

      void main() {
        ivec3 rc = getOutputCoords();

        vec4 result = vec4(0.);

        ivec3 thisRC;
        int rows = ${this.enableShapeUniforms ? "outShape[1]" : outputShape[1]};
        int cols = ${this.enableShapeUniforms ? "outShape[2]" : outputShape[2]};

        ${mainLoop}

        setOutput(result);
      }
    `;
    }
  };
  function getReshapedInputCoords(shape, enableShapeUniforms) {
    const coordsFromIndexSnippet = enableShapeUniforms ? getLogicalCoordinatesFromFlatIndexByUniform(["r", "c", "d"], "inputShape") : getLogicalCoordinatesFromFlatIndex(["r", "c", "d"], shape);
    return `
    ivec3 inputCoordsFromReshapedOutCoords(int index) {
      ${coordsFromIndexSnippet}
      return ivec3(r, c, d);
    }
  `;
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/texture_manager.js
  var TextureManager = class {
    constructor(gpgpu) {
      this.gpgpu = gpgpu;
      this.numUsedTextures = 0;
      this.numFreeTextures = 0;
      this._numBytesAllocated = 0;
      this._numBytesFree = 0;
      this.freeTextures = {};
      this.logEnabled = false;
      this.usedTextures = {};
    }
    acquireTexture(shapeRC, usage, isPacked) {
      const physicalTexType = getPhysicalFromLogicalTextureType(usage, isPacked);
      const shapeKey = getKeyFromTextureShape(shapeRC, physicalTexType, isPacked);
      if (!(shapeKey in this.freeTextures)) {
        this.freeTextures[shapeKey] = [];
      }
      if (!(shapeKey in this.usedTextures)) {
        this.usedTextures[shapeKey] = [];
      }
      const texBytes = computeBytes(shapeRC, physicalTexType, this.gpgpu.gl, this.gpgpu.textureConfig, isPacked);
      if (this.freeTextures[shapeKey].length > 0) {
        this.numFreeTextures--;
        this.numUsedTextures++;
        this._numBytesFree -= texBytes;
        this.log();
        const newTexture2 = this.freeTextures[shapeKey].shift();
        this.usedTextures[shapeKey].push(newTexture2);
        return newTexture2;
      }
      let newTexture;
      if (physicalTexType === PhysicalTextureType.PACKED_2X2_FLOAT32) {
        newTexture = this.gpgpu.createPackedMatrixTexture(shapeRC[0], shapeRC[1]);
      } else if (physicalTexType === PhysicalTextureType.PACKED_2X2_FLOAT16) {
        newTexture = this.gpgpu.createFloat16PackedMatrixTexture(shapeRC[0], shapeRC[1]);
      } else if (physicalTexType === PhysicalTextureType.UNPACKED_FLOAT32) {
        newTexture = this.gpgpu.createFloat32MatrixTexture(shapeRC[0], shapeRC[1]);
      } else if (physicalTexType === PhysicalTextureType.UNPACKED_FLOAT16) {
        newTexture = this.gpgpu.createFloat16MatrixTexture(shapeRC[0], shapeRC[1]);
      } else if (physicalTexType === PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE) {
        newTexture = this.gpgpu.createUnsignedBytesMatrixTexture(shapeRC[0], shapeRC[1]);
      }
      this.usedTextures[shapeKey].push(newTexture);
      this.numUsedTextures++;
      this._numBytesAllocated += texBytes;
      this.log();
      return newTexture;
    }
    releaseTexture(texture, shape, logicalTexType, isPacked) {
      if (this.freeTextures == null) {
        return;
      }
      const physicalTexType = getPhysicalFromLogicalTextureType(logicalTexType, isPacked);
      const shapeKey = getKeyFromTextureShape(shape, physicalTexType, isPacked);
      if (!(shapeKey in this.freeTextures)) {
        this.freeTextures[shapeKey] = [];
      }
      const texBytes = computeBytes(shape, physicalTexType, this.gpgpu.gl, this.gpgpu.textureConfig, isPacked);
      const deleteTexThreshold = env().get("WEBGL_DELETE_TEXTURE_THRESHOLD");
      if (deleteTexThreshold !== -1 && this._numBytesAllocated > deleteTexThreshold) {
        this.gpgpu.deleteMatrixTexture(texture);
        this._numBytesAllocated -= texBytes;
      } else {
        this.freeTextures[shapeKey].push(texture);
        this.numFreeTextures++;
        this._numBytesFree += texBytes;
      }
      this.numUsedTextures--;
      const texList = this.usedTextures[shapeKey];
      const texIndex = texList.indexOf(texture);
      if (texIndex < 0) {
        throw new Error("Cannot release a texture that was never provided by this texture manager");
      }
      texList.splice(texIndex, 1);
      this.log();
    }
    log() {
      if (!this.logEnabled) {
        return;
      }
      const total = this.numFreeTextures + this.numUsedTextures;
      console.log("Free/Used", `${this.numFreeTextures} / ${this.numUsedTextures}`, `(${total})`);
      const freeRatio = this._numBytesFree / this._numBytesAllocated;
      console.log(`Bytes allocated: ${this._numBytesAllocated}`);
      console.log(`Bytes unused: ${this._numBytesFree} (${Math.round(100 * freeRatio)}%)`);
    }
    get numBytesAllocated() {
      return this._numBytesAllocated;
    }
    get numBytesFree() {
      return this._numBytesFree;
    }
    getNumUsedTextures() {
      return this.numUsedTextures;
    }
    getNumFreeTextures() {
      return this.numFreeTextures;
    }
    dispose() {
      if (this.freeTextures == null) {
        return;
      }
      for (const texShape in this.freeTextures) {
        this.freeTextures[texShape].forEach((tex) => {
          this.gpgpu.deleteMatrixTexture(tex);
        });
      }
      for (const texShape in this.usedTextures) {
        this.usedTextures[texShape].forEach((tex) => {
          this.gpgpu.deleteMatrixTexture(tex);
        });
      }
      this.freeTextures = null;
      this.usedTextures = null;
      this.numUsedTextures = 0;
      this.numFreeTextures = 0;
      this._numBytesAllocated = 0;
      this._numBytesFree = 0;
    }
  };
  function numBytesForInternalFormat(gl, internalFormat) {
    const glany = gl;
    if (internalFormat === glany.R32F) {
      return 4;
    } else if (internalFormat === glany.R16F) {
      return 2;
    } else if (internalFormat === glany.RGBA32F) {
      return 16;
    } else if (internalFormat === gl.RGBA) {
      return 16;
    } else if (internalFormat === glany.RGBA16F) {
      return 8;
    }
    throw new Error(`Unknown internal format ${internalFormat}`);
  }
  function computeBytes(shape, physicalTexType, gl, textureConfig, isPacked) {
    const internalFormat = internalFormatForPhysicalTexType(physicalTexType, textureConfig);
    let numElements;
    if (isPacked) {
      const [packedWidth, packedHeight] = getPackedMatrixTextureShapeWidthHeight(shape[0], shape[1]);
      numElements = packedWidth * packedHeight;
    } else {
      const [width, height] = getUnpackedMatrixTextureShapeWidthHeight(shape[0], shape[1]);
      numElements = width * height;
    }
    const bytesPerElement2 = numBytesForInternalFormat(gl, internalFormat);
    return numElements * bytesPerElement2;
  }
  function internalFormatForPhysicalTexType(physicalTexType, textureConfig) {
    switch (physicalTexType) {
      case PhysicalTextureType.PACKED_2X2_FLOAT32:
        return getInternalFormatForPackedMatrixTexture(textureConfig);
      case PhysicalTextureType.PACKED_2X2_FLOAT16:
        return getInternalFormatForFloat16PackedMatrixTexture(textureConfig);
      case PhysicalTextureType.UNPACKED_FLOAT32:
        return getInternalFormatForFloat32MatrixTexture(textureConfig);
      case PhysicalTextureType.UNPACKED_FLOAT16:
        return getInternalFormatForFloat16MatrixTexture(textureConfig);
      case PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE:
        return getInternalFormatForUnsignedBytesMatrixTexture(textureConfig);
      default:
        throw new Error(`Unknown physical texture type ${physicalTexType}`);
    }
  }
  function getPhysicalTextureForRendering(isPacked) {
    if (env().getBool("WEBGL_RENDER_FLOAT32_ENABLED")) {
      if (isPacked) {
        return PhysicalTextureType.PACKED_2X2_FLOAT32;
      }
      return PhysicalTextureType.UNPACKED_FLOAT32;
    }
    if (isPacked) {
      return PhysicalTextureType.PACKED_2X2_FLOAT16;
    }
    return PhysicalTextureType.UNPACKED_FLOAT16;
  }
  function getPhysicalFromLogicalTextureType(logicalTexType, isPacked) {
    if (logicalTexType === TextureUsage.UPLOAD) {
      return PhysicalTextureType.PACKED_2X2_FLOAT32;
    } else if (logicalTexType === TextureUsage.RENDER || logicalTexType == null) {
      return getPhysicalTextureForRendering(isPacked);
    } else if (logicalTexType === TextureUsage.DOWNLOAD || logicalTexType === TextureUsage.PIXELS) {
      return PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE;
    }
    throw new Error(`Unknown logical texture type ${logicalTexType}`);
  }
  function getKeyFromTextureShape(shapeRowsCol, physicalTexType, isPacked) {
    return `${shapeRowsCol[0]}_${shapeRowsCol[1]}_${physicalTexType}_${isPacked}`;
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/unaryop_gpu.js
  var UnaryOpProgram = class {
    constructor(aShape, opSnippet) {
      this.variableNames = ["A"];
      this.outputShape = aShape;
      this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
      this.userCode = `
      float unaryOperation(float x) {
        ${opSnippet}
      }

      void main() {
        float x = getAAtOutCoords();
        float y = unaryOperation(x);

        setOutput(y);
      }
    `;
    }
  };
  var CHECK_NAN_SNIPPET = `if (isnan(x)) return x;`;
  var LINEAR = `return x;`;
  var ABS = `return abs(x);`;
  var ELU2 = `return (x >= 0.0) ? x : (exp(x) - 1.0);`;
  var RELU = CHECK_NAN_SNIPPET + `
  return (x < 0.0) ? 0.0 : x;
`;
  var RELU6 = CHECK_NAN_SNIPPET + `
  return (x < 0.0) ? 0.0 : min(6.0, x);
`;
  var CLONE = "return x;";
  var SIGMOID = `return 1.0 / (1.0 + exp(-1.0 * x));`;

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/unaryop_packed_gpu.js
  var LINEAR2 = `return x;`;
  var ELU3 = `
  vec4 result;

  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);
  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);
  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);
  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);

  return result;
`;
  var RELU2 = `
  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
  var RELU62 = `
  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
  var SIGMOID2 = `return 1.0 / (1.0 + exp(-1.0 * x));`;
  var UnaryOpPackedProgram = class {
    constructor(aShape, opSnippet) {
      this.variableNames = ["A"];
      this.packedInputs = true;
      this.packedOutput = true;
      this.outputShape = aShape;
      this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
      this.userCode = `
      vec4 unaryOperation(vec4 x) {
        ${opSnippet}
      }

      void main() {
        vec4 x = getAAtOutCoords();
        vec4 y = unaryOperation(x);

        setOutput(y);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/unpack_gpu.js
  var UnpackProgram = class {
    constructor(outputShape) {
      this.variableNames = ["A"];
      this.packedInputs = true;
      this.packedOutput = false;
      this.outputShape = outputShape;
      const rank = outputShape.length;
      const channels = getChannels("rc", rank);
      const dtype = getCoordsDataType(rank);
      const sourceCoords = getSourceCoords(rank, channels);
      const innerDims = channels.slice(-2);
      const coords2 = rank <= 1 ? "rc" : `vec2(${innerDims.join(",")})`;
      this.userCode = `
      void main() {
        ${dtype} rc = getOutputCoords();
        vec4 packedInput = getA(${sourceCoords});

        setOutput(getChannel(packedInput, ${coords2}));
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/backend_webgl.js
  var whereImpl3 = kernel_impls_exports.whereImpl;
  var EPSILON_FLOAT322 = 1e-7;
  var EPSILON_FLOAT162 = 1e-4;
  var binaryCaches = {};
  function getBinaryCache(webGLVersion) {
    if (webGLVersion in binaryCaches) {
      return binaryCaches[webGLVersion];
    }
    binaryCaches[webGLVersion] = {};
    return binaryCaches[webGLVersion];
  }
  var CPU_HANDOFF_SIZE_THRESHOLD = env().getNumber("CPU_HANDOFF_SIZE_THRESHOLD");
  var BEFORE_PAGING_CONSTANT = 600;
  function numMBBeforeWarning() {
    if (env().global.screen == null) {
      return 1024;
    }
    return env().global.screen.height * env().global.screen.width * window.devicePixelRatio * BEFORE_PAGING_CONSTANT / 1024 / 1024;
  }
  var MathBackendWebGL = class extends KernelBackend {
    constructor(gpgpu) {
      super();
      this.pendingRead = new WeakMap();
      this.pendingDisposal = new WeakSet();
      this.dataRefCount = new WeakMap();
      this.numBytesInGPU = 0;
      this.uploadWaitMs = 0;
      this.downloadWaitMs = 0;
      this.lastGlFlushTime = 0;
      this.warnedAboutMemory = false;
      this.pendingDeletes = 0;
      this.disposed = false;
      if (!env().getBool("HAS_WEBGL")) {
        throw new Error("WebGL is not supported on this device");
      }
      if (gpgpu == null) {
        const gl = getWebGLContext(env().getNumber("WEBGL_VERSION"));
        this.binaryCache = getBinaryCache(env().getNumber("WEBGL_VERSION"));
        this.gpgpu = new GPGPUContext(gl);
        this.canvas = gl.canvas;
        this.gpgpuCreatedLocally = true;
      } else {
        this.gpgpu = gpgpu;
        this.binaryCache = {};
        this.gpgpuCreatedLocally = false;
        this.canvas = gpgpu.gl.canvas;
      }
      this.textureManager = new TextureManager(this.gpgpu);
      this.numMBBeforeWarning = numMBBeforeWarning();
      this.texData = new DataStorage(this, engine());
    }
    nextDataId() {
      return MathBackendWebGL.nextDataId++;
    }
    numDataIds() {
      return this.texData.numDataIds() - this.pendingDeletes;
    }
    write(values, shape, dtype) {
      if (env().getBool("WEBGL_CHECK_NUMERICAL_PROBLEMS") || env().getBool("DEBUG")) {
        this.checkNumericalProblems(values);
      }
      if (dtype === "complex64" && values != null) {
        throw new Error(`Cannot write to a complex64 dtype. Please use tf.complex(real, imag).`);
      }
      const dataId = { id: this.nextDataId() };
      this.texData.set(dataId, { shape, dtype, values, usage: TextureUsage.UPLOAD, refCount: 1 });
      return dataId;
    }
    refCount(dataId) {
      if (this.texData.has(dataId)) {
        const tensorData = this.texData.get(dataId);
        return tensorData.refCount;
      }
      return 0;
    }
    incRef(dataId) {
      const texData = this.texData.get(dataId);
      texData.refCount++;
    }
    decRef(dataId) {
      if (this.texData.has(dataId)) {
        const texData = this.texData.get(dataId);
        texData.refCount--;
      }
    }
    move(dataId, values, shape, dtype, refCount) {
      if (env().getBool("DEBUG")) {
        this.checkNumericalProblems(values);
      }
      if (dtype === "complex64") {
        throw new Error(`Cannot write to a complex64 dtype. Please use tf.complex(real, imag).`);
      }
      this.texData.set(dataId, { shape, dtype, values, usage: TextureUsage.UPLOAD, refCount });
    }
    disposeIntermediateTensorInfo(tensorInfo) {
      this.disposeData(tensorInfo.dataId);
    }
    readSync(dataId) {
      const texData = this.texData.get(dataId);
      const { values, dtype, complexTensorInfos, slice: slice4, shape, isPacked } = texData;
      if (slice4 != null) {
        let program;
        if (isPacked) {
          program = new UnaryOpPackedProgram(shape, CLONE);
        } else {
          program = new UnaryOpProgram(shape, CLONE);
        }
        const res = this.runWebGLProgram(program, [{ dataId, shape, dtype }], dtype);
        const data = this.readSync(res.dataId);
        this.disposeIntermediateTensorInfo(res);
        return data;
      }
      if (values != null) {
        return this.convertAndCacheOnCPU(dataId);
      }
      if (dtype === "string") {
        return values;
      }
      const shouldTimeProgram = this.activeTimers != null;
      let start;
      if (shouldTimeProgram) {
        start = util_exports.now();
      }
      let result;
      if (dtype === "complex64") {
        const realValues = this.readSync(complexTensorInfos.real.dataId);
        const imagValues = this.readSync(complexTensorInfos.imag.dataId);
        result = backend_util_exports.mergeRealAndImagArrays(realValues, imagValues);
      } else {
        result = this.getValuesFromTexture(dataId);
      }
      if (shouldTimeProgram) {
        this.downloadWaitMs += util_exports.now() - start;
      }
      return this.convertAndCacheOnCPU(dataId, result);
    }
    async read(dataId) {
      if (this.pendingRead.has(dataId)) {
        const subscribers2 = this.pendingRead.get(dataId);
        return new Promise((resolve) => subscribers2.push(resolve));
      }
      const texData = this.texData.get(dataId);
      const { values, shape, slice: slice4, dtype, complexTensorInfos, isPacked } = texData;
      if (slice4 != null) {
        let program;
        if (isPacked) {
          program = new UnaryOpPackedProgram(shape, CLONE);
        } else {
          program = new UnaryOpProgram(shape, CLONE);
        }
        const res = this.runWebGLProgram(program, [{ dataId, shape, dtype }], dtype);
        const data = this.read(res.dataId);
        this.disposeIntermediateTensorInfo(res);
        return data;
      }
      if (values != null) {
        return this.convertAndCacheOnCPU(dataId);
      }
      if (!env().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED") && env().getNumber("WEBGL_VERSION") === 2) {
        throw new Error(`tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and WEBGL_VERSION=2 not yet supported.`);
      }
      let buffer3 = null;
      let tmpDownloadTarget;
      if (dtype !== "complex64" && env().get("WEBGL_BUFFER_SUPPORTED")) {
        tmpDownloadTarget = this.decode(dataId);
        const tmpData = this.texData.get(tmpDownloadTarget.dataId);
        buffer3 = this.gpgpu.createBufferFromTexture(tmpData.texture, ...getDenseTexShape(shape));
      }
      this.pendingRead.set(dataId, []);
      if (dtype !== "complex64") {
        await this.gpgpu.createAndWaitForFence();
      }
      let vals;
      if (dtype === "complex64") {
        const ps = await Promise.all([
          this.read(complexTensorInfos.real.dataId),
          this.read(complexTensorInfos.imag.dataId)
        ]);
        const realValues = ps[0];
        const imagValues = ps[1];
        vals = backend_util_exports.mergeRealAndImagArrays(realValues, imagValues);
      } else if (buffer3 == null) {
        vals = this.getValuesFromTexture(dataId);
      } else {
        const size2 = util_exports.sizeFromShape(shape);
        vals = this.gpgpu.downloadFloat32MatrixFromBuffer(buffer3, size2);
      }
      if (tmpDownloadTarget != null) {
        this.disposeIntermediateTensorInfo(tmpDownloadTarget);
      }
      if (buffer3 != null) {
        const gl = this.gpgpu.gl;
        callAndCheck(gl, () => gl.deleteBuffer(buffer3));
      }
      const dTypeVals = this.convertAndCacheOnCPU(dataId, vals);
      const subscribers = this.pendingRead.get(dataId);
      this.pendingRead.delete(dataId);
      subscribers.forEach((resolve) => resolve(dTypeVals));
      if (this.pendingDisposal.has(dataId)) {
        this.pendingDisposal.delete(dataId);
        if (this.disposeData(dataId)) {
          engine().removeDataId(dataId, this);
        }
        this.pendingDeletes--;
      }
      return dTypeVals;
    }
    bufferSync(t) {
      const data = this.readSync(t.dataId);
      let decodedData = data;
      if (t.dtype === "string") {
        try {
          decodedData = data.map((d) => util_exports.decodeString(d));
        } catch (_a2) {
          throw new Error("Failed to decode encoded string bytes into utf-8");
        }
      }
      return buffer2(t.shape, t.dtype, decodedData);
    }
    checkNumericalProblems(values) {
      if (values == null) {
        return;
      }
      for (let i = 0; i < values.length; i++) {
        const num = values[i];
        if (!canBeRepresented(num)) {
          if (env().getBool("WEBGL_RENDER_FLOAT32_CAPABLE")) {
            throw Error(`The value ${num} cannot be represented with your current settings. Consider enabling float32 rendering: 'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'`);
          }
          throw Error(`The value ${num} cannot be represented on this device.`);
        }
      }
    }
    getValuesFromTexture(dataId) {
      const { shape, dtype, isPacked } = this.texData.get(dataId);
      const size2 = util_exports.sizeFromShape(shape);
      if (env().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")) {
        const tmpTarget = this.decode(dataId);
        const tmpData2 = this.texData.get(tmpTarget.dataId);
        const vals2 = this.gpgpu.downloadMatrixFromPackedTexture(tmpData2.texture, ...getDenseTexShape(shape)).subarray(0, size2);
        this.disposeIntermediateTensorInfo(tmpTarget);
        return vals2;
      }
      const shouldUsePackedProgram = env().getBool("WEBGL_PACK") && isPacked === true;
      const outputShape = shouldUsePackedProgram ? getShapeAs3D(shape) : shape;
      const program = shouldUsePackedProgram ? new EncodeFloatPackedProgram(outputShape) : new EncodeFloatProgram(outputShape);
      const output = this.runWebGLProgram(program, [{ shape: outputShape, dtype, dataId }], "float32");
      const tmpData = this.texData.get(output.dataId);
      const vals = this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(tmpData.texture, tmpData.texShape[0], tmpData.texShape[1]).subarray(0, size2);
      this.disposeIntermediateTensorInfo(output);
      return vals;
    }
    timerAvailable() {
      return env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0;
    }
    async time(f) {
      const oldActiveTimers = this.activeTimers;
      const newActiveTimers = [];
      let outerMostTime = false;
      if (this.programTimersStack == null) {
        this.programTimersStack = newActiveTimers;
        outerMostTime = true;
      } else {
        this.activeTimers.push(newActiveTimers);
      }
      this.activeTimers = newActiveTimers;
      f();
      const flattenedActiveTimerQueries = util_exports.flatten(this.activeTimers.map((d) => d.query)).filter((d) => d != null);
      const flattenedActiveTimerNames = util_exports.flatten(this.activeTimers.map((d) => d.name)).filter((d) => d != null);
      this.activeTimers = oldActiveTimers;
      if (outerMostTime) {
        this.programTimersStack = null;
      }
      const res = {
        uploadWaitMs: this.uploadWaitMs,
        downloadWaitMs: this.downloadWaitMs,
        kernelMs: null,
        wallMs: null
      };
      if (env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) {
        const kernelMs = await Promise.all(flattenedActiveTimerQueries);
        res["kernelMs"] = util_exports.sum(kernelMs);
        res["getExtraProfileInfo"] = () => kernelMs.map((d, i) => ({ name: flattenedActiveTimerNames[i], ms: d })).map((d) => `${d.name}: ${d.ms}`).join(", ");
      } else {
        res["kernelMs"] = {
          error: "WebGL query timers are not supported in this environment."
        };
      }
      this.uploadWaitMs = 0;
      this.downloadWaitMs = 0;
      return res;
    }
    memory() {
      return {
        unreliable: false,
        numBytesInGPU: this.numBytesInGPU,
        numBytesInGPUAllocated: this.textureManager.numBytesAllocated,
        numBytesInGPUFree: this.textureManager.numBytesFree
      };
    }
    startTimer() {
      if (env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) {
        return this.gpgpu.beginQuery();
      }
      return { startMs: util_exports.now(), endMs: null };
    }
    endTimer(query) {
      if (env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) {
        this.gpgpu.endQuery();
        return query;
      }
      query.endMs = util_exports.now();
      return query;
    }
    async getQueryTime(query) {
      if (env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) {
        return this.gpgpu.waitForQueryAndGetTime(query);
      }
      const timerQuery = query;
      return timerQuery.endMs - timerQuery.startMs;
    }
    disposeData(dataId, force = false) {
      if (this.pendingDisposal.has(dataId)) {
        return false;
      }
      if (!this.texData.has(dataId)) {
        return true;
      }
      if (force) {
        this.texData.get(dataId).refCount = 0;
      } else {
        this.texData.get(dataId).refCount--;
      }
      if (!force && this.texData.get(dataId).refCount > 0) {
        return false;
      }
      if (this.pendingRead.has(dataId)) {
        this.pendingDisposal.add(dataId);
        this.pendingDeletes++;
        return false;
      }
      this.releaseGPUData(dataId);
      const { complexTensorInfos } = this.texData.get(dataId);
      if (complexTensorInfos != null) {
        this.disposeData(complexTensorInfos.real.dataId, force);
        this.disposeData(complexTensorInfos.imag.dataId, force);
      }
      this.texData.delete(dataId);
      return true;
    }
    releaseGPUData(dataId) {
      const { texture, dtype, texShape, usage, isPacked, slice: slice4 } = this.texData.get(dataId);
      const key = slice4 && slice4.origDataId || dataId;
      const refCount = this.dataRefCount.get(key);
      if (refCount > 1) {
        this.dataRefCount.set(key, refCount - 1);
      } else {
        this.dataRefCount.delete(key);
        if (texture != null) {
          this.numBytesInGPU -= this.computeBytes(texShape, dtype);
          this.textureManager.releaseTexture(texture, texShape, usage, isPacked);
        }
      }
      const texData = this.texData.get(dataId);
      texData.texture = null;
      texData.texShape = null;
      texData.isPacked = false;
      texData.slice = null;
    }
    getTexture(dataId) {
      this.uploadToGPU(dataId);
      return this.texData.get(dataId).texture;
    }
    getDataInfo(dataId) {
      return this.texData.get(dataId);
    }
    shouldExecuteOnCPU(inputs, sizeThreshold = CPU_HANDOFF_SIZE_THRESHOLD) {
      return env().getBool("WEBGL_CPU_FORWARD") && inputs.every((input2) => this.texData.get(input2.dataId).texture == null && util_exports.sizeFromShape(input2.shape) < sizeThreshold);
    }
    getGPGPUContext() {
      return this.gpgpu;
    }
    where(condition) {
      backend_util_exports.warn("tf.where() in webgl locks the UI thread. Call tf.whereAsync() instead");
      const condVals = condition.dataSync();
      return whereImpl3(condition.shape, condVals);
    }
    packedUnaryOp(x, op2, dtype) {
      const program = new UnaryOpPackedProgram(x.shape, op2);
      const outInfo = this.compileAndRun(program, [x], dtype);
      return engine().makeTensorFromDataId(outInfo.dataId, outInfo.shape, outInfo.dtype);
    }
    abs(x) {
      if (this.shouldExecuteOnCPU([x]) && x.dtype !== "complex64") {
        const outValues = simpleAbsImplCPU(this.texData.get(x.dataId).values);
        return this.makeOutput(x.shape, x.dtype, outValues);
      }
      if (env().getBool("WEBGL_PACK_UNARY_OPERATIONS")) {
        return this.packedUnaryOp(x, ABS, x.dtype);
      }
      const program = new UnaryOpProgram(x.shape, ABS);
      const outInfo = this.compileAndRun(program, [x]);
      return engine().makeTensorFromDataId(outInfo.dataId, outInfo.shape, outInfo.dtype);
    }
    makeTensorInfo(shape, dtype, values) {
      let dataId;
      if (dtype === "string" && values != null && values.length > 0 && util_exports.isString(values[0])) {
        const encodedValues = values.map((d) => util_exports.encodeString(d));
        dataId = this.write(encodedValues, shape, dtype);
      } else {
        dataId = this.write(values, shape, dtype);
      }
      this.texData.get(dataId).usage = null;
      return { dataId, shape, dtype };
    }
    makeOutput(shape, dtype, values) {
      const { dataId } = this.makeTensorInfo(shape, dtype, values);
      return engine().makeTensorFromDataId(dataId, shape, dtype, this);
    }
    unpackTensor(input2) {
      const program = new UnpackProgram(input2.shape);
      return this.runWebGLProgram(program, [input2], input2.dtype);
    }
    packTensor(input2) {
      const program = new PackProgram(input2.shape);
      const preventEagerUnpackingOutput = true;
      return this.runWebGLProgram(program, [input2], input2.dtype, null, preventEagerUnpackingOutput);
    }
    packedReshape(input2, afterShape) {
      const input3DShape = [
        getBatchDim(input2.shape),
        ...getRowsCols(input2.shape)
      ];
      const input3D = {
        dtype: input2.dtype,
        shape: input3DShape,
        dataId: input2.dataId
      };
      const afterShapeAs3D = [
        getBatchDim(afterShape),
        ...getRowsCols(afterShape)
      ];
      const program = new ReshapePackedProgram(afterShapeAs3D, input3DShape);
      const preventEagerUnpackingOfOutput = true;
      const customValues = [input3DShape];
      const output = this.runWebGLProgram(program, [input3D], input2.dtype, customValues, preventEagerUnpackingOfOutput);
      return { dataId: output.dataId, shape: afterShape, dtype: output.dtype };
    }
    decode(dataId) {
      const texData = this.texData.get(dataId);
      const { isPacked, shape, dtype } = texData;
      const shapeAs3D = getShapeAs3D(shape);
      let program;
      const denseTexShape = getDenseTexShape(shapeAs3D);
      if (isPacked) {
        program = new DecodeMatrixPackedProgram(shapeAs3D);
      } else {
        program = new DecodeMatrixProgram(shapeAs3D);
      }
      const preventEagerUnpackingOfOutput = true;
      const customValues = [denseTexShape];
      const out = this.runWebGLProgram(program, [{ shape: shapeAs3D, dtype, dataId }], dtype, customValues, preventEagerUnpackingOfOutput);
      return { dtype, shape, dataId: out.dataId };
    }
    runWebGLProgram(program, inputs, outputDtype, customUniformValues, preventEagerUnpackingOfOutput = false) {
      const output = this.makeTensorInfo(program.outputShape, outputDtype);
      const outData = this.texData.get(output.dataId);
      if (program.packedOutput) {
        outData.isPacked = true;
      }
      if (program.outPackingScheme === PackingScheme.DENSE) {
        const texelShape = getDenseTexShape(program.outputShape);
        outData.texShape = texelShape.map((d) => d * 2);
      }
      if (program.outTexUsage != null) {
        outData.usage = program.outTexUsage;
      }
      if (util_exports.sizeFromShape(output.shape) === 0) {
        outData.values = util_exports.getTypedArrayFromDType(output.dtype, 0);
        return output;
      }
      const dataToDispose = [];
      const inputsData = inputs.map((input2) => {
        if (input2.dtype === "complex64") {
          throw new Error(`GPGPUProgram does not support complex64 input. For complex64 dtypes, please separate the program into real and imaginary parts.`);
        }
        let texData = this.texData.get(input2.dataId);
        if (texData.texture == null) {
          if (!program.packedInputs && util_exports.sizeFromShape(input2.shape) <= env().getNumber("WEBGL_SIZE_UPLOAD_UNIFORM")) {
            return {
              shape: input2.shape,
              texData: null,
              isUniform: true,
              uniformValues: texData.values
            };
          }
          if (program.packedInputs) {
            texData.isPacked = true;
            texData.shape = input2.shape;
          }
        } else if (!!texData.isPacked !== !!program.packedInputs) {
          input2 = texData.isPacked ? this.unpackTensor(input2) : this.packTensor(input2);
          dataToDispose.push(input2);
          texData = this.texData.get(input2.dataId);
        } else if (texData.isPacked && !isReshapeFree(texData.shape, input2.shape)) {
          const savedInput = input2;
          const targetShape = input2.shape;
          input2.shape = texData.shape;
          input2 = this.packedReshape(input2, targetShape);
          dataToDispose.push(input2);
          texData = this.texData.get(input2.dataId);
          savedInput.shape = targetShape;
        }
        this.uploadToGPU(input2.dataId);
        return { shape: input2.shape, texData, isUniform: false };
      });
      this.uploadToGPU(output.dataId);
      const outputData = { shape: output.shape, texData: outData, isUniform: false };
      const key = makeShaderKey(program, inputsData, outputData);
      const binary = this.getAndSaveBinary(key, () => {
        return compileProgram(this.gpgpu, program, inputsData, outputData);
      });
      const shouldTimeProgram = this.activeTimers != null;
      let query;
      if (shouldTimeProgram) {
        query = this.startTimer();
      }
      runProgram(this.gpgpu, binary, inputsData, outputData, customUniformValues);
      dataToDispose.forEach((info) => this.disposeIntermediateTensorInfo(info));
      if (shouldTimeProgram) {
        query = this.endTimer(query);
        this.activeTimers.push({ name: program.constructor.name, query: this.getQueryTime(query) });
      }
      const glFlushThreshold = env().get("WEBGL_FLUSH_THRESHOLD");
      if (glFlushThreshold > 0) {
        const time = util_exports.now();
        if (time - this.lastGlFlushTime > glFlushThreshold) {
          this.gpgpu.gl.flush();
          this.lastGlFlushTime = time;
        }
      }
      if (!env().getBool("WEBGL_LAZILY_UNPACK") && outData.isPacked && preventEagerUnpackingOfOutput === false) {
        const unpacked = this.unpackTensor(output);
        this.disposeIntermediateTensorInfo(output);
        return unpacked;
      }
      return output;
    }
    compileAndRun(program, inputs, outputDtype, customUniformValues, preventEagerUnpackingOfOutput = false) {
      outputDtype = outputDtype || inputs[0].dtype;
      const outInfo = this.runWebGLProgram(program, inputs, outputDtype, customUniformValues, preventEagerUnpackingOfOutput);
      return outInfo;
    }
    getAndSaveBinary(key, getBinary) {
      if (!(key in this.binaryCache)) {
        this.binaryCache[key] = getBinary();
      }
      return this.binaryCache[key];
    }
    getTextureManager() {
      return this.textureManager;
    }
    dispose() {
      if (this.disposed) {
        return;
      }
      if (!env().getBool("IS_TEST")) {
        const allKeys = Object.keys(this.binaryCache);
        allKeys.forEach((key) => {
          this.gpgpu.deleteProgram(this.binaryCache[key].webGLProgram);
          delete this.binaryCache[key];
        });
      }
      this.textureManager.dispose();
      if (this.canvas != null && (typeof HTMLCanvasElement !== "undefined" && this.canvas instanceof HTMLCanvasElement)) {
        this.canvas.remove();
      } else {
        this.canvas = null;
      }
      if (this.gpgpuCreatedLocally) {
        this.gpgpu.program = null;
        this.gpgpu.dispose();
      }
      this.disposed = true;
    }
    floatPrecision() {
      if (this.floatPrecisionValue == null) {
        this.floatPrecisionValue = tidy(() => {
          if (!env().get("WEBGL_RENDER_FLOAT32_ENABLED")) {
            const debugFlag = env().getBool("DEBUG");
            env().set("DEBUG", false);
            const underflowCheckValue = this.abs(scalar(1e-8)).dataSync()[0];
            env().set("DEBUG", debugFlag);
            if (underflowCheckValue > 0) {
              return 32;
            }
          }
          return 16;
        });
      }
      return this.floatPrecisionValue;
    }
    epsilon() {
      return this.floatPrecision() === 32 ? EPSILON_FLOAT322 : EPSILON_FLOAT162;
    }
    uploadToGPU(dataId) {
      const texData = this.texData.get(dataId);
      const { shape, dtype, values, texture, usage, isPacked } = texData;
      if (texture != null) {
        return;
      }
      const shouldTimeProgram = this.activeTimers != null;
      let start;
      if (shouldTimeProgram) {
        start = util_exports.now();
      }
      let texShape = texData.texShape;
      if (texShape == null) {
        texShape = getTextureShapeFromLogicalShape(shape, isPacked);
        texData.texShape = texShape;
      }
      if (values != null) {
        const shapeAs3D = getShapeAs3D(shape);
        let program;
        let width = texShape[1], height = texShape[0];
        const isByteArray = values instanceof Uint8Array || values instanceof Uint8ClampedArray;
        if (isPacked) {
          [width, height] = getPackedMatrixTextureShapeWidthHeight(texShape[0], texShape[1]);
          program = new EncodeMatrixPackedProgram(shapeAs3D, isByteArray);
        } else {
          program = new EncodeMatrixProgram(shapeAs3D, isByteArray);
        }
        const tempDenseInputHandle = this.makeTensorInfo([height, width], dtype);
        if (isByteArray) {
          this.texData.get(tempDenseInputHandle.dataId).usage = TextureUsage.PIXELS;
        } else {
          this.texData.get(tempDenseInputHandle.dataId).usage = TextureUsage.UPLOAD;
        }
        this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(tempDenseInputHandle.dataId), width, height, values);
        const customValues = [[height, width]];
        const preventEagerUnpacking = true;
        const encodedOutputTarget = this.runWebGLProgram(program, [tempDenseInputHandle], dtype, customValues, preventEagerUnpacking);
        const outputTexData = this.texData.get(encodedOutputTarget.dataId);
        texData.texture = outputTexData.texture;
        texData.texShape = outputTexData.texShape;
        texData.isPacked = outputTexData.isPacked;
        texData.usage = outputTexData.usage;
        this.disposeIntermediateTensorInfo(tempDenseInputHandle);
        this.texData.delete(encodedOutputTarget.dataId);
        texData.values = null;
        if (shouldTimeProgram) {
          this.uploadWaitMs += util_exports.now() - start;
        }
      } else {
        const newTexture = this.acquireTexture(texShape, usage, dtype, isPacked);
        texData.texture = newTexture;
      }
    }
    convertAndCacheOnCPU(dataId, float32Values) {
      const texData = this.texData.get(dataId);
      const { dtype } = texData;
      this.releaseGPUData(dataId);
      if (float32Values != null) {
        texData.values = float32ToTypedArray(float32Values, dtype);
      }
      return texData.values;
    }
    acquireTexture(texShape, texType, dtype, isPacked) {
      this.numBytesInGPU += this.computeBytes(texShape, dtype);
      if (!this.warnedAboutMemory && this.numBytesInGPU > this.numMBBeforeWarning * 1024 * 1024) {
        const mb = (this.numBytesInGPU / 1024 / 1024).toFixed(2);
        this.warnedAboutMemory = true;
        console.warn(`High memory usage in GPU: ${mb} MB, most likely due to a memory leak`);
      }
      return this.textureManager.acquireTexture(texShape, texType, isPacked);
    }
    computeBytes(shape, dtype) {
      return shape[0] * shape[1] * util_exports.bytesPerElement(dtype);
    }
  };
  MathBackendWebGL.nextDataId = 0;
  function float32ToTypedArray(a, dtype) {
    if (dtype === "float32" || dtype === "complex64") {
      return a;
    } else if (dtype === "int32" || dtype === "bool") {
      const result = dtype === "int32" ? new Int32Array(a.length) : new Uint8Array(a.length);
      for (let i = 0; i < result.length; ++i) {
        result[i] = Math.round(a[i]);
      }
      return result;
    } else {
      throw new Error(`Unknown dtype ${dtype}`);
    }
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/base.js
  if (device_util_exports.isBrowser()) {
    registerBackend("webgl", () => new MathBackendWebGL(), 2);
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/binaryop_gpu.js
  var CHECK_NAN_SNIPPET2 = `
  if (isnan(a)) return a;
  if (isnan(b)) return b;
`;
  var BinaryOpProgram = class {
    constructor(op2, aShape, bShape) {
      this.variableNames = ["A", "B"];
      this.outputShape = backend_util_exports.assertAndGetBroadcastShape(aShape, bShape);
      this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
      this.userCode = `
      float binaryOperation(float a, float b) {
        ${op2}
      }

      void main() {
        float a = getAAtOutCoords();
        float b = getBAtOutCoords();
        setOutput(binaryOperation(a, b));
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/binaryop_packed_gpu.js
  var CHECK_NAN_SNIPPET3 = `
  result.r = isNaN.r > 0. ? NAN : result.r;
  result.g = isNaN.g > 0. ? NAN : result.g;
  result.b = isNaN.b > 0. ? NAN : result.b;
  result.a = isNaN.a > 0. ? NAN : result.a;
`;
  var BinaryOpPackedProgram = class {
    constructor(op2, aShape, bShape, checkOutOfBounds = false) {
      this.variableNames = ["A", "B"];
      this.supportsBroadcasting = true;
      this.packedInputs = true;
      this.packedOutput = true;
      this.outputShape = backend_util_exports.assertAndGetBroadcastShape(aShape, bShape);
      const rank = this.outputShape.length;
      this.enableShapeUniforms = useShapeUniforms(rank);
      let checkOutOfBoundsString = "";
      if (checkOutOfBounds) {
        if (rank === 0 || util_exports.sizeFromShape(this.outputShape) === 1) {
          checkOutOfBoundsString = `
          result.y = 0.;
          result.z = 0.;
          result.w = 0.;
        `;
        } else {
          const dtype = getCoordsDataType(rank);
          checkOutOfBoundsString = `
          ${dtype} coords = getOutputCoords();
        `;
          if (rank === 1) {
            if (this.enableShapeUniforms) {
              checkOutOfBoundsString += `
            result.y = (coords + 1) >= outShape ? 0. : result.y;
            result.z = 0.;
            result.w = 0.;
          `;
            } else {
              checkOutOfBoundsString += `
            result.y = (coords + 1) >= ${this.outputShape[0]} ? 0. : result.y;
            result.z = 0.;
            result.w = 0.;
          `;
            }
          } else {
            const channels = getChannels("coords", rank);
            if (this.enableShapeUniforms) {
              checkOutOfBoundsString += `
            bool nextRowOutOfBounds =
              (${channels[rank - 2]} + 1) >= outShape[${rank} - 2];
            bool nextColOutOfBounds =
              (${channels[rank - 1]} + 1) >= outShape[${rank} - 1];
            result.y = nextColOutOfBounds ? 0. : result.y;
            result.z = nextRowOutOfBounds ? 0. : result.z;
            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;
          `;
            } else {
              checkOutOfBoundsString += `
            bool nextRowOutOfBounds =
              (${channels[rank - 2]} + 1) >= ${this.outputShape[rank - 2]};
            bool nextColOutOfBounds =
              (${channels[rank - 1]} + 1) >= ${this.outputShape[rank - 1]};
            result.y = nextColOutOfBounds ? 0. : result.y;
            result.z = nextRowOutOfBounds ? 0. : result.z;
            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;
          `;
            }
          }
        }
      }
      this.userCode = `
      vec4 binaryOperation(vec4 a, vec4 b) {
        ${op2}
      }

      void main() {
        vec4 a = getAAtOutCoords();
        vec4 b = getBAtOutCoords();

        vec4 result = binaryOperation(a, b);
        ${checkOutOfBoundsString}

        setOutput(result);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Identity.js
  function identity2(args) {
    const { inputs, backend: backend2 } = args;
    const { x } = inputs;
    backend2.incRef(x.dataId);
    return { dataId: x.dataId, shape: x.shape, dtype: x.dtype };
  }
  var identityConfig2 = {
    kernelName: Identity,
    backendName: "webgl",
    kernelFunc: identity2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Complex.js
  function complex3(args) {
    const { inputs, backend: backend2 } = args;
    const { real: real4, imag: imag4 } = inputs;
    const complexInfo = backend2.makeTensorInfo(real4.shape, "complex64");
    const complex4 = backend2.texData.get(complexInfo.dataId);
    const realTensorInfo = identity2({ inputs: { x: real4 }, backend: backend2 });
    const imagTensorInfo = identity2({ inputs: { x: imag4 }, backend: backend2 });
    complex4.complexTensorInfos = { real: realTensorInfo, imag: imagTensorInfo };
    return complexInfo;
  }
  var complexConfig2 = {
    kernelName: Complex,
    backendName: "webgl",
    kernelFunc: complex3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LeakyRelu.js
  var LEAKYRELU = `return (a < 0.) ? b * a : a;`;
  var LEAKYRELU_PACKED = `
  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));
  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);
`;
  function leakyRelu3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { alpha } = attrs;
    const $alpha = backend2.makeTensorInfo([], "float32", util_exports.createScalarValue(alpha, "float32"));
    const program = env().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new BinaryOpPackedProgram(LEAKYRELU_PACKED, x.shape, $alpha.shape) : new BinaryOpProgram(LEAKYRELU, x.shape, $alpha.shape);
    const result = backend2.runWebGLProgram(program, [x, $alpha], "float32");
    backend2.disposeIntermediateTensorInfo($alpha);
    return result;
  }
  var leakyReluConfig2 = {
    kernelName: LeakyRelu,
    backendName: "webgl",
    kernelFunc: leakyRelu3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Prelu.js
  var PRELU = `return (a < 0.) ? b * a : a;`;
  var PRELU_PACKED = `
  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));
  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);
`;
  function prelu3(args) {
    const { inputs, backend: backend2 } = args;
    const { x, alpha } = inputs;
    const program = env().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new BinaryOpPackedProgram(PRELU_PACKED, x.shape, alpha.shape) : new BinaryOpProgram(PRELU, x.shape, alpha.shape);
    return backend2.runWebGLProgram(program, [x, alpha], "float32");
  }
  var preluConfig2 = {
    kernelName: Prelu,
    backendName: "webgl",
    kernelFunc: prelu3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernel_utils/kernel_funcs_utils.js
  var CHECK_NAN_SNIPPET_UNARY = `if (isnan(x)) return x;`;
  var CHECK_NAN_SNIPPET_BINARY = `
  if (isnan(a)) return a;
  if (isnan(b)) return b;
`;
  var CHECK_NAN_SNIPPET_BINARY_PACKED = `
  result.r = isNaN.r > 0. ? NAN : result.r;
  result.g = isNaN.g > 0. ? NAN : result.g;
  result.b = isNaN.b > 0. ? NAN : result.b;
  result.a = isNaN.a > 0. ? NAN : result.a;
`;
  function unaryKernelFunc2({ opSnippet, packedOpSnippet, cpuKernelImpl, dtype }) {
    return ({ inputs, backend: backend2 }) => {
      const { x } = inputs;
      const webglBackend = backend2;
      const $dtype = dtype || x.dtype;
      if (webglBackend.shouldExecuteOnCPU([x]) && cpuKernelImpl != null) {
        const xData = webglBackend.texData.get(x.dataId);
        const outValues = cpuKernelImpl(xData.values, $dtype);
        return webglBackend.makeTensorInfo(x.shape, $dtype, outValues);
      }
      const shouldUsePackedProgram = env().getBool("WEBGL_PACK_UNARY_OPERATIONS") && packedOpSnippet != null;
      let program;
      if (shouldUsePackedProgram) {
        program = new UnaryOpPackedProgram(x.shape, packedOpSnippet);
      } else {
        program = new UnaryOpProgram(x.shape, opSnippet);
      }
      return webglBackend.runWebGLProgram(program, [x], $dtype);
    };
  }
  function binaryKernelFunc2({ opSnippet, packedOpSnippet, checkOutOfBounds = false, supportsComplex = false, cpuKernelImpl, dtype }) {
    return ({ inputs, backend: backend2 }) => {
      const { a, b } = inputs;
      const webglBackend = backend2;
      if (supportsComplex && a.dtype === "complex64") {
        const aData = webglBackend.texData.get(a.dataId);
        const bData = webglBackend.texData.get(b.dataId);
        const [real4, imag4] = [
          [aData.complexTensorInfos.real, bData.complexTensorInfos.real],
          [aData.complexTensorInfos.imag, bData.complexTensorInfos.imag]
        ].map((complexParts) => {
          const [aPart, bPart] = complexParts;
          const aHandle = {
            dataId: aPart.dataId,
            dtype: aPart.dtype,
            shape: a.shape
          };
          const bHandle = {
            dataId: bPart.dataId,
            dtype: bPart.dtype,
            shape: b.shape
          };
          const program2 = new BinaryOpProgram(opSnippet, a.shape, b.shape);
          return webglBackend.runWebGLProgram(program2, [aHandle, bHandle], upcastType(aPart.dtype, bPart.dtype));
        });
        const complexOutput = complex3({ inputs: { real: real4, imag: imag4 }, backend: webglBackend });
        webglBackend.disposeIntermediateTensorInfo(real4);
        webglBackend.disposeIntermediateTensorInfo(imag4);
        return complexOutput;
      }
      const $dtype = dtype || upcastType(a.dtype, b.dtype);
      if ((a.dtype === "string" || b.dtype === "string" || webglBackend.shouldExecuteOnCPU([a, b])) && cpuKernelImpl != null) {
        const aVals = webglBackend.texData.get(a.dataId).values;
        const bVals = webglBackend.texData.get(b.dataId).values;
        const decodedAVals = a.dtype === "string" ? backend_util_exports.fromUint8ToStringArray(aVals) : aVals;
        const decodedBVals = a.dtype === "string" ? backend_util_exports.fromUint8ToStringArray(bVals) : bVals;
        const [outValues, outShape] = cpuKernelImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype);
        const out = webglBackend.makeTensorInfo(outShape, $dtype);
        const outData = webglBackend.texData.get(out.dataId);
        outData.values = outValues;
        return out;
      }
      const shouldUsePackedProgram = env().getBool("WEBGL_PACK_BINARY_OPERATIONS") && packedOpSnippet != null;
      let program;
      if (shouldUsePackedProgram) {
        program = new BinaryOpPackedProgram(packedOpSnippet, a.shape, b.shape, checkOutOfBounds);
      } else {
        program = new BinaryOpProgram(opSnippet, a.shape, b.shape);
      }
      return webglBackend.runWebGLProgram(program, [a, b], $dtype);
    };
  }
  function mapActivationToShaderProgram(activation, packed = false) {
    if (activation === "linear") {
      if (packed) {
        return LINEAR2;
      }
      return LINEAR;
    } else if (activation === "relu") {
      if (packed) {
        return RELU2;
      }
      return RELU;
    } else if (activation === "elu") {
      if (packed) {
        return ELU3;
      }
      return ELU2;
    } else if (activation === "relu6") {
      if (packed) {
        return RELU62;
      }
      return RELU6;
    } else if (activation === "prelu") {
      if (packed) {
        return PRELU_PACKED;
      }
      return PRELU;
    } else if (activation === "leakyrelu") {
      if (packed) {
        return LEAKYRELU_PACKED;
      }
      return LEAKYRELU;
    } else if (activation === "sigmoid") {
      if (packed) {
        return SIGMOID2;
      }
      return SIGMOID;
    }
    throw new Error(`Activation ${activation} has not been implemented for the WebGL backend.`);
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/mulmat_packed_gpu.js
  var MatMulPackedProgram = class {
    constructor(aShape, bShape, outputShape, transposeA = false, transposeB = false, addBias = false, activation = null, hasPreluActivation = false, hasLeakyreluActivation = false) {
      this.variableNames = ["matrixA", "matrixB"];
      this.packedInputs = true;
      this.packedOutput = true;
      this.outputShape = outputShape;
      this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
      const sharedDim = transposeA ? aShape[1] : aShape[2];
      const sharedDimensionPacked = Math.ceil(sharedDim / 2);
      const aSample = transposeA ? "i * 2, rc.y" : "rc.y, i * 2";
      const bSample = transposeB ? "rc.z, i * 2" : "i * 2, rc.z";
      const aSwizzle = transposeA ? ["a.xxyy", "a.zzww"] : ["a.xxzz", "a.yyww"];
      const bSwizzle = transposeB ? ["b.xzxz", "b.ywyw"] : ["b.xyxy", "b.zwzw"];
      let activationSnippet = "", applyActivationSnippet = "";
      if (activation) {
        if (hasPreluActivation) {
          activationSnippet = `vec4 activation(vec4 a) {
          vec4 b = getPreluActivationWeightsAtOutCoords();
          ${activation}
        }`;
        } else if (hasLeakyreluActivation) {
          activationSnippet = `vec4 activation(vec4 a) {
          vec4 b = getLeakyreluAlphaAtOutCoords();
          ${activation}
        }`;
        } else {
          activationSnippet = `vec4 activation(vec4 x) {
          ${activation}
        }`;
        }
        applyActivationSnippet = `result = activation(result);`;
      }
      const addBiasSnippet = addBias ? "result += getBiasAtOutCoords();" : "";
      if (addBias) {
        this.variableNames.push("bias");
      }
      if (hasPreluActivation) {
        this.variableNames.push("preluActivationWeights");
      }
      if (hasLeakyreluActivation) {
        this.variableNames.push("leakyreluAlpha");
      }
      let batchASnippet = "rc.x";
      let batchBSnippet = "rc.x";
      if (aShape[0] < bShape[0]) {
        batchASnippet = `int(min(float(rc.x), ${aShape[0] - 1}.))`;
      } else if (bShape[0] < aShape[0]) {
        batchBSnippet = `int(min(float(rc.x), ${bShape[0] - 1}.))`;
      }
      this.userCode = `
      ${activationSnippet}
      // Don't use uniform for sharedDimensionPacked for performance.
      const float sharedDimension = ${sharedDimensionPacked}.0;

      vec4 dot2x2ARowBCol(ivec3 rc) {
        vec4 result = vec4(0);
        for (int i = 0; i < ${sharedDimensionPacked}; i++) {
          int batchA = ${batchASnippet};
          int batchB = ${batchBSnippet};
          vec4 a = getMatrixA(batchA, ${aSample});
          vec4 b = getMatrixB(batchB, ${bSample});

          // These swizzled products need to be separately added.
          // See: https://github.com/tensorflow/tfjs/issues/1735
          result += (${aSwizzle[0]} * ${bSwizzle[0]});
          result += (${aSwizzle[1]} * ${bSwizzle[1]});
        }
        return result;
      }

      void main() {
        ivec3 rc = getOutputCoords();
        vec4 result = dot2x2ARowBCol(rc);

        ${addBiasSnippet}

        ${applyActivationSnippet}

        setOutput(result);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/binaryop_complex_gpu.js
  var COMPLEX_MULTIPLY = {
    REAL: "return areal * breal - aimag * bimag;",
    IMAG: "return areal * bimag + aimag * breal;"
  };
  var BinaryOpComplexProgram = class {
    constructor(op2, aShape, bShape) {
      this.variableNames = ["AReal", "AImag", "BReal", "BImag"];
      this.outputShape = backend_util_exports.assertAndGetBroadcastShape(aShape, bShape);
      this.userCode = `
      float binaryOpComplex(
          float areal, float aimag, float breal, float bimag) {
        ${op2}
      }

      void main() {
        float areal = getARealAtOutCoords();
        float aimag = getAImagAtOutCoords();
        float breal = getBRealAtOutCoords();
        float bimag = getBImagAtOutCoords();
        setOutput(binaryOpComplex(areal, aimag, breal, bimag));
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Multiply.js
  var MUL = "return a * b;";
  function multiply2(args) {
    const { inputs, backend: backend2 } = args;
    const { a, b } = inputs;
    const dtype = backend_util_exports.upcastType(a.dtype, b.dtype);
    if (a.dtype === "complex64") {
      const aData = backend2.texData.get(a.dataId);
      const bData = backend2.texData.get(b.dataId);
      const realProgram = new BinaryOpComplexProgram(COMPLEX_MULTIPLY.REAL, a.shape, b.shape);
      const imagProgram = new BinaryOpComplexProgram(COMPLEX_MULTIPLY.IMAG, a.shape, b.shape);
      const inputs2 = [
        {
          dataId: aData.complexTensorInfos.real.dataId,
          dtype: aData.complexTensorInfos.real.dtype,
          shape: a.shape
        },
        {
          dataId: aData.complexTensorInfos.imag.dataId,
          dtype: aData.complexTensorInfos.imag.dtype,
          shape: a.shape
        },
        {
          dataId: bData.complexTensorInfos.real.dataId,
          dtype: bData.complexTensorInfos.real.dtype,
          shape: b.shape
        },
        {
          dataId: bData.complexTensorInfos.imag.dataId,
          dtype: bData.complexTensorInfos.imag.dtype,
          shape: b.shape
        }
      ];
      const realPart = backend2.runWebGLProgram(realProgram, inputs2, "float32");
      const imagPart = backend2.runWebGLProgram(imagProgram, inputs2, "float32");
      const complexOutput = complex3({ inputs: { real: realPart, imag: imagPart }, backend: backend2 });
      backend2.disposeIntermediateTensorInfo(realPart);
      backend2.disposeIntermediateTensorInfo(imagPart);
      return complexOutput;
    }
    if (backend2.shouldExecuteOnCPU([a, b])) {
      const aData = backend2.texData.get(a.dataId);
      const bData = backend2.texData.get(b.dataId);
      const [outValues, outShape] = multiplyImplCPU(a.shape, b.shape, aData.values, bData.values, dtype);
      const out = backend2.makeTensorInfo(outShape, dtype);
      const outData = backend2.texData.get(out.dataId);
      outData.values = outValues;
      return out;
    }
    let program;
    if (env().getBool("WEBGL_PACK_BINARY_OPERATIONS")) {
      program = new BinaryOpPackedProgram(MUL, a.shape, b.shape);
    } else {
      program = new BinaryOpProgram(MUL, a.shape, b.shape);
    }
    return backend2.runWebGLProgram(program, [a, b], dtype);
  }
  var multiplyConfig2 = {
    kernelName: Multiply,
    backendName: "webgl",
    kernelFunc: multiply2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernel_utils/reshape.js
  function packedReshape(input2, afterShape, backend2) {
    const input3DShape = [
      getBatchDim(input2.shape),
      ...getRowsCols(input2.shape)
    ];
    const input3D = {
      dtype: input2.dtype,
      shape: input3DShape,
      dataId: input2.dataId
    };
    const afterShapeAs3D = [
      getBatchDim(afterShape),
      ...getRowsCols(afterShape)
    ];
    const program = new ReshapePackedProgram(afterShapeAs3D, input3DShape);
    const preventEagerUnpackingOfOutput = true;
    const customValues = [input3DShape];
    const output = backend2.runWebGLProgram(program, [input3D], input2.dtype, customValues, preventEagerUnpackingOfOutput);
    return { dataId: output.dataId, shape: afterShape, dtype: output.dtype };
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Reshape.js
  function reshape3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { shape } = attrs;
    const webglBackend = backend2;
    const xSize = util_exports.sizeFromShape(x.shape);
    const $shape = util_exports.inferFromImplicitShape(shape, xSize);
    const $xSize = util_exports.sizeFromShape($shape);
    util_exports.assert(xSize === $xSize, () => `The new shape (${$shape}) has ${$xSize} elements and the old shape (${x.shape}) has ${xSize} elements. The new shape and old shape must have the same number of elements.`);
    const xTexData = webglBackend.texData.get(x.dataId);
    if (xTexData.isPacked && !isReshapeFree(x.shape, $shape) && !(xTexData.texture !== null && isReshapeFree(xTexData.shape, $shape))) {
      return packedReshape(x, $shape, webglBackend);
    }
    webglBackend.incRef(x.dataId);
    return { dataId: x.dataId, shape: $shape, dtype: x.dtype };
  }
  var reshapeConfig2 = {
    kernelName: Reshape,
    backendName: "webgl",
    kernelFunc: reshape3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/mean_gpu.js
  var MeanProgram = class {
    constructor(reduceInfo, divisor) {
      this.variableNames = ["x"];
      const { windowSize, batchSize, inSize, outSize } = reduceInfo;
      this.outputShape = [batchSize, outSize];
      const windowSizeNearestVec4 = Math.floor(windowSize / 4) * 4;
      const windowSizeVec4Remainder = windowSize % 4;
      let updateSnippet = `sumValue += dot(values, ones);`;
      if (divisor != null) {
        const denominator = 1 / divisor;
        updateSnippet = `sumValue += dot(values * ${util_exports.isInt(denominator) ? denominator.toPrecision(2) : denominator}, ones);`;
      }
      let checkOutOfBounds = "";
      if (inSize % windowSize > 0) {
        checkOutOfBounds = `
        if (inIdx < 0 || inIdx >= ${inSize}) {
          return 0.0;
        }
      `;
      }
      this.userCode = `
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float getValue(int batch, int inIdx) {
        ${checkOutOfBounds}
        return getX(batch, inIdx);
      }

      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = outIdx * ${windowSize};

        float sumValue = 0.0;

        for (int i = 0; i < ${windowSizeNearestVec4}; i += 4) {
          int inIdx = inOffset + i;
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            getValue(batch, inIdx + 3)
          );

          ${updateSnippet}
        }

        int inIdx = inOffset + ${windowSizeNearestVec4};
        if (${windowSizeVec4Remainder === 1}) {
          vec4 values = vec4(getValue(batch, inIdx), 0.0, 0.0, 0.0);

          ${updateSnippet}
        } else if (${windowSizeVec4Remainder === 2}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1), 0.0, 0.0);

          ${updateSnippet}
        } else if (${windowSizeVec4Remainder === 3}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2), 0.0);

          ${updateSnippet}
        }
        setOutput(sumValue);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/reduce_gpu.js
  var ReduceProgram = class {
    constructor(reduceInfo, reduceType) {
      this.variableNames = ["x"];
      const { windowSize, batchSize, inSize, outSize } = reduceInfo;
      this.outputShape = [batchSize, outSize];
      let initializationValue = "0.0";
      let compareOp = ``;
      if (reduceType === "prod") {
        initializationValue = "1.0";
      } else if (reduceType === "min") {
        initializationValue = "1.0 / 1e-20";
        compareOp = `min`;
      } else if (reduceType === "max") {
        initializationValue = "-1.0 / 1e-20";
        compareOp = `max`;
      }
      let returnValue = `${reduceType}(${reduceType}(${reduceType}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;
      if (reduceType === "sum") {
        returnValue = `sumValue`;
      } else if (reduceType === "prod") {
        returnValue = `prodValue`;
      } else if (reduceType === "all") {
        returnValue = `allValue`;
      } else if (reduceType === "any") {
        returnValue = `anyValue`;
      }
      const windowSizeNearestVec4 = Math.floor(windowSize / 4) * 4;
      const windowSizeVec4Remainder = windowSize % 4;
      let updateSnippet = `
      if (${reduceType === "sum"}) {
        sumValue += dot(values, ones);
      } else if (${reduceType === "prod"}) {
        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);
        prodValue *= tmp[0] * tmp[1];
      } else {
        minMaxValue = ${compareOp}(values, minMaxValue);
        if (${reduceType === "min"} || ${reduceType === "max"}) {
          minMaxValue = ${compareOp}(values, minMaxValue);
          bvec4 isNaN = isnan(values);
          if (isNaN.r || isNaN.g || isNaN.b || isNaN.a) {
            minMaxValue = vec4(NAN);
          }
        }
      }
    `;
      let vecType = `vec4`;
      if (reduceType === "all") {
        initializationValue = "1.0";
        updateSnippet = `
        bool reducedAllValue = all(values);
        float floatedReducedAllValue = float(reducedAllValue);
        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);
      `;
        vecType = `bvec4`;
      } else if (reduceType === "any") {
        initializationValue = "0.0";
        updateSnippet = `
        bool reducedAnyValue = any(values);
        float floatedReducedAnyValue = float(reducedAnyValue);
        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);
      `;
        vecType = `bvec4`;
      }
      let checkOutOfBounds = "";
      if (inSize % windowSize > 0) {
        checkOutOfBounds = `
        if (inIdx < 0 || inIdx >= ${inSize}) {
          return initializationValue;
        }
      `;
      }
      this.userCode = `
      const float initializationValue = ${initializationValue};
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float getValue(int batch, int inIdx) {
        ${checkOutOfBounds}
        return getX(batch, inIdx);
      }

      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = outIdx * ${windowSize};

        vec4 minMaxValue = vec4(${initializationValue});
        float prodValue = 1.0;
        float sumValue = 0.0;
        float allValue = 1.0;
        float anyValue = 0.0;

        for (int i = 0; i < ${windowSizeNearestVec4}; i += 4) {
          int inIdx = inOffset + i;
          ${vecType} values = ${vecType}(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            getValue(batch, inIdx + 3)
          );

          ${updateSnippet}
        }

        int inIdx = inOffset + ${windowSizeNearestVec4};
        if (${windowSizeVec4Remainder === 1}) {
          ${vecType} values = ${vecType}(
            getValue(batch, inIdx),
            initializationValue,
            initializationValue,
            initializationValue
          );

          ${updateSnippet}
        } else if (${windowSizeVec4Remainder === 2}) {
          ${vecType} values = ${vecType}(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            initializationValue,
            initializationValue
          );

          ${updateSnippet}
        } else if (${windowSizeVec4Remainder === 3}) {
          ${vecType} values = ${vecType}(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            initializationValue
          );

          ${updateSnippet}
        }
        setOutput(${returnValue});
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernel_utils/reduce.js
  function getReductionStages(inShape) {
    const stages = [];
    while (stages.length === 0 || stages[stages.length - 1].outSize !== 1) {
      const outSize = stages.length ? stages[stages.length - 1].outSize : inShape[1];
      const windowSize = backend_util_exports.computeOptimalWindowSize(outSize);
      stages.push({
        inSize: outSize,
        windowSize,
        outSize: Math.ceil(outSize / windowSize)
      });
    }
    return stages;
  }
  function reduce(x, dtype, reductionType, backend2) {
    const reductionStages = getReductionStages(x.shape);
    let result = x;
    for (let i = 0; i < reductionStages.length; i++) {
      const { inSize, windowSize, outSize } = reductionStages[i];
      let program;
      let previousResult;
      if (reductionType === "mean") {
        program = i === 0 ? new MeanProgram({ windowSize, inSize, batchSize: x.shape[0], outSize }, inSize) : new MeanProgram({ windowSize, inSize, batchSize: x.shape[0], outSize });
      } else {
        program = new ReduceProgram({ windowSize, inSize, batchSize: x.shape[0], outSize }, reductionType);
      }
      previousResult = result;
      result = backend2.runWebGLProgram(program, [result], dtype);
      if (previousResult.dataId !== x.dataId) {
        backend2.disposeIntermediateTensorInfo(previousResult);
      }
    }
    return result;
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/transpose_gpu.js
  var TransposeProgram = class {
    constructor(aShape, newDim) {
      this.variableNames = ["A"];
      const outputShape = new Array(aShape.length);
      for (let i = 0; i < outputShape.length; i++) {
        outputShape[i] = aShape[newDim[i]];
      }
      this.outputShape = outputShape;
      this.rank = outputShape.length;
      const dtype = getCoordsDataType(this.rank);
      const switched = getSwitchedCoords(newDim);
      this.userCode = `
    void main() {
      ${dtype} resRC = getOutputCoords();
      setOutput(getA(${switched}));
    }
    `;
    }
  };
  function getSwitchedCoords(newDim) {
    const rank = newDim.length;
    if (rank > 6) {
      throw Error(`Transpose for rank ${rank} is not yet supported`);
    }
    const originalOrder = ["resRC.x", "resRC.y", "resRC.z", "resRC.w", "resRC.u", "resRC.v"];
    const switchedCoords = new Array(rank);
    for (let i = 0; i < newDim.length; i++) {
      switchedCoords[newDim[i]] = originalOrder[i];
    }
    return switchedCoords.join();
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/transpose_packed_gpu.js
  var TransposePackedProgram = class {
    constructor(aShape, newDim) {
      this.variableNames = ["A"];
      this.packedInputs = true;
      this.packedOutput = true;
      const outputShape = new Array(aShape.length);
      for (let i = 0; i < outputShape.length; i++) {
        outputShape[i] = aShape[newDim[i]];
      }
      this.outputShape = outputShape;
      this.rank = outputShape.length;
      if (this.rank > 6) {
        throw Error(`Packed transpose for rank ${this.rank} is not yet supported.`);
      }
      const dtype = getCoordsDataType(this.rank);
      const outputOrder = getVecChannels("rc", this.rank);
      const switchedOrder = new Array(this.rank);
      for (let i = 0; i < newDim.length; i++) {
        switchedOrder[newDim[i]] = outputOrder[i];
      }
      const innerDims = `vec2(${switchedOrder.slice(-2).join()})`;
      const nextColumn = `++${outputOrder[this.rank - 1]} < ${outputShape[this.rank - 1]}`;
      const getc = `getChannel(getA(${switchedOrder.join()}), ${innerDims})`;
      this.userCode = `
    void main() {
      ${dtype} rc = getOutputCoords();
      vec4 result = vec4(0.);
      result[0] = ${getc};
      if(${nextColumn}) {
        result[1] = ${getc};
      }
      --${outputOrder[this.rank - 1]};
      if(++${outputOrder[this.rank - 2]} < ${outputShape[this.rank - 2]}) {
        result[2] = ${getc};
        if(${nextColumn}) {
          result[3] = ${getc};
        }
      }
      setOutput(result);
    }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Transpose_impl.js
  function transposeImpl2(x, perm, backend2) {
    const program = env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new TransposePackedProgram(x.shape, perm) : new TransposeProgram(x.shape, perm);
    return backend2.runWebGLProgram(program, [x], x.dtype);
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Sum_impl.js
  function sumImpl(x, axis, keepDims, backend2) {
    const reductionIndices = axis;
    const xRank = x.shape.length;
    const origAxes = util_exports.parseAxisParam(reductionIndices, x.shape);
    let axes = origAxes;
    const permutedAxes = backend_util_exports.getAxesPermutation(axes, xRank);
    const sumInputIsTransposed = permutedAxes != null;
    let sumInput = x;
    if (sumInputIsTransposed) {
      sumInput = transposeImpl2(x, permutedAxes, backend2);
      axes = backend_util_exports.getInnerMostAxes(axes.length, xRank);
    }
    backend_util_exports.assertAxesAreInnerMostDims("sum", axes, xRank);
    const [sumOutShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(sumInput.shape, axes);
    let outShape = sumOutShape;
    if (keepDims) {
      outShape = backend_util_exports.expandShapeToKeepDim(sumOutShape, origAxes);
    }
    const inSize = util_exports.sizeFromShape(reduceShape);
    const xSize = util_exports.sizeFromShape(x.shape);
    const batchSize = xSize / inSize;
    const reshapedInput = reshape3({ inputs: { x: sumInput }, attrs: { shape: [batchSize, inSize] }, backend: backend2 });
    const outType = sumOutType(x.dtype);
    const reduced = reduce(reshapedInput, outType, "sum", backend2);
    const out = reshape3({ inputs: { x: reduced }, attrs: { shape: outShape }, backend: backend2 });
    backend2.disposeIntermediateTensorInfo(reshapedInput);
    backend2.disposeIntermediateTensorInfo(reduced);
    if (sumInputIsTransposed) {
      backend2.disposeIntermediateTensorInfo(sumInput);
    }
    return out;
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Sum.js
  function sum4(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { axis, keepDims } = attrs;
    return sumImpl(x, axis, keepDims, backend2);
  }
  var sumConfig2 = {
    kernelName: Sum,
    backendName: "webgl",
    kernelFunc: sum4
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Transpose.js
  function transpose3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { perm } = attrs;
    const webglBackend = backend2;
    const xRank = x.shape.length;
    const newShape = new Array(xRank);
    for (let i = 0; i < newShape.length; i++) {
      newShape[i] = x.shape[perm[i]];
    }
    let out;
    if (webglBackend.shouldExecuteOnCPU([x])) {
      const xTexData = webglBackend.texData.get(x.dataId);
      const values = xTexData.values;
      const outValues = transposeImplCPU(values, x.shape, x.dtype, perm, newShape);
      out = webglBackend.makeTensorInfo(newShape, x.dtype);
      const outData = webglBackend.texData.get(out.dataId);
      outData.values = outValues;
    } else {
      out = transposeImpl2(x, perm, webglBackend);
    }
    return out;
  }
  var transposeConfig2 = {
    kernelName: Transpose,
    backendName: "webgl",
    kernelFunc: transpose3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/BatchMatMul_impl.js
  var MATMUL_SHARED_DIM_THRESHOLD = 1e3;
  function batchMatMulImpl({ a, b, transposeA, transposeB, backend: backend2, bias = null, preluActivationWeights = null, leakyreluAlpha = 0, activation = null }) {
    const aRank = a.shape.length;
    const bRank = b.shape.length;
    const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];
    const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];
    const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];
    const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];
    const outerDimsA = a.shape.slice(0, -2);
    const outerDimsB = b.shape.slice(0, -2);
    const batchDimA = util_exports.sizeFromShape(outerDimsA);
    const batchDimB = util_exports.sizeFromShape(outerDimsB);
    const batchDimsCompatible = batchDimA === batchDimB || batchDimA === 1 || batchDimB === 1;
    util_exports.assert(aRank >= 2 && bRank >= 2 && batchDimsCompatible, () => `Error in matMul: the input batch dimensions must either be the same or at least one input batch dimension must be 1. Got input batch dimensions of (${outerDimsA}) and (${outerDimsB}).`);
    const outShapeOuterDims = batchDimA > batchDimB ? a.shape.slice(0, -2) : b.shape.slice(0, -2);
    const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);
    util_exports.assert(innerShapeA === innerShapeB, () => `Error in matMul: inner shapes (${innerShapeA}) and (${innerShapeB}) of Tensors with shapes ${a.shape} and ${b.shape} and transposeA=${transposeA} and transposeB=${transposeB} must match.`);
    const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] : [batchDimA, outerShapeA, innerShapeA];
    const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] : [batchDimB, innerShapeB, outerShapeB];
    const a3d = reshape3({ inputs: { x: a }, backend: backend2, attrs: { shape: a3dShape } });
    const b3d = reshape3({ inputs: { x: b }, backend: backend2, attrs: { shape: b3dShape } });
    const intermediates = [a3d, b3d];
    const batchDim = Math.max(batchDimA, batchDimB);
    const sharedDim = transposeA ? a3d.shape[1] : a3d.shape[2];
    const hasBias = bias != null;
    const hasPreluActivationWeights = preluActivationWeights != null;
    const hasLeakyreluAlpha = activation === "leakyrelu";
    const fusedActivation = activation != null ? mapActivationToShaderProgram(activation, true) : null;
    const containsFusedOps = hasBias || hasPreluActivationWeights || hasLeakyreluAlpha || fusedActivation != null;
    let out;
    if ((outerShapeA === 1 || outerShapeB === 1) && sharedDim > MATMUL_SHARED_DIM_THRESHOLD && containsFusedOps === false) {
      let aVec = a3d;
      let bVec = b3d;
      if (transposeA) {
        aVec = transpose3({ inputs: { x: a3d }, backend: backend2, attrs: { perm: [0, 2, 1] } });
        intermediates.push(aVec);
      }
      if (transposeB) {
        bVec = transpose3({ inputs: { x: b3d }, backend: backend2, attrs: { perm: [0, 2, 1] } });
        intermediates.push(bVec);
      }
      const shouldReshapeA = outerShapeB !== 1;
      const shouldReshapeB = outerShapeB === 1;
      let aVec3d = aVec;
      if (shouldReshapeA) {
        aVec3d = reshape3({
          inputs: { x: aVec },
          backend: backend2,
          attrs: { shape: [batchDim, sharedDim, 1] }
        });
        intermediates.push(aVec3d);
      }
      const axis = outerShapeB === 1 ? 2 : 1;
      let bVec3d = bVec;
      if (shouldReshapeB) {
        bVec3d = reshape3({
          inputs: { x: bVec },
          backend: backend2,
          attrs: { shape: [batchDim, 1, sharedDim] }
        });
        intermediates.push(bVec3d);
      }
      const product = multiply2({ inputs: { a: aVec3d, b: bVec3d }, backend: backend2 });
      out = sum4({ inputs: { x: product }, backend: backend2, attrs: { axis, keepDims: true } });
      intermediates.push(product);
    } else {
      const dtype = upcastType(a.dtype, b.dtype);
      const program = new MatMulPackedProgram(a3dShape, b3dShape, [batchDim, outerShapeA, outerShapeB], transposeA, transposeB, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
      const inputs = [a3d, b3d];
      if (bias != null) {
        inputs.push(bias);
      }
      if (hasPreluActivationWeights) {
        inputs.push(preluActivationWeights);
      }
      if (hasLeakyreluAlpha) {
        const $leakyreluAlpha = backend2.makeTensorInfo([], "float32", util_exports.createScalarValue(leakyreluAlpha, "float32"));
        inputs.push($leakyreluAlpha);
        intermediates.push($leakyreluAlpha);
      }
      out = backend2.runWebGLProgram(program, inputs, dtype);
    }
    const outReshaped = reshape3({ inputs: { x: out }, backend: backend2, attrs: { shape: outShape } });
    intermediates.push(out);
    for (const i of intermediates) {
      backend2.disposeIntermediateTensorInfo(i);
    }
    return outReshaped;
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/_FusedMatMul.js
  function _fusedMatMul2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { a, b, bias, preluActivationWeights } = inputs;
    const { transposeA, transposeB, activation, leakyreluAlpha } = attrs;
    return batchMatMulImpl({
      a,
      b,
      transposeA,
      transposeB,
      backend: backend2,
      bias,
      preluActivationWeights,
      leakyreluAlpha,
      activation
    });
  }
  var _fusedMatMulConfig2 = {
    kernelName: _FusedMatMul,
    backendName: "webgl",
    kernelFunc: _fusedMatMul2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Abs.js
  var ABS2 = `return abs(x);`;
  function abs3(args) {
    const { inputs, backend: backend2 } = args;
    const { x } = inputs;
    if (backend2.shouldExecuteOnCPU([x]) && x.dtype !== "complex64") {
      const xData = backend2.texData.get(x.dataId);
      const outValues = simpleAbsImplCPU(xData.values);
      return backend2.makeTensorInfo(x.shape, x.dtype, outValues);
    }
    let program;
    if (env().getBool("WEBGL_PACK_UNARY_OPERATIONS")) {
      program = new UnaryOpPackedProgram(x.shape, ABS2);
    } else {
      program = new UnaryOpProgram(x.shape, ABS2);
    }
    return backend2.runWebGLProgram(program, [x], x.dtype);
  }
  var absConfig2 = {
    kernelName: Abs,
    backendName: "webgl",
    kernelFunc: abs3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Acos.js
  var ACOS = CHECK_NAN_SNIPPET + `
  if (abs(x) > 1.) {
    return NAN;
  }
  return acos(x);
`;
  var acos3 = unaryKernelFunc2({ opSnippet: ACOS });
  var acosConfig2 = {
    kernelName: Acos,
    backendName: "webgl",
    kernelFunc: acos3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Acosh.js
  var ACOSH = CHECK_NAN_SNIPPET + `
  if (x < 1.0) return NAN;
return log(x + sqrt(x * x - 1.0));`;
  var acosh3 = unaryKernelFunc2({ opSnippet: ACOSH });
  var acoshConfig2 = {
    kernelName: Acosh,
    backendName: "webgl",
    kernelFunc: acosh3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Add.js
  var ADD = "return a + b;";
  var addKernelFunc = binaryKernelFunc2({
    opSnippet: ADD,
    packedOpSnippet: ADD,
    supportsComplex: true,
    cpuKernelImpl: addImplCPU
  });
  var addConfig2 = {
    kernelName: Add,
    backendName: "webgl",
    kernelFunc: addKernelFunc
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/addn_gpu.js
  var AddNProgram = class {
    constructor(outputShape, shapes) {
      this.outputShape = [];
      this.outputShape = outputShape;
      this.variableNames = shapes.map((_, i) => `T${i}`);
      const snippets = [];
      this.variableNames.forEach((variable2) => {
        snippets.push(`float v${variable2} = get${variable2}AtOutCoords();`);
      });
      const operation = this.variableNames.map((variable2) => {
        return `v${variable2}`;
      }).join(" + ");
      this.userCode = `
      void main() {
        ${snippets.join("\n        ")}

        float result = ${operation};
        setOutput(result);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/addn_packed_gpu.js
  var AddNPackedProgram = class {
    constructor(outputShape, shapes) {
      this.outputShape = [];
      this.packedInputs = true;
      this.packedOutput = true;
      this.outputShape = outputShape;
      this.variableNames = shapes.map((_, i) => `T${i}`);
      const snippets = [];
      this.variableNames.forEach((variable2) => {
        snippets.push(`vec4 v${variable2} = get${variable2}AtOutCoords();`);
      });
      const operation = this.variableNames.map((variable2) => {
        return `v${variable2}`;
      }).join(" + ");
      this.userCode = `
      void main() {
        ${snippets.join("\n        ")}

        vec4 result = ${operation};
        setOutput(result);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/AddN.js
  function addN2(args) {
    const { inputs, backend: backend2 } = args;
    const tensors = inputs;
    if (tensors.length === 1) {
      return identity2({ inputs: { x: tensors[0] }, backend: backend2 });
    }
    if (tensors.length > env().get("WEBGL_MAX_TEXTURES_IN_SHADER")) {
      const midIndex = Math.floor(tensors.length / 2);
      const leftSide = addN2({ inputs: tensors.slice(0, midIndex), backend: backend2 });
      const rightSide = addN2({ inputs: tensors.slice(midIndex), backend: backend2 });
      return addN2({ inputs: [leftSide, rightSide], backend: backend2 });
    }
    const dtype = tensors.map((t) => t.dtype).reduce((d1, d2) => upcastType(d1, d2));
    const shapes = tensors.map((t) => t.shape);
    const usePackedOp = env().getBool("WEBGL_PACK");
    const program = usePackedOp ? new AddNPackedProgram(tensors[0].shape, shapes) : new AddNProgram(tensors[0].shape, shapes);
    return backend2.runWebGLProgram(program, tensors, dtype);
  }
  var addNConfig2 = {
    kernelName: AddN,
    backendName: "webgl",
    kernelFunc: addN2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/All.js
  function all3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { axis, keepDims } = attrs;
    const xRank = x.shape.length;
    const origAxes = util_exports.parseAxisParam(axis, x.shape);
    let axes = origAxes;
    const permutedAxes = backend_util_exports.getAxesPermutation(axes, xRank);
    let permutedX = x;
    if (permutedAxes != null) {
      permutedX = transpose3({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
      axes = backend_util_exports.getInnerMostAxes(axes.length, xRank);
    }
    backend_util_exports.assertAxesAreInnerMostDims("all", axes, xRank);
    const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(permutedX.shape, axes);
    const inSize = util_exports.sizeFromShape(reduceShape);
    const a2D = reshape3({ inputs: { x: permutedX }, backend: backend2, attrs: { shape: [-1, inSize] } });
    const reduced = reduce(a2D, a2D.dtype, "all", backend2);
    let res;
    if (keepDims) {
      const newShape = backend_util_exports.expandShapeToKeepDim(outShape, origAxes);
      res = reshape3({ inputs: { x: reduced }, backend: backend2, attrs: { shape: newShape } });
    } else {
      res = reshape3({ inputs: { x: reduced }, backend: backend2, attrs: { shape: outShape } });
    }
    backend2.disposeIntermediateTensorInfo(a2D);
    backend2.disposeIntermediateTensorInfo(reduced);
    if (permutedAxes != null) {
      backend2.disposeIntermediateTensorInfo(permutedX);
    }
    return res;
  }
  var allConfig2 = {
    kernelName: All,
    backendName: "webgl",
    kernelFunc: all3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Any.js
  function any3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { axis, keepDims } = attrs;
    const xRank = x.shape.length;
    const origAxes = util_exports.parseAxisParam(axis, x.shape);
    let axes = origAxes;
    const permutedAxes = backend_util_exports.getAxesPermutation(axes, xRank);
    let permutedX = x;
    if (permutedAxes != null) {
      permutedX = transpose3({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
      axes = backend_util_exports.getInnerMostAxes(axes.length, xRank);
    }
    backend_util_exports.assertAxesAreInnerMostDims("any", axes, xRank);
    const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(permutedX.shape, axes);
    const inSize = util_exports.sizeFromShape(reduceShape);
    const a2D = reshape3({ inputs: { x: permutedX }, backend: backend2, attrs: { shape: [-1, inSize] } });
    const reduced = reduce(a2D, a2D.dtype, "any", backend2);
    let res;
    if (keepDims) {
      const newShape = backend_util_exports.expandShapeToKeepDim(outShape, origAxes);
      res = reshape3({ inputs: { x: reduced }, backend: backend2, attrs: { shape: newShape } });
    } else {
      res = reshape3({ inputs: { x: reduced }, backend: backend2, attrs: { shape: outShape } });
    }
    backend2.disposeIntermediateTensorInfo(a2D);
    backend2.disposeIntermediateTensorInfo(reduced);
    if (permutedAxes != null) {
      backend2.disposeIntermediateTensorInfo(permutedX);
    }
    return res;
  }
  var anyConfig2 = {
    kernelName: Any,
    backendName: "webgl",
    kernelFunc: any3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/argminmax_gpu.js
  var ArgMinMaxProgram = class {
    constructor(reduceInfo, op2, firstPass) {
      this.variableNames = ["A"];
      const { windowSize, batchSize, outSize } = reduceInfo;
      if (!firstPass) {
        this.variableNames.push("bestIndicesA");
      }
      this.outputShape = [batchSize, outSize];
      const compOp = op2 === "max" ? ">" : "<";
      const indexSnippet = firstPass ? "inOffset + i;" : "round(getBestIndicesA(batch, inOffset + i));";
      this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = outIdx * ${windowSize};

        int bestIndex = inOffset;
        float bestValue = getA(batch, bestIndex);

        for (int i = 0; i < ${windowSize}; i++) {
          int inIdx = ${indexSnippet};
          float candidate = getA(batch, inIdx);
          if (candidate ${compOp} bestValue) {
            bestValue = candidate;
            bestIndex = inIdx;
          }
        }
        setOutput(float(bestIndex));
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/argminmax_packed_gpu.js
  var ArgMinMaxPackedProgram = class {
    constructor(shape, windowSize, op2, firstPass) {
      this.variableNames = ["A"];
      this.packedInputs = true;
      this.packedOutput = true;
      util_exports.assert(shape.length > 2, () => `Packed arg${op2.charAt(0).toUpperCase() + op2.slice(1)} supports only inputs with rank above 2.`);
      const inSize = shape[shape.length - 1];
      const outSize = Math.ceil(inSize / windowSize);
      this.outputShape = shape.slice(0, -1);
      if (outSize > 1) {
        this.outputShape.push(outSize);
      }
      if (!firstPass) {
        this.variableNames.push("bestIndicesA");
      }
      const outShape = this.outputShape;
      const rank = outShape.length;
      const dtype = getCoordsDataType(rank);
      const coords2 = getChannels("coords", rank);
      let sourceLocSetup;
      let sourceRank;
      if (outSize === 1) {
        sourceRank = rank + 1;
        const sourceLocDType = getCoordsDataType(sourceRank);
        sourceLocSetup = `
        ${sourceLocDType} sourceLocR = ${sourceLocDType}(${coords2.join()}, 0);
        ++${coords2[rank - 1]};
        ${sourceLocDType} sourceLocG = ${sourceLocDType}(${coords2.join()}, 0);
        ++${coords2[rank - 2]};
        ${sourceLocDType} sourceLocA = ${sourceLocDType}(${coords2.join()}, 0);
        --${coords2[rank - 1]};
        ${sourceLocDType} sourceLocB = ${sourceLocDType}(${coords2.join()}, 0);
        --${coords2[rank - 2]};`;
      } else {
        sourceRank = rank;
        sourceLocSetup = `
        ${dtype} sourceLocR = coords;
        ++${coords2[rank - 1]};
        ${dtype} sourceLocG = coords;
        ++${coords2[rank - 2]};
        ${dtype} sourceLocA = coords;
        --${coords2[rank - 1]};
        ${dtype} sourceLocB = coords;
        --${coords2[rank - 2]};`;
      }
      const channels = ["x", "y", "z", "w", "u", "v"].slice(0, sourceRank);
      const inChannel = "." + channels[sourceRank - 1];
      const intChannels = channels.map((x) => "int " + x);
      const srcRCoords = getChannels("sourceLocR", sourceRank - 1).concat("inIdx.r");
      const srcGCoords = getChannels("sourceLocG", sourceRank - 1).concat("inIdx.g");
      const srcBCoords = getChannels("sourceLocB", sourceRank - 1).concat("inIdx.b");
      const srcACoords = getChannels("sourceLocA", sourceRank - 1).concat("inIdx.a");
      const compOp = op2 === "max" ? "greaterThan" : "lessThan";
      const fetchCandidateIdx = firstPass ? "" : `
          inIdx = round(vec4(getBestIndicesAChannel(${srcRCoords.join()}),
                             getBestIndicesAChannel(${srcGCoords.join()}),
                             getBestIndicesAChannel(${srcBCoords.join()}),
                             getBestIndicesAChannel(${srcACoords.join()})));`;
      const fetchValue = `vec4(
            getAChannel(${srcRCoords.join()}),
            hasNextCol ? getAChannel(${srcGCoords.join()}) : 0.,
            hasNextRow ? getAChannel(${srcBCoords.join()}) : 0.,
            hasNextRow && hasNextCol ? getAChannel(${srcACoords.join()}) : 0.)`;
      const getBestIndicesAChannelSnippet = firstPass ? "" : `
      float getBestIndicesAChannel(${intChannels.join()}) {
        return getChannel(getBestIndicesA(${channels.join()}),
                                          vec2(${channels.slice(-2).join()}));
      }`;
      this.userCode = `
      float getAChannel(${intChannels.join()}) {
        return getChannel(getA(${channels.join()}),
                               vec2(${channels.slice(-2).join()}));
      }
      ${getBestIndicesAChannelSnippet}
      void main() {
        ${dtype} coords = getOutputCoords();
        bool hasNextCol = ${coords2[rank - 1]} < ${outShape[rank - 1] - 1};
        bool hasNextRow = ${coords2[rank - 2]} < ${outShape[rank - 2] - 1};
        ${sourceLocSetup}
        ivec4 srcIdx = ivec4(sourceLocR${inChannel}, sourceLocG${inChannel},
          sourceLocB${inChannel}, sourceLocA${inChannel}) * ${windowSize};
        ivec4 inIdx = srcIdx;
        vec4 bestIndex = vec4(inIdx);
        vec4 bestValue = ${fetchValue};

        for (int i = 0; i < ${windowSize}; i++) {
          inIdx = srcIdx;
          ${fetchCandidateIdx}
          vec4 candidate = ${fetchValue};
          bvec4 nan = isnan(candidate);
          bvec4 replace = bvec4(
            vec4(${compOp}(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));

          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,
                           replace.y  ? candidate.y : bestValue.y,
                           replace.z  ? candidate.z : bestValue.z,
                           replace.w  ? candidate.w : bestValue.w);
          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));
          srcIdx++;
        }
        setOutput(bestIndex);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernel_utils/arg_min_max.js
  function argReduce(backend2, x, reduceType, bestIndicesA = null) {
    let batchSize = x.shape[0];
    let inSize = x.shape[1];
    if (bestIndicesA != null) {
      batchSize = bestIndicesA.shape[0];
      inSize = bestIndicesA.shape[1];
    }
    const windowSize = backend_util_exports.computeOptimalWindowSize(inSize);
    const reduceInfo = { windowSize, inSize, batchSize, outSize: Math.ceil(inSize / windowSize) };
    const program = new ArgMinMaxProgram(reduceInfo, reduceType, bestIndicesA == null);
    const inputs = [x];
    if (bestIndicesA != null) {
      inputs.push(bestIndicesA);
    }
    const output = backend2.runWebGLProgram(program, inputs, "int32");
    if (output.shape[1] === 1) {
      return output;
    }
    const result = argReduce(backend2, x, reduceType, output);
    backend2.disposeIntermediateTensorInfo(output);
    return result;
  }
  function argReducePacked(backend2, x, reduceType, bestIndicesA = null) {
    const inShape = bestIndicesA != null ? bestIndicesA.shape : x.shape;
    const inSize = inShape[inShape.length - 1];
    const windowSize = backend_util_exports.computeOptimalWindowSize(inSize);
    const program = new ArgMinMaxPackedProgram(inShape, windowSize, reduceType, bestIndicesA == null);
    const inputs = bestIndicesA == null ? [x] : [x, bestIndicesA];
    const output = backend2.runWebGLProgram(program, inputs, "int32");
    if (output.shape.length === x.shape.length) {
      const result = argReducePacked(backend2, x, reduceType, output);
      backend2.disposeIntermediateTensorInfo(output);
      return result;
    }
    return output;
  }
  function argMinMaxReduce(backend2, x, axis, reduceType) {
    const axes = [axis];
    backend_util_exports.assertAxesAreInnerMostDims("arg" + reduceType.charAt(0).toUpperCase() + reduceType.slice(1), axes, x.shape.length);
    if (!env().getBool("WEBGL_PACK_REDUCE") || x.shape.length <= 2) {
      const intermediateTensorInfos = [];
      const xtexData = backend2.texData.get(x.dataId);
      const xIsPacked = xtexData !== null && xtexData.isPacked;
      let xUnPacked = x;
      if (xIsPacked) {
        xUnPacked = backend2.unpackTensor(x);
        intermediateTensorInfos.push(xUnPacked);
      }
      const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(xUnPacked.shape, axes);
      const inSize = util_exports.sizeFromShape(reduceShape);
      const a2D = reshape3({ inputs: { x: xUnPacked }, backend: backend2, attrs: { shape: [-1, inSize] } });
      intermediateTensorInfos.push(a2D);
      const reduced = argReduce(backend2, a2D, reduceType);
      intermediateTensorInfos.push(reduced);
      const reshaped = reshape3({ inputs: { x: reduced }, backend: backend2, attrs: { shape: outShape } });
      intermediateTensorInfos.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
      return reshaped;
    }
    return argReducePacked(backend2, x, reduceType);
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ArgMax.js
  function argMax3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { axis } = attrs;
    let axes = util_exports.parseAxisParam(axis, x.shape);
    const permutedAxes = backend_util_exports.getAxesPermutation(axes, x.shape.length);
    let $x = x;
    const intermediateTensorInfos = [];
    if (permutedAxes != null) {
      $x = transpose3({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
      intermediateTensorInfos.push($x);
      axes = backend_util_exports.getInnerMostAxes(axes.length, $x.shape.length);
    }
    backend_util_exports.assertAxesAreInnerMostDims("argMax", [axes[0]], $x.shape.length);
    const out = argMinMaxReduce(backend2, $x, axes[0], "max");
    intermediateTensorInfos.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
    return out;
  }
  var argMaxConfig2 = {
    kernelName: ArgMax,
    backendName: "webgl",
    kernelFunc: argMax3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ArgMin.js
  function argMin3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { axis } = attrs;
    let axes = util_exports.parseAxisParam(axis, x.shape);
    const permutedAxes = backend_util_exports.getAxesPermutation(axes, x.shape.length);
    let $x = x;
    const intermediateTensorInfos = [];
    if (permutedAxes != null) {
      $x = transpose3({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
      intermediateTensorInfos.push($x);
      axes = backend_util_exports.getInnerMostAxes(axes.length, $x.shape.length);
    }
    backend_util_exports.assertAxesAreInnerMostDims("argMin", [axes[0]], $x.shape.length);
    const out = argMinMaxReduce(backend2, $x, axes[0], "min");
    intermediateTensorInfos.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
    return out;
  }
  var argMinConfig2 = {
    kernelName: ArgMin,
    backendName: "webgl",
    kernelFunc: argMin3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Asin.js
  var ASIN = CHECK_NAN_SNIPPET + `
  if (abs(x) > 1.) {
    return NAN;
  }
  return asin(x);
`;
  var asin3 = unaryKernelFunc2({ opSnippet: ASIN });
  var asinConfig2 = {
    kernelName: Asin,
    backendName: "webgl",
    kernelFunc: asin3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Asinh.js
  var ASINH = CHECK_NAN_SNIPPET + `return log(x + sqrt(x * x + 1.0));`;
  var asinh3 = unaryKernelFunc2({ opSnippet: ASINH });
  var asinhConfig2 = {
    kernelName: Asinh,
    backendName: "webgl",
    kernelFunc: asinh3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Atan.js
  var ATAN = CHECK_NAN_SNIPPET + `
  return atan(x);
`;
  var atan4 = unaryKernelFunc2({ opSnippet: ATAN });
  var atanConfig2 = {
    kernelName: Atan,
    backendName: "webgl",
    kernelFunc: atan4
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Atan2.js
  var ATAN2 = CHECK_NAN_SNIPPET_BINARY + `
  return atan(a, b);
`;
  var ATAN2_PACKED = `
  vec4 result = atan(a, b);
  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));
  ` + CHECK_NAN_SNIPPET_BINARY_PACKED + `
  return result;
`;
  var atan23 = binaryKernelFunc2({ opSnippet: ATAN2, packedOpSnippet: ATAN2_PACKED });
  var atan2Config2 = {
    kernelName: Atan2,
    backendName: "webgl",
    kernelFunc: atan23
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Atanh.js
  var ATANH = CHECK_NAN_SNIPPET + `
  if ((x < -1.0) || (x > 1.0)) return NAN;
return (log(1.0 + x) - log(1.0 - x)) / 2.0;`;
  var atanh3 = unaryKernelFunc2({ opSnippet: ATANH });
  var atanhConfig2 = {
    kernelName: Atanh,
    backendName: "webgl",
    kernelFunc: atanh3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/pool_gpu.js
  var Pool2DProgram = class {
    constructor(convInfo, poolType, computePositions, flattenPositions = false, includeBatchInIndex = false) {
      this.variableNames = ["x"];
      if (poolType === "avg" && computePositions) {
        throw new Error("Cannot compute positions for average pool.");
      }
      const filterWidth = convInfo.filterWidth;
      const strideHeight = convInfo.strideHeight;
      const strideWidth = convInfo.strideWidth;
      const dilationHeight = convInfo.dilationHeight;
      const dilationWidth = convInfo.dilationWidth;
      const effectiveFilterHeight = convInfo.effectiveFilterHeight;
      const effectiveFilterWidth = convInfo.effectiveFilterWidth;
      const padTop = convInfo.padInfo.top;
      const padLeft = convInfo.padInfo.left;
      this.outputShape = convInfo.outShape;
      const isAvgPool = poolType === "avg";
      const batchFlattenPositionStr = `((batch  * ${convInfo.inHeight} + xR) * ${convInfo.inWidth} + xC) * ${convInfo.inChannels} + d`;
      const flattenPositionStr = `(xR * ${convInfo.inWidth} + xC) * ${convInfo.inChannels} + d`;
      let initializationValue = "0.0";
      if (!isAvgPool) {
        initializationValue = "-1.0 / 1e-20";
      }
      if (computePositions) {
        const compareOp2 = ">=";
        this.userCode = `
        const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});
        const ivec2 pads = ivec2(${padTop}, ${padLeft});

        void main() {
          ivec4 coords = getOutputCoords();
          int batch = coords[0];
          int d = coords[3];

          ivec2 xRCCorner = coords.yz * strides - pads;
          int xRCorner = xRCCorner.x;
          int xCCorner = xRCCorner.y;

          // max/min x(?, ?, d) to get y(yR, yC, d).
          // ? = to be determined
          float minMaxValue = 0.0;
          float minMaxValueFound = 0.0;
          int minMaxPosition = 0;
          float avgValue = 0.0;

          for (int wR = 0; wR < ${effectiveFilterHeight};
              wR += ${dilationHeight}) {
            int xR = xRCorner + wR;

            if (xR < 0 || xR >= ${convInfo.inHeight}) {
              continue;
            }

            for (int wC = 0; wC < ${effectiveFilterWidth};
                wC += ${dilationWidth}) {
              int xC = xCCorner + wC;

              if (xC < 0 || xC >= ${convInfo.inWidth}) {
                continue;
              }

              float value = getX(batch, xR, xC, d);

              // If a min / max value has already been found, use it. If not,
              // use the current value.
              float currMinMaxValue = mix(
                  value, minMaxValue, minMaxValueFound);
              if (value ${compareOp2} currMinMaxValue) {
                minMaxValue = value;
                minMaxValueFound = 1.0;
                minMaxPosition = ${flattenPositions ? includeBatchInIndex ? batchFlattenPositionStr : flattenPositionStr : `wR * ${effectiveFilterWidth} + wC`};
              }
            }
          }
          setOutput(float(minMaxPosition));
        }
      `;
        return;
      }
      const compareOp = "max";
      let returnValue = `${poolType}(${poolType}(${poolType}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;
      if (poolType === "avg") {
        returnValue = `avgValue / count`;
      }
      const filterWidthNearestVec4 = Math.floor(filterWidth / 4) * 4;
      const filterWidthVec4Remainder = filterWidth % 4;
      const updateSnippet = `
      if (${isAvgPool}) {
        avgValue += dot(values, ones);
      } else {
        minMaxValue = ${compareOp}(values, minMaxValue);
      }
    `;
      this.userCode = `
      const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});
      const ivec2 pads = ivec2(${padTop}, ${padLeft});
      const float initializationValue = ${initializationValue};
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float count = 0.0;

      float getValue(int batch, int xR, int xC, int d) {
        if (xC < 0 || xC >= ${convInfo.inWidth}) {
          return initializationValue;
        }
        count += 1.0;
        return getX(batch, xR, xC, d);
      }

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d = coords[3];

        ivec2 xRCCorner = coords.yz * strides - pads;
        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        // max/min x(?, ?, d) to get y(yR, yC, d).
        // ? = to be determined
        vec4 minMaxValue = vec4(${initializationValue});
        float avgValue = 0.0;
        count = 0.0;

        for (int wR = 0; wR < ${effectiveFilterHeight};
            wR += ${dilationHeight}) {
          int xR = xRCorner + wR;

          if (xR < 0 || xR >= ${convInfo.inHeight}) {
            continue;
          }

          for (int wC = 0; wC < ${filterWidthNearestVec4}; wC += 4) {
            int xC = xCCorner + wC * ${dilationWidth};

            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              getValue(batch, xR, xC + ${dilationWidth}, d),
              getValue(batch, xR, xC + 2 * ${dilationWidth}, d),
              getValue(batch, xR, xC + 3 * ${dilationWidth}, d)
            );

            ${updateSnippet}
          }

          int xC = xCCorner + ${filterWidthNearestVec4};
          if (${filterWidthVec4Remainder === 1}) {
            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              initializationValue,
              initializationValue,
              initializationValue
            );

            ${updateSnippet}
          } else if (${filterWidthVec4Remainder === 2}) {
            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              getValue(batch, xR, xC + ${dilationWidth}, d),
              initializationValue,
              initializationValue
            );

            ${updateSnippet}
          } else if (${filterWidthVec4Remainder === 3}) {
            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              getValue(batch, xR, xC + ${dilationWidth}, d),
              getValue(batch, xR, xC + 2 * ${dilationWidth}, d),
              initializationValue
            );

            ${updateSnippet}
          }
        }
        setOutput(${returnValue});
      }
    `;
    }
  };
  var Pool3DProgram = class {
    constructor(convInfo, poolType, computePositions, flattenPositions = false, includeBatchInIndex = false) {
      this.variableNames = ["x"];
      if (poolType === "avg" && computePositions) {
        throw new Error("Cannot compute positions for average pool.");
      }
      const filterWidth = convInfo.filterWidth;
      const strideDepth = convInfo.strideDepth;
      const strideHeight = convInfo.strideHeight;
      const strideWidth = convInfo.strideWidth;
      const dilationDepth = convInfo.dilationDepth;
      const dilationHeight = convInfo.dilationHeight;
      const dilationWidth = convInfo.dilationWidth;
      const effectiveFilterDepth = convInfo.effectiveFilterDepth;
      const effectiveFilterHeight = convInfo.effectiveFilterHeight;
      const effectiveFilterWidth = convInfo.effectiveFilterWidth;
      const padFront = convInfo.padInfo.front;
      const padTop = convInfo.padInfo.top;
      const padLeft = convInfo.padInfo.left;
      this.outputShape = convInfo.outShape;
      const isAvgPool = poolType === "avg";
      let initializationValue = "0.0";
      if (!isAvgPool) {
        initializationValue = "-1.0 / 1e-20";
      }
      if (computePositions) {
        const compareOp2 = ">=";
        this.userCode = `
        const ivec3 strides =
            ivec3(${strideDepth}, ${strideHeight}, ${strideWidth});
        const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});

        void main() {
          ivec5 coords = getOutputCoords();
          int batch = coords.x;
          int ch = coords.u;

          ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;
          int xDCorner = xCorner.x;
          int xRCorner = xCorner.y;
          int xCCorner = xCorner.z;

          // max/min x(?, ?, ?, ch) to get y(yD, yR, yC, ch).
          // ? = to be determined
          float minMaxValue = 0.0;
          float minMaxValueFound = 0.0;
          int minMaxPosition = 0;

          for (int wD = 0; wD < ${effectiveFilterDepth};
              wD += ${dilationDepth}) {
            int xD = xDCorner + wD;

            if (xD < 0 || xD >= ${convInfo.inDepth}) {
              continue;
            }

            for (int wR = 0; wR < ${effectiveFilterHeight};
                wR += ${dilationHeight}) {
              int xR = xRCorner + wR;

              if (xR < 0 || xR >= ${convInfo.inHeight}) {
                continue;
              }

              for (int wC = 0; wC < ${effectiveFilterWidth};
                  wC += ${dilationWidth}) {
                int xC = xCCorner + wC;

                if (xC < 0 || xC >= ${convInfo.inWidth}) {
                  continue;
                }

                float value = getX(batch, xD, xR, xC, ch);

                // If a min / max value has already been found, use it. If not,
                // use the current value.
                float currMinMaxValue = mix(
                    value, minMaxValue, minMaxValueFound);
                if (value ${compareOp2} currMinMaxValue) {
                  minMaxValue = value;
                  minMaxValueFound = 1.0;
                  minMaxPosition = ${flattenPositions ? includeBatchInIndex ? `(((batch * ${convInfo.inDepth} + xD) * ${convInfo.inHeight} + xR) * ${convInfo.inWidth} + xC) * ${convInfo.inChannels} + ch` : `((xD * ${convInfo.inHeight} + xR) * ${convInfo.inWidth} + xC) * ${convInfo.inChannels} + ch` : `wD * ${effectiveFilterHeight} * ${effectiveFilterWidth} +
                      wR * ${effectiveFilterWidth} + wC`};
                }
              }
            }
          }
          setOutput(float(minMaxPosition));
        }
      `;
        return;
      }
      const compareOp = "max";
      let returnValue = `${poolType}(${poolType}(${poolType}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;
      if (poolType === "avg") {
        returnValue = `avgValue / count`;
      }
      const filterWidthNearestVec4 = Math.floor(filterWidth / 4) * 4;
      const filterWidthVec4Remainder = filterWidth % 4;
      const updateSnippet = `
      if (${isAvgPool}) {
        avgValue += dot(values, ones);
      } else {
        minMaxValue = ${compareOp}(values, minMaxValue);
      }
    `;
      this.userCode = `
      const ivec3 strides =
        ivec3(${strideDepth}, ${strideHeight}, ${strideWidth});
      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});
      const float initializationValue = ${initializationValue};
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float count = 0.0;

      float getValue(int batch, int xD, int xR, int xC, int ch) {
        if (xC < 0 || xC >= ${convInfo.inWidth}) {
          return initializationValue;
        }
        count += 1.0;
        return getX(batch, xD, xR, xC, ch);
      }

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int ch = coords.u;

        ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;
        int xDCorner = xCorner.x;
        int xRCorner = xCorner.y;
        int xCCorner = xCorner.z;

        // max/min x(?, ?, ?, d) to get y(yD, yR, yC, ch).
        // ? = to be determined
        vec4 minMaxValue = vec4(${initializationValue});
        float avgValue = 0.0;
        count = 0.0;

        for (int wD = 0; wD < ${effectiveFilterDepth};
            wD += ${dilationDepth}) {
          int xD = xDCorner + wD;

          if (xD < 0 || xD >= ${convInfo.inDepth}) {
            continue;
          }

          for (int wR = 0; wR < ${effectiveFilterHeight};
            wR += ${dilationHeight}) {
            int xR = xRCorner + wR;

            if (xR < 0 || xR >= ${convInfo.inHeight}) {
              continue;
            }

            for (int wC = 0; wC < ${filterWidthNearestVec4}; wC += 4) {
              int xC = xCCorner + wC * ${dilationWidth};

              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                getValue(batch, xD, xR, xC + ${dilationWidth}, ch),
                getValue(batch, xD, xR, xC + 2 * ${dilationWidth}, ch),
                getValue(batch, xD, xR, xC + 3 * ${dilationWidth}, ch)
              );

              ${updateSnippet}
            }

            int xC = xCCorner + ${filterWidthNearestVec4};
            if (${filterWidthVec4Remainder === 1}) {
              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                initializationValue,
                initializationValue,
                initializationValue
              );

              ${updateSnippet}
            } else if (${filterWidthVec4Remainder === 2}) {
              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                getValue(batch, xD, xR, xC + ${dilationWidth}, ch),
                initializationValue,
                initializationValue
              );

              ${updateSnippet}
            } else if (${filterWidthVec4Remainder === 3}) {
              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                getValue(batch, xD, xR, xC + ${dilationWidth}, ch),
                getValue(batch, xD, xR, xC + 2 * ${dilationWidth}, ch),
                initializationValue
              );

              ${updateSnippet}
            }
          }
          setOutput(${returnValue});
        }
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/AvgPool.js
  function avgPool3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    assertNotComplex2(x, "avgPool");
    const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
    const dilations = 1;
    util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
    const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode);
    if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 && util_exports.arraysEqual(convInfo.inShape, convInfo.outShape)) {
      return identity2({ inputs: { x }, backend: backend2 });
    }
    const avgPoolProgram = new Pool2DProgram(convInfo, "avg", false);
    return backend2.runWebGLProgram(avgPoolProgram, [x], "float32");
  }
  var avgPoolConfig2 = {
    kernelName: AvgPool,
    backendName: "webgl",
    kernelFunc: avgPool3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/AvgPool3D.js
  function avgPool3D2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat } = attrs;
    const dilations = [1, 1, 1];
    const convInfo = backend_util_exports.computePool3DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode, dataFormat);
    const avgPoolProgram = new Pool3DProgram(convInfo, "avg", false);
    return backend2.runWebGLProgram(avgPoolProgram, [x], "float32");
  }
  var avgPool3DConfig2 = {
    kernelName: AvgPool3D,
    backendName: "webgl",
    kernelFunc: avgPool3D2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/avg_pool_backprop_gpu.js
  var AvgPool2DBackpropProgram = class {
    constructor(convInfo) {
      this.variableNames = ["dy"];
      this.outputShape = convInfo.inShape;
      const filterHeight = convInfo.filterHeight;
      const filterWidth = convInfo.filterWidth;
      const strideHeight = convInfo.strideHeight;
      const strideWidth = convInfo.strideWidth;
      const dilationHeight = convInfo.dilationHeight;
      const dilationWidth = convInfo.dilationWidth;
      const effectiveFilterHeight = convInfo.effectiveFilterHeight;
      const effectiveFilterWidth = convInfo.effectiveFilterWidth;
      const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
      const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
      const avgMultiplier = 1 / (filterHeight * filterWidth);
      this.userCode = `
      const ivec2 pads = ivec2(${padTop}, ${padLeft});
      const float avgMultiplier = float(${avgMultiplier});

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];

        ivec2 dyRCCorner = coords.yz - pads;
        int dyRCorner = dyRCCorner.x;
        int dyCCorner = dyRCCorner.y;

        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${effectiveFilterHeight};
            wR += ${dilationHeight}) {
          float dyR = float(dyRCorner + wR) / ${strideHeight}.0;

          if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          for (int wC = 0; wC < ${effectiveFilterWidth};
            wC+= ${dilationWidth}) {
            float dyC = float(dyCCorner + wC) / ${strideWidth}.0;

            if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            float dyValue = getDy(b, idyR, idyC, d);

            dotProd += dyValue * avgMultiplier;
          }
        }
        setOutput(dotProd);
      }
    `;
    }
  };
  var AvgPool3DBackpropProgram = class {
    constructor(convInfo) {
      this.variableNames = ["dy"];
      this.outputShape = convInfo.inShape;
      const filterDepth = convInfo.filterDepth;
      const filterHeight = convInfo.filterHeight;
      const filterWidth = convInfo.filterWidth;
      const strideDepth = convInfo.strideDepth;
      const strideHeight = convInfo.strideHeight;
      const strideWidth = convInfo.strideWidth;
      const dilationDepth = convInfo.dilationDepth;
      const dilationHeight = convInfo.dilationHeight;
      const dilationWidth = convInfo.dilationWidth;
      const effectiveFilterDepth = convInfo.effectiveFilterDepth;
      const effectiveFilterHeight = convInfo.effectiveFilterHeight;
      const effectiveFilterWidth = convInfo.effectiveFilterWidth;
      const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;
      const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
      const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
      const avgMultiplier = 1 / (filterDepth * filterHeight * filterWidth);
      this.userCode = `
      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});
      const float avgMultiplier = float(${avgMultiplier});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int ch = coords.u;

        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;
        int dyDCorner = dyCorner.x;
        int dyRCorner = dyCorner.y;
        int dyCCorner = dyCorner.z;

        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get
        // dx(xD, xR, xC, ch).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;

        for (int wD = 0; wD < ${effectiveFilterDepth};
            wD += ${dilationDepth}) {
          float dyD = float(dyDCorner + wD) / ${strideDepth}.0;

          if (dyD < 0.0 || dyD >= ${convInfo.outDepth}.0 || fract(dyD) > 0.0) {
            continue;
          }
          int idyD = int(dyD);

          for (int wR = 0; wR < ${effectiveFilterHeight};
              wR += ${dilationHeight}) {
            float dyR = float(dyRCorner + wR) / ${strideHeight}.0;

            if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 ||
                fract(dyR) > 0.0) {
              continue;
            }
            int idyR = int(dyR);

            for (int wC = 0; wC < ${effectiveFilterWidth};
                wC += ${dilationWidth}) {
              float dyC = float(dyCCorner + wC) / ${strideWidth}.0;

              if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||
                  fract(dyC) > 0.0) {
                continue;
              }
              int idyC = int(dyC);

              float dyValue = getDy(batch, idyD, idyR, idyC, ch);

              dotProd += dyValue * avgMultiplier;
            }
          }
        }
        setOutput(dotProd);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/AvgPool3DGrad.js
  function avgPool3DGrad2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { dy, input: input2 } = inputs;
    const x = input2;
    const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
    const dilations = [1, 1, 1];
    const convInfo = backend_util_exports.computePool3DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode);
    const avgPoolBackpropProgram = new AvgPool3DBackpropProgram(convInfo);
    return backend2.runWebGLProgram(avgPoolBackpropProgram, [dy], x.dtype);
  }
  var avgPoolGrad3DConfig = {
    kernelName: AvgPool3DGrad,
    backendName: "webgl",
    kernelFunc: avgPool3DGrad2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/AvgPoolGrad.js
  function avgPoolGrad3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { dy, input: input2 } = inputs;
    const x = input2;
    assertNotComplex2([dy, input2], "avgPoolGrad");
    const { filterSize, strides, pad: pad2 } = attrs;
    const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, 1, pad2);
    const avgPoolBackpropProgram = new AvgPool2DBackpropProgram(convInfo);
    return backend2.runWebGLProgram(avgPoolBackpropProgram, [dy], x.dtype);
  }
  var avgPoolGradConfig3 = {
    kernelName: AvgPoolGrad,
    backendName: "webgl",
    kernelFunc: avgPoolGrad3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/BatchMatMul.js
  function batchMatMul2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { a, b } = inputs;
    const { transposeA, transposeB } = attrs;
    return batchMatMulImpl({ a, b, transposeA, transposeB, backend: backend2 });
  }
  var batchMatMulConfig2 = {
    kernelName: BatchMatMul,
    backendName: "webgl",
    kernelFunc: batchMatMul2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/batchnorm_gpu.js
  var BatchNormProgram = class {
    constructor(xShape, meanShape, varianceShape, offsetShape, scaleShape, varianceEpsilon) {
      this.outputShape = [];
      this.variableNames = ["x", "mean", "variance"];
      backend_util_exports.assertAndGetBroadcastShape(xShape, meanShape);
      backend_util_exports.assertAndGetBroadcastShape(xShape, varianceShape);
      let offsetSnippet = "0.0";
      if (offsetShape != null) {
        backend_util_exports.assertAndGetBroadcastShape(xShape, offsetShape);
        this.variableNames.push("offset");
        offsetSnippet = "getOffsetAtOutCoords()";
      }
      let scaleSnippet = "1.0";
      if (scaleShape != null) {
        backend_util_exports.assertAndGetBroadcastShape(xShape, scaleShape);
        this.variableNames.push("scale");
        scaleSnippet = "getScaleAtOutCoords()";
      }
      this.outputShape = xShape;
      this.userCode = `
      void main() {
        float x = getXAtOutCoords();
        float mean = getMeanAtOutCoords();
        float variance = getVarianceAtOutCoords();
        float offset = ${offsetSnippet};
        float scale = ${scaleSnippet};
        float inv = scale * inversesqrt(variance + float(${varianceEpsilon}));
        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/batchnorm_packed_gpu.js
  var BatchNormPackedProgram = class {
    constructor(xShape, meanShape, varianceShape, offsetShape, scaleShape, varianceEpsilon) {
      this.packedInputs = true;
      this.packedOutput = true;
      this.variableNames = ["x", "mean", "variance"];
      backend_util_exports.assertAndGetBroadcastShape(xShape, meanShape);
      backend_util_exports.assertAndGetBroadcastShape(xShape, varianceShape);
      let offsetSnippet = "vec4(0.0)";
      if (offsetShape != null) {
        backend_util_exports.assertAndGetBroadcastShape(xShape, offsetShape);
        this.variableNames.push("offset");
        offsetSnippet = "getOffsetAtOutCoords()";
      }
      let scaleSnippet = "vec4(1.0)";
      if (scaleShape != null) {
        backend_util_exports.assertAndGetBroadcastShape(xShape, scaleShape);
        this.variableNames.push("scale");
        scaleSnippet = "getScaleAtOutCoords()";
      }
      this.outputShape = xShape;
      this.userCode = `
      void main() {
        vec4 offset = ${offsetSnippet};
        vec4 scale = ${scaleSnippet};

        vec4 x = getXAtOutCoords();
        vec4 mean = getMeanAtOutCoords();
        vec4 variance = getVarianceAtOutCoords();

        vec4 inv = scale * inversesqrt(variance + vec4(${varianceEpsilon}));

        setOutput((x - mean) * inv + offset);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/BatchNorm.js
  var batchNorm3 = ({ inputs, backend: backend2, attrs }) => {
    const { x, mean: mean3, variance, offset, scale: scale2 } = inputs;
    util_exports.assert(mean3.shape.length === variance.shape.length, () => "Batch normalization gradient requires mean and variance to have equal ranks.");
    util_exports.assert(offset == null || mean3.shape.length === offset.shape.length, () => "Batch normalization gradient requires mean and offset to have equal ranks.");
    util_exports.assert(scale2 == null || mean3.shape.length === scale2.shape.length, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
    let { varianceEpsilon } = attrs;
    if (varianceEpsilon == null) {
      varianceEpsilon = 1e-3;
    }
    const finalInputs = [x, mean3, variance];
    let offsetShape = null;
    if (offset != null) {
      offsetShape = offset.shape;
      finalInputs.push(offset);
    }
    let scaleShape = null;
    if (scale2 != null) {
      scaleShape = scale2.shape;
      finalInputs.push(scale2);
    }
    const program = env().getBool("WEBGL_PACK_NORMALIZATION") ? new BatchNormPackedProgram(x.shape, mean3.shape, variance.shape, offsetShape, scaleShape, varianceEpsilon) : new BatchNormProgram(x.shape, mean3.shape, variance.shape, offsetShape, scaleShape, varianceEpsilon);
    const output = backend2.runWebGLProgram(program, finalInputs, finalInputs[0].dtype);
    return output;
  };
  var batchNormConfig2 = {
    kernelName: FusedBatchNorm,
    backendName: "webgl",
    kernelFunc: batchNorm3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/slice_gpu.js
  var SliceProgram = class {
    constructor(destSize) {
      this.variableNames = ["source"];
      this.outputShape = destSize;
      this.rank = destSize.length;
      const dtype = getCoordsDataType(this.rank);
      this.customUniforms = [{ name: "start", arrayIndex: this.rank, type: "int" }];
      const sourceCoords = getCoords(this.rank);
      let body;
      const coordSum = destSize.map((_, i) => {
        return `sourceLoc.${coords[i]} = start[${i}] + coords.${coords[i]};`;
      });
      body = `
        ${dtype} sourceLoc;
        ${dtype} coords = getOutputCoords();
        ${coordSum.join("\n")}
      `;
      this.userCode = `
      void main() {
        ${body}
        setOutput(getSource(${sourceCoords}));
      }
    `;
    }
  };
  var coords = ["x", "y", "z", "w", "u", "v"];
  function getCoords(rank) {
    if (rank === 1) {
      return "sourceLoc";
    } else if (rank <= 6) {
      return coords.slice(0, rank).map((x) => "sourceLoc." + x).join(",");
    } else {
      throw Error(`Slicing for rank ${rank} is not yet supported`);
    }
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/slice_packed_gpu.js
  var SlicePackedProgram = class {
    constructor(destSize) {
      this.variableNames = ["source"];
      this.packedInputs = true;
      this.packedOutput = true;
      this.outputShape = destSize;
      this.rank = destSize.length;
      this.customUniforms = [{ name: "start", arrayIndex: this.rank, type: "int" }];
      const dtype = getCoordsDataType(this.rank);
      const coords2 = getChannels("coords", this.rank);
      const sourceLoc = getChannels("sourceLoc", this.rank);
      const innerDims = this.rank === 1 ? "sourceLoc" : `vec2(${sourceLoc.slice(-2).join()})`;
      const getChannel = `getChannel(getSource(${sourceLoc.join()}), ${innerDims})`;
      const upperRow = `
      result.x = ${getChannel};
      if (++${coords2[this.rank - 1]} < ${destSize[this.rank - 1]}) {
        ++${sourceLoc[this.rank - 1]};
        result.y = ${getChannel};
        --${sourceLoc[this.rank - 1]};
      }
    `;
      const lowerRow = this.rank === 1 ? "" : `
      --${coords2[this.rank - 1]};
      if (++${coords2[this.rank - 2]} < ${destSize[this.rank - 2]}) {
        ++${sourceLoc[this.rank - 2]};
        result.z = ${getChannel};
        if (++${coords2[this.rank - 1]} < ${destSize[this.rank - 1]}) {
          ++${sourceLoc[this.rank - 1]};
          result.w = ${getChannel};
        }
      }
    `;
      const sourceLocSetup = this.rank <= 4 ? `sourceLoc = coords +
            ${dtype}(${destSize.map((_, i) => `start[${i}]`).join()});` : destSize.map((_, i) => `${sourceLoc[i]} = ${coords2[i]} + start[${i}];`).join("\n");
      this.userCode = `
      void main() {
        ${dtype} coords = getOutputCoords();
        ${dtype} sourceLoc;
        ${sourceLocSetup}
        vec4 result = vec4(0.);
        ${upperRow}
        ${lowerRow}
        setOutput(result);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Slice.js
  function shallowSlice(x, begin, size2, backend2) {
    const xTexData = backend2.texData.get(x.dataId);
    const t = backend2.makeTensorInfo(size2, x.dtype);
    const newTexData = backend2.texData.get(t.dataId);
    Object.assign(newTexData, xTexData);
    newTexData.refCount = 1;
    newTexData.shape = size2;
    newTexData.dtype = x.dtype;
    let flatOffset = slice_util_exports.computeFlatOffset(begin, util_exports.computeStrides(x.shape));
    if (xTexData.slice) {
      flatOffset += xTexData.slice.flatOffset;
    }
    newTexData.slice = {
      flatOffset,
      origDataId: xTexData.slice && xTexData.slice.origDataId || x.dataId
    };
    const refCount = backend2.dataRefCount.get(newTexData.slice.origDataId) || 1;
    backend2.dataRefCount.set(newTexData.slice.origDataId, refCount + 1);
    return t;
  }
  function slice3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { begin, size: size2 } = attrs;
    const [$begin, $size] = slice_util_exports.parseSliceParams(x, begin, size2);
    slice_util_exports.assertParamsValid(x, $begin, $size);
    if (util_exports.sizeFromShape($size) === 0) {
      return backend2.makeTensorInfo($size, x.dtype, []);
    }
    if (backend2.shouldExecuteOnCPU([x]) || x.dtype === "string") {
      const xTexData = backend2.texData.get(x.dataId);
      const outValues = sliceImplCPU(xTexData.values, $begin, $size, x.shape, x.dtype);
      return backend2.makeTensorInfo($size, x.dtype, outValues);
    }
    const { isPacked } = backend2.texData.get(x.dataId);
    const isContinous = slice_util_exports.isSliceContinous(x.shape, $begin, $size);
    if (isPacked || !isContinous) {
      const program = env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new SlicePackedProgram($size) : new SliceProgram($size);
      const customValues = [$begin];
      return backend2.runWebGLProgram(program, [x], x.dtype, customValues);
    }
    backend2.uploadToGPU(x.dataId);
    return shallowSlice(x, $begin, $size, backend2);
  }
  var sliceConfig2 = {
    kernelName: Slice,
    backendName: "webgl",
    kernelFunc: slice3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/BatchToSpaceND.js
  var batchToSpaceND3 = (args) => {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { blockShape, crops } = attrs;
    util_exports.assert(x.shape.length <= 4, () => "batchToSpaceND for rank > 4 with a WebGL backend not implemented yet");
    const prod4 = blockShape.reduce((a, b) => a * b);
    const reshaped = backend_util_exports.getReshaped(x.shape, blockShape, prod4);
    const permuted = backend_util_exports.getPermuted(reshaped.length, blockShape.length);
    const reshapedPermuted = backend_util_exports.getReshapedPermuted(x.shape, blockShape, prod4);
    const sliceBeginCoords = backend_util_exports.getSliceBeginCoords(crops, blockShape.length);
    const sliceSize = backend_util_exports.getSliceSize(reshapedPermuted, crops, blockShape.length);
    const toDispose = [];
    const reshapedIntermediate = reshape3({ inputs: { x }, backend: backend2, attrs: { shape: reshaped } });
    const transposedIntermediate = transpose3({ inputs: { x: reshapedIntermediate }, backend: backend2, attrs: { perm: permuted } });
    const reshapedIntermediate2 = reshape3({
      inputs: { x: transposedIntermediate },
      backend: backend2,
      attrs: { shape: reshapedPermuted }
    });
    const sliced = slice3({
      inputs: { x: reshapedIntermediate2 },
      backend: backend2,
      attrs: { begin: sliceBeginCoords, size: sliceSize }
    });
    toDispose.push(reshapedIntermediate);
    toDispose.push(transposedIntermediate);
    toDispose.push(reshapedIntermediate2);
    toDispose.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
    return sliced;
  };
  var batchToSpaceNDConfig2 = {
    kernelName: BatchToSpaceND,
    backendName: "webgl",
    kernelFunc: batchToSpaceND3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Bincount.js
  function bincount3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, weights } = inputs;
    const { size: size2 } = attrs;
    const xVals = backend2.readSync(x.dataId);
    const weightsVals = backend2.readSync(weights.dataId);
    const outVals = bincountImplCPU(xVals, weightsVals, weights.dtype, weights.shape, size2);
    return backend2.makeTensorInfo([size2], weights.dtype, outVals);
  }
  var bincountConfig2 = {
    kernelName: Bincount,
    backendName: "webgl",
    kernelFunc: bincount3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/BroadcastArgs.js
  function broadcastArgs2(args) {
    const { inputs, backend: backend2 } = args;
    const { s0, s1 } = inputs;
    const s0Vals = backend2.readSync(s0.dataId);
    const s1Vals = backend2.readSync(s1.dataId);
    const broadcastShape = backend_util_exports.assertAndGetBroadcastShape(Array.from(s0Vals), Array.from(s1Vals));
    return backend2.makeTensorInfo([broadcastShape.length], "int32", Int32Array.from(broadcastShape));
  }
  var broadcastArgsConfig2 = {
    kernelName: BroadcastArgs,
    backendName: "webgl",
    kernelFunc: broadcastArgs2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/NotEqual.js
  var NOT_EQUAL = `return float(a != b);`;
  var notEqual3 = binaryKernelFunc2({ opSnippet: NOT_EQUAL, cpuKernelImpl: notEqualImplCPU, dtype: "bool" });
  var notEqualConfig2 = {
    kernelName: NotEqual,
    backendName: "webgl",
    kernelFunc: notEqual3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Real.js
  function real3(args) {
    const { inputs, backend: backend2 } = args;
    const { input: input2 } = inputs;
    const inputData = backend2.texData.get(input2.dataId);
    return identity2({ inputs: { x: inputData.complexTensorInfos.real }, backend: backend2 });
  }
  var realConfig2 = {
    kernelName: Real,
    backendName: "webgl",
    kernelFunc: real3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernel_utils/int.js
  var TO_INT = `return float(int(x));`;
  function int(input2, backend2) {
    const program = new UnaryOpProgram(input2.shape, TO_INT);
    const output = backend2.runWebGLProgram(program, [input2], "int32");
    return { dataId: output.dataId, shape: output.shape, dtype: output.dtype };
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Cast.js
  function cast4(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { dtype } = attrs;
    if (dtype === "complex64") {
      if (x.dtype === "complex64") {
        return identity2({ inputs: { x }, backend: backend2 });
      }
      const zerosTensor = zeros(x.shape);
      const floatX = cast4({ inputs: { x }, backend: backend2, attrs: { dtype: "float32" } });
      const result = complex3({ inputs: { real: floatX, imag: zerosTensor }, backend: backend2 });
      zerosTensor.dispose();
      backend2.disposeIntermediateTensorInfo(floatX);
      return result;
    }
    if (x.dtype === "complex64") {
      const realPart = real3({ inputs: { input: x }, backend: backend2 });
      const result = cast4({ inputs: { x: realPart }, backend: backend2, attrs: { dtype } });
      backend2.disposeIntermediateTensorInfo(realPart);
      return result;
    }
    if (!util_exports.hasEncodingLoss(x.dtype, dtype)) {
      const result = identity2({ inputs: { x }, backend: backend2 });
      return { dataId: result.dataId, shape: result.shape, dtype };
    }
    if (dtype === "int32") {
      return int(x, backend2);
    }
    if (dtype === "bool") {
      const zerosTensorInfo = backend2.makeTensorInfo([], "bool", util_exports.getTypedArrayFromDType("bool", 1));
      const binaryInputs = { a: x, b: zerosTensorInfo };
      const result = notEqual3({ inputs: binaryInputs, backend: backend2 });
      backend2.disposeIntermediateTensorInfo(zerosTensorInfo);
      return result;
    }
    throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);
  }
  var castConfig2 = {
    kernelName: Cast,
    backendName: "webgl",
    kernelFunc: cast4
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Ceil.js
  var CEIL = `return ceil(x);`;
  var ceil3 = unaryKernelFunc2({ opSnippet: CEIL, packedOpSnippet: CEIL, cpuKernelImpl: ceilImplCPU });
  var ceilConfig2 = {
    kernelName: Ceil,
    backendName: "webgl",
    kernelFunc: ceil3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/clip_gpu.js
  var ClipProgram = class {
    constructor(aShape) {
      this.variableNames = ["A"];
      this.customUniforms = [
        { name: "minVal", type: "float" },
        { name: "maxVal", type: "float" }
      ];
      this.outputShape = aShape;
      this.userCode = `

      void main() {
        float value = getAAtOutCoords();
        if (isnan(value)) {
          setOutput(value);
          return;
        }

        setOutput(clamp(value, minVal, maxVal));
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/clip_packed_gpu.js
  var ClipPackedProgram = class {
    constructor(aShape) {
      this.variableNames = ["A"];
      this.packedInputs = true;
      this.packedOutput = true;
      this.customUniforms = [
        { name: "minVal", type: "float" },
        { name: "maxVal", type: "float" }
      ];
      this.outputShape = aShape;
      this.userCode = `
      void main() {
        vec4 value = getAAtOutCoords();

        if (any(isnan(value))) {
          setOutput(value);
          return;
        }

        setOutput(clamp(value, vec4(minVal), vec4(maxVal)));
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ClipByValue.js
  function clipByValue2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { clipValueMin, clipValueMax } = attrs;
    let program;
    if (env().getBool("WEBGL_PACK_CLIP")) {
      program = new ClipPackedProgram(x.shape);
    } else {
      program = new ClipProgram(x.shape);
    }
    const customValues = [[clipValueMin], [clipValueMax]];
    return backend2.runWebGLProgram(program, [x], x.dtype, customValues);
  }
  var clipByValueConfig = {
    kernelName: ClipByValue,
    backendName: "webgl",
    kernelFunc: clipByValue2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/complex_abs_gpu.js
  var ComplexAbsProgram = class {
    constructor(shape) {
      this.variableNames = ["real", "imag"];
      this.outputShape = shape;
      this.userCode = `
      void main() {
        float re = abs(getRealAtOutCoords());
        float im = abs(getImagAtOutCoords());
        float mx = max(re, im);

        // sadly the length function in glsl is not underflow-safe
        // (at least not on Intel GPUs). So the safe solution is
        // to ensure underflow-safety in all cases.
        setOutput(
          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))
        );
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ComplexAbs.js
  function makeComplexComponentTensorInfo(complexTensor, complexPart) {
    return {
      dataId: complexPart.dataId,
      dtype: complexPart.dtype,
      shape: complexTensor.shape
    };
  }
  function complexAbs2(args) {
    const { inputs, backend: backend2 } = args;
    const { x } = inputs;
    const xData = backend2.texData.get(x.dataId);
    const program = new ComplexAbsProgram(x.shape);
    const programInputs = [
      makeComplexComponentTensorInfo(x, xData.complexTensorInfos.real),
      makeComplexComponentTensorInfo(x, xData.complexTensorInfos.imag)
    ];
    return backend2.runWebGLProgram(program, programInputs, programInputs[0].dtype);
  }
  var complexAbsConfig2 = {
    kernelName: ComplexAbs,
    backendName: "webgl",
    kernelFunc: complexAbs2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/concat_gpu.js
  var ConcatProgram = class {
    constructor(shapes) {
      this.outputShape = [];
      this.outputShape = backend_util_exports.computeOutShape(shapes, 1);
      this.variableNames = shapes.map((_, i) => `T${i}`);
      const offsets = new Array(shapes.length - 1);
      offsets[0] = shapes[0][1];
      for (let i = 1; i < offsets.length; i++) {
        offsets[i] = offsets[i - 1] + shapes[i][1];
      }
      const snippets = [`if (yC < ${offsets[0]}) setOutput(getT0(yR, yC));`];
      for (let i = 1; i < offsets.length; i++) {
        const shift = offsets[i - 1];
        snippets.push(`else if (yC < ${offsets[i]}) setOutput(getT${i}(yR, yC-${shift}));`);
      }
      const lastIndex = offsets.length;
      const lastShift = offsets[offsets.length - 1];
      snippets.push(`else setOutput(getT${lastIndex}(yR, yC-${lastShift}));`);
      this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int yR = coords.x;
        int yC = coords.y;

        ${snippets.join("\n        ")}
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/concat_packed_gpu.js
  var ConcatPackedProgram = class {
    constructor(shapes, axis) {
      this.packedInputs = true;
      this.packedOutput = true;
      this.outputShape = [];
      this.outputShape = backend_util_exports.computeOutShape(shapes, axis);
      const shape = this.outputShape;
      const rank = shape.length;
      const dtype = getCoordsDataType(rank);
      const coords2 = getChannels("coords", rank);
      const channels = ["x", "y", "z", "w", "u", "v"].slice(0, rank);
      this.variableNames = shapes.map((_, i) => `T${i}`);
      const offsets = new Array(shapes.length - 1);
      offsets[0] = shapes[0][axis];
      for (let i = 1; i < offsets.length; i++) {
        offsets[i] = offsets[i - 1] + shapes[i][axis];
      }
      const channel = channels[axis];
      const lastChannels = channels.slice(-2);
      const allChannels = channels.join();
      let getValueSnippet = `if (${channel} < ${offsets[0]}) {
        return getChannel(
            getT0(${allChannels}), vec2(${lastChannels.join()}));
        }`;
      for (let i = 1; i < offsets.length; i++) {
        const shift2 = offsets[i - 1];
        getValueSnippet += `
        if (${channel} < ${offsets[i]}  && ${channel} >= ${offsets[i - 1]}) {
          return getChannel(
            getT${i}(${shiftedChannels(channels, channel, shift2)}),
            vec2(${shiftedChannels(lastChannels, channel, shift2)}));
        }`;
      }
      const lastIndex = offsets.length;
      const shift = offsets[offsets.length - 1];
      getValueSnippet += `
        return getChannel(
          getT${lastIndex}(${shiftedChannels(channels, channel, shift)}),
          vec2(${shiftedChannels(lastChannels, channel, shift)}));`;
      this.userCode = `
      float getValue(${channels.map((x) => "int " + x)}) {
        ${getValueSnippet}
      }

      void main() {
        ${dtype} coords = getOutputCoords();
        vec4 result = vec4(getValue(${coords2}), 0., 0., 0.);

        ${coords2[rank - 1]} = ${coords2[rank - 1]} + 1;
        if (${coords2[rank - 1]} < ${shape[rank - 1]}) {
          result.g = getValue(${coords2});
        }

        ${coords2[rank - 2]} = ${coords2[rank - 2]} + 1;
        if (${coords2[rank - 2]} < ${shape[rank - 2]}) {
          result.a = getValue(${coords2});
        }

        ${coords2[rank - 1]} = ${coords2[rank - 1]} - 1;
        if (${coords2[rank - 2]} < ${shape[rank - 2]} &&
            ${coords2[rank - 1]} < ${shape[rank - 1]}) {
          result.b = getValue(${coords2});
        }
        setOutput(result);
      }
    `;
    }
  };
  function shiftedChannels(channels, channel, shift) {
    const channelIdx = channels.indexOf(channel);
    const res = channels.map((c, idx) => {
      if (idx === channelIdx) {
        return `${c} - ${shift}`;
      } else {
        return c;
      }
    });
    return res.join();
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Imag.js
  function imag3(args) {
    const { inputs, backend: backend2 } = args;
    const { input: input2 } = inputs;
    const inputData = backend2.texData.get(input2.dataId);
    return identity2({ inputs: { x: inputData.complexTensorInfos.imag }, backend: backend2 });
  }
  var imagConfig2 = {
    kernelName: Imag,
    backendName: "webgl",
    kernelFunc: imag3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Concat_impl.js
  function concatImpl2(inputs, axis, backend2) {
    const dtype = inputs[0].dtype;
    if (dtype === "complex64") {
      const reals = inputs.map((t) => real3({ inputs: { input: t }, backend: backend2 }));
      const imags = inputs.map((t) => imag3({ inputs: { input: t }, backend: backend2 }));
      const realConcated = concatImpl2(reals, axis, backend2);
      const imagConcated = concatImpl2(imags, axis, backend2);
      const result2 = complex3({ inputs: { real: realConcated, imag: imagConcated }, backend: backend2 });
      reals.forEach((r) => backend2.disposeIntermediateTensorInfo(r));
      imags.forEach((i) => backend2.disposeIntermediateTensorInfo(i));
      backend2.disposeIntermediateTensorInfo(realConcated);
      backend2.disposeIntermediateTensorInfo(imagConcated);
      return result2;
    }
    let runOnCpu = backend2.shouldExecuteOnCPU(inputs);
    if (dtype === "string") {
      runOnCpu = true;
    }
    if (runOnCpu) {
      const tensors2D2 = inputs.map((t) => {
        const innerSize = util_exports.sizeFromShape(t.shape.slice(axis));
        const shape = [-1, innerSize];
        return reshape3({ inputs: { x: t }, backend: backend2, attrs: { shape } });
      });
      const inputsValShapes = tensors2D2.map((t) => {
        return { vals: backend2.readSync(t.dataId), shape: t.shape };
      });
      const outShape2 = backend_util_exports.computeOutShape(tensors2D2.map((t) => t.shape), 1);
      const simplyConcat = tensors2D2[0].shape[0] === 1;
      const outVals = concatImplCPU(inputsValShapes, outShape2, dtype, simplyConcat);
      const finalOutShape = backend_util_exports.computeOutShape(inputs.map((t) => t.shape), axis);
      const outInfo = backend2.makeTensorInfo(finalOutShape, dtype, outVals);
      tensors2D2.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
      return outInfo;
    }
    if (inputs.length > env().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER")) {
      const midIndex = Math.floor(inputs.length / 2);
      const leftSide = concatImpl2(inputs.slice(0, midIndex), axis, backend2);
      const rightSide = concatImpl2(inputs.slice(midIndex), axis, backend2);
      const result2 = concatImpl2([leftSide, rightSide], axis, backend2);
      backend2.disposeIntermediateTensorInfo(leftSide);
      backend2.disposeIntermediateTensorInfo(rightSide);
      return result2;
    }
    if (env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") && inputs[0].shape.length > 1) {
      const program2 = new ConcatPackedProgram(inputs.map((t) => t.shape), axis);
      return backend2.runWebGLProgram(program2, inputs, dtype);
    }
    const { tensors2D, outShape } = computeTensors2D(inputs, axis, backend2);
    const program = new ConcatProgram(tensors2D.map((t) => t.shape));
    const result = backend2.runWebGLProgram(program, tensors2D, dtype);
    tensors2D.forEach((r) => backend2.disposeIntermediateTensorInfo(r));
    const reshapedResult = reshape3({ inputs: { x: result }, attrs: { shape: outShape }, backend: backend2 });
    backend2.disposeIntermediateTensorInfo(result);
    return reshapedResult;
  }
  function computeTensors2D(inputs, axis, backend2) {
    const outShape = backend_util_exports.computeOutShape(inputs.map((t) => t.shape), axis);
    const tensors2D = inputs.map((x) => reshape3({
      inputs: { x },
      attrs: { shape: [-1, util_exports.sizeFromShape(x.shape.slice(axis))] },
      backend: backend2
    }));
    return { tensors2D, outShape };
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Concat.js
  function concat3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { axis } = attrs;
    const $axis = util_exports.parseAxisParam(axis, inputs[0].shape)[0];
    const outShape = backend_util_exports.computeOutShape(inputs.map((t) => t.shape), $axis);
    if (util_exports.sizeFromShape(outShape) === 0) {
      return backend2.makeTensorInfo(outShape, inputs[0].dtype, []);
    }
    const $inputs = inputs.filter((t) => util_exports.sizeFromShape(t.shape) > 0);
    if ($inputs.length === 1) {
      return identity2({ inputs: { x: $inputs[0] }, backend: backend2 });
    }
    const shapes = $inputs.map((t) => t.shape);
    backend_util_exports.assertParamsConsistent(shapes, $axis);
    return concatImpl2($inputs, $axis, backend2);
  }
  var concatConfig2 = {
    kernelName: Concat,
    backendName: "webgl",
    kernelFunc: concat3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/conv_gpu.js
  var Conv2DProgram = class {
    constructor(convInfo, addBias = false, activation = null, hasPreluActivationWeights = false, hasLeakyreluAlpha = false) {
      this.variableNames = ["x", "W"];
      this.outputShape = convInfo.outShape;
      const padTop = convInfo.padInfo.top;
      const padLeft = convInfo.padInfo.left;
      const strideHeight = convInfo.strideHeight;
      const strideWidth = convInfo.strideWidth;
      const dilationHeight = convInfo.dilationHeight;
      const dilationWidth = convInfo.dilationWidth;
      const filterHeight = convInfo.filterHeight;
      const filterWidth = convInfo.filterWidth;
      const inputDepthNearestVec4 = Math.floor(convInfo.inChannels / 4) * 4;
      const inputDepthVec4Remainder = convInfo.inChannels % 4;
      const isChannelsLast = convInfo.dataFormat === "channelsLast";
      const rowDim = isChannelsLast ? 1 : 2;
      const colDim = isChannelsLast ? 2 : 3;
      const channelDim = isChannelsLast ? 3 : 1;
      let activationSnippet = "", applyActivationSnippet = "";
      if (activation) {
        if (hasPreluActivationWeights) {
          activationSnippet = `float activation(float a) {
          float b = getPreluActivationWeightsAtOutCoords();
          ${activation}
        }`;
        } else if (hasLeakyreluAlpha) {
          activationSnippet = `float activation(float a) {
          float b = getLeakyreluAlphaAtOutCoords();
          ${activation}
        }`;
        } else {
          activationSnippet = `
          float activation(float x) {
            ${activation}
          }
        `;
        }
        applyActivationSnippet = `result = activation(result);`;
      }
      const addBiasSnippet = addBias ? "result += getBiasAtOutCoords();" : "";
      if (addBias) {
        this.variableNames.push("bias");
      }
      if (hasPreluActivationWeights) {
        this.variableNames.push("preluActivationWeights");
      }
      if (hasLeakyreluAlpha) {
        this.variableNames.push("leakyreluAlpha");
      }
      this.userCode = `
      ${activationSnippet}

      const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});
      const ivec2 pads = ivec2(${padTop}, ${padLeft});

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d2 = coords[${channelDim}];

        ivec2 xRCCorner =
            ivec2(coords[${rowDim}], coords[${colDim}]) * strides - pads;
        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${filterHeight}; wR++) {
          int xR = xRCorner + wR * ${dilationHeight};

          if (xR < 0 || xR >= ${convInfo.inHeight}) {
            continue;
          }

          for (int wC = 0; wC < ${filterWidth}; wC++) {
            int xC = xCCorner + wC * ${dilationWidth};

            if (xC < 0 || xC >= ${convInfo.inWidth}) {
              continue;
            }

            for (int d1 = 0; d1 < ${inputDepthNearestVec4}; d1 += 4) {
              vec4 wValues = vec4(
                getW(wR, wC, d1, d2),
                getW(wR, wC, d1 + 1, d2),
                getW(wR, wC, d1 + 2, d2),
                getW(wR, wC, d1 + 3, d2)
              );

              if (${isChannelsLast}) {
                vec4 xValues = vec4(
                  getX(batch, xR, xC, d1),
                  getX(batch, xR, xC, d1 + 1),
                  getX(batch, xR, xC, d1 + 2),
                  getX(batch, xR, xC, d1 + 3)
                );
                dotProd += dot(xValues, wValues);
              } else {
                vec4 xValues = vec4(
                  getX(batch, d1, xR, xC),
                  getX(batch, d1 + 1, xR, xC),
                  getX(batch, d1 + 2, xR, xC),
                  getX(batch, d1 + 3, xR, xC)
                );
                dotProd += dot(xValues, wValues);
              }
            }

            if (${inputDepthVec4Remainder === 1}) {

              if (${isChannelsLast}) {
                dotProd +=
                    getX(batch, xR, xC, ${inputDepthNearestVec4}) *
                    getW(wR, wC, ${inputDepthNearestVec4}, d2);
              } else {
                dotProd +=
                    getX(batch, ${inputDepthNearestVec4}, xR, xC) *
                    getW(wR, wC, ${inputDepthNearestVec4}, d2);
              }

            } else if (${inputDepthVec4Remainder === 2}) {
              vec2 wValues = vec2(
                getW(wR, wC, ${inputDepthNearestVec4}, d2),
                getW(wR, wC, ${inputDepthNearestVec4} + 1, d2)
              );

              if (${isChannelsLast}) {
                vec2 xValues = vec2(
                  getX(batch, xR, xC, ${inputDepthNearestVec4}),
                  getX(batch, xR, xC, ${inputDepthNearestVec4} + 1)
                );
                dotProd += dot(xValues, wValues);
              } else {
                vec2 xValues = vec2(
                  getX(batch, ${inputDepthNearestVec4}, xR, xC),
                  getX(batch, ${inputDepthNearestVec4} + 1, xR, xC)
                );
                dotProd += dot(xValues, wValues);
              }

            } else if (${inputDepthVec4Remainder === 3}) {
              vec3 wValues = vec3(
                getW(wR, wC, ${inputDepthNearestVec4}, d2),
                getW(wR, wC, ${inputDepthNearestVec4} + 1, d2),
                getW(wR, wC, ${inputDepthNearestVec4} + 2, d2)
              );

              if (${isChannelsLast}) {
                vec3 xValues = vec3(
                  getX(batch, xR, xC, ${inputDepthNearestVec4}),
                  getX(batch, xR, xC, ${inputDepthNearestVec4} + 1),
                  getX(batch, xR, xC, ${inputDepthNearestVec4} + 2)
                );
                dotProd += dot(xValues, wValues);
              } else {
                vec3 xValues = vec3(
                  getX(batch, ${inputDepthNearestVec4}, xR, xC),
                  getX(batch, ${inputDepthNearestVec4} + 1, xR, xC),
                  getX(batch, ${inputDepthNearestVec4} + 2, xR, xC)
                );
                dotProd += dot(xValues, wValues);
              }

            }
          }
        }

        float result = dotProd;
        ${addBiasSnippet}
        ${applyActivationSnippet}
        setOutput(result);
      }
    `;
    }
  };
  var Conv3DProgram = class {
    constructor(convInfo) {
      this.variableNames = ["x", "W"];
      this.outputShape = convInfo.outShape;
      const padFront = convInfo.padInfo.front;
      const padTop = convInfo.padInfo.top;
      const padLeft = convInfo.padInfo.left;
      const strideDepth = convInfo.strideDepth;
      const strideHeight = convInfo.strideHeight;
      const strideWidth = convInfo.strideWidth;
      const dilationDepth = convInfo.dilationDepth;
      const dilationHeight = convInfo.dilationHeight;
      const dilationWidth = convInfo.dilationWidth;
      const filterDepth = convInfo.filterDepth;
      const filterHeight = convInfo.filterHeight;
      const filterWidth = convInfo.filterWidth;
      const inputDepthNearestVec4 = Math.floor(convInfo.inChannels / 4) * 4;
      const inputDepthVec4Remainder = convInfo.inChannels % 4;
      this.userCode = `
      const ivec3 strides = ivec3(${strideDepth}, ${strideHeight}, ${strideWidth});
      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int d2 = coords.u;

        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;
        int xFCorner = xFRCCorner.x;
        int xRCorner = xFRCCorner.y;
        int xCCorner = xFRCCorner.z;

        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get
        // y(yF, yR, yC, d2). ? = to be determined. : = across all
        // values in that axis.
        float dotProd = 0.0;
        for (int wF = 0; wF < ${filterDepth}; wF++) {
          int xF = xFCorner + wF * ${dilationDepth};

          if (xF < 0 || xF >= ${convInfo.inDepth}) {
            continue;
          }

          for (int wR = 0; wR < ${filterHeight}; wR++) {
            int xR = xRCorner + wR * ${dilationHeight};

            if (xR < 0 || xR >= ${convInfo.inHeight}) {
              continue;
            }

            for (int wC = 0; wC < ${filterWidth}; wC++) {
              int xC = xCCorner + wC * ${dilationWidth};

              if (xC < 0 || xC >= ${convInfo.inWidth}) {
                continue;
              }

              for (int d1 = 0; d1 < ${inputDepthNearestVec4}; d1 += 4) {
                vec4 xValues = vec4(
                  getX(batch, xF, xR, xC, d1),
                  getX(batch, xF, xR, xC, d1 + 1),
                  getX(batch, xF, xR, xC, d1 + 2),
                  getX(batch, xF, xR, xC, d1 + 3)
                );
                vec4 wValues = vec4(
                  getW(wF, wR, wC, d1, d2),
                  getW(wF, wR, wC, d1 + 1, d2),
                  getW(wF, wR, wC, d1 + 2, d2),
                  getW(wF, wR, wC, d1 + 3, d2)
                );

                dotProd += dot(xValues, wValues);
              }

              if (${inputDepthVec4Remainder === 1}) {
                dotProd +=
                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4}) *
                  getW(wF, wR, wC, ${inputDepthNearestVec4}, d2);
              } else if (${inputDepthVec4Remainder === 2}) {
                vec2 xValues = vec2(
                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4}),
                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4} + 1)
                );
                vec2 wValues = vec2(
                  getW(wF, wR, wC, ${inputDepthNearestVec4}, d2),
                  getW(wF, wR, wC, ${inputDepthNearestVec4} + 1, d2)
                );
                dotProd += dot(xValues, wValues);
              } else if (${inputDepthVec4Remainder === 3}) {
                vec3 xValues = vec3(
                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4}),
                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4} + 1),
                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4} + 2)
                );
                vec3 wValues = vec3(
                  getW(wF, wR, wC, ${inputDepthNearestVec4}, d2),
                  getW(wF, wR, wC, ${inputDepthNearestVec4} + 1, d2),
                  getW(wF, wR, wC, ${inputDepthNearestVec4} + 2, d2)
                );
                dotProd += dot(xValues, wValues);
              }
            }
          }
        }
        setOutput(dotProd);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/im2col_packed_gpu.js
  var Im2ColPackedProgram = class {
    constructor(outputShape, convInfo) {
      this.variableNames = ["A"];
      this.packedInputs = true;
      this.packedOutput = true;
      this.customUniforms = [
        { name: "inputShape", type: "ivec3" },
        { name: "pad", type: "ivec2" },
        { name: "stride", type: "ivec2" },
        { name: "dilation", type: "ivec2" },
        { name: "inChannels", type: "int" },
        { name: "itemsPerBlockRow", type: "int" },
        { name: "outWidth", type: "int" }
      ];
      this.outputShape = outputShape;
      this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
      const { dataFormat } = convInfo;
      const glsl = getGlslDifferences();
      const isChannelsLast = dataFormat === "channelsLast";
      const rowDim = isChannelsLast ? 0 : 1;
      const colDim = isChannelsLast ? 1 : 2;
      const boundsCheckingSnippet = this.enableShapeUniforms ? "if(blockIndex < outShape[1] && pos < outShape[0]) {" : `if(blockIndex < ${outputShape[1]} && pos < ${outputShape[0]}) {`;
      let unrolled = ``;
      for (let row = 0; row <= 1; row++) {
        for (let col = 0; col <= 1; col++) {
          unrolled += `
          blockIndex = rc.y + ${col};
          pos = rc.x + ${row};

          ${boundsCheckingSnippet}
            offsetY = int(blockIndex / outWidth) * stride[0] - pad[0];
            d0 = offsetY + dilation[0] * (pos / itemsPerBlockRow);

            if(d0 < inputShape[${rowDim}] && d0 >= 0) {
              // Use custom imod instead mod. On Intel GPU, mod may generate
              // unexpected value.
              // https://github.com/tensorflow/tfjs/issues/5447
              offsetX = imod(blockIndex, outWidth) * stride[1] - pad[1];
              d1 = offsetX + dilation[1] * (imod(pos, itemsPerBlockRow) /
                  inChannels);

              if(d1 < inputShape[${colDim}] && d1 >= 0) {

                ch = imod(pos, inChannels);

                if (${isChannelsLast}) {
                  innerDims = vec2(d1, ch);
                  result[${row * 2 + col}] = getChannel(
                    getA(d0, int(innerDims.x),
                    int(innerDims.y)), innerDims);
                } else {
                  innerDims = vec2(d0, d1);
                  result[${row * 2 + col}] = getChannel(
                    getA(ch, int(innerDims.x),
                    int(innerDims.y)), innerDims);
                }
              }
            }
          }
        `;
        }
      }
      this.userCode = `
      void main() {
        ivec2 rc = getOutputCoords();

        vec4 result = vec4(0);

        int blockIndex, pos, offsetY, d0, offsetX, d1, ch;
        vec2 innerDims;

        ${unrolled}

        ${glsl.output} = result;
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Conv2D_impl.js
  function conv2dByMatMul({ x, filter, convInfo, backend: backend2, bias = null, preluActivationWeights = null, leakyreluAlpha = 0, activation = null }) {
    const xShape = x.shape;
    const xTexData = backend2.texData.get(x.dataId);
    const sharedMatMulDim = convInfo.inChannels;
    const outerShapeX = xShape[0] * xShape[1] * xShape[2];
    const outerShapeFilter = convInfo.outChannels;
    const isChannelsLast = convInfo.dataFormat === "channelsLast";
    const transposeA = false;
    const transposeB = false;
    let out;
    const intermediates = [];
    const batchMatMulWillBeUnpacked = (outerShapeX === 1 || outerShapeFilter === 1) && sharedMatMulDim > MATMUL_SHARED_DIM_THRESHOLD;
    const canOptimize = !batchMatMulWillBeUnpacked && xTexData.isPacked && isChannelsLast && xTexData.texture != null && xShape[2] % 2 !== 0 && util_exports.arraysEqual(xTexData.shape.slice(-3), xShape.slice(-3));
    if (canOptimize) {
      const targetShape = xShape[0] * xShape[1] * (xShape[2] + 1);
      const xReshaped = {
        dataId: x.dataId,
        shape: [1, targetShape, convInfo.inChannels],
        dtype: x.dtype
      };
      const originalXTexDataShape = xTexData.shape;
      xTexData.shape = xTexData.shape.slice();
      xTexData.shape[xTexData.shape.length - 2]++;
      util_exports.assert(isReshapeFree(xTexData.shape, xReshaped.shape), () => `packed reshape ${xTexData.shape} to ${xReshaped.shape} isn't free`);
      const filterReshaped = reshape3({
        inputs: { x: filter },
        backend: backend2,
        attrs: { shape: [1, convInfo.inChannels, convInfo.outChannels] }
      });
      intermediates.push(filterReshaped);
      const pointwiseConv = batchMatMulImpl({
        a: xReshaped,
        b: filterReshaped,
        backend: backend2,
        transposeA,
        transposeB,
        bias,
        activation,
        preluActivationWeights,
        leakyreluAlpha
      });
      const pointwiseConvTexData = backend2.texData.get(pointwiseConv.dataId);
      util_exports.assert(pointwiseConvTexData.isPacked, () => "batchMatMul result is expected to be packed");
      xTexData.shape = originalXTexDataShape;
      pointwiseConvTexData.shape = convInfo.outShape;
      out = identity2({ inputs: { x: pointwiseConv }, backend: backend2 });
      out.shape = convInfo.outShape;
      intermediates.push(pointwiseConv);
    } else {
      const targetShape = isChannelsLast ? xShape[0] * xShape[1] * xShape[2] : xShape[0] * xShape[2] * xShape[3];
      const xReshaped = reshape3({
        inputs: { x },
        backend: backend2,
        attrs: { shape: [1, targetShape, convInfo.inChannels] }
      });
      const filterReshaped = reshape3({
        inputs: { x: filter },
        backend: backend2,
        attrs: { shape: [1, convInfo.inChannels, convInfo.outChannels] }
      });
      const result = batchMatMulImpl({
        a: xReshaped,
        b: filterReshaped,
        transposeA,
        transposeB,
        backend: backend2,
        bias,
        activation,
        preluActivationWeights,
        leakyreluAlpha
      });
      out = reshape3({ inputs: { x: result }, backend: backend2, attrs: { shape: convInfo.outShape } });
      intermediates.push(xReshaped);
      intermediates.push(filterReshaped);
      intermediates.push(result);
    }
    for (const i of intermediates) {
      backend2.disposeIntermediateTensorInfo(i);
    }
    return out;
  }
  function conv2dWithIm2Row({ x, filter, convInfo, backend: backend2, bias = null, preluActivationWeights = null, leakyreluAlpha = 0, activation = null }) {
    const { filterWidth, filterHeight, inChannels, outWidth, outHeight, dataFormat } = convInfo;
    const isChannelsLast = dataFormat === "channelsLast";
    const sharedDim = filterWidth * filterHeight * inChannels;
    const numCols = outHeight * outWidth;
    const x2ColShape = [sharedDim, numCols];
    const transposeA = true;
    const transposeB = false;
    const intermediates = [];
    const xSqueezed = reshape3({ inputs: { x }, backend: backend2, attrs: { shape: x.shape.slice(1) } });
    const w2Row = reshape3({
      inputs: { x: filter },
      backend: backend2,
      attrs: { shape: [1, sharedDim, util_exports.sizeFromShape(filter.shape) / sharedDim] }
    });
    intermediates.push(xSqueezed);
    intermediates.push(w2Row);
    const im2ColProgram = new Im2ColPackedProgram(x2ColShape, convInfo);
    const customValues = [
      xSqueezed.shape,
      [convInfo.padInfo.top, convInfo.padInfo.left],
      [convInfo.strideHeight, convInfo.strideWidth],
      [convInfo.dilationHeight, convInfo.dilationWidth],
      [convInfo.inChannels],
      [convInfo.filterWidth * convInfo.inChannels],
      [convInfo.outWidth]
    ];
    const im2Col = backend2.runWebGLProgram(im2ColProgram, [xSqueezed], "float32", customValues);
    const im2ColReshaped = reshape3({
      inputs: { x: im2Col },
      backend: backend2,
      attrs: { shape: [1, x2ColShape[0], x2ColShape[1]] }
    });
    intermediates.push(im2Col);
    intermediates.push(im2ColReshaped);
    const hasBias = bias != null;
    const hasPreluActivationWeights = preluActivationWeights != null;
    const hasLeakyreluAlpha = activation === "leakyrelu";
    const fusedActivation = activation ? mapActivationToShaderProgram(activation, true) : null;
    const matmulProgram = new MatMulPackedProgram(im2ColReshaped.shape, w2Row.shape, [1, numCols, convInfo.outChannels], transposeA, transposeB, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
    const inputs = [im2ColReshaped, w2Row];
    if (bias) {
      inputs.push(bias);
    }
    if (hasPreluActivationWeights) {
      inputs.push(preluActivationWeights);
    }
    if (hasLeakyreluAlpha) {
      const $leakyreluAlpha = backend2.makeTensorInfo([], "float32", util_exports.createScalarValue(leakyreluAlpha, "float32"));
      inputs.push($leakyreluAlpha);
      intermediates.push($leakyreluAlpha);
    }
    const product = backend2.runWebGLProgram(matmulProgram, inputs, "float32");
    const outShape = isChannelsLast ? [1, outHeight, outWidth, convInfo.outChannels] : [1, convInfo.outChannels, outHeight, outWidth];
    const out = reshape3({ inputs: { x: product }, backend: backend2, attrs: { shape: outShape } });
    intermediates.push(product);
    for (const i of intermediates) {
      backend2.disposeIntermediateTensorInfo(i);
    }
    return out;
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Conv2D.js
  function conv2d3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, filter } = inputs;
    const { strides, pad: pad2, dataFormat, dilations, dimRoundingMode } = attrs;
    const $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
    const convInfo = backend_util_exports.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad2, dimRoundingMode, false, $dataFormat);
    let out;
    if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 && convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 && convInfo.strideHeight === 1 && convInfo.strideWidth === 1 && (convInfo.padInfo.type === "SAME" || convInfo.padInfo.type === "VALID")) {
      out = conv2dByMatMul({ x, filter, convInfo, backend: backend2 });
    } else if (env().getBool("WEBGL_CONV_IM2COL") && x.shape[0] === 1) {
      out = conv2dWithIm2Row({ x, filter, convInfo, backend: backend2 });
    } else {
      const program = new Conv2DProgram(convInfo);
      out = backend2.runWebGLProgram(program, [x, filter], "float32");
    }
    const outReshaped = reshape3({ inputs: { x: out }, backend: backend2, attrs: { shape: convInfo.outShape } });
    backend2.disposeIntermediateTensorInfo(out);
    return outReshaped;
  }
  var conv2DConfig2 = {
    kernelName: Conv2D,
    backendName: "webgl",
    kernelFunc: conv2d3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/conv_backprop_gpu.js
  var Conv2DDerFilterProgram = class {
    constructor(convInfo) {
      this.variableNames = ["x", "dy"];
      this.outputShape = convInfo.filterShape;
      const strideHeight = convInfo.strideHeight;
      const strideWidth = convInfo.strideWidth;
      const padTop = convInfo.padInfo.top;
      const padLeft = convInfo.padInfo.left;
      const isChannelsLast = convInfo.dataFormat === "channelsLast";
      this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int wR = coords.x;
        int wC = coords.y;
        int d1 = coords.z;
        int d2 = coords.w;

        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;

        for (int b = 0; b < ${convInfo.batchSize}; b++) {
          for (int yR = 0; yR < ${convInfo.outHeight}; yR++) {
            int xR = wR + yR * ${strideHeight} - ${padTop};

            if (xR < 0 || xR >= ${convInfo.inHeight}) {
              continue;
            }

            for (int yC = 0; yC < ${convInfo.outWidth}; yC++) {
              int xC = wC + yC * ${strideWidth} - ${padLeft};

              if (xC < 0 || xC >= ${convInfo.inWidth}) {
                continue;
              }

              if (${isChannelsLast}) {
                float dyValue = getDy(b, yR, yC, d2);
                float xValue = getX(b, xR, xC, d1);
                dotProd += (xValue * dyValue);
              } else {
                float dyValue = getDy(b, d2, yR, yC);
                float xValue = getX(b, d1, xR, xC);
                dotProd += (xValue * dyValue);
              }

            }
          }
        }
        setOutput(dotProd);
      }
    `;
    }
  };
  var Conv2DDerInputProgram = class {
    constructor(convInfo) {
      this.variableNames = ["dy", "W"];
      this.outputShape = convInfo.inShape;
      const filterHeight = convInfo.filterHeight;
      const filterWidth = convInfo.filterWidth;
      const strideHeight = convInfo.strideHeight;
      const strideWidth = convInfo.strideWidth;
      const isChannelsLast = convInfo.dataFormat === "channelsLast";
      const padTop = filterHeight - 1 - convInfo.padInfo.top;
      const padLeft = filterWidth - 1 - convInfo.padInfo.left;
      const rowDim = isChannelsLast ? 1 : 2;
      const colDim = isChannelsLast ? 2 : 3;
      const channelDim = isChannelsLast ? 3 : 1;
      this.userCode = `
      const ivec2 pads = ivec2(${padTop}, ${padLeft});

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d1 = coords[${channelDim}];

        ivec2 dyCorner = ivec2(coords[${rowDim}], coords[${colDim}]) - pads;
        int dyRCorner = dyCorner.x;
        int dyCCorner = dyCorner.y;

        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${filterHeight}; wR++) {
          float dyR = float(dyRCorner + wR) / ${strideHeight}.0;

          if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          int wRPerm = ${filterHeight} - 1 - wR;

          for (int wC = 0; wC < ${filterWidth}; wC++) {
            float dyC = float(dyCCorner + wC) / ${strideWidth}.0;

            if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            int wCPerm = ${filterWidth} - 1 - wC;

            for (int d2 = 0; d2 < ${convInfo.outChannels}; d2++) {

              if (${isChannelsLast}) {
                float xValue = getDy(batch, idyR, idyC, d2);
                float wValue = getW(wRPerm, wCPerm, d1, d2);
                dotProd += xValue * wValue;
              } else {
                float xValue = getDy(batch, d2, idyR, idyC);
                float wValue = getW(wRPerm, wCPerm, d1, d2);
                dotProd += xValue * wValue;
              }

            }
          }
        }
        setOutput(dotProd);
      }
    `;
    }
  };
  var Conv3DDerFilterProgram = class {
    constructor(convInfo) {
      this.variableNames = ["x", "dy"];
      this.outputShape = convInfo.filterShape;
      const strideDepth = convInfo.strideDepth;
      const strideHeight = convInfo.strideHeight;
      const strideWidth = convInfo.strideWidth;
      const padFront = convInfo.padInfo.front;
      const padTop = convInfo.padInfo.top;
      const padLeft = convInfo.padInfo.left;
      this.userCode = `
      void main() {
        ivec5 coords = getOutputCoords();
        int wF = coords.x;
        int wR = coords.y;
        int wC = coords.z;
        int d1 = coords.w;
        int d2 = coords.u;

        float dotProd = 0.0;

        for (int b = 0; b < ${convInfo.batchSize}; b++) {
          for (int yF = 0; yF < ${convInfo.outDepth}; yF++) {
            int xF = wF + yF * ${strideDepth} - ${padFront};

            if (xF < 0 || xF >= ${convInfo.inDepth}) {
              continue;
            }

            for (int yR = 0; yR < ${convInfo.outHeight}; yR++) {
              int xR = wR + yR * ${strideHeight} - ${padTop};

              if (xR < 0 || xR >= ${convInfo.inHeight}) {
                continue;
              }

              for (int yC = 0; yC < ${convInfo.outWidth}; yC++) {
                int xC = wC + yC * ${strideWidth} - ${padLeft};

                if (xC < 0 || xC >= ${convInfo.inWidth}) {
                  continue;
                }

                float dyValue = getDy(b, yF, yR, yC, d2);
                float xValue = getX(b, xF, xR, xC, d1);
                dotProd += (xValue * dyValue);
              }
            }
          }
        }
        setOutput(dotProd);
      }
    `;
    }
  };
  var Conv3DDerInputProgram = class {
    constructor(convInfo) {
      this.variableNames = ["dy", "W"];
      this.outputShape = convInfo.inShape;
      const filterDepth = convInfo.filterDepth;
      const filterHeight = convInfo.filterHeight;
      const filterWidth = convInfo.filterWidth;
      const strideDepth = convInfo.strideDepth;
      const strideHeight = convInfo.strideHeight;
      const strideWidth = convInfo.strideWidth;
      const padFront = filterDepth - 1 - convInfo.padInfo.front;
      const padTop = filterHeight - 1 - convInfo.padInfo.top;
      const padLeft = filterWidth - 1 - convInfo.padInfo.left;
      this.userCode = `
      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int d1 = coords.u;


        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;
        int dyFCorner = dyCorner.x;
        int dyRCorner = dyCorner.y;
        int dyCCorner = dyCorner.z;

        float dotProd = 0.0;
        for (int wF = 0; wF < ${filterDepth}; wF++) {
          float dyF = float(dyFCorner + wF) / ${strideDepth}.0;

          if (dyF < 0.0 || dyF >= ${convInfo.outDepth}.0 || fract(dyF) > 0.0) {
            continue;
          }
          int idyF = int(dyF);

          int wFPerm = ${filterDepth} - 1 - wF;

          for (int wR = 0; wR < ${filterHeight}; wR++) {
            float dyR = float(dyRCorner + wR) / ${strideHeight}.0;

            if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 ||
              fract(dyR) > 0.0) {
              continue;
            }
            int idyR = int(dyR);

            int wRPerm = ${filterHeight} - 1 - wR;

            for (int wC = 0; wC < ${filterWidth}; wC++) {
              float dyC = float(dyCCorner + wC) / ${strideWidth}.0;

              if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||
                  fract(dyC) > 0.0) {
                continue;
              }
              int idyC = int(dyC);

              int wCPerm = ${filterWidth} - 1 - wC;

              for (int d2 = 0; d2 < ${convInfo.outChannels}; d2++) {
                float xValue = getDy(batch, idyF, idyR, idyC, d2);
                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);
                dotProd += xValue * wValue;
              }
            }
          }
        }
        setOutput(dotProd);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Conv2DBackpropFilter.js
  function conv2DBackpropFilter3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, dy } = inputs;
    const { strides, pad: pad2, dataFormat, dimRoundingMode, filterShape } = attrs;
    const $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
    const convInfo = backend_util_exports.computeConv2DInfo(x.shape, filterShape, strides, 1, pad2, dimRoundingMode, false, $dataFormat);
    const program = new Conv2DDerFilterProgram(convInfo);
    return backend2.runWebGLProgram(program, [x, dy], "float32");
  }
  var conv2DBackpropFilterConfig2 = {
    kernelName: Conv2DBackpropFilter,
    backendName: "webgl",
    kernelFunc: conv2DBackpropFilter3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Conv2DBackpropInput.js
  function conv2DBackpropInput3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { dy, filter } = inputs;
    const { inputShape, strides, pad: pad2, dataFormat, dimRoundingMode } = attrs;
    const $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
    const convInfo = backend_util_exports.computeConv2DInfo(inputShape, filter.shape, strides, 1, pad2, dimRoundingMode, false, $dataFormat);
    const program = new Conv2DDerInputProgram(convInfo);
    return backend2.runWebGLProgram(program, [dy, filter], "float32");
  }
  var conv2DBackpropInputConfig2 = {
    kernelName: Conv2DBackpropInput,
    backendName: "webgl",
    kernelFunc: conv2DBackpropInput3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Conv3D.js
  function conv3D2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, filter } = inputs;
    const { strides, pad: pad2, dilations } = attrs;
    const convInfo = backend_util_exports.computeConv3DInfo(x.shape, filter.shape, strides, dilations, pad2);
    const program = new Conv3DProgram(convInfo);
    return backend2.runWebGLProgram(program, [x, filter], "float32");
  }
  var conv3DConfig2 = {
    kernelName: Conv3D,
    backendName: "webgl",
    kernelFunc: conv3D2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Conv3DBackpropFilterV2.js
  function conv3DBackpropFilterV22(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, dy } = inputs;
    const { strides, pad: pad2, filterShape } = attrs;
    const convInfo = backend_util_exports.computeConv3DInfo(x.shape, filterShape, strides, 1, pad2);
    const program = new Conv3DDerFilterProgram(convInfo);
    return backend2.runWebGLProgram(program, [x, dy], "float32");
  }
  var conv3DBackpropFilterV2Config2 = {
    kernelName: Conv3DBackpropFilterV2,
    backendName: "webgl",
    kernelFunc: conv3DBackpropFilterV22
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Conv3DBackpropInputV2.js
  function conv3DBackpropInput2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { dy, filter } = inputs;
    const { pad: pad2, strides, inputShape } = attrs;
    const convInfo = backend_util_exports.computeConv3DInfo(inputShape, filter.shape, strides, 1, pad2);
    const program = new Conv3DDerInputProgram(convInfo);
    return backend2.runWebGLProgram(program, [dy, filter], "float32");
  }
  var conv3DBackpropInputConfig = {
    kernelName: Conv3DBackpropInputV2,
    backendName: "webgl",
    kernelFunc: conv3DBackpropInput2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Cos.js
  var COS = CHECK_NAN_SNIPPET_UNARY + `
  return cos(x);
`;
  var cos3 = unaryKernelFunc2({ opSnippet: COS });
  var cosConfig2 = {
    kernelName: Cos,
    backendName: "webgl",
    kernelFunc: cos3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Cosh.js
  var COSH = `
  float e2x = exp(-x);
  return (e2x + 1.0 / e2x) / 2.0;
`;
  var cosh3 = unaryKernelFunc2({ opSnippet: COSH });
  var coshConfig2 = {
    kernelName: Cosh,
    backendName: "webgl",
    kernelFunc: cosh3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/crop_and_resize_gpu.js
  var CropAndResizeProgram = class {
    constructor(imageShape, boxShape, cropSize, method, extrapolationValue) {
      this.variableNames = ["Image", "Boxes", "BoxInd"];
      this.outputShape = [];
      const [batch, imageHeight, imageWidth, depth] = imageShape;
      const [numBoxes] = boxShape;
      const [cropHeight, cropWidth] = cropSize;
      this.outputShape = [numBoxes, cropHeight, cropWidth, depth];
      const methodId = method === "bilinear" ? 1 : 0;
      const [inputHeightFloat, inputWidthFloat] = [`${imageHeight - 1}.0`, `${imageWidth - 1}.0`];
      const [heightRatio, heightScale, inY] = cropHeight > 1 ? [
        `${(imageHeight - 1) / (cropHeight - 1)}`,
        "(y2-y1) * height_ratio",
        `y1*${inputHeightFloat} + float(y)*(height_scale)`
      ] : [
        "0.0",
        "0.0",
        `0.5 * (y1+y2) * ${inputHeightFloat}`
      ];
      const [widthRatio, widthScale, inX] = cropWidth > 1 ? [
        `${(imageWidth - 1) / (cropWidth - 1)}`,
        "(x2-x1) * width_ratio",
        `x1*${inputWidthFloat} + float(x)*(width_scale)`
      ] : [
        "0.0",
        "0.0",
        `0.5 * (x1+x2) * ${inputWidthFloat}`
      ];
      this.userCode = `
      const float height_ratio = float(${heightRatio});
      const float width_ratio = float(${widthRatio});
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int y = coords[1];
        int x = coords[2];
        int d = coords[3];

        // get box vals
        float y1 = getBoxes(b,0);
        float x1 = getBoxes(b,1);
        float y2 = getBoxes(b,2);
        float x2 = getBoxes(b,3);

        // get image in batch index
        int bInd = round(getBoxInd(b));
        if(bInd < 0 || bInd >= ${batch}) {
          return;
        }

        float height_scale = ${heightScale};
        float width_scale = ${widthScale};

        float in_y = ${inY};
        if( in_y < 0.0 || in_y > ${inputHeightFloat} ) {
          setOutput(float(${extrapolationValue}));
          return;
        }
        float in_x = ${inX};
        if( in_x < 0.0 || in_x > ${inputWidthFloat} ) {
          setOutput(float(${extrapolationValue}));
          return;
        }

        vec2 sourceFracIndexCR = vec2(in_x,in_y);
        if(${methodId} == 1) {
          // Compute the four integer indices.
          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);
          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));

          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);
          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);
          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);
          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);

          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);

          float top = topLeft + (topRight - topLeft) * fracCR.x;
          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;
          float newValue = top + (bottom - top) * fracCR.y;
          setOutput(newValue);
        } else {
          // Compute the coordinators of nearest neighbor point.
          ivec2 sourceNearestCR = ivec2(floor(
            sourceFracIndexCR + vec2(0.5,0.5)));
          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);
          setOutput(newValue);
        }
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/CropAndResize.js
  var cropAndResize3 = (args) => {
    const { inputs, backend: backend2, attrs } = args;
    const { image: image3, boxes, boxInd } = inputs;
    const { cropSize, method, extrapolationValue } = attrs;
    const program = new CropAndResizeProgram(image3.shape, boxes.shape, cropSize, method, extrapolationValue);
    return backend2.runWebGLProgram(program, [image3, boxes, boxInd], "float32");
  };
  var cropAndResizeConfig2 = {
    kernelName: CropAndResize,
    backendName: "webgl",
    kernelFunc: cropAndResize3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/cumsum_gpu.js
  var CumSumProgram = class {
    constructor(shape, exclusive, reverse4) {
      this.variableNames = ["x"];
      this.customUniforms = [{ name: "index", type: "float" }];
      this.outputShape = shape;
      const rank = shape.length;
      const val = exclusive ? "0.0" : `getX(${getCoords2(rank, "coords")})`;
      const length = shape[shape.length - 1];
      let condition = "";
      let idxString = "";
      if (exclusive) {
        condition = reverse4 ? `end != ${length - 1}` : "end != 0";
        idxString = reverse4 ? "end + 1" : "end - 1";
      } else {
        condition = reverse4 ? `end + pow2 < ${length}` : "end >= pow2";
        idxString = reverse4 ? "end + pow2" : "end - pow2";
      }
      this.userCode = `
      void main() {
        ${getCoordsDataType(rank)} coords = getOutputCoords();
        int end = ${getFinalCoord(rank, "coords")};
        float val = ${val};
        int pow2 = int(pow(2.0, index));
        if (${condition}) {
          int idx = ${idxString};
          ${getFinalCoord(rank, "coords")} = idx;
          val += getX(${getCoords2(rank, "coords")});
        }
        setOutput(val);
      }
    `;
    }
  };
  function getCoords2(rank, name) {
    if (rank === 1) {
      return `${name}`;
    } else if (rank === 2) {
      return `${name}.x, ${name}.y`;
    } else if (rank === 3) {
      return `${name}.x, ${name}.y, ${name}.z`;
    } else if (rank === 4) {
      return `${name}.x, ${name}.y, ${name}.z, ${name}.w`;
    } else {
      throw Error(`Cumulative sum for rank ${rank} is not yet supported`);
    }
  }
  function getFinalCoord(rank, name) {
    if (rank === 1) {
      return `${name}`;
    } else if (rank === 2) {
      return `${name}.y`;
    } else if (rank === 3) {
      return `${name}.z`;
    } else if (rank === 4) {
      return `${name}.w`;
    } else {
      throw Error(`Cumulative sum for rank ${rank} is not yet supported`);
    }
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Cumsum.js
  function cumsum3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { axis, exclusive, reverse: reverse4 } = attrs;
    const xRank = x.shape.length;
    const permutation = backend_util_exports.getAxesPermutation([axis], xRank);
    let permutedX = x;
    if (permutation != null) {
      permutedX = transpose3({ inputs: { x }, backend: backend2, attrs: { perm: permutation } });
    }
    const permutedAxis = backend_util_exports.getInnerMostAxes(1, xRank)[0];
    if (permutedAxis !== xRank - 1) {
      throw new Error(`WebGL cumsum shader expects an inner-most axis=${x.shape.length - 1} but got axis=${axis}`);
    }
    const size2 = permutedX.shape[permutedAxis];
    let result = identity2({ inputs: { x: permutedX }, backend: backend2 });
    for (let i = 0; i <= Math.ceil(Math.log2(size2)) - 1; i++) {
      const program = new CumSumProgram(permutedX.shape, false, reverse4);
      const customValues = [[i]];
      const prevResult = result;
      result = backend2.runWebGLProgram(program, [result], result.dtype, customValues);
      backend2.disposeIntermediateTensorInfo(prevResult);
    }
    if (exclusive) {
      const program = new CumSumProgram(permutedX.shape, exclusive, reverse4);
      const prevResult = result;
      result = backend2.runWebGLProgram(program, [result], result.dtype);
      backend2.disposeIntermediateTensorInfo(prevResult);
    }
    if (permutation != null) {
      const reversePermutation = backend_util_exports.getUndoAxesPermutation(permutation);
      const reverseTransposedResult = transpose3({ inputs: { x: result }, backend: backend2, attrs: { perm: reversePermutation } });
      backend2.disposeIntermediateTensorInfo(result);
      backend2.disposeIntermediateTensorInfo(permutedX);
      return reverseTransposedResult;
    }
    return result;
  }
  var cumsumConfig2 = {
    kernelName: Cumsum,
    backendName: "webgl",
    kernelFunc: cumsum3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/DenseBincount.js
  function denseBincount2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, weights } = inputs;
    const { size: size2, binaryOutput } = attrs;
    if (x.shape.length === 1) {
      const xVals = backend2.readSync(x.dataId);
      const weightsVals = backend2.readSync(weights.dataId);
      const outVals = bincountImplCPU(xVals, weightsVals, weights.dtype, weights.shape, size2);
      return backend2.makeTensorInfo([size2], weights.dtype, outVals);
    } else if (x.shape.length === 2) {
      const xBuf = backend2.bufferSync(x);
      const weightsBuf = backend2.bufferSync(weights);
      const outBuf = bincountReduceImplCPU(xBuf, weightsBuf, size2, binaryOutput);
      return backend2.makeTensorInfo(outBuf.shape, weights.dtype, outBuf.values);
    }
    throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${x.shape.length}.`);
  }
  var denseBincountConfig2 = {
    kernelName: DenseBincount,
    backendName: "webgl",
    kernelFunc: denseBincount2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/depth_to_space_gpu.js
  var DepthToSpaceProgram = class {
    constructor(outputShape, blockSize, dataFormat) {
      this.variableNames = ["x"];
      this.outputShape = [];
      this.outputShape = outputShape;
      this.blockSize = blockSize;
      this.dataFormat = dataFormat;
      this.userCode = `
    void main() {
      ivec4 coords = getOutputCoords();
      int b = coords[0];
      int h = ${this.getHeightCoordString()};
      int w = ${this.getWidthCoordString()};
      int d = ${this.getDepthCoordString()};

      int in_h = h / ${blockSize};
      int offset_h = imod(h, ${blockSize});
      int in_w = w / ${blockSize};
      int offset_w = imod(w, ${blockSize});
      int offset_d = (offset_h * ${blockSize} + offset_w) *
        ${this.getOutputDepthSize()};
      int in_d = d + offset_d;

      float result = ${this.getInputSamplingString()};
      setOutput(result);
    }
  `;
    }
    getHeightCoordString() {
      if (this.dataFormat === "NHWC") {
        return `coords[1]`;
      } else {
        return `coords[2]`;
      }
    }
    getWidthCoordString() {
      if (this.dataFormat === "NHWC") {
        return `coords[2]`;
      } else {
        return `coords[3]`;
      }
    }
    getDepthCoordString() {
      if (this.dataFormat === "NHWC") {
        return `coords[3]`;
      } else {
        return `coords[1]`;
      }
    }
    getOutputDepthSize() {
      if (this.dataFormat === "NHWC") {
        return this.outputShape[3];
      } else {
        return this.outputShape[1];
      }
    }
    getInputSamplingString() {
      if (this.dataFormat === "NHWC") {
        return `getX(b, in_h, in_w, in_d)`;
      } else {
        return `getX(b, in_d, in_h, in_w)`;
      }
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/DepthToSpace.js
  function depthToSpace3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { blockSize, dataFormat } = attrs;
    const batchSize = x.shape[0];
    const inputHeight = dataFormat === "NHWC" ? x.shape[1] : x.shape[2];
    const inputWidth = dataFormat === "NHWC" ? x.shape[2] : x.shape[3];
    const inputDepth = dataFormat === "NHWC" ? x.shape[3] : x.shape[1];
    const outputHeight = inputHeight * blockSize;
    const outputWidth = inputWidth * blockSize;
    const outputDepth = inputDepth / (blockSize * blockSize);
    const outputShape = dataFormat === "NHWC" ? [batchSize, outputHeight, outputWidth, outputDepth] : [batchSize, outputDepth, outputHeight, outputWidth];
    const program = new DepthToSpaceProgram(outputShape, blockSize, dataFormat);
    return backend2.runWebGLProgram(program, [x], x.dtype);
  }
  var depthToSpaceConfig2 = {
    kernelName: DepthToSpace,
    backendName: "webgl",
    kernelFunc: depthToSpace3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/conv_gpu_depthwise.js
  var DepthwiseConv2DProgram = class {
    constructor(convInfo, addBias = false, activation = null, hasPreluActivation = false, hasLeakyReluAlpha = false) {
      this.variableNames = ["x", "W"];
      this.customUniforms = [
        { name: "pads", type: "ivec2" },
        { name: "strides", type: "ivec2" },
        { name: "dilations", type: "ivec2" },
        { name: "inDims", type: "ivec2" }
      ];
      this.outputShape = convInfo.outShape;
      this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
      const filterHeight = convInfo.filterHeight;
      const filterWidth = convInfo.filterWidth;
      const channelMul = convInfo.outChannels / convInfo.inChannels;
      let activationSnippet = "", applyActivationSnippet = "";
      if (activation) {
        if (hasPreluActivation) {
          activationSnippet = `float activation(float a) {
          float b = getPreluActivationWeightsAtOutCoords();
          ${activation}
        }`;
        } else if (hasLeakyReluAlpha) {
          activationSnippet = `float activation(float a) {
          float b = getLeakyreluAlphaAtOutCoords();
          ${activation}
        }`;
        } else {
          activationSnippet = `
          float activation(float x) {
            ${activation}
          }
        `;
        }
        applyActivationSnippet = `result = activation(result);`;
      }
      const addBiasSnippet = addBias ? "result += getBiasAtOutCoords();" : "";
      if (addBias) {
        this.variableNames.push("bias");
      }
      if (hasPreluActivation) {
        this.variableNames.push("preluActivationWeights");
      }
      if (hasLeakyReluAlpha) {
        this.variableNames.push("leakyreluAlpha");
      }
      this.userCode = `
      ${activationSnippet}

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords.x;
        ivec2 xRCCorner = coords.yz * strides - pads;
        int d2 = coords.w;
        int d1 = d2 / ${channelMul};
        int q = d2 - d1 * ${channelMul};

        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        // TO DO(dsmilkov): Flatten the two for loops and vec4 the operations.
        for (int wR = 0; wR < ${filterHeight}; wR++) {
          int xR = xRCorner + wR * dilations[0];

          if (xR < 0 || xR >= inDims[0]) {
            continue;
          }

          for (int wC = 0; wC < ${filterWidth}; wC++) {
            int xC = xCCorner + wC * dilations[1];

            if (xC < 0 || xC >= inDims[1]) {
              continue;
            }

            float xVal = getX(batch, xR, xC, d1);
            float wVal = getW(wR, wC, d1, q);
            dotProd += xVal * wVal;
          }
        }

        float result = dotProd;
        ${addBiasSnippet}
        ${applyActivationSnippet}
        setOutput(result);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/conv_packed_gpu_depthwise.js
  var DepthwiseConvPacked2DProgram = class {
    constructor(convInfo, addBias = false, activation = null, hasPreluActivation = false, hasLeakyReluAlpha = false) {
      this.variableNames = ["x", "W"];
      this.packedInputs = true;
      this.packedOutput = true;
      this.customUniforms = [
        { name: "pads", type: "ivec2" },
        { name: "strides", type: "ivec2" },
        { name: "dilations", type: "ivec2" },
        { name: "inDims", type: "ivec2" }
      ];
      this.outputShape = convInfo.outShape;
      this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
      const channelMul = convInfo.outChannels / convInfo.inChannels;
      const padLeft = convInfo.padInfo.left;
      const strideWidth = convInfo.strideWidth;
      const dilationWidth = convInfo.dilationWidth;
      const filterHeight = convInfo.filterHeight;
      const filterWidth = convInfo.filterWidth;
      const texelsAcross = filterWidth;
      let mainLoop = `
      int xR; int xC; int xCOffset;
      vec4 wTexel; vec4 previous; vec4 final;`;
      for (let c = 0; c < filterWidth; c++) {
        mainLoop += `
          vec4 xTexelC${c * 2};
          int xTexelC${c * 2}Ready;
          vec4 xTexelC${c * 2 + 1};
          int xTexelC${c * 2 + 1}Ready;
          vec4 xC${c};`;
      }
      mainLoop += `
    for (int r = 0; r < ${filterHeight}; r++) {
      `;
      for (let c = 0; c < filterWidth; c++) {
        mainLoop += `
          xTexelC${c * 2} = vec4(0.0);
          xTexelC${c * 2}Ready = 0;
          xTexelC${c * 2 + 1} = vec4(0.0);
          xTexelC${c * 2 + 1}Ready = 0;
          xC${c} = vec4(0.0);`;
      }
      mainLoop += `
        xR = xRCorner + r * dilations[0];
        if (xR >=0 && xR < inDims[0]) {
      `;
      for (let texelC = 0; texelC < (texelsAcross + 1) / 2; texelC++) {
        const colIndex = texelC * 2;
        mainLoop += `
          xC = xCCorner + ${colIndex * dilationWidth};
          `;
        if (strideWidth === 1) {
          if (colIndex < filterWidth) {
            if (padLeft % 2 === 1) {
              mainLoop += `
                xCOffset = xC + 1;
                if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex}Ready == 0) {
                  xTexelC${colIndex} = getX(batch, xR, xCOffset, d1);

                  // Need to manually clear unused channels in case
                  // we're reading from recycled texture.
                  if (xCOffset + 1 >= inDims[1]) {
                    xTexelC${colIndex}.zw = vec2(0.0);
                  }
                  xTexelC${colIndex}Ready = 1;
                }
              `;
              if (dilationWidth === 1 && colIndex > 0) {
                mainLoop += `
                xC${colIndex} = vec4(xTexelC${colIndex - 2}.zw, xTexelC${colIndex}.xy);
                `;
              } else {
                mainLoop += `
                  xCOffset = xC + 1 - 2;

                  if (xCOffset >= 0 && xCOffset < inDims[1]) {
                    previous = getX(batch, xR, xCOffset, d1);

                    // Need to manually clear unused channels in case
                    // we're reading from recycled texture.
                    if (xCOffset + 1 >= inDims[1]) {
                      previous.zw = vec2(0.0);
                    }

                    xC${colIndex} = vec4(previous.zw, xTexelC${colIndex}.xy);
                  } else {
                    xC${colIndex} = vec4(0.0, 0.0, xTexelC${colIndex}.xy);
                  }
                  `;
              }
            } else {
              mainLoop += `
                if (xC >= 0 && xC < inDims[1] && xTexelC${colIndex}Ready == 0) {
                  xTexelC${colIndex} = getX(batch, xR, xC, d1);
                  if (xC + 1 >= inDims[1]) {
                    xTexelC${colIndex}.zw = vec2(0.0);
                  }
                  xTexelC${colIndex}Ready = 1;
                }

                xC${colIndex} = xTexelC${colIndex};
                `;
            }
            if (colIndex + 1 < filterWidth) {
              const nextTexelOffset = padLeft % 2 === 0 ? util_exports.nearestLargerEven(dilationWidth) : dilationWidth;
              if (dilationWidth % 2 === 0 && padLeft % 2 === 1 || dilationWidth % 2 !== 0 && padLeft % 2 !== 1) {
                mainLoop += `
                  xCOffset = xC + imod(pads[1], 2) + ${nextTexelOffset};

                  if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex + 1}Ready == 0) {
                    xTexelC${colIndex + 1} = getX(batch, xR, xCOffset, d1);

                    // Need to manually clear unused channels in case
                    // we're reading from recycled texture.
                    if (xCOffset + 1 >= inDims[1]) {
                      xTexelC${colIndex + 1}.zw = vec2(0.0);
                    }
                    xTexelC${colIndex + 1}Ready = 1;
                  }
                  `;
                if (dilationWidth > 1) {
                  mainLoop += `
                    xCOffset -= 2;
                    if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex}Ready == 0) {
                      xTexelC${colIndex} = getX(batch, xR, xCOffset, d1);
                      xTexelC${colIndex}Ready = 1;
                    }
                    `;
                }
                mainLoop += `
                  xC${colIndex + 1} = vec4(xTexelC${colIndex}.zw, xTexelC${colIndex + 1}.xy);
                  `;
              } else {
                if (nextTexelOffset === 1) {
                  mainLoop += `
                    xC${colIndex + 1} = xTexelC${colIndex};
                    `;
                } else {
                  mainLoop += `
                    xCOffset = xC + ${nextTexelOffset};

                    if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex + 1}Ready == 0) {
                      xTexelC${colIndex + 1} = getX(batch, xR, xCOffset, d1);
                      if (xCOffset + 1 >= inDims[1]) {
                        xTexelC${colIndex + 1}.zw = vec2(0.0);
                      }
                      xTexelC${colIndex + 1}Ready = 1;
                    }

                    xC${colIndex + 1} = xTexelC${colIndex + 1};
                    `;
                }
              }
            }
          }
        } else {
          if (colIndex < filterWidth) {
            if (padLeft % 2 === 1) {
              mainLoop += `
                xCOffset = xC + 1 - strides[1];
                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex}Ready == 0) {
                  xTexelC${colIndex} = getX(batch, xR, xCOffset, d1);
                  // Need to manually clear unused channels in case
                  // we're reading from recycled texture.
                  if (xCOffset + 1 >= inDims[1]) {
                    xTexelC${colIndex}.zw = vec2(0.0);
                  }
                  xTexelC${colIndex}Ready = 1;
                }

                if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC${colIndex + 1}Ready == 0) {
                  xTexelC${colIndex + 1} = getX(batch, xR, xC + 1, d1);
                  // Need to manually clear unused channels in case
                  // we're reading from recycled texture.
                  if (xC + 2 >= inDims[1]) {
                    xTexelC${colIndex + 1}.zw = vec2(0.0);
                  }
                  xTexelC${colIndex + 1}Ready = 1;
                }

                xC${colIndex} = vec4(xTexelC${colIndex}.zw, xTexelC${colIndex + 1}.zw);
              `;
              if (colIndex + 1 < filterWidth) {
                mainLoop += `
                  final = vec4(0.0);
                  xCOffset = xC + 1 + strides[1];
                  if(xCOffset >= 0 && xCOffset < inDims[1]) {
                    final = getX(batch, xR, xCOffset, d1);
                  }
                  xC${colIndex + 1} = vec4(xTexelC${colIndex + 1}.xy, final.xy);
                `;
              }
            } else {
              mainLoop += `
                if(xC >= 0 && xC < inDims[1] && xTexelC${colIndex}Ready == 0) {
                  xTexelC${colIndex} = getX(batch, xR, xC, d1);
                  if (xC + 1 >= inDims[1]) {
                    xTexelC${colIndex}.zw = vec2(0.0);
                  }
                  xTexelC${colIndex}Ready = 1;
                }

                xCOffset = xC + strides[1];
                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex + 1}Ready == 0) {
                  xTexelC${colIndex + 1} = getX(batch, xR, xCOffset, d1);
                  if (xCOffset + 1 >= inDims[1]) {
                    xTexelC${colIndex + 1}.zw = vec2(0.);
                  }
                  xTexelC${colIndex + 1}Ready = 1;
                }

                xC${colIndex} = vec4(
                  xTexelC${colIndex}.xy, xTexelC${colIndex + 1}.xy);
              `;
              if (colIndex + 1 < filterWidth) {
                mainLoop += `
                  xC${colIndex + 1} = vec4(xTexelC${colIndex}.zw, xTexelC${colIndex + 1}.zw);
                `;
              }
            }
          }
        }
        if (colIndex < filterWidth) {
          mainLoop += `
            wTexel = getW(r, ${colIndex}, d1, q);
            dotProd += xC${colIndex} * vec4(wTexel.xz, wTexel.xz);
          `;
          if (colIndex + 1 < filterWidth) {
            mainLoop += `
              wTexel = getW(r, ${colIndex + 1}, d1, q);
              dotProd += xC${colIndex + 1} * vec4(wTexel.xz, wTexel.xz);
            `;
          }
        }
      }
      mainLoop += `
    }
  `;
      mainLoop += `
      }
    `;
      let activationSnippet = "", applyActivationSnippet = "";
      if (activation) {
        if (hasPreluActivation) {
          activationSnippet = `vec4 activation(vec4 a) {
          vec4 b = getPreluActivationWeightsAtOutCoords();
          ${activation}
        }`;
        } else if (hasLeakyReluAlpha) {
          activationSnippet = `vec4 activation(vec4 a) {
          vec4 b = getLeakyreluAlphaAtOutCoords();
          ${activation}
        }`;
        } else {
          activationSnippet = `vec4 activation(vec4 x) {
          ${activation}
        }`;
        }
        applyActivationSnippet = `result = activation(result);`;
      }
      const addBiasSnippet = addBias ? "result += getBiasAtOutCoords();" : "";
      if (addBias) {
        this.variableNames.push("bias");
      }
      if (hasPreluActivation) {
        this.variableNames.push("preluActivationWeights");
      }
      if (hasLeakyReluAlpha) {
        this.variableNames.push("leakyreluAlpha");
      }
      this.userCode = `
      ${activationSnippet}

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords.x;
        ivec2 xRCCorner = coords.yz * strides - pads;
        int d2 = coords.w;
        int d1 = d2 / ${channelMul};
        int q = d2 - d1 * ${channelMul};
        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.
        vec4 dotProd = vec4(0.000000000000001);

        ${mainLoop}

        vec4 result = dotProd - vec4(0.000000000000001);
        ${addBiasSnippet}
        ${applyActivationSnippet}
        setOutput(result);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/DepthwiseConv2dNative.js
  function depthwiseConv2dNative2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, filter } = inputs;
    const { strides, pad: pad2, dilations, dimRoundingMode } = attrs;
    let $dilations = dilations;
    if ($dilations == null) {
      $dilations = [1, 1];
    }
    util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(strides, $dilations), () => `Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${strides} and dilations '${$dilations}'`);
    const convInfo = backend_util_exports.computeConv2DInfo(x.shape, filter.shape, strides, $dilations, pad2, dimRoundingMode, true);
    let program;
    if (env().getBool("WEBGL_PACK_DEPTHWISECONV") && convInfo.strideWidth <= 2 && convInfo.outChannels / convInfo.inChannels === 1) {
      program = new DepthwiseConvPacked2DProgram(convInfo);
    } else {
      program = new DepthwiseConv2DProgram(convInfo);
    }
    const customValues = [
      [convInfo.padInfo.top, convInfo.padInfo.left],
      [convInfo.strideHeight, convInfo.strideWidth],
      [convInfo.dilationHeight, convInfo.dilationWidth],
      [convInfo.inHeight, convInfo.inWidth]
    ];
    return backend2.runWebGLProgram(program, [x, filter], "float32", customValues);
  }
  var depthwiseConv2dNativeConfig2 = {
    kernelName: DepthwiseConv2dNative,
    backendName: "webgl",
    kernelFunc: depthwiseConv2dNative2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/conv_backprop_gpu_depthwise.js
  var DepthwiseConv2DDerFilterProgram = class {
    constructor(convInfo) {
      this.variableNames = ["x", "dy"];
      this.outputShape = convInfo.filterShape;
      const strideHeight = convInfo.strideHeight;
      const strideWidth = convInfo.strideWidth;
      const padTop = convInfo.padInfo.top;
      const padLeft = convInfo.padInfo.left;
      const channelMul = convInfo.outChannels / convInfo.inChannels;
      this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int wR = coords.x;
        int wC = coords.y;
        int d1 = coords.z;
        int dm = coords.w;
        int d2 = d1 * ${channelMul} + dm;

        float dotProd = 0.0;

        // TO DO: Vec4 over the batch size
        for (int b = 0; b < ${convInfo.batchSize}; b++) {
          for (int yR = 0; yR < ${convInfo.outHeight}; yR++) {
            int xR = wR + yR * ${strideHeight} - ${padTop};

            if (xR < 0 || xR >= ${convInfo.inHeight}) {
              continue;
            }

            for (int yC = 0; yC < ${convInfo.outWidth}; yC++) {
              int xC = wC + yC * ${strideWidth} - ${padLeft};

              if (xC < 0 || xC >= ${convInfo.inWidth}) {
                continue;
              }

              float dyValue = getDy(b, yR, yC, d2);
              float xValue = getX(b, xR, xC, d1);
              dotProd += (xValue * dyValue);
            }
          }
        }
        setOutput(dotProd);
      }
    `;
    }
  };
  var DepthwiseConv2DDerInputProgram = class {
    constructor(convInfo) {
      this.variableNames = ["dy", "W"];
      this.outputShape = convInfo.inShape;
      const filterHeight = convInfo.filterHeight;
      const filterWidth = convInfo.filterWidth;
      const strideHeight = convInfo.strideHeight;
      const strideWidth = convInfo.strideWidth;
      const padTop = filterHeight - 1 - convInfo.padInfo.top;
      const padLeft = filterWidth - 1 - convInfo.padInfo.left;
      const channelMul = convInfo.outChannels / convInfo.inChannels;
      this.userCode = `
      const ivec2 pads = ivec2(${padTop}, ${padLeft});

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d1 = coords[3];
        ivec2 dyCorner = coords.yz - pads;
        int dyRCorner = dyCorner.x;
        int dyCCorner = dyCorner.y;

        float dotProd = 0.0;

        for (int wR = 0; wR < ${filterHeight}; wR++) {
          float dyR = float(dyRCorner + wR) / ${strideHeight}.0;

          if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          int wRPerm = ${filterHeight} - 1 - wR;

          for (int wC = 0; wC < ${filterWidth}; wC++) {
            float dyC = float(dyCCorner + wC) / ${strideWidth}.0;

            if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            int wCPerm = ${filterWidth} - 1 - wC;

            // TO DO: Vec4 over the channelMul
            for (int dm = 0; dm < ${channelMul}; dm++) {
              int d2 = d1 * ${channelMul} + dm;
              float xValue = getDy(batch, idyR, idyC, d2);
              float wValue = getW(wRPerm, wCPerm, d1, dm);
              dotProd += xValue * wValue;
            }
          }
        }
        setOutput(dotProd);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/DepthwiseConv2dNativeBackpropFilter.js
  function depthwiseConv2dNativeBackpropFilter3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, dy } = inputs;
    const { strides, dilations, pad: pad2, dimRoundingMode, filterShape } = attrs;
    const convInfo = backend_util_exports.computeConv2DInfo(x.shape, filterShape, strides, dilations, pad2, dimRoundingMode, true);
    const program = new DepthwiseConv2DDerFilterProgram(convInfo);
    return backend2.runWebGLProgram(program, [x, dy], "float32");
  }
  var depthwiseConv2dNativeBackpropFilterConfig2 = {
    kernelName: DepthwiseConv2dNativeBackpropFilter,
    backendName: "webgl",
    kernelFunc: depthwiseConv2dNativeBackpropFilter3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/DepthwiseConv2dNativeBackpropInput.js
  function depthwiseConv2dNativeBackpropInput3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { dy, filter } = inputs;
    const { strides, dilations, pad: pad2, dimRoundingMode, inputShape } = attrs;
    const convInfo = backend_util_exports.computeConv2DInfo(inputShape, filter.shape, strides, dilations, pad2, dimRoundingMode, true);
    const program = new DepthwiseConv2DDerInputProgram(convInfo);
    return backend2.runWebGLProgram(program, [dy, filter], "float32");
  }
  var depthwiseConv2dNativeBackpropInputConfig2 = {
    kernelName: DepthwiseConv2dNativeBackpropInput,
    backendName: "webgl",
    kernelFunc: depthwiseConv2dNativeBackpropInput3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/diag_gpu.js
  var DiagProgram = class {
    constructor(size2) {
      this.variableNames = ["X"];
      this.outputShape = [size2, size2];
      this.userCode = `
      void main() {
          ivec2 coords = getOutputCoords();
          float val = coords[0] == coords[1] ? getX(coords[0]) : 0.0;
          setOutput(val);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Diag.js
  function diag2(args) {
    const { inputs, backend: backend2 } = args;
    const { x } = inputs;
    const outShape = [...x.shape, ...x.shape];
    const xSize = util_exports.sizeFromShape(x.shape);
    const flat = reshape3({ inputs: { x }, backend: backend2, attrs: { shape: [xSize] } });
    const program = new DiagProgram(xSize);
    const res = backend2.runWebGLProgram(program, [flat], flat.dtype);
    const out = reshape3({ inputs: { x: res }, backend: backend2, attrs: { shape: outShape } });
    backend2.disposeIntermediateTensorInfo(flat);
    backend2.disposeIntermediateTensorInfo(res);
    return out;
  }
  var diagConfig2 = {
    kernelName: Diag,
    backendName: "webgl",
    kernelFunc: diag2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/dilation_gpu.js
  var Dilation2DProgram = class {
    constructor(convInfo) {
      this.variableNames = ["x", "W"];
      this.outputShape = convInfo.outShape;
      const { inHeight, inWidth, padInfo, strideHeight, strideWidth, filterHeight, filterWidth, dilationHeight, dilationWidth } = convInfo;
      const { top: padTop, left: padLeft } = padInfo;
      this.userCode = `
      const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});
      const ivec2 pads = ivec2(${padTop}, ${padLeft});
      const float neg_infinity = -3.4e38;

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords.x;
        int d1 = coords.w;
        ivec2 outTopLeftCorner =
            coords.yz * strides - pads;
        int hBeg = outTopLeftCorner.x;
        int wBeg = outTopLeftCorner.y;

        float curVal = neg_infinity;
        for (int h = 0; h < ${filterHeight}; h++) {
          int hIn = hBeg + h * ${dilationHeight};

          if (hIn >= 0 && hIn < ${inHeight}) {
            for (int w = 0; w < ${filterWidth}; w++) {
              int wIn = wBeg + w * ${dilationWidth};

              if (wIn >= 0 && wIn < ${inWidth}) {
                float xVal = getX(batch, hIn, wIn, d1);
                float wVal = getW(h, w, d1);

                float val = xVal + wVal;
                if (val > curVal) {
                  curVal = val;
                }
              }
            }
          }
        }

        float result = curVal;
        setOutput(result);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Dilation2D.js
  function dilation2D(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, filter } = inputs;
    const { strides, pad: pad2, dilations } = attrs;
    const convInfo = backend_util_exports.computeDilation2DInfo(x.shape, filter.shape, strides, pad2, "NHWC", dilations);
    let out;
    const program = new Dilation2DProgram(convInfo);
    out = backend2.runWebGLProgram(program, [x, filter], "float32");
    const outReshaped = reshape3({ inputs: { x: out }, backend: backend2, attrs: { shape: convInfo.outShape } });
    backend2.disposeIntermediateTensorInfo(out);
    return outReshaped;
  }
  var dilation2DConfig = {
    kernelName: Dilation2D,
    backendName: "webgl",
    kernelFunc: dilation2D
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Einsum.js
  function einsum2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { equation } = attrs;
    const tensors = inputs;
    const { allDims, summedDims, idDims } = backend_util_exports.decodeEinsumEquation(equation, tensors.length);
    backend_util_exports.checkEinsumDimSizes(allDims.length, idDims, tensors);
    const { path, steps } = backend_util_exports.getEinsumComputePath(summedDims, idDims);
    const nSteps = steps.length;
    let out = null;
    let numDimsRemaining = allDims.length;
    const tensorsToDispose = [];
    for (let i = 0; i < nSteps; ++i) {
      for (const idTerm of steps[i]) {
        const { permutationIndices: perm, expandDims: dimsToExpand } = backend_util_exports.getEinsumPermutation(numDimsRemaining, idDims[idTerm]);
        let x;
        if (backend_util_exports.isIdentityPermutation(perm)) {
          x = tensors[idTerm];
        } else {
          x = transpose3({ inputs: { x: tensors[idTerm] }, backend: backend2, attrs: { perm } });
          tensorsToDispose.push(x);
        }
        const targetShape = x.shape.slice();
        for (let k = 0; k < dimsToExpand.length; ++k) {
          targetShape.splice(dimsToExpand[k], 0, 1);
        }
        if (!util_exports.arraysEqual(x.shape, targetShape)) {
          x = reshape3({ inputs: { x }, backend: backend2, attrs: { shape: targetShape } });
          tensorsToDispose.push(x);
        }
        if (out === null) {
          out = x;
        } else {
          out = multiply2({ inputs: { a: x, b: out }, backend: backend2 });
          tensorsToDispose.push(out);
        }
      }
      if (i < nSteps - 1) {
        if (path[i] >= 0) {
          out = sum4({
            inputs: { x: out },
            backend: backend2,
            attrs: {
              axis: path[i] - (allDims.length - numDimsRemaining),
              keepDims: false
            }
          });
          tensorsToDispose.push(out);
        }
        numDimsRemaining--;
      }
    }
    for (const tensorInfo of tensorsToDispose) {
      if (tensorInfo === out) {
        continue;
      }
      backend2.disposeIntermediateTensorInfo(tensorInfo);
    }
    return out;
  }
  var einsumConfig2 = {
    kernelName: Einsum,
    backendName: "webgl",
    kernelFunc: einsum2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Elu.js
  var ELU4 = `return (x >= 0.0) ? x : (exp(x) - 1.0);`;
  var ELU_PACKED = `
  vec4 result;

  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);
  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);
  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);
  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);

  return result;
`;
  var elu4 = unaryKernelFunc2({ opSnippet: ELU4, packedOpSnippet: ELU_PACKED });
  var eluConfig2 = {
    kernelName: Elu,
    backendName: "webgl",
    kernelFunc: elu4
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/EluGrad.js
  var ELU_DER = `return (b >= 1.0) ? a : a * (b + 1.0);`;
  var ELU_DER_PACKED = `
  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));
  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));
`;
  var eluGrad2 = (args) => {
    const { inputs, backend: backend2 } = args;
    const { dy, y } = inputs;
    const program = env().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new BinaryOpPackedProgram(ELU_DER_PACKED, dy.shape, y.shape) : new BinaryOpProgram(ELU_DER, dy.shape, y.shape);
    return backend2.runWebGLProgram(program, [dy, y], dy.dtype);
  };
  var eluGradConfig3 = {
    kernelName: EluGrad,
    backendName: "webgl",
    kernelFunc: eluGrad2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Equal.js
  var PACKED_EQUAL = `
  return vec4(equal(a, b));
`;
  var EQUAL = `return float(a == b);`;
  var equal3 = binaryKernelFunc2({
    opSnippet: EQUAL,
    packedOpSnippet: PACKED_EQUAL,
    dtype: "bool",
    cpuKernelImpl: equalImplCPU
  });
  var equalConfig2 = {
    kernelName: Equal,
    backendName: "webgl",
    kernelFunc: equal3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Erf.js
  var ERF = `
  // Error function is calculated approximately with elementary function.
  // See "Handbook of Mathematical Functions with Formulas,
  // Graphs, and Mathematical Tables", Abramowitz and Stegun.
  float p = ${backend_util_exports.ERF_P};
  float a1 = ${backend_util_exports.ERF_A1};
  float a2 = ${backend_util_exports.ERF_A2};
  float a3 = ${backend_util_exports.ERF_A3};
  float a4 = ${backend_util_exports.ERF_A4};
  float a5 = ${backend_util_exports.ERF_A5};

  float sign = sign(x);
  x = abs(x);
  float t = 1.0 / (1.0 + p * x);
  return sign * (1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x));
`;
  var erf3 = unaryKernelFunc2({ opSnippet: ERF });
  var erfConfig2 = {
    kernelName: Erf,
    backendName: "webgl",
    kernelFunc: erf3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Exp.js
  var EXP = `return exp(x);`;
  var exp3 = unaryKernelFunc2({
    opSnippet: EXP,
    packedOpSnippet: EXP,
    cpuKernelImpl: expImplCPU,
    dtype: "float32"
  });
  var expConfig2 = {
    kernelName: Exp,
    backendName: "webgl",
    kernelFunc: exp3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ExpandDims.js
  function expandDims4(args) {
    const { inputs, attrs, backend: backend2 } = args;
    const { dim } = attrs;
    const { input: input2 } = inputs;
    const inputRank = input2.shape.length;
    const newShape = input2.shape.slice();
    let $dim = dim;
    if (dim < 0) {
      util_exports.assert(-(inputRank + 1) <= dim, () => `Axis must be in the interval [${-(inputRank + 1)}, ${inputRank}]`);
      $dim = inputRank + dim + 1;
    }
    newShape.splice($dim, 0, 1);
    return reshape3({ inputs: { x: input2 }, backend: backend2, attrs: { shape: newShape } });
  }
  var expandDimsConfig2 = {
    kernelName: ExpandDims,
    backendName: "webgl",
    kernelFunc: expandDims4
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Expm1.js
  var EXPM1 = `return exp(x) - 1.0;`;
  var expm13 = unaryKernelFunc2({ opSnippet: EXPM1, packedOpSnippet: EXPM1, cpuKernelImpl: expm1ImplCPU });
  var expm1Config2 = {
    kernelName: Expm1,
    backendName: "webgl",
    kernelFunc: expm13
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/fft_gpu.js
  var FFTProgram = class {
    constructor(component, inputShape, inverse) {
      this.variableNames = ["real", "imag"];
      const innerDim = inputShape[1];
      this.outputShape = inputShape;
      const exponentMultiplierSnippet = inverse ? `2.0 * ${Math.PI}` : `-2.0 * ${Math.PI}`;
      const resultDenominator = inverse ? `${innerDim}.0` : "1.0";
      let opString;
      if (component === "real") {
        opString = "return real * expR - imag * expI;";
      } else if (component === "imag") {
        opString = "return real * expI + imag * expR;";
      } else {
        throw new Error(`FFT component must be either "real" or "imag", got ${component}.`);
      }
      this.userCode = `
      const float exponentMultiplier = ${exponentMultiplierSnippet};

      float unaryOpComplex(float real, float expR, float imag, float expI) {
        ${opString}
      }

      float mulMatDFT(int batch, int index) {
        float indexRatio = float(index) / float(${innerDim});
        float exponentMultiplierTimesIndexRatio =
            exponentMultiplier * indexRatio;

        float result = 0.0;

        for (int i = 0; i < ${innerDim}; i++) {
          // x = (-2|2 * PI / N) * index * i;
          float x = exponentMultiplierTimesIndexRatio * float(i);
          float expR = cos(x);
          float expI = sin(x);
          float real = getReal(batch, i);
          float imag = getImag(batch, i);

          result +=
              unaryOpComplex(real, expR, imag, expI) / ${resultDenominator};
        }

        return result;
      }

      void main() {
        ivec2 coords = getOutputCoords();
        setOutput(mulMatDFT(coords[0], coords[1]));
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FFT_impl.js
  function fftImpl2(x, inverse, backend2) {
    const xData = backend2.texData.get(x.dataId);
    const inputSize = util_exports.sizeFromShape(x.shape);
    const innerDimensionSize = x.shape[x.shape.length - 1];
    const batch = inputSize / innerDimensionSize;
    const input2D = reshape3({ inputs: { x }, backend: backend2, attrs: { shape: [batch, innerDimensionSize] } });
    const xShape = input2D.shape;
    const realProgram = new FFTProgram("real", xShape, inverse);
    const imagProgram = new FFTProgram("imag", xShape, inverse);
    const inputs = [
      {
        dataId: xData.complexTensorInfos.real.dataId,
        dtype: xData.complexTensorInfos.real.dtype,
        shape: xShape
      },
      {
        dataId: xData.complexTensorInfos.imag.dataId,
        dtype: xData.complexTensorInfos.imag.dtype,
        shape: xShape
      }
    ];
    const realPart = backend2.runWebGLProgram(realProgram, inputs, "float32");
    const imagPart = backend2.runWebGLProgram(imagProgram, inputs, "float32");
    const complexOutput = complex3({ inputs: { real: realPart, imag: imagPart }, backend: backend2 });
    backend2.disposeIntermediateTensorInfo(realPart);
    backend2.disposeIntermediateTensorInfo(imagPart);
    const complexOutputReshaped = reshape3({ inputs: { x: complexOutput }, backend: backend2, attrs: { shape: x.shape } });
    backend2.disposeIntermediateTensorInfo(input2D);
    backend2.disposeIntermediateTensorInfo(complexOutput);
    return complexOutputReshaped;
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FFT.js
  function fft3(args) {
    const { inputs, backend: backend2 } = args;
    const { input: input2 } = inputs;
    return fftImpl2(input2, false, backend2);
  }
  var fftConfig2 = {
    kernelName: FFT,
    backendName: "webgl",
    kernelFunc: fft3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/fill_gpu.js
  var FillProgram = class {
    constructor(shape, value) {
      this.outputShape = [];
      this.customUniforms = [{ name: "value", type: "float" }];
      this.variableNames = ["x"];
      this.outputShape = shape;
      this.userCode = `
      void main() {
        // Input can be obtained from uniform value.
        setOutput(value);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Fill.js
  function fill3(args) {
    const { backend: backend2, attrs } = args;
    const { shape, value } = attrs;
    let { dtype } = attrs;
    dtype = dtype || util_exports.inferDtype(value);
    if (dtype === "string") {
      const values = util_exports.getArrayFromDType(dtype, util_exports.sizeFromShape(shape));
      values.fill(value);
      return backend2.makeTensorInfo(shape, dtype, values);
    } else {
      const program = new FillProgram(shape, value);
      const customValues = [[value]];
      return backend2.runWebGLProgram(program, [], dtype, customValues);
    }
  }
  var fillConfig2 = {
    kernelName: Fill,
    backendName: "webgl",
    kernelFunc: fill3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/flip_left_right_gpu.js
  var FlipLeftRightProgram = class {
    constructor(imageShape) {
      this.variableNames = ["Image"];
      this.outputShape = [];
      const imageWidth = imageShape[2];
      this.outputShape = imageShape;
      this.userCode = `
        void main() {
          ivec4 coords = getOutputCoords();
          int x = coords[2];

          int coordX = ${imageWidth} - x - 1;
          float outputValue;
          if(coordX >= 0 && coordX < ${imageWidth}) {
            outputValue = getImage(coords[0], coords[1], coordX, coords[3]);
          } else {
            outputValue = getImage(coords[0], coords[1], coords[2], coords[3]);
          }
          setOutput(outputValue);
        }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FlipLeftRight.js
  var flipLeftRightConfig2 = {
    kernelName: FlipLeftRight,
    backendName: "webgl",
    kernelFunc: ({ inputs, backend: backend2 }) => {
      const { image: image3 } = inputs;
      const webglBackend = backend2;
      const program = new FlipLeftRightProgram(image3.shape);
      const output = webglBackend.runWebGLProgram(program, [image3], image3.dtype);
      return output;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Floor.js
  var FLOOR = `return floor(x);`;
  var floor3 = unaryKernelFunc2({ opSnippet: FLOOR, packedOpSnippet: FLOOR, cpuKernelImpl: floorImplCPU });
  var floorConfig2 = {
    kernelName: Floor,
    backendName: "webgl",
    kernelFunc: floor3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FloorDiv.js
  var INT_DIV = `
  float s = sign(a) * sign(b);
  int ia = round(a);
  int ib = round(b);
  if (ib != 0) {
    // Windows (D3D) wants guaranteed non-zero int division at compile-time.
    return float(idiv(ia, ib, s));
  } else {
    return NAN;
  }
`;
  var INT_DIV_PACKED = `
  ivec4 ia = round(a);
  ivec4 ib = round(b);
  bvec4 cond = notEqual(ib, ivec4(0));
  ivec4 result = ivec4(0);
  vec4 s = sign(a) * sign(b);

  // Windows (D3D) wants guaranteed non-zero int division at compile-time.
  if (cond[0]) {
    result[0] = idiv(ia[0], ib[0], s[0]);
  }
  if (cond[1]) {
    result[1] = idiv(ia[1], ib[1], s[1]);
  }
  if (cond[2]) {
    result[2] = idiv(ia[2], ib[2], s[2]);
  }
  if (cond[3]) {
    result[3] = idiv(ia[3], ib[3], s[3]);
  }
  return vec4(result);
`;
  var floorDiv3 = binaryKernelFunc2({ opSnippet: INT_DIV, packedOpSnippet: INT_DIV_PACKED, dtype: "int32" });
  var floorDivConfig2 = {
    kernelName: FloorDiv,
    backendName: "webgl",
    kernelFunc: floorDiv3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FromPixels_utils/from_pixels_gpu.js
  var FromPixelsProgram = class {
    constructor(outputShape) {
      this.variableNames = ["A"];
      const glsl = getGlslDifferences();
      const [height, width] = outputShape;
      this.outputShape = outputShape;
      this.userCode = `
      void main() {
        ivec3 coords = getOutputCoords();
        int texR = coords[0];
        int texC = coords[1];
        int depth = coords[2];
        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${width}.0, ${height}.0);

        vec4 values = ${glsl.texture2D}(A, uv);
        float value;
        if (depth == 0) {
          value = values.r;
        } else if (depth == 1) {
          value = values.g;
        } else if (depth == 2) {
          value = values.b;
        } else if (depth == 3) {
          value = values.a;
        }

        setOutput(floor(value * 255.0 + 0.5));
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FromPixels_utils/from_pixels_packed_gpu.js
  var FromPixelsPackedProgram = class {
    constructor(outputShape) {
      this.variableNames = ["A"];
      this.packedInputs = false;
      this.packedOutput = true;
      const glsl = getGlslDifferences();
      const [height, width] = outputShape;
      this.outputShape = outputShape;
      this.userCode = `
      void main() {
        ivec3 coords = getOutputCoords();
        int texR = coords[0];
        int texC = coords[1];
        int depth = coords[2];

        vec4 result = vec4(0.);

        for(int row=0; row<=1; row++) {
          for(int col=0; col<=1; col++) {
            texC = coords[1] + row;
            depth = coords[2] + col;

            vec2 uv = (vec2(texC, texR) + halfCR) /
                       vec2(${width}.0, ${height}.0);
            vec4 values = ${glsl.texture2D}(A, uv);
            float value;
            if (depth == 0) {
              value = values.r;
            } else if (depth == 1) {
              value = values.g;
            } else if (depth == 2) {
              value = values.b;
            } else if (depth == 3) {
              value = values.a;
            }

            result[row * 2 + col] = floor(value * 255.0 + 0.5);
          }
        }

        ${glsl.output} = result;
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FromPixels.js
  var fromPixelsConfig = {
    kernelName: FromPixels,
    backendName: "webgl",
    kernelFunc: fromPixels
  };
  var fromPixels2DContext;
  function fromPixels(args) {
    const { inputs, backend: backend2, attrs } = args;
    let { pixels } = inputs;
    const { numChannels } = attrs;
    const isVideo = typeof HTMLVideoElement !== "undefined" && pixels instanceof HTMLVideoElement;
    const isImage = typeof HTMLImageElement !== "undefined" && pixels instanceof HTMLImageElement;
    const [width, height] = isVideo ? [
      pixels.videoWidth,
      pixels.videoHeight
    ] : [pixels.width, pixels.height];
    const texShape = [height, width];
    const outShape = [height, width, numChannels];
    if (isImage || isVideo) {
      if (fromPixels2DContext == null) {
        fromPixels2DContext = document.createElement("canvas").getContext("2d");
      }
      fromPixels2DContext.canvas.width = width;
      fromPixels2DContext.canvas.height = height;
      fromPixels2DContext.drawImage(pixels, 0, 0, width, height);
      pixels = fromPixels2DContext.canvas;
    }
    const tempPixelHandle = backend2.makeTensorInfo(texShape, "int32");
    backend2.texData.get(tempPixelHandle.dataId).usage = TextureUsage.PIXELS;
    backend2.gpgpu.uploadPixelDataToTexture(backend2.getTexture(tempPixelHandle.dataId), pixels);
    const program = env().getBool("WEBGL_PACK") ? new FromPixelsPackedProgram(outShape) : new FromPixelsProgram(outShape);
    const res = backend2.runWebGLProgram(program, [tempPixelHandle], "int32");
    backend2.disposeData(tempPixelHandle.dataId);
    return res;
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FusedConv2D.js
  function fusedConv2d(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, filter, bias, preluActivationWeights } = inputs;
    const { strides, pad: pad2, dataFormat, dilations, dimRoundingMode, activation, leakyreluAlpha } = attrs;
    const $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
    const convInfo = backend_util_exports.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad2, dimRoundingMode, false, $dataFormat);
    let out;
    const intermediates = [];
    if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 && convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 && convInfo.strideHeight === 1 && convInfo.strideWidth === 1 && (convInfo.padInfo.type === "SAME" || convInfo.padInfo.type === "VALID")) {
      out = conv2dByMatMul({
        x,
        filter,
        convInfo,
        backend: backend2,
        bias,
        activation,
        preluActivationWeights,
        leakyreluAlpha
      });
    } else if (env().getBool("WEBGL_CONV_IM2COL") && x.shape[0] === 1) {
      out = conv2dWithIm2Row({
        x,
        filter,
        convInfo,
        backend: backend2,
        bias,
        activation,
        preluActivationWeights,
        leakyreluAlpha
      });
    } else {
      const hasBias = bias != null;
      const hasPreluActivationWeights = preluActivationWeights != null;
      const hasLeakyreluAlpha = activation === "leakyrelu";
      const fusedActivation = activation ? mapActivationToShaderProgram(activation, false) : null;
      const program = new Conv2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
      const inputs2 = [x, filter];
      if (bias) {
        inputs2.push(bias);
      }
      if (preluActivationWeights) {
        inputs2.push(preluActivationWeights);
      }
      if (hasLeakyreluAlpha) {
        const $leakyreluAlpha = backend2.makeTensorInfo([], "float32", util_exports.createScalarValue(leakyreluAlpha, "float32"));
        inputs2.push($leakyreluAlpha);
        intermediates.push($leakyreluAlpha);
      }
      out = backend2.runWebGLProgram(program, inputs2, "float32");
    }
    const outReshaped = reshape3({ inputs: { x: out }, backend: backend2, attrs: { shape: convInfo.outShape } });
    intermediates.push(out);
    intermediates.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
    return outReshaped;
  }
  var fusedConv2DConfig2 = {
    kernelName: FusedConv2D,
    backendName: "webgl",
    kernelFunc: fusedConv2d
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FusedDepthwiseConv2D.js
  function fusedDepthwiseConv2D2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, filter, bias, preluActivationWeights } = inputs;
    const { strides, pad: pad2, dilations, dimRoundingMode, activation, leakyreluAlpha } = attrs;
    const intermediates = [];
    let $dilations = dilations;
    if ($dilations == null) {
      $dilations = [1, 1];
    }
    util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(strides, $dilations), () => `Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${strides} and dilations '${$dilations}'`);
    const convInfo = backend_util_exports.computeConv2DInfo(x.shape, filter.shape, strides, $dilations, pad2, dimRoundingMode, true);
    const shouldPackDepthwiseConv = env().getBool("WEBGL_PACK_DEPTHWISECONV") && convInfo.strideWidth <= 2 && convInfo.outChannels / convInfo.inChannels === 1;
    const fusedActivation = activation ? mapActivationToShaderProgram(activation, shouldPackDepthwiseConv) : null;
    const programInputs = [x, filter];
    const hasBias = bias != null;
    const hasPreluActivationWeights = preluActivationWeights != null;
    const hasLeakyreluAlpha = activation === "leakyrelu";
    if (hasBias) {
      programInputs.push(bias);
    }
    if (hasPreluActivationWeights) {
      programInputs.push(preluActivationWeights);
    }
    if (hasLeakyreluAlpha) {
      const $leakyreluAlpha = backend2.makeTensorInfo([], "float32", util_exports.createScalarValue(leakyreluAlpha, "float32"));
      programInputs.push($leakyreluAlpha);
      intermediates.push($leakyreluAlpha);
    }
    let program;
    if (shouldPackDepthwiseConv) {
      program = new DepthwiseConvPacked2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
    } else {
      program = new DepthwiseConv2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
    }
    const customValues = [
      [convInfo.padInfo.top, convInfo.padInfo.left],
      [convInfo.strideHeight, convInfo.strideWidth],
      [convInfo.dilationHeight, convInfo.dilationWidth],
      [convInfo.inHeight, convInfo.inWidth]
    ];
    const result = backend2.runWebGLProgram(program, programInputs, "float32", customValues);
    intermediates.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
    return result;
  }
  var fusedDepthwiseConv2DConfig2 = {
    kernelName: FusedDepthwiseConv2D,
    backendName: "webgl",
    kernelFunc: fusedDepthwiseConv2D2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/gather_nd_gpu.js
  var GatherNDProgram = class {
    constructor(sliceDim, strides, shape) {
      this.sliceDim = sliceDim;
      this.strides = strides;
      this.variableNames = ["x", "indices"];
      this.outputShape = shape;
      const stridesType = getCoordsDataType(strides.length);
      const dtype = getCoordsDataType(shape.length);
      const strideString = this.sliceDim > 1 ? "strides[j]" : "strides";
      this.userCode = `
        ${stridesType} strides = ${stridesType}(${this.strides});
         void main() {
          ${dtype} coords = getOutputCoords();
          int flattenIndex = 0;
          for (int j = 0; j < ${this.sliceDim}; j++) {
            int index = round(getIndices(coords[0], j));
            flattenIndex += index * ${strideString};
          }
          setOutput(getX(flattenIndex, coords[1]));
        }
      `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/GatherNd.js
  function gatherNd2(args) {
    const { inputs, backend: backend2 } = args;
    const { params, indices } = inputs;
    const indicesShape = indices.shape;
    const sliceRank = indicesShape[indicesShape.length - 1];
    const paramsSize = util_exports.sizeFromShape(params.shape);
    const [resultShape, numSlices, sliceSize, strides] = backend_util_exports.prepareAndValidate(params, indices);
    const flattenIndices = reshape3({ inputs: { x: indices }, backend: backend2, attrs: { shape: [numSlices, sliceRank] } });
    const flattenX = reshape3({
      inputs: { x: params },
      backend: backend2,
      attrs: { shape: [util_exports.sizeFromShape(params.shape) / sliceSize, sliceSize] }
    });
    if (backend2.shouldExecuteOnCPU([params, indices]) || params.dtype === "string") {
      const indicesData = backend2.readSync(indices.dataId);
      const paramsBuf = backend2.bufferSync(params);
      const outValue = gatherNdImplCPU(indicesData, paramsBuf, params.dtype, numSlices, sliceRank, sliceSize, strides, params.shape, paramsSize);
      return backend2.makeTensorInfo(resultShape, params.dtype, outValue.values);
    }
    const program = new GatherNDProgram(sliceRank, strides, [numSlices, sliceSize]);
    const res = backend2.runWebGLProgram(program, [flattenX, flattenIndices], flattenX.dtype);
    const reshaped = reshape3({ inputs: { x: res }, backend: backend2, attrs: { shape: resultShape } });
    backend2.disposeIntermediateTensorInfo(flattenIndices);
    backend2.disposeIntermediateTensorInfo(flattenX);
    backend2.disposeIntermediateTensorInfo(res);
    return reshaped;
  }
  var gatherNdConfig2 = {
    kernelName: GatherNd,
    backendName: "webgl",
    kernelFunc: gatherNd2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/gather_gpu.js
  var GatherProgram = class {
    constructor(aShape, outputShape) {
      this.variableNames = ["A", "indices"];
      this.outputShape = outputShape;
      this.rank = outputShape.length;
      const dtype = getCoordsDataType(this.rank);
      const sourceCoords = getSourceCoords2(aShape, 2);
      this.userCode = `
      void main() {
        ${dtype} resRC = getOutputCoords();
        setOutput(getA(${sourceCoords}));
      }
    `;
    }
  };
  function getSourceCoords2(aShape, axis) {
    const currentCoords = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"];
    const sourceCoords = [];
    for (let i = 0; i < aShape.length; i++) {
      if (i === 2) {
        sourceCoords.push("int(getIndices(resRC.x, resRC.z))");
      } else {
        sourceCoords.push(`${currentCoords[i]}`);
      }
    }
    return sourceCoords.join();
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/GatherV2.js
  function gatherV22(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, indices } = inputs;
    const { axis, batchDims } = attrs;
    const parsedAxis = util_exports.parseAxisParam(axis, x.shape)[0];
    const indicesVals = backend2.readSync(indices.dataId);
    const axisDim = x.shape[parsedAxis];
    for (let i = 0; i < indicesVals.length; ++i) {
      const index = indicesVals[i];
      util_exports.assert(index <= axisDim - 1 && index >= 0, () => `GatherV2: the index value ${index} is not in [0, ${axisDim - 1}]`);
    }
    const shapeInfo = backend_util_exports.segment_util.collectGatherOpShapeInfo(x, indices, parsedAxis, batchDims);
    const indicesSize = util_exports.sizeFromShape(indices.shape);
    const toDispose = [];
    const flattenX = reshape3({
      inputs: { x },
      backend: backend2,
      attrs: {
        shape: [
          shapeInfo.batchSize,
          shapeInfo.outerSize,
          shapeInfo.dimSize,
          shapeInfo.sliceSize
        ]
      }
    });
    const flattenIndex = reshape3({
      inputs: { x: indices },
      backend: backend2,
      attrs: { shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize] }
    });
    toDispose.push(flattenX);
    toDispose.push(flattenIndex);
    const flattenOutputShape = [
      shapeInfo.batchSize,
      shapeInfo.outerSize,
      indicesSize / shapeInfo.batchSize,
      shapeInfo.sliceSize
    ];
    if (backend2.shouldExecuteOnCPU([x, indices]) || x.dtype === "string") {
      const indicesBuf = backend2.bufferSync(flattenIndex);
      const xBuf = backend2.bufferSync(flattenX);
      const outBuf = gatherV2ImplCPU(xBuf, indicesBuf, flattenOutputShape);
      toDispose.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
      return backend2.makeTensorInfo(shapeInfo.outputShape, outBuf.dtype, outBuf.values);
    }
    const program = new GatherProgram(flattenX.shape, flattenOutputShape);
    const res = backend2.runWebGLProgram(program, [flattenX, flattenIndex], flattenX.dtype);
    toDispose.push(res);
    const reshaped = reshape3({ inputs: { x: res }, backend: backend2, attrs: { shape: shapeInfo.outputShape } });
    toDispose.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
    return reshaped;
  }
  var gatherV2Config2 = {
    kernelName: GatherV2,
    backendName: "webgl",
    kernelFunc: gatherV22
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Greater.js
  var GREATER = `return float(a > b);`;
  var GREATER_PACKED = `
  return vec4(greaterThan(a, b));
`;
  var greater3 = binaryKernelFunc2({
    opSnippet: GREATER,
    packedOpSnippet: GREATER_PACKED,
    cpuKernelImpl: greaterImplCPU,
    dtype: "bool"
  });
  var greaterConfig2 = {
    kernelName: Greater,
    backendName: "webgl",
    kernelFunc: greater3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/GreaterEqual.js
  var GREATER_EQUAL = `return float(a >= b);`;
  var GREATER_EQUAL_PACKED = `
  return vec4(greaterThanEqual(a, b));
`;
  var greaterEqual3 = binaryKernelFunc2({
    opSnippet: GREATER_EQUAL,
    packedOpSnippet: GREATER_EQUAL_PACKED,
    dtype: "bool",
    cpuKernelImpl: greaterEqualImplCPU
  });
  var greaterEqualConfig2 = {
    kernelName: GreaterEqual,
    backendName: "webgl",
    kernelFunc: greaterEqual3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/IFFT.js
  function ifft3(args) {
    const { inputs, backend: backend2 } = args;
    const { input: input2 } = inputs;
    return fftImpl2(input2, true, backend2);
  }
  var ifftConfig2 = {
    kernelName: IFFT,
    backendName: "webgl",
    kernelFunc: ifft3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/IsFinite.js
  var IS_FINITE = `return float(!isnan(x) && !isinf(x));`;
  var isFinite4 = unaryKernelFunc2({ opSnippet: IS_FINITE, dtype: "bool" });
  var isFiniteConfig2 = {
    kernelName: IsFinite,
    backendName: "webgl",
    kernelFunc: isFinite4
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/IsInf.js
  var IS_INF = `return float(isinf(x));`;
  var isInf3 = unaryKernelFunc2({ opSnippet: IS_INF, dtype: "bool" });
  var isInfConfig2 = {
    kernelName: IsInf,
    backendName: "webgl",
    kernelFunc: isInf3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/IsNaN.js
  var IS_NAN = `return float(isnan(x));`;
  var isNaN4 = unaryKernelFunc2({ opSnippet: IS_NAN, dtype: "bool" });
  var isNaNConfig2 = {
    kernelName: IsNan,
    backendName: "webgl",
    kernelFunc: isNaN4
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Less.js
  var LESS = `return float(a < b);`;
  var LESS_PACKED = `
  return vec4(lessThan(a, b));
`;
  var less3 = binaryKernelFunc2({
    opSnippet: LESS,
    packedOpSnippet: LESS_PACKED,
    cpuKernelImpl: lessImplCPU,
    dtype: "bool"
  });
  var lessConfig2 = {
    kernelName: Less,
    backendName: "webgl",
    kernelFunc: less3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LessEqual.js
  var LESS_EQUAL = `return float(a <= b);`;
  var LESS_EQUAL_PACKED = `
  return vec4(lessThanEqual(a, b));
`;
  var lessEqual3 = binaryKernelFunc2({
    opSnippet: LESS_EQUAL,
    packedOpSnippet: LESS_EQUAL_PACKED,
    cpuKernelImpl: lessEqualImplCPU,
    dtype: "bool"
  });
  var lessEqualConfig2 = {
    kernelName: LessEqual,
    backendName: "webgl",
    kernelFunc: lessEqual3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LinSpace.js
  function linSpace2(args) {
    const { backend: backend2, attrs } = args;
    const { start, stop: stop2, num } = attrs;
    const outVals = linSpaceImplCPU(start, stop2, num);
    return backend2.makeTensorInfo([outVals.length], "float32", outVals);
  }
  var linSpaceConfig2 = {
    kernelName: LinSpace,
    backendName: "webgl",
    kernelFunc: linSpace2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Log.js
  var LOG = `if (x < 0.0) return NAN;
  return log(x);`;
  var LOG_PACKED = `
  vec4 result = log(x);
  vec4 isNaN = vec4(lessThan(x, vec4(0.0)));
  result.r = isNaN.r == 1.0 ? NAN : result.r;
  result.g = isNaN.g == 1.0 ? NAN : result.g;
  result.b = isNaN.b == 1.0 ? NAN : result.b;
  result.a = isNaN.a == 1.0 ? NAN : result.a;

  return result;
`;
  var log7 = unaryKernelFunc2({ opSnippet: LOG, packedOpSnippet: LOG_PACKED, cpuKernelImpl: logImplCPU });
  var logConfig2 = {
    kernelName: Log,
    backendName: "webgl",
    kernelFunc: log7
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Log1p.js
  var LOG1P = `return log(1.0 + x);`;
  var log1p3 = unaryKernelFunc2({ opSnippet: LOG1P });
  var log1pConfig2 = {
    kernelName: Log1p,
    backendName: "webgl",
    kernelFunc: log1p3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LogicalAnd.js
  var LOGICAL_AND = `return float(a >= 1.0 && b >= 1.0);`;
  var LOGICAL_AND_PACKED = `
  return vec4(
    vec4(greaterThanEqual(a, vec4(1.0))) *
    vec4(greaterThanEqual(b, vec4(1.0))));
`;
  var logicalAnd3 = binaryKernelFunc2({
    opSnippet: LOGICAL_AND,
    packedOpSnippet: LOGICAL_AND_PACKED,
    dtype: "bool"
  });
  var logicalAndConfig2 = {
    kernelName: LogicalAnd,
    backendName: "webgl",
    kernelFunc: logicalAnd3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LogicalNot.js
  var LOGICAL_NOT = `return float(!(x >= 1.0));`;
  var logicalNot3 = unaryKernelFunc2({ opSnippet: LOGICAL_NOT });
  var logicalNotConfig2 = {
    kernelName: LogicalNot,
    backendName: "webgl",
    kernelFunc: logicalNot3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LogicalOr.js
  var LOGICAL_OR = `return float(a >= 1.0 || b >= 1.0);`;
  var LOGICAL_OR_PACKED = `
  return min(
    vec4(greaterThanEqual(a, vec4(1.0))) +
    vec4(greaterThanEqual(b, vec4(1.0))),
    vec4(1.0));
`;
  var logicalOr3 = binaryKernelFunc2({ opSnippet: LOGICAL_OR, packedOpSnippet: LOGICAL_OR_PACKED, dtype: "bool" });
  var logicalOrConfig2 = {
    kernelName: LogicalOr,
    backendName: "webgl",
    kernelFunc: logicalOr3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/lrn_gpu.js
  var LRNProgram = class {
    constructor(xShape, radius, bias, alpha, beta) {
      this.variableNames = ["x"];
      this.outputShape = [];
      const rad = radius;
      const maxD = xShape[3] - 1;
      this.outputShape = xShape;
      let powOperator;
      const basis = `float(${bias}) + float(${alpha}) * sum`;
      if (beta === 0.5) {
        powOperator = `inversesqrt(${basis})`;
      } else if (beta === 1) {
        powOperator = `1.0/(${basis})`;
      } else {
        powOperator = `exp(log(${basis}) * float(-${beta}));`;
      }
      this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int r = coords[1];
        int c = coords[2];
        int d = coords[3];
        float x = getX(b, r, c, d);
        float sum = 0.0;
        for (int j = -${rad}; j <= ${rad}; j++) {
          int idx = d + j;
          if (idx >= 0 && idx <=  ${maxD}) {
            float z = getX(b, r, c, idx);
            sum += z * z;
          }
        }
        float val = x * ${powOperator};
        setOutput(val);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/lrn_packed_gpu.js
  var LRNPackedProgram = class {
    constructor(xShape, radius, bias, alpha, beta) {
      this.variableNames = ["x"];
      this.outputShape = [];
      this.packedInputs = true;
      this.packedOutput = true;
      const rad = radius;
      const maxD = xShape[3] - 1;
      this.outputShape = xShape;
      let powOperator;
      const basis = `float(${bias}) + float(${alpha}) * sum`;
      if (beta === 0.5) {
        powOperator = `inversesqrt(${basis})`;
      } else if (beta === 1) {
        powOperator = `1.0/(${basis})`;
      } else {
        powOperator = `exp(log(${basis}) * float(-${beta}));`;
      }
      this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords.x;
        int r = coords.y;
        int c = coords.z;
        int d = coords.w;

        bool hasNextCol = d < ${this.outputShape[3]};
        bool hasNextRow = c < ${this.outputShape[2]};

        vec4 sum = vec4(0.);
        vec4 xFragAtOutputCoords = getX(b, r, c, d);

        vec4 xAtOutputCoords = vec4(
          getChannel(xFragAtOutputCoords, vec2(c, d)),
          hasNextCol ?
            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,
          hasNextRow ?
            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,
          (hasNextRow && hasNextCol) ?
            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0
        );

        int firstChannel = d - ${rad};
        vec2 cache = vec2(0.);
        if(firstChannel >= 0){
          vec4 firstChannelFrag = getX(b, r, c, firstChannel);
          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));
            if(hasNextRow){
              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));
            }
        }

        ivec2 depth = ivec2(d, d + 1);
        for (int j = - ${rad}; j <= ${rad}; j++) {
          ivec2 idx = depth + j;
          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));
          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(${maxD}));

          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;
          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;

          if(depthInRange || depthPlusOneInRange){
            vec4 z = vec4(0.);
            vec4 xFragAtCurrentDepth;
            z.xz = cache.xy;
            if(depthPlusOneInRange && hasNextCol){
              xFragAtCurrentDepth = idx.y != d ?
                getX(b, r, c, idx.y) : xFragAtOutputCoords;
              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));
              if(hasNextRow){
                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));
              }
            }
            cache.xy = z.yw;
            sum += z * z;
          }
        }
        vec4 result = xAtOutputCoords * ${powOperator};
        setOutput(result);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LRN.js
  var lrn = (args) => {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { depthRadius, bias, alpha, beta } = attrs;
    const program = env().getBool("WEBGL_PACK_NORMALIZATION") ? new LRNPackedProgram(x.shape, depthRadius, bias, alpha, beta) : new LRNProgram(x.shape, depthRadius, bias, alpha, beta);
    return backend2.runWebGLProgram(program, [x], x.dtype);
  };
  var LRNConfig = {
    kernelName: LRN,
    backendName: "webgl",
    kernelFunc: lrn
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/lrn_grad_gpu.js
  var LRNGradProgram = class {
    constructor(inputShape, depthRadius, bias, alpha, beta) {
      this.variableNames = ["inputImage", "outputImage", "dy"];
      this.outputShape = [];
      this.outputShape = inputShape;
      this.depth = inputShape[3];
      this.depthRadius = depthRadius;
      this.bias = bias;
      this.alpha = alpha;
      this.beta = beta;
      this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int r = coords[1];
        int c = coords[2];

        float result = 0.0;
        for (int d = 0; d < ${this.depth}; ++d) {
          int depthBegin = int(max(0.0, float(d - ${depthRadius})));
          int depthEnd = int(min(float(${this.depth}),
              float(d + ${depthRadius} + 1)));

          const int MIN_DEPTH_BEGIN = 0;
          const int MAX_DEPTH_END = ${this.depth};

          float norm = 0.0;
          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {
            if (k < depthBegin){
              continue;
            }
            else if (k >= depthBegin && k < depthEnd) {
              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);
            }
            else {
              break;
            }
          }

          norm = float(${alpha}) * norm + float(${bias});

          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){
            if (k < depthBegin){
              continue;
            }
            else if (k >= depthBegin && k < depthEnd){
              float dyi = -2.0 * float(${alpha})
                * float(${beta})
                * getInputImage(b ,r ,c, k) * getOutputImage(b, r, c, d)
                / norm;
              if (k == d) {
                dyi += pow(norm, -1.0 * ${beta});
              }
              if (k == coords[3]) {
                dyi *= getDy(b, r, c, d);
                result += dyi;
              }
            }
            else {
              break;
            }
          }
      }
      setOutput(result);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LRNGrad.js
  var lrnGrad = (args) => {
    const { inputs, backend: backend2, attrs } = args;
    const { x, y, dy } = inputs;
    const { depthRadius, bias, alpha, beta } = attrs;
    const program = new LRNGradProgram(x.shape, depthRadius, bias, alpha, beta);
    return backend2.runWebGLProgram(program, [x, y, dy], x.dtype);
  };
  var LRNGradConfig = {
    kernelName: LRNGrad,
    backendName: "webgl",
    kernelFunc: lrnGrad
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Max_impl.js
  function maxImpl2(x, reduceShape, outShape, backend2) {
    const inSize = util_exports.sizeFromShape(reduceShape);
    const xSize = util_exports.sizeFromShape(x.shape);
    const batchSize = xSize / inSize;
    const reshapedInput = reshape3({ inputs: { x }, attrs: { shape: [batchSize, inSize] }, backend: backend2 });
    const reduced = reduce(reshapedInput, x.dtype, "max", backend2);
    const reshapedOutput = reshape3({ inputs: { x: reduced }, attrs: { shape: outShape }, backend: backend2 });
    backend2.disposeIntermediateTensorInfo(reshapedInput);
    backend2.disposeIntermediateTensorInfo(reduced);
    return reshapedOutput;
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Max.js
  function max4(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { reductionIndices, keepDims } = attrs;
    const xRank = x.shape.length;
    const origAxes = util_exports.parseAxisParam(reductionIndices, x.shape);
    let axes = origAxes;
    const permutedAxes = backend_util_exports.getAxesPermutation(axes, xRank);
    const maxInputIsTransposed = permutedAxes != null;
    const shouldExecuteOnCPU = backend2.shouldExecuteOnCPU([x]);
    let maxInput = x;
    if (maxInputIsTransposed) {
      if (shouldExecuteOnCPU) {
        const xTexData = backend2.texData.get(maxInput.dataId);
        const values = xTexData.values;
        const newShape = new Array(xRank);
        for (let i = 0; i < newShape.length; i++) {
          newShape[i] = x.shape[permutedAxes[i]];
        }
        const maxInputValues = transposeImplCPU(values, x.shape, x.dtype, permutedAxes, newShape);
        maxInput = backend2.makeTensorInfo(newShape, x.dtype);
        const maxInputData = backend2.texData.get(maxInput.dataId);
        maxInputData.values = maxInputValues;
      } else {
        maxInput = transposeImpl2(x, permutedAxes, backend2);
      }
      axes = backend_util_exports.getInnerMostAxes(axes.length, xRank);
    }
    backend_util_exports.assertAxesAreInnerMostDims("max", axes, xRank);
    const [maxOutShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(maxInput.shape, axes);
    let outShape = maxOutShape;
    if (keepDims) {
      outShape = backend_util_exports.expandShapeToKeepDim(maxOutShape, origAxes);
    }
    let out;
    if (shouldExecuteOnCPU) {
      const xTexData = backend2.texData.get(maxInput.dataId);
      const values = xTexData.values;
      const outValues = maxImplCPU(values, util_exports.sizeFromShape(reduceShape), outShape, x.dtype);
      out = backend2.makeTensorInfo(outShape, x.dtype);
      const outData = backend2.texData.get(out.dataId);
      outData.values = outValues;
    } else {
      out = maxImpl2(maxInput, reduceShape, outShape, backend2);
    }
    if (maxInputIsTransposed) {
      backend2.disposeIntermediateTensorInfo(maxInput);
    }
    return out;
  }
  var maxConfig2 = {
    kernelName: Max,
    backendName: "webgl",
    kernelFunc: max4
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Maximum.js
  var MAXIMUM = CHECK_NAN_SNIPPET2 + `
  return max(a, b);
`;
  var MAXIMUM_PACKED = `
  vec4 result = vec4(max(a, b));
  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));
  ` + CHECK_NAN_SNIPPET3 + `
  return result;
`;
  var maximum3 = binaryKernelFunc2({
    opSnippet: MAXIMUM,
    packedOpSnippet: MAXIMUM_PACKED,
    cpuKernelImpl: maximumImplCPU
  });
  var maximumConfig2 = {
    kernelName: Maximum,
    backendName: "webgl",
    kernelFunc: maximum3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPool.js
  function maxPool3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    assertNotComplex2(x, "maxPool");
    const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
    const dilations = 1;
    util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
    const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode);
    if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 && util_exports.arraysEqual(convInfo.inShape, convInfo.outShape)) {
      return identity2({ inputs: { x }, backend: backend2 });
    }
    const maxPoolProgram = new Pool2DProgram(convInfo, "max", false);
    return backend2.runWebGLProgram(maxPoolProgram, [x], x.dtype);
  }
  var maxPoolConfig2 = {
    kernelName: MaxPool,
    backendName: "webgl",
    kernelFunc: maxPool3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPool3D.js
  function maxPool3d2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { filterSize, strides, pad: pad2, dataFormat, dimRoundingMode } = attrs;
    const dilations = [1, 1, 1];
    const convInfo = backend_util_exports.computePool3DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode, dataFormat);
    const maxPoolProgram = new Pool3DProgram(convInfo, "max", false);
    return backend2.runWebGLProgram(maxPoolProgram, [x], x.dtype);
  }
  var maxPool3DConfig2 = {
    kernelName: MaxPool3D,
    backendName: "webgl",
    kernelFunc: maxPool3d2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/max_pool_backprop_gpu.js
  var MaxPool2DBackpropProgram = class {
    constructor(convInfo) {
      this.variableNames = ["dy", "maxPos"];
      this.outputShape = convInfo.inShape;
      const strideHeight = convInfo.strideHeight;
      const strideWidth = convInfo.strideWidth;
      const dilationHeight = convInfo.dilationHeight;
      const effectiveFilterHeight = convInfo.effectiveFilterHeight;
      const effectiveFilterWidth = convInfo.effectiveFilterWidth;
      const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
      const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
      const lastIndex = effectiveFilterHeight * effectiveFilterWidth - 1;
      this.userCode = `
      const ivec2 pads = ivec2(${padTop}, ${padLeft});

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];

        ivec2 dyRCCorner = coords.yz - pads;
        int dyRCorner = dyRCCorner.x;
        int dyCCorner = dyRCCorner.y;

        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${effectiveFilterHeight};
          wR += ${dilationHeight}) {
          float dyR = float(dyRCorner + wR) / ${strideHeight}.0;

          if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          for (int wC = 0; wC < ${effectiveFilterWidth}; wC++) {
            float dyC = float(dyCCorner + wC) / ${strideWidth}.0;

            if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            float dyValue = getDy(b, idyR, idyC, d);
            int maxPosValue = ${lastIndex} - int(getMaxPos(b, idyR, idyC, d));

            // Get the current value, check it against the value from the
            // position matrix.
            int curPosValue = wR * ${effectiveFilterWidth} + wC;
            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);

            dotProd += dyValue * mask;
          }
        }
        setOutput(dotProd);
      }
    `;
    }
  };
  var MaxPool3DBackpropProgram = class {
    constructor(convInfo) {
      this.variableNames = ["dy", "maxPos"];
      this.outputShape = convInfo.inShape;
      const strideDepth = convInfo.strideDepth;
      const strideHeight = convInfo.strideHeight;
      const strideWidth = convInfo.strideWidth;
      const dilationDepth = convInfo.dilationDepth;
      const dilationHeight = convInfo.dilationHeight;
      const dilationWidth = convInfo.dilationWidth;
      const effectiveFilterDepth = convInfo.effectiveFilterDepth;
      const effectiveFilterHeight = convInfo.effectiveFilterHeight;
      const effectiveFilterWidth = convInfo.effectiveFilterWidth;
      const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;
      const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
      const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
      const lastIndex = effectiveFilterDepth * effectiveFilterHeight * effectiveFilterWidth - 1;
      this.userCode = `
      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int ch = coords.u;

        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;
        int dyDCorner = dyCorner.x;
        int dyRCorner = dyCorner.y;
        int dyCCorner = dyCorner.z;

        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get
        // dx(xD, xR, xC, ch).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;

        for (int wD = 0; wD < ${effectiveFilterDepth};
           wD += ${dilationDepth}) {
          float dyD = float(dyDCorner + wD) / ${strideDepth}.0;

          if (dyD < 0.0 || dyD >= ${convInfo.outDepth}.0 || fract(dyD) > 0.0) {
            continue;
          }
          int idyD = int(dyD);

          for (int wR = 0; wR < ${effectiveFilterHeight};
              wR += ${dilationHeight}) {
            float dyR = float(dyRCorner + wR) / ${strideHeight}.0;

            if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 ||
                fract(dyR) > 0.0) {
              continue;
            }
            int idyR = int(dyR);

            for (int wC = 0; wC < ${effectiveFilterWidth};
                wC += ${dilationWidth}) {
              float dyC = float(dyCCorner + wC) / ${strideWidth}.0;

              if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||
                  fract(dyC) > 0.0) {
                continue;
              }
              int idyC = int(dyC);

              float dyValue = getDy(batch, idyD, idyR, idyC, ch);
              int maxPosValue = ${lastIndex} -
                  int(getMaxPos(batch, idyD, idyR, idyC, ch));

              // Get the current value, check it against the value from the
              // position matrix.
              int curPosValue =
                  wD * ${effectiveFilterHeight} * ${effectiveFilterWidth} +
                  wR * ${effectiveFilterWidth} + wC;
              float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);

              dotProd += dyValue * mask;
            }
          }
        }
        setOutput(dotProd);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPool3DGrad.js
  function maxPool3DGrad2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { dy, input: input2 } = inputs;
    const x = input2;
    const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
    const dilations = [1, 1, 1];
    const convInfo = backend_util_exports.computePool3DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode);
    const maxPool3dPositionsProgram = new Pool3DProgram(convInfo, "max", true);
    const maxPool3dPositions2 = backend2.runWebGLProgram(maxPool3dPositionsProgram, [x], x.dtype);
    const maxPoolBackpropProgram = new MaxPool3DBackpropProgram(convInfo);
    const result = backend2.runWebGLProgram(maxPoolBackpropProgram, [dy, maxPool3dPositions2], x.dtype);
    backend2.disposeIntermediateTensorInfo(maxPool3dPositions2);
    return result;
  }
  var maxPoolGrad3DConfig = {
    kernelName: MaxPool3DGrad,
    backendName: "webgl",
    kernelFunc: maxPool3DGrad2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPoolGrad.js
  function maxPoolGrad3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { dy, input: input2, output } = inputs;
    const x = input2;
    assertNotComplex2([input2, output], "maxPoolGrad");
    const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
    const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, 1, pad2, dimRoundingMode);
    const getPositions = true;
    const maxPoolPositionsProgram = new Pool2DProgram(convInfo, "max", getPositions);
    const maxPoolPositions2 = backend2.runWebGLProgram(maxPoolPositionsProgram, [x], x.dtype);
    const maxPoolBackPropProgram = new MaxPool2DBackpropProgram(convInfo);
    const result = backend2.runWebGLProgram(maxPoolBackPropProgram, [dy, maxPoolPositions2], x.dtype);
    backend2.disposeIntermediateTensorInfo(maxPoolPositions2);
    return result;
  }
  var maxPoolGradConfig3 = {
    kernelName: MaxPoolGrad,
    backendName: "webgl",
    kernelFunc: maxPoolGrad3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPoolWithArgmax_impl.js
  function maxPoolWithArgmaxImpl2(x, includeBatchInIndex, convInfo, backend2) {
    let program = new Pool2DProgram(convInfo, "max", false);
    const poolOutput = backend2.runWebGLProgram(program, [x], "float32");
    program = new Pool2DProgram(convInfo, "max", true, true, includeBatchInIndex);
    const indexOutput = backend2.runWebGLProgram(program, [x], "float32");
    return [poolOutput, indexOutput];
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPoolWithArgmax.js
  var maxPoolWithArgmaxConfig2 = {
    kernelName: MaxPoolWithArgmax,
    backendName: "webgl",
    kernelFunc: ({ inputs, attrs, backend: backend2 }) => {
      const { x } = inputs;
      const { filterSize, strides, pad: pad2, includeBatchInIndex } = attrs;
      const webglBackend = backend2;
      util_exports.assert(x.shape.length === 4, () => `Error in maxPool: input must be rank 4 but got rank ${x.shape.length}.`);
      const dilations = [1, 1];
      util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
      const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, dilations, pad2);
      const [result, indexes] = maxPoolWithArgmaxImpl2(x, includeBatchInIndex, convInfo, webglBackend);
      return [result, indexes];
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Mean_impl.js
  function meanImpl(x, reduceShape, outShape, backend2) {
    const inSize = util_exports.sizeFromShape(reduceShape);
    const xSize = util_exports.sizeFromShape(x.shape);
    const batchSize = xSize / inSize;
    const reshapedInput = reshape3({ inputs: { x }, attrs: { shape: [batchSize, inSize] }, backend: backend2 });
    const reduced = reduce(reshapedInput, "float32", "mean", backend2);
    const reshapedOutput = reshape3({ inputs: { x: reduced }, attrs: { shape: outShape }, backend: backend2 });
    backend2.disposeIntermediateTensorInfo(reshapedInput);
    backend2.disposeIntermediateTensorInfo(reduced);
    return reshapedOutput;
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Mean.js
  var meanConfig2 = {
    kernelName: Mean,
    backendName: "webgl",
    kernelFunc: ({ inputs, attrs, backend: backend2 }) => {
      const { x } = inputs;
      const { keepDims, axis } = attrs;
      const webglBackend = backend2;
      const xRank = x.shape.length;
      const origAxes = util_exports.parseAxisParam(axis, x.shape);
      let axes = origAxes;
      const permutedAxes = backend_util_exports.getAxesPermutation(axes, xRank);
      const meanInputIsTransposed = permutedAxes != null;
      const shouldExecuteOnCPU = webglBackend.shouldExecuteOnCPU([x]);
      const intermediates = [];
      let meanInput = x;
      if (meanInputIsTransposed) {
        if (shouldExecuteOnCPU) {
          const xTexData = webglBackend.texData.get(meanInput.dataId);
          const values = xTexData.values;
          const newShape = new Array(xRank);
          for (let i = 0; i < newShape.length; i++) {
            newShape[i] = x.shape[permutedAxes[i]];
          }
          const meanInputValues = transposeImplCPU(values, x.shape, x.dtype, permutedAxes, newShape);
          meanInput = webglBackend.makeTensorInfo(newShape, x.dtype);
          const meanInputData = webglBackend.texData.get(meanInput.dataId);
          meanInputData.values = meanInputValues;
        } else {
          meanInput = transposeImpl2(x, permutedAxes, webglBackend);
        }
        intermediates.push(meanInput);
        axes = backend_util_exports.getInnerMostAxes(axes.length, xRank);
      }
      backend_util_exports.assertAxesAreInnerMostDims("sum", axes, xRank);
      const [meanOutShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(meanInput.shape, axes);
      let outShape = meanOutShape;
      if (keepDims) {
        outShape = backend_util_exports.expandShapeToKeepDim(meanOutShape, origAxes);
      }
      const out = meanImpl(meanInput, reduceShape, outShape, webglBackend);
      for (const i of intermediates) {
        webglBackend.disposeIntermediateTensorInfo(i);
      }
      return out;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Min.js
  function min4(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { axis, keepDims } = attrs;
    const xRank = x.shape.length;
    const origAxes = util_exports.parseAxisParam(axis, x.shape);
    let axes = origAxes;
    const permutedAxes = backend_util_exports.getAxesPermutation(axes, xRank);
    let permutedX = x;
    if (permutedAxes != null) {
      permutedX = transpose3({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
      axes = backend_util_exports.getInnerMostAxes(axes.length, x.shape.length);
    }
    backend_util_exports.assertAxesAreInnerMostDims("min", axes, xRank);
    const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(permutedX.shape, axes);
    const inSize = util_exports.sizeFromShape(reduceShape);
    const a2D = reshape3({ inputs: { x: permutedX }, backend: backend2, attrs: { shape: [-1, inSize] } });
    const reduced = reduce(a2D, a2D.dtype, "min", backend2);
    let res;
    if (keepDims) {
      const newShape = backend_util_exports.expandShapeToKeepDim(outShape, origAxes);
      res = reshape3({ inputs: { x: reduced }, backend: backend2, attrs: { shape: newShape } });
    } else {
      res = reshape3({ inputs: { x: reduced }, backend: backend2, attrs: { shape: outShape } });
    }
    backend2.disposeIntermediateTensorInfo(a2D);
    backend2.disposeIntermediateTensorInfo(reduced);
    if (permutedAxes != null) {
      backend2.disposeIntermediateTensorInfo(permutedX);
    }
    return res;
  }
  var minConfig2 = {
    kernelName: Min,
    backendName: "webgl",
    kernelFunc: min4
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Minimum.js
  var MINIMUM = CHECK_NAN_SNIPPET2 + `
  return min(a, b);
`;
  var MINIMUM_PACKED = `
  vec4 result = vec4(min(a, b));
  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));
  ` + CHECK_NAN_SNIPPET3 + `
  return result;
`;
  var minimum3 = binaryKernelFunc2({
    opSnippet: MINIMUM,
    packedOpSnippet: MINIMUM_PACKED,
    cpuKernelImpl: minimumImplCPU
  });
  var minimumConfig2 = {
    kernelName: Minimum,
    backendName: "webgl",
    kernelFunc: minimum3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/mirror_pad_gpu.js
  var MirrorPadProgram = class {
    constructor(xShape, paddings, mode) {
      this.variableNames = ["x"];
      this.outputShape = paddings.map((p3, i) => p3[0] + xShape[i] + p3[1]);
      const rank = xShape.length;
      const dtype = getCoordsDataType(rank);
      const start = paddings.map((p3) => p3[0]).join(",");
      const end = paddings.map((p3, i) => p3[0] + xShape[i]).join(",");
      const unpackedCoords = ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, rank);
      const offset = mode === "reflect" ? 0 : 1;
      if (rank === 1) {
        this.userCode = `
        int start = ${start};
        int end = ${end};

        void main() {
          int outC = getOutputCoords();
          if (outC < start) {
            outC = start * 2 - outC - ${offset};
          } else if(outC >= end) {
            outC = (end - 1) * 2 - outC + ${offset};
          }
          setOutput(getX(outC - start));
        }
      `;
        return;
      }
      this.userCode = `
      ${dtype} start = ${dtype}(${start});
      ${dtype} end = ${dtype}(${end});

      void main() {
        ${dtype} outC = getOutputCoords();
        for (int i = 0; i < ${rank}; i++) {
          if (outC[i] < start[i]) {
            outC[i] = start[i] * 2 - outC[i] - ${offset};
          } else if(outC[i] >= end[i]) {
            outC[i] = (end[i] - 1) * 2 - outC[i] + ${offset};
          }
        }
        ${dtype} coords = outC - start;
        setOutput(getX(${unpackedCoords}));
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/mirror_pad_packed_gpu.js
  var MirrorPadPackedProgram = class {
    constructor(xShape, paddings, mode) {
      this.variableNames = ["x"];
      this.packedInputs = true;
      this.packedOutput = true;
      this.outputShape = paddings.map((p3, i) => p3[0] + xShape[i] + p3[1]);
      const rank = xShape.length;
      const dtype = getCoordsDataType(rank);
      const start = paddings.map((p3) => p3[0]).join(",");
      const end = paddings.map((p3, i) => p3[0] + xShape[i]).join(",");
      const coords2 = getChannels("rc", rank);
      const source = getChannels("source", rank);
      const cLimit = `${coords2[rank - 1]} < ${this.outputShape[rank - 1]}`;
      const innerDims = rank === 1 ? "source" : `vec2(${source.slice(-2).join()})`;
      const offset = mode === "reflect" ? 0 : 1;
      let mainLoop = "";
      if (rank === 1) {
        const padSetup = `
        ${dtype} source = rc;
        if (source < start) {
          source = start * 2 - source - ${offset};
        } else if (source >= end) {
          source = (end - 1) * 2 - source + ${offset};
        }
        source -= start;
      `;
        mainLoop = `
        ${dtype} rc = outputLoc;
        ${padSetup}
        result[0] = getChannel(getX(${source.join()}), ${innerDims});
        ${coords2[rank - 1]} += 1;
        if(${cLimit}) {
          ${padSetup}
          result[1] = getChannel(getX(${source.join()}), ${innerDims});
        }
      `;
      } else {
        const padSetup = `
        ${dtype} source = rc;
        ${dtype} lt = ${dtype}(lessThan(source, start));
        ${dtype} gte = ${dtype}(greaterThanEqual(source, end));
        ${dtype} orig = 1 - (lt + gte);
        source = orig * source +
                lt * (start * 2 - source - ${offset}) +
                gte * ((end - 1) * 2 - source + ${offset});
        source -= start;
      `;
        mainLoop = `
        ${dtype} rc = outputLoc;
        ${padSetup}
        result[0] = getChannel(getX(${source.join()}), ${innerDims});
        ${coords2[rank - 1]} += 1;
        if(${cLimit}) {
          ${padSetup}
          result[1] = getChannel(getX(${source.join()}), ${innerDims});
        }
        rc = outputLoc;
        ${coords2[rank - 2]} += 1;
        if(${coords2[rank - 2]} < ${this.outputShape[rank - 2]}) {
          ${padSetup}
          result[2] = getChannel(getX(${source.join()}), ${innerDims});
          ${coords2[rank - 1]} += 1;
          if(${cLimit}) {
            ${padSetup}
            result[3] = getChannel(getX(${source.join()}), ${innerDims});
          }
        }
      `;
      }
      this.userCode = `
      const ${dtype} start = ${dtype}(${start});
      const ${dtype} end = ${dtype}(${end});

      void main() {
        ${dtype} outputLoc = getOutputCoords();
        vec4 result = vec4(0.);
        ${mainLoop}
        setOutput(result);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/MirrorPad.js
  var mirrorPadKernelFunc = ({ inputs, backend: backend2, attrs }) => {
    const { x } = inputs;
    const { paddings, mode } = attrs;
    const program = env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new MirrorPadPackedProgram(x.shape, paddings, mode) : new MirrorPadProgram(x.shape, paddings, mode);
    const output = backend2.runWebGLProgram(program, [x], x.dtype);
    return output;
  };
  var mirrorPadConfig2 = {
    kernelName: MirrorPad,
    backendName: "webgl",
    kernelFunc: mirrorPadKernelFunc
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Mod.js
  var MOD = `if (b == 0.0) return NAN;
  return mod(a, b);`;
  var MOD_PACKED = `
  vec4 result = mod(a, b);
  vec4 isNaN = vec4(equal(b, vec4(0.0)));
  ` + CHECK_NAN_SNIPPET3 + `
  return result;
`;
  var mod3 = binaryKernelFunc2({
    opSnippet: MOD,
    packedOpSnippet: MOD_PACKED
  });
  var modConfig2 = {
    kernelName: Mod,
    backendName: "webgl",
    kernelFunc: mod3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/multinomial_gpu.js
  var MultinomialProgram = class {
    constructor(batchSize, numOutcomes, numSamples) {
      this.variableNames = ["probs"];
      this.customUniforms = [{ name: "seed", type: "float" }];
      this.outputShape = [batchSize, numSamples];
      this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];

        float r = random(seed);
        float cdf = 0.0;

        for (int i = 0; i < ${numOutcomes - 1}; i++) {
          cdf += getProbs(batch, i);

          if (r < cdf) {
            setOutput(float(i));
            return;
          }
        }

        // If no other event happened, last event happened.
        setOutput(float(${numOutcomes - 1}));
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/RealDiv.js
  var DIV = `
if (a == b) {
  return 1.0;
};
return a / b;`;
  var DIV_PACKED = `
  // vec4 one = vec4(equal(a, b));
  // return one + (vec4(1.0) - one) * a / b;
  vec4 result = a / b;
  if(a.x == b.x) {
    result.x = 1.;
  }
  if(a.y == b.y) {
    result.y = 1.;
  }
  if(a.z == b.z) {
    result.z = 1.;
  }
  if(a.w == b.w) {
    result.w = 1.;
  }

  return result;
`;
  var realDiv = binaryKernelFunc2({ opSnippet: DIV, packedOpSnippet: DIV_PACKED, checkOutOfBounds: true });
  var realDivConfig2 = {
    kernelName: RealDiv,
    backendName: "webgl",
    kernelFunc: realDiv
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Sub.js
  var SUB = "return a - b;";
  var sub3 = binaryKernelFunc2({
    opSnippet: SUB,
    packedOpSnippet: SUB,
    supportsComplex: true,
    cpuKernelImpl: subImplCPU
  });
  var subConfig2 = {
    kernelName: Sub,
    backendName: "webgl",
    kernelFunc: sub3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Softmax.js
  function softmax3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { logits } = inputs;
    const { dim } = attrs;
    const axes = util_exports.parseAxisParam([dim], logits.shape);
    const maxLogit = max4({
      inputs: { x: logits },
      backend: backend2,
      attrs: { reductionIndices: axes, keepDims: false }
    });
    const expandedShape = backend_util_exports.expandShapeToKeepDim(maxLogit.shape, axes);
    const maxLogitsReshaped = reshape3({ inputs: { x: maxLogit }, backend: backend2, attrs: { shape: expandedShape } });
    const a = sub3({ inputs: { a: logits, b: maxLogitsReshaped }, backend: backend2 });
    const b = exp3({ inputs: { x: a }, backend: backend2 });
    const sumExp = sum4({ inputs: { x: b }, backend: backend2, attrs: { axis: axes, keepDims: false } });
    const sumExpReshaped = reshape3({ inputs: { x: sumExp }, backend: backend2, attrs: { shape: expandedShape } });
    const res = realDiv({ inputs: { a: b, b: sumExpReshaped }, backend: backend2 });
    backend2.disposeIntermediateTensorInfo(maxLogit);
    backend2.disposeIntermediateTensorInfo(maxLogitsReshaped);
    backend2.disposeIntermediateTensorInfo(a);
    backend2.disposeIntermediateTensorInfo(b);
    backend2.disposeIntermediateTensorInfo(sumExp);
    backend2.disposeIntermediateTensorInfo(sumExpReshaped);
    return res;
  }
  var softmaxConfig2 = {
    kernelName: Softmax,
    backendName: "webgl",
    kernelFunc: softmax3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Multinomial.js
  function multinomial2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { logits } = inputs;
    const { numSamples, seed, normalized } = attrs;
    const probs = normalized ? logits : softmax3({ inputs: { logits }, backend: backend2, attrs: { dim: logits.shape.length - 1 } });
    const batchSize = probs.shape[0];
    const numOutcomes = probs.shape[1];
    const program = new MultinomialProgram(batchSize, numOutcomes, numSamples);
    const customValues = [[seed]];
    const res = backend2.runWebGLProgram(program, [probs], "int32", customValues);
    if (!normalized) {
      backend2.disposeIntermediateTensorInfo(probs);
    }
    return res;
  }
  var multinomialConfig2 = {
    kernelName: Multinomial,
    backendName: "webgl",
    kernelFunc: multinomial2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Neg.js
  var NEG = `return -x;`;
  function neg3(args) {
    const { inputs, backend: backend2 } = args;
    const { x } = inputs;
    if (backend2.shouldExecuteOnCPU([x])) {
      const xData = backend2.texData.get(x.dataId);
      const [outValues, newShape] = negImplCPU(xData.values, x.shape, x.dtype);
      return backend2.makeTensorInfo(newShape, x.dtype, outValues);
    }
    let program;
    if (env().getBool("WEBGL_PACK_UNARY_OPERATIONS")) {
      program = new UnaryOpPackedProgram(x.shape, NEG);
    } else {
      program = new UnaryOpProgram(x.shape, NEG);
    }
    return backend2.runWebGLProgram(program, [x], x.dtype);
  }
  var negConfig2 = {
    kernelName: Neg,
    backendName: "webgl",
    kernelFunc: neg3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/NonMaxSuppressionV3.js
  var nonMaxSuppressionV3Impl3 = kernel_impls_exports.nonMaxSuppressionV3Impl;
  function nonMaxSuppressionV32(args) {
    backend_util_exports.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
    const { inputs, backend: backend2, attrs } = args;
    const { boxes, scores } = inputs;
    const { maxOutputSize, iouThreshold, scoreThreshold } = attrs;
    const boxesVals = backend2.readSync(boxes.dataId);
    const scoresVals = backend2.readSync(scores.dataId);
    const { selectedIndices } = nonMaxSuppressionV3Impl3(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);
    return backend2.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices));
  }
  var nonMaxSuppressionV3Config2 = {
    kernelName: NonMaxSuppressionV3,
    backendName: "webgl",
    kernelFunc: nonMaxSuppressionV32
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/NonMaxSuppressionV4.js
  var nonMaxSuppressionV4Impl3 = kernel_impls_exports.nonMaxSuppressionV4Impl;
  function nonMaxSuppressionV42(args) {
    backend_util_exports.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
    const { inputs, backend: backend2, attrs } = args;
    const { boxes, scores } = inputs;
    const { maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize } = attrs;
    const boxesVals = backend2.readSync(boxes.dataId);
    const scoresVals = backend2.readSync(scores.dataId);
    const { selectedIndices, validOutputs } = nonMaxSuppressionV4Impl3(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize);
    return [
      backend2.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices)),
      backend2.makeTensorInfo([], "int32", new Int32Array([validOutputs]))
    ];
  }
  var nonMaxSuppressionV4Config2 = {
    kernelName: NonMaxSuppressionV4,
    backendName: "webgl",
    kernelFunc: nonMaxSuppressionV42
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/NonMaxSuppressionV5.js
  var nonMaxSuppressionV5Impl3 = kernel_impls_exports.nonMaxSuppressionV5Impl;
  function nonMaxSuppressionV52(args) {
    backend_util_exports.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
    const { inputs, backend: backend2, attrs } = args;
    const { boxes, scores } = inputs;
    const { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma } = attrs;
    const boxesVals = backend2.readSync(boxes.dataId);
    const scoresVals = backend2.readSync(scores.dataId);
    const maxOutputSizeVal = maxOutputSize;
    const iouThresholdVal = iouThreshold;
    const scoreThresholdVal = scoreThreshold;
    const softNmsSigmaVal = softNmsSigma;
    const { selectedIndices, selectedScores } = nonMaxSuppressionV5Impl3(boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal, scoreThresholdVal, softNmsSigmaVal);
    return [
      backend2.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices)),
      backend2.makeTensorInfo([selectedScores.length], "float32", new Float32Array(selectedScores))
    ];
  }
  var nonMaxSuppressionV5Config2 = {
    kernelName: NonMaxSuppressionV5,
    backendName: "webgl",
    kernelFunc: nonMaxSuppressionV52
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/onehot_gpu.js
  var OneHotProgram = class {
    constructor(numIndices, depth, onValue, offValue) {
      this.variableNames = ["indices"];
      this.outputShape = [numIndices, depth];
      this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int index = round(getIndices(coords.x));
        setOutput(mix(float(${offValue}), float(${onValue}),
                      float(index == coords.y)));
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/OneHot.js
  var oneHot3 = (args) => {
    const { inputs, backend: backend2, attrs } = args;
    const { indices } = inputs;
    const { depth, onValue, offValue } = attrs;
    const indicesSize = util_exports.sizeFromShape(indices.shape);
    const program = new OneHotProgram(indicesSize, depth, onValue, offValue);
    const reshaped = reshape3({ inputs: { x: indices }, backend: backend2, attrs: { shape: [indicesSize] } });
    const result = backend2.runWebGLProgram(program, [reshaped], indices.dtype);
    backend2.disposeIntermediateTensorInfo(reshaped);
    const outShape = [...indices.shape, depth];
    const out = reshape3({ inputs: { x: result }, backend: backend2, attrs: { shape: outShape } });
    backend2.disposeIntermediateTensorInfo(result);
    return out;
  };
  var oneHotConfig2 = {
    kernelName: OneHot,
    backendName: "webgl",
    kernelFunc: oneHot3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ZerosLike.js
  function zerosLike3(args) {
    const { inputs, backend: backend2 } = args;
    const { x } = inputs;
    if (x.dtype === "complex64") {
      const realPart = real3({ inputs: { input: x }, backend: backend2 });
      const r = zerosLike3({ inputs: { x: realPart }, backend: backend2 });
      const imagPart = imag3({ inputs: { input: x }, backend: backend2 });
      const i = zerosLike3({ inputs: { x: imagPart }, backend: backend2 });
      const result = complex3({ inputs: { real: r, imag: i }, backend: backend2 });
      backend2.disposeIntermediateTensorInfo(realPart);
      backend2.disposeIntermediateTensorInfo(r);
      backend2.disposeIntermediateTensorInfo(imagPart);
      backend2.disposeIntermediateTensorInfo(i);
      return result;
    } else {
      return fill3({
        attrs: {
          shape: x.shape,
          dtype: x.dtype,
          value: x.dtype === "string" ? "" : 0
        },
        backend: backend2
      });
    }
  }
  var zerosLikeConfig2 = {
    kernelName: ZerosLike,
    backendName: "webgl",
    kernelFunc: zerosLike3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/OnesLike.js
  function onesLike3(args) {
    const { inputs, backend: backend2 } = args;
    const { x } = inputs;
    if (x.dtype === "string") {
      throw new Error("onesLike is not supported under string dtype");
    } else if (x.dtype === "complex64") {
      const realPart = real3({ inputs: { input: x }, backend: backend2 });
      const r = onesLike3({ inputs: { x: realPart }, backend: backend2 });
      const imagPart = imag3({ inputs: { input: x }, backend: backend2 });
      const i = zerosLike3({ inputs: { x: imagPart }, backend: backend2 });
      const result = complex3({ inputs: { real: r, imag: i }, backend: backend2 });
      backend2.disposeIntermediateTensorInfo(realPart);
      backend2.disposeIntermediateTensorInfo(r);
      backend2.disposeIntermediateTensorInfo(imagPart);
      backend2.disposeIntermediateTensorInfo(i);
      return result;
    } else {
      return fill3({ attrs: { shape: x.shape, dtype: x.dtype, value: 1 }, backend: backend2 });
    }
  }
  var onesLikeConfig2 = {
    kernelName: OnesLike,
    backendName: "webgl",
    kernelFunc: onesLike3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Pack.js
  function pack2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { axis } = attrs;
    if (inputs.length === 1) {
      return expandDims4({ inputs: { input: inputs[0] }, backend: backend2, attrs: { dim: axis } });
    }
    const shape = inputs[0].shape;
    const dtype = inputs[0].dtype;
    inputs.forEach((t) => {
      util_exports.assertShapesMatch(shape, t.shape, "All tensors passed to stack must have matching shapes");
      util_exports.assert(dtype === t.dtype, () => "All tensors passed to stack must have matching dtypes");
    });
    const intermediateTensorInfos = [];
    const expandedTensors = inputs.map((t) => {
      const expandedT = expandDims4({ inputs: { input: t }, backend: backend2, attrs: { dim: axis } });
      intermediateTensorInfos.push(expandedT);
      return expandedT;
    });
    const result = concat3({ inputs: expandedTensors, backend: backend2, attrs: { axis } });
    intermediateTensorInfos.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
    return result;
  }
  var packConfig2 = {
    kernelName: Pack,
    backendName: "webgl",
    kernelFunc: pack2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/pad_gpu.js
  var PadProgram = class {
    constructor(xShape, paddings, constantValue) {
      this.variableNames = ["x"];
      this.customUniforms = [{ name: "value", type: "float" }];
      this.outputShape = paddings.map((p3, i) => p3[0] + xShape[i] + p3[1]);
      const rank = xShape.length;
      const type = getCoordsDataType(rank);
      const start = paddings.map((p3) => p3[0]).join(",");
      const end = paddings.map((p3, i) => p3[0] + xShape[i]).join(",");
      const unpackedCoords = ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, rank);
      if (rank === 1) {
        this.userCode = `
        int start = ${start};
        int end = ${end};

        void main() {
          int outC = getOutputCoords();
          if (outC < start || outC >= end) {
            setOutput(value);
          } else {
            setOutput(getX(outC - start));
          }
        }
      `;
        return;
      }
      this.userCode = `
      ${type} start = ${type}(${start});
      ${type} end = ${type}(${end});

      void main() {
        ${type} outC = getOutputCoords();
        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {
          setOutput(value);
        } else {
          ${type} coords = outC - start;
          setOutput(getX(${unpackedCoords}));
        }
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/pad_packed_gpu.js
  var PadPackedProgram = class {
    constructor(xShape, paddings, constantValue) {
      this.variableNames = ["x"];
      this.packedInputs = true;
      this.packedOutput = true;
      this.customUniforms = [{ name: "value", type: "float" }];
      this.outputShape = paddings.map((p3, i) => p3[0] + xShape[i] + p3[1]);
      const rank = xShape.length;
      const dtype = getCoordsDataType(rank);
      const start = paddings.map((p3) => p3[0]).join(",");
      const end = paddings.map((p3, i) => p3[0] + xShape[i]).join(",");
      const coords2 = getChannels("rc", rank);
      const source = getChannels("source", rank);
      const cLimit = `${coords2[rank - 1]} < ${this.outputShape[rank - 1]}`;
      const innerDims = rank === 1 ? "source" : `vec2(${source.slice(-2).join()})`;
      const componentSetup = [
        `${dtype} rc = outputLoc;`,
        `${coords2[rank - 1]} += 1;
       if(${cLimit}) {
      `,
        rank === 1 ? "" : `}
       rc = outputLoc;
       ${coords2[rank - 2]} += 1;
       if(${coords2[rank - 2]} < ${this.outputShape[rank - 2]}) {`,
        rank === 1 ? "" : `  ${coords2[rank - 1]} += 1;
         if(${cLimit}) {`
      ];
      const paddingArea = rank === 1 ? "rc < start || rc >= end" : "any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))";
      let mainLoop = "";
      for (let i = 0, j = rank === 1 ? 2 : 4; i < j; i++) {
        mainLoop += `
        ${componentSetup[i]}
        if (${paddingArea}) {
          result[${i}] = float(value);
        } else {
          ${dtype} source = rc - start;
          result[${i}] = getChannel(getX(${source.join()}), ${innerDims});
        }
      `;
      }
      mainLoop += rank === 1 ? `} ` : `}}`;
      this.userCode = `
      const ${dtype} start = ${dtype}(${start});
      const ${dtype} end = ${dtype}(${end});

      void main() {
        ${dtype} outputLoc = getOutputCoords();
        vec4 result = vec4(0.);
        ${mainLoop}
        setOutput(result);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/PadV2.js
  var padV22 = (args) => {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { paddings, constantValue } = attrs;
    if (util_exports.sizeFromShape(x.shape) === 0) {
      const outputShape = paddings.map((p3, i) => p3[0] + x.shape[i] + p3[1]);
      return fill3({
        backend: backend2,
        attrs: { shape: outputShape, value: constantValue, dtype: x.dtype }
      });
    }
    const program = env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new PadPackedProgram(x.shape, paddings, constantValue) : new PadProgram(x.shape, paddings, constantValue);
    const customValues = [[constantValue]];
    return backend2.runWebGLProgram(program, [x], x.dtype, customValues);
  };
  var padV2Config2 = {
    kernelName: PadV2,
    backendName: "webgl",
    kernelFunc: padV22
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Pow.js
  var POW = `
  if(a < 0.0 && floor(b) < b){
    return NAN;
  }
  if (b == 0.0) {
    return 1.0;
  }
  return (round(mod(b, 2.0)) != 1) ?
      pow(abs(a), b) : sign(a) * pow(abs(a), b);
`;
  var POW_PACKED = `
  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.
  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));
  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);
  vec4 result = multiplier * pow(abs(a), b);

  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS
  bvec4 isExpZero = equal(b, vec4(0.0));
  result.r = isExpZero.r ? 1.0 : result.r;
  result.g = isExpZero.g ? 1.0 : result.g;
  result.b = isExpZero.b ? 1.0 : result.b;
  result.a = isExpZero.a ? 1.0 : result.a;

  vec4 isNaN = vec4(lessThan(a, vec4(0.0))) * vec4(lessThan(floor(b), b));
  ` + CHECK_NAN_SNIPPET3 + `
  return result;
`;
  var pow3 = binaryKernelFunc2({ opSnippet: POW, packedOpSnippet: POW_PACKED });
  var powConfig2 = {
    kernelName: Pow,
    backendName: "webgl",
    kernelFunc: pow3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Prod.js
  function prod3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { axis, keepDims } = attrs;
    const xRank = x.shape.length;
    const toDispose = [];
    const origAxes = util_exports.parseAxisParam(axis, x.shape);
    let axes = origAxes;
    const permutedAxes = backend_util_exports.getAxesPermutation(axes, xRank);
    let permutedX = x;
    if (permutedAxes != null) {
      permutedX = transpose3({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
      axes = backend_util_exports.getInnerMostAxes(axes.length, xRank);
      toDispose.push(permutedX);
    }
    backend_util_exports.assertAxesAreInnerMostDims("prod", axes, xRank);
    let res;
    if (backend2.shouldExecuteOnCPU([permutedX])) {
      const xVals = backend2.texData.get(permutedX.dataId).values;
      const { outVals, outShape, outDtype } = prodImplCPU(permutedX.shape, permutedX.dtype, xVals, axes);
      res = backend2.makeTensorInfo(outShape, outDtype, outVals);
    } else {
      const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(permutedX.shape, axes);
      const inSize = util_exports.sizeFromShape(reduceShape);
      const a2D = reshape3({ inputs: { x: permutedX }, backend: backend2, attrs: { shape: [-1, inSize] } });
      const outputDType = sumOutType(x.dtype);
      const reduced = reduce(a2D, outputDType, "prod", backend2);
      res = reshape3({ inputs: { x: reduced }, backend: backend2, attrs: { shape: outShape } });
      toDispose.push(a2D);
      toDispose.push(reduced);
    }
    if (keepDims) {
      toDispose.push(res);
      const newShape = backend_util_exports.expandShapeToKeepDim(res.shape, origAxes);
      res = reshape3({ inputs: { x: res }, backend: backend2, attrs: { shape: newShape } });
    }
    toDispose.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
    return res;
  }
  var prodConfig2 = {
    kernelName: Prod,
    backendName: "webgl",
    kernelFunc: prod3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Range.js
  var range4 = (args) => {
    const { backend: backend2, attrs } = args;
    const { start, stop: stop2, step: step4, dtype } = attrs;
    const values = rangeImplCPU(start, stop2, step4, dtype);
    return backend2.makeTensorInfo([values.length], dtype, values);
  };
  var rangeConfig2 = {
    kernelName: Range,
    backendName: "webgl",
    kernelFunc: range4
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Reciprocal.js
  var RECIPROCAL = `return 1.0 / x;`;
  var reciprocal3 = unaryKernelFunc2({ opSnippet: RECIPROCAL });
  var reciprocalConfig2 = {
    kernelName: Reciprocal,
    backendName: "webgl",
    kernelFunc: reciprocal3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Relu.js
  var RELU3 = CHECK_NAN_SNIPPET + `
  return (x < 0.0) ? 0.0 : x;
`;
  var RELU_PACKED = `
  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
  var relu3 = unaryKernelFunc2({ opSnippet: RELU3, packedOpSnippet: RELU_PACKED });
  var reluConfig2 = {
    kernelName: Relu,
    backendName: "webgl",
    kernelFunc: relu3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Relu6.js
  var RELU63 = CHECK_NAN_SNIPPET + `
  return (x < 0.0) ? 0.0 : min(6.0, x);
`;
  var RELU6_PACKED = `
  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
  var relu63 = unaryKernelFunc2({ opSnippet: RELU63, packedOpSnippet: RELU6_PACKED });
  var relu6Config2 = {
    kernelName: Relu6,
    backendName: "webgl",
    kernelFunc: relu63
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/resize_bilinear_gpu.js
  var ResizeBilinearProgram = class {
    constructor(inputShape, newHeight, newWidth, alignCorners, halfPixelCenters) {
      this.variableNames = ["A"];
      this.outputShape = [];
      const [batch, oldHeight, oldWidth, depth] = inputShape;
      this.outputShape = [batch, newHeight, newWidth, depth];
      const effectiveInSize = [
        alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
        alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
      ];
      const effectiveOutSize = [
        alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
        alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
      ];
      let sourceFracIndexRC;
      if (halfPixelCenters) {
        sourceFracIndexRC = `(vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC - vec2(0.5)`;
      } else {
        sourceFracIndexRC = `vec2(yRC) * effectiveInputOverOutputRatioRC`;
      }
      this.userCode = `
      const vec2 effectiveInputOverOutputRatioRC = vec2(
          ${effectiveInSize[0] / effectiveOutSize[0]},
          ${effectiveInSize[1] / effectiveOutSize[1]});
      const vec2 inputShapeRC = vec2(${oldHeight}.0, ${oldWidth}.0);

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        ivec2 yRC = coords.yz;

        // Fractional source index.
        vec2 sourceFracIndexRC = ${sourceFracIndexRC};

        // Compute the four integer indices.
        ivec2 sourceFloorRC = ivec2(max(sourceFracIndexRC, vec2(0.0)));
        ivec2 sourceCeilRC = ivec2(
          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));

        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);
        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);
        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);
        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);

        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);

        float top = topLeft + (topRight - topLeft) * fracRC.y;
        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;
        float newValue = top + (bottom - top) * fracRC.x;

        setOutput(newValue);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/resize_bilinear_packed_gpu.js
  var ResizeBilinearPackedProgram = class {
    constructor(inputShape, newHeight, newWidth, alignCorners, halfPixelCenters) {
      this.variableNames = ["A"];
      this.packedInputs = true;
      this.packedOutput = true;
      this.outputShape = [];
      const [batch, oldHeight, oldWidth, depth] = inputShape;
      this.outputShape = [batch, newHeight, newWidth, depth];
      const effectiveInSize = [
        alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
        alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
      ];
      const effectiveOutSize = [
        alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
        alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
      ];
      let sourceFracIndexRC;
      if (halfPixelCenters) {
        sourceFracIndexRC = `(vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC - vec3(0.5)`;
      } else {
        sourceFracIndexRC = `vec3(yRC) * effectiveInputOverOutputRatioRC`;
      }
      this.userCode = `
      const vec3 effectiveInputOverOutputRatioRC = vec3(
          ${effectiveInSize[0] / effectiveOutSize[0]},
          ${effectiveInSize[1] / effectiveOutSize[1]},
          ${effectiveInSize[1] / effectiveOutSize[1]});
      const vec3 inputShapeRC = vec3(${oldHeight}.0, ${oldWidth}.0,
                                     ${oldWidth}.0);

      float getAValue(int b, int r, int c, int d) {
        return getChannel(getA(b, r, c, d), vec2(c, d));
      }

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        // Calculate values for next column in yRC.z.
        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);

        // Fractional source index.
        vec3 sourceFracIndexRC = ${sourceFracIndexRC};

        // Compute the four integer indices.
        ivec3 sourceFloorRC = ivec3(max(sourceFracIndexRC, vec3(0.0)));
        ivec3 sourceCeilRC = ivec3(
          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));

        // Should we calculate next column and row elements in 2x2 packed cell.
        bool hasNextCol = d < ${depth - 1};
        bool hasNextRow = coords.z < ${newWidth - 1};

        // In parallel, construct four corners for all four components in
        // packed 2x2 cell.
        vec4 topLeft = vec4(
          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),
          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);

        vec4 bottomLeft = vec4(
          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),
          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);

        vec4 topRight = vec4(
          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),
          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);

        vec4 bottomRight = vec4(
          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),
          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);

        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);

        vec4 top = mix(topLeft, topRight, fracRC.yyzz);
        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);
        vec4 newValue = mix(top, bottom, fracRC.x);

        setOutput(newValue);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ResizeBilinear.js
  function resizeBilinear3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { images } = inputs;
    const { alignCorners, halfPixelCenters, size: size2 } = attrs;
    const [newHeight, newWidth] = size2;
    const program = env().getBool("WEBGL_PACK_IMAGE_OPERATIONS") ? new ResizeBilinearPackedProgram(images.shape, newHeight, newWidth, alignCorners, halfPixelCenters) : new ResizeBilinearProgram(images.shape, newHeight, newWidth, alignCorners, halfPixelCenters);
    return backend2.runWebGLProgram(program, [images], "float32");
  }
  var resizeBilinearConfig2 = {
    kernelName: ResizeBilinear,
    backendName: "webgl",
    kernelFunc: resizeBilinear3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/resize_bilinear_backprop_gpu.js
  var ResizeBilinearBackpropProgram = class {
    constructor(dyShape, inputShape, alignCorners) {
      this.variableNames = ["dy"];
      this.outputShape = [];
      this.outputShape = inputShape;
      const [, xHeight, xWidth] = inputShape;
      const [, yHeight, yWidth] = dyShape;
      const effectiveXSize = [
        alignCorners && yHeight > 1 ? xHeight - 1 : xHeight,
        alignCorners && yWidth > 1 ? xWidth - 1 : xWidth
      ];
      const effectiveYSize = [
        alignCorners && yHeight > 1 ? yHeight - 1 : yHeight,
        alignCorners && yWidth > 1 ? yWidth - 1 : yWidth
      ];
      const heightScale = effectiveXSize[0] / effectiveYSize[0];
      const widthScale = effectiveXSize[1] / effectiveYSize[1];
      const invHeightScale = 1 / heightScale;
      const invWidthScale = 1 / widthScale;
      const winHeight = Math.ceil(invHeightScale) * 2 + 2;
      const winWidth = Math.ceil(invWidthScale) * 2 + 2;
      this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        int r = coords[1];
        int c = coords[2];

        float accumulator = 0.0;

        const float heightScale = float(${heightScale});
        const float widthScale = float(${widthScale});

        const float invHeightScale = float(${invHeightScale});
        const float invWidthScale = float(${invWidthScale});

        const int winHeight = int(${winHeight});
        const int winWidth = int(${winWidth});

        // Compute bounds for where in dy we will look
        float startRLerp = floor(float(r) * invHeightScale);
        int startDyR = int(startRLerp - float(winHeight / 2));

        float startCLerp = floor(float(c) * invWidthScale);
        int startDyC = int(startCLerp - float(winWidth / 2));

        // Loop over dy
        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {
          int dyR = dyROffset + startDyR;

          // Guard against the window exceeding the bounds of dy
          if (dyR < 0 || dyR >= ${yHeight}) {
            continue;
          }

          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {
            int dyC = dyCOffset + startDyC;

            // Guard against the window exceeding the bounds of dy
            if (dyC < 0 || dyC >= ${yWidth}) {
              continue;
            }

            float dxR = float(dyR) * heightScale;
            int topDxRIndex = int(floor(dxR));
            int bottomDxRIndex = int(min(ceil(dxR), ${xHeight - 1}.0));
            float dxRLerp = dxR - float(topDxRIndex);
            float inverseDxRLerp = 1.0 - dxRLerp;

            float dxC = float(dyC) * widthScale;
            int leftDxCIndex = int(floor(dxC));
            int rightDxCIndex = int(min(ceil(dxC), ${xWidth - 1}.0));
            float dxCLerp = dxC - float(leftDxCIndex);
            float inverseDxCLerp = 1.0 - dxCLerp;

            if (r == topDxRIndex && c == leftDxCIndex) {
              // topLeft
              accumulator +=
                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;
            }

            if (r == topDxRIndex && c == rightDxCIndex) {
              // topRight
              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;
            }

            if (r == bottomDxRIndex && c == leftDxCIndex) {
              // bottomLeft
              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;
            }

            if (r == bottomDxRIndex && c == rightDxCIndex) {
              // bottomRight
              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;
            }
          }
        }
        // End loop over dy

        setOutput(accumulator);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ResizeBilinearGrad.js
  function resizeBilinearGrad2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { images, dy } = inputs;
    const { alignCorners } = attrs;
    const program = new ResizeBilinearBackpropProgram(dy.shape, images.shape, alignCorners);
    return backend2.runWebGLProgram(program, [dy], dy.dtype);
  }
  var resizeBilinearGradConfig3 = {
    kernelName: ResizeBilinearGrad,
    backendName: "webgl",
    kernelFunc: resizeBilinearGrad2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/resize_nearest_neighbor_gpu.js
  var ResizeNearestNeighborProgram = class {
    constructor(inputShape, newHeight, newWidth, alignCorners, halfPixelCenters) {
      this.variableNames = ["A"];
      this.outputShape = [];
      const [batch, oldHeight, oldWidth, depth] = inputShape;
      this.outputShape = [batch, newHeight, newWidth, depth];
      const effectiveInSize = [
        alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
        alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
      ];
      const effectiveOutSize = [
        alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
        alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
      ];
      const roundBase = alignCorners ? "0.5" : "0.0";
      let sourceFracIndexRC;
      if (halfPixelCenters) {
        sourceFracIndexRC = `max((vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC, vec2(0.0))`;
      } else {
        sourceFracIndexRC = `vec2(yRC) * effectiveInputOverOutputRatioRC`;
      }
      this.userCode = `
      const vec2 effectiveInputOverOutputRatioRC = vec2(
          ${effectiveInSize[0] / effectiveOutSize[0]},
          ${effectiveInSize[1] / effectiveOutSize[1]});
      const vec2 inputShapeRC = vec2(${oldHeight}.0, ${oldWidth}.0);

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        ivec2 yRC = coords.yz;

        // Fractional source index.
        vec2 sourceFracIndexRC = ${sourceFracIndexRC};

        // Compute the coordinators of nearest neighbor point.
        ivec2 sourceNearestRC = ivec2(
          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${roundBase})));
        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);

        setOutput(newValue);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/resize_nearest_neighbor_packed_gpu.js
  var ResizeNearestNeighborPackedProgram = class {
    constructor(inputShape, newHeight, newWidth, alignCorners, halfPixelCenters) {
      this.variableNames = ["A"];
      this.packedInputs = true;
      this.packedOutput = true;
      this.outputShape = [];
      const [batch, oldHeight, oldWidth, depth] = inputShape;
      this.outputShape = [batch, newHeight, newWidth, depth];
      const effectiveInSize = [
        alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
        alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
      ];
      const effectiveOutSize = [
        alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
        alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
      ];
      const roundBase = alignCorners ? "0.5" : "0.0";
      let sourceFracIndexRC;
      if (halfPixelCenters) {
        sourceFracIndexRC = `max((vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC, vec3(0.0))`;
      } else {
        sourceFracIndexRC = `vec3(yRC) * effectiveInputOverOutputRatioRC`;
      }
      this.userCode = `
      const vec3 effectiveInputOverOutputRatioRC = vec3(
          ${effectiveInSize[0] / effectiveOutSize[0]},
          ${effectiveInSize[1] / effectiveOutSize[1]},
          ${effectiveInSize[1] / effectiveOutSize[1]});
      const vec3 inputShapeRC = vec3(${oldHeight}.0, ${oldWidth}.0,
                                     ${oldWidth}.0);

      float getAValue(int b, int r, int c, int d) {
        return getChannel(getA(b, r, c, d), vec2(c, d));
      }

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        // Calculate values for next column in yRC.z.
        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);

        // Fractional source index.
        vec3 sourceFracIndexRC = ${sourceFracIndexRC};

        // Compute the coordinators of nearest neighbor point.
        ivec3 sourceNearestRC = ivec3(
          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${roundBase})));

        // Should we calculate next column and row elements in 2x2 packed cell.
        bool hasNextCol = d < ${depth - 1};
        bool hasNextRow = coords.z < ${newWidth - 1};

        vec4 newValue = vec4(
          getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d),
          hasNextCol ? getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d + 1) : 0.0);

        setOutput(newValue);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ResizeNearestNeighbor.js
  function resizeNearestNeighbor3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { images } = inputs;
    const { alignCorners, halfPixelCenters, size: size2 } = attrs;
    const [newHeight, newWidth] = size2;
    const program = env().getBool("WEBGL_PACK_IMAGE_OPERATIONS") ? new ResizeNearestNeighborPackedProgram(images.shape, newHeight, newWidth, alignCorners, halfPixelCenters) : new ResizeNearestNeighborProgram(images.shape, newHeight, newWidth, alignCorners, halfPixelCenters);
    return backend2.runWebGLProgram(program, [images], images.dtype);
  }
  var resizeNearestNeighborConfig2 = {
    kernelName: ResizeNearestNeighbor,
    backendName: "webgl",
    kernelFunc: resizeNearestNeighbor3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/resize_nearest_neighbor_backprop_gpu.js
  var ResizeNearestNeigborBackpropProgram = class {
    constructor(dyShape, inputShape, alignCorners) {
      this.variableNames = ["dy"];
      this.outputShape = [];
      this.outputShape = inputShape;
      const [, xHeight, xWidth] = inputShape;
      const [, yHeight, yWidth] = dyShape;
      const effectiveXSize = [
        alignCorners && yHeight > 1 ? xHeight - 1 : xHeight,
        alignCorners && yWidth > 1 ? xWidth - 1 : xWidth
      ];
      const effectiveYSize = [
        alignCorners && yHeight > 1 ? yHeight - 1 : yHeight,
        alignCorners && yWidth > 1 ? yWidth - 1 : yWidth
      ];
      const heightScale = effectiveXSize[0] / effectiveYSize[0];
      const widthScale = effectiveXSize[1] / effectiveYSize[1];
      const invHeightScale = 1 / heightScale;
      const invWidthScale = 1 / widthScale;
      const winHeight = Math.ceil(invHeightScale) * 2 + 2;
      const winWidth = Math.ceil(invWidthScale) * 2 + 2;
      this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        int r = coords[1];
        int c = coords[2];

        float accumulator = 0.0;

        const float heightScale = float(${heightScale});
        const float widthScale = float(${widthScale});

        const float invHeightScale = float(${invHeightScale});
        const float invWidthScale = float(${invWidthScale});

        const int winHeight = int(${winHeight});
        const int winWidth = int(${winWidth});

        // Compute bounds for where in dy we will look
        float startRLerp = floor(float(r) * invHeightScale);
        int startDyR = int(floor(startRLerp - float(winHeight / 2)));

        float startCLerp = floor(float(c) * invWidthScale);
        int startDyC = int(floor(startCLerp - float(winWidth / 2)));

        // Loop over dy
        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {
          int dyR = dyROffset + startDyR;

          // Guard against the window exceeding the bounds of dy
          if (dyR < 0 || dyR >= ${yHeight}) {
            continue;
          }

          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {
            int dyC = dyCOffset + startDyC;

            // Guard against the window exceeding the bounds of dy
            if (dyC < 0 || dyC >= ${yWidth}) {
              continue;
            }

            float sourceFracRow =
              float(${effectiveXSize[0]}) *
                (float(dyR) / float(${effectiveYSize[0]}));

            float sourceFracCol =
                float(${effectiveXSize[1]}) *
                  (float(dyC) / float(${effectiveYSize[1]}));

            int sourceNearestRow = int(min(
                float(int(${xHeight}) - 1),
                ${alignCorners} ? float(round(sourceFracRow)) :
                                  float(floor(sourceFracRow))));

            int sourceNearestCol = int(min(
                float(int(${xWidth}) - 1),
                ${alignCorners} ? float(round(sourceFracCol)) :
                                  float(floor(sourceFracCol))));

            if (r == sourceNearestRow && c == sourceNearestCol) {
              accumulator += getDy(b, dyR, dyC, d);
            }
          }
        }
        // End loop over dy

        setOutput(accumulator);
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ResizeNearestNeighborGrad.js
  function resizeNearestNeighborGrad2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { images, dy } = inputs;
    const { alignCorners } = attrs;
    const program = new ResizeNearestNeigborBackpropProgram(dy.shape, images.shape, alignCorners);
    return backend2.runWebGLProgram(program, [dy], dy.dtype);
  }
  var resizeNearestNeighborGradConfig3 = {
    kernelName: ResizeNearestNeighborGrad,
    backendName: "webgl",
    kernelFunc: resizeNearestNeighborGrad2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/reverse_gpu.js
  var ReverseProgram = class {
    constructor(xShape, axis) {
      this.variableNames = ["x"];
      const rank = xShape.length;
      if (rank > 4) {
        throw new Error(`WebGL backend: Reverse of rank-${rank} tensor is not yet supported`);
      }
      this.outputShape = xShape;
      if (rank === 1) {
        this.userCode = `
        void main() {
          int coord = getOutputCoords();
          setOutput(getX(${xShape[0]} - coord - 1));
        }
      `;
        return;
      }
      const getInCoord = (i) => {
        if (axis.indexOf(i) !== -1 && xShape[i] !== 1) {
          return `${xShape[i]} - coords[${i}] - 1`;
        }
        return `coords[${i}]`;
      };
      const inCoords = xShape.map((_, i) => getInCoord(i)).join(",");
      const type = getCoordsDataType(rank);
      this.userCode = `
      void main() {
        ${type} coords = getOutputCoords();
        setOutput(getX(${inCoords}));
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/reverse_packed_gpu.js
  var ReversePackedProgram = class {
    constructor(xShape, axis) {
      this.variableNames = ["x"];
      this.packedInputs = true;
      this.packedOutput = true;
      const rank = xShape.length;
      if (rank > 4) {
        throw new Error(`WebGL backend: Reverse of rank-${rank} tensor is not yet supported`);
      }
      this.outputShape = xShape;
      const channels = getChannels("rc", rank);
      const nextColumn = `${channels[rank - 1]} + 1 < ${this.outputShape[rank - 1]}`;
      const nextRow = `${channels[rank - 2]} + 1 < ${this.outputShape[rank - 2]}`;
      const type = getCoordsDataType(rank);
      if (rank === 1) {
        this.userCode = `
        void main(){
          int rc = getOutputCoords();
          vec4 result = vec4(0.);
          result.r = getChannel(getX(${xShape[0]} - rc - 1),
            ${xShape[0]} - rc - 1);
          if(${nextColumn}){
              result.g = getChannel(getX(${xShape[0]} - (rc  + 1) - 1),
                ${xShape[0]} - (rc  + 1) - 1);
          }
          setOutput(result);
        }
      `;
      } else {
        this.userCode = `
        void main() {
          ${type} rc = getOutputCoords();
          vec4 result = vec4(0.);
          result.r = ${getR(channels.slice())};
          if(${nextColumn}){
            result.g = ${getG(channels.slice())};
          }
          if(${nextRow}) {
            result.b = ${getB(channels.slice())};
            if(${nextColumn}) {
              result.a = ${getA(channels.slice())};
            }
          }
          setOutput(result);
        }
    `;
      }
      function getR(channels2) {
        return getChannel(channels2);
      }
      function getG(channels2) {
        channels2[rank - 1] = "(" + channels2[rank - 1] + ` + 1)`;
        return getChannel(channels2);
      }
      function getB(channels2) {
        channels2[rank - 2] = "(" + channels2[rank - 2] + ` + 1)`;
        return getChannel(channels2);
      }
      function getA(channels2) {
        channels2[rank - 1] = "(" + channels2[rank - 1] + ` + 1)`;
        channels2[rank - 2] = "(" + channels2[rank - 2] + ` + 1)`;
        return getChannel(channels2);
      }
      function getChannel(channels2) {
        const inCoordsArray = xShape.map((_, i) => getInCoord(i, channels2));
        const inCoords = inCoordsArray.join(",");
        const innerDims = inCoordsArray.slice(-2).join(",");
        return `getChannel(getX(${inCoords}), vec2(${innerDims}))`;
      }
      function getInCoord(i, channels1) {
        if (axis.indexOf(i) !== -1 && xShape[i] !== 1) {
          return `${xShape[i]} - ${channels1[i]} - 1`;
        } else {
          return `${channels1[i]}`;
        }
      }
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Reverse.js
  function reverse3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { dims } = attrs;
    const xRank = x.shape.length;
    const $dims = util_exports.parseAxisParam(dims, x.shape);
    if (xRank === 0) {
      return identity2({ inputs: { x }, backend: backend2 });
    }
    const program = env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new ReversePackedProgram(x.shape, $dims) : new ReverseProgram(x.shape, $dims);
    return backend2.runWebGLProgram(program, [x], x.dtype);
  }
  var reverseConfig2 = {
    kernelName: Reverse,
    backendName: "webgl",
    kernelFunc: reverse3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/rotate_gpu.js
  var RotateProgram = class {
    constructor(imageShape, fillValue) {
      this.variableNames = ["Image"];
      this.outputShape = [];
      this.customUniforms = [{ name: "params", type: "vec4" }];
      const imageHeight = imageShape[1];
      const imageWidth = imageShape[2];
      this.outputShape = imageShape;
      let fillSnippet = "";
      if (typeof fillValue === "number") {
        fillSnippet = `float outputValue = ${fillValue.toFixed(2)};`;
      } else {
        fillSnippet = `
        vec3 fill = vec3(${fillValue.join(",")});
        float outputValue = fill[coords[3]];`;
      }
      this.userCode = `
        void main() {
          ivec4 coords = getOutputCoords();
          int x = coords[2];
          int y = coords[1];
          float coordXFloat = (float(x) - params[0]) * params[3] -
            (float(y) - params[1]) * params[2];
          float coordYFloat = (float(x) - params[0]) * params[2] +
            (float(y) - params[1]) * params[3];
          int coordX = int(round(coordXFloat + params[0]));
          int coordY = int(round(coordYFloat + params[1]));
          ${fillSnippet}
          if(coordX >= 0 && coordX < ${imageWidth} && coordY >= 0 && coordY < ${imageHeight}) {
            outputValue = getImage(coords[0], coordY, coordX, coords[3]);
          }
          setOutput(outputValue);
        }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/RotateWithOffset.js
  var rotateWithOffsetConfig2 = {
    kernelName: RotateWithOffset,
    backendName: "webgl",
    kernelFunc: ({ inputs, attrs, backend: backend2 }) => {
      const { image: image3 } = inputs;
      const { radians, fillValue, center } = attrs;
      const webglBackend = backend2;
      const program = new RotateProgram(image3.shape, fillValue);
      const [centerX, centerY] = backend_util_exports.getImageCenter(center, image3.shape[1], image3.shape[2]);
      const customValues = [[centerX, centerY, Math.sin(radians), Math.cos(radians)]];
      const output = webglBackend.runWebGLProgram(program, [image3], image3.dtype, customValues);
      return output;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Round.js
  var ROUND = `
  // OpenGL ES does not support round function.
  // The algorithm is based on banker's rounding.
  float base = floor(x);
  if ((x - base) < 0.5) {
    return floor(x);
  } else if ((x - base) > 0.5) {
    return ceil(x);
  } else {
    if (mod(base, 2.0) == 0.0) {
      return base;
    } else {
      return base + 1.0;
    }
  }
`;
  var round4 = unaryKernelFunc2({ opSnippet: ROUND });
  var roundConfig2 = {
    kernelName: Round,
    backendName: "webgl",
    kernelFunc: round4
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Rsqrt.js
  var RSQRT = `return inversesqrt(x);`;
  var rsqrt3 = unaryKernelFunc2({ opSnippet: RSQRT, cpuKernelImpl: rsqrtImplCPU });
  var rsqrtConfig2 = {
    kernelName: Rsqrt,
    backendName: "webgl",
    kernelFunc: rsqrt3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/scatter_gpu.js
  var ScatterProgram = class {
    constructor(updateSize, sliceDim, indicesRank, updatesRank, strides, shape, summingDupeIndex = true) {
      this.variableNames = ["updates", "indices", "defaultValue"];
      this.outputShape = shape;
      const stridesType = getCoordsDataType(strides.length);
      const dtype = getCoordsDataType(shape.length);
      let indicesString = "";
      if (indicesRank === 1) {
        indicesString = "i";
      } else if (indicesRank === 2) {
        indicesString = "i, j";
      }
      const indicesSnippet = `getIndices(${indicesString})`;
      let updatesString = "";
      if (updatesRank === 1) {
        updatesString = "i";
      } else if (updatesRank === 2) {
        updatesString = "i, coords[1]";
      }
      const updatesSnippet = `getUpdates(${updatesString})`;
      const strideString = sliceDim > 1 ? "strides[j]" : "strides";
      this.userCode = `
        ${stridesType} strides = ${stridesType}(${strides});

        void main() {
          ${dtype} coords = getOutputCoords();
          float sum = 0.0;
          bool found = false;
          for (int i = 0; i < ${updateSize}; i++) {
            int flattenedIndex = 0;
            for (int j = 0; j < ${sliceDim}; j++) {
              int index = round(${indicesSnippet});
              flattenedIndex += index * ${strideString};
            }
            if (flattenedIndex == coords[0]) {
              sum += ${updatesSnippet};
              found = true;
            }
          }
          setOutput(mix(getDefaultValue(), sum, float(found)));
        }
      `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ScatterNd.js
  function scatterNd2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { indices, updates } = inputs;
    const { shape } = attrs;
    const { sliceRank, numUpdates, sliceSize, strides, outputSize } = backend_util_exports.calculateShapes(updates, indices, shape);
    const flattenShape = [outputSize / sliceSize, sliceSize];
    if (outputSize === 0) {
      return backend2.makeTensorInfo(shape, indices.dtype);
    }
    const flattenIndices = reshape3({ inputs: { x: indices }, backend: backend2, attrs: { shape: [numUpdates, sliceRank] } });
    const flattenX = reshape3({ inputs: { x: updates }, backend: backend2, attrs: { shape: [numUpdates, sliceSize] } });
    const defaultValue = backend2.makeTensorInfo([], "float32", new Float32Array([0]));
    const program = new ScatterProgram(numUpdates, sliceRank, flattenIndices.shape.length, flattenX.shape.length, strides, flattenShape);
    const res = backend2.runWebGLProgram(program, [flattenX, flattenIndices, defaultValue], flattenX.dtype);
    const reshaped = reshape3({ inputs: { x: res }, backend: backend2, attrs: { shape } });
    backend2.disposeIntermediateTensorInfo(flattenIndices);
    backend2.disposeIntermediateTensorInfo(flattenX);
    backend2.disposeIntermediateTensorInfo(res);
    backend2.disposeIntermediateTensorInfo(defaultValue);
    return reshaped;
  }
  var scatterNdConfig2 = {
    kernelName: ScatterNd,
    backendName: "webgl",
    kernelFunc: scatterNd2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/select_gpu.js
  var SelectProgram = class {
    constructor(cRank, shape, rank) {
      this.variableNames = ["c", "a", "b"];
      this.outputShape = shape;
      let cCoords;
      let abCoords;
      if (rank > 4) {
        throw Error(`Where for rank ${rank} is not yet supported`);
      }
      if (rank === 1) {
        abCoords = `resRC`;
        cCoords = `resRC`;
      } else {
        const currentCoords = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"];
        const cCoordVars = [];
        const abCoordVars = [];
        for (let i = 0; i < shape.length; i++) {
          abCoordVars.push(`${currentCoords[i]}`);
          if (i < cRank) {
            cCoordVars.push(`${currentCoords[i]}`);
          }
        }
        cCoords = cCoordVars.join();
        abCoords = abCoordVars.join();
      }
      const dtype = getCoordsDataType(rank);
      this.userCode = `
      void main() {
        ${dtype} resRC = getOutputCoords();
        float cVal = getC(${cCoords});
        if (cVal >= 1.0) {
          setOutput(getA(${abCoords}));
        } else {
          setOutput(getB(${abCoords}));
        }
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Select.js
  function select3(args) {
    const { inputs, backend: backend2 } = args;
    const { condition, t, e } = inputs;
    const program = new SelectProgram(condition.shape.length, t.shape, t.shape.length);
    return backend2.runWebGLProgram(program, [condition, t, e], upcastType(t.dtype, e.dtype));
  }
  var selectConfig2 = {
    kernelName: Select,
    backendName: "webgl",
    kernelFunc: select3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Selu.js
  var SELU = `
  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.
  // see: https://arxiv.org/abs/1706.02515
  float scaleAlpha = ${backend_util_exports.SELU_SCALEALPHA};
  float scale = ${backend_util_exports.SELU_SCALE};
  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);
`;
  var selu3 = unaryKernelFunc2({ opSnippet: SELU });
  var seluConfig2 = {
    kernelName: Selu,
    backendName: "webgl",
    kernelFunc: selu3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Sigmoid.js
  var SIGMOID3 = `return 1.0 / (1.0 + exp(-1.0 * x));`;
  var sigmoid3 = unaryKernelFunc2({
    opSnippet: SIGMOID3,
    packedOpSnippet: SIGMOID3,
    cpuKernelImpl: sigmoidImplCPU
  });
  var sigmoidConfig2 = {
    kernelName: Sigmoid,
    backendName: "webgl",
    kernelFunc: sigmoid3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Sign.js
  var SIGN = `
  if (isnan(x)) { return 0.0; }
  return sign(x);
`;
  var sign3 = unaryKernelFunc2({ opSnippet: SIGN });
  var signConfig2 = {
    kernelName: Sign,
    backendName: "webgl",
    kernelFunc: sign3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Sin.js
  var SIN = CHECK_NAN_SNIPPET_UNARY + `
  return sin(x);
`;
  var sin3 = unaryKernelFunc2({ opSnippet: SIN });
  var sinConfig2 = {
    kernelName: Sin,
    backendName: "webgl",
    kernelFunc: sin3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Sinh.js
  var SINH = `
  float e2x = exp(x);
  return (e2x - 1.0 / e2x) / 2.0;
`;
  var sinh3 = unaryKernelFunc2({ opSnippet: SINH });
  var sinhConfig2 = {
    kernelName: Sinh,
    backendName: "webgl",
    kernelFunc: sinh3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Softplus.js
  var SOFTPLUS = `
  float epsilon = 1.1920928955078125e-7;
  float threshold = log(epsilon) + 2.0;

  bool too_large = x > -threshold;
  bool too_small = x < threshold;

  float result;
  float exp_x = exp(x);

  if (too_large){
    result = x;
  }
  else if (too_small){
    result = exp_x;
  }
  else{
    result = log(exp_x + 1.0);
  }
  return result;
`;
  var softplus3 = unaryKernelFunc2({ opSnippet: SOFTPLUS });
  var softplusConfig2 = {
    kernelName: Softplus,
    backendName: "webgl",
    kernelFunc: softplus3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/SpaceToBatchND.js
  var spaceToBatchND3 = (args) => {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { blockShape, paddings } = attrs;
    util_exports.assert(x.shape.length <= 4, () => "spaceToBatchND for rank > 4 with a WebGL backend not implemented yet");
    const prod4 = blockShape.reduce((a, b) => a * b);
    const completePaddings = [[0, 0]];
    completePaddings.push(...paddings);
    for (let i = 1 + blockShape.length; i < x.shape.length; ++i) {
      completePaddings.push([0, 0]);
    }
    const toDispose = [];
    const paddedX = padV22({
      inputs: { x },
      backend: backend2,
      attrs: { paddings: completePaddings, constantValue: 0 }
    });
    const reshapedPaddedShape = backend_util_exports.getReshaped(paddedX.shape, blockShape, prod4, false);
    const permutedReshapedPaddedPermutation = backend_util_exports.getPermuted(reshapedPaddedShape.length, blockShape.length, false);
    const flattenShape = backend_util_exports.getReshapedPermuted(paddedX.shape, blockShape, prod4, false);
    const reshapedPaddedX = reshape3({ inputs: { x: paddedX }, backend: backend2, attrs: { shape: reshapedPaddedShape } });
    const paddedXT = transpose3({
      inputs: { x: reshapedPaddedX },
      backend: backend2,
      attrs: { perm: permutedReshapedPaddedPermutation }
    });
    const result = reshape3({ inputs: { x: paddedXT }, backend: backend2, attrs: { shape: flattenShape } });
    toDispose.push(paddedX);
    toDispose.push(reshapedPaddedX);
    toDispose.push(paddedXT);
    toDispose.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
    return result;
  };
  var spaceToBatchNDConfig2 = {
    kernelName: SpaceToBatchND,
    backendName: "webgl",
    kernelFunc: spaceToBatchND3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/SparseFillEmptyRows.js
  function sparseFillEmptyRows2(args) {
    const { inputs, backend: backend2 } = args;
    const { indices, values, denseShape, defaultValue } = inputs;
    if (denseShape.shape.length !== 1) {
      throw new Error(`Dense shape must be a vector, saw:
         ${denseShape.shape}`);
    }
    if (indices.shape.length !== 2) {
      throw new Error(`Indices must be a matrix, saw:
         ${indices.shape}`);
    }
    if (values.shape.length !== 1) {
      throw new Error(`Values must be a vector, saw:
         ${values.shape}`);
    }
    if (defaultValue.shape.length !== 0) {
      throw new Error(`Default value must be a scalar, saw:
        ${defaultValue.shape}`);
    }
    const $indices = backend2.readSync(indices.dataId);
    const $values = backend2.readSync(values.dataId);
    const $denseShape = backend2.readSync(denseShape.dataId);
    const $defaultValue = backend2.readSync(defaultValue.dataId)[0];
    const [outputIndices, outputIndicesShape, outputValues, emptyRowIndicator, reverseIndexMap] = sparseFillEmptyRowsImplCPU($indices, indices.shape, indices.dtype, $values, values.dtype, $denseShape, $defaultValue);
    return [
      backend2.makeTensorInfo(outputIndicesShape, indices.dtype, outputIndices),
      backend2.makeTensorInfo([outputIndicesShape[0]], values.dtype, outputValues),
      backend2.makeTensorInfo([emptyRowIndicator.length], "bool", new Uint8Array(emptyRowIndicator.map((value) => Number(value)))),
      backend2.makeTensorInfo([reverseIndexMap.length], indices.dtype, new Int32Array(reverseIndexMap))
    ];
  }
  var sparseFillEmptyRowsConfig2 = {
    kernelName: SparseFillEmptyRows,
    backendName: "webgl",
    kernelFunc: sparseFillEmptyRows2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/SparseReshape.js
  function sparseReshape2(args) {
    const { inputs, backend: backend2 } = args;
    const { inputIndices, inputShape, newShape } = inputs;
    if (inputIndices.shape.length !== 2) {
      throw new Error(`Input indices should be a matrix but received shape ${inputIndices.shape}`);
    }
    if (inputShape.shape.length !== 1) {
      throw new Error(`Input shape should be a vector but received shape ${inputShape.shape}`);
    }
    if (newShape.shape.length !== 1) {
      throw new Error(`Target shape should be a vector but received shape ${newShape.shape}`);
    }
    const $inputShape = Array.from(backend2.readSync(inputShape.dataId));
    const $inputIndices = backend2.readSync(inputIndices.dataId);
    const targetShape = Array.from(backend2.readSync(newShape.dataId));
    const [newIndices, indicesShape, outputShape] = sparseReshapeImplCPU($inputIndices, inputIndices.shape, inputIndices.dtype, $inputShape, targetShape);
    return [
      backend2.makeTensorInfo(indicesShape, inputIndices.dtype, newIndices),
      backend2.makeTensorInfo([outputShape.length], newShape.dtype, new Int32Array(outputShape))
    ];
  }
  var sparseReshapeConfig2 = {
    kernelName: SparseReshape,
    backendName: "webgl",
    kernelFunc: sparseReshape2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/SparseSegmentMean.js
  function sparseSegmentMean2(args) {
    const { inputs, backend: backend2 } = args;
    const { data, indices, segmentIds } = inputs;
    if (data.shape.length < 1) {
      throw new Error(`Data should be at least 1 dimensional but received scalar`);
    }
    if (indices.shape.length !== 1) {
      throw new Error(`Indices should be a vector but received shape
              ${indices.shape}`);
    }
    if (segmentIds.shape.length !== 1) {
      throw new Error(`Segment ids should be a vector but received shape
              ${segmentIds.shape}`);
    }
    const $data = backend2.readSync(data.dataId);
    const $indices = backend2.readSync(indices.dataId);
    const $segmentIds = backend2.readSync(segmentIds.dataId);
    const [outputData, outputDataShape] = sparseSegmentReductionImplCPU($data, data.shape, data.dtype, $indices, $segmentIds, true);
    return backend2.makeTensorInfo(outputDataShape, data.dtype, outputData);
  }
  var sparseSegmentMeanConfig2 = {
    kernelName: SparseSegmentMean,
    backendName: "webgl",
    kernelFunc: sparseSegmentMean2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/SparseSegmentSum.js
  function sparseSegmentSum2(args) {
    const { inputs, backend: backend2 } = args;
    const { data, indices, segmentIds } = inputs;
    if (data.shape.length < 1) {
      throw new Error(`Data should be at least 1 dimensional but received scalar`);
    }
    if (indices.shape.length !== 1) {
      throw new Error(`Indices should be a vector but received shape
             ${indices.shape}`);
    }
    if (segmentIds.shape.length !== 1) {
      throw new Error(`Segment ids should be a vector but received shape
             ${segmentIds.shape}`);
    }
    const $data = backend2.readSync(data.dataId);
    const $indices = backend2.readSync(indices.dataId);
    const $segmentIds = backend2.readSync(segmentIds.dataId);
    const [outputData, outputDataShape] = sparseSegmentReductionImplCPU($data, data.shape, data.dtype, $indices, $segmentIds);
    return backend2.makeTensorInfo(outputDataShape, data.dtype, outputData);
  }
  var sparseSegmentSumConfig2 = {
    kernelName: SparseSegmentSum,
    backendName: "webgl",
    kernelFunc: sparseSegmentSum2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/SparseToDense.js
  function sparseToDense2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { sparseIndices, sparseValues, defaultValue } = inputs;
    const { outputShape } = attrs;
    const { sliceRank, numUpdates, strides, outputSize } = backend_util_exports.calculateShapes(sparseValues, sparseIndices, outputShape);
    const sumDupeIndices = false;
    const program = new ScatterProgram(numUpdates, sliceRank, sparseIndices.shape.length, sparseValues.shape.length, strides, [outputSize, 1], sumDupeIndices);
    const res = backend2.runWebGLProgram(program, [sparseValues, sparseIndices, defaultValue], sparseValues.dtype);
    const reshaped = reshape3({ inputs: { x: res }, backend: backend2, attrs: { shape: outputShape } });
    backend2.disposeIntermediateTensorInfo(res);
    return reshaped;
  }
  var sparseToDenseConfig2 = {
    kernelName: SparseToDense,
    backendName: "webgl",
    kernelFunc: sparseToDense2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/SplitV.js
  function splitV2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { numOrSizeSplits, axis } = attrs;
    const $axis = util_exports.parseAxisParam(axis, x.shape)[0];
    const splitSizes = backend_util_exports.prepareSplitSize(x, numOrSizeSplits, $axis);
    const xRank = x.shape.length;
    const begin = new Array(xRank).fill(0);
    const size2 = x.shape.slice();
    return splitSizes.map((s) => {
      const sliceSize = [...size2];
      sliceSize[$axis] = s;
      const sliceT = slice3({ inputs: { x }, backend: backend2, attrs: { begin, size: sliceSize } });
      begin[$axis] += s;
      return sliceT;
    });
  }
  var splitVConfig2 = {
    kernelName: SplitV,
    backendName: "webgl",
    kernelFunc: splitV2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Sqrt.js
  var SQRT = `return sqrt(x);`;
  var sqrt3 = unaryKernelFunc2({ opSnippet: SQRT, packedOpSnippet: SQRT, cpuKernelImpl: sqrtImplCPU });
  var sqrtConfig2 = {
    kernelName: Sqrt,
    backendName: "webgl",
    kernelFunc: sqrt3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Square.js
  var SQUARE = `return x * x;`;
  var square3 = unaryKernelFunc2({ opSnippet: SQUARE });
  var squareConfig2 = {
    kernelName: Square,
    backendName: "webgl",
    kernelFunc: square3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/SquaredDifference.js
  var SQUARED_DIFFERENCE = "return (a - b) * (a - b);";
  var squaredDifference3 = binaryKernelFunc2({ opSnippet: SQUARED_DIFFERENCE, packedOpSnippet: SQUARED_DIFFERENCE });
  var squaredDifferenceConfig2 = {
    kernelName: SquaredDifference,
    backendName: "webgl",
    kernelFunc: squaredDifference3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Step.js
  function step3({ inputs, attrs, backend: backend2 }) {
    const { x } = inputs;
    const opSnippet = CHECK_NAN_SNIPPET + `
    return x > 0.0 ? 1.0 : float(${attrs.alpha});
  `;
    const program = new UnaryOpProgram(x.shape, opSnippet);
    return backend2.runWebGLProgram(program, [x], x.dtype);
  }
  var stepConfig2 = {
    kernelName: Step,
    backendName: "webgl",
    kernelFunc: step3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/strided_slice_gpu.js
  var StridedSliceProgram = class {
    constructor(begin, strides, size2) {
      this.variableNames = ["x"];
      this.outputShape = size2;
      const rank = size2.length;
      const inputDtype = getCoordsDataType(size2.length);
      const dtype = getCoordsDataType(size2.length);
      let newCoords = "";
      if (rank === 1) {
        newCoords = "coords * strides + begin";
      } else {
        let outputAxis = 0;
        newCoords = size2.map((_, i) => {
          outputAxis++;
          return size2.length === 1 ? `coords * strides[${i}] + begin[${i}]` : `coords[${outputAxis - 1}] * strides[${i}] + begin[${i}]`;
        }).join(",");
      }
      this.userCode = `
      ${inputDtype} begin = ${inputDtype}(${begin});
      ${inputDtype} strides = ${inputDtype}(${strides});

      void main() {
        ${dtype} coords = getOutputCoords();
        setOutput(getX(${newCoords}));
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/StridedSlice.js
  function stridedSlice3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask } = attrs;
    const { finalShapeSparse, finalShape, isIdentity, sliceDim0, isSimpleSlice, begin: $begin, end: $end, strides: $strides } = slice_util_exports.sliceInfo(x.shape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask);
    let result;
    if (isIdentity) {
      result = reshape3({ inputs: { x }, backend: backend2, attrs: { shape: finalShape } });
    } else if (sliceDim0 || isSimpleSlice) {
      util_exports.assert(x.shape.length >= 1, () => `Input must have rank at least 1, got: ${x.shape.length}`);
      const size2 = slice_util_exports.computeOutShape($begin, $end, $strides);
      const sliced = slice3({ inputs: { x }, backend: backend2, attrs: { begin: $begin, size: size2 } });
      result = reshape3({ inputs: { x: sliced }, backend: backend2, attrs: { shape: finalShape } });
      backend2.disposeIntermediateTensorInfo(sliced);
    } else {
      const shouldExecuteOnCPU = backend2.shouldExecuteOnCPU([x]);
      if (shouldExecuteOnCPU) {
        const values = backend2.readSync(x.dataId);
        const xBuf = buffer2(x.shape, x.dtype, values);
        const resultValues = stridedSliceImplCPU(finalShapeSparse, xBuf, $strides, $begin);
        result = backend2.makeTensorInfo(finalShape, x.dtype, resultValues.values);
      } else {
        const program = new StridedSliceProgram($begin, $strides, finalShapeSparse);
        result = backend2.runWebGLProgram(program, [x], x.dtype);
      }
    }
    const resultReshaped = reshape3({ inputs: { x: result }, backend: backend2, attrs: { shape: finalShape } });
    backend2.disposeIntermediateTensorInfo(result);
    return resultReshaped;
  }
  var stridedSliceConfig2 = {
    kernelName: StridedSlice,
    backendName: "webgl",
    kernelFunc: stridedSlice3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/StringNGrams.js
  function stringNGrams2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { separator, nGramWidths, leftPad, rightPad: rightPad2, padWidth, preserveShortSequences } = attrs;
    const { data, dataSplits } = inputs;
    const $data = backend2.readSync(data.dataId);
    const $dataSplits = backend2.readSync(dataSplits.dataId);
    const [nGrams, nGramsSplits] = stringNGramsImplCPU($data, $dataSplits, separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences);
    return [
      backend2.makeTensorInfo([nGrams.length], "string", nGrams),
      backend2.makeTensorInfo(dataSplits.shape, "int32", nGramsSplits)
    ];
  }
  var stringNGramsConfig2 = {
    kernelName: StringNGrams,
    backendName: "webgl",
    kernelFunc: stringNGrams2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/StringSplit.js
  function stringSplit2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { skipEmpty } = attrs;
    const { input: input2, delimiter } = inputs;
    if (input2.dtype !== "string") {
      throw new Error("Input must be of datatype string");
    }
    if (input2.shape.length !== 1) {
      throw new Error(`Input must be a vector, got shape: ${input2.shape}`);
    }
    if (delimiter.shape.length !== 0) {
      throw new Error(`Delimiter must be a scalar, got shape: ${delimiter.shape}`);
    }
    const $input = backend2.readSync(input2.dataId);
    const $delimiter = backend2.readSync(delimiter.dataId)[0];
    const [indices, values, shape] = stringSplitImplCPU($input, $delimiter, skipEmpty);
    const outputSize = values.length;
    return [
      backend2.makeTensorInfo([outputSize, 2], "int32", indices),
      backend2.makeTensorInfo([outputSize], "string", values),
      backend2.makeTensorInfo([2], "int32", new Int32Array(shape))
    ];
  }
  var stringSplitConfig2 = {
    kernelName: StringSplit,
    backendName: "webgl",
    kernelFunc: stringSplit2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/StringToHashBucketFast.js
  function stringToHashBucketFast2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { numBuckets } = attrs;
    const { input: input2 } = inputs;
    if (input2.dtype !== "string") {
      throw new Error("Input must be of datatype string");
    }
    if (numBuckets <= 0) {
      throw new Error(`Number of buckets must be at least 1`);
    }
    const $input = backend2.readSync(input2.dataId);
    const output = stringToHashBucketFastImplCPU($input, numBuckets);
    return backend2.makeTensorInfo(input2.shape, "int32", output);
  }
  var stringToHashBucketFastConfig2 = {
    kernelName: StringToHashBucketFast,
    backendName: "webgl",
    kernelFunc: stringToHashBucketFast2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Tan.js
  var TAN = `return tan(x);`;
  var tan3 = unaryKernelFunc2({ opSnippet: TAN });
  var tanConfig2 = {
    kernelName: Tan,
    backendName: "webgl",
    kernelFunc: tan3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Tanh.js
  var TANH = `
  float e2x = exp(-2.0 * abs(x));
  return sign(x) * (1.0 - e2x) / (1.0 + e2x);
`;
  var tanh4 = unaryKernelFunc2({ opSnippet: TANH });
  var tanhConfig2 = {
    kernelName: Tanh,
    backendName: "webgl",
    kernelFunc: tanh4
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/tile_gpu.js
  var TileProgram = class {
    constructor(aShape, reps) {
      this.variableNames = ["A"];
      const outputShape = new Array(aShape.length);
      for (let i = 0; i < outputShape.length; i++) {
        outputShape[i] = aShape[i] * reps[i];
      }
      this.outputShape = outputShape;
      this.rank = outputShape.length;
      const dtype = getCoordsDataType(this.rank);
      const sourceCoords = getSourceCoords3(aShape);
      this.userCode = `
      void main() {
        ${dtype} resRC = getOutputCoords();
        setOutput(getA(${sourceCoords}));
      }
    `;
    }
  };
  function getSourceCoords3(aShape) {
    const rank = aShape.length;
    if (rank > 5) {
      throw Error(`Tile for rank ${rank} is not yet supported`);
    }
    if (rank === 1) {
      return `imod(resRC, ${aShape[0]})`;
    }
    const currentCoords = ["resRC.x", "resRC.y", "resRC.z", "resRC.w", "resRC.u"];
    const sourceCoords = [];
    for (let i = 0; i < aShape.length; i++) {
      sourceCoords.push(`imod(${currentCoords[i]}, ${aShape[i]})`);
    }
    return sourceCoords.join();
  }

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Tile.js
  function tile4(params) {
    const { inputs, backend: backend2, attrs } = params;
    const { x } = inputs;
    const { reps } = attrs;
    if (x.dtype === "string" || x.shape.length > 5) {
      const data = backend2.readSync(x.dataId);
      const value = x.dtype === "string" ? data.map((d) => util_exports.decodeString(d)) : data;
      const buf = buffer2(x.shape, x.dtype, value);
      const outBuf = tileImplCPU(buf, reps);
      return backend2.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
    }
    const program = new TileProgram(x.shape, reps);
    const output = backend2.runWebGLProgram(program, [x], x.dtype);
    return output;
  }
  var tileConfig2 = {
    kernelName: Tile,
    backendName: "webgl",
    kernelFunc: tile4
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/top_k_gpu.js
  var SwapProgram = class {
    constructor(shape) {
      this.variableNames = ["x", "indices"];
      this.customUniforms = [
        { name: "n", type: "int" },
        { name: "firstPass", type: "int" },
        { name: "negativeInf", type: "float" },
        { name: "dir", type: "int" },
        { name: "inc", type: "int" }
      ];
      this.outputShape = shape;
      this.userCode = `
       void main() {
         ivec2 coords = getOutputCoords();
         int batch = coords[0];
         int elemIdx = coords[1];

         // We compare elements pair-wise within a group of size 2 * inc.
         // The comparing rule for each group alternates between ascending
         // and descending. Within each group, we compare each pair at
         // positions i and i+inc. To decide whether an element at position i
         // is x0 or x1, we mod it by 2 * inc, if the result is smaller than
         // inc, it is in the first half of the group, we denote it as x0,
         // otherwise we denote it as x1.
         // For example, as shown in the Bitonic top K paper referenced above,
         // Figure5(a) shows that element[1] is in the
         // second half of the group when group size is 2, but it is in the
         // first half of the group when group size is 4.

         bool isFirstInPair = imod(elemIdx, 2 * inc) < inc;
         int i = isFirstInPair ? elemIdx : elemIdx - inc;

         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));
         int i1 = firstPass == 1 ? i + inc : int(getIndices(batch, i + inc));
         float x0 = i0 < n ? getX(batch, i0) : negativeInf;
         float x1 = i1 < n ? getX(batch, i1) : negativeInf;

         // Denotes which direction indices are in (ascending or descending).
         bool reverse = imod(elemIdx, 2 * dir) >= dir;
         bool isGreater = x0 > x1 || (x0 == x1 && i1 > i0);
         if (reverse == isGreater) { // Elements in opposite order of direction
           int iTemp = i0;
           i0 = i1;
           i1 = iTemp;
         }
         if (isFirstInPair) {
            setOutput(float(i0));
         } else {
            setOutput(float(i1));
         }
       }
     `;
    }
  };
  var MergeProgram = class {
    constructor(shape) {
      this.variableNames = ["x", "indices"];
      this.customUniforms = [
        { name: "n", type: "int" },
        { name: "firstPass", type: "int" },
        { name: "k", type: "int" }
      ];
      this.outputShape = shape;
      this.userCode = `
    void main() {
         // Takes max of indices (0, k), (1, k + 1), (2, k + 2) ...
         ivec2 coords = getOutputCoords();
         int batch = coords[0];
         int elemIdx = coords[1];

         // The output size is half of the previous size.
         // If the previous sequence is | | | | _ _ _ _  | | | |  _ _ _ _ (k=4),
         // we only need to output the indices at positions |, the indices at
         // positions _ can be thrown away, see Figure5(b) After Phase 2
         // (Merge phase) in the Bitonic Top K paper referenced above.
         // For example, the paper shows we only need to output the orange bars.
         // The output sequence should look like this | | | | | | | |.
         // Because the sequence is halved, to map the output index back
         // to the previous sequence to find the corresponding value,
         // we need to double the index. When we double the index,
         // we basically interpolate a position, so 2i looks like
         // | _ | _ | _ | _ | _ | _ | _. We move the | to the first k position
         // of each 2k positions by - elemIdx % k. E.g. for output at
         // index 4,5,6,7, we want to get the corresponding element at
         // original index 8,9,10,11, for output at index 8,9,10,11,
         // we want to get the corresponding element at original index
         // 16,17,18,19, so on and so forth.

         int i = elemIdx < k ? elemIdx : (elemIdx * 2 - imod(elemIdx, k));
         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));
         int i1 = firstPass == 1 ? i + k : int(getIndices(batch, i + k));

         float x0 = getX(batch, i0);
         float x1 = i1 < n ? getX(batch, i1) : x0;

         setOutput(x0 >= x1 ? float(i0) : float(i1));
       }
     `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/TopK.js
  function disposeIntermediateTensorInfoOrNull(backend2, tensorInfo) {
    if (tensorInfo !== null) {
      backend2.disposeIntermediateTensorInfo(tensorInfo);
    }
  }
  function roundUpToPow2(num) {
    let pow22 = 1;
    while (pow22 < num) {
      pow22 *= 2;
    }
    return pow22;
  }
  function topK2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x } = inputs;
    const { k, sorted } = attrs;
    const TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD = env().getNumber("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD");
    const TOPK_K_CPU_HANDOFF_THRESHOLD = env().getNumber("TOPK_K_CPU_HANDOFF_THRESHOLD");
    const xShape = x.shape;
    const lastDim = xShape[xShape.length - 1];
    if (backend2.shouldExecuteOnCPU([x]) || lastDim < TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD || k > TOPK_K_CPU_HANDOFF_THRESHOLD) {
      const xVals = backend2.readSync(x.dataId);
      const [allTopKVals, allTopKIndices] = topKImplCPU(xVals, xShape, x.dtype, k, sorted);
      return [
        backend2.makeTensorInfo(allTopKVals.shape, allTopKVals.dtype, allTopKVals.values),
        backend2.makeTensorInfo(allTopKIndices.shape, allTopKIndices.dtype, allTopKIndices.values)
      ];
    }
    if (k === 0) {
      xShape[xShape.length - 1] = 0;
      return [
        backend2.makeTensorInfo(xShape, x.dtype, []),
        backend2.makeTensorInfo(xShape, "int32", [])
      ];
    }
    if (lastDim === 1) {
      return [
        x,
        fill3({ attrs: { shape: xShape, dtype: "int32", value: 0 }, backend: backend2 })
      ];
    }
    const xtexData = backend2.texData.get(x.dataId);
    const xIsPacked = xtexData !== null && xtexData.isPacked;
    const xUnPacked = xIsPacked ? backend2.unpackTensor(x) : x;
    const xSize = util_exports.sizeFromShape(xShape);
    const batch = xSize / lastDim;
    const x2D = reshape3({ inputs: { x: xUnPacked }, attrs: { shape: [batch, lastDim] }, backend: backend2 });
    if (xIsPacked) {
      disposeIntermediateTensorInfoOrNull(backend2, xUnPacked);
    }
    const kPow2 = roundUpToPow2(k);
    const lastDimPow2 = roundUpToPow2(lastDim);
    let indices = null;
    const getInputs = () => indices === null ? [x2D, x2D] : [x2D, indices];
    const runSwap = (dir, inc, shape) => {
      const inputs2 = getInputs();
      const program = new SwapProgram(shape);
      const fistPass = indices === null ? 1 : 0;
      const customValues = [[lastDim], [fistPass], [Number.NEGATIVE_INFINITY], [dir], [inc]];
      const prevIndices2 = indices;
      indices = backend2.runWebGLProgram(program, inputs2, "int32", customValues);
      disposeIntermediateTensorInfoOrNull(backend2, prevIndices2);
    };
    for (let len = 1; len < kPow2; len *= 2) {
      const dir = len * 2;
      for (let inc = len; inc >= 1; inc /= 2) {
        runSwap(dir, inc, [batch, lastDimPow2]);
      }
    }
    for (let indicesSize = lastDimPow2; indicesSize > kPow2; indicesSize /= 2) {
      const inputs2 = getInputs();
      const mergeProgram = new MergeProgram([batch, indicesSize / 2]);
      const firstPass = indices === null ? 1 : 0;
      const customValues = [[lastDim], [firstPass], [kPow2]];
      const prevIndices2 = indices;
      indices = backend2.runWebGLProgram(mergeProgram, inputs2, "int32", customValues);
      disposeIntermediateTensorInfoOrNull(backend2, prevIndices2);
      const len = kPow2 / 2;
      const dir = len * 2;
      for (let inc = len; inc >= 1; inc /= 2) {
        runSwap(dir, inc, indices.shape);
      }
    }
    let prevIndices = indices;
    indices = slice3({ inputs: { x: indices }, backend: backend2, attrs: { begin: 0, size: [batch, k] } });
    disposeIntermediateTensorInfoOrNull(backend2, prevIndices);
    let values = gatherV22({ inputs: { x: x2D, indices }, backend: backend2, attrs: { axis: 1, batchDims: 1 } });
    disposeIntermediateTensorInfoOrNull(backend2, x2D);
    const newShape = xShape.slice(0, -1);
    newShape.push(k);
    prevIndices = indices;
    indices = reshape3({ inputs: { x: indices }, attrs: { shape: newShape }, backend: backend2 });
    disposeIntermediateTensorInfoOrNull(backend2, prevIndices);
    const prevValues = values;
    values = reshape3({ inputs: { x: values }, attrs: { shape: newShape }, backend: backend2 });
    disposeIntermediateTensorInfoOrNull(backend2, prevValues);
    return [values, indices];
  }
  var topKConfig2 = {
    kernelName: TopK,
    backendName: "webgl",
    kernelFunc: topK2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/transform_gpu.js
  var TransformProgram = class {
    constructor(imageHeight, imageWidth, interpolation, fillMode, fillValue, outShape) {
      this.variableNames = ["Image", "Transforms"];
      this.outputShape = outShape;
      const interpolationModeId = interpolation === "nearest" ? 1 : 2;
      let fillModeId;
      switch (fillMode) {
        case "constant":
          fillModeId = 1;
          break;
        case "reflect":
          fillModeId = 2;
          break;
        case "wrap":
          fillModeId = 3;
          break;
        case "nearest":
          fillModeId = 4;
          break;
        default:
          fillModeId = 1;
          break;
      }
      this.userCode = `
            float mapCoord(float outCoord, float len) {
              float inCoord = outCoord;
              if(${fillModeId} == 2) {
                if (inCoord < 0.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz2 = 2.0 * len;
                    if (inCoord < sz2) {
                      inCoord = sz2 * float(int(float(-inCoord / sz2))) +
                      inCoord;
                    }
                    inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1.0;
                  }
                } else if (inCoord > len - 1.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz2 = 2.0 * len;
                    inCoord -= sz2 * float(int(float(inCoord / sz2)));
                    if (inCoord >= len) {
                      inCoord = sz2 - inCoord - 1.0;
                    }
                  }
                }
                return clamp(inCoord, 0.0, len - 1.0);
              } else if (${fillModeId} == 3) {
                if (inCoord < 0.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz = len - 1.0;
                    inCoord += len * (float(int(float(-inCoord / sz))) + 1.0);
                  }
                } else if (inCoord > len - 1.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz = len - 1.0;
                    inCoord -= len * float(int(float(inCoord / sz)));
                  }
                }
                return clamp(inCoord, 0.0, len - 1.0);
              } else if (${fillModeId} == 4) {
                return clamp(outCoord, 0.0, len - 1.0);
              } else {
                return outCoord;
              }
            }

            float readWithFillValue(int batch, int coordY, int coordX,
              int channel) {
              float outputValue;
              if (0 <= coordY && coordY < ${imageHeight} && 0 <= coordX && coordX < ${imageWidth}) {
                  outputValue = getImage(batch, coordY, coordX, channel);
              } else {
                outputValue = float(${fillValue});
              }
              return outputValue;
            }

            void main() {
              ivec4 coords = getOutputCoords();
              float outputValue;
              int batch = coords[0];
              int x = coords[2];
              int y = coords[1];
              int channel = coords[3];
              float xf = float(x);
              float yf = float(y);
              float a1 = getTransforms(batch, 0);
              float a2 = getTransforms(batch, 1);
              float a3 = getTransforms(batch, 2);
              float b1 = getTransforms(batch, 3);
              float b2 = getTransforms(batch, 4);
              float b3 = getTransforms(batch, 5);
              float c1 = getTransforms(batch, 6);
              float c2 = getTransforms(batch, 7);
              float projection = c1 * xf + c2 * yf + 1.0;
              if (projection == 0.0) {
                outputValue = float(${fillValue});
              } else {
                float inX = (a1 * xf + a2 * yf + a3) / projection;
                float inY = (b1 * xf + b2 * yf + b3) / projection;
                float mapX = mapCoord(inX, float(${imageWidth}));
                float mapY = mapCoord(inY, float(${imageHeight}));

                if (${interpolationModeId} == 1) {
                  int coordY = int(round(mapY));
                  int coordX = int(round(mapX));
                  outputValue = readWithFillValue(batch, coordY, coordX,
                    channel);
                } else {
                  float yFloor = floor(mapY);
                  float xFloor = floor(mapX);
                  float yCeil = yFloor + 1.0;
                  float xCeil = xFloor + 1.0;
                  float valueYFloor = (xCeil - mapX) *
                  readWithFillValue(batch, int(yFloor), int(xFloor), channel) +
                  (mapX - xFloor) *
                  readWithFillValue(batch, int(yFloor), int(xCeil), channel);
                  float valueYCeil = (xCeil - mapX) *
                  readWithFillValue(batch, int(yCeil), int(xFloor), channel) +
                  (mapX - xFloor) *
                  readWithFillValue(batch, int(yCeil), int(xCeil), channel);
                  outputValue = (yCeil - mapY) * valueYFloor +
                  (mapY - yFloor) * valueYCeil;
                }
              }
              setOutput(outputValue);
            }
        `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Transform.js
  function transform3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { image: image3, transforms } = inputs;
    const { interpolation, fillMode, fillValue, outputShape } = attrs;
    const [batch, imageHeight, imageWidth, numChannels] = image3.shape;
    const [outHeight, outWidth] = outputShape != null ? outputShape : [imageHeight, imageWidth];
    const outShape = [
      batch,
      outHeight,
      outWidth,
      numChannels
    ];
    const program = new TransformProgram(imageHeight, imageWidth, interpolation, fillMode, fillValue, outShape);
    return backend2.runWebGLProgram(program, [image3, transforms], "float32");
  }
  var transformConfig2 = {
    kernelName: Transform,
    backendName: "webgl",
    kernelFunc: transform3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Unique.js
  function unique4(args) {
    const { inputs, attrs, backend: backend2 } = args;
    const { axis } = attrs;
    const { x } = inputs;
    assertNotComplex2(x, "unique");
    console.warn("WARNING: ", "UI might be locked temporarily as data is being downloaded");
    const values = backend2.readSync(x.dataId);
    const { outputValues, outputShape, indices } = uniqueImplCPU(values, axis, x.shape, x.dtype);
    return [
      backend2.makeTensorInfo(outputShape, x.dtype, outputValues),
      backend2.makeTensorInfo([indices.length], "int32", indices)
    ];
  }
  var uniqueConfig2 = {
    kernelName: Unique,
    backendName: "webgl",
    kernelFunc: unique4
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Unpack.js
  function unpack2(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { value } = inputs;
    let { axis } = attrs;
    if (axis < 0) {
      axis += value.shape.length;
    }
    const x = value;
    const xRank = x.shape.length;
    const num = value.shape[axis];
    const outShape = new Array(xRank - 1);
    let outIndex = 0;
    for (let i = 0; i < xRank; i++) {
      if (i !== axis) {
        outShape[outIndex++] = x.shape[i];
      }
    }
    const toDispose = [];
    const begin = new Array(xRank).fill(0);
    const size2 = x.shape.slice();
    size2[axis] = 1;
    const res = new Array(num);
    for (let i = 0; i < res.length; i++) {
      begin[axis] = i;
      const sliced = slice3({ inputs: { x }, backend: backend2, attrs: { begin, size: size2 } });
      const reshaped = reshape3({ inputs: { x: sliced }, backend: backend2, attrs: { shape: outShape } });
      res[i] = reshaped;
      toDispose.push(sliced);
    }
    toDispose.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
    return res;
  }
  var unpackConfig2 = {
    kernelName: Unpack,
    backendName: "webgl",
    kernelFunc: unpack2
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/segment_gpu.js
  var SegmentOpProgram = class {
    constructor(segOpInfo, segOpType) {
      this.variableNames = ["x", "segmentIds"];
      const windowSize = segOpInfo.windowSize;
      const batchSize = segOpInfo.batchSize;
      const inSize = segOpInfo.inSize;
      const numSegments = segOpInfo.numSegments;
      const outSize = numSegments * Math.ceil(inSize / windowSize);
      this.outputShape = [batchSize, outSize];
      const initializationValue = "0.0";
      const returnValue = `sumValue`;
      const windowSizeNearestVec4 = Math.floor(windowSize / 4) * 4;
      const windowSizeVec4Remainder = windowSize % 4;
      const updateSnippet = `
        sumValue += dot(values, segFilter);
    `;
      let checkValueOutOfBounds = "";
      if (inSize % windowSize > 0) {
        checkValueOutOfBounds = `
        if (inIdx < 0 || inIdx >= ${inSize}) {
          return initializationValue;
        }
      `;
      }
      let checkSegmentIdOutOfBounds = "";
      if (inSize % windowSize > 0) {
        checkSegmentIdOutOfBounds = `
        if (inIdx < 0 || inIdx >= ${inSize}) {
          return -1.0;
        }
      `;
      }
      this.userCode = `
      const float initializationValue = ${initializationValue};

      float getValue(int batch, int inIdx) {
        ${checkValueOutOfBounds}
        return getX(batch, inIdx);
      }

      float getSegmentIdAtIndex(int inIdx) {
        ${checkSegmentIdOutOfBounds}
        return getSegmentIds(inIdx);
      }

      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = int(floor(float(outIdx) / float(
          ${numSegments})) * float(${windowSize}));
        int currentSeg = int(mod(float(outIdx), float(${numSegments})));

        float sumValue = 0.0;

        for (int i = 0; i < ${windowSizeNearestVec4}; i += 4) {
          int inIdx = inOffset + i;
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            getValue(batch, inIdx + 3)
          );

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0
          );

          ${updateSnippet}
        }

        int inIdx = inOffset + ${windowSizeNearestVec4};
        if (${windowSizeVec4Remainder === 1}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            initializationValue,
            initializationValue,
            initializationValue
          );

          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            0,
            0,
            0
          );

          ${updateSnippet}
        } else if (${windowSizeVec4Remainder === 2}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            initializationValue,
            initializationValue
          );

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,
              0,
              0
          );

          ${updateSnippet}
        } else if (${windowSizeVec4Remainder === 3}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            initializationValue
          );

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,
            0
          );

          ${updateSnippet}
        }
        setOutput(${returnValue});
      }
    `;
    }
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/UnsortedSegmentSum.js
  function unsortedSegmentSum3(args) {
    const { inputs, backend: backend2, attrs } = args;
    const { x, segmentIds } = inputs;
    const { numSegments } = attrs;
    const xRank = x.shape.length;
    const toDispose = [];
    let axis = 0;
    const permutation = backend_util_exports.getAxesPermutation([axis], xRank);
    let permutedX = x;
    if (permutation != null) {
      permutedX = transpose3({ inputs: { x }, backend: backend2, attrs: { perm: permutation } });
      toDispose.push(permutedX);
      axis = backend_util_exports.getInnerMostAxes(1, xRank)[0];
    }
    const outShape = backend_util_exports.segment_util.computeOutShape(permutedX.shape, axis, numSegments);
    const inSize = util_exports.sizeFromShape([permutedX.shape[axis]]);
    const a2D = reshape3({ inputs: { x: permutedX }, backend: backend2, attrs: { shape: [-1, inSize] } });
    toDispose.push(a2D);
    const outputDType = sumOutType(x.dtype);
    const segOpCompute = (x2, segOpType, segmentIds2, dtype, numSegments2) => {
      const batchSize = x2.shape[0];
      const inSize2 = x2.shape[1];
      const windowSize = backend_util_exports.segment_util.segOpComputeOptimalWindowSize(inSize2, numSegments2);
      const segOpInfo = { windowSize, inSize: inSize2, batchSize, numSegments: numSegments2 };
      const program = new SegmentOpProgram(segOpInfo, segOpType);
      const output = backend2.compileAndRun(program, [x2, segmentIds2], dtype);
      toDispose.push(output);
      if (output.shape[1] === numSegments2) {
        return output;
      }
      const rangeInfo = range4({
        backend: backend2,
        attrs: { start: 0, stop: numSegments2, step: 1, dtype: "float32" }
      });
      const tileInfo = tile4({
        inputs: { x: rangeInfo },
        backend: backend2,
        attrs: { reps: [inSize2 / windowSize] }
      });
      toDispose.push(rangeInfo);
      toDispose.push(tileInfo);
      const result2 = segOpCompute(output, segOpType, tileInfo, dtype, numSegments2);
      return result2;
    };
    const segOpResult = segOpCompute(a2D, "unsortedSegmentSum", segmentIds, outputDType, numSegments);
    const reshaped = reshape3({ inputs: { x: segOpResult }, backend: backend2, attrs: { shape: outShape } });
    let result = reshaped;
    if (permutation != null) {
      toDispose.push(reshaped);
      const perm = backend_util_exports.getUndoAxesPermutation(permutation);
      result = transpose3({ inputs: { x: result }, backend: backend2, attrs: { perm } });
    }
    toDispose.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
    return result;
  }
  var unsortedSegmentSumConfig2 = {
    kernelName: UnsortedSegmentSum,
    backendName: "webgl",
    kernelFunc: unsortedSegmentSum3
  };

  // node_modules/@tensorflow/tfjs-backend-webgl/dist/register_all_kernels.js
  var kernelConfigs2 = [
    LRNConfig,
    LRNGradConfig,
    _fusedMatMulConfig2,
    absConfig2,
    acosConfig2,
    acoshConfig2,
    addConfig2,
    addNConfig2,
    allConfig2,
    anyConfig2,
    argMaxConfig2,
    argMinConfig2,
    asinConfig2,
    asinhConfig2,
    atan2Config2,
    atanConfig2,
    atanhConfig2,
    avgPool3DConfig2,
    avgPoolConfig2,
    avgPoolGrad3DConfig,
    avgPoolGradConfig3,
    batchMatMulConfig2,
    batchNormConfig2,
    batchToSpaceNDConfig2,
    bincountConfig2,
    broadcastArgsConfig2,
    castConfig2,
    ceilConfig2,
    clipByValueConfig,
    complexAbsConfig2,
    complexConfig2,
    concatConfig2,
    conv2DBackpropFilterConfig2,
    conv2DBackpropInputConfig2,
    conv2DConfig2,
    conv3DBackpropFilterV2Config2,
    conv3DBackpropInputConfig,
    conv3DConfig2,
    cosConfig2,
    coshConfig2,
    cropAndResizeConfig2,
    cumsumConfig2,
    denseBincountConfig2,
    depthToSpaceConfig2,
    depthwiseConv2dNativeBackpropFilterConfig2,
    depthwiseConv2dNativeBackpropInputConfig2,
    depthwiseConv2dNativeConfig2,
    diagConfig2,
    dilation2DConfig,
    einsumConfig2,
    eluConfig2,
    eluGradConfig3,
    equalConfig2,
    erfConfig2,
    expConfig2,
    expandDimsConfig2,
    expm1Config2,
    fftConfig2,
    fillConfig2,
    flipLeftRightConfig2,
    floorConfig2,
    floorDivConfig2,
    fromPixelsConfig,
    fusedConv2DConfig2,
    fusedDepthwiseConv2DConfig2,
    gatherNdConfig2,
    gatherV2Config2,
    greaterConfig2,
    greaterEqualConfig2,
    identityConfig2,
    ifftConfig2,
    imagConfig2,
    isFiniteConfig2,
    isInfConfig2,
    isNaNConfig2,
    leakyReluConfig2,
    lessConfig2,
    lessEqualConfig2,
    linSpaceConfig2,
    log1pConfig2,
    logConfig2,
    logicalAndConfig2,
    logicalNotConfig2,
    logicalOrConfig2,
    maxConfig2,
    maxPool3DConfig2,
    maxPoolConfig2,
    maxPoolGrad3DConfig,
    maxPoolGradConfig3,
    maxPoolWithArgmaxConfig2,
    maximumConfig2,
    meanConfig2,
    minConfig2,
    minimumConfig2,
    mirrorPadConfig2,
    modConfig2,
    multinomialConfig2,
    multiplyConfig2,
    negConfig2,
    nonMaxSuppressionV3Config2,
    nonMaxSuppressionV4Config2,
    nonMaxSuppressionV5Config2,
    notEqualConfig2,
    oneHotConfig2,
    onesLikeConfig2,
    packConfig2,
    padV2Config2,
    powConfig2,
    preluConfig2,
    prodConfig2,
    rangeConfig2,
    realConfig2,
    realDivConfig2,
    reciprocalConfig2,
    relu6Config2,
    reluConfig2,
    reshapeConfig2,
    resizeBilinearConfig2,
    resizeBilinearGradConfig3,
    resizeNearestNeighborConfig2,
    resizeNearestNeighborGradConfig3,
    reverseConfig2,
    rotateWithOffsetConfig2,
    roundConfig2,
    rsqrtConfig2,
    scatterNdConfig2,
    selectConfig2,
    seluConfig2,
    sigmoidConfig2,
    signConfig2,
    sinConfig2,
    sinhConfig2,
    sliceConfig2,
    softmaxConfig2,
    softplusConfig2,
    spaceToBatchNDConfig2,
    sparseFillEmptyRowsConfig2,
    sparseReshapeConfig2,
    sparseSegmentMeanConfig2,
    sparseSegmentSumConfig2,
    sparseToDenseConfig2,
    splitVConfig2,
    sqrtConfig2,
    squareConfig2,
    squaredDifferenceConfig2,
    stepConfig2,
    stridedSliceConfig2,
    stringNGramsConfig2,
    stringSplitConfig2,
    stringToHashBucketFastConfig2,
    subConfig2,
    sumConfig2,
    tanConfig2,
    tanhConfig2,
    tileConfig2,
    topKConfig2,
    transformConfig2,
    transposeConfig2,
    uniqueConfig2,
    unpackConfig2,
    unsortedSegmentSumConfig2,
    zerosLikeConfig2
  ];
  for (const kernelConfig of kernelConfigs2) {
    registerKernel(kernelConfig);
  }

  // hw4/bd_sents.json
  var bd_sents_default = [[0, "bipolar disorder be a serious disorder of mood that be associate with considerable psychosocial and economic morbidity."], [0, "even though it be more common than previously think, it have until relatively recently be somewhat neglect in term of research when compare to disorder such as schizophrenia and major depression."], [0, "recent advance in the field of nosology, epidemiology, and molecular genetic in particular have begin to unravel some of the complexity of this disorder and the next few year be likely to witness substantial change to the way in which the broad spectrum of bipolar disorder be diagnose and manage."], [1, "over the last decade, there have be a grow appreciation of the importance of identify and treat cognitive impairment associate with bipolar disorder, since it persist in remission period."], [1, "evidence indicate that neurocognitive dysfunction may significantly influence patient' psychosocial outcome."], [1, "an ever-increase body of research seek to achieve a well understanding of potential moderator contribute to cognitive impairment in bipolar disorder in order to develop prevention strategy and effective treatment."], [1, "this review provide an overview of the available datum from study examine treatment for cognitive dysfunction in bipolar disorder as well as potential novel treatment, from both pharmacological and psychological perspective."], [1, "all these datum encourage the development of further study to find effective strategy to prevent and treat cognitive impairment associate with bipolar disorder."], [1, "these effort may ultimately lead to an improvement of psychosocial function in these patient."], [2, "it be clinically important to recognize both bipolar disorder and borderline personality disorder (bpd) in patient seek treatment for depression, and it be important to distinguish between the two."], [2, "research consider whether bpd should be consider part of a bipolar spectrum reach differ conclusion."], [2, "we review the most studied question on the relationship between bpd and bipolar disorder: their diagnostic concordance."], [2, "across study, approximately 10% of patient with bpd have bipolar i disorder and another 10% have bipolar ii disorder."], [2, "likewise, approximately 20% of bipolar ii patient be diagnose with bpd, though only 10% of bipolar i patient be diagnose with bpd."], [2, "while the comorbidity rate be substantial, each disorder be nontheless diagnose in the absence of the other in the vast majority of case (80% to 90%)."], [2, "in study examine personality disorder broadly, other personality disorder be more commonly diagnose in bipolar patient than be bpd."], [2, "likewise, the converse be also true: other axis i disorder such as major depression, substance abuse, and post-traumatic stress disorder be also more commonly diagnose in patient with bpd than be bipolar disorder."], [2, "these finding challenge the notion that bpd be part of the bipolar spectrum."], [3, "episode duration, recurrence rate, and time spend in manic and depressive phase of bipolar disorder (bd) be not well define for subtype of the disorder."], [3, "we review the course, timing, and duration of episode of mania and depression among 1130 clinically treat dsm-iv-tr bd patient of various type, and compare duration and rate as well as total proportion of time in depressive versus manic episode during 16.7 average year at risk."], [3, "as expect, episode of depression be much long than mania, but episode-duration do not differ among bd diagnostic type: i, ii, with mainly mix-episode (bd-mx), or with psychotic feature (bd-p)."], [3, "recurrence rate (episode/year) and proportion of time in depression and their ratio to mania be high in bd-ii and bd-mx subject, with more mania/year in psychotic and bd-i subject."], [3, "in most bd-subtype, except with psychotic feature, there be more time in depressive than manic morbidity, owe mainly to long depressive than manic episode."], [3, "the proportion of time in depression be high among those who follow a predominant dmi course, whereas total time in mania be great in bd with psychotic feature and bd-i. and with an mdi course."], [3, "subtype of bd patient differ little in episode-duration, which be consistently much long for depression."], [3, "the finding underscore the limited control of bipolar depression with available treatment."], [4, "characterize by the switch of manic and depressive phase, bipolar disorder be describe as early as the fifth century bc."], [4, "nevertheless up to date, the underlying neurobiology be still largely unclear, assume a multifactor genesis with both biological-genetic and psychosocial factor."], [4, "significant process have be achieve in recent year in research the cause of bipolar disorder with modern molecular biological (e.g., genetic and epigenetic study) and imaging technique (e.g., positron emission tomography (pet) and functional magnetic resonance imaging (fmri))."], [4, "in this chapter we will first summarize our recent knowledge on the etiology of bipolar disorder."], [4, "we then discuss how several factor observe to contribute to bipolar disorder in human patient can be manipulate to generate rodent model for bipolar disorder."], [4, "finally, we will give an overview on behavioral test that can be use to assess bipolar-disorder-like behavior in rodent."], [5, "borderline personality disorder (bpd) and bipolar disorder (type i and ii) be frequently confuse because of their symptomatic overlap."], [5, "although affective instability be a prominent feature of each, the pattern be entirely different."], [5, "bpd be characterize by transient mood shift that occur in response to interpersonal stressor, whereas bipolar disorder be associate with sustained mood change."], [5, "these disorder can be far distinguish by compare their phenomenology, etiology, family history, biological study, outcome, and response to medication."], [5, "their distinction be of great clinical importance because misdiagnosis can deprive the patient of potentially effective treatment, whether it be psychotherapy for bpd or medication for bipolar disorder."], [5, "on the basis of a comprehensive literature review, guideline for differential diagnosis be suggest, and priority for further research be recommend."], [6, "this review article provide an overview of the frequency, burden of illness, diagnosis, and treatment of bipolar disorder (bd) from the perspective of the advanced practice nurse (apns)."], [6, 'pubmed search be conduct use the follow keyword: "bipolar disorder and primary care," restrict to date 2000 to present; "bipolar disorder and nurse practitioner"; and "bipolar disorder and clinical nurse specialist."'], [6, "select article be relevant to adult outpatient care in the united states, with a prioritization of article write by apn or publish in nursing journal."], [6, "bd have a substantial lifetime prevalence in the population at 4%."], [6, "because the manic or depressive symptom of bd tend to be severe and recurrent over a patient's lifetime, the condition be associate with significant burden to the individual, caregiver, and society."], [6, "clinician awareness that bd may be present increase the likelihood of successful recognition and appropriate treatment."], [6, "a number of pharmacological and nonpharmacological treatment be available for acute and maintenance treatment, with the prospect of achieve reduce symptom burden and increase function for many patient."], [6, "awareness of the disease burden, diagnostic issue, and management choice in bd have the potential to enhance outcome in substantial proportion of patient."], [7, "bipolar disorder be a severe psychiatric disorder, characterize by depressive, manic and mixed episode."], [7, "the illness affect about 1-2\xA0% of the population."], [7, "bipolar i disorder affect both gender equally, whereas bipolar ii disorder seem to occur more frequently in woman."], [7, "the classification of the different subtype of bipolar disorder be do depend on the severity and frequency of the episode."], [7, "other subtype beside bipolar i and bipolar ii disorder be rapid cycling (more than 4 episode of mania, depression, hypomania or mixed state in one year) and cyclothymia (hypomanic and subdepressive symptom over a two year period)."], [7, "besides a thorough psychiatric and neurological examination, further clinical test should be perform in order to exclude differential diagnosis (psychiatric as well as neurological and somatic disease)."], [7, "the course of the illness be often negatively affect by the high frequency of psychiatric and somatic comorbiditie."], [7, "after all the prognosis of bipolar disorder be depend on the individual course of the illness."], [7, "notably comorbiditie and psychotic symptom seem to have a negative influence on the prognosis."], [8, "further understanding of old age bipolar disorder (oabd) may lead to more specific recommendation for treatment adjust to the specific characteristic and need cause by age-relate somatic and cognitive change."], [8, "late-onset mania have a broad differential diagnosis and require full psychiatric and somatic work-up, include brain imaging."], [8, "research on pharmacotherapy in oabd be limited."], [8, "first-line treatment of oabd be similar to that for adult bipolar disorder (bd), with specific attention to vulnerability to side effect and somatic comorbidity."], [8, "because finding in young adult with bd cannot be extrapolate to oabd, more research in oabd be warrant."], [9, "bipolar disorder (bpd) be a potentially lifelong condition characterise by extreme change in mood that may begin in childhood and cause substantial impairment."], [9, "over the past decade, bpd have be the focus of increase attention mainly due to controversy surround its prevalence, diagnosis and treatment in child and adolescent."], [9, "this report address these controversy by review the extant evidence base, provide clinician with a summary of the literature on diagnosis, phenomenology and treatment of paediatric bpd."], [9, "the debate regard diagnose child with bpd base on severe irritability and aggression be mostly resolve."], [9, "the current data support utilise the diagnostic criterion base on episodic change of mood polarity."], [9, "therefore, longitudinal course of illness should be explore in detail when diagnose bpd."], [9, "give high rate of genetic predisposition for bpd, assessment of youth should focus on obtain accurate family history of this condition."], [9, "additionally, there have be a substantial increase in randomised placebo-control clinical trial evaluate pharmacological agent for mood stabilisation in child and adolescent, which we summarise in this review."], [9, "despite significant progress be make in the field of paediatric bpd, more research be need in the area of phenomenology, pathophysiology, course and treatment of this condition in youth."], [10, "people with bipolar disorder frequently experience persistent residual symptom, problem in psychosocial functioning, cognitive impairment, and poor quality of life."], [10, "in the last decade, the treatment target in clinical and research setting have focus not only on clinical remission, but also on functional recovery and, more lately, in personal recovery, take into account patient' well-being and quality of life."], [10, "hence, the trend in psychiatry and psychology be to treat bipolar disorder in an integrative and holistic manner."], [10, "this literature review offer an overview regard psychosocial function in bipolar disorder."], [10, "first, a brief summary be provide regard the definition of psychosocial functioning and the tool to measure it."], [10, "then, the most report variable influence the functional outcome in patient with bipolar disorder be list."], [10, "thereafter, we include a section discuss therapy with prove efficacy at enhance functional outcome."], [10, "other possible therapy that could be useful to prevent functional decline and improve function be present in another section."], [10, "finally, in the last part of this review, different intervention direct to improve patient' well-being, quality of life, and personal recovery be briefly describe."], [11, "patient with adult attention-deficit/ hyperactivity disorder (adhd) and bipolar disorder can present with similar symptom, include increase energy, distractibility, disorganization, impulsivity, hyperactivity, and rapid speech."], [11, "determine whether the patient have either, or possibly both, of these syndrome can be a complex task."], [11, "this review attempt to clarify where these disorder overlap, both symptomatically and epidemiologically, and where they diverge, to help clinician increase the accuracy of their diagnosis."], [11, "change to diagnostic criterion from the fourth to the fifth edition of the diagnostic and statistical manual of mental disorders (from dsm-iv-tr to dsm-5) be discuss, as be the evidence base for pharmacological treatment."], [11, "study and source be identify use computerized search."], [11, "adult adhd and bipolar disorder have multiple overlap symptom, but there be difference in prevalence (adhd affect 4.4% of adult in the united states versus 1.4% for bipolar disorder), onset of symptom (usually before age 7 year in adhd versus after age 12 year in bipolar disorder), disease course (chronic in adhd versus cyclical in bipolar disorder), mood symptom (absent in adhd but always present in bipolar disorder), and psychotic symptom (absent in adhd but sometimes present in bipolar disorder)."], [11, "approximately 20% of adult patient with adhd also have bipolar disorder, while 10%-20% of patient with bipolar disorder have adult adhd."], [11, "comorbidity of bipolar disorder and adhd be associate with an early age of onset and a more chronic and disabling course of bipolar disorder, as well as more psychiatric comorbidity."], [11, "distinguish between adult adhd and bipolar disorder require careful attention to phenomenology and awareness of epidemiology, with a focus on childhood history, lifetime course of symptom, and the possibility of comorbidity."], [12, "bipolar disorder be a lifelong mood disorder characterize by extreme mood swing between mania and depression."], [12, "despite fitness cost associate with increase mortality and significant impairment, bipolar disorder have persist in the population with a high heritability and a stable prevalence."], [12, "creativity and other positive trait have repeatedly be associate with the bipolar spectrum, particularly among unaffected first-degree relative and those with milder expression of bipolar trait."], [12, "this suggest a model in which large dose of risk variant cause illness, but mild to moderate dose confer advantage, which serve to maintain bipolar disorder in the population."], [12, "bipolar disorder may thus be well conceptualize as a dimensional trait exist at the extreme of normal population variation in positive temperament, personality, and cognitive trait, aspect of which may reflect a share vulnerability with creativity."], [12, "investigation of this share vulnerability may provide insight into the genetic mechanism underlie illness and suggest novel treatment."], [13, "because the elderly be the fast grow segment of the population, the number of old adult with bipolar disorder be increase."], [13, "geriatric bipolar disorder be relatively rare, with an estimate lifetime prevalence of 0.5% to 1%, although approximately 4% to 17% of old patient in clinical psychiatric setting have bipolar disorder."], [13, "bipolar elder be disproportionately affect by medical burden."], [13, "give the complex nature of this disorder, comorbidity, and behavioral disturbance, various intervention may be indicate, include pharmacotherapie, electroconvulsive therapy, psychotherapy, and integrate care model."], [13, "additional research be need to well understand the epidemiology, phenomenology, and treatment of geriatric bipolar disorder."], [14, "the purpose of this study be to analyze the evidence support a staging model for bipolar disorder."], [14, "the author conduct an extensive medline and pubme search of the publish literature use a variety of search term (staging, bipolar disorder, early intervention) to find relevant article, which be review in detail."], [14, "only recently specific proposal have be make to apply clinical staging to bipolar disorder."], [14, "the staging model in bipolar disorder suggest a progression from prodromal (at-risk) to more severe and refractory presentation (stage iv)."], [14, "a staging model imply a longitudinal appraisal of different aspect: clinical variable, such as number of episode and subsyndromal symptom, functional and cognitive impairment, comorbidity, biomarker, and neuroanatomical change."], [14, "staging model be base on the fact that response to treatment be generally well when it be introduce early in the course of the illness."], [14, "it assume that early stage have well prognosis and require simple therapeutic regimen."], [14, "staging may assist in bipolar disorder treatment planning and prognosis, and emphasize the importance of early intervention."], [14, "further research be require in this exciting and novel area."], [15, "the population over age 60 be grow more rapidly than the general population."], [15, "give the project increase and need for datum that can inform treatment, this review provide a brief description of new publication focus on mania in old-age bipolar disorder (oabd), include epidemiology, diagnosis, and treatment."], [15, "age cutoff to define oabd range from 50 to 65\xA0year."], [15, "oabd clinical presentation and course of illness be highly variable, often characterize by mood episode recurrence, medical comorbidity, cognitive deficit, and impaired functioning."], [15, "there be little pharmacotherapy datum on mania in oabd."], [15, "lithium and valproate have be test in a single randomized control trial and there be datum of more limited quality with other compound."], [15, "treat oabd be challenge due to medical complexity, comorbidity, diminish tolerance to treatment, and a limited evidence base."], [15, "more datum be need to keep pace with clinical demand."], [16, "bipolar disorder (manic-depressive illness) be a common, recurrent, and severe psychiatric disorder that affect 1% to 3% of the us population."], [16, "the illness be characterize by episode of mania, depression, or mixed state (simultaneously occur manic and depressive symptom)."], [16, "bipolar disorder frequently go unrecognized and untreated for many year without clinical vigilance."], [16, "new screening tool have be develop to assist physician in make the diagnosis."], [16, "fortunately, several medication be now available to treat the acute mood episode of bipolar disorder and to prevent further episode with maintenance treatment."], [17, "bipolar disorder be a chronic, severe, recurrent mood disorder."], [17, "traditional estimate of the prevalence of the disorder may underestimate the actual total disease burden."], [17, "the condition can occur across a wide spectrum of age, but the most common age of onset appear to be between the age of 15 and 19."], [17, "bipolar disorder be often underdiagnose or misdiagnose, with profound negative clinical and economic consequence."], [17, "medical and psychiatric comorbidity be common in patient with bipolar disorder."], [17, "functional disability because of bipolar disorder be comparable with that of many chronic medical condition."], [17, "it have be estimate that the total annual societal cost of bipolar disorder may be as high as 45 billion dollar."], [18, "essential fact."], [18, "bipolar disorder be a potentially lifelong and disabling condition."], [18, "bipolar i, characterise by episode of mania and depression, be estimate to affect 1 per cent of the adult population."], [18, "bipolar ii, characterise by hypomania and depression, affect an estimate 0.4 per cent of adult."], [18, "episode can vary in length and frequency."], [19, "bipolar affective disorder run a natural course of frequent relapse and recurrence."], [19, "despite significant stride in the pharmacological treatment of bipolar disorder, most bipolar patient cannot be treat only by drug."], [19, "the limitation of use medication alone in symptomatic, relapse prevention, and satisfaction/quality of life term have long prompt interest in wide form of management."], [19, "one of the promising way how to enhance remission seem to be combination of pharmacotherapy and psychoeducation."], [19, "study be identify through pubmed, web of science and scopus database as well as exist review."], [19, 'the search term include "bipolar disorder", "psychoeducation", "psychotherapy", "psychosocial treatment", "family therapy", "individual therapy", "group therapy", and "psychoeducation".'], [19, "the search be perform by repeat use of the word in different combination with no language or time limitation."], [19, "this article be a review with conclusion concern with psychoeducation in bipolar disorder."], [19, "randomize control trial of cognitive behavioral therapy, interpersonal and social rhythm therapy, individual, group and family psychoeducation show that these approach augment stabilize effect of pharmacotherapy."], [19, "patient and their family should be educate about bipolar disorder, trigger, warning sign, mood relapse, suicidal ideation, and the effectiveness of early intervention to reduce complication."], [19, "psychosocial approach be important therapeutic strategy for reduce relapse and rehospitalization in bipolar disorder."], [20, "primary mania and hypomania in full or subsyndromal form be the define feature of bipolar disorder and be common in neurologic patient, as be manic syndrome precipitate by medication use to treat neurologic disorder."], [20, "this article address the diagnosis, pathophysiology, treatment, and course of bipolar disorder after a manic episode as well as mania as a manifestation of neurologic disease."], [20, "mania can be a primary psychiatric disorder but can also be a symptom of a neurologic disorder, especially right-sided cerebrovascular disease."], [20, "treatment (such as corticosteroid and dopaminergic agent) for neurologic illness regularly induce mania."], [20, "the neurobiology of primary mania and bipolar disorder involve alteration in intracellular signaling, change in gene expression, neural network interaction, and apoptosis."], [20, "except when induce by time-limit treatment with a provoke agent, mania tend to be highly recurrent and to alternate or be exhibit alongside depression."], [20, "symptom of mania become more complex and treatment refractory with time, although effective treatment improve the long-term outcome."], [20, "behavioral manifestation of mania may be more obvious than affective symptom, especially in patient with aprosodia."], [20, "atypical antipsychotic drug be often first-line acute treatment, but the evidence support their long-term prophylactic efficacy be questionable."], [20, "in addition to be an establish mood stabilizer, lithium have putative neuroprotective property, although a side effect can be impaired memory."], [21, "to identify clinical characteristic and adverse outcome associate with an early age of onset of bipolar disorder."], [21, "a comprehensive search yield 15 empirical paper compare clinical presentation and outcome in individual with bipolar disorder group accord to age of onset (total n=7370)."], [21, "the follow variable be examine to determine odd ratio (or) and 95% confidence interval (ci): presence of axis i comorbidity, rapid cycling, psychotic symptom, mixed episode (dsm-iv), lifetime suicide attempt, lifetime alcohol and substance abuse, symptom severity, and treatment delay."], [21, "early age of onset be find to be associate with long delay to treatment (hedges' g=0.39, p=.001), great severity of depression (hedges' g=0.42, p<.001), and high level of comorbid anxiety (or=2.34, p<.001) and substance use (or=1.80, p<.001)."], [21, "surprisingly, no association be find between early age of onset and clinical characteristic such as psychotic symptom or mixed episode as define by dsm-iv."], [21, "early age of onset of bipolar disorder be associate with factor that can negatively impact long-term outcome such as increase comorbidity."], [21, "however, no association be find between early onset and indicator of severity or treatment resistance such as psychotic symptom."], [21, "clinical feature find to have the strong relationship with early age of onset be those potentially amenable to pharmacological and psychological treatment."], [21, "result highlight the importance of early identification and provide potential area of focus for the development of early intervention in bipolar disorder."], [22, "high rate of misdiagnosis, delay diagnosis, and lack of recognition and treatment of comorbid condition often lead patient with bipolar illness to have a chronic course with high disability, unemployment rate, and mortality."], [22, "despite the recognition that long-term outcome of bipolar disorder depend on systematic assessment of both interepisodic dysfunctional domain and comorbid psychiatric and medical condition, treatment of bipolar disorder still focus primarily on alleviation of acute symptom and prevention of future recurrence."], [22, "we propose here to review the evidence offer a modern view of bipolar disorder define as a chronic and progressive multisystem disorder, take into account characteristic of each patient as well as biosignature in order to help design personalize treatment."], [22, "we conduct a systematic pubmed search of all english-language article, publish between 2000 and 2010, focus on the english and french literature with bipolar disorder cross-reference with the follow search term: emotional dysregulation, sleep and circadian rhythm disturbance, cognitive impairment, age at onset, comorbid medical and psychiatric condition, psychosocial and medical intervention, outcome, remission, and personalize medicine."], [22, "the search be conduct between july 2009 and july 2010."], [22, "the literature on bipolar disorder be review to provide support evidence that the assessment of various symptom domain that be dysfunctional between episode should all be consider as core dimension of the disorder."], [22, "forty-one article be identify through the pubmed search describe above and select on the basis of address any combination of the search term in conjunction with bipolar disorder."], [22, "current guideline advocate the use of more or less similar treatment algorithm for all patient, ignore the clinical, pathophysiological, and lifetime heterogeneity of bipolar disorder."], [22, "systematic assessment of interepisodic dimension, along with comorbid medical and psychiatric risk factor, should be perform along the life cycle in order to plan specific and personalize"], [22, "pharmacologic, medical, and psychosocial intervention tailor to the need of each patient and ready-to-test biosignature to serve as risk factor or diagnostic or prognostic tool."], [22, "medical and research finding, along with health economic datum, support a more modern view of bipolar disorder as a chronic, progressive, multisystem disorder."], [22, "this new comprehensive framework should guide the search to identify biomarker and etiologic factor and should help design a new policy for health care, include prevention, diagnosis, treatment, and training."], [23, "childhood bipolar disorder remain a controversial but increasingly diagnose disorder that be associate with significant impairment, chronic course and treatment resistance."], [23, "therefore, the search for prodrome or early marker of risk for later childhood bipolar disorder may be of great importance for prevention and/or early identification."], [23, "literature search be conduct to identify review, case report and empirical paper address the issue of prodrome of childhood bipolar disorder."], [23, "a total of 54 article be find that relate to bipolar prodrome, risk factor for later childhood bipolar disorder, childhood risk for adult bipolar disorder, mania manifestation in early childhood, and neuropsychological and biological marker of childhood bipolar disorder."], [23, "a review of article suggest (a) childhood bipolar prodrome may be detectable prior to the onset of the disorder, (b) prodromal symptom may display episodicity during childhood, (c) there be evidence of possible endophenotypic marker such as deficit in executive function, sustain attention, and emotion labeling, (d) there be a potential association with functional, structural, and biochemical alteration evident in brain structure involve in mood regulation, (e) a link between childhood bipolar disorder with early tempermental marker, such as emotional regulation and behavioral disinhibition and (f) there be some early but promise evidence of effective psychotherapeutic prevention."], [23, "there have be very limited investigation of early prodrome of childhood bipolar disorder."], [23, "base on the promise finding of prodrome as well as high-risk state and possible endophenotypic marker, more control and target investigation into the early marker of bipolar disorder appear warrant and potentially fruitful."], [23, "until such longitudinal study with appropriate control be conduct, specific marker for bipolar prodrome will remain elusive, although evidence suggest they be manifest in at least some subgroup."], [23, "the finding of promise psychotherapeutic prevention program underscore the need to find specific and sensitive marker of bipolar prodrome in childhood."], [24, "this article present an overview of bipolar disorder (bpd) in child, a condition that only recently have be recognize as a legitimate diagnosis."], [24, "bipolar disorder in child be underrecognized for many reason include lack of awareness, diagnostic confusion, and the different clinical picture in child."], [24, "available datum strongly suggest that prepubertal childhood bpd be a non-episodic, chronic, rapid cycling, mixed manic state."], [24, "it may be comorbid with attention-deficit/hyperactivity disorder (adhd) and conduct disorder (cd) or it may demonstrate feature of adhd and cd, far complicate recognition and subsequent treatment."], [24, "treatment issue be discuss, and some reason for the urgency of early recognition and treatment be explain."], [25, "to synthesize the literature and develop guidance on support need for primary care and perinatal provider in screening, initial management, triage, and bridge treatment for perinatal bipolar disorder."], [25, "we conduct a scoping review by search six electronic database use keyword relate to perinatal bipolar disorder."], [25, "we summarize descriptive statistic on setting and extract information on care approach."], [25, "we synthesize the literature on indirect care model and extract datum on screening, follow-up, referral, and management."], [25, "1169 article be retrieve."], [25, "51 article be include after review."], [25, "most paper be review."], [25, "few address care in obstetric (n\xA0=\xA020, 39%), primary care (n\xA0=\xA010, 20%), and pediatric setting (n\xA0=\xA02, 4%)."], [25, "most paper (n\xA0=\xA030, 59%) discuss use screen instrument for bipolar disorder."], [25, "article be mix on recommendation for bipolar disorder screening."], [25, "varied strategy for structured assessment exist and be influence by practice setting."], [25, "there remain uncertainty about optimal strategy for screening and management of perinatal bipolar disorder."], [25, "we recommend screen for bipolar disorder in the perinatal period in select circumstance (with depression screening, know bipolar disorder risk factor, and prior to start antidepressant)."], [25, "if specialty mental health care be unavailable, we recommend enhance usual care through integrated care strategy such as indirect consultation."], [26, "bipolar disorder be a multifactorial disease with a strong genetic component."], [26, "however, environmental factor also play a role in the onset of the disease and in manic and depressive recurrence."], [26, "the onset of the disorder be the consequence of a complex interaction between genetic and environmental factor."], [26, "this gene-environment interaction be well illustrate by the influence of childhood trauma on the clinical expression of the disease in term of age of onset, comorbidity and suicide."], [26, "the complexity and heterogeneity of bipolar disorder require the identification of homogenous sub-group with the use of biomarker that could help reduce the etiological heterogeneity and well target the therapeutical option."], [27, "bipolar disorder be a pathological disturbance of mood, characterize by wax and wane manic, depressive and, sometimes distinctly mixed state."], [27, "a diagnosis of bipolar disorder can only be make with certainty when the manic syndrome declare itself."], [27, "most individual who be diagnose with this disorder will experience both pole of the illness recurrently, but depressive episode be the common cause of morbidity and, indeed, of death by suicide."], [27, "twin, adoption and epidemiological study suggest a strongly genetic aetiology."], [27, "it be a genetically and phenotypically complex disorder."], [27, "thus, the gene contribute be likely to be numerous and of small effect."], [27, "individual with bipolar disorder also display deficit on a range of neuropsychological task in both the acute and euthymic phase of illness and correlation between number of affective episode experience and task performance be commonly report."], [27, "current self-report and observer-rate scale be optimize for unipolar depression and hence limit in their ability to accurately assess bipolar depression."], [27, "the development of a specific depression rating scale will improve the assessment of bipolar depression in both research and clinical setting."], [27, "it will improve the development of well treatment and intervention."], [27, "guideline support the use of antidepressant for bipolar depression."], [27, "with regard to the adverse effect of antidepressant for bipolar depression, double-blind, placebo-control datum suggest that antidepressant monotherapy or the addition of a tricyclic antidepressant may worsen the course of bipolar disorder."], [27, "importantly, adjunctive psychotherapy add significantly (both statistically and clinically) to the efficacy of pharmacological treatment regimen."], [27, "the successful management of bipolar disorder clearly demand improved recognition of bipolar disorder and effective long-term treatment for bipolar depression as well as mania."], [28, "clinical staging be widespread in medicine - it inform prognosis, clinical course, and treatment, and assist individualized care."], [28, "staging place an individual on a probabilistic continuum of increase potential disease severity, range from clinically at-risk or latency stage through first threshold episode of illness or recurrence, and, finally, to late or end-stage disease."], [28, "the aim of the present paper be to examine and update the evidence regard staging in bipolar disorder, and how this might inform target and individualized intervention approach."], [28, "we provide a narrative review of the relevant information."], [28, "in bipolar disorder, the validity of staging be inform by a range of finding that accompany illness progression, include neuroimaging datum suggest incremental volume loss, cognitive change, and a decline likelihood of response to pharmacological and psychosocial treatment."], [28, "staging inform the adoption of a number of approach, include the active promotion of both indicate prevention for at-risk individual and early intervention strategy for newly diagnose individual, and the tailored implementation of treatment accord to the stage of illness."], [28, "the nature of bipolar disorder imply the presence of an active process of neuroprogression that be consider to be at least partly mediate by inflammation, oxidative stress, apoptosis, and change in neurogenesis."], [28, "it far support the concept of neuroprotection, in that a diversity of agent have putative effect against these molecular target."], [28, "clinically, staging suggest that the at-risk state or first episode be a period that require particularly active and broad-base treatment, consistent with the hope that the temporal trajectory of the illness can be alter."], [28, "prompt treatment may be potentially neuroprotective and attenuate the neurostructural and neurocognitive change that emerge with chronicity."], [28, "staging highlight the need for intervention at a service delivery level and implement treatment at the early stage of illness possible."], [29, "bipolar disorder be a mood disorder characterize by impair episode of mania and depression."], [29, "twin study have establish that bipolar disorder be among the most heritable of medical disorder and effort to identify specific susceptibility gene have intensify over the past two decade."], [29, "the search for gene influence bipolar disorder have be complicate by a paucity of animal model, limited understanding of pathogenesis, and the genetic and phenotypic complexity of the syndrome."], [29, "linkage study have implicate several chromosomal region as harbor relevant gene, but result have be inconsistent."], [29, "it be now widely accept that the genetic liability to bipolar disorder reflect the action of many gene of individually small effect, a scenario for which linkage study be poorly suit."], [29, "thus, association study, which be more powerful for the detection of modest effect loci, have become the focus of gene-find research."], [29, "a large number of candidate gene, include biological candidate derive from hypothesis about the pathogenesis of the disorder and positional candidate derive from linkage and cytogenetic study, have be evaluate."], [29, "several of these gene have be associate with the disorder in independent study (include bdnf, daoa, disc1, grik4, slc6a4, and tph2), but none have be establish."], [29, "the clinical heterogeneity of bipolar disorder and its phenotypic and genetic overlap with other disorder (especially schizophrenia, schizoaffective disorder, and major depressive disorder) have raise question about the optimal phenotype definition for genetic study."], [29, "nevertheless, genomewide association analysis, which have successfully identify susceptibility gene for a variety of complex disorder, have begin to implicate specific gene for bipolar disorder (dgkh, cacna1c, ank3)."], [29, "the polygenicity of the disorder mean that very large sample will be need to detect the modest effect loci that likely contribute to bipolar disorder."], [29, "detailed genetic dissection of the disorder may provide novel target (both pharmacologic and psychosocial) for intervention."], [30, "bipolar disorder be diagnose on the basis of patient and/or family report and behavioral observation."], [30, "traditionally regard as an affective disorder involve behavioral change, bipolar disorder have be reconceptualize as a multisystem disease associate with mood, cognitive, metabolic, autonomic and sleep/wake dysfunction."], [30, "accordingly, recent study have focus on the identification of biomarker relate to the pathophysiological mechanism underlie the development, clinical presentation and course of bipolar disorder."], [30, "this article provide an overview of the available literature regard circulate peripheral and neuroimaging biomarker in bipolar disorder."], [30, "neurotrophic factor, immune parameter, oxidative stress parameter, hormone and neuroimaging finding be take into consideration."], [30, "biomarkers research in bipolar disorder be a new field with an expand knowledge."], [30, "current evidence suggest that a single biomarker will not be able to cover the biological and clinical complexity of bipolar disorder."], [30, "alternatively, a composite of biomarker, include neurotrophic factor, cytokine and oxidative stress molecule, may be promise to identify altered mood state and neuroprogression in bipolar disorder."], [31, "bipolar disorder be a complex condition that be difficult to diagnose and treat, and many patient with this illness be not receive adequate care, particularly in the early stage of the disorder when effective treatment be most critical."], [31, "self-assessment cme be an educational activity in which clinician answer a series of multiple-choice question to ascertain their current knowledge and practice in treat cns disorder."], [31, "after complete the self-assessment, clinician have the opportunity to review correct answer, see how their colleague respond, and receive recommendation for further reading."], [31, "this self-assessment cme activity focus on recognize and bridge gap in knowledge pertain to bipolar disorder recognition and treatment."], [32, "bipolar disorder be a prevalent, chronic and heterogeneous psychiatric disorder."], [32, "there be increase evidence that early recognition and treatment can improve long-term outcome and prevent disability."], [32, "early intervention service for schizophrenia be well-fund and develop throughout the uk with close attention pay to the prodromal or early warning sign of schizophrenia, whereas there be currently no clear guideline on the clinical, biological and neuropsychological marker of early bipolar disorder."], [32, "this article review the grow literature on the bipolar prodrome and the differentiation between the syndrome of unipolar and bipolar depression."], [33, "bipolar disorder be one of the most severely debilitate of all medical illness."], [33, "it can lead to significant suffering for patient and their family, limit function and workplace productivity, and with its risk of increase morbidity and mortality, it be increasingly recognize as a major public health problem."], [33, "for a large number of patient, outcome be poor."], [33, "patient with bipolar disorder generally experience high rate of relapse, a chronic recurrent course, linger residual symptom, functional impairment, psychosocial disability and diminish well-being."], [33, "despite this, little be know about the specific pathophysiology of bipolar disorder."], [33, "a well understanding of the neurobiological underpinning of this condition, inform by preclinical and clinical research, will be essential for the future development of specific target therapy that be more effective, achieve their effect more quickly and be well tolerate than currently available treatment."], [33, "an abundance of research have implicate specific neuroendocrine, neurotransmitter and intracellular signal system in the pathophysiology and treatment of this illness."], [33, "more recently, genetic association study have identify numerous gene that confer vulnerability to the disorder, many of which be know to function in the signal pathway previously identify as relevant to the etiology of the illness."], [33, "in this article, we will review current knowledge regard the neurotransmitter system, signal network, neuroendocrine system and genetic of bipolar disorder; all of these allow insight into the mechanism of illness and thus offer potential novel direction for the development of novel therapeutic."], [34, "there be an urgent need to identify objective biomarker for the assessment of bipolar disorder, to improve diagnosis and prognostic evaluation."], [34, "neuroimaging be a particularly promising approach."], [34, "we review here the structural and functional neuroimaging study carry out on bipolar disorder."], [34, "these study have lead to the development of neurobiological model of bipolar disorder assume cortical-limbic dysregulation."], [34, "dorsal brain structure be think to decrease in volume and activity in bipolar disorder, reduce inhibition of the ventral-limbic network and enhance emotional response."], [34, "these model also assume abnormal prefrontal-subcortical limbic connectivity."], [34, "this abnormal connectivity have be identify by both diffusion tensor imaging study (anatomical connectivity) and functional mri (functional connectivity)."], [34, "however, study be currently limit by the heterogeneity of the patient include."], [34, "future research should include study to validate biomarker for the assessment of bipolar disorder and study of large and well characterize sample of patient with bipolar disorder."], [35, "bipolar disorder be a multifaceted illness and there be often a substantial delay between the first onset of symptom and diagnosis."], [35, "early detection have the potential to curtail illness progression and disorder-associate burden but it require a clear understanding of the initial bipolar prodrome."], [35, "this article summarize the phenomenology of bipolar disorder with an emphasis on the initial prodrome, the evolution of the illness, and the implication for prevention and early intervention."], [35, "a literature review be undertake use medline, web of science, and a hand search of relevant literature use keyword (e.g., phenomenology, initial or early symptom, risk factor, and predictor/prediction)."], [35, "finding from the literature be review and synthesize and have be put into a clinical context."], [35, "bipolar disorder be a recurrent, persistent, and disable illness that typically develop in adolescence or early adulthood."], [35, "the literature search yield 28 article, in which mood lability, nonspecific, non-mood symptom, and cyclothymic temperament be the most cite prodromal feature."], [35, "a small number of key prospective study have provide evidence in support of an initial bipolar prodrome; however, methodological difference across study have prohibit its clear delineation."], [35, "it be, therefore, not currently possible to anticipate those who will develop bipolar disorder solely on the basis of early phenomenology."], [35, "accurate characterization of the bipolar disorder prodrome through high-quality, prospective research study with adequate control group will ultimately facilitate prompt and accurate diagnosis."], [36, "bipolar disorder continue to present complex diagnostic and therapeutic challenge."], [36, "originally consider 2 separate disease (mania and depression), bipolar disorder be now recognize to be a single disorder characterize by different subtype and degree of severity."], [36, "despite the availability of official guideline, such as the dsm-iv and icd-10, diagnosis be still problematic."], [36, "traditionally, bipolar disorder have be consider a clinical entity distinct from schizophrenia, although that assumption be be increasingly challenge."], [36, "proponent of a bipolar continuum theory support the concept of an expand psychiatric continuum range from unipolar to bipolar disorder all the way to schizophrenia."], [36, "this notion be support by various independent finding."], [36, "both bipolar disorder and schizophrenia demonstrate a high degree of genetic transmissibility."], [36, "some datum report in family and twin study suggest hereditary overlap between the 2 disorder."], [36, "gene mapping for both disease be in its early stage, but certain susceptibility marker appear to be locate on the same chromosome."], [36, "bipolar disorder and schizophrenia also demonstrate some similarity in neurotransmitter dysfunction."], [36, "as further indirect evidence of a possible association, many new atypical antipsychotic agent approve for the treatment of schizophrenia be also prove useful for bipolar disorder."], [36, "ongoing research should aid in the understanding of bipolar disorder and foster the development of more effective treatment."], [37, "this article examine the individual component of bipolar disorder in child and the behavior that can escalate as a result of misdiagnosis and treatment."], [37, "the brain/behavior relationship in bipolar disorder can be affect by genetic, developmental failure, or environmental influence, which can cause an onset of dramatic mood swing and dysfunctional behavior."], [37, "school be often the site where mental health disorder be observe when compare behavior with other child."], [37, "assess the emotional, academic, and health need of a student with a bipolar disorder be a critical step in design effective intervention and school accommodation."], [37, "without appropriate medical, psychological, pharmaceutical, and academic intervention, a child be at risk for uncontrolled mania, depression, substance abuse, or suicide."], [37, "the school nurse be part of the multidisciplinary team and play a key role in facilitating case management to potentially reverse this possible negative trajectory."], [37, "successful case management provide child with bipolar disorder the opportunity to reach their academic potential."], [38, "bipolar disorder heterogeneity be large, lead to difficulty in identify neuropathophysiological and etiological mechanism and hinder the formation of clinically homogeneous patient group in clinical trial."], [38, "identify marker of clinically more homogeneous group would help disentangle bd heterogeneity."], [38, "neuroimaging may aid in identify such group by highlight specific biomarker of bd subtype or clinical dimension."], [38, "we perform a systematic literature search of the neuroimaging literature assess biomarker of relevant bd phenotype (type-i vs. ii, presence vs. absence of psychotic feature, suicidal behavior and impulsivity, rapid cycling, good vs. poor medication response, age at onset, cognitive performance and circadian abnormality)."], [38, "consistent biomarker be associate with suicidal behavior, i.e. frontal/anterior alteration (prefrontal and cingulate grey matter, prefrontal white matter) in patient with a history of suicide attempt; and with cognitive performance, i.e. involvement of frontal and temporal region, superior and inferior longitudinal fasciculus, right thalamic radiation, and corpus callosum in executive dysfunction."], [38, "for the other dimension and sub-type study, no consistent biomarker be identify."], [38, "study be heterogeneous both in methodology and outcome."], [38, "though theoretically promising, neuroimaging have not yet prove capable of disentangle subtype and dimension of bipolar disorder, due to high between-study heterogeneity."], [38, "we issue recommendation for future study."], [39, "provide an overview of how bipolar disorder affect cognitive function in patient."], [39, 'medline and psycinfo datum basis be search for article index by the combination of mesh term or key word "bipolar disorder" with the follow term: "cognition", "memory", "neuropsychology", "neuropsychological test", "lithium", "anticonvulsant", "antipsychotic", and "schizophrenia".'], [39, "constraint limit time period of publication or their language be not apply."], [39, "reference list of publication identify by these procedure be hand-search for additional relevant citation."], [39, "there be evidence of stable and lasting cognitive impairment in all phase of bipolar disorder, include the remission phase, particularly in the follow domain: sustain attention, memory and executive function."], [39, "but research on the cognitive function have yield inconsistent result over recent year."], [39, "there be a grow need for clarification regard the magnitude, clinical relevance and confound variable of cognitive impairment in bipolar patient."], [39, "the impact of bipolar illness on cognition can be influence by age of onset, pharmacological treatment, individual response, familial risk factor, and clinical feature."], [39, "in addition to the mood state, cognitive performance in bipolar patient be influence by seasonality."], [39, "previous optimistic assumption about the prognosis of bipolar disorder be base on the success of the control of mood symptom by pharmacotherapy."], [39, 'however, it be now clear that the "remitted" euthymic bipolar patient have distinct impairment of executive function, verbal memory, psychomotor speed, and sustain attention.'], [39, "mood stabilizer and atypical antipsychotic may reduce cognitive deficit in certain domain and may have a positive effect on quality of life and social functioning."], [40, "mania in old age be not as rare as it be once think to be."], [40, "it may constitute up to 5 per cent of admission in the psychogeriatric department."], [40, "the clinical picture, for the most part, seem to correspond with mania in young patient, although some patient may have atypical presentation."], [40, "secondary mania should be exclude first, before a firm diagnosis of primary affective disorder be make."], [40, "the prognosis and treatment of late onset mania do not seem to differ appreciably from those in young patient."], [41, "early onset (pediatric) bipolar disorder be still an issue of much controversy due to several clinical particularity of the thymic episode at this age."], [41, "to date, there be indeed no consensus regard the prevalence of bipolar disorder before puberty."], [41, "diagnosis criterion in child and young adolescent remain thus elusive."], [41, "the purpose of this review be to provide an overview of this issue."], [41, "the idea of continuity, from childhood to adulthood, in bipolar disorder also raise important question regard predictive factor of bipolar disorder in adult."], [41, "study on the childhood of bipolar adult, as well as study on the child of bipolar parent will be review, in an attempt to identify the psychopathological substrate of bipolar disorder."], [42, "in dsm-5, bipolar disorder (bs) be no long conceptualise as a pure mood disorder together with unipolar depression, but as a bridge between schizophrenia and depressive disorder."], [42, "this nosological classification be found on the historical context of the 19th century."], [42, "in addition to unipolar depression and schizophrenia, schizoaffective disorder, borderline personality disorder and attention-deficit hyperactivity disorder (adhd) overlap with bs symptomatology."], [42, "overlap also exist with somatic disease such as multiple sclerosis, cushing's syndrome and syphilis as well as iatrogenic affective syndrome."], [43, "the author provide an overview of the diagnosis, course, and treatment of bipolar ii disorder, a distinct subtype that be often misdiagnose as unipolar depression or bipolar i disorder."], [43, "they discuss research suggest that underdiagnosis of bipolar ii disorder reflect a failure to identify subthreshold expression of mania (hypomania)."], [43, "the course of bipolar ii disorder be different from that of bipolar i disorder or unipolar depression, with distinct difference in rate of recovery, clinical feature, and number of episode."], [43, "the risk of suicide appear to be particularly elevate."], [43, "high rate of comorbid disorder have be report, include substance abuse or dependence, anxiety disorder, and personality disorder."], [43, "few definitive study exist on which to base conclusion about the differential efficacy of various treatment strategy in bipolar ii disorder and bipolar i disorder."], [43, "preliminary study suggest that the new anticonvulsant may be of benefit for patient with bipolar ii disorder, while other datum suggest that there may be a great role for antidepressant medication."], [44, "it be clinically important to recognize both bipolar disorder and borderline personality disorder (bpd) in patient seek treatment for depression, and it be important to distinguish between the two."], [44, "the most studied question on the relationship between bpd and bipolar disorder be their diagnostic concordance."], [44, "across study approximately 10 % of patient with bpd have bipolar i disorder and another 10 % have bipolar ii disorder."], [44, "likewise, approximately 20 % of bipolar ii patient be diagnose with bpd, though only 10 % of bipolar i patient be diagnose with bpd."], [44, "while the comorbidity rate be substantial, each disorder be, nonetheless, diagnose in the absence of the other in the vast majority of case (80-90 %)."], [44, "in study examine personality disorder broadly, other personality disorder be more commonly diagnose in bipolar patient than be bpd."], [44, "likewise, the converse be also true: other axis i disorder such as major depression, substance abuse, and post-traumatic stress disorder be more commonly diagnose in patient with bpd than be bipolar disorder."], [44, "study compare patient with bpd and bipolar disorder find significant difference on a range of variable."], [44, "these finding challenge the notion that bpd be part of the bipolar spectrum."], [44, "while a substantial literature have document problem with the under-recognition and under-diagnosis of bipolar disorder, more recent study have find evidence of bipolar disorder over-diagnosis and that bpd be a significant contributor to over-diagnosis."], [44, "re-conceptualize the diagnostic and statistical manual of mental disorders, fifth edition, diagnostic criterion for bipolar disorder as a type of test, rather than the final word on diagnosis, shift the diagnostician from think solely whether a patient do or do not have a disorder to consider the risk of false-positive and false-negative diagnosis, and the ease by which each type of diagnostic error can be correct by longitudinal observation."], [45, "bipolar disorder be an affective or mood disorder that affect child and adolescent as well as adult."], [45, "originally think to be rare in childhood, this disorder be now diagnose even in the prepubertal age group."], [45, "with pediatrician provide health care for the majority of child and adolescent, these physician will see the child early in their presentation with affective disorder."], [45, "this review focus on the early recognition of child with bipolar disorder or child who be at increase risk of develop mania."], [45, "early recognition can lead to early treatment and reduce both short- and long-term morbidity and mortality."], [45, "this review cover the definition, epidemiology, presentation and differential diagnosis, comorbid diagnosis, precipitant, risk factor, treatment, and outcome."], [46, "bipolar illness be a serious heritable mood disorder characterize by recurrent episode of depression and mania."], [46, "the mean age of onset be under 25 year of age, but the period of risk extend from prepuberty to senescence."], [46, "fifteen percent of person with the disorder commit suicide."], [46, "bipolar disorder carry an increase risk of cardiovascular disease."], [47, "despite the fact that the nosologic position of bipolar ii disorder continue to be debate, several line of research indicate that it be a distinct nosologic category that should be separate from both bipolar i and unipolar major depression."], [47, "this review of the author' and other' work demonstrate that the lifetime risk of suicide attempt be high in bipolar ii and low in unipolar patient, whereas risk be intermediate in bipolar i patient."], [47, "moreover, two report show that bipolar ii patient be over represent among suicide victim."], [47, "clinician must take great care in not miss this diagnosis, which, when untreated, have ominous prognostic implication."], [48, "bipolar disorder be a brain illness with complexity in its composition and treatment."], [48, "result from the national comorbidity survey replication study estimate the lifetime prevalence of bipolar spectrum illness to be 4.5%."], [48, "these patient be also report to have their illness frequently treat suboptimally and to be at risk of suffer extensive disability."], [48, "pharmacist be in a key position to deliver important pharmacy care service to patient who have bipolar disorder and receive treatment in need of close monitoring."], [48, "describe here be the result of this study and opportunity for pharmacist to support this important patient population."], [49, "bipolar disorder be a multifactorial psychiatric disorder with developmental and progressive neurophysiological alteration."], [49, "this disorder be typically characterize by cyclical and recurrent episode of mania and depression but be heterogeneous in its clinical presentation and outcome."], [49, "although the dsm-iv-tr criterion identify several feature that be of phenomenological relevance, these be of less utility for define homogeneous subgroup, for analysis of correlation with biomarker or for direct focused medication strategy."], [49, "we provide a comprehensive review of exist evidence regard to age at onset in bipolar disorder."], [49, "eight admixture study demonstrate three homogeneous subgroup of patient with bipolar disorder identify accord to age at onset (early, intermediate and late age at onset), with two cutoff point, at 21 and 34 year."], [49, "it be suggest that the early-onset subgroup have specific clinical feature and outcome different from those of the other subgroup."], [49, "early-onset subgroup may be consider a more suitable clinical phenotype for the identification of susceptibility gene with recent datum demonstrating association with genetic variant specifically in this subgroup."], [49, "the use of age at onset as a specifi may also facilitate the identification of other biological marker for use in brain imaging, circadian, inflammatory and cognitive research."], [49, "a key challenge be pose by the use of age at onset in treatment decision algorithm, although further research be require to increase the evidence-base."], [49, "we discuss three potential benefit of specify age at onset, namely: focus medication strategy, the target prevention of specific comorbid condition and decrease the duration of untreated illness."], [49, "we argue that age at onset should be include as a specifi for bipolar disorder."], [50, "to provide a historical review of childhood depression and bipolar disorder, cover concept, diagnostic category, epidemiology, genetic and neurobiological aspect as well as predispose factor and treatment modality."], [50, "extensive review of the literature on child depression and bipolar disorder."], [50, "child depression and bipolar disorder be associate with genetic factor, mood, adverse life event, divorce, academic problem, physical and sexual abuse, and neurobiological factor."], [50, "treatment usually include medication and psychotherapy."], [50, "these be important childhood disorder whose diagnosis be often difficult."], [50, "the identification and treatment of depression and bipolar disorder reduce the suffering of affect child and adolescent."], [50, "the pediatrician can intervene by orient the family in mild case, but must be alert to case require more aggressive treatment."], [51, "the presentation of bipolar disorder in child and adolescent may vary from its presentation in adult."], [51, "rage, irritability, and long episode be common manifestation of mania in young people with bipolar disorder."], [51, "frequent comorbid disorder in young patient include adhd and anxiety disorder."], [51, "prodromal and subsyndromal state of bipolar disorder, such as bipolar disorder nos, present opportunity for early intervention and prevention."], [51, "early recognition and intervention be crucial, because untreated pediatric bipolar disorder become chronic, have a high incidence of relapse, and have a poor prognosis."], [52, "this article review juvenile onset bipolar disorder with regard to history, diagnosis, comorbidity, differential diagnosis, prevalence, etiology, treatment, and outcome."], [52, "specifically, it deal with past and current diagnostic criterion for juvenile onset bipolar disorder, the controversy around its comorbidity with attention deficit hyperactivity disorder (adhd), and how to differentiate it from adhd, conduct disorder, drug and alcohol abuse, and schizophrenia, genetic and neuroimaging study investigate the possible etiology of this condition be also describe."], [52, "treatment, both pharmacological (eg, lithium, neuroleptic, anticonvulsant, benzodiazepine, antidepressant) and psychosocial (eg, psychoeducation of child and family, school intervention, family, group and/or individual therapy) be outline."], [52, "finally, long-term outcome and factor which may influence outcome be address."], [53, "to identify and describe the complexity of diagnose bipolar disorder, include the diagnostic process and patient experience of be newly diagnose with bipolar disorder."], [53, "a mix-method focused ethnography be conduct, ground in a post-positivist foundation."], [53, "medical record (\u2009=\u2009100) of patient whose diagnosis have be switch to bipolar disorder be examine."], [53, "six week post-hospitalization, ten outpatient with the diagnosis of bipolar disorder undergo an in-depth interview."], [53, "four diagnostic process be identify during the retrospective record review."], [53, "two pattern and five theme be identify from the interview."], [53, "the first pattern, live with undiagnosed bipolar disorder, demonstrate common experience of distinguish impulsive mood and behavior, suffer life challenge, and seek relief."], [53, "the second pattern, acclimate to a new diagnosis of bipolar disorder, demonstrate participant' way of understand the diagnosis and reconcile the diagnosis."], [53, "pattern in the interview corroborate datum from the record review."], [53, "the rendering of an appropriate diagnosis be key."], [53, "many participant' life be significantly improve when diagnosis be make, and treatment recommendation for bipolar disorder (bpd) be initiate."], [53, "these finding offer clinician and researcher new way to think about the complexity of the diagnosis of bpd include contrast decision-make outcome along a screening, diagnosis, and treatment continuum, as well as use the diagnostic event to instigate meaningful life change in the patient."], [54, "there have be major advance in clinical understanding and treatment of bipolar disorder over the past decade."], [54, "randomise control trial of pharmacological treatment and psychological intervention have show that there be effective short-term and long-term treatment for the disorder."], [54, "despite advance in treatment, diagnosis be often delay or mistaken, and many people who could benefit be not use the treatment available."], [54, "functional and symptomatic recovery from episode of bipolar disorder be frequently less complete than previously consider, and disability be often profound."], [54, "although manic episode be the distinguish feature of bipolar disorder, it appear that depression be the predominant mood disturbance and that much of the functional impairment associate with bipolar disorder result from this."], [54, "comorbidity with anxiety disorder or substance misuse be common."], [54, "advance in genetic, brain imaging and basic pharmacology be start to provide understanding of the complex causative process."], [55, "although awareness on bipolar disorder have increase during the last decade, this condition remains characterize by a disable burden, in term of morbidity and functional impairment."], [55, "this paper aim to review some critical issue in the current knowledge on bipolar disorder."], [55, "although large european epidemiological study be lack, bipolar disorder be characterize by a set of severe feature, include an early age of onset, a chronic outcome and an important suicidal risk."], [55, "a majority of bipolar patient also experience a comorbid axis i condition, include substance abuse, anxiety disorder and attention-deficit hyperactivity disorder."], [55, "this situation present a therapeutic challenge, since antidepressant or methylphenidate may be associate with the risk of induce mania."], [55, "recently, a large number of study have provide evidence for the efficacy of new compound in the treatment of both mania and bipolar depression, but also in long-term relapse prevention."], [55, "recent research have also allow for the redefinition of the concept of mood stabilizer and for improve exist guideline on the clinical management of bipolar disorder."], [56, "the objective of this article be to discuss the rationale/background for early intervention in bipolar disorder."], [56, "narrative review."], [56, "there be often significant delay before the diagnosis of bipolar disorder be make and effective management initiate."], [56, "grow evidence from both preclinical and clinical literature point to a clear need for improved early identification and early intervention in bipolar disorder."], [56, "increase effort be be apply to the identification of those at high risk of onset of bipolar disorder."], [56, "it be hope that identification of an early prodrome of illness will allow preventative measure to be take."], [56, "there be a clear rationale for improved early identification and early intervention in bipolar disorder."], [57, "bipolar disease be often misdiagnose, sometimes repeatedly."], [57, "the screening tool and tip you'll find here will help you identify patient without delay."], [58, "the aim of the present study be to characterize the neurocognitive effect of lithium in bipolar disorder to inform clinical and research approach for further investigation."], [58, "key word pertain to neurocognition in bipolar disorder and lithium treatment be use to search recognize database to identify relevant literature."], [58, "the author also retrieve gray literature (e.g., book chapter) know to they and examine pertinent article from bibliography."], [58, "a limited number of study have examine the effect of lithium on neurocognition in bipolar disorder and, although in some domain a consistent picture emerge, in many domain the finding be mixed."], [58, "lithium administration appear to reshape key component of neurocognition - in particular, psychomotor speed, verbal memory, and verbal fluency."], [58, "notably, it have a sophisticated neurocognitive profile, such that while lithium impairs neurocognition across some domain, it seemingly preserve other - possibly those vulnerable to the effect of bipolar disorder."], [58, "furthermore, its effect be likely to be direct and indirect (via mood, for example) and cumulative with duration of treatment."], [58, "disentangle the component of neurocognition modulate by lithium in the context of a fluctuating and complex illness such as bipolar disorder be a significant challenge but one that therefore demand a stratified and systematic approach, such as that provide by the lithium battery."], [58, "in order to delineate the effect of lithium therapy on neurocognition in bipolar disorder within both research and clinical practice, a great understanding and measurement of the relatively stable neurocognitive component be need to examine those that indeed change with lithium treatment."], [58, "in order to achieve this, we propose a lithium battery-clinical and a lithium battery-research that can be apply to these respective setting."], [59, "many finding that seem to be inconsistent in bipolar disorder research could be explain by heterogeneity of the illness and by imprecise diagnostic boundary."], [59, "this review of publish datum find support for the existence of three main subtype of bipolar disorder: (1) classical, (2) psychosis spectrum and (3) 'characterological'."], [59, "these differ with respect to clinical presentation and course of illness, family history and possibly long-term treatment response."], [59, "for instance, in a series of genetic study, lithium responder show an episodic course of illness with a family history of mostly bipolar disorder."], [59, "in contrast, responder to lamotrigine monotherapy have a rapid-cycle clinical course and frequent comorbid condition, especially in the anxiety-panic disorder spectrum."], [59, "their relative have elevate rate of anxiety and major depression, but not bipolar disorder."], [59, "in summary, recognise the clinical and familial subtype of bipolar disorder might lead to more target treatment."], [60, "bipolar ii disorder (bp-ii) be define, by dsm-iv, as recurrent episode of depression and hypomania."], [60, "hypomania, accord to dsm-iv, require elevated (euphoric) and/or irritable mood, plus at least three of the follow symptom (four if mood be only irritable): grandiosity, decrease need for sleep, increase talk, race thought, distractibility, overactivity (an increase in goal-direct activity), psychomotor agitation and excessive involvement in risky activity."], [60, "this observable change in function should not be severe enough to cause marked impairment of social or occupational functioning, or to require hospitalisation."], [60, "the distinction between bp-ii and bipolar i disorder (bp-i) be not clearcut."], [60, "the symptom of mania (define bp-i) and hypomania (define bp-ii) be the same, apart from the presence of psychosis in mania, and the distinction be base on the presence of marked impairment associate with mania, i.e. mania be more severe and may require hospitalisation."], [60, "this be an unclear boundary that can lead to misclassification; however, the fact that hypomania often increase function make the distinction between mania and hypomania clear."], [60, "bp-ii depression can be syndromal and subsyndromal, and it be the prominent feature of bp-ii."], [60, "it be often a mixed depression, i.e. it have concurrent, usually subsyndromal, hypomanic symptom."], [60, "it be the depression that usually lead the patient to seek treatment."], [60, "dsm-iv bipolar disorder (bp-i, bp-ii, cyclothymic disorder and bipolar disorder not otherwise classified, which include very rapid cycling and recurrent hypomania)"], [60, "be now consider to be part of the 'bipolar spectrum'."], [60, "this be not include in dsm-iv, but be think to also include antidepressant/substance-associate hypomania, cyclothymic temperament (a trait of highly unstable mood, thinking and behaviour), unipolar mixed depression and highly recurrent unipolar depression."], [60, "bp-ii be underdiagnose in clinical practice, and its pharmacological treatment be understudied."], [60, "underdiagnosis be demonstrate by recent epidemiological study."], [60, "while, in dsm-iv, bp-ii be report to have a lifetime community prevalence of 0.5%, epidemiological study have instead find that it have a lifetime community prevalence (include the bipolar spectrum) of around 5%."], [60, "in depressed outpatient, one in two may have bp-ii."], [60, "the recent increased diagnosing of bp-ii in research setting be relate to several factor, include the introduction of the use of semi-structured interview by train research clinician, a relaxation of diagnostic criterion such that the minimum duration of hypomania be now less than the 4 day stipulate by dsm-iv, and a probe for a history of hypomania focus more on overactivity (increase goal-direct activity) than on mood change (although this be still require for a diagnosis of hypomania)."], [60, "guideline on the treatment of bp-ii be mainly consensus base and tend to follow those for the treatment of bp-i, because there have be few control study of the treatment of bp-ii."], [60, "the current, limited evidence support the follow line of treatment for bp-ii."], [60, "hypomania be likely to respond to the same agent useful for mania, i.e. mood-stabilise agent such as lithium and valproate, and the second-generation antipsychotic (i.e. olanzapine, quetiapine, risperidone, ziprasidone, aripiprazole)."], [60, "hypomania should be treat even if associate with overfunctioning, because a depression often soon follow hypomania (the hypomania-depression cycle)."], [60, "for the treatment of acute bp-ii depression, two control study of quetiapine have not find clearcut positive effect."], [60, "naturalistic study, although open to several bias, have find antidepressant in acute bp-ii depression to be as effective as in unipolar depression; however, one recent large control study (mainly in patient with bp-i) have find antidepressant to be no more effective than placebo."], [60, "result from naturalistic study and clinical observation on mixed depression, while in need of replication in control study, indicate that antidepressant may worsen the concurrent intradepression hypomanic symptom."], [60, "the only preventive treatment for both depression and hypomania that be support by several, albeit old, control study be lithium."], [60, "lamotrigine have show some efficacy in delay depression recurrence, but there have also be several negative unpublished study of the drug in this indication."], [61, "a grow body of evidence suggest that bipolar disorder (bd) be a progressive disease accord to clinical, biochemical and neuroimaging finding."], [61, "this study review the literature on the relationship between specific biomarker and bd stage."], [61, "a comprehensive literature search of medline and pubmed be conduct to identify study in english and portuguese use the keyword biomarker, neurotrophic factor, inflammation, oxidative stress, neuroprogression and staging model cros-reference with bipolar disorder."], [61, "morphometric study of patient with bd find neuroanatomic abnormality, such as ventricular enlargement, grey matter loss in the hippocampus and cerebellum, volume decrease in the prefrontal cortex and variation in the size of the amygdala."], [61, "other study demonstrate that serum concentration of neurotrophic factor, inflammatory mediator and oxidative stress may be use as bd biomarker."], [61, "the analysis of neurobiological change associate with bd progression and activity may confirm the existence of bd biomarker, which may be then include in staging model that will lead to improvement in treatment algorithm and more effective, individually tailor treatment regimen."], [61, "biomarker may also be use to define early intervention to control disease progression."], [62, "untreated early-onset bipolar disorder be associate with high rate of rapid cycling, more comorbidity, and more severe mania and depression than adult-onset bipolar disorder."], [62, "correctly diagnose bipolar disorder early in its course can prevent expose a young patient to treatment that may exacerbate or advance the progression of the disorder."], [62, "appropriate pharmacologic and psychosocial intervention be necessary in the acute treatment of pediatric bipolar disorder."], [63, "bipolar disorder (bd) be a chronic and severe mental disorder with recurrent episode of mania and depression."], [63, "in addition to neuronal alteration, accumulate evidence have reveal the importance of glial system in pathophysiology and phenotype of the illness."], [63, "postmortem study have repeatedly demonstrate the alteration in glial cell and its function in patient with bd."], [63, "the activate microglia and inflammatory cytokine be propose to be the potential biomarker that may help to predict disease exacerbation in bd."], [63, "on the other hand, anti-bd drug have be show to produce profound effect on glial activity, which not only contribute to the therapeutic efficacy, but may also provide a potential target for the drug development of bd."], [63, "we will focus on the recent development of glial abnormality and potential therapeutic benefit target to glial modulation in bd."], [64, "bipolar disorder be a highly recurrent and chronic psychiatric condition that shortens life expectancy, cause functional impairment and disruption to social, work and family life."], [64, "several form of bipolar disorder be recognise, include both bipolar i and bipolar ii disorder."], [64, "bipolar i be characterise by recurrent episode of depression and mania whereas bipolar ii disorder be characterise by recurrent depression and hypomania, a milder form of mania."], [64, "there have be debate concern the definition of hypomania since at least the 1970."], [64, "the main area of argument focus on the minimum duration of hypomania, its stem criterion and the number of symptom require for diagnosis."], [64, "arrive at the correct definition of hypomania be a key diagnostic issue."], [64, "there be increase evidence for the existence of a broad spectrum of bipolar disorder, and datum demonstrate the clinical validity of modify some of the criterion for hypomania be review here."], [65, "the long-term outcome of bipolar disorder range from last remission to chronic course or frequent recurrence require admission."], [65, "the distinction between bipolar i and ii disorder have limit utility in outcome prediction."], [65, "it be unclear to what extent the clinical course of bipolar disorder predict long-term outcome."], [65, "a representative sample of 191 individual diagnose with bipolar i or ii disorder be recruit and follow for up to 5 year use a life-chart method."], [65, "we previously describe the clinical course over the first 18 month with dimensional course characteristic and latent class."], [65, "now we test if these course characteristic predict long-term outcome, include time ill (time with any mood symptom) and hospital admission over a second non-overlapping follow-up period in 111 individual with available datum from both 18 month and 5 year follow-up."], [65, "dimensional course characteristic from the first 18 month prospectively predict outcome over the follow 3.5 year."], [65, "the proportion of time depress, the severity of depressive symptom and the proportion of time manic predict more time ill."], [65, "the proportion of time manic, the severity of manic symptom and depression-to-mania switching predict a great likelihood of hospital admission."], [65, "all prediction remain significant after control for age, sex and bipolar i v. ii disorder."], [65, "differential association with long-term outcome suggest that course characteristic may facilitate care planning with great predictive validity than establish type of bipolar disorder."], [65, "a clinical course dominate by depressive symptom predict a great proportion of time ill."], [65, "a clinical course characterize by manic episode predict hospital admission."], [66, "to review the epidemiology and disease characteristic of the bipolar disorder (bd) spectrum, render an accurate and timely diagnosis, and review treatment option through provider and patient collaboration."], [66, "comprehensive review of current scientific literature derive from electronic database and professional medical reference."], [66, "bd be a multifactorial disease that can interfere with cognition and behavior, cause a severe impact on patient and family."], [66, "the variable course and often delay diagnosis of this disorder can cause frustration for the patient and the healthcare provider."], [66, "because most undiagnosed patient with bd seek treatment within the primary care setting, it be imperative that clinician become expert in the recognition of and intervention for this condition."], [66, "the primary care provider be in a key position to render early diagnosis and treatment of bd."], [66, "this disease should always be consider as part of the differential diagnosis for depression or anxiety."], [66, "nurse practitioner can be effective provider by use good nursing practice of communication, education, and advocacy for the patient and family."], [66, "knowledge of current diagnostic criterion and management be imperative for successful treatment of patient with bd."], [67, "bipolar disorder (bpd) be a devastating illness that be characterize by recurrent episode of mania and depression."], [67, "in addition to these cyclic episode, individual with bpd exhibit change in psychovegetative function, cognitive performance, and general health and well be."], [67, "in this article we draw from neuroimage finding in human, postmortem datum, and human genetic and pharmacological study as well as datum from animal model of behavior to discuss the neurobiology of bpd."], [67, "we conclude with a synthesis of where the field stand and with suggestion and strategy for future area of study to far increase our conceptual understanding of this complex illness."], [68, "we review the recent literature in order to establish the importance of a spectrum for bipolar affective disorder, and that unipolar depression, bipolar ii and bipolar i be discrete entity that may however evolve in sequence."], [68, "we discuss clinical, genetic and neurobiological datum which illustrate the difference between bipolar i and bipolar ii."], [68, "to fit the datum we suggest a series of multiple mood disorder genotype, some of which evolve into other condition on the bipolar spectrum."], [68, "thence we discuss the nature of the bipolar spectrum and demonstrate how this concept can be use as the basis of a staging model for bipolar disorder."], [69, "bipolar disorder be a relatively common condition characterise by recurrent episode of mania and depression, and associate with high level of morbidity and mortality."], [69, "although there have be substantial advance in the pharmacotherapeutic of this condition over the last 10-15 year, the benefit have be predominantly in term of tolerability and safety, with no new treatment be demonstrate to be more effective than lithium--the prototype mood stabilis."], [69, "this article review current and emerge medication for bipolar disorder."], [69, "most of the emerge treatment in pharmaceutical industry developmental programme be new or modified anticonvulsant or atypical antipsychotic."], [69, "a number of possible future direction and challenge for the field be discuss."], [69, "the treatment of bipolar disorder be unlikely to advance substantially until the causative pathogenetic molecular process be elucidated."], [70, "bipolar disorder constitute a group of frequent, chronic psychiatric illness with a most severe impact on the patient's life."], [70, "the course can be very individual and heterogeneous, the well know and most frequent manifestation include the classical bipolar i and bipolar ii disorder."], [70, "however, in germany even typical bipolar i disorder be underdiagnosed and, consequently, undertreated."], [70, "this be true despite the fact that the number of pharmacological treatment option have rapidly increase during recent year, both in the field of anticonvulsant and atypical antipsychotic."], [70, "this supply we today with new therapeutic strategy, not only for acute mania, but also for bipolar depression and maintenance treatment, and it be feasible to assume that there will be more option available within the next few year."], [71, "to consider whether consensus exist in recommendation for manage bipolar mixed state publish in recent review and treatment guideline, and to summarise what might be their good management."], [71, "limitation to and change in the definition of mixed state compromise diagnosis and management."], [71, "the striking comparison between dsm-iv and dsm-5 criterion set risk under-diagnosis and over-diagnosis."], [71, "current review and guideline offer limited evidence to guide treatment; however, management should involve address the contribution of any antidepressant medication, and the introduction of a second-generation antipsychotic medication to stabilise the condition."], [72, "bipolar disorder be a chronic, recur illness that require long-term prophylactic treatment."], [72, "however, treatment be often complicate by misdiagnosis and inappropriate medication selection."], [72, "a number of therapy be available for the treatment of bipolar disorder and the ultimate therapeutic choice depend on the individual patient's current symptom, disease history, and comorbid illness."], [72, "however, research be need to improve the overall prognosis for patient with bipolar depression, particularly because approximately 20% of patient commit suicide."], [72, "mania be the most dramatic expression of bipolar disorder and may overshadow the impact of the depressive phase of the illness."], [72, "compare with mania, episode of bipolar depression be more frequent, of long duration, and be associate with high rate of morbidity and mortality."], [72, "therefore, successful treatment and prevention of bipolar depression remain an essential treatment goal."], [73, "bipolar disorder (bd) have traditionally be think of as an episodic condition, characterize by period of hypomania/mania and depression."], [73, "however, evidence be accumulate to suggest that this condition be associate with significant chronicity."], [73, "for a large proportion of patient with bd, residual, sub-syndromal symptom persist between major syndromal episode, and study have show that many patient with bipolar disorder be symptomatic for approximately 50% of the time over follow-up period of great than 10 year."], [73, "moreover, while the prevalence of bd have be estimate to be around 1-2%, there be grow evidence that this may be a substantial underestimation."], [73, "there be a number of reason for this potential underestimation, include difficulty in diagnosis."], [73, "add to the burden of bd be the issue of comorbidity, with an increase prevalence of many chronic condition in those with a primary diagnosis of bd."], [73, "conversely, for many patient with chronic condition, both medical and psychiatric, bd frequently exist as a comorbid secondary diagnosis."], [73, "this issue of comorbidity complicate estimate of use of pharmaceutical agent for bd, such as mood stabilizer, which be know to be use off-label in condition such as borderline personality or substance use disorder."], [73, "we speculate that such off-label prescribing may not be truly off-label but may be instead fully justify by an overlook secondary diagnosis of bd."], [73, "finally, we discuss the association of bipolar disorder with a significant economic burden, to the individual and to society, both due to the direct cost of medical expenditure and indirect cost such as loss of productivity and increase mortality."], [74, "bipolar disorder (bd) be characterize by period of abnormally elevate mood (mania) that cycle with abnormally lower mood (depression)."], [74, "multiple structural, metabolic, and biochemical abnormality be evident in the brain's cortex, subcortex, and deep region."], [74, "this disorder be highly genetically condition but also highly susceptible to environmental stressor: prenatal or perinatal insult, childhood sexual or physical abuse, challenging life event, substance abuse, and other toxic chemical exposure."], [74, "its high morbidity, lose productivity, and suicide risk place a great toll on society."], [74, "since world war ii, bd have be steadily worsen with early age of onset, great intensity of symptom, and development of drug resistance."], [74, "incidence in child be rise and misdiagnosis be common."], [74, "disciplined management of the many risk factor be essential, include cognitive psychotherapy and support from family and community."], [74, "lithium have be the foundational treatment, follow by valproate and other mood stabilizer, antidepressant, and anticonvulsant."], [74, "several single-nutrient and multinutrient supplement have also prove beneficial."], [74, "controlled, double-blind trial show multinutrient combination of vitamin, mineral, orthomolecule, herbal, and the omega-3 fatty acid epa and dha to be effective monotherapy."], [74, "the molecular action of lithium and valproate converge with nutrient on the level of the cell membrane and its molecular signal transduction system."], [74, "this emergent, unified rationale presage effective integrative management of bipolar disorder."], [75, "recent research on the epidemiology, clinical course, diagnosis, and treatment of bipolar ii disorder (bd ii) stand to have a considerable impact on clinical practice."], [75, "this paper review these development."], [75, "we conduct a pubmed search, focus on the period from january 1, 1994, to august 31, 2004."], [75, "article deem directly relevant to the epidemiology, course, diagnosis, and management of bd ii be consider."], [75, "the prevalence of bd ii be likely high than previously suggest."], [75, "systematic probe for particular clinical feature and use of screen tool allow for a more timely and accurate detection of the disorder."], [75, "there be a paucity of good quality datum to guide clinician treat bd ii."], [75, "significant progress have be make in clarify diagnostic and treatment issue in bd ii."], [75, "neither strong nor broad treatment recommendation can be make; a cautious interpretation of available datum suggest that lithium or lamotrigine be fairly reasonable first-line choice."], [75, "more well-design study with large sample be need to improve the evidence base for manage this disorder."], [76, "bipolar disorder have not be well study in prepubertal child, despite its potentially debilitate effect on growth and development."], [76, "however, there have be case report of mania in this age group date back to esquirol in the mid-19th century."], [76, "despite anecdotal case report, explicit criterion to diagnose mania in child be not use until 1960."], [76, "since 1980 the dsm-iii/dsm-iii-r criterion have indicate adult criterion can be use to diagnose childhood mania, with some modification to adjust for age difference."], [76, "bipolar disorder have not be frequently consider in the psychiatric differential diagnosis of child."], [76, "however, if a diagnosis of mania be make, clinical rating scale can be use to rate the severity of manic symptom and to monitor treatment."], [76, "a manic child should be treat use a biopsychosocial approach."], [76, "to date, lithium carbonate have be the most commonly use psychopharmacological treatment, but result have be variable."], [76, "additional research be need, include double-blind, placebo-control study to document the beneficial effect of mood-stabilize medication."], [76, "also, diagnostic instrument should be refine to improve their utility."], [76, "finally, child at high risk for develop mania should be study to identify predictor of bipolar disorder in child."], [77, "bipolar disorder be a diagnostically heterogeneous disorder, although mania emerge as a distinct phenotype characterize by elevated mood and increase activity or energy."], [77, "while bipolar disorder's cyclicity be difficult to represent in animal, model of mania have begin to decode its fundamental underlying neurobiology."], [77, "when psychostimulant such as amphetamine or cocaine be administer to rodent, a result upsurge of motor activity be think to share face and predictive validity with mania in human."], [77, "study black swiss mouse, which inherently exhibit proclivity for reward seek and risk taking, also have yield some insight."], [77, "far, translate the biology of bipolar disorder in human into animal model have lead to great understanding of role for candidate biological system such as the grik2 and clock gene, as well as the extracellular signal-relate kinase pathway involve in the pathophysiology of the illness."], [77, "the national institute of mental health research domain criteria initiative seek to identify build block of complex illness like bipolar disorder in hope of uncover the neurobiology of each, as well as how each fit together to produce syndrome like bipolar disorder or why so many mental illness co-occur together."], [77, "research domain criteria-drive preclinical model of isolated behavior and domain involve in mania and bipolar disorder will ultimately inform movement toward nosology support by neurobiology."], [78, "the use of clinical staging model be emerge as a novel and useful paradigm for diagnose severe mental disorder."], [78, 'the term "neuroprogression" have be use to define the pathological reorganization of the central nervous system along the course of severe mental disorder.'], [78, "in bipolar disorder (bd), neural substrate reactivity be change by repeat mood episode, promote a brain rewire that lead to an increase vulnerability to life stress."], [78, 'a search in the pubmed database be perform with the follow term: "stage", "neuroprogression", "serum", "plasma", "blood", "neuroimage", "pet scan", "fmri", "neurotrophin", "inflammatory marker" and "oxidative stress marker", which be individually cross with "cognition", "functionality", "response to treatment" and "bipolar disorder".'], [78, "the inclusion criterion comprise original paper in the english language."], [78, "abstract from scientific meeting be not include."], [78, "we divide the result accord to the available evidence of serum biomarker as potential mediator of neuroprogression, with brain imaging, cognition, functioning and response to treatment consider as consequence."], [78, "the challenge in bd treatment be translate the knowledge of neuronal plasticity and neurobiology into clinical practice."], [78, "neuroprogression and staging can have important clinical implication, give that early and late stage of the disorder appear to present different biological feature and therefore may require different treatment strategy."], [79, "our aim be to review evidence of the role of cognitive deficit in bipolar disorder and their relationship to other factor, such as disorder variable, treatment, additional diagnosis, genetic risk, and brain imaging finding."], [79, "study that examine cognitive dysfunction in bipolar disorder and its relationship to the variable of clinical, genetic, and bipolar disorder subtype, as well as neuro-anatomical and neuro-functional evidence have be review."], [79, "finding from our own study have also be use while conduct the review."], [79, "in bipolar disorder, deficit in executive function, memory, and attention persist in the euthymic state."], [79, "the number of episode and the course of the disorder seem to be relate to the severity of memory dysfunction and psychomotor slowness."], [79, "however, symptom of cognitive dysfunction be present at the onset of the disorder."], [79, "moreover, cognitive dysfunction have be observe in the healthy relative of bipolar disorder patient."], [79, "cognitive dysfunction in bipolar disorder be associate with functional and possibly structural anomaly in some part of the brain, such as the frontal and cingulate cortex."], [79, "some recent study report a relationship between symptom of cognitive dysfunction and genetic variation in bipolar disorder."], [79, "today, the presence of cognitive deficit in bipolar disorder be widely accept; however, evidence of the neurobiological and clinical correlate of cognitive symptom be still limited."], [79, "more study be need to investigate the relationship between cognitive dysfunction in bipolar disorder and risk."], [79, "genetic study be just now amend our body of knowledge."], [79, "there have be many conflicting result report by brain imaging study."], [79, "different brain imaging approach and genetic method should be use with more specific cognitive and social-emotional task for increase our knowledge about the nature of cognitive deficit in bipolar disorder."], [80, "bipolar disorder, a serious illness result in significant psychosocial morbidity and excess mortality, have be report to be frequently underdiagnose."], [80, "however, during the past few year we have observe the emergence of an opposite phenomenon--the overdiagnosis of bipolar disorder."], [80, "in the present report from the rhode island methods to improve diagnostic assessment and services (midas) project, we empirically examine whether bipolar disorder be overdiagnose."], [80, "seven hundred psychiatric outpatient be interview with the structured clinical interview for dsm-iv (scid) and complete a self-administer questionnaire, which ask the patient whether they have be previously diagnose with bipolar or manic-depressive disorder by a health care professional."], [80, "family history information be obtain from the patient regard first-degree relative."], [80, "diagnosis be blind to the result of the self-administer scale."], [80, "the study be conduct from may 2001 to march 2005."], [80, "few than half the patient who report that they have be previously diagnose with bipolar disorder receive a diagnosis of bipolar disorder base on the scid."], [80, "patient with scid-diagnose bipolar disorder have a significantly high morbid risk of bipolar disorder than patient who self-report a previous diagnosis of bipolar disorder that be not confirm by the scid (p < .02)."], [80, "patient who self-report a previous diagnosis of bipolar disorder that be not confirm by the scid do not have a significantly high morbid risk for bipolar disorder than the patient who be negative for bipolar disorder by self-report and the scid."], [80, "not only be there a problem with underdiagnosis of bipolar disorder, but also an equal if not great problem exist with overdiagnosis."], [81, "adult attention-deficit/hyperactivity disorder (adhd) be increasingly recognize and report to frequently coexist with bipolar disorder."], [81, "concurrent diagnosis of adult adhd and bipolar disorder remain controversial."], [81, "in this study, we conduct a systematic review to examine the rate and diagnostic validity of the concept of comorbid adult adhd and bipolar disorder."], [81, "medline, embase, psycinfo, and cochrane database be search for article publish before march 30, 2007, use the keyword manic, bipolar, attention deficit hyperactivity, and adult."], [81, "the computer search be supplement with bibliographic cros-reference."], [81, "exclusion criterion be study with only pediatric subject, childhood adhd only but not adult adhd, and either bipolar disorder or adhd only, but not both; review article, case report; letter to the editor; and book chapter."], [81, "of the 262 citation find, 12 study meet our inclusion criterion."], [81, "specific diagnostic validate criterion examine be phenomenology, course of illness, heredity, biological marker, and treatment response."], [81, "there be 6 study on comorbid rate, 4 on phenomenology, 3 on course of illness, 2 on heredity, none on biological marker, and 1 on treatment response."], [81, "the propose comorbid syndrome be fairly common (present in up to 47% of adult adhd and 21% of bipolar disorder population), with a more severe course of illness compare with that of bipolar disorder alone, and high rate of comorbidity with other psychiatric disorder."], [81, "its treatment appear to require initial mood stabilization."], [81, "comorbid adult adhd and bipolar disorder have be insufficiently study, with more emphasis on comorbidity rate and few datum on course, neurobiology, heredity, and treatment."], [81, "the diagnostic validity of adult adhd/ bipolar disorder as a true comorbidity be not well-establish on the basis of this equivocal and insufficient literature."], [81, "more study be greatly need to far clarify its diagnostic validity and treatment approach."], [82, "although there be a broad base of literature on depression among elderly patient and on mania in young patient, there be a relative paucity of information on bipolar disorder in the elderly population."], [82, "while the quantity of datum reflect the relative prevalence of these illness, there be evidence to suggest that classification of mania in the elderly with respect to age of onset, natural course, family history, and pathophysiology may be useful in understand the heterogeneous etiology of this syndrome."], [82, "this paper present a review of the literature on the incidence and course of illness in late-life bipolar disorder."], [82, "far, dilemma of diagnostic classification in relation to associate risk factor will be discuss."], [83, "systematic review suggest comorbid borderline personality disorder be present in approximately 20% of individual who have bipolar disorder, but current diagnostic system demonstrate a move towards dimensional rather than categorical approach to classify personality pathology."], [83, "we aim to examine the presence and severity of borderline personality trait in bipolar i and bipolar ii disorder, and to explore association between the presence/severity of borderline personality trait and clinical outcome in bipolar disorder."], [83, "borderline personality trait be measure in 1447 individual with dsm-iv bipolar disorder (1008 bipolar i disorder and 439 bipolar ii disorder) use the borderline evaluation of severity over time (best) questionnaire."], [83, "lifetime clinical outcome be assess via schedule for clinical assessment in neuropsychiatry (scan) semi-structured interview and clinical case note."], [83, "borderline personality trait be common in both bipolar disorder group, with 86.2% participant report at least one trait."], [83, "these include trait that overlap with (eg mood instability) and those that be distinct from the symptom of bipolar disorder (eg fear of abandonment)."], [83, "borderline personality trait be significantly more frequent and more severe in bipolar ii disorder compare to bipolar i disorder."], [83, "more severe borderline trait, and even the presence of a single borderline personality trait, be significantly associate with young age of bipolar disorder onset and high prevalence of lifetime alcohol misuse in both bipolar disorder group."], [83, "the presence of comorbid borderline personality trait should be consider in the management of all patient with bipolar disorder irrespective of whether criterion for a categorical borderline personality disorder diagnosis be meet."], [84, "in treat bipolar disorder, specific psychotherapy in adjunct to pharmacotherapy have be show to be effective in prevent new episode and treat depressive episode."], [84, "among those, interpersonal and social rhythm therapy (ipsrt) develop by frank, amalgamation of interpersonal psychotherapy (ipt) with behavioral therapy focus on social rhythm have be show to be an efficacious adjunct to mediation in prevent new episode in bipolar i patient and in treat depression in bipolar i arid ii disorder."], [84, "ipsrt have also be show to enhance total functioning, relationship functioning and life satisfaction among patient with bipolar disorder, even after pretreatment functioning and concurrent depression be covarie."], [84, "ipsrt be design to directly address the major pathway to recurrence in bipolar disorder, namely medication nonadherence, stressful life event, and disruption in social rhythm."], [84, "ipt, originate by klerman et al., be a strategic time-limit psychotherapy focus on one or two of four current interpersonal problem area (ie, grief, interpersonal role dispute, role transition, and interpersonal dificit)."], [84, 'in ipsrt, the fifth problem area "grief for the lose healthy self" have be add in order to promote acceptance of the diagnosis and the need for life-long treatment.'], [84, "social rhythm therapy be a behavioral approach aim at increase regularity of social rhythm use the social rhythm metric (srm), a chart to record daily social activity include how stimulate they be, develop from observation that disruption in social rhythm often trigger affective episode in patient with bipolar disorder."], [84, "ipsrt also appear to be a promising intervention for a subset of individual with bipolar ii depression as monotherapy for the acute treatment."]];

  // hw4/bd_tokens.json
  var bd_tokens_default = [[0, "bipolar"], [0, "disorder"], [0, "be"], [0, "a"], [0, "serious"], [0, "disorder"], [0, "of"], [0, "mood"], [0, "that"], [0, "be"], [0, "associate"], [0, "with"], [0, "considerable"], [0, "psychosocial"], [0, "and"], [0, "economic"], [0, "morbidity"], [0, "."], [1, "even"], [1, "though"], [1, "it"], [1, "be"], [1, "more"], [1, "common"], [1, "than"], [1, "previously"], [1, "think"], [1, ","], [1, "it"], [1, "have"], [1, "until"], [1, "relatively"], [1, "recently"], [1, "be"], [1, "somewhat"], [1, "neglect"], [1, "in"], [1, "term"], [1, "of"], [1, "research"], [1, "when"], [1, "compare"], [1, "to"], [1, "disorder"], [1, "such"], [1, "as"], [1, "schizophrenia"], [1, "and"], [1, "major"], [1, "depression"], [1, "."], [2, "recent"], [2, "advance"], [2, "in"], [2, "the"], [2, "field"], [2, "of"], [2, "nosology"], [2, ","], [2, "epidemiology"], [2, ","], [2, "and"], [2, "molecular"], [2, "genetic"], [2, "in"], [2, "particular"], [2, "have"], [2, "begin"], [2, "to"], [2, "unravel"], [2, "some"], [2, "of"], [2, "the"], [2, "complexity"], [2, "of"], [2, "this"], [2, "disorder"], [2, "and"], [2, "the"], [2, "next"], [2, "few"], [2, "year"], [2, "be"], [2, "likely"], [2, "to"], [2, "witness"], [2, "substantial"], [2, "change"], [2, "to"], [2, "the"], [2, "way"], [2, "in"], [2, "which"], [2, "the"], [2, "broad"], [2, "spectrum"], [2, "of"], [2, "bipolar"], [2, "disorder"], [2, "be"], [2, "diagnose"], [2, "and"], [2, "manage"], [2, "."], [3, "over"], [3, "the"], [3, "last"], [3, "decade"], [3, ","], [3, "there"], [3, "have"], [3, "be"], [3, "a"], [3, "grow"], [3, "appreciation"], [3, "of"], [3, "the"], [3, "importance"], [3, "of"], [3, "identify"], [3, "and"], [3, "treat"], [3, "cognitive"], [3, "impairment"], [3, "associate"], [3, "with"], [3, "bipolar"], [3, "disorder"], [3, ","], [3, "since"], [3, "it"], [3, "persist"], [3, "in"], [3, "remission"], [3, "period"], [3, "."], [4, "evidence"], [4, "indicate"], [4, "that"], [4, "neurocognitive"], [4, "dysfunction"], [4, "may"], [4, "significantly"], [4, "influence"], [4, "patient"], [4, "'"], [4, "psychosocial"], [4, "outcome"], [4, "."], [5, "an"], [5, "ever"], [5, "-"], [5, "increase"], [5, "body"], [5, "of"], [5, "research"], [5, "seek"], [5, "to"], [5, "achieve"], [5, "a"], [5, "well"], [5, "understanding"], [5, "of"], [5, "potential"], [5, "moderator"], [5, "contribute"], [5, "to"], [5, "cognitive"], [5, "impairment"], [5, "in"], [5, "bipolar"], [5, "disorder"], [5, "in"], [5, "order"], [5, "to"], [5, "develop"], [5, "prevention"], [5, "strategy"], [5, "and"], [5, "effective"], [5, "treatment"], [5, "."], [6, "this"], [6, "review"], [6, "provide"], [6, "an"], [6, "overview"], [6, "of"], [6, "the"], [6, "available"], [6, "datum"], [6, "from"], [6, "study"], [6, "examine"], [6, "treatment"], [6, "for"], [6, "cognitive"], [6, "dysfunction"], [6, "in"], [6, "bipolar"], [6, "disorder"], [6, "as"], [6, "well"], [6, "as"], [6, "potential"], [6, "novel"], [6, "treatment"], [6, ","], [6, "from"], [6, "both"], [6, "pharmacological"], [6, "and"], [6, "psychological"], [6, "perspective"], [6, "."], [7, "all"], [7, "these"], [7, "datum"], [7, "encourage"], [7, "the"], [7, "development"], [7, "of"], [7, "further"], [7, "study"], [7, "to"], [7, "find"], [7, "effective"], [7, "strategy"], [7, "to"], [7, "prevent"], [7, "and"], [7, "treat"], [7, "cognitive"], [7, "impairment"], [7, "associate"], [7, "with"], [7, "bipolar"], [7, "disorder"], [7, "."], [8, "these"], [8, "effort"], [8, "may"], [8, "ultimately"], [8, "lead"], [8, "to"], [8, "an"], [8, "improvement"], [8, "of"], [8, "psychosocial"], [8, "function"], [8, "in"], [8, "these"], [8, "patient"], [8, "."], [9, "it"], [9, "be"], [9, "clinically"], [9, "important"], [9, "to"], [9, "recognize"], [9, "both"], [9, "bipolar"], [9, "disorder"], [9, "and"], [9, "borderline"], [9, "personality"], [9, "disorder"], [9, "("], [9, "bpd"], [9, ")"], [9, "in"], [9, "patient"], [9, "seek"], [9, "treatment"], [9, "for"], [9, "depression"], [9, ","], [9, "and"], [9, "it"], [9, "be"], [9, "important"], [9, "to"], [9, "distinguish"], [9, "between"], [9, "the"], [9, "two"], [9, "."], [10, "research"], [10, "consider"], [10, "whether"], [10, "bpd"], [10, "should"], [10, "be"], [10, "consider"], [10, "part"], [10, "of"], [10, "a"], [10, "bipolar"], [10, "spectrum"], [10, "reach"], [10, "differ"], [10, "conclusion"], [10, "."], [11, "we"], [11, "review"], [11, "the"], [11, "most"], [11, "studied"], [11, "question"], [11, "on"], [11, "the"], [11, "relationship"], [11, "between"], [11, "bpd"], [11, "and"], [11, "bipolar"], [11, "disorder"], [11, ":"], [11, "their"], [11, "diagnostic"], [11, "concordance"], [11, "."], [12, "across"], [12, "study"], [12, ","], [12, "approximately"], [12, "10"], [12, "%"], [12, "of"], [12, "patient"], [12, "with"], [12, "bpd"], [12, "have"], [12, "bipolar"], [12, "i"], [12, "disorder"], [12, "and"], [12, "another"], [12, "10"], [12, "%"], [12, "have"], [12, "bipolar"], [12, "ii"], [12, "disorder"], [12, "."], [13, "likewise"], [13, ","], [13, "approximately"], [13, "20"], [13, "%"], [13, "of"], [13, "bipolar"], [13, "ii"], [13, "patient"], [13, "be"], [13, "diagnose"], [13, "with"], [13, "bpd"], [13, ","], [13, "though"], [13, "only"], [13, "10"], [13, "%"], [13, "of"], [13, "bipolar"], [13, "i"], [13, "patient"], [13, "be"], [13, "diagnose"], [13, "with"], [13, "bpd"], [13, "."], [14, "while"], [14, "the"], [14, "comorbidity"], [14, "rate"], [14, "be"], [14, "substantial"], [14, ","], [14, "each"], [14, "disorder"], [14, "be"], [14, "nontheless"], [14, "diagnose"], [14, "in"], [14, "the"], [14, "absence"], [14, "of"], [14, "the"], [14, "other"], [14, "in"], [14, "the"], [14, "vast"], [14, "majority"], [14, "of"], [14, "case"], [14, "("], [14, "80"], [14, "%"], [14, "to"], [14, "90"], [14, "%"], [14, ")"], [14, "."], [15, "in"], [15, "study"], [15, "examine"], [15, "personality"], [15, "disorder"], [15, "broadly"], [15, ","], [15, "other"], [15, "personality"], [15, "disorder"], [15, "be"], [15, "more"], [15, "commonly"], [15, "diagnose"], [15, "in"], [15, "bipolar"], [15, "patient"], [15, "than"], [15, "be"], [15, "bpd"], [15, "."], [16, "likewise"], [16, ","], [16, "the"], [16, "converse"], [16, "be"], [16, "also"], [16, "true"], [16, ":"], [16, "other"], [16, "axis"], [16, "i"], [16, "disorder"], [16, "such"], [16, "as"], [16, "major"], [16, "depression"], [16, ","], [16, "substance"], [16, "abuse"], [16, ","], [16, "and"], [16, "post"], [16, "-"], [16, "traumatic"], [16, "stress"], [16, "disorder"], [16, "be"], [16, "also"], [16, "more"], [16, "commonly"], [16, "diagnose"], [16, "in"], [16, "patient"], [16, "with"], [16, "bpd"], [16, "than"], [16, "be"], [16, "bipolar"], [16, "disorder"], [16, "."], [17, "these"], [17, "finding"], [17, "challenge"], [17, "the"], [17, "notion"], [17, "that"], [17, "bpd"], [17, "be"], [17, "part"], [17, "of"], [17, "the"], [17, "bipolar"], [17, "spectrum"], [17, "."], [18, "episode"], [18, "duration"], [18, ","], [18, "recurrence"], [18, "rate"], [18, ","], [18, "and"], [18, "time"], [18, "spend"], [18, "in"], [18, "manic"], [18, "and"], [18, "depressive"], [18, "phase"], [18, "of"], [18, "bipolar"], [18, "disorder"], [18, "("], [18, "bd"], [18, ")"], [18, "be"], [18, "not"], [18, "well"], [18, "define"], [18, "for"], [18, "subtype"], [18, "of"], [18, "the"], [18, "disorder"], [18, "."], [19, "we"], [19, "review"], [19, "the"], [19, "course"], [19, ","], [19, "timing"], [19, ","], [19, "and"], [19, "duration"], [19, "of"], [19, "episode"], [19, "of"], [19, "mania"], [19, "and"], [19, "depression"], [19, "among"], [19, "1130"], [19, "clinically"], [19, "treat"], [19, "dsm"], [19, "-"], [19, "iv"], [19, "-"], [19, "tr"], [19, "bd"], [19, "patient"], [19, "of"], [19, "various"], [19, "type"], [19, ","], [19, "and"], [19, "compare"], [19, "duration"], [19, "and"], [19, "rate"], [19, "as"], [19, "well"], [19, "as"], [19, "total"], [19, "proportion"], [19, "of"], [19, "time"], [19, "in"], [19, "depressive"], [19, "versus"], [19, "manic"], [19, "episode"], [19, "during"], [19, "16.7"], [19, "average"], [19, "year"], [19, "at"], [19, "risk"], [19, "."], [20, "as"], [20, "expect"], [20, ","], [20, "episode"], [20, "of"], [20, "depression"], [20, "be"], [20, "much"], [20, "long"], [20, "than"], [20, "mania"], [20, ","], [20, "but"], [20, "episode"], [20, "-"], [20, "duration"], [20, "do"], [20, "not"], [20, "differ"], [20, "among"], [20, "bd"], [20, "diagnostic"], [20, "type"], [20, ":"], [20, "i"], [20, ","], [20, "ii"], [20, ","], [20, "with"], [20, "mainly"], [20, "mix"], [20, "-"], [20, "episode"], [20, "("], [20, "bd"], [20, "-"], [20, "mx"], [20, ")"], [20, ","], [20, "or"], [20, "with"], [20, "psychotic"], [20, "feature"], [20, "("], [20, "bd"], [20, "-"], [20, "p"], [20, ")"], [20, "."], [21, "recurrence"], [21, "rate"], [21, "("], [21, "episode"], [21, "/"], [21, "year"], [21, ")"], [21, "and"], [21, "proportion"], [21, "of"], [21, "time"], [21, "in"], [21, "depression"], [21, "and"], [21, "their"], [21, "ratio"], [21, "to"], [21, "mania"], [21, "be"], [21, "high"], [21, "in"], [21, "bd"], [21, "-"], [21, "ii"], [21, "and"], [21, "bd"], [21, "-"], [21, "mx"], [21, "subject"], [21, ","], [21, "with"], [21, "more"], [21, "mania"], [21, "/"], [21, "year"], [21, "in"], [21, "psychotic"], [21, "and"], [21, "bd"], [21, "-"], [21, "i"], [21, "subject"], [21, "."], [22, "in"], [22, "most"], [22, "bd"], [22, "-"], [22, "subtype"], [22, ","], [22, "except"], [22, "with"], [22, "psychotic"], [22, "feature"], [22, ","], [22, "there"], [22, "be"], [22, "more"], [22, "time"], [22, "in"], [22, "depressive"], [22, "than"], [22, "manic"], [22, "morbidity"], [22, ","], [22, "owe"], [22, "mainly"], [22, "to"], [22, "long"], [22, "depressive"], [22, "than"], [22, "manic"], [22, "episode"], [22, "."], [23, "the"], [23, "proportion"], [23, "of"], [23, "time"], [23, "in"], [23, "depression"], [23, "be"], [23, "high"], [23, "among"], [23, "those"], [23, "who"], [23, "follow"], [23, "a"], [23, "predominant"], [23, "dmi"], [23, "course"], [23, ","], [23, "whereas"], [23, "total"], [23, "time"], [23, "in"], [23, "mania"], [23, "be"], [23, "great"], [23, "in"], [23, "bd"], [23, "with"], [23, "psychotic"], [23, "feature"], [23, "and"], [23, "bd"], [23, "-"], [23, "i."], [23, "and"], [23, "with"], [23, "an"], [23, "mdi"], [23, "course"], [23, "."], [24, "subtype"], [24, "of"], [24, "bd"], [24, "patient"], [24, "differ"], [24, "little"], [24, "in"], [24, "episode"], [24, "-"], [24, "duration"], [24, ","], [24, "which"], [24, "be"], [24, "consistently"], [24, "much"], [24, "long"], [24, "for"], [24, "depression"], [24, "."], [25, "the"], [25, "finding"], [25, "underscore"], [25, "the"], [25, "limited"], [25, "control"], [25, "of"], [25, "bipolar"], [25, "depression"], [25, "with"], [25, "available"], [25, "treatment"], [25, "."], [26, "characterize"], [26, "by"], [26, "the"], [26, "switch"], [26, "of"], [26, "manic"], [26, "and"], [26, "depressive"], [26, "phase"], [26, ","], [26, "bipolar"], [26, "disorder"], [26, "be"], [26, "describe"], [26, "as"], [26, "early"], [26, "as"], [26, "the"], [26, "fifth"], [26, "century"], [26, "bc"], [26, "."], [27, "nevertheless"], [27, "up"], [27, "to"], [27, "date"], [27, ","], [27, "the"], [27, "underlie"], [27, "neurobiology"], [27, "be"], [27, "still"], [27, "largely"], [27, "unclear"], [27, ","], [27, "assume"], [27, "a"], [27, "multifactor"], [27, "genesis"], [27, "with"], [27, "both"], [27, "biological"], [27, "-"], [27, "genetic"], [27, "and"], [27, "psychosocial"], [27, "factor"], [27, "."], [28, "significant"], [28, "process"], [28, "have"], [28, "be"], [28, "achieve"], [28, "in"], [28, "recent"], [28, "year"], [28, "in"], [28, "research"], [28, "the"], [28, "cause"], [28, "of"], [28, "bipolar"], [28, "disorder"], [28, "with"], [28, "modern"], [28, "molecular"], [28, "biological"], [28, "("], [28, "e.g."], [28, ","], [28, "genetic"], [28, "and"], [28, "epigenetic"], [28, "study"], [28, ")"], [28, "and"], [28, "imaging"], [28, "technique"], [28, "("], [28, "e.g."], [28, ","], [28, "positron"], [28, "emission"], [28, "tomography"], [28, "("], [28, "pet"], [28, ")"], [28, "and"], [28, "functional"], [28, "magnetic"], [28, "resonance"], [28, "imaging"], [28, "("], [28, "fmri"], [28, ")"], [28, ")"], [28, "."], [29, "in"], [29, "this"], [29, "chapter"], [29, "we"], [29, "will"], [29, "first"], [29, "summarize"], [29, "our"], [29, "recent"], [29, "knowledge"], [29, "on"], [29, "the"], [29, "etiology"], [29, "of"], [29, "bipolar"], [29, "disorder"], [29, "."], [30, "we"], [30, "then"], [30, "discuss"], [30, "how"], [30, "several"], [30, "factor"], [30, "observe"], [30, "to"], [30, "contribute"], [30, "to"], [30, "bipolar"], [30, "disorder"], [30, "in"], [30, "human"], [30, "patient"], [30, "can"], [30, "be"], [30, "manipulate"], [30, "to"], [30, "generate"], [30, "rodent"], [30, "model"], [30, "for"], [30, "bipolar"], [30, "disorder"], [30, "."], [31, "finally"], [31, ","], [31, "we"], [31, "will"], [31, "give"], [31, "an"], [31, "overview"], [31, "on"], [31, "behavioral"], [31, "test"], [31, "that"], [31, "can"], [31, "be"], [31, "use"], [31, "to"], [31, "assess"], [31, "bipolar"], [31, "-"], [31, "disorder"], [31, "-"], [31, "like"], [31, "behavior"], [31, "in"], [31, "rodent"], [31, "."], [32, "borderline"], [32, "personality"], [32, "disorder"], [32, "("], [32, "bpd"], [32, ")"], [32, "and"], [32, "bipolar"], [32, "disorder"], [32, "("], [32, "type"], [32, "i"], [32, "and"], [32, "ii"], [32, ")"], [32, "be"], [32, "frequently"], [32, "confuse"], [32, "because"], [32, "of"], [32, "their"], [32, "symptomatic"], [32, "overlap"], [32, "."], [33, "although"], [33, "affective"], [33, "instability"], [33, "be"], [33, "a"], [33, "prominent"], [33, "feature"], [33, "of"], [33, "each"], [33, ","], [33, "the"], [33, "pattern"], [33, "be"], [33, "entirely"], [33, "different"], [33, "."], [34, "bpd"], [34, "be"], [34, "characterize"], [34, "by"], [34, "transient"], [34, "mood"], [34, "shift"], [34, "that"], [34, "occur"], [34, "in"], [34, "response"], [34, "to"], [34, "interpersonal"], [34, "stressor"], [34, ","], [34, "whereas"], [34, "bipolar"], [34, "disorder"], [34, "be"], [34, "associate"], [34, "with"], [34, "sustained"], [34, "mood"], [34, "change"], [34, "."], [35, "these"], [35, "disorder"], [35, "can"], [35, "be"], [35, "far"], [35, "distinguish"], [35, "by"], [35, "compare"], [35, "their"], [35, "phenomenology"], [35, ","], [35, "etiology"], [35, ","], [35, "family"], [35, "history"], [35, ","], [35, "biological"], [35, "study"], [35, ","], [35, "outcome"], [35, ","], [35, "and"], [35, "response"], [35, "to"], [35, "medication"], [35, "."], [36, "their"], [36, "distinction"], [36, "be"], [36, "of"], [36, "great"], [36, "clinical"], [36, "importance"], [36, "because"], [36, "misdiagnosis"], [36, "can"], [36, "deprive"], [36, "the"], [36, "patient"], [36, "of"], [36, "potentially"], [36, "effective"], [36, "treatment"], [36, ","], [36, "whether"], [36, "it"], [36, "be"], [36, "psychotherapy"], [36, "for"], [36, "bpd"], [36, "or"], [36, "medication"], [36, "for"], [36, "bipolar"], [36, "disorder"], [36, "."], [37, "on"], [37, "the"], [37, "basis"], [37, "of"], [37, "a"], [37, "comprehensive"], [37, "literature"], [37, "review"], [37, ","], [37, "guideline"], [37, "for"], [37, "differential"], [37, "diagnosis"], [37, "be"], [37, "suggest"], [37, ","], [37, "and"], [37, "priority"], [37, "for"], [37, "further"], [37, "research"], [37, "be"], [37, "recommend"], [37, "."], [38, "this"], [38, "review"], [38, "article"], [38, "provide"], [38, "an"], [38, "overview"], [38, "of"], [38, "the"], [38, "frequency"], [38, ","], [38, "burden"], [38, "of"], [38, "illness"], [38, ","], [38, "diagnosis"], [38, ","], [38, "and"], [38, "treatment"], [38, "of"], [38, "bipolar"], [38, "disorder"], [38, "("], [38, "bd"], [38, ")"], [38, "from"], [38, "the"], [38, "perspective"], [38, "of"], [38, "the"], [38, "advanced"], [38, "practice"], [38, "nurse"], [38, "("], [38, "apns"], [38, ")"], [38, "."], [39, "pubme"], [39, "search"], [39, "be"], [39, "conduct"], [39, "use"], [39, "the"], [39, "follow"], [39, "keyword"], [39, ":"], [39, '"'], [39, "bipolar"], [39, "disorder"], [39, "and"], [39, "primary"], [39, "care"], [39, ","], [39, '"'], [39, "restrict"], [39, "to"], [39, "date"], [39, "2000"], [39, "to"], [39, "present"], [39, ";"], [39, '"'], [39, "bipolar"], [39, "disorder"], [39, "and"], [39, "nurse"], [39, "practitioner"], [39, '"'], [39, ";"], [39, "and"], [39, '"'], [39, "bipolar"], [39, "disorder"], [39, "and"], [39, "clinical"], [39, "nurse"], [39, "specialist"], [39, "."], [39, '"'], [40, "select"], [40, "article"], [40, "be"], [40, "relevant"], [40, "to"], [40, "adult"], [40, "outpatient"], [40, "care"], [40, "in"], [40, "the"], [40, "united"], [40, "states"], [40, ","], [40, "with"], [40, "a"], [40, "prioritization"], [40, "of"], [40, "article"], [40, "write"], [40, "by"], [40, "apn"], [40, "or"], [40, "publish"], [40, "in"], [40, "nursing"], [40, "journal"], [40, "."], [41, "bd"], [41, "have"], [41, "a"], [41, "substantial"], [41, "lifetime"], [41, "prevalence"], [41, "in"], [41, "the"], [41, "population"], [41, "at"], [41, "4"], [41, "%"], [41, "."], [42, "because"], [42, "the"], [42, "manic"], [42, "or"], [42, "depressive"], [42, "symptom"], [42, "of"], [42, "bd"], [42, "tend"], [42, "to"], [42, "be"], [42, "severe"], [42, "and"], [42, "recurrent"], [42, "over"], [42, "a"], [42, "patient"], [42, "'s"], [42, "lifetime"], [42, ","], [42, "the"], [42, "condition"], [42, "be"], [42, "associate"], [42, "with"], [42, "significant"], [42, "burden"], [42, "to"], [42, "the"], [42, "individual"], [42, ","], [42, "caregiver"], [42, ","], [42, "and"], [42, "society"], [42, "."], [43, "clinician"], [43, "awareness"], [43, "that"], [43, "bd"], [43, "may"], [43, "be"], [43, "present"], [43, "increase"], [43, "the"], [43, "likelihood"], [43, "of"], [43, "successful"], [43, "recognition"], [43, "and"], [43, "appropriate"], [43, "treatment"], [43, "."], [44, "a"], [44, "number"], [44, "of"], [44, "pharmacological"], [44, "and"], [44, "nonpharmacological"], [44, "treatment"], [44, "be"], [44, "available"], [44, "for"], [44, "acute"], [44, "and"], [44, "maintenance"], [44, "treatment"], [44, ","], [44, "with"], [44, "the"], [44, "prospect"], [44, "of"], [44, "achieve"], [44, "reduce"], [44, "symptom"], [44, "burden"], [44, "and"], [44, "increase"], [44, "function"], [44, "for"], [44, "many"], [44, "patient"], [44, "."], [45, "awareness"], [45, "of"], [45, "the"], [45, "disease"], [45, "burden"], [45, ","], [45, "diagnostic"], [45, "issue"], [45, ","], [45, "and"], [45, "management"], [45, "choice"], [45, "in"], [45, "bd"], [45, "have"], [45, "the"], [45, "potential"], [45, "to"], [45, "enhance"], [45, "outcome"], [45, "in"], [45, "substantial"], [45, "proportion"], [45, "of"], [45, "patient"], [45, "."], [46, "bipolar"], [46, "disorder"], [46, "be"], [46, "a"], [46, "severe"], [46, "psychiatric"], [46, "disorder"], [46, ","], [46, "characterize"], [46, "by"], [46, "depressive"], [46, ","], [46, "manic"], [46, "and"], [46, "mixed"], [46, "episode"], [46, "."], [47, "the"], [47, "illness"], [47, "affect"], [47, "about"], [47, "1"], [47, "-"], [47, "2"], [47, "\xA0"], [47, "%"], [47, "of"], [47, "the"], [47, "population"], [47, "."], [48, "bipolar"], [48, "i"], [48, "disorder"], [48, "affect"], [48, "both"], [48, "gender"], [48, "equally"], [48, ","], [48, "whereas"], [48, "bipolar"], [48, "ii"], [48, "disorder"], [48, "seem"], [48, "to"], [48, "occur"], [48, "more"], [48, "frequently"], [48, "in"], [48, "woman"], [48, "."], [49, "the"], [49, "classification"], [49, "of"], [49, "the"], [49, "different"], [49, "subtype"], [49, "of"], [49, "bipolar"], [49, "disorder"], [49, "be"], [49, "do"], [49, "depend"], [49, "on"], [49, "the"], [49, "severity"], [49, "and"], [49, "frequency"], [49, "of"], [49, "the"], [49, "episode"], [49, "."], [50, "other"], [50, "subtype"], [50, "beside"], [50, "bipolar"], [50, "i"], [50, "and"], [50, "bipolar"], [50, "ii"], [50, "disorder"], [50, "be"], [50, "rapid"], [50, "cycling"], [50, "("], [50, "more"], [50, "than"], [50, "4"], [50, "episode"], [50, "of"], [50, "mania"], [50, ","], [50, "depression"], [50, ","], [50, "hypomania"], [50, "or"], [50, "mixed"], [50, "state"], [50, "in"], [50, "one"], [50, "year"], [50, ")"], [50, "and"], [50, "cyclothymia"], [50, "("], [50, "hypomanic"], [50, "and"], [50, "subdepressive"], [50, "symptom"], [50, "over"], [50, "a"], [50, "two"], [50, "year"], [50, "period"], [50, ")"], [50, "."], [51, "besides"], [51, "a"], [51, "thorough"], [51, "psychiatric"], [51, "and"], [51, "neurological"], [51, "examination"], [51, ","], [51, "further"], [51, "clinical"], [51, "test"], [51, "should"], [51, "be"], [51, "perform"], [51, "in"], [51, "order"], [51, "to"], [51, "exclude"], [51, "differential"], [51, "diagnosis"], [51, "("], [51, "psychiatric"], [51, "as"], [51, "well"], [51, "as"], [51, "neurological"], [51, "and"], [51, "somatic"], [51, "disease"], [51, ")"], [51, "."], [52, "the"], [52, "course"], [52, "of"], [52, "the"], [52, "illness"], [52, "be"], [52, "often"], [52, "negatively"], [52, "affect"], [52, "by"], [52, "the"], [52, "high"], [52, "frequency"], [52, "of"], [52, "psychiatric"], [52, "and"], [52, "somatic"], [52, "comorbiditie"], [52, "."], [53, "after"], [53, "all"], [53, "the"], [53, "prognosis"], [53, "of"], [53, "bipolar"], [53, "disorder"], [53, "be"], [53, "depend"], [53, "on"], [53, "the"], [53, "individual"], [53, "course"], [53, "of"], [53, "the"], [53, "illness"], [53, "."], [54, "notably"], [54, "comorbiditie"], [54, "and"], [54, "psychotic"], [54, "symptom"], [54, "seem"], [54, "to"], [54, "have"], [54, "a"], [54, "negative"], [54, "influence"], [54, "on"], [54, "the"], [54, "prognosis"], [54, "."], [55, "further"], [55, "understanding"], [55, "of"], [55, "old"], [55, "age"], [55, "bipolar"], [55, "disorder"], [55, "("], [55, "oabd"], [55, ")"], [55, "may"], [55, "lead"], [55, "to"], [55, "more"], [55, "specific"], [55, "recommendation"], [55, "for"], [55, "treatment"], [55, "adjust"], [55, "to"], [55, "the"], [55, "specific"], [55, "characteristic"], [55, "and"], [55, "need"], [55, "cause"], [55, "by"], [55, "age"], [55, "-"], [55, "relate"], [55, "somatic"], [55, "and"], [55, "cognitive"], [55, "change"], [55, "."], [56, "late"], [56, "-"], [56, "onset"], [56, "mania"], [56, "have"], [56, "a"], [56, "broad"], [56, "differential"], [56, "diagnosis"], [56, "and"], [56, "require"], [56, "full"], [56, "psychiatric"], [56, "and"], [56, "somatic"], [56, "work"], [56, "-"], [56, "up"], [56, ","], [56, "include"], [56, "brain"], [56, "imaging"], [56, "."], [57, "research"], [57, "on"], [57, "pharmacotherapy"], [57, "in"], [57, "oabd"], [57, "be"], [57, "limit"], [57, "."], [58, "first"], [58, "-"], [58, "line"], [58, "treatment"], [58, "of"], [58, "oabd"], [58, "be"], [58, "similar"], [58, "to"], [58, "that"], [58, "for"], [58, "adult"], [58, "bipolar"], [58, "disorder"], [58, "("], [58, "bd"], [58, ")"], [58, ","], [58, "with"], [58, "specific"], [58, "attention"], [58, "to"], [58, "vulnerability"], [58, "to"], [58, "side"], [58, "effect"], [58, "and"], [58, "somatic"], [58, "comorbidity"], [58, "."], [59, "because"], [59, "find"], [59, "in"], [59, "young"], [59, "adult"], [59, "with"], [59, "bd"], [59, "can"], [59, "not"], [59, "be"], [59, "extrapolate"], [59, "to"], [59, "oabd"], [59, ","], [59, "more"], [59, "research"], [59, "in"], [59, "oabd"], [59, "be"], [59, "warrant"], [59, "."], [60, "bipolar"], [60, "disorder"], [60, "("], [60, "bpd"], [60, ")"], [60, "be"], [60, "a"], [60, "potentially"], [60, "lifelong"], [60, "condition"], [60, "characterise"], [60, "by"], [60, "extreme"], [60, "change"], [60, "in"], [60, "mood"], [60, "that"], [60, "may"], [60, "begin"], [60, "in"], [60, "childhood"], [60, "and"], [60, "cause"], [60, "substantial"], [60, "impairment"], [60, "."], [61, "over"], [61, "the"], [61, "past"], [61, "decade"], [61, ","], [61, "bpd"], [61, "have"], [61, "be"], [61, "the"], [61, "focus"], [61, "of"], [61, "increase"], [61, "attention"], [61, "mainly"], [61, "due"], [61, "to"], [61, "controversy"], [61, "surround"], [61, "its"], [61, "prevalence"], [61, ","], [61, "diagnosis"], [61, "and"], [61, "treatment"], [61, "in"], [61, "child"], [61, "and"], [61, "adolescent"], [61, "."], [62, "this"], [62, "report"], [62, "address"], [62, "these"], [62, "controversy"], [62, "by"], [62, "review"], [62, "the"], [62, "extant"], [62, "evidence"], [62, "base"], [62, ","], [62, "provide"], [62, "clinician"], [62, "with"], [62, "a"], [62, "summary"], [62, "of"], [62, "the"], [62, "literature"], [62, "on"], [62, "diagnosis"], [62, ","], [62, "phenomenology"], [62, "and"], [62, "treatment"], [62, "of"], [62, "paediatric"], [62, "bpd"], [62, "."], [63, "the"], [63, "debate"], [63, "regard"], [63, "diagnose"], [63, "child"], [63, "with"], [63, "bpd"], [63, "base"], [63, "on"], [63, "severe"], [63, "irritability"], [63, "and"], [63, "aggression"], [63, "be"], [63, "mostly"], [63, "resolve"], [63, "."], [64, "the"], [64, "current"], [64, "data"], [64, "support"], [64, "utilise"], [64, "the"], [64, "diagnostic"], [64, "criterion"], [64, "base"], [64, "on"], [64, "episodic"], [64, "change"], [64, "of"], [64, "mood"], [64, "polarity"], [64, "."], [65, "therefore"], [65, ","], [65, "longitudinal"], [65, "course"], [65, "of"], [65, "illness"], [65, "should"], [65, "be"], [65, "explore"], [65, "in"], [65, "detail"], [65, "when"], [65, "diagnose"], [65, "bpd"], [65, "."], [66, "give"], [66, "high"], [66, "rate"], [66, "of"], [66, "genetic"], [66, "predisposition"], [66, "for"], [66, "bpd"], [66, ","], [66, "assessment"], [66, "of"], [66, "youth"], [66, "should"], [66, "focus"], [66, "on"], [66, "obtain"], [66, "accurate"], [66, "family"], [66, "history"], [66, "of"], [66, "this"], [66, "condition"], [66, "."], [67, "additionally"], [67, ","], [67, "there"], [67, "have"], [67, "be"], [67, "a"], [67, "substantial"], [67, "increase"], [67, "in"], [67, "randomised"], [67, "placebo"], [67, "-"], [67, "control"], [67, "clinical"], [67, "trial"], [67, "evaluate"], [67, "pharmacological"], [67, "agent"], [67, "for"], [67, "mood"], [67, "stabilisation"], [67, "in"], [67, "child"], [67, "and"], [67, "adolescent"], [67, ","], [67, "which"], [67, "we"], [67, "summarise"], [67, "in"], [67, "this"], [67, "review"], [67, "."], [68, "despite"], [68, "significant"], [68, "progress"], [68, "be"], [68, "make"], [68, "in"], [68, "the"], [68, "field"], [68, "of"], [68, "paediatric"], [68, "bpd"], [68, ","], [68, "more"], [68, "research"], [68, "be"], [68, "nee"], [68, "in"], [68, "the"], [68, "area"], [68, "of"], [68, "phenomenology"], [68, ","], [68, "pathophysiology"], [68, ","], [68, "course"], [68, "and"], [68, "treatment"], [68, "of"], [68, "this"], [68, "condition"], [68, "in"], [68, "youth"], [68, "."], [69, "people"], [69, "with"], [69, "bipolar"], [69, "disorder"], [69, "frequently"], [69, "experience"], [69, "persistent"], [69, "residual"], [69, "symptom"], [69, ","], [69, "problem"], [69, "in"], [69, "psychosocial"], [69, "functioning"], [69, ","], [69, "cognitive"], [69, "impairment"], [69, ","], [69, "and"], [69, "poor"], [69, "quality"], [69, "of"], [69, "life"], [69, "."], [70, "in"], [70, "the"], [70, "last"], [70, "decade"], [70, ","], [70, "the"], [70, "treatment"], [70, "target"], [70, "in"], [70, "clinical"], [70, "and"], [70, "research"], [70, "setting"], [70, "have"], [70, "focus"], [70, "not"], [70, "only"], [70, "on"], [70, "clinical"], [70, "remission"], [70, ","], [70, "but"], [70, "also"], [70, "on"], [70, "functional"], [70, "recovery"], [70, "and"], [70, ","], [70, "more"], [70, "lately"], [70, ","], [70, "in"], [70, "personal"], [70, "recovery"], [70, ","], [70, "take"], [70, "into"], [70, "account"], [70, "patient"], [70, "'"], [70, "well"], [70, "-"], [70, "being"], [70, "and"], [70, "quality"], [70, "of"], [70, "life"], [70, "."], [71, "hence"], [71, ","], [71, "the"], [71, "trend"], [71, "in"], [71, "psychiatry"], [71, "and"], [71, "psychology"], [71, "be"], [71, "to"], [71, "treat"], [71, "bipolar"], [71, "disorder"], [71, "in"], [71, "an"], [71, "integrative"], [71, "and"], [71, "holistic"], [71, "manner"], [71, "."], [72, "this"], [72, "literature"], [72, "review"], [72, "offer"], [72, "an"], [72, "overview"], [72, "regard"], [72, "psychosocial"], [72, "function"], [72, "in"], [72, "bipolar"], [72, "disorder"], [72, "."], [73, "first"], [73, ","], [73, "a"], [73, "brief"], [73, "summary"], [73, "be"], [73, "provide"], [73, "regard"], [73, "the"], [73, "definition"], [73, "of"], [73, "psychosocial"], [73, "functioning"], [73, "and"], [73, "the"], [73, "tool"], [73, "to"], [73, "measure"], [73, "it"], [73, "."], [74, "then"], [74, ","], [74, "the"], [74, "most"], [74, "report"], [74, "variable"], [74, "influence"], [74, "the"], [74, "functional"], [74, "outcome"], [74, "in"], [74, "patient"], [74, "with"], [74, "bipolar"], [74, "disorder"], [74, "be"], [74, "list"], [74, "."], [75, "thereafter"], [75, ","], [75, "we"], [75, "include"], [75, "a"], [75, "section"], [75, "discuss"], [75, "therapy"], [75, "with"], [75, "prove"], [75, "efficacy"], [75, "at"], [75, "enhance"], [75, "functional"], [75, "outcome"], [75, "."], [76, "other"], [76, "possible"], [76, "therapy"], [76, "that"], [76, "could"], [76, "be"], [76, "useful"], [76, "to"], [76, "prevent"], [76, "functional"], [76, "decline"], [76, "and"], [76, "improve"], [76, "function"], [76, "be"], [76, "present"], [76, "in"], [76, "another"], [76, "section"], [76, "."], [77, "finally"], [77, ","], [77, "in"], [77, "the"], [77, "last"], [77, "part"], [77, "of"], [77, "this"], [77, "review"], [77, ","], [77, "different"], [77, "intervention"], [77, "direct"], [77, "to"], [77, "improve"], [77, "patient"], [77, "'"], [77, "well"], [77, "-"], [77, "being"], [77, ","], [77, "quality"], [77, "of"], [77, "life"], [77, ","], [77, "and"], [77, "personal"], [77, "recovery"], [77, "be"], [77, "briefly"], [77, "describe"], [77, "."], [78, "patient"], [78, "with"], [78, "adult"], [78, "attention"], [78, "-"], [78, "deficit/"], [78, "hyperactivity"], [78, "disorder"], [78, "("], [78, "adhd"], [78, ")"], [78, "and"], [78, "bipolar"], [78, "disorder"], [78, "can"], [78, "present"], [78, "with"], [78, "similar"], [78, "symptom"], [78, ","], [78, "include"], [78, "increase"], [78, "energy"], [78, ","], [78, "distractibility"], [78, ","], [78, "disorganization"], [78, ","], [78, "impulsivity"], [78, ","], [78, "hyperactivity"], [78, ","], [78, "and"], [78, "rapid"], [78, "speech"], [78, "."], [79, "determine"], [79, "whether"], [79, "the"], [79, "patient"], [79, "have"], [79, "either"], [79, ","], [79, "or"], [79, "possibly"], [79, "both"], [79, ","], [79, "of"], [79, "these"], [79, "syndrome"], [79, "can"], [79, "be"], [79, "a"], [79, "complex"], [79, "task"], [79, "."], [80, "this"], [80, "review"], [80, "attempt"], [80, "to"], [80, "clarify"], [80, "where"], [80, "these"], [80, "disorder"], [80, "overlap"], [80, ","], [80, "both"], [80, "symptomatically"], [80, "and"], [80, "epidemiologically"], [80, ","], [80, "and"], [80, "where"], [80, "they"], [80, "diverge"], [80, ","], [80, "to"], [80, "help"], [80, "clinician"], [80, "increase"], [80, "the"], [80, "accuracy"], [80, "of"], [80, "their"], [80, "diagnosis"], [80, "."], [81, "change"], [81, "to"], [81, "diagnostic"], [81, "criterion"], [81, "from"], [81, "the"], [81, "fourth"], [81, "to"], [81, "the"], [81, "fifth"], [81, "edition"], [81, "of"], [81, "the"], [81, "diagnostic"], [81, "and"], [81, "statistical"], [81, "manual"], [81, "of"], [81, "mental"], [81, "disorder"], [81, "("], [81, "from"], [81, "dsm"], [81, "-"], [81, "iv"], [81, "-"], [81, "tr"], [81, "to"], [81, "dsm-5"], [81, ")"], [81, "be"], [81, "discuss"], [81, ","], [81, "as"], [81, "be"], [81, "the"], [81, "evidence"], [81, "base"], [81, "for"], [81, "pharmacological"], [81, "treatment"], [81, "."], [82, "study"], [82, "and"], [82, "source"], [82, "be"], [82, "identify"], [82, "use"], [82, "computerized"], [82, "search"], [82, "."], [83, "adult"], [83, "adhd"], [83, "and"], [83, "bipolar"], [83, "disorder"], [83, "have"], [83, "multiple"], [83, "overlap"], [83, "symptom"], [83, ","], [83, "but"], [83, "there"], [83, "be"], [83, "difference"], [83, "in"], [83, "prevalence"], [83, "("], [83, "adhd"], [83, "affect"], [83, "4.4"], [83, "%"], [83, "of"], [83, "adult"], [83, "in"], [83, "the"], [83, "united"], [83, "states"], [83, "versus"], [83, "1.4"], [83, "%"], [83, "for"], [83, "bipolar"], [83, "disorder"], [83, ")"], [83, ","], [83, "onset"], [83, "of"], [83, "symptom"], [83, "("], [83, "usually"], [83, "before"], [83, "age"], [83, "7"], [83, "year"], [83, "in"], [83, "adhd"], [83, "versus"], [83, "after"], [83, "age"], [83, "12"], [83, "year"], [83, "in"], [83, "bipolar"], [83, "disorder"], [83, ")"], [83, ","], [83, "disease"], [83, "course"], [83, "("], [83, "chronic"], [83, "in"], [83, "adhd"], [83, "versus"], [83, "cyclical"], [83, "in"], [83, "bipolar"], [83, "disorder"], [83, ")"], [83, ","], [83, "mood"], [83, "symptom"], [83, "("], [83, "absent"], [83, "in"], [83, "adhd"], [83, "but"], [83, "always"], [83, "present"], [83, "in"], [83, "bipolar"], [83, "disorder"], [83, ")"], [83, ","], [83, "and"], [83, "psychotic"], [83, "symptom"], [83, "("], [83, "absent"], [83, "in"], [83, "adhd"], [83, "but"], [83, "sometimes"], [83, "present"], [83, "in"], [83, "bipolar"], [83, "disorder"], [83, ")"], [83, "."], [84, "approximately"], [84, "20"], [84, "%"], [84, "of"], [84, "adult"], [84, "patient"], [84, "with"], [84, "adhd"], [84, "also"], [84, "have"], [84, "bipolar"], [84, "disorder"], [84, ","], [84, "while"], [84, "10%-20"], [84, "%"], [84, "of"], [84, "patient"], [84, "with"], [84, "bipolar"], [84, "disorder"], [84, "have"], [84, "adult"], [84, "adhd"], [84, "."], [85, "comorbidity"], [85, "of"], [85, "bipolar"], [85, "disorder"], [85, "and"], [85, "adhd"], [85, "be"], [85, "associate"], [85, "with"], [85, "an"], [85, "early"], [85, "age"], [85, "of"], [85, "onset"], [85, "and"], [85, "a"], [85, "more"], [85, "chronic"], [85, "and"], [85, "disabling"], [85, "course"], [85, "of"], [85, "bipolar"], [85, "disorder"], [85, ","], [85, "as"], [85, "well"], [85, "as"], [85, "more"], [85, "psychiatric"], [85, "comorbidity"], [85, "."], [86, "distinguish"], [86, "between"], [86, "adult"], [86, "adhd"], [86, "and"], [86, "bipolar"], [86, "disorder"], [86, "require"], [86, "careful"], [86, "attention"], [86, "to"], [86, "phenomenology"], [86, "and"], [86, "awareness"], [86, "of"], [86, "epidemiology"], [86, ","], [86, "with"], [86, "a"], [86, "focus"], [86, "on"], [86, "childhood"], [86, "history"], [86, ","], [86, "lifetime"], [86, "course"], [86, "of"], [86, "symptom"], [86, ","], [86, "and"], [86, "the"], [86, "possibility"], [86, "of"], [86, "comorbidity"], [86, "."], [87, "bipolar"], [87, "disorder"], [87, "be"], [87, "a"], [87, "lifelong"], [87, "mood"], [87, "disorder"], [87, "characterize"], [87, "by"], [87, "extreme"], [87, "mood"], [87, "swing"], [87, "between"], [87, "mania"], [87, "and"], [87, "depression"], [87, "."], [88, "despite"], [88, "fitness"], [88, "cost"], [88, "associate"], [88, "with"], [88, "increase"], [88, "mortality"], [88, "and"], [88, "significant"], [88, "impairment"], [88, ","], [88, "bipolar"], [88, "disorder"], [88, "have"], [88, "persist"], [88, "in"], [88, "the"], [88, "population"], [88, "with"], [88, "a"], [88, "high"], [88, "heritability"], [88, "and"], [88, "a"], [88, "stable"], [88, "prevalence"], [88, "."], [89, "creativity"], [89, "and"], [89, "other"], [89, "positive"], [89, "trait"], [89, "have"], [89, "repeatedly"], [89, "be"], [89, "associate"], [89, "with"], [89, "the"], [89, "bipolar"], [89, "spectrum"], [89, ","], [89, "particularly"], [89, "among"], [89, "unaffected"], [89, "first"], [89, "-"], [89, "degree"], [89, "relative"], [89, "and"], [89, "those"], [89, "with"], [89, "milder"], [89, "expression"], [89, "of"], [89, "bipolar"], [89, "trait"], [89, "."], [90, "this"], [90, "suggest"], [90, "a"], [90, "model"], [90, "in"], [90, "which"], [90, "large"], [90, "dose"], [90, "of"], [90, "risk"], [90, "variant"], [90, "cause"], [90, "illness"], [90, ","], [90, "but"], [90, "mild"], [90, "to"], [90, "moderate"], [90, "dose"], [90, "confer"], [90, "advantage"], [90, ","], [90, "which"], [90, "serve"], [90, "to"], [90, "maintain"], [90, "bipolar"], [90, "disorder"], [90, "in"], [90, "the"], [90, "population"], [90, "."], [91, "bipolar"], [91, "disorder"], [91, "may"], [91, "thus"], [91, "be"], [91, "well"], [91, "conceptualize"], [91, "as"], [91, "a"], [91, "dimensional"], [91, "trait"], [91, "exist"], [91, "at"], [91, "the"], [91, "extreme"], [91, "of"], [91, "normal"], [91, "population"], [91, "variation"], [91, "in"], [91, "positive"], [91, "temperament"], [91, ","], [91, "personality"], [91, ","], [91, "and"], [91, "cognitive"], [91, "trait"], [91, ","], [91, "aspect"], [91, "of"], [91, "which"], [91, "may"], [91, "reflect"], [91, "a"], [91, "share"], [91, "vulnerability"], [91, "with"], [91, "creativity"], [91, "."], [92, "investigation"], [92, "of"], [92, "this"], [92, "share"], [92, "vulnerability"], [92, "may"], [92, "provide"], [92, "insight"], [92, "into"], [92, "the"], [92, "genetic"], [92, "mechanism"], [92, "underlie"], [92, "illness"], [92, "and"], [92, "suggest"], [92, "novel"], [92, "treatment"], [92, "."], [93, "because"], [93, "the"], [93, "elderly"], [93, "be"], [93, "the"], [93, "fast"], [93, "grow"], [93, "segment"], [93, "of"], [93, "the"], [93, "population"], [93, ","], [93, "the"], [93, "number"], [93, "of"], [93, "old"], [93, "adult"], [93, "with"], [93, "bipolar"], [93, "disorder"], [93, "be"], [93, "increase"], [93, "."], [94, "geriatric"], [94, "bipolar"], [94, "disorder"], [94, "be"], [94, "relatively"], [94, "rare"], [94, ","], [94, "with"], [94, "an"], [94, "estimate"], [94, "lifetime"], [94, "prevalence"], [94, "of"], [94, "0.5"], [94, "%"], [94, "to"], [94, "1"], [94, "%"], [94, ","], [94, "although"], [94, "approximately"], [94, "4"], [94, "%"], [94, "to"], [94, "17"], [94, "%"], [94, "of"], [94, "old"], [94, "patient"], [94, "in"], [94, "clinical"], [94, "psychiatric"], [94, "setting"], [94, "have"], [94, "bipolar"], [94, "disorder"], [94, "."], [95, "bipolar"], [95, "elder"], [95, "be"], [95, "disproportionately"], [95, "affect"], [95, "by"], [95, "medical"], [95, "burden"], [95, "."], [96, "give"], [96, "the"], [96, "complex"], [96, "nature"], [96, "of"], [96, "this"], [96, "disorder"], [96, ","], [96, "comorbidity"], [96, ","], [96, "and"], [96, "behavioral"], [96, "disturbance"], [96, ","], [96, "various"], [96, "intervention"], [96, "may"], [96, "be"], [96, "indicate"], [96, ","], [96, "include"], [96, "pharmacotherapie"], [96, ","], [96, "electroconvulsive"], [96, "therapy"], [96, ","], [96, "psychotherapy"], [96, ","], [96, "and"], [96, "integrate"], [96, "care"], [96, "model"], [96, "."], [97, "additional"], [97, "research"], [97, "be"], [97, "nee"], [97, "to"], [97, "well"], [97, "understand"], [97, "the"], [97, "epidemiology"], [97, ","], [97, "phenomenology"], [97, ","], [97, "and"], [97, "treatment"], [97, "of"], [97, "geriatric"], [97, "bipolar"], [97, "disorder"], [97, "."], [98, "the"], [98, "purpose"], [98, "of"], [98, "this"], [98, "study"], [98, "be"], [98, "to"], [98, "analyze"], [98, "the"], [98, "evidence"], [98, "support"], [98, "a"], [98, "staging"], [98, "model"], [98, "for"], [98, "bipolar"], [98, "disorder"], [98, "."], [99, "the"], [99, "author"], [99, "conduct"], [99, "an"], [99, "extensive"], [99, "medline"], [99, "and"], [99, "pubme"], [99, "search"], [99, "of"], [99, "the"], [99, "publish"], [99, "literature"], [99, "use"], [99, "a"], [99, "variety"], [99, "of"], [99, "search"], [99, "term"], [99, "("], [99, "staging"], [99, ","], [99, "bipolar"], [99, "disorder"], [99, ","], [99, "early"], [99, "intervention"], [99, ")"], [99, "to"], [99, "find"], [99, "relevant"], [99, "article"], [99, ","], [99, "which"], [99, "be"], [99, "review"], [99, "in"], [99, "detail"], [99, "."], [100, "only"], [100, "recently"], [100, "specific"], [100, "proposal"], [100, "have"], [100, "be"], [100, "make"], [100, "to"], [100, "apply"], [100, "clinical"], [100, "staging"], [100, "to"], [100, "bipolar"], [100, "disorder"], [100, "."], [101, "the"], [101, "staging"], [101, "model"], [101, "in"], [101, "bipolar"], [101, "disorder"], [101, "suggest"], [101, "a"], [101, "progression"], [101, "from"], [101, "prodromal"], [101, "("], [101, "at"], [101, "-"], [101, "risk"], [101, ")"], [101, "to"], [101, "more"], [101, "severe"], [101, "and"], [101, "refractory"], [101, "presentation"], [101, "("], [101, "stage"], [101, "iv"], [101, ")"], [101, "."], [102, "a"], [102, "staging"], [102, "model"], [102, "imply"], [102, "a"], [102, "longitudinal"], [102, "appraisal"], [102, "of"], [102, "different"], [102, "aspect"], [102, ":"], [102, "clinical"], [102, "variable"], [102, ","], [102, "such"], [102, "as"], [102, "number"], [102, "of"], [102, "episode"], [102, "and"], [102, "subsyndromal"], [102, "symptom"], [102, ","], [102, "functional"], [102, "and"], [102, "cognitive"], [102, "impairment"], [102, ","], [102, "comorbidity"], [102, ","], [102, "biomarker"], [102, ","], [102, "and"], [102, "neuroanatomical"], [102, "change"], [102, "."], [103, "stage"], [103, "model"], [103, "be"], [103, "base"], [103, "on"], [103, "the"], [103, "fact"], [103, "that"], [103, "response"], [103, "to"], [103, "treatment"], [103, "be"], [103, "generally"], [103, "well"], [103, "when"], [103, "it"], [103, "be"], [103, "introduce"], [103, "early"], [103, "in"], [103, "the"], [103, "course"], [103, "of"], [103, "the"], [103, "illness"], [103, "."], [104, "it"], [104, "assume"], [104, "that"], [104, "early"], [104, "stage"], [104, "have"], [104, "well"], [104, "prognosis"], [104, "and"], [104, "require"], [104, "simple"], [104, "therapeutic"], [104, "regiman"], [104, "."], [105, "staging"], [105, "may"], [105, "assist"], [105, "in"], [105, "bipolar"], [105, "disorder"], [105, "treatment"], [105, "planning"], [105, "and"], [105, "prognosis"], [105, ","], [105, "and"], [105, "emphasize"], [105, "the"], [105, "importance"], [105, "of"], [105, "early"], [105, "intervention"], [105, "."], [106, "further"], [106, "research"], [106, "be"], [106, "require"], [106, "in"], [106, "this"], [106, "exciting"], [106, "and"], [106, "novel"], [106, "area"], [106, "."], [107, "the"], [107, "population"], [107, "over"], [107, "age"], [107, "60"], [107, "be"], [107, "grow"], [107, "more"], [107, "rapidly"], [107, "than"], [107, "the"], [107, "general"], [107, "population"], [107, "."], [108, "give"], [108, "the"], [108, "project"], [108, "increase"], [108, "and"], [108, "need"], [108, "for"], [108, "datum"], [108, "that"], [108, "can"], [108, "inform"], [108, "treatment"], [108, ","], [108, "this"], [108, "review"], [108, "provide"], [108, "a"], [108, "brief"], [108, "description"], [108, "of"], [108, "new"], [108, "publication"], [108, "focus"], [108, "on"], [108, "mania"], [108, "in"], [108, "old"], [108, "-"], [108, "age"], [108, "bipolar"], [108, "disorder"], [108, "("], [108, "oabd"], [108, ")"], [108, ","], [108, "include"], [108, "epidemiology"], [108, ","], [108, "diagnosis"], [108, ","], [108, "and"], [108, "treatment"], [108, "."], [109, "age"], [109, "cutoff"], [109, "to"], [109, "define"], [109, "oabd"], [109, "range"], [109, "from"], [109, "50"], [109, "to"], [109, "65"], [109, "\xA0"], [109, "year"], [109, "."], [110, "oabd"], [110, "clinical"], [110, "presentation"], [110, "and"], [110, "course"], [110, "of"], [110, "illness"], [110, "be"], [110, "highly"], [110, "variable"], [110, ","], [110, "often"], [110, "characterize"], [110, "by"], [110, "mood"], [110, "episode"], [110, "recurrence"], [110, ","], [110, "medical"], [110, "comorbidity"], [110, ","], [110, "cognitive"], [110, "deficit"], [110, ","], [110, "and"], [110, "impaired"], [110, "functioning"], [110, "."], [111, "there"], [111, "be"], [111, "little"], [111, "pharmacotherapy"], [111, "datum"], [111, "on"], [111, "mania"], [111, "in"], [111, "oabd"], [111, "."], [112, "lithium"], [112, "and"], [112, "valproate"], [112, "have"], [112, "be"], [112, "test"], [112, "in"], [112, "a"], [112, "single"], [112, "randomize"], [112, "control"], [112, "trial"], [112, "and"], [112, "there"], [112, "be"], [112, "datum"], [112, "of"], [112, "more"], [112, "limited"], [112, "quality"], [112, "with"], [112, "other"], [112, "compound"], [112, "."], [113, "treat"], [113, "oabd"], [113, "be"], [113, "challenge"], [113, "due"], [113, "to"], [113, "medical"], [113, "complexity"], [113, ","], [113, "comorbidity"], [113, ","], [113, "diminish"], [113, "tolerance"], [113, "to"], [113, "treatment"], [113, ","], [113, "and"], [113, "a"], [113, "limited"], [113, "evidence"], [113, "base"], [113, "."], [114, "more"], [114, "datum"], [114, "be"], [114, "nee"], [114, "to"], [114, "keep"], [114, "pace"], [114, "with"], [114, "clinical"], [114, "demand"], [114, "."], [115, "bipolar"], [115, "disorder"], [115, "("], [115, "manic"], [115, "-"], [115, "depressive"], [115, "illness"], [115, ")"], [115, "be"], [115, "a"], [115, "common"], [115, ","], [115, "recurrent"], [115, ","], [115, "and"], [115, "severe"], [115, "psychiatric"], [115, "disorder"], [115, "that"], [115, "affect"], [115, "1"], [115, "%"], [115, "to"], [115, "3"], [115, "%"], [115, "of"], [115, "the"], [115, "us"], [115, "population"], [115, "."], [116, "the"], [116, "illness"], [116, "be"], [116, "characterize"], [116, "by"], [116, "episode"], [116, "of"], [116, "mania"], [116, ","], [116, "depression"], [116, ","], [116, "or"], [116, "mixed"], [116, "state"], [116, "("], [116, "simultaneously"], [116, "occur"], [116, "manic"], [116, "and"], [116, "depressive"], [116, "symptom"], [116, ")"], [116, "."], [117, "bipolar"], [117, "disorder"], [117, "frequently"], [117, "go"], [117, "unrecognized"], [117, "and"], [117, "untreated"], [117, "for"], [117, "many"], [117, "year"], [117, "without"], [117, "clinical"], [117, "vigilance"], [117, "."], [118, "new"], [118, "screening"], [118, "tool"], [118, "have"], [118, "be"], [118, "develop"], [118, "to"], [118, "assist"], [118, "physician"], [118, "in"], [118, "make"], [118, "the"], [118, "diagnosis"], [118, "."], [119, "fortunately"], [119, ","], [119, "several"], [119, "medication"], [119, "be"], [119, "now"], [119, "available"], [119, "to"], [119, "treat"], [119, "the"], [119, "acute"], [119, "mood"], [119, "episode"], [119, "of"], [119, "bipolar"], [119, "disorder"], [119, "and"], [119, "to"], [119, "prevent"], [119, "further"], [119, "episode"], [119, "with"], [119, "maintenance"], [119, "treatment"], [119, "."], [120, "bipolar"], [120, "disorder"], [120, "be"], [120, "a"], [120, "chronic"], [120, ","], [120, "severe"], [120, ","], [120, "recurrent"], [120, "mood"], [120, "disorder"], [120, "."], [121, "traditional"], [121, "estimate"], [121, "of"], [121, "the"], [121, "prevalence"], [121, "of"], [121, "the"], [121, "disorder"], [121, "may"], [121, "underestimate"], [121, "the"], [121, "actual"], [121, "total"], [121, "disease"], [121, "burden"], [121, "."], [122, "the"], [122, "condition"], [122, "can"], [122, "occur"], [122, "across"], [122, "a"], [122, "wide"], [122, "spectrum"], [122, "of"], [122, "age"], [122, ","], [122, "but"], [122, "the"], [122, "most"], [122, "common"], [122, "age"], [122, "of"], [122, "onset"], [122, "appear"], [122, "to"], [122, "be"], [122, "between"], [122, "the"], [122, "age"], [122, "of"], [122, "15"], [122, "and"], [122, "19"], [122, "."], [123, "bipolar"], [123, "disorder"], [123, "be"], [123, "often"], [123, "underdiagnose"], [123, "or"], [123, "misdiagnose"], [123, ","], [123, "with"], [123, "profound"], [123, "negative"], [123, "clinical"], [123, "and"], [123, "economic"], [123, "consequence"], [123, "."], [124, "medical"], [124, "and"], [124, "psychiatric"], [124, "comorbidity"], [124, "be"], [124, "common"], [124, "in"], [124, "patient"], [124, "with"], [124, "bipolar"], [124, "disorder"], [124, "."], [125, "functional"], [125, "disability"], [125, "because"], [125, "of"], [125, "bipolar"], [125, "disorder"], [125, "be"], [125, "comparable"], [125, "with"], [125, "that"], [125, "of"], [125, "many"], [125, "chronic"], [125, "medical"], [125, "condition"], [125, "."], [126, "it"], [126, "have"], [126, "be"], [126, "estimate"], [126, "that"], [126, "the"], [126, "total"], [126, "annual"], [126, "societal"], [126, "cost"], [126, "of"], [126, "bipolar"], [126, "disorder"], [126, "may"], [126, "be"], [126, "as"], [126, "high"], [126, "as"], [126, "45"], [126, "billion"], [126, "dollar"], [126, "."], [127, "essential"], [127, "fact"], [127, "."], [128, "bipolar"], [128, "disorder"], [128, "be"], [128, "a"], [128, "potentially"], [128, "lifelong"], [128, "and"], [128, "disabling"], [128, "condition"], [128, "."], [129, "bipolar"], [129, "i"], [129, ","], [129, "characterise"], [129, "by"], [129, "episode"], [129, "of"], [129, "mania"], [129, "and"], [129, "depression"], [129, ","], [129, "be"], [129, "estimate"], [129, "to"], [129, "affect"], [129, "1"], [129, "per"], [129, "cent"], [129, "of"], [129, "the"], [129, "adult"], [129, "population"], [129, "."], [130, "bipolar"], [130, "ii"], [130, ","], [130, "characterise"], [130, "by"], [130, "hypomania"], [130, "and"], [130, "depression"], [130, ","], [130, "affect"], [130, "an"], [130, "estimate"], [130, "0.4"], [130, "per"], [130, "cent"], [130, "of"], [130, "adult"], [130, "."], [131, "episode"], [131, "can"], [131, "vary"], [131, "in"], [131, "length"], [131, "and"], [131, "frequency"], [131, "."], [132, "bipolar"], [132, "affective"], [132, "disorder"], [132, "run"], [132, "a"], [132, "natural"], [132, "course"], [132, "of"], [132, "frequent"], [132, "relapse"], [132, "and"], [132, "recurrence"], [132, "."], [133, "despite"], [133, "significant"], [133, "stride"], [133, "in"], [133, "the"], [133, "pharmacological"], [133, "treatment"], [133, "of"], [133, "bipolar"], [133, "disorder"], [133, ","], [133, "most"], [133, "bipolar"], [133, "patient"], [133, "can"], [133, "not"], [133, "be"], [133, "treat"], [133, "only"], [133, "by"], [133, "drug"], [133, "."], [134, "the"], [134, "limitation"], [134, "of"], [134, "use"], [134, "medication"], [134, "alone"], [134, "in"], [134, "symptomatic"], [134, ","], [134, "relapse"], [134, "prevention"], [134, ","], [134, "and"], [134, "satisfaction"], [134, "/"], [134, "quality"], [134, "of"], [134, "life"], [134, "term"], [134, "have"], [134, "long"], [134, "prompt"], [134, "interest"], [134, "in"], [134, "wide"], [134, "form"], [134, "of"], [134, "management"], [134, "."], [135, "one"], [135, "of"], [135, "the"], [135, "promising"], [135, "way"], [135, "how"], [135, "to"], [135, "enhance"], [135, "remission"], [135, "seem"], [135, "to"], [135, "be"], [135, "combination"], [135, "of"], [135, "pharmacotherapy"], [135, "and"], [135, "psychoeducation"], [135, "."], [136, "study"], [136, "be"], [136, "identify"], [136, "through"], [136, "pubmed"], [136, ","], [136, "web"], [136, "of"], [136, "science"], [136, "and"], [136, "scopus"], [136, "database"], [136, "as"], [136, "well"], [136, "as"], [136, "exist"], [136, "review"], [136, "."], [137, "the"], [137, "search"], [137, "term"], [137, "include"], [137, '"'], [137, "bipolar"], [137, "disorder"], [137, '"'], [137, ","], [137, '"'], [137, "psychoeducation"], [137, '"'], [137, ","], [137, '"'], [137, "psychotherapy"], [137, '"'], [137, ","], [137, '"'], [137, "psychosocial"], [137, "treatment"], [137, '"'], [137, ","], [137, '"'], [137, "family"], [137, "therapy"], [137, '"'], [137, ","], [137, '"'], [137, "individual"], [137, "therapy"], [137, '"'], [137, ","], [137, '"'], [137, "group"], [137, "therapy"], [137, '"'], [137, ","], [137, "and"], [137, '"'], [137, "psychoeducation"], [137, '"'], [137, "."], [138, "the"], [138, "search"], [138, "be"], [138, "perform"], [138, "by"], [138, "repeat"], [138, "use"], [138, "of"], [138, "the"], [138, "word"], [138, "in"], [138, "different"], [138, "combination"], [138, "with"], [138, "no"], [138, "language"], [138, "or"], [138, "time"], [138, "limitation"], [138, "."], [139, "this"], [139, "article"], [139, "be"], [139, "a"], [139, "review"], [139, "with"], [139, "conclusion"], [139, "concern"], [139, "with"], [139, "psychoeducation"], [139, "in"], [139, "bipolar"], [139, "disorder"], [139, "."], [140, "randomize"], [140, "control"], [140, "trial"], [140, "of"], [140, "cognitive"], [140, "behavioral"], [140, "therapy"], [140, ","], [140, "interpersonal"], [140, "and"], [140, "social"], [140, "rhythm"], [140, "therapy"], [140, ","], [140, "individual"], [140, ","], [140, "group"], [140, "and"], [140, "family"], [140, "psychoeducation"], [140, "show"], [140, "that"], [140, "these"], [140, "approach"], [140, "augment"], [140, "stabilize"], [140, "effect"], [140, "of"], [140, "pharmacotherapy"], [140, "."], [141, "patient"], [141, "and"], [141, "their"], [141, "family"], [141, "should"], [141, "be"], [141, "educate"], [141, "about"], [141, "bipolar"], [141, "disorder"], [141, ","], [141, "trigger"], [141, ","], [141, "warning"], [141, "sign"], [141, ","], [141, "mood"], [141, "relapse"], [141, ","], [141, "suicidal"], [141, "ideation"], [141, ","], [141, "and"], [141, "the"], [141, "effectiveness"], [141, "of"], [141, "early"], [141, "intervention"], [141, "to"], [141, "reduce"], [141, "complication"], [141, "."], [142, "psychosocial"], [142, "approach"], [142, "be"], [142, "important"], [142, "therapeutic"], [142, "strategy"], [142, "for"], [142, "reduce"], [142, "relapse"], [142, "and"], [142, "rehospitalization"], [142, "in"], [142, "bipolar"], [142, "disorder"], [142, "."], [143, "primary"], [143, "mania"], [143, "and"], [143, "hypomania"], [143, "in"], [143, "full"], [143, "or"], [143, "subsyndromal"], [143, "form"], [143, "be"], [143, "the"], [143, "define"], [143, "feature"], [143, "of"], [143, "bipolar"], [143, "disorder"], [143, "and"], [143, "be"], [143, "common"], [143, "in"], [143, "neurologic"], [143, "patient"], [143, ","], [143, "as"], [143, "be"], [143, "manic"], [143, "syndrome"], [143, "precipitate"], [143, "by"], [143, "medication"], [143, "use"], [143, "to"], [143, "treat"], [143, "neurologic"], [143, "disorder"], [143, "."], [144, "this"], [144, "article"], [144, "address"], [144, "the"], [144, "diagnosis"], [144, ","], [144, "pathophysiology"], [144, ","], [144, "treatment"], [144, ","], [144, "and"], [144, "course"], [144, "of"], [144, "bipolar"], [144, "disorder"], [144, "after"], [144, "a"], [144, "manic"], [144, "episode"], [144, "as"], [144, "well"], [144, "as"], [144, "mania"], [144, "as"], [144, "a"], [144, "manifestation"], [144, "of"], [144, "neurologic"], [144, "disease"], [144, "."], [145, "mania"], [145, "can"], [145, "be"], [145, "a"], [145, "primary"], [145, "psychiatric"], [145, "disorder"], [145, "but"], [145, "can"], [145, "also"], [145, "be"], [145, "a"], [145, "symptom"], [145, "of"], [145, "a"], [145, "neurologic"], [145, "disorder"], [145, ","], [145, "especially"], [145, "right"], [145, "-"], [145, "sided"], [145, "cerebrovascular"], [145, "disease"], [145, "."], [146, "treatment"], [146, "("], [146, "such"], [146, "as"], [146, "corticosteroid"], [146, "and"], [146, "dopaminergic"], [146, "agent"], [146, ")"], [146, "for"], [146, "neurologic"], [146, "illness"], [146, "regularly"], [146, "induce"], [146, "mania"], [146, "."], [147, "the"], [147, "neurobiology"], [147, "of"], [147, "primary"], [147, "mania"], [147, "and"], [147, "bipolar"], [147, "disorder"], [147, "involve"], [147, "alteration"], [147, "in"], [147, "intracellular"], [147, "signaling"], [147, ","], [147, "change"], [147, "in"], [147, "gene"], [147, "expression"], [147, ","], [147, "neural"], [147, "network"], [147, "interaction"], [147, ","], [147, "and"], [147, "apoptosis"], [147, "."], [148, "except"], [148, "when"], [148, "induce"], [148, "by"], [148, "time"], [148, "-"], [148, "limit"], [148, "treatment"], [148, "with"], [148, "a"], [148, "provoke"], [148, "agent"], [148, ","], [148, "mania"], [148, "tend"], [148, "to"], [148, "be"], [148, "highly"], [148, "recurrent"], [148, "and"], [148, "to"], [148, "alternate"], [148, "or"], [148, "be"], [148, "exhibit"], [148, "alongside"], [148, "depression"], [148, "."], [149, "symptom"], [149, "of"], [149, "mania"], [149, "become"], [149, "more"], [149, "complex"], [149, "and"], [149, "treatment"], [149, "refractory"], [149, "with"], [149, "time"], [149, ","], [149, "although"], [149, "effective"], [149, "treatment"], [149, "improve"], [149, "the"], [149, "long"], [149, "-"], [149, "term"], [149, "outcome"], [149, "."], [150, "behavioral"], [150, "manifestation"], [150, "of"], [150, "mania"], [150, "may"], [150, "be"], [150, "more"], [150, "obvious"], [150, "than"], [150, "affective"], [150, "symptom"], [150, ","], [150, "especially"], [150, "in"], [150, "patient"], [150, "with"], [150, "aprosodia"], [150, "."], [151, "atypical"], [151, "antipsychotic"], [151, "drug"], [151, "be"], [151, "often"], [151, "first"], [151, "-"], [151, "line"], [151, "acute"], [151, "treatment"], [151, ","], [151, "but"], [151, "the"], [151, "evidence"], [151, "support"], [151, "their"], [151, "long"], [151, "-"], [151, "term"], [151, "prophylactic"], [151, "efficacy"], [151, "be"], [151, "questionable"], [151, "."], [152, "in"], [152, "addition"], [152, "to"], [152, "be"], [152, "an"], [152, "establish"], [152, "mood"], [152, "stabilizer"], [152, ","], [152, "lithium"], [152, "have"], [152, "putative"], [152, "neuroprotective"], [152, "property"], [152, ","], [152, "although"], [152, "a"], [152, "side"], [152, "effect"], [152, "can"], [152, "be"], [152, "impaired"], [152, "memory"], [152, "."], [153, "to"], [153, "identify"], [153, "clinical"], [153, "characteristic"], [153, "and"], [153, "adverse"], [153, "outcome"], [153, "associate"], [153, "with"], [153, "an"], [153, "early"], [153, "age"], [153, "of"], [153, "onset"], [153, "of"], [153, "bipolar"], [153, "disorder"], [153, "."], [154, "a"], [154, "comprehensive"], [154, "search"], [154, "yield"], [154, "15"], [154, "empirical"], [154, "paper"], [154, "compare"], [154, "clinical"], [154, "presentation"], [154, "and"], [154, "outcome"], [154, "in"], [154, "individual"], [154, "with"], [154, "bipolar"], [154, "disorder"], [154, "group"], [154, "accord"], [154, "to"], [154, "age"], [154, "of"], [154, "onset"], [154, "("], [154, "total"], [154, "n=7370"], [154, ")"], [154, "."], [155, "the"], [155, "follow"], [155, "variable"], [155, "be"], [155, "examine"], [155, "to"], [155, "determine"], [155, "odd"], [155, "ratio"], [155, "("], [155, "or"], [155, ")"], [155, "and"], [155, "95"], [155, "%"], [155, "confidence"], [155, "interval"], [155, "("], [155, "ci"], [155, "):"], [155, "presence"], [155, "of"], [155, "axis"], [155, "i"], [155, "comorbidity"], [155, ","], [155, "rapid"], [155, "cycling"], [155, ","], [155, "psychotic"], [155, "symptom"], [155, ","], [155, "mixed"], [155, "episode"], [155, "("], [155, "dsm"], [155, "-"], [155, "iv"], [155, ")"], [155, ","], [155, "lifetime"], [155, "suicide"], [155, "attempt"], [155, ","], [155, "lifetime"], [155, "alcohol"], [155, "and"], [155, "substance"], [155, "abuse"], [155, ","], [155, "symptom"], [155, "severity"], [155, ","], [155, "and"], [155, "treatment"], [155, "delay"], [155, "."], [156, "early"], [156, "age"], [156, "of"], [156, "onset"], [156, "be"], [156, "find"], [156, "to"], [156, "be"], [156, "associate"], [156, "with"], [156, "long"], [156, "delay"], [156, "to"], [156, "treatment"], [156, "("], [156, "hedge"], [156, "'"], [156, "g=0.39"], [156, ","], [156, "p=.001"], [156, ")"], [156, ","], [156, "great"], [156, "severity"], [156, "of"], [156, "depression"], [156, "("], [156, "hedge"], [156, "'"], [156, "g=0.42"], [156, ","], [156, "p<.001"], [156, ")"], [156, ","], [156, "and"], [156, "high"], [156, "level"], [156, "of"], [156, "comorbid"], [156, "anxiety"], [156, "("], [156, "or=2.34"], [156, ","], [156, "p<.001"], [156, ")"], [156, "and"], [156, "substance"], [156, "use"], [156, "("], [156, "or=1.80"], [156, ","], [156, "p<.001"], [156, ")"], [156, "."], [157, "surprisingly"], [157, ","], [157, "no"], [157, "association"], [157, "be"], [157, "find"], [157, "between"], [157, "early"], [157, "age"], [157, "of"], [157, "onset"], [157, "and"], [157, "clinical"], [157, "characteristic"], [157, "such"], [157, "as"], [157, "psychotic"], [157, "symptom"], [157, "or"], [157, "mixed"], [157, "episode"], [157, "as"], [157, "define"], [157, "by"], [157, "dsm"], [157, "-"], [157, "iv"], [157, "."], [158, "early"], [158, "age"], [158, "of"], [158, "onset"], [158, "of"], [158, "bipolar"], [158, "disorder"], [158, "be"], [158, "associate"], [158, "with"], [158, "factor"], [158, "that"], [158, "can"], [158, "negatively"], [158, "impact"], [158, "long"], [158, "-"], [158, "term"], [158, "outcome"], [158, "such"], [158, "as"], [158, "increase"], [158, "comorbidity"], [158, "."], [159, "however"], [159, ","], [159, "no"], [159, "association"], [159, "be"], [159, "find"], [159, "between"], [159, "early"], [159, "onset"], [159, "and"], [159, "indicator"], [159, "of"], [159, "severity"], [159, "or"], [159, "treatment"], [159, "resistance"], [159, "such"], [159, "as"], [159, "psychotic"], [159, "symptom"], [159, "."], [160, "clinical"], [160, "feature"], [160, "find"], [160, "to"], [160, "have"], [160, "the"], [160, "strong"], [160, "relationship"], [160, "with"], [160, "early"], [160, "age"], [160, "of"], [160, "onset"], [160, "be"], [160, "those"], [160, "potentially"], [160, "amenable"], [160, "to"], [160, "pharmacological"], [160, "and"], [160, "psychological"], [160, "treatment"], [160, "."], [161, "result"], [161, "highlight"], [161, "the"], [161, "importance"], [161, "of"], [161, "early"], [161, "identification"], [161, "and"], [161, "provide"], [161, "potential"], [161, "area"], [161, "of"], [161, "focus"], [161, "for"], [161, "the"], [161, "development"], [161, "of"], [161, "early"], [161, "intervention"], [161, "in"], [161, "bipolar"], [161, "disorder"], [161, "."], [162, "high"], [162, "rate"], [162, "of"], [162, "misdiagnosis"], [162, ","], [162, "delay"], [162, "diagnosis"], [162, ","], [162, "and"], [162, "lack"], [162, "of"], [162, "recognition"], [162, "and"], [162, "treatment"], [162, "of"], [162, "comorbid"], [162, "condition"], [162, "often"], [162, "lead"], [162, "patient"], [162, "with"], [162, "bipolar"], [162, "illness"], [162, "to"], [162, "have"], [162, "a"], [162, "chronic"], [162, "course"], [162, "with"], [162, "high"], [162, "disability"], [162, ","], [162, "unemployment"], [162, "rate"], [162, ","], [162, "and"], [162, "mortality"], [162, "."], [163, "despite"], [163, "the"], [163, "recognition"], [163, "that"], [163, "long"], [163, "-"], [163, "term"], [163, "outcome"], [163, "of"], [163, "bipolar"], [163, "disorder"], [163, "depend"], [163, "on"], [163, "systematic"], [163, "assessment"], [163, "of"], [163, "both"], [163, "interepisodic"], [163, "dysfunctional"], [163, "domain"], [163, "and"], [163, "comorbid"], [163, "psychiatric"], [163, "and"], [163, "medical"], [163, "condition"], [163, ","], [163, "treatment"], [163, "of"], [163, "bipolar"], [163, "disorder"], [163, "still"], [163, "focus"], [163, "primarily"], [163, "on"], [163, "alleviation"], [163, "of"], [163, "acute"], [163, "symptom"], [163, "and"], [163, "prevention"], [163, "of"], [163, "future"], [163, "recurrence"], [163, "."], [164, "we"], [164, "propose"], [164, "here"], [164, "to"], [164, "review"], [164, "the"], [164, "evidence"], [164, "offer"], [164, "a"], [164, "modern"], [164, "view"], [164, "of"], [164, "bipolar"], [164, "disorder"], [164, "define"], [164, "as"], [164, "a"], [164, "chronic"], [164, "and"], [164, "progressive"], [164, "multisystem"], [164, "disorder"], [164, ","], [164, "take"], [164, "into"], [164, "account"], [164, "characteristic"], [164, "of"], [164, "each"], [164, "patient"], [164, "as"], [164, "well"], [164, "as"], [164, "biosignature"], [164, "in"], [164, "order"], [164, "to"], [164, "help"], [164, "design"], [164, "personalize"], [164, "treatment"], [164, "."], [165, "we"], [165, "conduct"], [165, "a"], [165, "systematic"], [165, "pubmed"], [165, "search"], [165, "of"], [165, "all"], [165, "english"], [165, "-"], [165, "language"], [165, "article"], [165, ","], [165, "publish"], [165, "between"], [165, "2000"], [165, "and"], [165, "2010"], [165, ","], [165, "focus"], [165, "on"], [165, "the"], [165, "english"], [165, "and"], [165, "french"], [165, "literature"], [165, "with"], [165, "bipolar"], [165, "disorder"], [165, "cross"], [165, "-"], [165, "reference"], [165, "with"], [165, "the"], [165, "follow"], [165, "search"], [165, "term"], [165, ":"], [165, "emotional"], [165, "dysregulation"], [165, ","], [165, "sleep"], [165, "and"], [165, "circadian"], [165, "rhythm"], [165, "disturbance"], [165, ","], [165, "cognitive"], [165, "impairment"], [165, ","], [165, "age"], [165, "at"], [165, "onset"], [165, ","], [165, "comorbid"], [165, "medical"], [165, "and"], [165, "psychiatric"], [165, "condition"], [165, ","], [165, "psychosocial"], [165, "and"], [165, "medical"], [165, "intervention"], [165, ","], [165, "outcome"], [165, ","], [165, "remission"], [165, ","], [165, "and"], [165, "personalize"], [165, "medicine"], [165, "."], [166, "the"], [166, "search"], [166, "be"], [166, "conduct"], [166, "between"], [166, "july"], [166, "2009"], [166, "and"], [166, "july"], [166, "2010"], [166, "."], [167, "the"], [167, "literature"], [167, "on"], [167, "bipolar"], [167, "disorder"], [167, "be"], [167, "review"], [167, "to"], [167, "provide"], [167, "support"], [167, "evidence"], [167, "that"], [167, "the"], [167, "assessment"], [167, "of"], [167, "various"], [167, "symptom"], [167, "domain"], [167, "that"], [167, "be"], [167, "dysfunctional"], [167, "between"], [167, "episode"], [167, "should"], [167, "all"], [167, "be"], [167, "consider"], [167, "as"], [167, "core"], [167, "dimension"], [167, "of"], [167, "the"], [167, "disorder"], [167, "."], [168, "forty"], [168, "-"], [168, "one"], [168, "article"], [168, "be"], [168, "identify"], [168, "through"], [168, "the"], [168, "pubmed"], [168, "search"], [168, "describe"], [168, "above"], [168, "and"], [168, "select"], [168, "on"], [168, "the"], [168, "basis"], [168, "of"], [168, "address"], [168, "any"], [168, "combination"], [168, "of"], [168, "the"], [168, "search"], [168, "term"], [168, "in"], [168, "conjunction"], [168, "with"], [168, "bipolar"], [168, "disorder"], [168, "."], [169, "current"], [169, "guideline"], [169, "advocate"], [169, "the"], [169, "use"], [169, "of"], [169, "more"], [169, "or"], [169, "less"], [169, "similar"], [169, "treatment"], [169, "algorithm"], [169, "for"], [169, "all"], [169, "patient"], [169, ","], [169, "ignore"], [169, "the"], [169, "clinical"], [169, ","], [169, "pathophysiological"], [169, ","], [169, "and"], [169, "lifetime"], [169, "heterogeneity"], [169, "of"], [169, "bipolar"], [169, "disorder"], [169, "."], [170, "systematic"], [170, "assessment"], [170, "of"], [170, "interepisodic"], [170, "dimension"], [170, ","], [170, "along"], [170, "with"], [170, "comorbid"], [170, "medical"], [170, "and"], [170, "psychiatric"], [170, "risk"], [170, "factor"], [170, ","], [170, "should"], [170, "be"], [170, "perform"], [170, "along"], [170, "the"], [170, "life"], [170, "cycle"], [170, "in"], [170, "order"], [170, "to"], [170, "plan"], [170, "specific"], [170, "and"], [170, "personalize"], [171, "pharmacologic"], [171, ","], [171, "medical"], [171, ","], [171, "and"], [171, "psychosocial"], [171, "intervention"], [171, "tailor"], [171, "to"], [171, "the"], [171, "need"], [171, "of"], [171, "each"], [171, "patient"], [171, "and"], [171, "ready"], [171, "-"], [171, "to"], [171, "-"], [171, "test"], [171, "biosignature"], [171, "to"], [171, "serve"], [171, "as"], [171, "risk"], [171, "factor"], [171, "or"], [171, "diagnostic"], [171, "or"], [171, "prognostic"], [171, "tool"], [171, "."], [172, "medical"], [172, "and"], [172, "research"], [172, "finding"], [172, ","], [172, "along"], [172, "with"], [172, "health"], [172, "economic"], [172, "datum"], [172, ","], [172, "support"], [172, "a"], [172, "more"], [172, "modern"], [172, "view"], [172, "of"], [172, "bipolar"], [172, "disorder"], [172, "as"], [172, "a"], [172, "chronic"], [172, ","], [172, "progressive"], [172, ","], [172, "multisystem"], [172, "disorder"], [172, "."], [173, "this"], [173, "new"], [173, "comprehensive"], [173, "framework"], [173, "should"], [173, "guide"], [173, "the"], [173, "search"], [173, "to"], [173, "identify"], [173, "biomarker"], [173, "and"], [173, "etiologic"], [173, "factor"], [173, "and"], [173, "should"], [173, "help"], [173, "design"], [173, "a"], [173, "new"], [173, "policy"], [173, "for"], [173, "health"], [173, "care"], [173, ","], [173, "include"], [173, "prevention"], [173, ","], [173, "diagnosis"], [173, ","], [173, "treatment"], [173, ","], [173, "and"], [173, "training"], [173, "."], [174, "childhood"], [174, "bipolar"], [174, "disorder"], [174, "remain"], [174, "a"], [174, "controversial"], [174, "but"], [174, "increasingly"], [174, "diagnose"], [174, "disorder"], [174, "that"], [174, "be"], [174, "associate"], [174, "with"], [174, "significant"], [174, "impairment"], [174, ","], [174, "chronic"], [174, "course"], [174, "and"], [174, "treatment"], [174, "resistance"], [174, "."], [175, "therefore"], [175, ","], [175, "the"], [175, "search"], [175, "for"], [175, "prodrome"], [175, "or"], [175, "early"], [175, "marker"], [175, "of"], [175, "risk"], [175, "for"], [175, "later"], [175, "childhood"], [175, "bipolar"], [175, "disorder"], [175, "may"], [175, "be"], [175, "of"], [175, "great"], [175, "importance"], [175, "for"], [175, "prevention"], [175, "and/or"], [175, "early"], [175, "identification"], [175, "."], [176, "literature"], [176, "search"], [176, "be"], [176, "conduct"], [176, "to"], [176, "identify"], [176, "review"], [176, ","], [176, "case"], [176, "report"], [176, "and"], [176, "empirical"], [176, "paper"], [176, "address"], [176, "the"], [176, "issue"], [176, "of"], [176, "prodrome"], [176, "of"], [176, "childhood"], [176, "bipolar"], [176, "disorder"], [176, "."], [177, "a"], [177, "total"], [177, "of"], [177, "54"], [177, "article"], [177, "be"], [177, "find"], [177, "that"], [177, "relate"], [177, "to"], [177, "bipolar"], [177, "prodrome"], [177, ","], [177, "risk"], [177, "factor"], [177, "for"], [177, "later"], [177, "childhood"], [177, "bipolar"], [177, "disorder"], [177, ","], [177, "childhood"], [177, "risk"], [177, "for"], [177, "adult"], [177, "bipolar"], [177, "disorder"], [177, ","], [177, "mania"], [177, "manifestation"], [177, "in"], [177, "early"], [177, "childhood"], [177, ","], [177, "and"], [177, "neuropsychological"], [177, "and"], [177, "biological"], [177, "marker"], [177, "of"], [177, "childhood"], [177, "bipolar"], [177, "disorder"], [177, "."], [178, "a"], [178, "review"], [178, "of"], [178, "article"], [178, "suggest"], [178, "("], [178, "a"], [178, ")"], [178, "childhood"], [178, "bipolar"], [178, "prodrome"], [178, "may"], [178, "be"], [178, "detectable"], [178, "prior"], [178, "to"], [178, "the"], [178, "onset"], [178, "of"], [178, "the"], [178, "disorder"], [178, ","], [178, "("], [178, "b"], [178, ")"], [178, "prodromal"], [178, "symptom"], [178, "may"], [178, "display"], [178, "episodicity"], [178, "during"], [178, "childhood"], [178, ","], [178, "("], [178, "c"], [178, ")"], [178, "there"], [178, "be"], [178, "evidence"], [178, "of"], [178, "possible"], [178, "endophenotypic"], [178, "marker"], [178, "such"], [178, "as"], [178, "deficit"], [178, "in"], [178, "executive"], [178, "function"], [178, ","], [178, "sustain"], [178, "attention"], [178, ","], [178, "and"], [178, "emotion"], [178, "labeling"], [178, ","], [178, "("], [178, "d"], [178, ")"], [178, "there"], [178, "be"], [178, "a"], [178, "potential"], [178, "association"], [178, "with"], [178, "functional"], [178, ","], [178, "structural"], [178, ","], [178, "and"], [178, "biochemical"], [178, "alteration"], [178, "evident"], [178, "in"], [178, "brain"], [178, "structure"], [178, "involve"], [178, "in"], [178, "mood"], [178, "regulation"], [178, ","], [178, "("], [178, "e"], [178, ")"], [178, "a"], [178, "link"], [178, "between"], [178, "childhood"], [178, "bipolar"], [178, "disorder"], [178, "with"], [178, "early"], [178, "tempermental"], [178, "marker"], [178, ","], [178, "such"], [178, "as"], [178, "emotional"], [178, "regulation"], [178, "and"], [178, "behavioral"], [178, "disinhibition"], [178, "and"], [178, "("], [178, "f"], [178, ")"], [178, "there"], [178, "be"], [178, "some"], [178, "early"], [178, "but"], [178, "promise"], [178, "evidence"], [178, "of"], [178, "effective"], [178, "psychotherapeutic"], [178, "prevention"], [178, "."], [179, "there"], [179, "have"], [179, "be"], [179, "very"], [179, "limited"], [179, "investigation"], [179, "of"], [179, "early"], [179, "prodrome"], [179, "of"], [179, "childhood"], [179, "bipolar"], [179, "disorder"], [179, "."], [180, "base"], [180, "on"], [180, "the"], [180, "promise"], [180, "finding"], [180, "of"], [180, "prodrome"], [180, "as"], [180, "well"], [180, "as"], [180, "high"], [180, "-"], [180, "risk"], [180, "state"], [180, "and"], [180, "possible"], [180, "endophenotypic"], [180, "marker"], [180, ","], [180, "more"], [180, "control"], [180, "and"], [180, "target"], [180, "investigation"], [180, "into"], [180, "the"], [180, "early"], [180, "marker"], [180, "of"], [180, "bipolar"], [180, "disorder"], [180, "appear"], [180, "warrant"], [180, "and"], [180, "potentially"], [180, "fruitful"], [180, "."], [181, "until"], [181, "such"], [181, "longitudinal"], [181, "study"], [181, "with"], [181, "appropriate"], [181, "control"], [181, "be"], [181, "conduct"], [181, ","], [181, "specific"], [181, "marker"], [181, "for"], [181, "bipolar"], [181, "prodrome"], [181, "will"], [181, "remain"], [181, "elusive"], [181, ","], [181, "although"], [181, "evidence"], [181, "suggest"], [181, "they"], [181, "be"], [181, "manifest"], [181, "in"], [181, "at"], [181, "least"], [181, "some"], [181, "subgroup"], [181, "."], [182, "the"], [182, "finding"], [182, "of"], [182, "promise"], [182, "psychotherapeutic"], [182, "prevention"], [182, "program"], [182, "underscore"], [182, "the"], [182, "need"], [182, "to"], [182, "find"], [182, "specific"], [182, "and"], [182, "sensitive"], [182, "marker"], [182, "of"], [182, "bipolar"], [182, "prodrome"], [182, "in"], [182, "childhood"], [182, "."], [183, "this"], [183, "article"], [183, "present"], [183, "an"], [183, "overview"], [183, "of"], [183, "bipolar"], [183, "disorder"], [183, "("], [183, "bpd"], [183, ")"], [183, "in"], [183, "child"], [183, ","], [183, "a"], [183, "condition"], [183, "that"], [183, "only"], [183, "recently"], [183, "have"], [183, "be"], [183, "recognize"], [183, "as"], [183, "a"], [183, "legitimate"], [183, "diagnosis"], [183, "."], [184, "bipolar"], [184, "disorder"], [184, "in"], [184, "child"], [184, "be"], [184, "underrecognized"], [184, "for"], [184, "many"], [184, "reason"], [184, "include"], [184, "lack"], [184, "of"], [184, "awareness"], [184, ","], [184, "diagnostic"], [184, "confusion"], [184, ","], [184, "and"], [184, "the"], [184, "different"], [184, "clinical"], [184, "picture"], [184, "in"], [184, "child"], [184, "."], [185, "available"], [185, "datum"], [185, "strongly"], [185, "suggest"], [185, "that"], [185, "prepubertal"], [185, "childhood"], [185, "bpd"], [185, "be"], [185, "a"], [185, "non"], [185, "-"], [185, "episodic"], [185, ","], [185, "chronic"], [185, ","], [185, "rapid"], [185, "cycling"], [185, ","], [185, "mixed"], [185, "manic"], [185, "state"], [185, "."], [186, "it"], [186, "may"], [186, "be"], [186, "comorbid"], [186, "with"], [186, "attention"], [186, "-"], [186, "deficit"], [186, "/"], [186, "hyperactivity"], [186, "disorder"], [186, "("], [186, "adhd"], [186, ")"], [186, "and"], [186, "conduct"], [186, "disorder"], [186, "("], [186, "cd"], [186, ")"], [186, "or"], [186, "it"], [186, "may"], [186, "demonstrate"], [186, "feature"], [186, "of"], [186, "adhd"], [186, "and"], [186, "cd"], [186, ","], [186, "far"], [186, "complicate"], [186, "recognition"], [186, "and"], [186, "subsequent"], [186, "treatment"], [186, "."], [187, "treatment"], [187, "issue"], [187, "be"], [187, "discuss"], [187, ","], [187, "and"], [187, "some"], [187, "reason"], [187, "for"], [187, "the"], [187, "urgency"], [187, "of"], [187, "early"], [187, "recognition"], [187, "and"], [187, "treatment"], [187, "be"], [187, "explain"], [187, "."], [188, "to"], [188, "synthesize"], [188, "the"], [188, "literature"], [188, "and"], [188, "develop"], [188, "guidance"], [188, "on"], [188, "support"], [188, "need"], [188, "for"], [188, "primary"], [188, "care"], [188, "and"], [188, "perinatal"], [188, "provider"], [188, "in"], [188, "screening"], [188, ","], [188, "initial"], [188, "management"], [188, ","], [188, "triage"], [188, ","], [188, "and"], [188, "bridge"], [188, "treatment"], [188, "for"], [188, "perinatal"], [188, "bipolar"], [188, "disorder"], [188, "."], [189, "we"], [189, "conduct"], [189, "a"], [189, "scoping"], [189, "review"], [189, "by"], [189, "search"], [189, "six"], [189, "electronic"], [189, "database"], [189, "use"], [189, "keyword"], [189, "relate"], [189, "to"], [189, "perinatal"], [189, "bipolar"], [189, "disorder"], [189, "."], [190, "we"], [190, "summarize"], [190, "descriptive"], [190, "statistic"], [190, "on"], [190, "set"], [190, "and"], [190, "extract"], [190, "information"], [190, "on"], [190, "care"], [190, "approach"], [190, "."], [191, "we"], [191, "synthesize"], [191, "the"], [191, "literature"], [191, "on"], [191, "indirect"], [191, "care"], [191, "model"], [191, "and"], [191, "extract"], [191, "datum"], [191, "on"], [191, "screening"], [191, ","], [191, "follow"], [191, "-"], [191, "up"], [191, ","], [191, "referral"], [191, ","], [191, "and"], [191, "management"], [191, "."], [192, "1169"], [192, "article"], [192, "be"], [192, "retrieve"], [192, "."], [193, "51"], [193, "article"], [193, "be"], [193, "include"], [193, "after"], [193, "review"], [193, "."], [194, "most"], [194, "paper"], [194, "be"], [194, "review"], [194, "."], [195, "few"], [195, "address"], [195, "care"], [195, "in"], [195, "obstetric"], [195, "("], [195, "n"], [195, "\xA0"], [195, "="], [195, "\xA0"], [195, "20"], [195, ","], [195, "39"], [195, "%"], [195, ")"], [195, ","], [195, "primary"], [195, "care"], [195, "("], [195, "n"], [195, "\xA0"], [195, "="], [195, "\xA0"], [195, "10"], [195, ","], [195, "20"], [195, "%"], [195, ")"], [195, ","], [195, "and"], [195, "pediatric"], [195, "setting"], [195, "("], [195, "n"], [195, "\xA0"], [195, "="], [195, "\xA0"], [195, "2"], [195, ","], [195, "4"], [195, "%"], [195, ")"], [195, "."], [196, "most"], [196, "paper"], [196, "("], [196, "n"], [196, "\xA0"], [196, "="], [196, "\xA0"], [196, "30"], [196, ","], [196, "59"], [196, "%"], [196, ")"], [196, "discuss"], [196, "use"], [196, "screen"], [196, "instrument"], [196, "for"], [196, "bipolar"], [196, "disorder"], [196, "."], [197, "article"], [197, "be"], [197, "mix"], [197, "on"], [197, "recommendation"], [197, "for"], [197, "bipolar"], [197, "disorder"], [197, "screening"], [197, "."], [198, "varied"], [198, "strategy"], [198, "for"], [198, "structured"], [198, "assessment"], [198, "exist"], [198, "and"], [198, "be"], [198, "influence"], [198, "by"], [198, "practice"], [198, "setting"], [198, "."], [199, "there"], [199, "remain"], [199, "uncertainty"], [199, "about"], [199, "optimal"], [199, "strategy"], [199, "for"], [199, "screening"], [199, "and"], [199, "management"], [199, "of"], [199, "perinatal"], [199, "bipolar"], [199, "disorder"], [199, "."], [200, "we"], [200, "recommend"], [200, "screen"], [200, "for"], [200, "bipolar"], [200, "disorder"], [200, "in"], [200, "the"], [200, "perinatal"], [200, "period"], [200, "in"], [200, "select"], [200, "circumstance"], [200, "("], [200, "with"], [200, "depression"], [200, "screening"], [200, ","], [200, "know"], [200, "bipolar"], [200, "disorder"], [200, "risk"], [200, "factor"], [200, ","], [200, "and"], [200, "prior"], [200, "to"], [200, "start"], [200, "antidepressant"], [200, ")"], [200, "."], [201, "if"], [201, "specialty"], [201, "mental"], [201, "health"], [201, "care"], [201, "be"], [201, "unavailable"], [201, ","], [201, "we"], [201, "recommend"], [201, "enhance"], [201, "usual"], [201, "care"], [201, "through"], [201, "integrated"], [201, "care"], [201, "strategy"], [201, "such"], [201, "as"], [201, "indirect"], [201, "consultation"], [201, "."], [202, "bipolar"], [202, "disorder"], [202, "be"], [202, "a"], [202, "multifactorial"], [202, "disease"], [202, "with"], [202, "a"], [202, "strong"], [202, "genetic"], [202, "component"], [202, "."], [203, "however"], [203, ","], [203, "environmental"], [203, "factor"], [203, "also"], [203, "play"], [203, "a"], [203, "role"], [203, "in"], [203, "the"], [203, "onset"], [203, "of"], [203, "the"], [203, "disease"], [203, "and"], [203, "in"], [203, "manic"], [203, "and"], [203, "depressive"], [203, "recurrence"], [203, "."], [204, "the"], [204, "onset"], [204, "of"], [204, "the"], [204, "disorder"], [204, "be"], [204, "the"], [204, "consequence"], [204, "of"], [204, "a"], [204, "complex"], [204, "interaction"], [204, "between"], [204, "genetic"], [204, "and"], [204, "environmental"], [204, "factor"], [204, "."], [205, "this"], [205, "gene"], [205, "-"], [205, "environment"], [205, "interaction"], [205, "be"], [205, "well"], [205, "illustrate"], [205, "by"], [205, "the"], [205, "influence"], [205, "of"], [205, "childhood"], [205, "trauma"], [205, "on"], [205, "the"], [205, "clinical"], [205, "expression"], [205, "of"], [205, "the"], [205, "disease"], [205, "in"], [205, "term"], [205, "of"], [205, "age"], [205, "of"], [205, "onset"], [205, ","], [205, "comorbidity"], [205, "and"], [205, "suicide"], [205, "."], [206, "the"], [206, "complexity"], [206, "and"], [206, "heterogeneity"], [206, "of"], [206, "bipolar"], [206, "disorder"], [206, "require"], [206, "the"], [206, "identification"], [206, "of"], [206, "homogenous"], [206, "sub"], [206, "-"], [206, "group"], [206, "with"], [206, "the"], [206, "use"], [206, "of"], [206, "biomarker"], [206, "that"], [206, "could"], [206, "help"], [206, "reduce"], [206, "the"], [206, "etiological"], [206, "heterogeneity"], [206, "and"], [206, "well"], [206, "target"], [206, "the"], [206, "therapeutical"], [206, "option"], [206, "."], [207, "bipolar"], [207, "disorder"], [207, "be"], [207, "a"], [207, "pathological"], [207, "disturbance"], [207, "of"], [207, "mood"], [207, ","], [207, "characterize"], [207, "by"], [207, "wax"], [207, "and"], [207, "wane"], [207, "manic"], [207, ","], [207, "depressive"], [207, "and"], [207, ","], [207, "sometimes"], [207, "distinctly"], [207, "mixed"], [207, "state"], [207, "."], [208, "a"], [208, "diagnosis"], [208, "of"], [208, "bipolar"], [208, "disorder"], [208, "can"], [208, "only"], [208, "be"], [208, "make"], [208, "with"], [208, "certainty"], [208, "when"], [208, "the"], [208, "manic"], [208, "syndrome"], [208, "declare"], [208, "itself"], [208, "."], [209, "most"], [209, "individual"], [209, "who"], [209, "be"], [209, "diagnose"], [209, "with"], [209, "this"], [209, "disorder"], [209, "will"], [209, "experience"], [209, "both"], [209, "pole"], [209, "of"], [209, "the"], [209, "illness"], [209, "recurrently"], [209, ","], [209, "but"], [209, "depressive"], [209, "episode"], [209, "be"], [209, "the"], [209, "common"], [209, "cause"], [209, "of"], [209, "morbidity"], [209, "and"], [209, ","], [209, "indeed"], [209, ","], [209, "of"], [209, "death"], [209, "by"], [209, "suicide"], [209, "."], [210, "twin"], [210, ","], [210, "adoption"], [210, "and"], [210, "epidemiological"], [210, "study"], [210, "suggest"], [210, "a"], [210, "strongly"], [210, "genetic"], [210, "aetiology"], [210, "."], [211, "it"], [211, "be"], [211, "a"], [211, "genetically"], [211, "and"], [211, "phenotypically"], [211, "complex"], [211, "disorder"], [211, "."], [212, "thus"], [212, ","], [212, "the"], [212, "gene"], [212, "contribute"], [212, "be"], [212, "likely"], [212, "to"], [212, "be"], [212, "numerous"], [212, "and"], [212, "of"], [212, "small"], [212, "effect"], [212, "."], [213, "individual"], [213, "with"], [213, "bipolar"], [213, "disorder"], [213, "also"], [213, "display"], [213, "deficit"], [213, "on"], [213, "a"], [213, "range"], [213, "of"], [213, "neuropsychological"], [213, "task"], [213, "in"], [213, "both"], [213, "the"], [213, "acute"], [213, "and"], [213, "euthymic"], [213, "phase"], [213, "of"], [213, "illness"], [213, "and"], [213, "correlation"], [213, "between"], [213, "number"], [213, "of"], [213, "affective"], [213, "episode"], [213, "experience"], [213, "and"], [213, "task"], [213, "performance"], [213, "be"], [213, "commonly"], [213, "report"], [213, "."], [214, "current"], [214, "self"], [214, "-"], [214, "report"], [214, "and"], [214, "observer"], [214, "-"], [214, "rate"], [214, "scale"], [214, "be"], [214, "optimize"], [214, "for"], [214, "unipolar"], [214, "depression"], [214, "and"], [214, "hence"], [214, "limit"], [214, "in"], [214, "their"], [214, "ability"], [214, "to"], [214, "accurately"], [214, "assess"], [214, "bipolar"], [214, "depression"], [214, "."], [215, "the"], [215, "development"], [215, "of"], [215, "a"], [215, "specific"], [215, "depression"], [215, "rating"], [215, "scale"], [215, "will"], [215, "improve"], [215, "the"], [215, "assessment"], [215, "of"], [215, "bipolar"], [215, "depression"], [215, "in"], [215, "both"], [215, "research"], [215, "and"], [215, "clinical"], [215, "setting"], [215, "."], [216, "it"], [216, "will"], [216, "improve"], [216, "the"], [216, "development"], [216, "of"], [216, "well"], [216, "treatment"], [216, "and"], [216, "intervention"], [216, "."], [217, "guideline"], [217, "support"], [217, "the"], [217, "use"], [217, "of"], [217, "antidepressant"], [217, "for"], [217, "bipolar"], [217, "depression"], [217, "."], [218, "with"], [218, "regard"], [218, "to"], [218, "the"], [218, "adverse"], [218, "effect"], [218, "of"], [218, "antidepressant"], [218, "for"], [218, "bipolar"], [218, "depression"], [218, ","], [218, "double"], [218, "-"], [218, "blind"], [218, ","], [218, "placebo"], [218, "-"], [218, "control"], [218, "datum"], [218, "suggest"], [218, "that"], [218, "antidepressant"], [218, "monotherapy"], [218, "or"], [218, "the"], [218, "addition"], [218, "of"], [218, "a"], [218, "tricyclic"], [218, "antidepressant"], [218, "may"], [218, "worsen"], [218, "the"], [218, "course"], [218, "of"], [218, "bipolar"], [218, "disorder"], [218, "."], [219, "importantly"], [219, ","], [219, "adjunctive"], [219, "psychotherapy"], [219, "add"], [219, "significantly"], [219, "("], [219, "both"], [219, "statistically"], [219, "and"], [219, "clinically"], [219, ")"], [219, "to"], [219, "the"], [219, "efficacy"], [219, "of"], [219, "pharmacological"], [219, "treatment"], [219, "regiman"], [219, "."], [220, "the"], [220, "successful"], [220, "management"], [220, "of"], [220, "bipolar"], [220, "disorder"], [220, "clearly"], [220, "demand"], [220, "improved"], [220, "recognition"], [220, "of"], [220, "bipolar"], [220, "disorder"], [220, "and"], [220, "effective"], [220, "long"], [220, "-"], [220, "term"], [220, "treatment"], [220, "for"], [220, "bipolar"], [220, "depression"], [220, "as"], [220, "well"], [220, "as"], [220, "mania"], [220, "."], [221, "clinical"], [221, "staging"], [221, "be"], [221, "widespread"], [221, "in"], [221, "medicine"], [221, "-"], [221, "it"], [221, "inform"], [221, "prognosis"], [221, ","], [221, "clinical"], [221, "course"], [221, ","], [221, "and"], [221, "treatment"], [221, ","], [221, "and"], [221, "assist"], [221, "individualized"], [221, "care"], [221, "."], [222, "stage"], [222, "place"], [222, "an"], [222, "individual"], [222, "on"], [222, "a"], [222, "probabilistic"], [222, "continuum"], [222, "of"], [222, "increase"], [222, "potential"], [222, "disease"], [222, "severity"], [222, ","], [222, "range"], [222, "from"], [222, "clinically"], [222, "at"], [222, "-"], [222, "risk"], [222, "or"], [222, "latency"], [222, "stage"], [222, "through"], [222, "first"], [222, "threshold"], [222, "episode"], [222, "of"], [222, "illness"], [222, "or"], [222, "recurrence"], [222, ","], [222, "and"], [222, ","], [222, "finally"], [222, ","], [222, "to"], [222, "late"], [222, "or"], [222, "end"], [222, "-"], [222, "stage"], [222, "disease"], [222, "."], [223, "the"], [223, "aim"], [223, "of"], [223, "the"], [223, "present"], [223, "paper"], [223, "be"], [223, "to"], [223, "examine"], [223, "and"], [223, "update"], [223, "the"], [223, "evidence"], [223, "regard"], [223, "staging"], [223, "in"], [223, "bipolar"], [223, "disorder"], [223, ","], [223, "and"], [223, "how"], [223, "this"], [223, "might"], [223, "inform"], [223, "target"], [223, "and"], [223, "individualized"], [223, "intervention"], [223, "approach"], [223, "."], [224, "we"], [224, "provide"], [224, "a"], [224, "narrative"], [224, "review"], [224, "of"], [224, "the"], [224, "relevant"], [224, "information"], [224, "."], [225, "in"], [225, "bipolar"], [225, "disorder"], [225, ","], [225, "the"], [225, "validity"], [225, "of"], [225, "staging"], [225, "be"], [225, "inform"], [225, "by"], [225, "a"], [225, "range"], [225, "of"], [225, "find"], [225, "that"], [225, "accompany"], [225, "illness"], [225, "progression"], [225, ","], [225, "include"], [225, "neuroimaging"], [225, "datum"], [225, "suggest"], [225, "incremental"], [225, "volume"], [225, "loss"], [225, ","], [225, "cognitive"], [225, "change"], [225, ","], [225, "and"], [225, "a"], [225, "decline"], [225, "likelihood"], [225, "of"], [225, "response"], [225, "to"], [225, "pharmacological"], [225, "and"], [225, "psychosocial"], [225, "treatment"], [225, "."], [226, "staging"], [226, "inform"], [226, "the"], [226, "adoption"], [226, "of"], [226, "a"], [226, "number"], [226, "of"], [226, "approach"], [226, ","], [226, "include"], [226, "the"], [226, "active"], [226, "promotion"], [226, "of"], [226, "both"], [226, "indicate"], [226, "prevention"], [226, "for"], [226, "at"], [226, "-"], [226, "risk"], [226, "individual"], [226, "and"], [226, "early"], [226, "intervention"], [226, "strategy"], [226, "for"], [226, "newly"], [226, "diagnose"], [226, "individual"], [226, ","], [226, "and"], [226, "the"], [226, "tailored"], [226, "implementation"], [226, "of"], [226, "treatment"], [226, "accord"], [226, "to"], [226, "the"], [226, "stage"], [226, "of"], [226, "illness"], [226, "."], [227, "the"], [227, "nature"], [227, "of"], [227, "bipolar"], [227, "disorder"], [227, "imply"], [227, "the"], [227, "presence"], [227, "of"], [227, "an"], [227, "active"], [227, "process"], [227, "of"], [227, "neuroprogression"], [227, "that"], [227, "be"], [227, "consider"], [227, "to"], [227, "be"], [227, "at"], [227, "least"], [227, "partly"], [227, "mediate"], [227, "by"], [227, "inflammation"], [227, ","], [227, "oxidative"], [227, "stress"], [227, ","], [227, "apoptosis"], [227, ","], [227, "and"], [227, "change"], [227, "in"], [227, "neurogenesis"], [227, "."], [228, "it"], [228, "far"], [228, "support"], [228, "the"], [228, "concept"], [228, "of"], [228, "neuroprotection"], [228, ","], [228, "in"], [228, "that"], [228, "a"], [228, "diversity"], [228, "of"], [228, "agent"], [228, "have"], [228, "putative"], [228, "effect"], [228, "against"], [228, "these"], [228, "molecular"], [228, "target"], [228, "."], [229, "clinically"], [229, ","], [229, "staging"], [229, "suggest"], [229, "that"], [229, "the"], [229, "at"], [229, "-"], [229, "risk"], [229, "state"], [229, "or"], [229, "first"], [229, "episode"], [229, "be"], [229, "a"], [229, "period"], [229, "that"], [229, "require"], [229, "particularly"], [229, "active"], [229, "and"], [229, "broad"], [229, "-"], [229, "base"], [229, "treatment"], [229, ","], [229, "consistent"], [229, "with"], [229, "the"], [229, "hope"], [229, "that"], [229, "the"], [229, "temporal"], [229, "trajectory"], [229, "of"], [229, "the"], [229, "illness"], [229, "can"], [229, "be"], [229, "alter"], [229, "."], [230, "prompt"], [230, "treatment"], [230, "may"], [230, "be"], [230, "potentially"], [230, "neuroprotective"], [230, "and"], [230, "attenuate"], [230, "the"], [230, "neurostructural"], [230, "and"], [230, "neurocognitive"], [230, "change"], [230, "that"], [230, "emerge"], [230, "with"], [230, "chronicity"], [230, "."], [231, "stage"], [231, "highlight"], [231, "the"], [231, "need"], [231, "for"], [231, "intervention"], [231, "at"], [231, "a"], [231, "service"], [231, "delivery"], [231, "level"], [231, "and"], [231, "implement"], [231, "treatment"], [231, "at"], [231, "the"], [231, "early"], [231, "stage"], [231, "of"], [231, "illness"], [231, "possible"], [231, "."], [232, "bipolar"], [232, "disorder"], [232, "be"], [232, "a"], [232, "mood"], [232, "disorder"], [232, "characterize"], [232, "by"], [232, "impair"], [232, "episode"], [232, "of"], [232, "mania"], [232, "and"], [232, "depression"], [232, "."], [233, "twin"], [233, "study"], [233, "have"], [233, "establish"], [233, "that"], [233, "bipolar"], [233, "disorder"], [233, "be"], [233, "among"], [233, "the"], [233, "most"], [233, "heritable"], [233, "of"], [233, "medical"], [233, "disorder"], [233, "and"], [233, "effort"], [233, "to"], [233, "identify"], [233, "specific"], [233, "susceptibility"], [233, "gene"], [233, "have"], [233, "intensify"], [233, "over"], [233, "the"], [233, "past"], [233, "two"], [233, "decade"], [233, "."], [234, "the"], [234, "search"], [234, "for"], [234, "gene"], [234, "influence"], [234, "bipolar"], [234, "disorder"], [234, "have"], [234, "be"], [234, "complicate"], [234, "by"], [234, "a"], [234, "paucity"], [234, "of"], [234, "animal"], [234, "model"], [234, ","], [234, "limited"], [234, "understanding"], [234, "of"], [234, "pathogenesis"], [234, ","], [234, "and"], [234, "the"], [234, "genetic"], [234, "and"], [234, "phenotypic"], [234, "complexity"], [234, "of"], [234, "the"], [234, "syndrome"], [234, "."], [235, "linkage"], [235, "study"], [235, "have"], [235, "implicate"], [235, "several"], [235, "chromosomal"], [235, "region"], [235, "as"], [235, "harbor"], [235, "relevant"], [235, "gene"], [235, ","], [235, "but"], [235, "result"], [235, "have"], [235, "be"], [235, "inconsistent"], [235, "."], [236, "it"], [236, "be"], [236, "now"], [236, "widely"], [236, "accept"], [236, "that"], [236, "the"], [236, "genetic"], [236, "liability"], [236, "to"], [236, "bipolar"], [236, "disorder"], [236, "reflect"], [236, "the"], [236, "action"], [236, "of"], [236, "many"], [236, "gene"], [236, "of"], [236, "individually"], [236, "small"], [236, "effect"], [236, ","], [236, "a"], [236, "scenario"], [236, "for"], [236, "which"], [236, "linkage"], [236, "study"], [236, "be"], [236, "poorly"], [236, "suit"], [236, "."], [237, "thus"], [237, ","], [237, "association"], [237, "study"], [237, ","], [237, "which"], [237, "be"], [237, "more"], [237, "powerful"], [237, "for"], [237, "the"], [237, "detection"], [237, "of"], [237, "modest"], [237, "effect"], [237, "loci"], [237, ","], [237, "have"], [237, "become"], [237, "the"], [237, "focus"], [237, "of"], [237, "gene"], [237, "-"], [237, "find"], [237, "research"], [237, "."], [238, "a"], [238, "large"], [238, "number"], [238, "of"], [238, "candidate"], [238, "gene"], [238, ","], [238, "include"], [238, "biological"], [238, "candidate"], [238, "derive"], [238, "from"], [238, "hypothesis"], [238, "about"], [238, "the"], [238, "pathogenesis"], [238, "of"], [238, "the"], [238, "disorder"], [238, "and"], [238, "positional"], [238, "candidate"], [238, "derive"], [238, "from"], [238, "linkage"], [238, "and"], [238, "cytogenetic"], [238, "study"], [238, ","], [238, "have"], [238, "be"], [238, "evaluate"], [238, "."], [239, "several"], [239, "of"], [239, "these"], [239, "gene"], [239, "have"], [239, "be"], [239, "associate"], [239, "with"], [239, "the"], [239, "disorder"], [239, "in"], [239, "independent"], [239, "study"], [239, "("], [239, "include"], [239, "bdnf"], [239, ","], [239, "daoa"], [239, ","], [239, "disc1"], [239, ","], [239, "grik4"], [239, ","], [239, "slc6a4"], [239, ","], [239, "and"], [239, "tph2"], [239, ")"], [239, ","], [239, "but"], [239, "none"], [239, "have"], [239, "be"], [239, "establish"], [239, "."], [240, "the"], [240, "clinical"], [240, "heterogeneity"], [240, "of"], [240, "bipolar"], [240, "disorder"], [240, "and"], [240, "its"], [240, "phenotypic"], [240, "and"], [240, "genetic"], [240, "overlap"], [240, "with"], [240, "other"], [240, "disorder"], [240, "("], [240, "especially"], [240, "schizophrenia"], [240, ","], [240, "schizoaffective"], [240, "disorder"], [240, ","], [240, "and"], [240, "major"], [240, "depressive"], [240, "disorder"], [240, ")"], [240, "have"], [240, "raise"], [240, "question"], [240, "about"], [240, "the"], [240, "optimal"], [240, "phenotype"], [240, "definition"], [240, "for"], [240, "genetic"], [240, "study"], [240, "."], [241, "nevertheless"], [241, ","], [241, "genomewide"], [241, "association"], [241, "analysis"], [241, ","], [241, "which"], [241, "have"], [241, "successfully"], [241, "identify"], [241, "susceptibility"], [241, "gene"], [241, "for"], [241, "a"], [241, "variety"], [241, "of"], [241, "complex"], [241, "disorder"], [241, ","], [241, "have"], [241, "begin"], [241, "to"], [241, "implicate"], [241, "specific"], [241, "gene"], [241, "for"], [241, "bipolar"], [241, "disorder"], [241, "("], [241, "dgkh"], [241, ","], [241, "cacna1c"], [241, ","], [241, "ank3"], [241, ")"], [241, "."], [242, "the"], [242, "polygenicity"], [242, "of"], [242, "the"], [242, "disorder"], [242, "mean"], [242, "that"], [242, "very"], [242, "large"], [242, "sample"], [242, "will"], [242, "be"], [242, "need"], [242, "to"], [242, "detect"], [242, "the"], [242, "modest"], [242, "effect"], [242, "loci"], [242, "that"], [242, "likely"], [242, "contribute"], [242, "to"], [242, "bipolar"], [242, "disorder"], [242, "."], [243, "detailed"], [243, "genetic"], [243, "dissection"], [243, "of"], [243, "the"], [243, "disorder"], [243, "may"], [243, "provide"], [243, "novel"], [243, "target"], [243, "("], [243, "both"], [243, "pharmacologic"], [243, "and"], [243, "psychosocial"], [243, ")"], [243, "for"], [243, "intervention"], [243, "."], [244, "bipolar"], [244, "disorder"], [244, "be"], [244, "diagnose"], [244, "on"], [244, "the"], [244, "basis"], [244, "of"], [244, "patient"], [244, "and/or"], [244, "family"], [244, "report"], [244, "and"], [244, "behavioral"], [244, "observation"], [244, "."], [245, "traditionally"], [245, "regard"], [245, "as"], [245, "an"], [245, "affective"], [245, "disorder"], [245, "involve"], [245, "behavioral"], [245, "change"], [245, ","], [245, "bipolar"], [245, "disorder"], [245, "have"], [245, "be"], [245, "reconceptualize"], [245, "as"], [245, "a"], [245, "multisystem"], [245, "disease"], [245, "associate"], [245, "with"], [245, "mood"], [245, ","], [245, "cognitive"], [245, ","], [245, "metabolic"], [245, ","], [245, "autonomic"], [245, "and"], [245, "sleep"], [245, "/"], [245, "wake"], [245, "dysfunction"], [245, "."], [246, "accordingly"], [246, ","], [246, "recent"], [246, "study"], [246, "have"], [246, "focus"], [246, "on"], [246, "the"], [246, "identification"], [246, "of"], [246, "biomarker"], [246, "relate"], [246, "to"], [246, "the"], [246, "pathophysiological"], [246, "mechanism"], [246, "underlie"], [246, "the"], [246, "development"], [246, ","], [246, "clinical"], [246, "presentation"], [246, "and"], [246, "course"], [246, "of"], [246, "bipolar"], [246, "disorder"], [246, "."], [247, "this"], [247, "article"], [247, "provide"], [247, "an"], [247, "overview"], [247, "of"], [247, "the"], [247, "available"], [247, "literature"], [247, "regard"], [247, "circulate"], [247, "peripheral"], [247, "and"], [247, "neuroimaging"], [247, "biomarker"], [247, "in"], [247, "bipolar"], [247, "disorder"], [247, "."], [248, "neurotrophic"], [248, "factor"], [248, ","], [248, "immune"], [248, "parameter"], [248, ","], [248, "oxidative"], [248, "stress"], [248, "parameter"], [248, ","], [248, "hormone"], [248, "and"], [248, "neuroimaging"], [248, "finding"], [248, "be"], [248, "take"], [248, "into"], [248, "consideration"], [248, "."], [249, "biomarkers"], [249, "research"], [249, "in"], [249, "bipolar"], [249, "disorder"], [249, "be"], [249, "a"], [249, "new"], [249, "field"], [249, "with"], [249, "an"], [249, "expand"], [249, "knowledge"], [249, "."], [250, "current"], [250, "evidence"], [250, "suggest"], [250, "that"], [250, "a"], [250, "single"], [250, "biomarker"], [250, "will"], [250, "not"], [250, "be"], [250, "able"], [250, "to"], [250, "cover"], [250, "the"], [250, "biological"], [250, "and"], [250, "clinical"], [250, "complexity"], [250, "of"], [250, "bipolar"], [250, "disorder"], [250, "."], [251, "alternatively"], [251, ","], [251, "a"], [251, "composite"], [251, "of"], [251, "biomarker"], [251, ","], [251, "include"], [251, "neurotrophic"], [251, "factor"], [251, ","], [251, "cytokine"], [251, "and"], [251, "oxidative"], [251, "stress"], [251, "molecule"], [251, ","], [251, "may"], [251, "be"], [251, "promise"], [251, "to"], [251, "identify"], [251, "altered"], [251, "mood"], [251, "state"], [251, "and"], [251, "neuroprogression"], [251, "in"], [251, "bipolar"], [251, "disorder"], [251, "."], [252, "bipolar"], [252, "disorder"], [252, "be"], [252, "a"], [252, "complex"], [252, "condition"], [252, "that"], [252, "be"], [252, "difficult"], [252, "to"], [252, "diagnose"], [252, "and"], [252, "treat"], [252, ","], [252, "and"], [252, "many"], [252, "patient"], [252, "with"], [252, "this"], [252, "illness"], [252, "be"], [252, "not"], [252, "receive"], [252, "adequate"], [252, "care"], [252, ","], [252, "particularly"], [252, "in"], [252, "the"], [252, "early"], [252, "stage"], [252, "of"], [252, "the"], [252, "disorder"], [252, "when"], [252, "effective"], [252, "treatment"], [252, "be"], [252, "most"], [252, "critical"], [252, "."], [253, "self"], [253, "-"], [253, "assessment"], [253, "cme"], [253, "be"], [253, "an"], [253, "educational"], [253, "activity"], [253, "in"], [253, "which"], [253, "clinician"], [253, "answer"], [253, "a"], [253, "series"], [253, "of"], [253, "multiple"], [253, "-"], [253, "choice"], [253, "question"], [253, "to"], [253, "ascertain"], [253, "their"], [253, "current"], [253, "knowledge"], [253, "and"], [253, "practice"], [253, "in"], [253, "treat"], [253, "cns"], [253, "disorder"], [253, "."], [254, "after"], [254, "complete"], [254, "the"], [254, "self"], [254, "-"], [254, "assessment"], [254, ","], [254, "clinician"], [254, "have"], [254, "the"], [254, "opportunity"], [254, "to"], [254, "review"], [254, "correct"], [254, "answer"], [254, ","], [254, "see"], [254, "how"], [254, "their"], [254, "colleague"], [254, "respond"], [254, ","], [254, "and"], [254, "receive"], [254, "recommendation"], [254, "for"], [254, "further"], [254, "reading"], [254, "."], [255, "this"], [255, "self"], [255, "-"], [255, "assessment"], [255, "cme"], [255, "activity"], [255, "focus"], [255, "on"], [255, "recognize"], [255, "and"], [255, "bridge"], [255, "gap"], [255, "in"], [255, "knowledge"], [255, "pertain"], [255, "to"], [255, "bipolar"], [255, "disorder"], [255, "recognition"], [255, "and"], [255, "treatment"], [255, "."], [256, "bipolar"], [256, "disorder"], [256, "be"], [256, "a"], [256, "prevalent"], [256, ","], [256, "chronic"], [256, "and"], [256, "heterogeneous"], [256, "psychiatric"], [256, "disorder"], [256, "."], [257, "there"], [257, "be"], [257, "increase"], [257, "evidence"], [257, "that"], [257, "early"], [257, "recognition"], [257, "and"], [257, "treatment"], [257, "can"], [257, "improve"], [257, "long"], [257, "-"], [257, "term"], [257, "outcome"], [257, "and"], [257, "prevent"], [257, "disability"], [257, "."], [258, "early"], [258, "intervention"], [258, "service"], [258, "for"], [258, "schizophrenia"], [258, "be"], [258, "well"], [258, "-"], [258, "fund"], [258, "and"], [258, "develop"], [258, "throughout"], [258, "the"], [258, "uk"], [258, "with"], [258, "close"], [258, "attention"], [258, "pay"], [258, "to"], [258, "the"], [258, "prodromal"], [258, "or"], [258, "early"], [258, "warning"], [258, "sign"], [258, "of"], [258, "schizophrenia"], [258, ","], [258, "whereas"], [258, "there"], [258, "be"], [258, "currently"], [258, "no"], [258, "clear"], [258, "guideline"], [258, "on"], [258, "the"], [258, "clinical"], [258, ","], [258, "biological"], [258, "and"], [258, "neuropsychological"], [258, "marker"], [258, "of"], [258, "early"], [258, "bipolar"], [258, "disorder"], [258, "."], [259, "this"], [259, "article"], [259, "review"], [259, "the"], [259, "grow"], [259, "literature"], [259, "on"], [259, "the"], [259, "bipolar"], [259, "prodrome"], [259, "and"], [259, "the"], [259, "differentiation"], [259, "between"], [259, "the"], [259, "syndrome"], [259, "of"], [259, "unipolar"], [259, "and"], [259, "bipolar"], [259, "depression"], [259, "."], [260, "bipolar"], [260, "disorder"], [260, "be"], [260, "one"], [260, "of"], [260, "the"], [260, "most"], [260, "severely"], [260, "debilitate"], [260, "of"], [260, "all"], [260, "medical"], [260, "illness"], [260, "."], [261, "it"], [261, "can"], [261, "lead"], [261, "to"], [261, "significant"], [261, "suffering"], [261, "for"], [261, "patient"], [261, "and"], [261, "their"], [261, "family"], [261, ","], [261, "limit"], [261, "function"], [261, "and"], [261, "workplace"], [261, "productivity"], [261, ","], [261, "and"], [261, "with"], [261, "its"], [261, "risk"], [261, "of"], [261, "increase"], [261, "morbidity"], [261, "and"], [261, "mortality"], [261, ","], [261, "it"], [261, "be"], [261, "increasingly"], [261, "recognize"], [261, "as"], [261, "a"], [261, "major"], [261, "public"], [261, "health"], [261, "problem"], [261, "."], [262, "for"], [262, "a"], [262, "large"], [262, "number"], [262, "of"], [262, "patient"], [262, ","], [262, "outcome"], [262, "be"], [262, "poor"], [262, "."], [263, "patient"], [263, "with"], [263, "bipolar"], [263, "disorder"], [263, "generally"], [263, "experience"], [263, "high"], [263, "rate"], [263, "of"], [263, "relapse"], [263, ","], [263, "a"], [263, "chronic"], [263, "recurrent"], [263, "course"], [263, ","], [263, "linger"], [263, "residual"], [263, "symptom"], [263, ","], [263, "functional"], [263, "impairment"], [263, ","], [263, "psychosocial"], [263, "disability"], [263, "and"], [263, "diminish"], [263, "well"], [263, "-"], [263, "being"], [263, "."], [264, "despite"], [264, "this"], [264, ","], [264, "little"], [264, "be"], [264, "know"], [264, "about"], [264, "the"], [264, "specific"], [264, "pathophysiology"], [264, "of"], [264, "bipolar"], [264, "disorder"], [264, "."], [265, "a"], [265, "well"], [265, "understanding"], [265, "of"], [265, "the"], [265, "neurobiological"], [265, "underpinning"], [265, "of"], [265, "this"], [265, "condition"], [265, ","], [265, "inform"], [265, "by"], [265, "preclinical"], [265, "and"], [265, "clinical"], [265, "research"], [265, ","], [265, "will"], [265, "be"], [265, "essential"], [265, "for"], [265, "the"], [265, "future"], [265, "development"], [265, "of"], [265, "specific"], [265, "target"], [265, "therapy"], [265, "that"], [265, "be"], [265, "more"], [265, "effective"], [265, ","], [265, "achieve"], [265, "their"], [265, "effect"], [265, "more"], [265, "quickly"], [265, "and"], [265, "be"], [265, "well"], [265, "tolerate"], [265, "than"], [265, "currently"], [265, "available"], [265, "treatment"], [265, "."], [266, "an"], [266, "abundance"], [266, "of"], [266, "research"], [266, "have"], [266, "implicate"], [266, "specific"], [266, "neuroendocrine"], [266, ","], [266, "neurotransmitter"], [266, "and"], [266, "intracellular"], [266, "signal"], [266, "system"], [266, "in"], [266, "the"], [266, "pathophysiology"], [266, "and"], [266, "treatment"], [266, "of"], [266, "this"], [266, "illness"], [266, "."], [267, "more"], [267, "recently"], [267, ","], [267, "genetic"], [267, "association"], [267, "study"], [267, "have"], [267, "identify"], [267, "numerous"], [267, "gene"], [267, "that"], [267, "confer"], [267, "vulnerability"], [267, "to"], [267, "the"], [267, "disorder"], [267, ","], [267, "many"], [267, "of"], [267, "which"], [267, "be"], [267, "know"], [267, "to"], [267, "function"], [267, "in"], [267, "the"], [267, "signal"], [267, "pathway"], [267, "previously"], [267, "identify"], [267, "as"], [267, "relevant"], [267, "to"], [267, "the"], [267, "etiology"], [267, "of"], [267, "the"], [267, "illness"], [267, "."], [268, "in"], [268, "this"], [268, "article"], [268, ","], [268, "we"], [268, "will"], [268, "review"], [268, "current"], [268, "knowledge"], [268, "regard"], [268, "the"], [268, "neurotransmitter"], [268, "system"], [268, ","], [268, "signal"], [268, "network"], [268, ","], [268, "neuroendocrine"], [268, "system"], [268, "and"], [268, "genetic"], [268, "of"], [268, "bipolar"], [268, "disorder"], [268, ";"], [268, "all"], [268, "of"], [268, "these"], [268, "allow"], [268, "insight"], [268, "into"], [268, "the"], [268, "mechanism"], [268, "of"], [268, "illness"], [268, "and"], [268, "thus"], [268, "offer"], [268, "potential"], [268, "novel"], [268, "direction"], [268, "for"], [268, "the"], [268, "development"], [268, "of"], [268, "novel"], [268, "therapeutic"], [268, "."], [269, "there"], [269, "be"], [269, "an"], [269, "urgent"], [269, "need"], [269, "to"], [269, "identify"], [269, "objective"], [269, "biomarker"], [269, "for"], [269, "the"], [269, "assessment"], [269, "of"], [269, "bipolar"], [269, "disorder"], [269, ","], [269, "to"], [269, "improve"], [269, "diagnosis"], [269, "and"], [269, "prognostic"], [269, "evaluation"], [269, "."], [270, "neuroimage"], [270, "be"], [270, "a"], [270, "particularly"], [270, "promising"], [270, "approach"], [270, "."], [271, "we"], [271, "review"], [271, "here"], [271, "the"], [271, "structural"], [271, "and"], [271, "functional"], [271, "neuroimaging"], [271, "study"], [271, "carry"], [271, "out"], [271, "on"], [271, "bipolar"], [271, "disorder"], [271, "."], [272, "these"], [272, "study"], [272, "have"], [272, "lead"], [272, "to"], [272, "the"], [272, "development"], [272, "of"], [272, "neurobiological"], [272, "model"], [272, "of"], [272, "bipolar"], [272, "disorder"], [272, "assume"], [272, "cortical"], [272, "-"], [272, "limbic"], [272, "dysregulation"], [272, "."], [273, "dorsal"], [273, "brain"], [273, "structure"], [273, "be"], [273, "think"], [273, "to"], [273, "decrease"], [273, "in"], [273, "volume"], [273, "and"], [273, "activity"], [273, "in"], [273, "bipolar"], [273, "disorder"], [273, ","], [273, "reduce"], [273, "inhibition"], [273, "of"], [273, "the"], [273, "ventral"], [273, "-"], [273, "limbic"], [273, "network"], [273, "and"], [273, "enhance"], [273, "emotional"], [273, "response"], [273, "."], [274, "these"], [274, "model"], [274, "also"], [274, "assume"], [274, "abnormal"], [274, "prefrontal"], [274, "-"], [274, "subcortical"], [274, "limbic"], [274, "connectivity"], [274, "."], [275, "this"], [275, "abnormal"], [275, "connectivity"], [275, "have"], [275, "be"], [275, "identify"], [275, "by"], [275, "both"], [275, "diffusion"], [275, "tensor"], [275, "imaging"], [275, "study"], [275, "("], [275, "anatomical"], [275, "connectivity"], [275, ")"], [275, "and"], [275, "functional"], [275, "mri"], [275, "("], [275, "functional"], [275, "connectivity"], [275, ")"], [275, "."], [276, "however"], [276, ","], [276, "study"], [276, "be"], [276, "currently"], [276, "limit"], [276, "by"], [276, "the"], [276, "heterogeneity"], [276, "of"], [276, "the"], [276, "patient"], [276, "include"], [276, "."], [277, "future"], [277, "research"], [277, "should"], [277, "include"], [277, "study"], [277, "to"], [277, "validate"], [277, "biomarker"], [277, "for"], [277, "the"], [277, "assessment"], [277, "of"], [277, "bipolar"], [277, "disorder"], [277, "and"], [277, "study"], [277, "of"], [277, "large"], [277, "and"], [277, "well"], [277, "characterize"], [277, "sample"], [277, "of"], [277, "patient"], [277, "with"], [277, "bipolar"], [277, "disorder"], [277, "."], [278, "bipolar"], [278, "disorder"], [278, "be"], [278, "a"], [278, "multifaceted"], [278, "illness"], [278, "and"], [278, "there"], [278, "be"], [278, "often"], [278, "a"], [278, "substantial"], [278, "delay"], [278, "between"], [278, "the"], [278, "first"], [278, "onset"], [278, "of"], [278, "symptom"], [278, "and"], [278, "diagnosis"], [278, "."], [279, "early"], [279, "detection"], [279, "have"], [279, "the"], [279, "potential"], [279, "to"], [279, "curtail"], [279, "illness"], [279, "progression"], [279, "and"], [279, "disorder"], [279, "-"], [279, "associate"], [279, "burden"], [279, "but"], [279, "it"], [279, "require"], [279, "a"], [279, "clear"], [279, "understanding"], [279, "of"], [279, "the"], [279, "initial"], [279, "bipolar"], [279, "prodrome"], [279, "."], [280, "this"], [280, "article"], [280, "summarize"], [280, "the"], [280, "phenomenology"], [280, "of"], [280, "bipolar"], [280, "disorder"], [280, "with"], [280, "an"], [280, "emphasis"], [280, "on"], [280, "the"], [280, "initial"], [280, "prodrome"], [280, ","], [280, "the"], [280, "evolution"], [280, "of"], [280, "the"], [280, "illness"], [280, ","], [280, "and"], [280, "the"], [280, "implication"], [280, "for"], [280, "prevention"], [280, "and"], [280, "early"], [280, "intervention"], [280, "."], [281, "a"], [281, "literature"], [281, "review"], [281, "be"], [281, "undertake"], [281, "use"], [281, "medline"], [281, ","], [281, "web"], [281, "of"], [281, "science"], [281, ","], [281, "and"], [281, "a"], [281, "hand"], [281, "search"], [281, "of"], [281, "relevant"], [281, "literature"], [281, "use"], [281, "keyword"], [281, "("], [281, "e.g."], [281, ","], [281, "phenomenology"], [281, ","], [281, "initial"], [281, "or"], [281, "early"], [281, "symptom"], [281, ","], [281, "risk"], [281, "factor"], [281, ","], [281, "and"], [281, "predictor"], [281, "/"], [281, "prediction"], [281, ")"], [281, "."], [282, "find"], [282, "from"], [282, "the"], [282, "literature"], [282, "be"], [282, "review"], [282, "and"], [282, "synthesize"], [282, "and"], [282, "have"], [282, "be"], [282, "put"], [282, "into"], [282, "a"], [282, "clinical"], [282, "context"], [282, "."], [283, "bipolar"], [283, "disorder"], [283, "be"], [283, "a"], [283, "recurrent"], [283, ","], [283, "persistent"], [283, ","], [283, "and"], [283, "disable"], [283, "illness"], [283, "that"], [283, "typically"], [283, "develop"], [283, "in"], [283, "adolescence"], [283, "or"], [283, "early"], [283, "adulthood"], [283, "."], [284, "the"], [284, "literature"], [284, "search"], [284, "yield"], [284, "28"], [284, "article"], [284, ","], [284, "in"], [284, "which"], [284, "mood"], [284, "lability"], [284, ","], [284, "nonspecific"], [284, ","], [284, "non"], [284, "-"], [284, "mood"], [284, "symptom"], [284, ","], [284, "and"], [284, "cyclothymic"], [284, "temperament"], [284, "be"], [284, "the"], [284, "most"], [284, "cite"], [284, "prodromal"], [284, "feature"], [284, "."], [285, "a"], [285, "small"], [285, "number"], [285, "of"], [285, "key"], [285, "prospective"], [285, "study"], [285, "have"], [285, "provide"], [285, "evidence"], [285, "in"], [285, "support"], [285, "of"], [285, "an"], [285, "initial"], [285, "bipolar"], [285, "prodrome"], [285, ";"], [285, "however"], [285, ","], [285, "methodological"], [285, "difference"], [285, "across"], [285, "study"], [285, "have"], [285, "prohibit"], [285, "its"], [285, "clear"], [285, "delineation"], [285, "."], [286, "it"], [286, "be"], [286, ","], [286, "therefore"], [286, ","], [286, "not"], [286, "currently"], [286, "possible"], [286, "to"], [286, "anticipate"], [286, "those"], [286, "who"], [286, "will"], [286, "develop"], [286, "bipolar"], [286, "disorder"], [286, "solely"], [286, "on"], [286, "the"], [286, "basis"], [286, "of"], [286, "early"], [286, "phenomenology"], [286, "."], [287, "accurate"], [287, "characterization"], [287, "of"], [287, "the"], [287, "bipolar"], [287, "disorder"], [287, "prodrome"], [287, "through"], [287, "high"], [287, "-"], [287, "quality"], [287, ","], [287, "prospective"], [287, "research"], [287, "study"], [287, "with"], [287, "adequate"], [287, "control"], [287, "group"], [287, "will"], [287, "ultimately"], [287, "facilitate"], [287, "prompt"], [287, "and"], [287, "accurate"], [287, "diagnosis"], [287, "."], [288, "bipolar"], [288, "disorder"], [288, "continue"], [288, "to"], [288, "present"], [288, "complex"], [288, "diagnostic"], [288, "and"], [288, "therapeutic"], [288, "challenge"], [288, "."], [289, "originally"], [289, "consider"], [289, "2"], [289, "separate"], [289, "disease"], [289, "("], [289, "mania"], [289, "and"], [289, "depression"], [289, ")"], [289, ","], [289, "bipolar"], [289, "disorder"], [289, "be"], [289, "now"], [289, "recognize"], [289, "to"], [289, "be"], [289, "a"], [289, "single"], [289, "disorder"], [289, "characterize"], [289, "by"], [289, "different"], [289, "subtype"], [289, "and"], [289, "degree"], [289, "of"], [289, "severity"], [289, "."], [290, "despite"], [290, "the"], [290, "availability"], [290, "of"], [290, "official"], [290, "guideline"], [290, ","], [290, "such"], [290, "as"], [290, "the"], [290, "dsm"], [290, "-"], [290, "iv"], [290, "and"], [290, "icd-10"], [290, ","], [290, "diagnosis"], [290, "be"], [290, "still"], [290, "problematic"], [290, "."], [291, "traditionally"], [291, ","], [291, "bipolar"], [291, "disorder"], [291, "have"], [291, "be"], [291, "consider"], [291, "a"], [291, "clinical"], [291, "entity"], [291, "distinct"], [291, "from"], [291, "schizophrenia"], [291, ","], [291, "although"], [291, "that"], [291, "assumption"], [291, "be"], [291, "be"], [291, "increasingly"], [291, "challenge"], [291, "."], [292, "proponent"], [292, "of"], [292, "a"], [292, "bipolar"], [292, "continuum"], [292, "theory"], [292, "support"], [292, "the"], [292, "concept"], [292, "of"], [292, "an"], [292, "expand"], [292, "psychiatric"], [292, "continuum"], [292, "range"], [292, "from"], [292, "unipolar"], [292, "to"], [292, "bipolar"], [292, "disorder"], [292, "all"], [292, "the"], [292, "way"], [292, "to"], [292, "schizophrenia"], [292, "."], [293, "this"], [293, "notion"], [293, "be"], [293, "support"], [293, "by"], [293, "various"], [293, "independent"], [293, "finding"], [293, "."], [294, "both"], [294, "bipolar"], [294, "disorder"], [294, "and"], [294, "schizophrenia"], [294, "demonstrate"], [294, "a"], [294, "high"], [294, "degree"], [294, "of"], [294, "genetic"], [294, "transmissibility"], [294, "."], [295, "some"], [295, "datum"], [295, "report"], [295, "in"], [295, "family"], [295, "and"], [295, "twin"], [295, "study"], [295, "suggest"], [295, "hereditary"], [295, "overlap"], [295, "between"], [295, "the"], [295, "2"], [295, "disorder"], [295, "."], [296, "gene"], [296, "mapping"], [296, "for"], [296, "both"], [296, "disease"], [296, "be"], [296, "in"], [296, "its"], [296, "early"], [296, "stage"], [296, ","], [296, "but"], [296, "certain"], [296, "susceptibility"], [296, "marker"], [296, "appear"], [296, "to"], [296, "be"], [296, "locate"], [296, "on"], [296, "the"], [296, "same"], [296, "chromosome"], [296, "."], [297, "bipolar"], [297, "disorder"], [297, "and"], [297, "schizophrenia"], [297, "also"], [297, "demonstrate"], [297, "some"], [297, "similarity"], [297, "in"], [297, "neurotransmitter"], [297, "dysfunction"], [297, "."], [298, "as"], [298, "further"], [298, "indirect"], [298, "evidence"], [298, "of"], [298, "a"], [298, "possible"], [298, "association"], [298, ","], [298, "many"], [298, "new"], [298, "atypical"], [298, "antipsychotic"], [298, "agent"], [298, "approve"], [298, "for"], [298, "the"], [298, "treatment"], [298, "of"], [298, "schizophrenia"], [298, "be"], [298, "also"], [298, "prove"], [298, "useful"], [298, "for"], [298, "bipolar"], [298, "disorder"], [298, "."], [299, "ongoing"], [299, "research"], [299, "should"], [299, "aid"], [299, "in"], [299, "the"], [299, "understanding"], [299, "of"], [299, "bipolar"], [299, "disorder"], [299, "and"], [299, "foster"], [299, "the"], [299, "development"], [299, "of"], [299, "more"], [299, "effective"], [299, "treatment"], [299, "."], [300, "this"], [300, "article"], [300, "examine"], [300, "the"], [300, "individual"], [300, "component"], [300, "of"], [300, "bipolar"], [300, "disorder"], [300, "in"], [300, "child"], [300, "and"], [300, "the"], [300, "behavior"], [300, "that"], [300, "can"], [300, "escalate"], [300, "as"], [300, "a"], [300, "result"], [300, "of"], [300, "misdiagnosis"], [300, "and"], [300, "treatment"], [300, "."], [301, "the"], [301, "brain"], [301, "/"], [301, "behavior"], [301, "relationship"], [301, "in"], [301, "bipolar"], [301, "disorder"], [301, "can"], [301, "be"], [301, "affect"], [301, "by"], [301, "genetic"], [301, ","], [301, "developmental"], [301, "failure"], [301, ","], [301, "or"], [301, "environmental"], [301, "influence"], [301, ","], [301, "which"], [301, "can"], [301, "cause"], [301, "an"], [301, "onset"], [301, "of"], [301, "dramatic"], [301, "mood"], [301, "swing"], [301, "and"], [301, "dysfunctional"], [301, "behavior"], [301, "."], [302, "school"], [302, "be"], [302, "often"], [302, "the"], [302, "site"], [302, "where"], [302, "mental"], [302, "health"], [302, "disorder"], [302, "be"], [302, "observe"], [302, "when"], [302, "compare"], [302, "behavior"], [302, "with"], [302, "other"], [302, "child"], [302, "."], [303, "assess"], [303, "the"], [303, "emotional"], [303, ","], [303, "academic"], [303, ","], [303, "and"], [303, "health"], [303, "need"], [303, "of"], [303, "a"], [303, "student"], [303, "with"], [303, "a"], [303, "bipolar"], [303, "disorder"], [303, "be"], [303, "a"], [303, "critical"], [303, "step"], [303, "in"], [303, "design"], [303, "effective"], [303, "intervention"], [303, "and"], [303, "school"], [303, "accommodation"], [303, "."], [304, "without"], [304, "appropriate"], [304, "medical"], [304, ","], [304, "psychological"], [304, ","], [304, "pharmaceutical"], [304, ","], [304, "and"], [304, "academic"], [304, "intervention"], [304, ","], [304, "a"], [304, "child"], [304, "be"], [304, "at"], [304, "risk"], [304, "for"], [304, "uncontrolled"], [304, "mania"], [304, ","], [304, "depression"], [304, ","], [304, "substance"], [304, "abuse"], [304, ","], [304, "or"], [304, "suicide"], [304, "."], [305, "the"], [305, "school"], [305, "nurse"], [305, "be"], [305, "part"], [305, "of"], [305, "the"], [305, "multidisciplinary"], [305, "team"], [305, "and"], [305, "play"], [305, "a"], [305, "key"], [305, "role"], [305, "in"], [305, "facilitating"], [305, "case"], [305, "management"], [305, "to"], [305, "potentially"], [305, "reverse"], [305, "this"], [305, "possible"], [305, "negative"], [305, "trajectory"], [305, "."], [306, "successful"], [306, "case"], [306, "management"], [306, "provide"], [306, "child"], [306, "with"], [306, "bipolar"], [306, "disorder"], [306, "the"], [306, "opportunity"], [306, "to"], [306, "reach"], [306, "their"], [306, "academic"], [306, "potential"], [306, "."], [307, "bipolar"], [307, "disorder"], [307, "heterogeneity"], [307, "be"], [307, "large"], [307, ","], [307, "lead"], [307, "to"], [307, "difficulty"], [307, "in"], [307, "identify"], [307, "neuropathophysiological"], [307, "and"], [307, "etiological"], [307, "mechanism"], [307, "and"], [307, "hinder"], [307, "the"], [307, "formation"], [307, "of"], [307, "clinically"], [307, "homogeneous"], [307, "patient"], [307, "group"], [307, "in"], [307, "clinical"], [307, "trial"], [307, "."], [308, "identify"], [308, "marker"], [308, "of"], [308, "clinically"], [308, "more"], [308, "homogeneous"], [308, "group"], [308, "would"], [308, "help"], [308, "disentangle"], [308, "bd"], [308, "heterogeneity"], [308, "."], [309, "neuroimage"], [309, "may"], [309, "aid"], [309, "in"], [309, "identify"], [309, "such"], [309, "group"], [309, "by"], [309, "highlight"], [309, "specific"], [309, "biomarker"], [309, "of"], [309, "bd"], [309, "subtype"], [309, "or"], [309, "clinical"], [309, "dimension"], [309, "."], [310, "we"], [310, "perform"], [310, "a"], [310, "systematic"], [310, "literature"], [310, "search"], [310, "of"], [310, "the"], [310, "neuroimage"], [310, "literature"], [310, "assess"], [310, "biomarker"], [310, "of"], [310, "relevant"], [310, "bd"], [310, "phenotype"], [310, "("], [310, "type"], [310, "-"], [310, "i"], [310, "vs."], [310, "ii"], [310, ","], [310, "presence"], [310, "vs."], [310, "absence"], [310, "of"], [310, "psychotic"], [310, "feature"], [310, ","], [310, "suicidal"], [310, "behavior"], [310, "and"], [310, "impulsivity"], [310, ","], [310, "rapid"], [310, "cycling"], [310, ","], [310, "good"], [310, "vs."], [310, "poor"], [310, "medication"], [310, "response"], [310, ","], [310, "age"], [310, "at"], [310, "onset"], [310, ","], [310, "cognitive"], [310, "performance"], [310, "and"], [310, "circadian"], [310, "abnormality"], [310, ")"], [310, "."], [311, "consistent"], [311, "biomarker"], [311, "be"], [311, "associate"], [311, "with"], [311, "suicidal"], [311, "behavior"], [311, ","], [311, "i.e."], [311, "frontal"], [311, "/"], [311, "anterior"], [311, "alteration"], [311, "("], [311, "prefrontal"], [311, "and"], [311, "cingulate"], [311, "grey"], [311, "matter"], [311, ","], [311, "prefrontal"], [311, "white"], [311, "matter"], [311, ")"], [311, "in"], [311, "patient"], [311, "with"], [311, "a"], [311, "history"], [311, "of"], [311, "suicide"], [311, "attempt"], [311, ";"], [311, "and"], [311, "with"], [311, "cognitive"], [311, "performance"], [311, ","], [311, "i.e."], [311, "involvement"], [311, "of"], [311, "frontal"], [311, "and"], [311, "temporal"], [311, "region"], [311, ","], [311, "superior"], [311, "and"], [311, "inferior"], [311, "longitudinal"], [311, "fasciculus"], [311, ","], [311, "right"], [311, "thalamic"], [311, "radiation"], [311, ","], [311, "and"], [311, "corpus"], [311, "callosum"], [311, "in"], [311, "executive"], [311, "dysfunction"], [311, "."], [312, "for"], [312, "the"], [312, "other"], [312, "dimension"], [312, "and"], [312, "sub"], [312, "-"], [312, "type"], [312, "study"], [312, ","], [312, "no"], [312, "consistent"], [312, "biomarker"], [312, "be"], [312, "identify"], [312, "."], [313, "study"], [313, "be"], [313, "heterogeneous"], [313, "both"], [313, "in"], [313, "methodology"], [313, "and"], [313, "outcome"], [313, "."], [314, "though"], [314, "theoretically"], [314, "promising"], [314, ","], [314, "neuroimaging"], [314, "have"], [314, "not"], [314, "yet"], [314, "prove"], [314, "capable"], [314, "of"], [314, "disentangle"], [314, "subtype"], [314, "and"], [314, "dimension"], [314, "of"], [314, "bipolar"], [314, "disorder"], [314, ","], [314, "due"], [314, "to"], [314, "high"], [314, "between"], [314, "-"], [314, "study"], [314, "heterogeneity"], [314, "."], [315, "we"], [315, "issue"], [315, "recommendation"], [315, "for"], [315, "future"], [315, "study"], [315, "."], [316, "provide"], [316, "an"], [316, "overview"], [316, "of"], [316, "how"], [316, "bipolar"], [316, "disorder"], [316, "affect"], [316, "cognitive"], [316, "function"], [316, "in"], [316, "patient"], [316, "."], [317, "medline"], [317, "and"], [317, "psycinfo"], [317, "datum"], [317, "basis"], [317, "be"], [317, "search"], [317, "for"], [317, "article"], [317, "index"], [317, "by"], [317, "the"], [317, "combination"], [317, "of"], [317, "mesh"], [317, "term"], [317, "or"], [317, "key"], [317, "word"], [317, '"'], [317, "bipolar"], [317, "disorder"], [317, '"'], [317, "with"], [317, "the"], [317, "follow"], [317, "term"], [317, ":"], [317, '"'], [317, "cognition"], [317, '"'], [317, ","], [317, '"'], [317, "memory"], [317, '"'], [317, ","], [317, '"'], [317, "neuropsychology"], [317, '"'], [317, ","], [317, '"'], [317, "neuropsychological"], [317, "test"], [317, '"'], [317, ","], [317, '"'], [317, "lithium"], [317, '"'], [317, ","], [317, '"'], [317, "anticonvulsant"], [317, '"'], [317, ","], [317, '"'], [317, "antipsychotic"], [317, '"'], [317, ","], [317, "and"], [317, '"'], [317, "schizophrenia"], [317, '"'], [317, "."], [318, "constraint"], [318, "limit"], [318, "time"], [318, "period"], [318, "of"], [318, "publication"], [318, "or"], [318, "their"], [318, "language"], [318, "be"], [318, "not"], [318, "apply"], [318, "."], [319, "reference"], [319, "list"], [319, "of"], [319, "publication"], [319, "identify"], [319, "by"], [319, "these"], [319, "procedure"], [319, "be"], [319, "hand"], [319, "-"], [319, "search"], [319, "for"], [319, "additional"], [319, "relevant"], [319, "citation"], [319, "."], [320, "there"], [320, "be"], [320, "evidence"], [320, "of"], [320, "stable"], [320, "and"], [320, "lasting"], [320, "cognitive"], [320, "impairment"], [320, "in"], [320, "all"], [320, "phase"], [320, "of"], [320, "bipolar"], [320, "disorder"], [320, ","], [320, "include"], [320, "the"], [320, "remission"], [320, "phase"], [320, ","], [320, "particularly"], [320, "in"], [320, "the"], [320, "follow"], [320, "domain"], [320, ":"], [320, "sustain"], [320, "attention"], [320, ","], [320, "memory"], [320, "and"], [320, "executive"], [320, "function"], [320, "."], [321, "but"], [321, "research"], [321, "on"], [321, "the"], [321, "cognitive"], [321, "function"], [321, "have"], [321, "yield"], [321, "inconsistent"], [321, "result"], [321, "over"], [321, "recent"], [321, "year"], [321, "."], [322, "there"], [322, "be"], [322, "a"], [322, "grow"], [322, "need"], [322, "for"], [322, "clarification"], [322, "regard"], [322, "the"], [322, "magnitude"], [322, ","], [322, "clinical"], [322, "relevance"], [322, "and"], [322, "confound"], [322, "variable"], [322, "of"], [322, "cognitive"], [322, "impairment"], [322, "in"], [322, "bipolar"], [322, "patient"], [322, "."], [323, "the"], [323, "impact"], [323, "of"], [323, "bipolar"], [323, "illness"], [323, "on"], [323, "cognition"], [323, "can"], [323, "be"], [323, "influence"], [323, "by"], [323, "age"], [323, "of"], [323, "onset"], [323, ","], [323, "pharmacological"], [323, "treatment"], [323, ","], [323, "individual"], [323, "response"], [323, ","], [323, "familial"], [323, "risk"], [323, "factor"], [323, ","], [323, "and"], [323, "clinical"], [323, "feature"], [323, "."], [324, "in"], [324, "addition"], [324, "to"], [324, "the"], [324, "mood"], [324, "state"], [324, ","], [324, "cognitive"], [324, "performance"], [324, "in"], [324, "bipolar"], [324, "patient"], [324, "be"], [324, "influence"], [324, "by"], [324, "seasonality"], [324, "."], [325, "previous"], [325, "optimistic"], [325, "assumption"], [325, "about"], [325, "the"], [325, "prognosis"], [325, "of"], [325, "bipolar"], [325, "disorder"], [325, "be"], [325, "base"], [325, "on"], [325, "the"], [325, "success"], [325, "of"], [325, "the"], [325, "control"], [325, "of"], [325, "mood"], [325, "symptom"], [325, "by"], [325, "pharmacotherapy"], [325, "."], [326, "however"], [326, ","], [326, "it"], [326, "be"], [326, "now"], [326, "clear"], [326, "that"], [326, "the"], [326, '"'], [326, "remitted"], [326, '"'], [326, "euthymic"], [326, "bipolar"], [326, "patient"], [326, "have"], [326, "distinct"], [326, "impairment"], [326, "of"], [326, "executive"], [326, "function"], [326, ","], [326, "verbal"], [326, "memory"], [326, ","], [326, "psychomotor"], [326, "speed"], [326, ","], [326, "and"], [326, "sustain"], [326, "attention"], [326, "."], [327, "mood"], [327, "stabilizer"], [327, "and"], [327, "atypical"], [327, "antipsychotic"], [327, "may"], [327, "reduce"], [327, "cognitive"], [327, "deficit"], [327, "in"], [327, "certain"], [327, "domain"], [327, "and"], [327, "may"], [327, "have"], [327, "a"], [327, "positive"], [327, "effect"], [327, "on"], [327, "quality"], [327, "of"], [327, "life"], [327, "and"], [327, "social"], [327, "functioning"], [327, "."], [328, "mania"], [328, "in"], [328, "old"], [328, "age"], [328, "be"], [328, "not"], [328, "as"], [328, "rare"], [328, "as"], [328, "it"], [328, "be"], [328, "once"], [328, "think"], [328, "to"], [328, "be"], [328, "."], [329, "it"], [329, "may"], [329, "constitute"], [329, "up"], [329, "to"], [329, "5"], [329, "per"], [329, "cent"], [329, "of"], [329, "admission"], [329, "in"], [329, "the"], [329, "psychogeriatric"], [329, "department"], [329, "."], [330, "the"], [330, "clinical"], [330, "picture"], [330, ","], [330, "for"], [330, "the"], [330, "most"], [330, "part"], [330, ","], [330, "seem"], [330, "to"], [330, "correspond"], [330, "with"], [330, "mania"], [330, "in"], [330, "young"], [330, "patient"], [330, ","], [330, "although"], [330, "some"], [330, "patient"], [330, "may"], [330, "have"], [330, "atypical"], [330, "presentation"], [330, "."], [331, "secondary"], [331, "mania"], [331, "should"], [331, "be"], [331, "exclude"], [331, "first"], [331, ","], [331, "before"], [331, "a"], [331, "firm"], [331, "diagnosis"], [331, "of"], [331, "primary"], [331, "affective"], [331, "disorder"], [331, "be"], [331, "make"], [331, "."], [332, "the"], [332, "prognosis"], [332, "and"], [332, "treatment"], [332, "of"], [332, "late"], [332, "onset"], [332, "mania"], [332, "do"], [332, "not"], [332, "seem"], [332, "to"], [332, "differ"], [332, "appreciably"], [332, "from"], [332, "those"], [332, "in"], [332, "young"], [332, "patient"], [332, "."], [333, "early"], [333, "onset"], [333, "("], [333, "pediatric"], [333, ")"], [333, "bipolar"], [333, "disorder"], [333, "be"], [333, "still"], [333, "an"], [333, "issue"], [333, "of"], [333, "much"], [333, "controversy"], [333, "due"], [333, "to"], [333, "several"], [333, "clinical"], [333, "particularity"], [333, "of"], [333, "the"], [333, "thymic"], [333, "episode"], [333, "at"], [333, "this"], [333, "age"], [333, "."], [334, "to"], [334, "date"], [334, ","], [334, "there"], [334, "be"], [334, "indeed"], [334, "no"], [334, "consensus"], [334, "regard"], [334, "the"], [334, "prevalence"], [334, "of"], [334, "bipolar"], [334, "disorder"], [334, "before"], [334, "puberty"], [334, "."], [335, "diagnosis"], [335, "criterion"], [335, "in"], [335, "child"], [335, "and"], [335, "young"], [335, "adolescent"], [335, "remain"], [335, "thus"], [335, "elusive"], [335, "."], [336, "the"], [336, "purpose"], [336, "of"], [336, "this"], [336, "review"], [336, "be"], [336, "to"], [336, "provide"], [336, "an"], [336, "overview"], [336, "of"], [336, "this"], [336, "issue"], [336, "."], [337, "the"], [337, "idea"], [337, "of"], [337, "continuity"], [337, ","], [337, "from"], [337, "childhood"], [337, "to"], [337, "adulthood"], [337, ","], [337, "in"], [337, "bipolar"], [337, "disorder"], [337, "also"], [337, "raise"], [337, "important"], [337, "question"], [337, "regard"], [337, "predictive"], [337, "factor"], [337, "of"], [337, "bipolar"], [337, "disorder"], [337, "in"], [337, "adult"], [337, "."], [338, "study"], [338, "on"], [338, "the"], [338, "childhood"], [338, "of"], [338, "bipolar"], [338, "adult"], [338, ","], [338, "as"], [338, "well"], [338, "as"], [338, "study"], [338, "on"], [338, "the"], [338, "child"], [338, "of"], [338, "bipolar"], [338, "parent"], [338, "will"], [338, "be"], [338, "review"], [338, ","], [338, "in"], [338, "an"], [338, "attempt"], [338, "to"], [338, "identify"], [338, "the"], [338, "psychopathological"], [338, "substrate"], [338, "of"], [338, "bipolar"], [338, "disorder"], [338, "."], [339, "in"], [339, "dsm-5"], [339, ","], [339, "bipolar"], [339, "disorder"], [339, "("], [339, "bs"], [339, ")"], [339, "be"], [339, "no"], [339, "long"], [339, "conceptualise"], [339, "as"], [339, "a"], [339, "pure"], [339, "mood"], [339, "disorder"], [339, "together"], [339, "with"], [339, "unipolar"], [339, "depression"], [339, ","], [339, "but"], [339, "as"], [339, "a"], [339, "bridge"], [339, "between"], [339, "schizophrenia"], [339, "and"], [339, "depressive"], [339, "disorder"], [339, "."], [340, "this"], [340, "nosological"], [340, "classification"], [340, "be"], [340, "find"], [340, "on"], [340, "the"], [340, "historical"], [340, "context"], [340, "of"], [340, "the"], [340, "19th"], [340, "century"], [340, "."], [341, "in"], [341, "addition"], [341, "to"], [341, "unipolar"], [341, "depression"], [341, "and"], [341, "schizophrenia"], [341, ","], [341, "schizoaffective"], [341, "disorder"], [341, ","], [341, "borderline"], [341, "personality"], [341, "disorder"], [341, "and"], [341, "attention"], [341, "-"], [341, "deficit"], [341, "hyperactivity"], [341, "disorder"], [341, "("], [341, "adhd"], [341, ")"], [341, "overlap"], [341, "with"], [341, "bs"], [341, "symptomatology"], [341, "."], [342, "overlap"], [342, "also"], [342, "exist"], [342, "with"], [342, "somatic"], [342, "disease"], [342, "such"], [342, "as"], [342, "multiple"], [342, "sclerosis"], [342, ","], [342, "cushing"], [342, "'s"], [342, "syndrome"], [342, "and"], [342, "syphilis"], [342, "as"], [342, "well"], [342, "as"], [342, "iatrogenic"], [342, "affective"], [342, "syndrome"], [342, "."], [343, "the"], [343, "author"], [343, "provide"], [343, "an"], [343, "overview"], [343, "of"], [343, "the"], [343, "diagnosis"], [343, ","], [343, "course"], [343, ","], [343, "and"], [343, "treatment"], [343, "of"], [343, "bipolar"], [343, "ii"], [343, "disorder"], [343, ","], [343, "a"], [343, "distinct"], [343, "subtype"], [343, "that"], [343, "be"], [343, "often"], [343, "misdiagnose"], [343, "as"], [343, "unipolar"], [343, "depression"], [343, "or"], [343, "bipolar"], [343, "i"], [343, "disorder"], [343, "."], [344, "they"], [344, "discuss"], [344, "research"], [344, "suggest"], [344, "that"], [344, "underdiagnosis"], [344, "of"], [344, "bipolar"], [344, "ii"], [344, "disorder"], [344, "reflect"], [344, "a"], [344, "failure"], [344, "to"], [344, "identify"], [344, "subthreshold"], [344, "expression"], [344, "of"], [344, "mania"], [344, "("], [344, "hypomania"], [344, ")"], [344, "."], [345, "the"], [345, "course"], [345, "of"], [345, "bipolar"], [345, "ii"], [345, "disorder"], [345, "be"], [345, "different"], [345, "from"], [345, "that"], [345, "of"], [345, "bipolar"], [345, "i"], [345, "disorder"], [345, "or"], [345, "unipolar"], [345, "depression"], [345, ","], [345, "with"], [345, "distinct"], [345, "difference"], [345, "in"], [345, "rate"], [345, "of"], [345, "recovery"], [345, ","], [345, "clinical"], [345, "feature"], [345, ","], [345, "and"], [345, "number"], [345, "of"], [345, "episode"], [345, "."], [346, "the"], [346, "risk"], [346, "of"], [346, "suicide"], [346, "appear"], [346, "to"], [346, "be"], [346, "particularly"], [346, "elevate"], [346, "."], [347, "high"], [347, "rate"], [347, "of"], [347, "comorbid"], [347, "disorder"], [347, "have"], [347, "be"], [347, "report"], [347, ","], [347, "include"], [347, "substance"], [347, "abuse"], [347, "or"], [347, "dependence"], [347, ","], [347, "anxiety"], [347, "disorder"], [347, ","], [347, "and"], [347, "personality"], [347, "disorder"], [347, "."], [348, "few"], [348, "definitive"], [348, "study"], [348, "exist"], [348, "on"], [348, "which"], [348, "to"], [348, "base"], [348, "conclusion"], [348, "about"], [348, "the"], [348, "differential"], [348, "efficacy"], [348, "of"], [348, "various"], [348, "treatment"], [348, "strategy"], [348, "in"], [348, "bipolar"], [348, "ii"], [348, "disorder"], [348, "and"], [348, "bipolar"], [348, "i"], [348, "disorder"], [348, "."], [349, "preliminary"], [349, "study"], [349, "suggest"], [349, "that"], [349, "the"], [349, "new"], [349, "anticonvulsant"], [349, "may"], [349, "be"], [349, "of"], [349, "benefit"], [349, "for"], [349, "patient"], [349, "with"], [349, "bipolar"], [349, "ii"], [349, "disorder"], [349, ","], [349, "while"], [349, "other"], [349, "datum"], [349, "suggest"], [349, "that"], [349, "there"], [349, "may"], [349, "be"], [349, "a"], [349, "great"], [349, "role"], [349, "for"], [349, "antidepressant"], [349, "medication"], [349, "."], [350, "it"], [350, "be"], [350, "clinically"], [350, "important"], [350, "to"], [350, "recognize"], [350, "both"], [350, "bipolar"], [350, "disorder"], [350, "and"], [350, "borderline"], [350, "personality"], [350, "disorder"], [350, "("], [350, "bpd"], [350, ")"], [350, "in"], [350, "patient"], [350, "seek"], [350, "treatment"], [350, "for"], [350, "depression"], [350, ","], [350, "and"], [350, "it"], [350, "be"], [350, "important"], [350, "to"], [350, "distinguish"], [350, "between"], [350, "the"], [350, "two"], [350, "."], [351, "the"], [351, "most"], [351, "studied"], [351, "question"], [351, "on"], [351, "the"], [351, "relationship"], [351, "between"], [351, "bpd"], [351, "and"], [351, "bipolar"], [351, "disorder"], [351, "be"], [351, "their"], [351, "diagnostic"], [351, "concordance"], [351, "."], [352, "across"], [352, "study"], [352, "approximately"], [352, "10"], [352, "%"], [352, "of"], [352, "patient"], [352, "with"], [352, "bpd"], [352, "have"], [352, "bipolar"], [352, "i"], [352, "disorder"], [352, "and"], [352, "another"], [352, "10"], [352, "%"], [352, "have"], [352, "bipolar"], [352, "ii"], [352, "disorder"], [352, "."], [353, "likewise"], [353, ","], [353, "approximately"], [353, "20"], [353, "%"], [353, "of"], [353, "bipolar"], [353, "ii"], [353, "patient"], [353, "be"], [353, "diagnose"], [353, "with"], [353, "bpd"], [353, ","], [353, "though"], [353, "only"], [353, "10"], [353, "%"], [353, "of"], [353, "bipolar"], [353, "i"], [353, "patient"], [353, "be"], [353, "diagnose"], [353, "with"], [353, "bpd"], [353, "."], [354, "while"], [354, "the"], [354, "comorbidity"], [354, "rate"], [354, "be"], [354, "substantial"], [354, ","], [354, "each"], [354, "disorder"], [354, "be"], [354, ","], [354, "nonetheless"], [354, ","], [354, "diagnose"], [354, "in"], [354, "the"], [354, "absence"], [354, "of"], [354, "the"], [354, "other"], [354, "in"], [354, "the"], [354, "vast"], [354, "majority"], [354, "of"], [354, "case"], [354, "("], [354, "80"], [354, "-"], [354, "90"], [354, "%"], [354, ")"], [354, "."], [355, "in"], [355, "study"], [355, "examine"], [355, "personality"], [355, "disorder"], [355, "broadly"], [355, ","], [355, "other"], [355, "personality"], [355, "disorder"], [355, "be"], [355, "more"], [355, "commonly"], [355, "diagnose"], [355, "in"], [355, "bipolar"], [355, "patient"], [355, "than"], [355, "be"], [355, "bpd"], [355, "."], [356, "likewise"], [356, ","], [356, "the"], [356, "converse"], [356, "be"], [356, "also"], [356, "true"], [356, ":"], [356, "other"], [356, "axis"], [356, "i"], [356, "disorder"], [356, "such"], [356, "as"], [356, "major"], [356, "depression"], [356, ","], [356, "substance"], [356, "abuse"], [356, ","], [356, "and"], [356, "post"], [356, "-"], [356, "traumatic"], [356, "stress"], [356, "disorder"], [356, "be"], [356, "more"], [356, "commonly"], [356, "diagnose"], [356, "in"], [356, "patient"], [356, "with"], [356, "bpd"], [356, "than"], [356, "be"], [356, "bipolar"], [356, "disorder"], [356, "."], [357, "study"], [357, "compare"], [357, "patient"], [357, "with"], [357, "bpd"], [357, "and"], [357, "bipolar"], [357, "disorder"], [357, "find"], [357, "significant"], [357, "difference"], [357, "on"], [357, "a"], [357, "range"], [357, "of"], [357, "variable"], [357, "."], [358, "these"], [358, "finding"], [358, "challenge"], [358, "the"], [358, "notion"], [358, "that"], [358, "bpd"], [358, "be"], [358, "part"], [358, "of"], [358, "the"], [358, "bipolar"], [358, "spectrum"], [358, "."], [359, "while"], [359, "a"], [359, "substantial"], [359, "literature"], [359, "have"], [359, "document"], [359, "problem"], [359, "with"], [359, "the"], [359, "under"], [359, "-"], [359, "recognition"], [359, "and"], [359, "under"], [359, "-"], [359, "diagnosis"], [359, "of"], [359, "bipolar"], [359, "disorder"], [359, ","], [359, "more"], [359, "recent"], [359, "study"], [359, "have"], [359, "find"], [359, "evidence"], [359, "of"], [359, "bipolar"], [359, "disorder"], [359, "over"], [359, "-"], [359, "diagnosis"], [359, "and"], [359, "that"], [359, "bpd"], [359, "be"], [359, "a"], [359, "significant"], [359, "contributor"], [359, "to"], [359, "over"], [359, "-"], [359, "diagnosis"], [359, "."], [360, "re"], [360, "-"], [360, "conceptualize"], [360, "the"], [360, "diagnostic"], [360, "and"], [360, "statistical"], [360, "manual"], [360, "of"], [360, "mental"], [360, "disorder"], [360, ","], [360, "fifth"], [360, "edition"], [360, ","], [360, "diagnostic"], [360, "criterion"], [360, "for"], [360, "bipolar"], [360, "disorder"], [360, "as"], [360, "a"], [360, "type"], [360, "of"], [360, "test"], [360, ","], [360, "rather"], [360, "than"], [360, "the"], [360, "final"], [360, "word"], [360, "on"], [360, "diagnosis"], [360, ","], [360, "shift"], [360, "the"], [360, "diagnostician"], [360, "from"], [360, "think"], [360, "solely"], [360, "whether"], [360, "a"], [360, "patient"], [360, "do"], [360, "or"], [360, "do"], [360, "not"], [360, "have"], [360, "a"], [360, "disorder"], [360, "to"], [360, "consider"], [360, "the"], [360, "risk"], [360, "of"], [360, "false"], [360, "-"], [360, "positive"], [360, "and"], [360, "false"], [360, "-"], [360, "negative"], [360, "diagnosis"], [360, ","], [360, "and"], [360, "the"], [360, "ease"], [360, "by"], [360, "which"], [360, "each"], [360, "type"], [360, "of"], [360, "diagnostic"], [360, "error"], [360, "can"], [360, "be"], [360, "correct"], [360, "by"], [360, "longitudinal"], [360, "observation"], [360, "."], [361, "bipolar"], [361, "disorder"], [361, "be"], [361, "an"], [361, "affective"], [361, "or"], [361, "mood"], [361, "disorder"], [361, "that"], [361, "affect"], [361, "child"], [361, "and"], [361, "adolescent"], [361, "as"], [361, "well"], [361, "as"], [361, "adult"], [361, "."], [362, "originally"], [362, "think"], [362, "to"], [362, "be"], [362, "rare"], [362, "in"], [362, "childhood"], [362, ","], [362, "this"], [362, "disorder"], [362, "be"], [362, "now"], [362, "diagnose"], [362, "even"], [362, "in"], [362, "the"], [362, "prepubertal"], [362, "age"], [362, "group"], [362, "."], [363, "with"], [363, "pediatrician"], [363, "provide"], [363, "health"], [363, "care"], [363, "for"], [363, "the"], [363, "majority"], [363, "of"], [363, "child"], [363, "and"], [363, "adolescent"], [363, ","], [363, "these"], [363, "physician"], [363, "will"], [363, "see"], [363, "the"], [363, "child"], [363, "early"], [363, "in"], [363, "their"], [363, "presentation"], [363, "with"], [363, "affective"], [363, "disorder"], [363, "."], [364, "this"], [364, "review"], [364, "focus"], [364, "on"], [364, "the"], [364, "early"], [364, "recognition"], [364, "of"], [364, "child"], [364, "with"], [364, "bipolar"], [364, "disorder"], [364, "or"], [364, "child"], [364, "who"], [364, "be"], [364, "at"], [364, "increase"], [364, "risk"], [364, "of"], [364, "develop"], [364, "mania"], [364, "."], [365, "early"], [365, "recognition"], [365, "can"], [365, "lead"], [365, "to"], [365, "early"], [365, "treatment"], [365, "and"], [365, "reduce"], [365, "both"], [365, "short-"], [365, "and"], [365, "long"], [365, "-"], [365, "term"], [365, "morbidity"], [365, "and"], [365, "mortality"], [365, "."], [366, "this"], [366, "review"], [366, "cover"], [366, "the"], [366, "definition"], [366, ","], [366, "epidemiology"], [366, ","], [366, "presentation"], [366, "and"], [366, "differential"], [366, "diagnosis"], [366, ","], [366, "comorbid"], [366, "diagnosis"], [366, ","], [366, "precipitant"], [366, ","], [366, "risk"], [366, "factor"], [366, ","], [366, "treatment"], [366, ","], [366, "and"], [366, "outcome"], [366, "."], [367, "bipolar"], [367, "illness"], [367, "be"], [367, "a"], [367, "serious"], [367, "heritable"], [367, "mood"], [367, "disorder"], [367, "characterize"], [367, "by"], [367, "recurrent"], [367, "episode"], [367, "of"], [367, "depression"], [367, "and"], [367, "mania"], [367, "."], [368, "the"], [368, "mean"], [368, "age"], [368, "of"], [368, "onset"], [368, "be"], [368, "under"], [368, "25"], [368, "year"], [368, "of"], [368, "age"], [368, ","], [368, "but"], [368, "the"], [368, "period"], [368, "of"], [368, "risk"], [368, "extend"], [368, "from"], [368, "prepuberty"], [368, "to"], [368, "senescence"], [368, "."], [369, "fifteen"], [369, "percent"], [369, "of"], [369, "person"], [369, "with"], [369, "the"], [369, "disorder"], [369, "commit"], [369, "suicide"], [369, "."], [370, "bipolar"], [370, "disorder"], [370, "carry"], [370, "an"], [370, "increase"], [370, "risk"], [370, "of"], [370, "cardiovascular"], [370, "disease"], [370, "."], [371, "despite"], [371, "the"], [371, "fact"], [371, "that"], [371, "the"], [371, "nosologic"], [371, "position"], [371, "of"], [371, "bipolar"], [371, "ii"], [371, "disorder"], [371, "continue"], [371, "to"], [371, "be"], [371, "debate"], [371, ","], [371, "several"], [371, "line"], [371, "of"], [371, "research"], [371, "indicate"], [371, "that"], [371, "it"], [371, "be"], [371, "a"], [371, "distinct"], [371, "nosologic"], [371, "category"], [371, "that"], [371, "should"], [371, "be"], [371, "separate"], [371, "from"], [371, "both"], [371, "bipolar"], [371, "i"], [371, "and"], [371, "unipolar"], [371, "major"], [371, "depression"], [371, "."], [372, "this"], [372, "review"], [372, "of"], [372, "the"], [372, "author"], [372, "'"], [372, "and"], [372, "other"], [372, "'"], [372, "work"], [372, "demonstrate"], [372, "that"], [372, "the"], [372, "lifetime"], [372, "risk"], [372, "of"], [372, "suicide"], [372, "attempt"], [372, "be"], [372, "high"], [372, "in"], [372, "bipolar"], [372, "ii"], [372, "and"], [372, "low"], [372, "in"], [372, "unipolar"], [372, "patient"], [372, ","], [372, "whereas"], [372, "risk"], [372, "be"], [372, "intermediate"], [372, "in"], [372, "bipolar"], [372, "i"], [372, "patient"], [372, "."], [373, "moreover"], [373, ","], [373, "two"], [373, "report"], [373, "show"], [373, "that"], [373, "bipolar"], [373, "ii"], [373, "patient"], [373, "be"], [373, "over"], [373, "represent"], [373, "among"], [373, "suicide"], [373, "victim"], [373, "."], [374, "clinician"], [374, "must"], [374, "take"], [374, "great"], [374, "care"], [374, "in"], [374, "not"], [374, "miss"], [374, "this"], [374, "diagnosis"], [374, ","], [374, "which"], [374, ","], [374, "when"], [374, "untreated"], [374, ","], [374, "have"], [374, "ominous"], [374, "prognostic"], [374, "implication"], [374, "."], [375, "bipolar"], [375, "disorder"], [375, "be"], [375, "a"], [375, "brain"], [375, "illness"], [375, "with"], [375, "complexity"], [375, "in"], [375, "its"], [375, "composition"], [375, "and"], [375, "treatment"], [375, "."], [376, "result"], [376, "from"], [376, "the"], [376, "national"], [376, "comorbidity"], [376, "survey"], [376, "replication"], [376, "study"], [376, "estimate"], [376, "the"], [376, "lifetime"], [376, "prevalence"], [376, "of"], [376, "bipolar"], [376, "spectrum"], [376, "illness"], [376, "to"], [376, "be"], [376, "4.5"], [376, "%"], [376, "."], [377, "these"], [377, "patient"], [377, "be"], [377, "also"], [377, "report"], [377, "to"], [377, "have"], [377, "their"], [377, "illness"], [377, "frequently"], [377, "treat"], [377, "suboptimally"], [377, "and"], [377, "to"], [377, "be"], [377, "at"], [377, "risk"], [377, "of"], [377, "suffer"], [377, "extensive"], [377, "disability"], [377, "."], [378, "pharmacist"], [378, "be"], [378, "in"], [378, "a"], [378, "key"], [378, "position"], [378, "to"], [378, "deliver"], [378, "important"], [378, "pharmacy"], [378, "care"], [378, "service"], [378, "to"], [378, "patient"], [378, "who"], [378, "have"], [378, "bipolar"], [378, "disorder"], [378, "and"], [378, "receive"], [378, "treatment"], [378, "in"], [378, "need"], [378, "of"], [378, "close"], [378, "monitoring"], [378, "."], [379, "describe"], [379, "here"], [379, "be"], [379, "the"], [379, "result"], [379, "of"], [379, "this"], [379, "study"], [379, "and"], [379, "opportunity"], [379, "for"], [379, "pharmacist"], [379, "to"], [379, "support"], [379, "this"], [379, "important"], [379, "patient"], [379, "population"], [379, "."], [380, "bipolar"], [380, "disorder"], [380, "be"], [380, "a"], [380, "multifactorial"], [380, "psychiatric"], [380, "disorder"], [380, "with"], [380, "developmental"], [380, "and"], [380, "progressive"], [380, "neurophysiological"], [380, "alteration"], [380, "."], [381, "this"], [381, "disorder"], [381, "be"], [381, "typically"], [381, "characterize"], [381, "by"], [381, "cyclical"], [381, "and"], [381, "recurrent"], [381, "episode"], [381, "of"], [381, "mania"], [381, "and"], [381, "depression"], [381, "but"], [381, "be"], [381, "heterogeneous"], [381, "in"], [381, "its"], [381, "clinical"], [381, "presentation"], [381, "and"], [381, "outcome"], [381, "."], [382, "although"], [382, "the"], [382, "dsm"], [382, "-"], [382, "iv"], [382, "-"], [382, "tr"], [382, "criterion"], [382, "identify"], [382, "several"], [382, "feature"], [382, "that"], [382, "be"], [382, "of"], [382, "phenomenological"], [382, "relevance"], [382, ","], [382, "these"], [382, "be"], [382, "of"], [382, "less"], [382, "utility"], [382, "for"], [382, "define"], [382, "homogeneous"], [382, "subgroup"], [382, ","], [382, "for"], [382, "analysis"], [382, "of"], [382, "correlation"], [382, "with"], [382, "biomarker"], [382, "or"], [382, "for"], [382, "direct"], [382, "focused"], [382, "medication"], [382, "strategy"], [382, "."], [383, "we"], [383, "provide"], [383, "a"], [383, "comprehensive"], [383, "review"], [383, "of"], [383, "exist"], [383, "evidence"], [383, "regard"], [383, "to"], [383, "age"], [383, "at"], [383, "onset"], [383, "in"], [383, "bipolar"], [383, "disorder"], [383, "."], [384, "eight"], [384, "admixture"], [384, "study"], [384, "demonstrate"], [384, "three"], [384, "homogeneous"], [384, "subgroup"], [384, "of"], [384, "patient"], [384, "with"], [384, "bipolar"], [384, "disorder"], [384, "identify"], [384, "accord"], [384, "to"], [384, "age"], [384, "at"], [384, "onset"], [384, "("], [384, "early"], [384, ","], [384, "intermediate"], [384, "and"], [384, "late"], [384, "age"], [384, "at"], [384, "onset"], [384, ")"], [384, ","], [384, "with"], [384, "two"], [384, "cutoff"], [384, "point"], [384, ","], [384, "at"], [384, "21"], [384, "and"], [384, "34"], [384, "year"], [384, "."], [385, "it"], [385, "be"], [385, "suggest"], [385, "that"], [385, "the"], [385, "early"], [385, "-"], [385, "onset"], [385, "subgroup"], [385, "have"], [385, "specific"], [385, "clinical"], [385, "feature"], [385, "and"], [385, "outcome"], [385, "different"], [385, "from"], [385, "those"], [385, "of"], [385, "the"], [385, "other"], [385, "subgroup"], [385, "."], [386, "early"], [386, "-"], [386, "onset"], [386, "subgroup"], [386, "may"], [386, "be"], [386, "consider"], [386, "a"], [386, "more"], [386, "suitable"], [386, "clinical"], [386, "phenotype"], [386, "for"], [386, "the"], [386, "identification"], [386, "of"], [386, "susceptibility"], [386, "gene"], [386, "with"], [386, "recent"], [386, "datum"], [386, "demonstrate"], [386, "association"], [386, "with"], [386, "genetic"], [386, "variant"], [386, "specifically"], [386, "in"], [386, "this"], [386, "subgroup"], [386, "."], [387, "the"], [387, "use"], [387, "of"], [387, "age"], [387, "at"], [387, "onset"], [387, "as"], [387, "a"], [387, "specifi"], [387, "may"], [387, "also"], [387, "facilitate"], [387, "the"], [387, "identification"], [387, "of"], [387, "other"], [387, "biological"], [387, "marker"], [387, "for"], [387, "use"], [387, "in"], [387, "brain"], [387, "imaging"], [387, ","], [387, "circadian"], [387, ","], [387, "inflammatory"], [387, "and"], [387, "cognitive"], [387, "research"], [387, "."], [388, "a"], [388, "key"], [388, "challenge"], [388, "be"], [388, "pose"], [388, "by"], [388, "the"], [388, "use"], [388, "of"], [388, "age"], [388, "at"], [388, "onset"], [388, "in"], [388, "treatment"], [388, "decision"], [388, "algorithm"], [388, ","], [388, "although"], [388, "further"], [388, "research"], [388, "be"], [388, "require"], [388, "to"], [388, "increase"], [388, "the"], [388, "evidence"], [388, "-"], [388, "base"], [388, "."], [389, "we"], [389, "discuss"], [389, "three"], [389, "potential"], [389, "benefit"], [389, "of"], [389, "specify"], [389, "age"], [389, "at"], [389, "onset"], [389, ","], [389, "namely"], [389, ":"], [389, "focus"], [389, "medication"], [389, "strategy"], [389, ","], [389, "the"], [389, "target"], [389, "prevention"], [389, "of"], [389, "specific"], [389, "comorbid"], [389, "condition"], [389, "and"], [389, "decrease"], [389, "the"], [389, "duration"], [389, "of"], [389, "untreated"], [389, "illness"], [389, "."], [390, "we"], [390, "argue"], [390, "that"], [390, "age"], [390, "at"], [390, "onset"], [390, "should"], [390, "be"], [390, "include"], [390, "as"], [390, "a"], [390, "specifi"], [390, "for"], [390, "bipolar"], [390, "disorder"], [390, "."], [391, "to"], [391, "provide"], [391, "a"], [391, "historical"], [391, "review"], [391, "of"], [391, "childhood"], [391, "depression"], [391, "and"], [391, "bipolar"], [391, "disorder"], [391, ","], [391, "cover"], [391, "concept"], [391, ","], [391, "diagnostic"], [391, "category"], [391, ","], [391, "epidemiology"], [391, ","], [391, "genetic"], [391, "and"], [391, "neurobiological"], [391, "aspect"], [391, "as"], [391, "well"], [391, "as"], [391, "predispose"], [391, "factor"], [391, "and"], [391, "treatment"], [391, "modality"], [391, "."], [392, "extensive"], [392, "review"], [392, "of"], [392, "the"], [392, "literature"], [392, "on"], [392, "child"], [392, "depression"], [392, "and"], [392, "bipolar"], [392, "disorder"], [392, "."], [393, "child"], [393, "depression"], [393, "and"], [393, "bipolar"], [393, "disorder"], [393, "be"], [393, "associate"], [393, "with"], [393, "genetic"], [393, "factor"], [393, ","], [393, "mood"], [393, ","], [393, "adverse"], [393, "life"], [393, "event"], [393, ","], [393, "divorce"], [393, ","], [393, "academic"], [393, "problem"], [393, ","], [393, "physical"], [393, "and"], [393, "sexual"], [393, "abuse"], [393, ","], [393, "and"], [393, "neurobiological"], [393, "factor"], [393, "."], [394, "treatment"], [394, "usually"], [394, "include"], [394, "medication"], [394, "and"], [394, "psychotherapy"], [394, "."], [395, "these"], [395, "be"], [395, "important"], [395, "childhood"], [395, "disorder"], [395, "whose"], [395, "diagnosis"], [395, "be"], [395, "often"], [395, "difficult"], [395, "."], [396, "the"], [396, "identification"], [396, "and"], [396, "treatment"], [396, "of"], [396, "depression"], [396, "and"], [396, "bipolar"], [396, "disorder"], [396, "reduce"], [396, "the"], [396, "suffering"], [396, "of"], [396, "affect"], [396, "child"], [396, "and"], [396, "adolescent"], [396, "."], [397, "the"], [397, "pediatrician"], [397, "can"], [397, "intervene"], [397, "by"], [397, "orient"], [397, "the"], [397, "family"], [397, "in"], [397, "mild"], [397, "case"], [397, ","], [397, "but"], [397, "must"], [397, "be"], [397, "alert"], [397, "to"], [397, "case"], [397, "require"], [397, "more"], [397, "aggressive"], [397, "treatment"], [397, "."], [398, "the"], [398, "presentation"], [398, "of"], [398, "bipolar"], [398, "disorder"], [398, "in"], [398, "child"], [398, "and"], [398, "adolescent"], [398, "may"], [398, "vary"], [398, "from"], [398, "its"], [398, "presentation"], [398, "in"], [398, "adult"], [398, "."], [399, "rage"], [399, ","], [399, "irritability"], [399, ","], [399, "and"], [399, "long"], [399, "episode"], [399, "be"], [399, "common"], [399, "manifestation"], [399, "of"], [399, "mania"], [399, "in"], [399, "young"], [399, "people"], [399, "with"], [399, "bipolar"], [399, "disorder"], [399, "."], [400, "frequent"], [400, "comorbid"], [400, "disorder"], [400, "in"], [400, "young"], [400, "patient"], [400, "include"], [400, "adhd"], [400, "and"], [400, "anxiety"], [400, "disorder"], [400, "."], [401, "prodromal"], [401, "and"], [401, "subsyndromal"], [401, "state"], [401, "of"], [401, "bipolar"], [401, "disorder"], [401, ","], [401, "such"], [401, "as"], [401, "bipolar"], [401, "disorder"], [401, "nos"], [401, ","], [401, "present"], [401, "opportunity"], [401, "for"], [401, "early"], [401, "intervention"], [401, "and"], [401, "prevention"], [401, "."], [402, "early"], [402, "recognition"], [402, "and"], [402, "intervention"], [402, "be"], [402, "crucial"], [402, ","], [402, "because"], [402, "untreated"], [402, "pediatric"], [402, "bipolar"], [402, "disorder"], [402, "become"], [402, "chronic"], [402, ","], [402, "have"], [402, "a"], [402, "high"], [402, "incidence"], [402, "of"], [402, "relapse"], [402, ","], [402, "and"], [402, "have"], [402, "a"], [402, "poor"], [402, "prognosis"], [402, "."], [403, "this"], [403, "article"], [403, "review"], [403, "juvenile"], [403, "onset"], [403, "bipolar"], [403, "disorder"], [403, "with"], [403, "regard"], [403, "to"], [403, "history"], [403, ","], [403, "diagnosis"], [403, ","], [403, "comorbidity"], [403, ","], [403, "differential"], [403, "diagnosis"], [403, ","], [403, "prevalence"], [403, ","], [403, "etiology"], [403, ","], [403, "treatment"], [403, ","], [403, "and"], [403, "outcome"], [403, "."], [404, "specifically"], [404, ","], [404, "it"], [404, "deal"], [404, "with"], [404, "past"], [404, "and"], [404, "current"], [404, "diagnostic"], [404, "criterion"], [404, "for"], [404, "juvenile"], [404, "onset"], [404, "bipolar"], [404, "disorder"], [404, ","], [404, "the"], [404, "controversy"], [404, "around"], [404, "its"], [404, "comorbidity"], [404, "with"], [404, "attention"], [404, "deficit"], [404, "hyperactivity"], [404, "disorder"], [404, "("], [404, "adhd"], [404, ")"], [404, ","], [404, "and"], [404, "how"], [404, "to"], [404, "differentiate"], [404, "it"], [404, "from"], [404, "adhd"], [404, ","], [404, "conduct"], [404, "disorder"], [404, ","], [404, "drug"], [404, "and"], [404, "alcohol"], [404, "abuse"], [404, ","], [404, "and"], [404, "schizophrenia"], [404, ","], [404, "genetic"], [404, "and"], [404, "neuroimaging"], [404, "study"], [404, "investigate"], [404, "the"], [404, "possible"], [404, "etiology"], [404, "of"], [404, "this"], [404, "condition"], [404, "be"], [404, "also"], [404, "describe"], [404, "."], [405, "treatment"], [405, ","], [405, "both"], [405, "pharmacological"], [405, "("], [405, "eg"], [405, ","], [405, "lithium"], [405, ","], [405, "neuroleptic"], [405, ","], [405, "anticonvulsant"], [405, ","], [405, "benzodiazepine"], [405, ","], [405, "antidepressant"], [405, ")"], [405, "and"], [405, "psychosocial"], [405, "("], [405, "eg"], [405, ","], [405, "psychoeducation"], [405, "of"], [405, "child"], [405, "and"], [405, "family"], [405, ","], [405, "school"], [405, "intervention"], [405, ","], [405, "family"], [405, ","], [405, "group"], [405, "and/or"], [405, "individual"], [405, "therapy"], [405, ")"], [405, "be"], [405, "outline"], [405, "."], [406, "finally"], [406, ","], [406, "long"], [406, "-"], [406, "term"], [406, "outcome"], [406, "and"], [406, "factor"], [406, "which"], [406, "may"], [406, "influence"], [406, "outcome"], [406, "be"], [406, "address"], [406, "."], [407, "to"], [407, "identify"], [407, "and"], [407, "describe"], [407, "the"], [407, "complexity"], [407, "of"], [407, "diagnose"], [407, "bipolar"], [407, "disorder"], [407, ","], [407, "include"], [407, "the"], [407, "diagnostic"], [407, "process"], [407, "and"], [407, "patient"], [407, "experience"], [407, "of"], [407, "be"], [407, "newly"], [407, "diagnose"], [407, "with"], [407, "bipolar"], [407, "disorder"], [407, "."], [408, "a"], [408, "mix"], [408, "-"], [408, "method"], [408, "focused"], [408, "ethnography"], [408, "be"], [408, "conduct"], [408, ","], [408, "grind"], [408, "in"], [408, "a"], [408, "post"], [408, "-"], [408, "positivist"], [408, "foundation"], [408, "."], [409, "medical"], [409, "record"], [409, "("], [409, "\u2009"], [409, "="], [409, "\u2009"], [409, "100"], [409, ")"], [409, "of"], [409, "patient"], [409, "whose"], [409, "diagnosis"], [409, "have"], [409, "be"], [409, "switch"], [409, "to"], [409, "bipolar"], [409, "disorder"], [409, "be"], [409, "examine"], [409, "."], [410, "six"], [410, "week"], [410, "post"], [410, "-"], [410, "hospitalization"], [410, ","], [410, "ten"], [410, "outpatient"], [410, "with"], [410, "the"], [410, "diagnosis"], [410, "of"], [410, "bipolar"], [410, "disorder"], [410, "undergo"], [410, "an"], [410, "in"], [410, "-"], [410, "depth"], [410, "interview"], [410, "."], [411, "four"], [411, "diagnostic"], [411, "process"], [411, "be"], [411, "identify"], [411, "during"], [411, "the"], [411, "retrospective"], [411, "record"], [411, "review"], [411, "."], [412, "two"], [412, "pattern"], [412, "and"], [412, "five"], [412, "theme"], [412, "be"], [412, "identify"], [412, "from"], [412, "the"], [412, "interview"], [412, "."], [413, "the"], [413, "first"], [413, "pattern"], [413, ","], [413, "live"], [413, "with"], [413, "undiagnosed"], [413, "bipolar"], [413, "disorder"], [413, ","], [413, "demonstrate"], [413, "common"], [413, "experience"], [413, "of"], [413, "distinguish"], [413, "impulsive"], [413, "mood"], [413, "and"], [413, "behavior"], [413, ","], [413, "suffer"], [413, "life"], [413, "challenge"], [413, ","], [413, "and"], [413, "seek"], [413, "relief"], [413, "."], [414, "the"], [414, "second"], [414, "pattern"], [414, ","], [414, "acclimate"], [414, "to"], [414, "a"], [414, "new"], [414, "diagnosis"], [414, "of"], [414, "bipolar"], [414, "disorder"], [414, ","], [414, "demonstrate"], [414, "participant"], [414, "'"], [414, "way"], [414, "of"], [414, "understand"], [414, "the"], [414, "diagnosis"], [414, "and"], [414, "reconcile"], [414, "the"], [414, "diagnosis"], [414, "."], [415, "pattern"], [415, "in"], [415, "the"], [415, "interview"], [415, "corroborate"], [415, "datum"], [415, "from"], [415, "the"], [415, "record"], [415, "review"], [415, "."], [416, "the"], [416, "rendering"], [416, "of"], [416, "an"], [416, "appropriate"], [416, "diagnosis"], [416, "be"], [416, "key"], [416, "."], [417, "many"], [417, "participant"], [417, "'"], [417, "life"], [417, "be"], [417, "significantly"], [417, "improve"], [417, "when"], [417, "diagnosis"], [417, "be"], [417, "make"], [417, ","], [417, "and"], [417, "treatment"], [417, "recommendation"], [417, "for"], [417, "bipolar"], [417, "disorder"], [417, "("], [417, "bpd"], [417, ")"], [417, "be"], [417, "initiate"], [417, "."], [418, "these"], [418, "finding"], [418, "offer"], [418, "clinician"], [418, "and"], [418, "researcher"], [418, "new"], [418, "way"], [418, "to"], [418, "think"], [418, "about"], [418, "the"], [418, "complexity"], [418, "of"], [418, "the"], [418, "diagnosis"], [418, "of"], [418, "bpd"], [418, "include"], [418, "contrast"], [418, "decision"], [418, "-"], [418, "make"], [418, "outcome"], [418, "along"], [418, "a"], [418, "screening"], [418, ","], [418, "diagnosis"], [418, ","], [418, "and"], [418, "treatment"], [418, "continuum"], [418, ","], [418, "as"], [418, "well"], [418, "as"], [418, "use"], [418, "the"], [418, "diagnostic"], [418, "event"], [418, "to"], [418, "instigate"], [418, "meaningful"], [418, "life"], [418, "change"], [418, "in"], [418, "the"], [418, "patient"], [418, "."], [419, "there"], [419, "have"], [419, "be"], [419, "major"], [419, "advance"], [419, "in"], [419, "clinical"], [419, "understanding"], [419, "and"], [419, "treatment"], [419, "of"], [419, "bipolar"], [419, "disorder"], [419, "over"], [419, "the"], [419, "past"], [419, "decade"], [419, "."], [420, "randomise"], [420, "control"], [420, "trial"], [420, "of"], [420, "pharmacological"], [420, "treatment"], [420, "and"], [420, "psychological"], [420, "intervention"], [420, "have"], [420, "show"], [420, "that"], [420, "there"], [420, "be"], [420, "effective"], [420, "short"], [420, "-"], [420, "term"], [420, "and"], [420, "long"], [420, "-"], [420, "term"], [420, "treatment"], [420, "for"], [420, "the"], [420, "disorder"], [420, "."], [421, "despite"], [421, "advance"], [421, "in"], [421, "treatment"], [421, ","], [421, "diagnosis"], [421, "be"], [421, "often"], [421, "delay"], [421, "or"], [421, "mistaken"], [421, ","], [421, "and"], [421, "many"], [421, "people"], [421, "who"], [421, "could"], [421, "benefit"], [421, "be"], [421, "not"], [421, "use"], [421, "the"], [421, "treatment"], [421, "available"], [421, "."], [422, "functional"], [422, "and"], [422, "symptomatic"], [422, "recovery"], [422, "from"], [422, "episode"], [422, "of"], [422, "bipolar"], [422, "disorder"], [422, "be"], [422, "frequently"], [422, "less"], [422, "complete"], [422, "than"], [422, "previously"], [422, "consider"], [422, ","], [422, "and"], [422, "disability"], [422, "be"], [422, "often"], [422, "profound"], [422, "."], [423, "although"], [423, "manic"], [423, "episode"], [423, "be"], [423, "the"], [423, "distinguish"], [423, "feature"], [423, "of"], [423, "bipolar"], [423, "disorder"], [423, ","], [423, "it"], [423, "appear"], [423, "that"], [423, "depression"], [423, "be"], [423, "the"], [423, "predominant"], [423, "mood"], [423, "disturbance"], [423, "and"], [423, "that"], [423, "much"], [423, "of"], [423, "the"], [423, "functional"], [423, "impairment"], [423, "associate"], [423, "with"], [423, "bipolar"], [423, "disorder"], [423, "result"], [423, "from"], [423, "this"], [423, "."], [424, "comorbidity"], [424, "with"], [424, "anxiety"], [424, "disorder"], [424, "or"], [424, "substance"], [424, "misuse"], [424, "be"], [424, "common"], [424, "."], [425, "advance"], [425, "in"], [425, "genetic"], [425, ","], [425, "brain"], [425, "imaging"], [425, "and"], [425, "basic"], [425, "pharmacology"], [425, "be"], [425, "start"], [425, "to"], [425, "provide"], [425, "understanding"], [425, "of"], [425, "the"], [425, "complex"], [425, "causative"], [425, "process"], [425, "."], [426, "although"], [426, "awareness"], [426, "on"], [426, "bipolar"], [426, "disorder"], [426, "have"], [426, "increase"], [426, "during"], [426, "the"], [426, "last"], [426, "decade"], [426, ","], [426, "this"], [426, "condition"], [426, "remain"], [426, "characterize"], [426, "by"], [426, "a"], [426, "disable"], [426, "burden"], [426, ","], [426, "in"], [426, "term"], [426, "of"], [426, "morbidity"], [426, "and"], [426, "functional"], [426, "impairment"], [426, "."], [427, "this"], [427, "paper"], [427, "aim"], [427, "to"], [427, "review"], [427, "some"], [427, "critical"], [427, "issue"], [427, "in"], [427, "the"], [427, "current"], [427, "knowledge"], [427, "on"], [427, "bipolar"], [427, "disorder"], [427, "."], [428, "although"], [428, "large"], [428, "european"], [428, "epidemiological"], [428, "study"], [428, "be"], [428, "lack"], [428, ","], [428, "bipolar"], [428, "disorder"], [428, "be"], [428, "characterize"], [428, "by"], [428, "a"], [428, "set"], [428, "of"], [428, "severe"], [428, "feature"], [428, ","], [428, "include"], [428, "an"], [428, "early"], [428, "age"], [428, "of"], [428, "onset"], [428, ","], [428, "a"], [428, "chronic"], [428, "outcome"], [428, "and"], [428, "an"], [428, "important"], [428, "suicidal"], [428, "risk"], [428, "."], [429, "a"], [429, "majority"], [429, "of"], [429, "bipolar"], [429, "patient"], [429, "also"], [429, "experience"], [429, "a"], [429, "comorbid"], [429, "axis"], [429, "i"], [429, "condition"], [429, ","], [429, "include"], [429, "substance"], [429, "abuse"], [429, ","], [429, "anxiety"], [429, "disorder"], [429, "and"], [429, "attention"], [429, "-"], [429, "deficit"], [429, "hyperactivity"], [429, "disorder"], [429, "."], [430, "this"], [430, "situation"], [430, "present"], [430, "a"], [430, "therapeutic"], [430, "challenge"], [430, ","], [430, "since"], [430, "antidepressant"], [430, "or"], [430, "methylphenidate"], [430, "may"], [430, "be"], [430, "associate"], [430, "with"], [430, "the"], [430, "risk"], [430, "of"], [430, "induce"], [430, "mania"], [430, "."], [431, "recently"], [431, ","], [431, "a"], [431, "large"], [431, "number"], [431, "of"], [431, "study"], [431, "have"], [431, "provide"], [431, "evidence"], [431, "for"], [431, "the"], [431, "efficacy"], [431, "of"], [431, "new"], [431, "compound"], [431, "in"], [431, "the"], [431, "treatment"], [431, "of"], [431, "both"], [431, "mania"], [431, "and"], [431, "bipolar"], [431, "depression"], [431, ","], [431, "but"], [431, "also"], [431, "in"], [431, "long"], [431, "-"], [431, "term"], [431, "relapse"], [431, "prevention"], [431, "."], [432, "recent"], [432, "research"], [432, "have"], [432, "also"], [432, "allow"], [432, "for"], [432, "the"], [432, "redefinition"], [432, "of"], [432, "the"], [432, "concept"], [432, "of"], [432, "mood"], [432, "stabilizer"], [432, "and"], [432, "for"], [432, "improve"], [432, "exist"], [432, "guideline"], [432, "on"], [432, "the"], [432, "clinical"], [432, "management"], [432, "of"], [432, "bipolar"], [432, "disorder"], [432, "."], [433, "the"], [433, "objective"], [433, "of"], [433, "this"], [433, "article"], [433, "be"], [433, "to"], [433, "discuss"], [433, "the"], [433, "rationale"], [433, "/"], [433, "background"], [433, "for"], [433, "early"], [433, "intervention"], [433, "in"], [433, "bipolar"], [433, "disorder"], [433, "."], [434, "narrative"], [434, "review"], [434, "."], [435, "there"], [435, "be"], [435, "often"], [435, "significant"], [435, "delay"], [435, "before"], [435, "the"], [435, "diagnosis"], [435, "of"], [435, "bipolar"], [435, "disorder"], [435, "be"], [435, "make"], [435, "and"], [435, "effective"], [435, "management"], [435, "initiate"], [435, "."], [436, "grow"], [436, "evidence"], [436, "from"], [436, "both"], [436, "preclinical"], [436, "and"], [436, "clinical"], [436, "literature"], [436, "point"], [436, "to"], [436, "a"], [436, "clear"], [436, "need"], [436, "for"], [436, "improved"], [436, "early"], [436, "identification"], [436, "and"], [436, "early"], [436, "intervention"], [436, "in"], [436, "bipolar"], [436, "disorder"], [436, "."], [437, "increase"], [437, "effort"], [437, "be"], [437, "be"], [437, "apply"], [437, "to"], [437, "the"], [437, "identification"], [437, "of"], [437, "those"], [437, "at"], [437, "high"], [437, "risk"], [437, "of"], [437, "onset"], [437, "of"], [437, "bipolar"], [437, "disorder"], [437, "."], [438, "it"], [438, "be"], [438, "hope"], [438, "that"], [438, "identification"], [438, "of"], [438, "an"], [438, "early"], [438, "prodrome"], [438, "of"], [438, "illness"], [438, "will"], [438, "allow"], [438, "preventative"], [438, "measure"], [438, "to"], [438, "be"], [438, "take"], [438, "."], [439, "there"], [439, "be"], [439, "a"], [439, "clear"], [439, "rationale"], [439, "for"], [439, "improved"], [439, "early"], [439, "identification"], [439, "and"], [439, "early"], [439, "intervention"], [439, "in"], [439, "bipolar"], [439, "disorder"], [439, "."], [440, "bipolar"], [440, "disease"], [440, "be"], [440, "often"], [440, "misdiagnose"], [440, ","], [440, "sometimes"], [440, "repeatedly"], [440, "."], [441, "the"], [441, "screening"], [441, "tool"], [441, "and"], [441, "tip"], [441, "you"], [441, "'ll"], [441, "find"], [441, "here"], [441, "will"], [441, "help"], [441, "you"], [441, "identify"], [441, "patient"], [441, "without"], [441, "delay"], [441, "."], [442, "the"], [442, "aim"], [442, "of"], [442, "the"], [442, "present"], [442, "study"], [442, "be"], [442, "to"], [442, "characterize"], [442, "the"], [442, "neurocognitive"], [442, "effect"], [442, "of"], [442, "lithium"], [442, "in"], [442, "bipolar"], [442, "disorder"], [442, "to"], [442, "inform"], [442, "clinical"], [442, "and"], [442, "research"], [442, "approach"], [442, "for"], [442, "further"], [442, "investigation"], [442, "."], [443, "key"], [443, "word"], [443, "pertain"], [443, "to"], [443, "neurocognition"], [443, "in"], [443, "bipolar"], [443, "disorder"], [443, "and"], [443, "lithium"], [443, "treatment"], [443, "be"], [443, "use"], [443, "to"], [443, "search"], [443, "recognize"], [443, "database"], [443, "to"], [443, "identify"], [443, "relevant"], [443, "literature"], [443, "."], [444, "the"], [444, "author"], [444, "also"], [444, "retrieve"], [444, "gray"], [444, "literature"], [444, "("], [444, "e.g."], [444, ","], [444, "book"], [444, "chapter"], [444, ")"], [444, "know"], [444, "to"], [444, "they"], [444, "and"], [444, "examine"], [444, "pertinent"], [444, "article"], [444, "from"], [444, "bibliography"], [444, "."], [445, "a"], [445, "limited"], [445, "number"], [445, "of"], [445, "study"], [445, "have"], [445, "examine"], [445, "the"], [445, "effect"], [445, "of"], [445, "lithium"], [445, "on"], [445, "neurocognition"], [445, "in"], [445, "bipolar"], [445, "disorder"], [445, "and"], [445, ","], [445, "although"], [445, "in"], [445, "some"], [445, "domain"], [445, "a"], [445, "consistent"], [445, "picture"], [445, "emerge"], [445, ","], [445, "in"], [445, "many"], [445, "domain"], [445, "the"], [445, "finding"], [445, "be"], [445, "mixed"], [445, "."], [446, "lithium"], [446, "administration"], [446, "appear"], [446, "to"], [446, "reshape"], [446, "key"], [446, "component"], [446, "of"], [446, "neurocognition"], [446, "-"], [446, "in"], [446, "particular"], [446, ","], [446, "psychomotor"], [446, "speed"], [446, ","], [446, "verbal"], [446, "memory"], [446, ","], [446, "and"], [446, "verbal"], [446, "fluency"], [446, "."], [447, "notably"], [447, ","], [447, "it"], [447, "have"], [447, "a"], [447, "sophisticated"], [447, "neurocognitive"], [447, "profile"], [447, ","], [447, "such"], [447, "that"], [447, "while"], [447, "lithium"], [447, "impairs"], [447, "neurocognition"], [447, "across"], [447, "some"], [447, "domain"], [447, ","], [447, "it"], [447, "seemingly"], [447, "preserve"], [447, "other"], [447, "-"], [447, "possibly"], [447, "those"], [447, "vulnerable"], [447, "to"], [447, "the"], [447, "effect"], [447, "of"], [447, "bipolar"], [447, "disorder"], [447, "."], [448, "furthermore"], [448, ","], [448, "its"], [448, "effect"], [448, "be"], [448, "likely"], [448, "to"], [448, "be"], [448, "direct"], [448, "and"], [448, "indirect"], [448, "("], [448, "via"], [448, "mood"], [448, ","], [448, "for"], [448, "example"], [448, ")"], [448, "and"], [448, "cumulative"], [448, "with"], [448, "duration"], [448, "of"], [448, "treatment"], [448, "."], [449, "disentangle"], [449, "the"], [449, "component"], [449, "of"], [449, "neurocognition"], [449, "modulate"], [449, "by"], [449, "lithium"], [449, "in"], [449, "the"], [449, "context"], [449, "of"], [449, "a"], [449, "fluctuating"], [449, "and"], [449, "complex"], [449, "illness"], [449, "such"], [449, "as"], [449, "bipolar"], [449, "disorder"], [449, "be"], [449, "a"], [449, "significant"], [449, "challenge"], [449, "but"], [449, "one"], [449, "that"], [449, "therefore"], [449, "demand"], [449, "a"], [449, "stratified"], [449, "and"], [449, "systematic"], [449, "approach"], [449, ","], [449, "such"], [449, "as"], [449, "that"], [449, "provide"], [449, "by"], [449, "the"], [449, "lithium"], [449, "battery"], [449, "."], [450, "in"], [450, "order"], [450, "to"], [450, "delineate"], [450, "the"], [450, "effect"], [450, "of"], [450, "lithium"], [450, "therapy"], [450, "on"], [450, "neurocognition"], [450, "in"], [450, "bipolar"], [450, "disorder"], [450, "within"], [450, "both"], [450, "research"], [450, "and"], [450, "clinical"], [450, "practice"], [450, ","], [450, "a"], [450, "great"], [450, "understanding"], [450, "and"], [450, "measurement"], [450, "of"], [450, "the"], [450, "relatively"], [450, "stable"], [450, "neurocognitive"], [450, "component"], [450, "be"], [450, "nee"], [450, "to"], [450, "examine"], [450, "those"], [450, "that"], [450, "indeed"], [450, "change"], [450, "with"], [450, "lithium"], [450, "treatment"], [450, "."], [451, "in"], [451, "order"], [451, "to"], [451, "achieve"], [451, "this"], [451, ","], [451, "we"], [451, "propose"], [451, "a"], [451, "lithium"], [451, "battery"], [451, "-"], [451, "clinical"], [451, "and"], [451, "a"], [451, "lithium"], [451, "battery"], [451, "-"], [451, "research"], [451, "that"], [451, "can"], [451, "be"], [451, "apply"], [451, "to"], [451, "these"], [451, "respective"], [451, "setting"], [451, "."], [452, "many"], [452, "finding"], [452, "that"], [452, "seem"], [452, "to"], [452, "be"], [452, "inconsistent"], [452, "in"], [452, "bipolar"], [452, "disorder"], [452, "research"], [452, "could"], [452, "be"], [452, "explain"], [452, "by"], [452, "heterogeneity"], [452, "of"], [452, "the"], [452, "illness"], [452, "and"], [452, "by"], [452, "imprecise"], [452, "diagnostic"], [452, "boundary"], [452, "."], [453, "this"], [453, "review"], [453, "of"], [453, "publish"], [453, "datum"], [453, "find"], [453, "support"], [453, "for"], [453, "the"], [453, "existence"], [453, "of"], [453, "three"], [453, "main"], [453, "subtype"], [453, "of"], [453, "bipolar"], [453, "disorder"], [453, ":"], [453, "("], [453, "1"], [453, ")"], [453, "classical"], [453, ","], [453, "("], [453, "2"], [453, ")"], [453, "psychosis"], [453, "spectrum"], [453, "and"], [453, "("], [453, "3"], [453, ")"], [453, "'"], [453, "characterological"], [453, "'"], [453, "."], [454, "these"], [454, "differ"], [454, "with"], [454, "respect"], [454, "to"], [454, "clinical"], [454, "presentation"], [454, "and"], [454, "course"], [454, "of"], [454, "illness"], [454, ","], [454, "family"], [454, "history"], [454, "and"], [454, "possibly"], [454, "long"], [454, "-"], [454, "term"], [454, "treatment"], [454, "response"], [454, "."], [455, "for"], [455, "instance"], [455, ","], [455, "in"], [455, "a"], [455, "series"], [455, "of"], [455, "genetic"], [455, "study"], [455, ","], [455, "lithium"], [455, "responder"], [455, "show"], [455, "an"], [455, "episodic"], [455, "course"], [455, "of"], [455, "illness"], [455, "with"], [455, "a"], [455, "family"], [455, "history"], [455, "of"], [455, "mostly"], [455, "bipolar"], [455, "disorder"], [455, "."], [456, "in"], [456, "contrast"], [456, ","], [456, "responder"], [456, "to"], [456, "lamotrigine"], [456, "monotherapy"], [456, "have"], [456, "a"], [456, "rapid"], [456, "-"], [456, "cycle"], [456, "clinical"], [456, "course"], [456, "and"], [456, "frequent"], [456, "comorbid"], [456, "condition"], [456, ","], [456, "especially"], [456, "in"], [456, "the"], [456, "anxiety"], [456, "-"], [456, "panic"], [456, "disorder"], [456, "spectrum"], [456, "."], [457, "their"], [457, "relative"], [457, "have"], [457, "elevate"], [457, "rate"], [457, "of"], [457, "anxiety"], [457, "and"], [457, "major"], [457, "depression"], [457, ","], [457, "but"], [457, "not"], [457, "bipolar"], [457, "disorder"], [457, "."], [458, "in"], [458, "summary"], [458, ","], [458, "recognise"], [458, "the"], [458, "clinical"], [458, "and"], [458, "familial"], [458, "subtype"], [458, "of"], [458, "bipolar"], [458, "disorder"], [458, "might"], [458, "lead"], [458, "to"], [458, "more"], [458, "target"], [458, "treatment"], [458, "."], [459, "bipolar"], [459, "ii"], [459, "disorder"], [459, "("], [459, "bp"], [459, "-"], [459, "ii"], [459, ")"], [459, "be"], [459, "define"], [459, ","], [459, "by"], [459, "dsm"], [459, "-"], [459, "iv"], [459, ","], [459, "as"], [459, "recurrent"], [459, "episode"], [459, "of"], [459, "depression"], [459, "and"], [459, "hypomania"], [459, "."], [460, "hypomania"], [460, ","], [460, "accord"], [460, "to"], [460, "dsm"], [460, "-"], [460, "iv"], [460, ","], [460, "require"], [460, "elevated"], [460, "("], [460, "euphoric"], [460, ")"], [460, "and/or"], [460, "irritable"], [460, "mood"], [460, ","], [460, "plus"], [460, "at"], [460, "least"], [460, "three"], [460, "of"], [460, "the"], [460, "follow"], [460, "symptom"], [460, "("], [460, "four"], [460, "if"], [460, "mood"], [460, "be"], [460, "only"], [460, "irritable"], [460, "):"], [460, "grandiosity"], [460, ","], [460, "decrease"], [460, "need"], [460, "for"], [460, "sleep"], [460, ","], [460, "increase"], [460, "talk"], [460, ","], [460, "race"], [460, "thought"], [460, ","], [460, "distractibility"], [460, ","], [460, "overactivity"], [460, "("], [460, "an"], [460, "increase"], [460, "in"], [460, "goal"], [460, "-"], [460, "direct"], [460, "activity"], [460, ")"], [460, ","], [460, "psychomotor"], [460, "agitation"], [460, "and"], [460, "excessive"], [460, "involvement"], [460, "in"], [460, "risky"], [460, "activity"], [460, "."], [461, "this"], [461, "observable"], [461, "change"], [461, "in"], [461, "function"], [461, "should"], [461, "not"], [461, "be"], [461, "severe"], [461, "enough"], [461, "to"], [461, "cause"], [461, "marked"], [461, "impairment"], [461, "of"], [461, "social"], [461, "or"], [461, "occupational"], [461, "functioning"], [461, ","], [461, "or"], [461, "to"], [461, "require"], [461, "hospitalisation"], [461, "."], [462, "the"], [462, "distinction"], [462, "between"], [462, "bp"], [462, "-"], [462, "ii"], [462, "and"], [462, "bipolar"], [462, "i"], [462, "disorder"], [462, "("], [462, "bp"], [462, "-"], [462, "i"], [462, ")"], [462, "be"], [462, "not"], [462, "clearcut"], [462, "."], [463, "the"], [463, "symptom"], [463, "of"], [463, "mania"], [463, "("], [463, "define"], [463, "bp"], [463, "-"], [463, "i"], [463, ")"], [463, "and"], [463, "hypomania"], [463, "("], [463, "define"], [463, "bp"], [463, "-"], [463, "ii"], [463, ")"], [463, "be"], [463, "the"], [463, "same"], [463, ","], [463, "apart"], [463, "from"], [463, "the"], [463, "presence"], [463, "of"], [463, "psychosis"], [463, "in"], [463, "mania"], [463, ","], [463, "and"], [463, "the"], [463, "distinction"], [463, "be"], [463, "base"], [463, "on"], [463, "the"], [463, "presence"], [463, "of"], [463, "marked"], [463, "impairment"], [463, "associate"], [463, "with"], [463, "mania"], [463, ","], [463, "i.e."], [463, "mania"], [463, "be"], [463, "more"], [463, "severe"], [463, "and"], [463, "may"], [463, "require"], [463, "hospitalisation"], [463, "."], [464, "this"], [464, "be"], [464, "an"], [464, "unclear"], [464, "boundary"], [464, "that"], [464, "can"], [464, "lead"], [464, "to"], [464, "misclassification"], [464, ";"], [464, "however"], [464, ","], [464, "the"], [464, "fact"], [464, "that"], [464, "hypomania"], [464, "often"], [464, "increase"], [464, "function"], [464, "make"], [464, "the"], [464, "distinction"], [464, "between"], [464, "mania"], [464, "and"], [464, "hypomania"], [464, "clear"], [464, "."], [465, "bp"], [465, "-"], [465, "ii"], [465, "depression"], [465, "can"], [465, "be"], [465, "syndromal"], [465, "and"], [465, "subsyndromal"], [465, ","], [465, "and"], [465, "it"], [465, "be"], [465, "the"], [465, "prominent"], [465, "feature"], [465, "of"], [465, "bp"], [465, "-"], [465, "ii"], [465, "."], [466, "it"], [466, "be"], [466, "often"], [466, "a"], [466, "mixed"], [466, "depression"], [466, ","], [466, "i.e."], [466, "it"], [466, "have"], [466, "concurrent"], [466, ","], [466, "usually"], [466, "subsyndromal"], [466, ","], [466, "hypomanic"], [466, "symptom"], [466, "."], [467, "it"], [467, "be"], [467, "the"], [467, "depression"], [467, "that"], [467, "usually"], [467, "lead"], [467, "the"], [467, "patient"], [467, "to"], [467, "seek"], [467, "treatment"], [467, "."], [468, "dsm"], [468, "-"], [468, "iv"], [468, "bipolar"], [468, "disorder"], [468, "("], [468, "bp"], [468, "-"], [468, "i"], [468, ","], [468, "bp"], [468, "-"], [468, "ii"], [468, ","], [468, "cyclothymic"], [468, "disorder"], [468, "and"], [468, "bipolar"], [468, "disorder"], [468, "not"], [468, "otherwise"], [468, "classified"], [468, ","], [468, "which"], [468, "include"], [468, "very"], [468, "rapid"], [468, "cycling"], [468, "and"], [468, "recurrent"], [468, "hypomania"], [468, ")"], [469, "be"], [469, "now"], [469, "consider"], [469, "to"], [469, "be"], [469, "part"], [469, "of"], [469, "the"], [469, "'"], [469, "bipolar"], [469, "spectrum"], [469, "'"], [469, "."], [470, "this"], [470, "be"], [470, "not"], [470, "include"], [470, "in"], [470, "dsm"], [470, "-"], [470, "iv"], [470, ","], [470, "but"], [470, "be"], [470, "think"], [470, "to"], [470, "also"], [470, "include"], [470, "antidepressant"], [470, "/"], [470, "substance"], [470, "-"], [470, "associate"], [470, "hypomania"], [470, ","], [470, "cyclothymic"], [470, "temperament"], [470, "("], [470, "a"], [470, "trait"], [470, "of"], [470, "highly"], [470, "unstable"], [470, "mood"], [470, ","], [470, "thinking"], [470, "and"], [470, "behaviour"], [470, ")"], [470, ","], [470, "unipolar"], [470, "mixed"], [470, "depression"], [470, "and"], [470, "highly"], [470, "recurrent"], [470, "unipolar"], [470, "depression"], [470, "."], [471, "bp"], [471, "-"], [471, "ii"], [471, "be"], [471, "underdiagnose"], [471, "in"], [471, "clinical"], [471, "practice"], [471, ","], [471, "and"], [471, "its"], [471, "pharmacological"], [471, "treatment"], [471, "be"], [471, "understudy"], [471, "."], [472, "underdiagnosis"], [472, "be"], [472, "demonstrate"], [472, "by"], [472, "recent"], [472, "epidemiological"], [472, "study"], [472, "."], [473, "while"], [473, ","], [473, "in"], [473, "dsm"], [473, "-"], [473, "iv"], [473, ","], [473, "bp"], [473, "-"], [473, "ii"], [473, "be"], [473, "report"], [473, "to"], [473, "have"], [473, "a"], [473, "lifetime"], [473, "community"], [473, "prevalence"], [473, "of"], [473, "0.5"], [473, "%"], [473, ","], [473, "epidemiological"], [473, "study"], [473, "have"], [473, "instead"], [473, "find"], [473, "that"], [473, "it"], [473, "have"], [473, "a"], [473, "lifetime"], [473, "community"], [473, "prevalence"], [473, "("], [473, "include"], [473, "the"], [473, "bipolar"], [473, "spectrum"], [473, ")"], [473, "of"], [473, "around"], [473, "5"], [473, "%"], [473, "."], [474, "in"], [474, "depressed"], [474, "outpatient"], [474, ","], [474, "one"], [474, "in"], [474, "two"], [474, "may"], [474, "have"], [474, "bp"], [474, "-"], [474, "ii"], [474, "."], [475, "the"], [475, "recent"], [475, "increase"], [475, "diagnosing"], [475, "of"], [475, "bp"], [475, "-"], [475, "ii"], [475, "in"], [475, "research"], [475, "setting"], [475, "be"], [475, "relate"], [475, "to"], [475, "several"], [475, "factor"], [475, ","], [475, "include"], [475, "the"], [475, "introduction"], [475, "of"], [475, "the"], [475, "use"], [475, "of"], [475, "semi"], [475, "-"], [475, "structured"], [475, "interview"], [475, "by"], [475, "train"], [475, "research"], [475, "clinician"], [475, ","], [475, "a"], [475, "relaxation"], [475, "of"], [475, "diagnostic"], [475, "criterion"], [475, "such"], [475, "that"], [475, "the"], [475, "minimum"], [475, "duration"], [475, "of"], [475, "hypomania"], [475, "be"], [475, "now"], [475, "less"], [475, "than"], [475, "the"], [475, "4"], [475, "day"], [475, "stipulate"], [475, "by"], [475, "dsm"], [475, "-"], [475, "iv"], [475, ","], [475, "and"], [475, "a"], [475, "probe"], [475, "for"], [475, "a"], [475, "history"], [475, "of"], [475, "hypomania"], [475, "focus"], [475, "more"], [475, "on"], [475, "overactivity"], [475, "("], [475, "increase"], [475, "goal"], [475, "-"], [475, "direct"], [475, "activity"], [475, ")"], [475, "than"], [475, "on"], [475, "mood"], [475, "change"], [475, "("], [475, "although"], [475, "this"], [475, "be"], [475, "still"], [475, "require"], [475, "for"], [475, "a"], [475, "diagnosis"], [475, "of"], [475, "hypomania"], [475, ")"], [475, "."], [476, "guideline"], [476, "on"], [476, "the"], [476, "treatment"], [476, "of"], [476, "bp"], [476, "-"], [476, "ii"], [476, "be"], [476, "mainly"], [476, "consensus"], [476, "base"], [476, "and"], [476, "tend"], [476, "to"], [476, "follow"], [476, "those"], [476, "for"], [476, "the"], [476, "treatment"], [476, "of"], [476, "bp"], [476, "-"], [476, "i"], [476, ","], [476, "because"], [476, "there"], [476, "have"], [476, "be"], [476, "few"], [476, "control"], [476, "study"], [476, "of"], [476, "the"], [476, "treatment"], [476, "of"], [476, "bp"], [476, "-"], [476, "ii"], [476, "."], [477, "the"], [477, "current"], [477, ","], [477, "limited"], [477, "evidence"], [477, "support"], [477, "the"], [477, "follow"], [477, "line"], [477, "of"], [477, "treatment"], [477, "for"], [477, "bp"], [477, "-"], [477, "ii"], [477, "."], [478, "hypomania"], [478, "be"], [478, "likely"], [478, "to"], [478, "respond"], [478, "to"], [478, "the"], [478, "same"], [478, "agent"], [478, "useful"], [478, "for"], [478, "mania"], [478, ","], [478, "i.e."], [478, "mood"], [478, "-"], [478, "stabilise"], [478, "agent"], [478, "such"], [478, "as"], [478, "lithium"], [478, "and"], [478, "valproate"], [478, ","], [478, "and"], [478, "the"], [478, "second"], [478, "-"], [478, "generation"], [478, "antipsychotic"], [478, "("], [478, "i.e."], [478, "olanzapine"], [478, ","], [478, "quetiapine"], [478, ","], [478, "risperidone"], [478, ","], [478, "ziprasidone"], [478, ","], [478, "aripiprazole"], [478, ")"], [478, "."], [479, "hypomania"], [479, "should"], [479, "be"], [479, "treat"], [479, "even"], [479, "if"], [479, "associate"], [479, "with"], [479, "overfunctioning"], [479, ","], [479, "because"], [479, "a"], [479, "depression"], [479, "often"], [479, "soon"], [479, "follow"], [479, "hypomania"], [479, "("], [479, "the"], [479, "hypomania"], [479, "-"], [479, "depression"], [479, "cycle"], [479, ")"], [479, "."], [480, "for"], [480, "the"], [480, "treatment"], [480, "of"], [480, "acute"], [480, "bp"], [480, "-"], [480, "ii"], [480, "depression"], [480, ","], [480, "two"], [480, "control"], [480, "study"], [480, "of"], [480, "quetiapine"], [480, "have"], [480, "not"], [480, "find"], [480, "clearcut"], [480, "positive"], [480, "effect"], [480, "."], [481, "naturalistic"], [481, "study"], [481, ","], [481, "although"], [481, "open"], [481, "to"], [481, "several"], [481, "bias"], [481, ","], [481, "have"], [481, "find"], [481, "antidepressant"], [481, "in"], [481, "acute"], [481, "bp"], [481, "-"], [481, "ii"], [481, "depression"], [481, "to"], [481, "be"], [481, "as"], [481, "effective"], [481, "as"], [481, "in"], [481, "unipolar"], [481, "depression"], [481, ";"], [481, "however"], [481, ","], [481, "one"], [481, "recent"], [481, "large"], [481, "control"], [481, "study"], [481, "("], [481, "mainly"], [481, "in"], [481, "patient"], [481, "with"], [481, "bp"], [481, "-"], [481, "i"], [481, ")"], [481, "have"], [481, "find"], [481, "antidepressant"], [481, "to"], [481, "be"], [481, "no"], [481, "more"], [481, "effective"], [481, "than"], [481, "placebo"], [481, "."], [482, "result"], [482, "from"], [482, "naturalistic"], [482, "study"], [482, "and"], [482, "clinical"], [482, "observation"], [482, "on"], [482, "mixed"], [482, "depression"], [482, ","], [482, "while"], [482, "in"], [482, "need"], [482, "of"], [482, "replication"], [482, "in"], [482, "control"], [482, "study"], [482, ","], [482, "indicate"], [482, "that"], [482, "antidepressant"], [482, "may"], [482, "worsen"], [482, "the"], [482, "concurrent"], [482, "intradepression"], [482, "hypomanic"], [482, "symptom"], [482, "."], [483, "the"], [483, "only"], [483, "preventive"], [483, "treatment"], [483, "for"], [483, "both"], [483, "depression"], [483, "and"], [483, "hypomania"], [483, "that"], [483, "be"], [483, "support"], [483, "by"], [483, "several"], [483, ","], [483, "albeit"], [483, "old"], [483, ","], [483, "control"], [483, "study"], [483, "be"], [483, "lithium"], [483, "."], [484, "lamotrigine"], [484, "have"], [484, "show"], [484, "some"], [484, "efficacy"], [484, "in"], [484, "delay"], [484, "depression"], [484, "recurrence"], [484, ","], [484, "but"], [484, "there"], [484, "have"], [484, "also"], [484, "be"], [484, "several"], [484, "negative"], [484, "unpublished"], [484, "study"], [484, "of"], [484, "the"], [484, "drug"], [484, "in"], [484, "this"], [484, "indication"], [484, "."], [485, "a"], [485, "grow"], [485, "body"], [485, "of"], [485, "evidence"], [485, "suggest"], [485, "that"], [485, "bipolar"], [485, "disorder"], [485, "("], [485, "bd"], [485, ")"], [485, "be"], [485, "a"], [485, "progressive"], [485, "disease"], [485, "accord"], [485, "to"], [485, "clinical"], [485, ","], [485, "biochemical"], [485, "and"], [485, "neuroimaging"], [485, "finding"], [485, "."], [486, "this"], [486, "study"], [486, "review"], [486, "the"], [486, "literature"], [486, "on"], [486, "the"], [486, "relationship"], [486, "between"], [486, "specific"], [486, "biomarker"], [486, "and"], [486, "bd"], [486, "stage"], [486, "."], [487, "a"], [487, "comprehensive"], [487, "literature"], [487, "search"], [487, "of"], [487, "medline"], [487, "and"], [487, "pubme"], [487, "be"], [487, "conduct"], [487, "to"], [487, "identify"], [487, "study"], [487, "in"], [487, "english"], [487, "and"], [487, "portuguese"], [487, "use"], [487, "the"], [487, "keyword"], [487, "biomarker"], [487, ","], [487, "neurotrophic"], [487, "factor"], [487, ","], [487, "inflammation"], [487, ","], [487, "oxidative"], [487, "stress"], [487, ","], [487, "neuroprogression"], [487, "and"], [487, "staging"], [487, "model"], [487, "cro"], [487, "-"], [487, "reference"], [487, "with"], [487, "bipolar"], [487, "disorder"], [487, "."], [488, "morphometric"], [488, "study"], [488, "of"], [488, "patient"], [488, "with"], [488, "bd"], [488, "find"], [488, "neuroanatomic"], [488, "abnormality"], [488, ","], [488, "such"], [488, "as"], [488, "ventricular"], [488, "enlargement"], [488, ","], [488, "grey"], [488, "matter"], [488, "loss"], [488, "in"], [488, "the"], [488, "hippocampus"], [488, "and"], [488, "cerebellum"], [488, ","], [488, "volume"], [488, "decrease"], [488, "in"], [488, "the"], [488, "prefrontal"], [488, "cortex"], [488, "and"], [488, "variation"], [488, "in"], [488, "the"], [488, "size"], [488, "of"], [488, "the"], [488, "amygdala"], [488, "."], [489, "other"], [489, "study"], [489, "demonstrate"], [489, "that"], [489, "serum"], [489, "concentration"], [489, "of"], [489, "neurotrophic"], [489, "factor"], [489, ","], [489, "inflammatory"], [489, "mediator"], [489, "and"], [489, "oxidative"], [489, "stress"], [489, "may"], [489, "be"], [489, "use"], [489, "as"], [489, "bd"], [489, "biomarker"], [489, "."], [490, "the"], [490, "analysis"], [490, "of"], [490, "neurobiological"], [490, "change"], [490, "associate"], [490, "with"], [490, "bd"], [490, "progression"], [490, "and"], [490, "activity"], [490, "may"], [490, "confirm"], [490, "the"], [490, "existence"], [490, "of"], [490, "bd"], [490, "biomarker"], [490, ","], [490, "which"], [490, "may"], [490, "be"], [490, "then"], [490, "include"], [490, "in"], [490, "stage"], [490, "model"], [490, "that"], [490, "will"], [490, "lead"], [490, "to"], [490, "improvement"], [490, "in"], [490, "treatment"], [490, "algorithm"], [490, "and"], [490, "more"], [490, "effective"], [490, ","], [490, "individually"], [490, "tailor"], [490, "treatment"], [490, "regimen"], [490, "."], [491, "biomarker"], [491, "may"], [491, "also"], [491, "be"], [491, "use"], [491, "to"], [491, "define"], [491, "early"], [491, "intervention"], [491, "to"], [491, "control"], [491, "disease"], [491, "progression"], [491, "."], [492, "untreated"], [492, "early"], [492, "-"], [492, "onset"], [492, "bipolar"], [492, "disorder"], [492, "be"], [492, "associate"], [492, "with"], [492, "high"], [492, "rate"], [492, "of"], [492, "rapid"], [492, "cycling"], [492, ","], [492, "more"], [492, "comorbidity"], [492, ","], [492, "and"], [492, "more"], [492, "severe"], [492, "mania"], [492, "and"], [492, "depression"], [492, "than"], [492, "adult"], [492, "-"], [492, "onset"], [492, "bipolar"], [492, "disorder"], [492, "."], [493, "correctly"], [493, "diagnose"], [493, "bipolar"], [493, "disorder"], [493, "early"], [493, "in"], [493, "its"], [493, "course"], [493, "can"], [493, "prevent"], [493, "expose"], [493, "a"], [493, "young"], [493, "patient"], [493, "to"], [493, "treatment"], [493, "that"], [493, "may"], [493, "exacerbate"], [493, "or"], [493, "advance"], [493, "the"], [493, "progression"], [493, "of"], [493, "the"], [493, "disorder"], [493, "."], [494, "appropriate"], [494, "pharmacologic"], [494, "and"], [494, "psychosocial"], [494, "intervention"], [494, "be"], [494, "necessary"], [494, "in"], [494, "the"], [494, "acute"], [494, "treatment"], [494, "of"], [494, "pediatric"], [494, "bipolar"], [494, "disorder"], [494, "."], [495, "bipolar"], [495, "disorder"], [495, "("], [495, "bd"], [495, ")"], [495, "be"], [495, "a"], [495, "chronic"], [495, "and"], [495, "severe"], [495, "mental"], [495, "disorder"], [495, "with"], [495, "recurrent"], [495, "episode"], [495, "of"], [495, "mania"], [495, "and"], [495, "depression"], [495, "."], [496, "in"], [496, "addition"], [496, "to"], [496, "neuronal"], [496, "alteration"], [496, ","], [496, "accumulate"], [496, "evidence"], [496, "have"], [496, "reveal"], [496, "the"], [496, "importance"], [496, "of"], [496, "glial"], [496, "system"], [496, "in"], [496, "pathophysiology"], [496, "and"], [496, "phenotype"], [496, "of"], [496, "the"], [496, "illness"], [496, "."], [497, "postmortem"], [497, "study"], [497, "have"], [497, "repeatedly"], [497, "demonstrate"], [497, "the"], [497, "alteration"], [497, "in"], [497, "glial"], [497, "cell"], [497, "and"], [497, "its"], [497, "function"], [497, "in"], [497, "patient"], [497, "with"], [497, "bd"], [497, "."], [498, "the"], [498, "activate"], [498, "microglia"], [498, "and"], [498, "inflammatory"], [498, "cytokine"], [498, "be"], [498, "propose"], [498, "to"], [498, "be"], [498, "the"], [498, "potential"], [498, "biomarker"], [498, "that"], [498, "may"], [498, "help"], [498, "to"], [498, "predict"], [498, "disease"], [498, "exacerbation"], [498, "in"], [498, "bd"], [498, "."], [499, "on"], [499, "the"], [499, "other"], [499, "hand"], [499, ","], [499, "anti"], [499, "-"], [499, "bd"], [499, "drug"], [499, "have"], [499, "be"], [499, "show"], [499, "to"], [499, "produce"], [499, "profound"], [499, "effect"], [499, "on"], [499, "glial"], [499, "activity"], [499, ","], [499, "which"], [499, "not"], [499, "only"], [499, "contribute"], [499, "to"], [499, "the"], [499, "therapeutic"], [499, "efficacy"], [499, ","], [499, "but"], [499, "may"], [499, "also"], [499, "provide"], [499, "a"], [499, "potential"], [499, "target"], [499, "for"], [499, "the"], [499, "drug"], [499, "development"], [499, "of"], [499, "bd"], [499, "."], [500, "we"], [500, "will"], [500, "focus"], [500, "on"], [500, "the"], [500, "recent"], [500, "development"], [500, "of"], [500, "glial"], [500, "abnormality"], [500, "and"], [500, "potential"], [500, "therapeutic"], [500, "benefit"], [500, "target"], [500, "to"], [500, "glial"], [500, "modulation"], [500, "in"], [500, "bd"], [500, "."], [501, "bipolar"], [501, "disorder"], [501, "be"], [501, "a"], [501, "highly"], [501, "recurrent"], [501, "and"], [501, "chronic"], [501, "psychiatric"], [501, "condition"], [501, "that"], [501, "shortens"], [501, "life"], [501, "expectancy"], [501, ","], [501, "cause"], [501, "functional"], [501, "impairment"], [501, "and"], [501, "disruption"], [501, "to"], [501, "social"], [501, ","], [501, "work"], [501, "and"], [501, "family"], [501, "life"], [501, "."], [502, "several"], [502, "form"], [502, "of"], [502, "bipolar"], [502, "disorder"], [502, "be"], [502, "recognise"], [502, ","], [502, "include"], [502, "both"], [502, "bipolar"], [502, "i"], [502, "and"], [502, "bipolar"], [502, "ii"], [502, "disorder"], [502, "."], [503, "bipolar"], [503, "i"], [503, "be"], [503, "characterise"], [503, "by"], [503, "recurrent"], [503, "episode"], [503, "of"], [503, "depression"], [503, "and"], [503, "mania"], [503, "whereas"], [503, "bipolar"], [503, "ii"], [503, "disorder"], [503, "be"], [503, "characterise"], [503, "by"], [503, "recurrent"], [503, "depression"], [503, "and"], [503, "hypomania"], [503, ","], [503, "a"], [503, "milder"], [503, "form"], [503, "of"], [503, "mania"], [503, "."], [504, "there"], [504, "have"], [504, "be"], [504, "debate"], [504, "concern"], [504, "the"], [504, "definition"], [504, "of"], [504, "hypomania"], [504, "since"], [504, "at"], [504, "least"], [504, "the"], [504, "1970"], [504, "."], [505, "the"], [505, "main"], [505, "area"], [505, "of"], [505, "argument"], [505, "focus"], [505, "on"], [505, "the"], [505, "minimum"], [505, "duration"], [505, "of"], [505, "hypomania"], [505, ","], [505, "its"], [505, "stem"], [505, "criterion"], [505, "and"], [505, "the"], [505, "number"], [505, "of"], [505, "symptom"], [505, "require"], [505, "for"], [505, "diagnosis"], [505, "."], [506, "arrive"], [506, "at"], [506, "the"], [506, "correct"], [506, "definition"], [506, "of"], [506, "hypomania"], [506, "be"], [506, "a"], [506, "key"], [506, "diagnostic"], [506, "issue"], [506, "."], [507, "there"], [507, "be"], [507, "increase"], [507, "evidence"], [507, "for"], [507, "the"], [507, "existence"], [507, "of"], [507, "a"], [507, "broad"], [507, "spectrum"], [507, "of"], [507, "bipolar"], [507, "disorder"], [507, ","], [507, "and"], [507, "datum"], [507, "demonstrate"], [507, "the"], [507, "clinical"], [507, "validity"], [507, "of"], [507, "modify"], [507, "some"], [507, "of"], [507, "the"], [507, "criterion"], [507, "for"], [507, "hypomania"], [507, "be"], [507, "review"], [507, "here"], [507, "."], [508, "the"], [508, "long"], [508, "-"], [508, "term"], [508, "outcome"], [508, "of"], [508, "bipolar"], [508, "disorder"], [508, "range"], [508, "from"], [508, "last"], [508, "remission"], [508, "to"], [508, "chronic"], [508, "course"], [508, "or"], [508, "frequent"], [508, "recurrence"], [508, "require"], [508, "admission"], [508, "."], [509, "the"], [509, "distinction"], [509, "between"], [509, "bipolar"], [509, "i"], [509, "and"], [509, "ii"], [509, "disorder"], [509, "have"], [509, "limit"], [509, "utility"], [509, "in"], [509, "outcome"], [509, "prediction"], [509, "."], [510, "it"], [510, "be"], [510, "unclear"], [510, "to"], [510, "what"], [510, "extent"], [510, "the"], [510, "clinical"], [510, "course"], [510, "of"], [510, "bipolar"], [510, "disorder"], [510, "predict"], [510, "long"], [510, "-"], [510, "term"], [510, "outcome"], [510, "."], [511, "a"], [511, "representative"], [511, "sample"], [511, "of"], [511, "191"], [511, "individual"], [511, "diagnose"], [511, "with"], [511, "bipolar"], [511, "i"], [511, "or"], [511, "ii"], [511, "disorder"], [511, "be"], [511, "recruit"], [511, "and"], [511, "follow"], [511, "for"], [511, "up"], [511, "to"], [511, "5"], [511, "year"], [511, "use"], [511, "a"], [511, "life"], [511, "-"], [511, "chart"], [511, "method"], [511, "."], [512, "we"], [512, "previously"], [512, "describe"], [512, "the"], [512, "clinical"], [512, "course"], [512, "over"], [512, "the"], [512, "first"], [512, "18"], [512, "month"], [512, "with"], [512, "dimensional"], [512, "course"], [512, "characteristic"], [512, "and"], [512, "latent"], [512, "class"], [512, "."], [513, "now"], [513, "we"], [513, "test"], [513, "if"], [513, "these"], [513, "course"], [513, "characteristic"], [513, "predict"], [513, "long"], [513, "-"], [513, "term"], [513, "outcome"], [513, ","], [513, "include"], [513, "time"], [513, "ill"], [513, "("], [513, "time"], [513, "with"], [513, "any"], [513, "mood"], [513, "symptom"], [513, ")"], [513, "and"], [513, "hospital"], [513, "admission"], [513, "over"], [513, "a"], [513, "second"], [513, "non"], [513, "-"], [513, "overlapping"], [513, "follow"], [513, "-"], [513, "up"], [513, "period"], [513, "in"], [513, "111"], [513, "individual"], [513, "with"], [513, "available"], [513, "datum"], [513, "from"], [513, "both"], [513, "18"], [513, "month"], [513, "and"], [513, "5"], [513, "year"], [513, "follow"], [513, "-"], [513, "up"], [513, "."], [514, "dimensional"], [514, "course"], [514, "characteristic"], [514, "from"], [514, "the"], [514, "first"], [514, "18"], [514, "month"], [514, "prospectively"], [514, "predict"], [514, "outcome"], [514, "over"], [514, "the"], [514, "follow"], [514, "3.5"], [514, "year"], [514, "."], [515, "the"], [515, "proportion"], [515, "of"], [515, "time"], [515, "depress"], [515, ","], [515, "the"], [515, "severity"], [515, "of"], [515, "depressive"], [515, "symptom"], [515, "and"], [515, "the"], [515, "proportion"], [515, "of"], [515, "time"], [515, "manic"], [515, "predict"], [515, "more"], [515, "time"], [515, "ill"], [515, "."], [516, "the"], [516, "proportion"], [516, "of"], [516, "time"], [516, "manic"], [516, ","], [516, "the"], [516, "severity"], [516, "of"], [516, "manic"], [516, "symptom"], [516, "and"], [516, "depression"], [516, "-"], [516, "to"], [516, "-"], [516, "mania"], [516, "switching"], [516, "predict"], [516, "a"], [516, "great"], [516, "likelihood"], [516, "of"], [516, "hospital"], [516, "admission"], [516, "."], [517, "all"], [517, "prediction"], [517, "remain"], [517, "significant"], [517, "after"], [517, "control"], [517, "for"], [517, "age"], [517, ","], [517, "sex"], [517, "and"], [517, "bipolar"], [517, "i"], [517, "v."], [517, "ii"], [517, "disorder"], [517, "."], [518, "differential"], [518, "association"], [518, "with"], [518, "long"], [518, "-"], [518, "term"], [518, "outcome"], [518, "suggest"], [518, "that"], [518, "course"], [518, "characteristic"], [518, "may"], [518, "facilitate"], [518, "care"], [518, "planning"], [518, "with"], [518, "great"], [518, "predictive"], [518, "validity"], [518, "than"], [518, "establish"], [518, "type"], [518, "of"], [518, "bipolar"], [518, "disorder"], [518, "."], [519, "a"], [519, "clinical"], [519, "course"], [519, "dominate"], [519, "by"], [519, "depressive"], [519, "symptom"], [519, "predict"], [519, "a"], [519, "great"], [519, "proportion"], [519, "of"], [519, "time"], [519, "ill"], [519, "."], [520, "a"], [520, "clinical"], [520, "course"], [520, "characterize"], [520, "by"], [520, "manic"], [520, "episode"], [520, "predict"], [520, "hospital"], [520, "admission"], [520, "."], [521, "to"], [521, "review"], [521, "the"], [521, "epidemiology"], [521, "and"], [521, "disease"], [521, "characteristic"], [521, "of"], [521, "the"], [521, "bipolar"], [521, "disorder"], [521, "("], [521, "bd"], [521, ")"], [521, "spectrum"], [521, ","], [521, "render"], [521, "an"], [521, "accurate"], [521, "and"], [521, "timely"], [521, "diagnosis"], [521, ","], [521, "and"], [521, "review"], [521, "treatment"], [521, "option"], [521, "through"], [521, "provider"], [521, "and"], [521, "patient"], [521, "collaboration"], [521, "."], [522, "comprehensive"], [522, "review"], [522, "of"], [522, "current"], [522, "scientific"], [522, "literature"], [522, "derive"], [522, "from"], [522, "electronic"], [522, "database"], [522, "and"], [522, "professional"], [522, "medical"], [522, "reference"], [522, "."], [523, "bd"], [523, "be"], [523, "a"], [523, "multifactorial"], [523, "disease"], [523, "that"], [523, "can"], [523, "interfere"], [523, "with"], [523, "cognition"], [523, "and"], [523, "behavior"], [523, ","], [523, "cause"], [523, "a"], [523, "severe"], [523, "impact"], [523, "on"], [523, "patient"], [523, "and"], [523, "family"], [523, "."], [524, "the"], [524, "variable"], [524, "course"], [524, "and"], [524, "often"], [524, "delay"], [524, "diagnosis"], [524, "of"], [524, "this"], [524, "disorder"], [524, "can"], [524, "cause"], [524, "frustration"], [524, "for"], [524, "the"], [524, "patient"], [524, "and"], [524, "the"], [524, "healthcare"], [524, "provider"], [524, "."], [525, "because"], [525, "most"], [525, "undiagnosed"], [525, "patient"], [525, "with"], [525, "bd"], [525, "seek"], [525, "treatment"], [525, "within"], [525, "the"], [525, "primary"], [525, "care"], [525, "setting"], [525, ","], [525, "it"], [525, "be"], [525, "imperative"], [525, "that"], [525, "clinician"], [525, "become"], [525, "expert"], [525, "in"], [525, "the"], [525, "recognition"], [525, "of"], [525, "and"], [525, "intervention"], [525, "for"], [525, "this"], [525, "condition"], [525, "."], [526, "the"], [526, "primary"], [526, "care"], [526, "provider"], [526, "be"], [526, "in"], [526, "a"], [526, "key"], [526, "position"], [526, "to"], [526, "render"], [526, "early"], [526, "diagnosis"], [526, "and"], [526, "treatment"], [526, "of"], [526, "bd"], [526, "."], [527, "this"], [527, "disease"], [527, "should"], [527, "always"], [527, "be"], [527, "consider"], [527, "as"], [527, "part"], [527, "of"], [527, "the"], [527, "differential"], [527, "diagnosis"], [527, "for"], [527, "depression"], [527, "or"], [527, "anxiety"], [527, "."], [528, "nurse"], [528, "practitioner"], [528, "can"], [528, "be"], [528, "effective"], [528, "provider"], [528, "by"], [528, "use"], [528, "good"], [528, "nursing"], [528, "practice"], [528, "of"], [528, "communication"], [528, ","], [528, "education"], [528, ","], [528, "and"], [528, "advocacy"], [528, "for"], [528, "the"], [528, "patient"], [528, "and"], [528, "family"], [528, "."], [529, "knowledge"], [529, "of"], [529, "current"], [529, "diagnostic"], [529, "criterion"], [529, "and"], [529, "management"], [529, "be"], [529, "imperative"], [529, "for"], [529, "successful"], [529, "treatment"], [529, "of"], [529, "patient"], [529, "with"], [529, "bd"], [529, "."], [530, "bipolar"], [530, "disorder"], [530, "("], [530, "bpd"], [530, ")"], [530, "be"], [530, "a"], [530, "devastating"], [530, "illness"], [530, "that"], [530, "be"], [530, "characterize"], [530, "by"], [530, "recurrent"], [530, "episode"], [530, "of"], [530, "mania"], [530, "and"], [530, "depression"], [530, "."], [531, "in"], [531, "addition"], [531, "to"], [531, "these"], [531, "cyclic"], [531, "episode"], [531, ","], [531, "individual"], [531, "with"], [531, "bpd"], [531, "exhibit"], [531, "change"], [531, "in"], [531, "psychovegetative"], [531, "function"], [531, ","], [531, "cognitive"], [531, "performance"], [531, ","], [531, "and"], [531, "general"], [531, "health"], [531, "and"], [531, "well"], [531, "be"], [531, "."], [532, "in"], [532, "this"], [532, "article"], [532, "we"], [532, "draw"], [532, "from"], [532, "neuroimage"], [532, "finding"], [532, "in"], [532, "human"], [532, ","], [532, "postmortem"], [532, "datum"], [532, ","], [532, "and"], [532, "human"], [532, "genetic"], [532, "and"], [532, "pharmacological"], [532, "study"], [532, "as"], [532, "well"], [532, "as"], [532, "datum"], [532, "from"], [532, "animal"], [532, "model"], [532, "of"], [532, "behavior"], [532, "to"], [532, "discuss"], [532, "the"], [532, "neurobiology"], [532, "of"], [532, "bpd"], [532, "."], [533, "we"], [533, "conclude"], [533, "with"], [533, "a"], [533, "synthesis"], [533, "of"], [533, "where"], [533, "the"], [533, "field"], [533, "stand"], [533, "and"], [533, "with"], [533, "suggestion"], [533, "and"], [533, "strategy"], [533, "for"], [533, "future"], [533, "area"], [533, "of"], [533, "study"], [533, "to"], [533, "far"], [533, "increase"], [533, "our"], [533, "conceptual"], [533, "understanding"], [533, "of"], [533, "this"], [533, "complex"], [533, "illness"], [533, "."], [534, "we"], [534, "review"], [534, "the"], [534, "recent"], [534, "literature"], [534, "in"], [534, "order"], [534, "to"], [534, "establish"], [534, "the"], [534, "importance"], [534, "of"], [534, "a"], [534, "spectrum"], [534, "for"], [534, "bipolar"], [534, "affective"], [534, "disorder"], [534, ","], [534, "and"], [534, "that"], [534, "unipolar"], [534, "depression"], [534, ","], [534, "bipolar"], [534, "ii"], [534, "and"], [534, "bipolar"], [534, "i"], [534, "be"], [534, "discrete"], [534, "entity"], [534, "that"], [534, "may"], [534, "however"], [534, "evolve"], [534, "in"], [534, "sequence"], [534, "."], [535, "we"], [535, "discuss"], [535, "clinical"], [535, ","], [535, "genetic"], [535, "and"], [535, "neurobiological"], [535, "datum"], [535, "which"], [535, "illustrate"], [535, "the"], [535, "difference"], [535, "between"], [535, "bipolar"], [535, "i"], [535, "and"], [535, "bipolar"], [535, "ii"], [535, "."], [536, "to"], [536, "fit"], [536, "the"], [536, "datum"], [536, "we"], [536, "suggest"], [536, "a"], [536, "series"], [536, "of"], [536, "multiple"], [536, "mood"], [536, "disorder"], [536, "genotype"], [536, ","], [536, "some"], [536, "of"], [536, "which"], [536, "evolve"], [536, "into"], [536, "other"], [536, "condition"], [536, "on"], [536, "the"], [536, "bipolar"], [536, "spectrum"], [536, "."], [537, "thence"], [537, "we"], [537, "discuss"], [537, "the"], [537, "nature"], [537, "of"], [537, "the"], [537, "bipolar"], [537, "spectrum"], [537, "and"], [537, "demonstrate"], [537, "how"], [537, "this"], [537, "concept"], [537, "can"], [537, "be"], [537, "use"], [537, "as"], [537, "the"], [537, "basis"], [537, "of"], [537, "a"], [537, "staging"], [537, "model"], [537, "for"], [537, "bipolar"], [537, "disorder"], [537, "."], [538, "bipolar"], [538, "disorder"], [538, "be"], [538, "a"], [538, "relatively"], [538, "common"], [538, "condition"], [538, "characterise"], [538, "by"], [538, "recurrent"], [538, "episode"], [538, "of"], [538, "mania"], [538, "and"], [538, "depression"], [538, ","], [538, "and"], [538, "associate"], [538, "with"], [538, "high"], [538, "level"], [538, "of"], [538, "morbidity"], [538, "and"], [538, "mortality"], [538, "."], [539, "although"], [539, "there"], [539, "have"], [539, "be"], [539, "substantial"], [539, "advance"], [539, "in"], [539, "the"], [539, "pharmacotherapeutic"], [539, "of"], [539, "this"], [539, "condition"], [539, "over"], [539, "the"], [539, "last"], [539, "10"], [539, "-"], [539, "15"], [539, "year"], [539, ","], [539, "the"], [539, "benefit"], [539, "have"], [539, "be"], [539, "predominantly"], [539, "in"], [539, "term"], [539, "of"], [539, "tolerability"], [539, "and"], [539, "safety"], [539, ","], [539, "with"], [539, "no"], [539, "new"], [539, "treatment"], [539, "be"], [539, "demonstrate"], [539, "to"], [539, "be"], [539, "more"], [539, "effective"], [539, "than"], [539, "lithium"], [539, "--"], [539, "the"], [539, "prototype"], [539, "mood"], [539, "stabili"], [539, "."], [540, "this"], [540, "article"], [540, "review"], [540, "current"], [540, "and"], [540, "emerge"], [540, "medication"], [540, "for"], [540, "bipolar"], [540, "disorder"], [540, "."], [541, "most"], [541, "of"], [541, "the"], [541, "emerge"], [541, "treatment"], [541, "in"], [541, "pharmaceutical"], [541, "industry"], [541, "developmental"], [541, "programme"], [541, "be"], [541, "new"], [541, "or"], [541, "modify"], [541, "anticonvulsant"], [541, "or"], [541, "atypical"], [541, "antipsychotic"], [541, "."], [542, "a"], [542, "number"], [542, "of"], [542, "possible"], [542, "future"], [542, "direction"], [542, "and"], [542, "challenge"], [542, "for"], [542, "the"], [542, "field"], [542, "be"], [542, "discuss"], [542, "."], [543, "the"], [543, "treatment"], [543, "of"], [543, "bipolar"], [543, "disorder"], [543, "be"], [543, "unlikely"], [543, "to"], [543, "advance"], [543, "substantially"], [543, "until"], [543, "the"], [543, "causative"], [543, "pathogenetic"], [543, "molecular"], [543, "process"], [543, "be"], [543, "elucidated"], [543, "."], [544, "bipolar"], [544, "disorder"], [544, "constitute"], [544, "a"], [544, "group"], [544, "of"], [544, "frequent"], [544, ","], [544, "chronic"], [544, "psychiatric"], [544, "illness"], [544, "with"], [544, "a"], [544, "most"], [544, "severe"], [544, "impact"], [544, "on"], [544, "the"], [544, "patient"], [544, "'s"], [544, "life"], [544, "."], [545, "the"], [545, "course"], [545, "can"], [545, "be"], [545, "very"], [545, "individual"], [545, "and"], [545, "heterogeneous"], [545, ","], [545, "the"], [545, "well"], [545, "know"], [545, "and"], [545, "most"], [545, "frequent"], [545, "manifestation"], [545, "include"], [545, "the"], [545, "classical"], [545, "bipolar"], [545, "i"], [545, "and"], [545, "bipolar"], [545, "ii"], [545, "disorder"], [545, "."], [546, "however"], [546, ","], [546, "in"], [546, "germany"], [546, "even"], [546, "typical"], [546, "bipolar"], [546, "i"], [546, "disorder"], [546, "be"], [546, "underdiagnosed"], [546, "and"], [546, ","], [546, "consequently"], [546, ","], [546, "undertreated"], [546, "."], [547, "this"], [547, "be"], [547, "true"], [547, "despite"], [547, "the"], [547, "fact"], [547, "that"], [547, "the"], [547, "number"], [547, "of"], [547, "pharmacological"], [547, "treatment"], [547, "option"], [547, "have"], [547, "rapidly"], [547, "increase"], [547, "during"], [547, "recent"], [547, "year"], [547, ","], [547, "both"], [547, "in"], [547, "the"], [547, "field"], [547, "of"], [547, "anticonvulsant"], [547, "and"], [547, "atypical"], [547, "antipsychotic"], [547, "."], [548, "this"], [548, "supply"], [548, "we"], [548, "today"], [548, "with"], [548, "new"], [548, "therapeutic"], [548, "strategy"], [548, ","], [548, "not"], [548, "only"], [548, "for"], [548, "acute"], [548, "mania"], [548, ","], [548, "but"], [548, "also"], [548, "for"], [548, "bipolar"], [548, "depression"], [548, "and"], [548, "maintenance"], [548, "treatment"], [548, ","], [548, "and"], [548, "it"], [548, "be"], [548, "feasible"], [548, "to"], [548, "assume"], [548, "that"], [548, "there"], [548, "will"], [548, "be"], [548, "more"], [548, "option"], [548, "available"], [548, "within"], [548, "the"], [548, "next"], [548, "few"], [548, "year"], [548, "."], [549, "to"], [549, "consider"], [549, "whether"], [549, "consensus"], [549, "exist"], [549, "in"], [549, "recommendation"], [549, "for"], [549, "manage"], [549, "bipolar"], [549, "mixed"], [549, "state"], [549, "publish"], [549, "in"], [549, "recent"], [549, "review"], [549, "and"], [549, "treatment"], [549, "guideline"], [549, ","], [549, "and"], [549, "to"], [549, "summarise"], [549, "what"], [549, "might"], [549, "be"], [549, "their"], [549, "good"], [549, "management"], [549, "."], [550, "limitation"], [550, "to"], [550, "and"], [550, "change"], [550, "in"], [550, "the"], [550, "definition"], [550, "of"], [550, "mixed"], [550, "state"], [550, "compromise"], [550, "diagnosis"], [550, "and"], [550, "management"], [550, "."], [551, "the"], [551, "striking"], [551, "comparison"], [551, "between"], [551, "dsm"], [551, "-"], [551, "iv"], [551, "and"], [551, "dsm-5"], [551, "criterion"], [551, "set"], [551, "risk"], [551, "under"], [551, "-"], [551, "diagnosis"], [551, "and"], [551, "over"], [551, "-"], [551, "diagnosis"], [551, "."], [552, "current"], [552, "review"], [552, "and"], [552, "guideline"], [552, "offer"], [552, "limited"], [552, "evidence"], [552, "to"], [552, "guide"], [552, "treatment"], [552, ";"], [552, "however"], [552, ","], [552, "management"], [552, "should"], [552, "involve"], [552, "address"], [552, "the"], [552, "contribution"], [552, "of"], [552, "any"], [552, "antidepressant"], [552, "medication"], [552, ","], [552, "and"], [552, "the"], [552, "introduction"], [552, "of"], [552, "a"], [552, "second"], [552, "-"], [552, "generation"], [552, "antipsychotic"], [552, "medication"], [552, "to"], [552, "stabilise"], [552, "the"], [552, "condition"], [552, "."], [553, "bipolar"], [553, "disorder"], [553, "be"], [553, "a"], [553, "chronic"], [553, ","], [553, "recur"], [553, "illness"], [553, "that"], [553, "require"], [553, "long"], [553, "-"], [553, "term"], [553, "prophylactic"], [553, "treatment"], [553, "."], [554, "however"], [554, ","], [554, "treatment"], [554, "be"], [554, "often"], [554, "complicate"], [554, "by"], [554, "misdiagnosis"], [554, "and"], [554, "inappropriate"], [554, "medication"], [554, "selection"], [554, "."], [555, "a"], [555, "number"], [555, "of"], [555, "therapy"], [555, "be"], [555, "available"], [555, "for"], [555, "the"], [555, "treatment"], [555, "of"], [555, "bipolar"], [555, "disorder"], [555, "and"], [555, "the"], [555, "ultimate"], [555, "therapeutic"], [555, "choice"], [555, "depend"], [555, "on"], [555, "the"], [555, "individual"], [555, "patient"], [555, "'s"], [555, "current"], [555, "symptom"], [555, ","], [555, "disease"], [555, "history"], [555, ","], [555, "and"], [555, "comorbid"], [555, "illness"], [555, "."], [556, "however"], [556, ","], [556, "research"], [556, "be"], [556, "nee"], [556, "to"], [556, "improve"], [556, "the"], [556, "overall"], [556, "prognosis"], [556, "for"], [556, "patient"], [556, "with"], [556, "bipolar"], [556, "depression"], [556, ","], [556, "particularly"], [556, "because"], [556, "approximately"], [556, "20"], [556, "%"], [556, "of"], [556, "patient"], [556, "commit"], [556, "suicide"], [556, "."], [557, "mania"], [557, "be"], [557, "the"], [557, "most"], [557, "dramatic"], [557, "expression"], [557, "of"], [557, "bipolar"], [557, "disorder"], [557, "and"], [557, "may"], [557, "overshadow"], [557, "the"], [557, "impact"], [557, "of"], [557, "the"], [557, "depressive"], [557, "phase"], [557, "of"], [557, "the"], [557, "illness"], [557, "."], [558, "compare"], [558, "with"], [558, "mania"], [558, ","], [558, "episode"], [558, "of"], [558, "bipolar"], [558, "depression"], [558, "be"], [558, "more"], [558, "frequent"], [558, ","], [558, "of"], [558, "long"], [558, "duration"], [558, ","], [558, "and"], [558, "be"], [558, "associate"], [558, "with"], [558, "high"], [558, "rate"], [558, "of"], [558, "morbidity"], [558, "and"], [558, "mortality"], [558, "."], [559, "therefore"], [559, ","], [559, "successful"], [559, "treatment"], [559, "and"], [559, "prevention"], [559, "of"], [559, "bipolar"], [559, "depression"], [559, "remain"], [559, "an"], [559, "essential"], [559, "treatment"], [559, "goal"], [559, "."], [560, "bipolar"], [560, "disorder"], [560, "("], [560, "bd"], [560, ")"], [560, "have"], [560, "traditionally"], [560, "be"], [560, "think"], [560, "of"], [560, "as"], [560, "an"], [560, "episodic"], [560, "condition"], [560, ","], [560, "characterize"], [560, "by"], [560, "period"], [560, "of"], [560, "hypomania"], [560, "/"], [560, "mania"], [560, "and"], [560, "depression"], [560, "."], [561, "however"], [561, ","], [561, "evidence"], [561, "be"], [561, "accumulate"], [561, "to"], [561, "suggest"], [561, "that"], [561, "this"], [561, "condition"], [561, "be"], [561, "associate"], [561, "with"], [561, "significant"], [561, "chronicity"], [561, "."], [562, "for"], [562, "a"], [562, "large"], [562, "proportion"], [562, "of"], [562, "patient"], [562, "with"], [562, "bd"], [562, ","], [562, "residual"], [562, ","], [562, "sub"], [562, "-"], [562, "syndromal"], [562, "symptom"], [562, "persist"], [562, "between"], [562, "major"], [562, "syndromal"], [562, "episode"], [562, ","], [562, "and"], [562, "study"], [562, "have"], [562, "show"], [562, "that"], [562, "many"], [562, "patient"], [562, "with"], [562, "bipolar"], [562, "disorder"], [562, "be"], [562, "symptomatic"], [562, "for"], [562, "approximately"], [562, "50"], [562, "%"], [562, "of"], [562, "the"], [562, "time"], [562, "over"], [562, "follow"], [562, "-"], [562, "up"], [562, "period"], [562, "of"], [562, "great"], [562, "than"], [562, "10"], [562, "year"], [562, "."], [563, "moreover"], [563, ","], [563, "while"], [563, "the"], [563, "prevalence"], [563, "of"], [563, "bd"], [563, "have"], [563, "be"], [563, "estimate"], [563, "to"], [563, "be"], [563, "around"], [563, "1"], [563, "-"], [563, "2"], [563, "%"], [563, ","], [563, "there"], [563, "be"], [563, "grow"], [563, "evidence"], [563, "that"], [563, "this"], [563, "may"], [563, "be"], [563, "a"], [563, "substantial"], [563, "underestimation"], [563, "."], [564, "there"], [564, "be"], [564, "a"], [564, "number"], [564, "of"], [564, "reason"], [564, "for"], [564, "this"], [564, "potential"], [564, "underestimation"], [564, ","], [564, "include"], [564, "difficulty"], [564, "in"], [564, "diagnosis"], [564, "."], [565, "add"], [565, "to"], [565, "the"], [565, "burden"], [565, "of"], [565, "bd"], [565, "be"], [565, "the"], [565, "issue"], [565, "of"], [565, "comorbidity"], [565, ","], [565, "with"], [565, "an"], [565, "increase"], [565, "prevalence"], [565, "of"], [565, "many"], [565, "chronic"], [565, "condition"], [565, "in"], [565, "those"], [565, "with"], [565, "a"], [565, "primary"], [565, "diagnosis"], [565, "of"], [565, "bd"], [565, "."], [566, "conversely"], [566, ","], [566, "for"], [566, "many"], [566, "patient"], [566, "with"], [566, "chronic"], [566, "condition"], [566, ","], [566, "both"], [566, "medical"], [566, "and"], [566, "psychiatric"], [566, ","], [566, "bd"], [566, "frequently"], [566, "exist"], [566, "as"], [566, "a"], [566, "comorbid"], [566, "secondary"], [566, "diagnosis"], [566, "."], [567, "this"], [567, "issue"], [567, "of"], [567, "comorbidity"], [567, "complicate"], [567, "estimate"], [567, "of"], [567, "use"], [567, "of"], [567, "pharmaceutical"], [567, "agent"], [567, "for"], [567, "bd"], [567, ","], [567, "such"], [567, "as"], [567, "mood"], [567, "stabilizer"], [567, ","], [567, "which"], [567, "be"], [567, "know"], [567, "to"], [567, "be"], [567, "use"], [567, "off"], [567, "-"], [567, "label"], [567, "in"], [567, "condition"], [567, "such"], [567, "as"], [567, "borderline"], [567, "personality"], [567, "or"], [567, "substance"], [567, "use"], [567, "disorder"], [567, "."], [568, "we"], [568, "speculate"], [568, "that"], [568, "such"], [568, "off"], [568, "-"], [568, "label"], [568, "prescribing"], [568, "may"], [568, "not"], [568, "be"], [568, "truly"], [568, "off"], [568, "-"], [568, "label"], [568, "but"], [568, "may"], [568, "be"], [568, "instead"], [568, "fully"], [568, "justify"], [568, "by"], [568, "an"], [568, "overlook"], [568, "secondary"], [568, "diagnosis"], [568, "of"], [568, "bd"], [568, "."], [569, "finally"], [569, ","], [569, "we"], [569, "discuss"], [569, "the"], [569, "association"], [569, "of"], [569, "bipolar"], [569, "disorder"], [569, "with"], [569, "a"], [569, "significant"], [569, "economic"], [569, "burden"], [569, ","], [569, "to"], [569, "the"], [569, "individual"], [569, "and"], [569, "to"], [569, "society"], [569, ","], [569, "both"], [569, "due"], [569, "to"], [569, "the"], [569, "direct"], [569, "cost"], [569, "of"], [569, "medical"], [569, "expenditure"], [569, "and"], [569, "indirect"], [569, "cost"], [569, "such"], [569, "as"], [569, "loss"], [569, "of"], [569, "productivity"], [569, "and"], [569, "increase"], [569, "mortality"], [569, "."], [570, "bipolar"], [570, "disorder"], [570, "("], [570, "bd"], [570, ")"], [570, "be"], [570, "characterize"], [570, "by"], [570, "period"], [570, "of"], [570, "abnormally"], [570, "elevate"], [570, "mood"], [570, "("], [570, "mania"], [570, ")"], [570, "that"], [570, "cycle"], [570, "with"], [570, "abnormally"], [570, "low"], [570, "mood"], [570, "("], [570, "depression"], [570, ")"], [570, "."], [571, "multiple"], [571, "structural"], [571, ","], [571, "metabolic"], [571, ","], [571, "and"], [571, "biochemical"], [571, "abnormality"], [571, "be"], [571, "evident"], [571, "in"], [571, "the"], [571, "brain"], [571, "'s"], [571, "cortex"], [571, ","], [571, "subcortex"], [571, ","], [571, "and"], [571, "deep"], [571, "region"], [571, "."], [572, "this"], [572, "disorder"], [572, "be"], [572, "highly"], [572, "genetically"], [572, "condition"], [572, "but"], [572, "also"], [572, "highly"], [572, "susceptible"], [572, "to"], [572, "environmental"], [572, "stressor"], [572, ":"], [572, "prenatal"], [572, "or"], [572, "perinatal"], [572, "insult"], [572, ","], [572, "childhood"], [572, "sexual"], [572, "or"], [572, "physical"], [572, "abuse"], [572, ","], [572, "challenging"], [572, "life"], [572, "event"], [572, ","], [572, "substance"], [572, "abuse"], [572, ","], [572, "and"], [572, "other"], [572, "toxic"], [572, "chemical"], [572, "exposure"], [572, "."], [573, "its"], [573, "high"], [573, "morbidity"], [573, ","], [573, "lose"], [573, "productivity"], [573, ","], [573, "and"], [573, "suicide"], [573, "risk"], [573, "place"], [573, "a"], [573, "great"], [573, "toll"], [573, "on"], [573, "society"], [573, "."], [574, "since"], [574, "world"], [574, "war"], [574, "ii"], [574, ","], [574, "bd"], [574, "have"], [574, "be"], [574, "steadily"], [574, "worsen"], [574, "with"], [574, "early"], [574, "age"], [574, "of"], [574, "onset"], [574, ","], [574, "great"], [574, "intensity"], [574, "of"], [574, "symptom"], [574, ","], [574, "and"], [574, "development"], [574, "of"], [574, "drug"], [574, "resistance"], [574, "."], [575, "incidence"], [575, "in"], [575, "child"], [575, "be"], [575, "rise"], [575, "and"], [575, "misdiagnosis"], [575, "be"], [575, "common"], [575, "."], [576, "discipline"], [576, "management"], [576, "of"], [576, "the"], [576, "many"], [576, "risk"], [576, "factor"], [576, "be"], [576, "essential"], [576, ","], [576, "include"], [576, "cognitive"], [576, "psychotherapy"], [576, "and"], [576, "support"], [576, "from"], [576, "family"], [576, "and"], [576, "community"], [576, "."], [577, "lithium"], [577, "have"], [577, "be"], [577, "the"], [577, "foundational"], [577, "treatment"], [577, ","], [577, "follow"], [577, "by"], [577, "valproate"], [577, "and"], [577, "other"], [577, "mood"], [577, "stabilizer"], [577, ","], [577, "antidepressant"], [577, ","], [577, "and"], [577, "anticonvulsant"], [577, "."], [578, "several"], [578, "single"], [578, "-"], [578, "nutrient"], [578, "and"], [578, "multinutrient"], [578, "supplement"], [578, "have"], [578, "also"], [578, "prove"], [578, "beneficial"], [578, "."], [579, "control"], [579, ","], [579, "double"], [579, "-"], [579, "blind"], [579, "trial"], [579, "show"], [579, "multinutrient"], [579, "combination"], [579, "of"], [579, "vitamin"], [579, ","], [579, "mineral"], [579, ","], [579, "orthomolecule"], [579, ","], [579, "herbal"], [579, ","], [579, "and"], [579, "the"], [579, "omega-3"], [579, "fatty"], [579, "acid"], [579, "epa"], [579, "and"], [579, "dha"], [579, "to"], [579, "be"], [579, "effective"], [579, "monotherapy"], [579, "."], [580, "the"], [580, "molecular"], [580, "action"], [580, "of"], [580, "lithium"], [580, "and"], [580, "valproate"], [580, "converge"], [580, "with"], [580, "nutrient"], [580, "on"], [580, "the"], [580, "level"], [580, "of"], [580, "the"], [580, "cell"], [580, "membrane"], [580, "and"], [580, "its"], [580, "molecular"], [580, "signal"], [580, "transduction"], [580, "system"], [580, "."], [581, "this"], [581, "emergent"], [581, ","], [581, "unified"], [581, "rationale"], [581, "presage"], [581, "effective"], [581, "integrative"], [581, "management"], [581, "of"], [581, "bipolar"], [581, "disorder"], [581, "."], [582, "recent"], [582, "research"], [582, "on"], [582, "the"], [582, "epidemiology"], [582, ","], [582, "clinical"], [582, "course"], [582, ","], [582, "diagnosis"], [582, ","], [582, "and"], [582, "treatment"], [582, "of"], [582, "bipolar"], [582, "ii"], [582, "disorder"], [582, "("], [582, "bd"], [582, "ii"], [582, ")"], [582, "stand"], [582, "to"], [582, "have"], [582, "a"], [582, "considerable"], [582, "impact"], [582, "on"], [582, "clinical"], [582, "practice"], [582, "."], [583, "this"], [583, "paper"], [583, "review"], [583, "these"], [583, "development"], [583, "."], [584, "we"], [584, "conduct"], [584, "a"], [584, "pubmed"], [584, "search"], [584, ","], [584, "focus"], [584, "on"], [584, "the"], [584, "period"], [584, "from"], [584, "january"], [584, "1"], [584, ","], [584, "1994"], [584, ","], [584, "to"], [584, "august"], [584, "31"], [584, ","], [584, "2004"], [584, "."], [585, "article"], [585, "deem"], [585, "directly"], [585, "relevant"], [585, "to"], [585, "the"], [585, "epidemiology"], [585, ","], [585, "course"], [585, ","], [585, "diagnosis"], [585, ","], [585, "and"], [585, "management"], [585, "of"], [585, "bd"], [585, "ii"], [585, "be"], [585, "consider"], [585, "."], [586, "the"], [586, "prevalence"], [586, "of"], [586, "bd"], [586, "ii"], [586, "be"], [586, "likely"], [586, "high"], [586, "than"], [586, "previously"], [586, "suggest"], [586, "."], [587, "systematic"], [587, "probe"], [587, "for"], [587, "particular"], [587, "clinical"], [587, "feature"], [587, "and"], [587, "use"], [587, "of"], [587, "screen"], [587, "tool"], [587, "allow"], [587, "for"], [587, "a"], [587, "more"], [587, "timely"], [587, "and"], [587, "accurate"], [587, "detection"], [587, "of"], [587, "the"], [587, "disorder"], [587, "."], [588, "there"], [588, "be"], [588, "a"], [588, "paucity"], [588, "of"], [588, "good"], [588, "quality"], [588, "datum"], [588, "to"], [588, "guide"], [588, "clinician"], [588, "treat"], [588, "bd"], [588, "ii"], [588, "."], [589, "significant"], [589, "progress"], [589, "have"], [589, "be"], [589, "make"], [589, "in"], [589, "clarify"], [589, "diagnostic"], [589, "and"], [589, "treatment"], [589, "issue"], [589, "in"], [589, "bd"], [589, "ii"], [589, "."], [590, "neither"], [590, "strong"], [590, "nor"], [590, "broad"], [590, "treatment"], [590, "recommendation"], [590, "can"], [590, "be"], [590, "make"], [590, ";"], [590, "a"], [590, "cautious"], [590, "interpretation"], [590, "of"], [590, "available"], [590, "datum"], [590, "suggest"], [590, "that"], [590, "lithium"], [590, "or"], [590, "lamotrigine"], [590, "be"], [590, "fairly"], [590, "reasonable"], [590, "first"], [590, "-"], [590, "line"], [590, "choice"], [590, "."], [591, "more"], [591, "well"], [591, "-"], [591, "design"], [591, "study"], [591, "with"], [591, "large"], [591, "sample"], [591, "be"], [591, "nee"], [591, "to"], [591, "improve"], [591, "the"], [591, "evidence"], [591, "base"], [591, "for"], [591, "manage"], [591, "this"], [591, "disorder"], [591, "."], [592, "bipolar"], [592, "disorder"], [592, "have"], [592, "not"], [592, "be"], [592, "well"], [592, "study"], [592, "in"], [592, "prepubertal"], [592, "child"], [592, ","], [592, "despite"], [592, "its"], [592, "potentially"], [592, "debilitate"], [592, "effect"], [592, "on"], [592, "growth"], [592, "and"], [592, "development"], [592, "."], [593, "however"], [593, ","], [593, "there"], [593, "have"], [593, "be"], [593, "case"], [593, "report"], [593, "of"], [593, "mania"], [593, "in"], [593, "this"], [593, "age"], [593, "group"], [593, "date"], [593, "back"], [593, "to"], [593, "esquirol"], [593, "in"], [593, "the"], [593, "mid-19th"], [593, "century"], [593, "."], [594, "despite"], [594, "anecdotal"], [594, "case"], [594, "report"], [594, ","], [594, "explicit"], [594, "criterion"], [594, "to"], [594, "diagnose"], [594, "mania"], [594, "in"], [594, "child"], [594, "be"], [594, "not"], [594, "use"], [594, "until"], [594, "1960"], [594, "."], [595, "since"], [595, "1980"], [595, "the"], [595, "dsm"], [595, "-"], [595, "iii"], [595, "/"], [595, "dsm"], [595, "-"], [595, "iii"], [595, "-"], [595, "r"], [595, "criterion"], [595, "have"], [595, "indicate"], [595, "adult"], [595, "criterion"], [595, "can"], [595, "be"], [595, "use"], [595, "to"], [595, "diagnose"], [595, "childhood"], [595, "mania"], [595, ","], [595, "with"], [595, "some"], [595, "modification"], [595, "to"], [595, "adjust"], [595, "for"], [595, "age"], [595, "difference"], [595, "."], [596, "bipolar"], [596, "disorder"], [596, "have"], [596, "not"], [596, "be"], [596, "frequently"], [596, "consider"], [596, "in"], [596, "the"], [596, "psychiatric"], [596, "differential"], [596, "diagnosis"], [596, "of"], [596, "child"], [596, "."], [597, "however"], [597, ","], [597, "if"], [597, "a"], [597, "diagnosis"], [597, "of"], [597, "mania"], [597, "be"], [597, "make"], [597, ","], [597, "clinical"], [597, "rating"], [597, "scale"], [597, "can"], [597, "be"], [597, "use"], [597, "to"], [597, "rate"], [597, "the"], [597, "severity"], [597, "of"], [597, "manic"], [597, "symptom"], [597, "and"], [597, "to"], [597, "monitor"], [597, "treatment"], [597, "."], [598, "a"], [598, "manic"], [598, "child"], [598, "should"], [598, "be"], [598, "treat"], [598, "use"], [598, "a"], [598, "biopsychosocial"], [598, "approach"], [598, "."], [599, "to"], [599, "date"], [599, ","], [599, "lithium"], [599, "carbonate"], [599, "have"], [599, "be"], [599, "the"], [599, "most"], [599, "commonly"], [599, "use"], [599, "psychopharmacological"], [599, "treatment"], [599, ","], [599, "but"], [599, "result"], [599, "have"], [599, "be"], [599, "variable"], [599, "."], [600, "additional"], [600, "research"], [600, "be"], [600, "nee"], [600, ","], [600, "include"], [600, "double"], [600, "-"], [600, "blind"], [600, ","], [600, "placebo"], [600, "-"], [600, "control"], [600, "study"], [600, "to"], [600, "document"], [600, "the"], [600, "beneficial"], [600, "effect"], [600, "of"], [600, "mood"], [600, "-"], [600, "stabilize"], [600, "medication"], [600, "."], [601, "also"], [601, ","], [601, "diagnostic"], [601, "instrument"], [601, "should"], [601, "be"], [601, "refine"], [601, "to"], [601, "improve"], [601, "their"], [601, "utility"], [601, "."], [602, "finally"], [602, ","], [602, "child"], [602, "at"], [602, "high"], [602, "risk"], [602, "for"], [602, "develop"], [602, "mania"], [602, "should"], [602, "be"], [602, "study"], [602, "to"], [602, "identify"], [602, "predictor"], [602, "of"], [602, "bipolar"], [602, "disorder"], [602, "in"], [602, "child"], [602, "."], [603, "bipolar"], [603, "disorder"], [603, "be"], [603, "a"], [603, "diagnostically"], [603, "heterogeneous"], [603, "disorder"], [603, ","], [603, "although"], [603, "mania"], [603, "emerge"], [603, "as"], [603, "a"], [603, "distinct"], [603, "phenotype"], [603, "characterize"], [603, "by"], [603, "elevated"], [603, "mood"], [603, "and"], [603, "increase"], [603, "activity"], [603, "or"], [603, "energy"], [603, "."], [604, "while"], [604, "bipolar"], [604, "disorder"], [604, "'s"], [604, "cyclicity"], [604, "be"], [604, "difficult"], [604, "to"], [604, "represent"], [604, "in"], [604, "animal"], [604, ","], [604, "model"], [604, "of"], [604, "mania"], [604, "have"], [604, "begin"], [604, "to"], [604, "decode"], [604, "its"], [604, "fundamental"], [604, "underlying"], [604, "neurobiology"], [604, "."], [605, "when"], [605, "psychostimulant"], [605, "such"], [605, "as"], [605, "amphetamine"], [605, "or"], [605, "cocaine"], [605, "be"], [605, "administer"], [605, "to"], [605, "rodent"], [605, ","], [605, "a"], [605, "result"], [605, "upsurge"], [605, "of"], [605, "motor"], [605, "activity"], [605, "be"], [605, "think"], [605, "to"], [605, "share"], [605, "face"], [605, "and"], [605, "predictive"], [605, "validity"], [605, "with"], [605, "mania"], [605, "in"], [605, "human"], [605, "."], [606, "study"], [606, "black"], [606, "swiss"], [606, "mouse"], [606, ","], [606, "which"], [606, "inherently"], [606, "exhibit"], [606, "proclivity"], [606, "for"], [606, "reward"], [606, "seek"], [606, "and"], [606, "risk"], [606, "taking"], [606, ","], [606, "also"], [606, "have"], [606, "yield"], [606, "some"], [606, "insight"], [606, "."], [607, "far"], [607, ","], [607, "translate"], [607, "the"], [607, "biology"], [607, "of"], [607, "bipolar"], [607, "disorder"], [607, "in"], [607, "human"], [607, "into"], [607, "animal"], [607, "model"], [607, "have"], [607, "lead"], [607, "to"], [607, "great"], [607, "understanding"], [607, "of"], [607, "role"], [607, "for"], [607, "candidate"], [607, "biological"], [607, "system"], [607, "such"], [607, "as"], [607, "the"], [607, "grik2"], [607, "and"], [607, "clock"], [607, "gene"], [607, ","], [607, "as"], [607, "well"], [607, "as"], [607, "the"], [607, "extracellular"], [607, "signal"], [607, "-"], [607, "relate"], [607, "kinase"], [607, "pathway"], [607, "involve"], [607, "in"], [607, "the"], [607, "pathophysiology"], [607, "of"], [607, "the"], [607, "illness"], [607, "."], [608, "the"], [608, "national"], [608, "institute"], [608, "of"], [608, "mental"], [608, "health"], [608, "research"], [608, "domain"], [608, "criterion"], [608, "initiative"], [608, "seek"], [608, "to"], [608, "identify"], [608, "build"], [608, "block"], [608, "of"], [608, "complex"], [608, "illness"], [608, "like"], [608, "bipolar"], [608, "disorder"], [608, "in"], [608, "hope"], [608, "of"], [608, "uncover"], [608, "the"], [608, "neurobiology"], [608, "of"], [608, "each"], [608, ","], [608, "as"], [608, "well"], [608, "as"], [608, "how"], [608, "each"], [608, "fit"], [608, "together"], [608, "to"], [608, "produce"], [608, "syndrome"], [608, "like"], [608, "bipolar"], [608, "disorder"], [608, "or"], [608, "why"], [608, "so"], [608, "many"], [608, "mental"], [608, "illness"], [608, "co"], [608, "-"], [608, "occur"], [608, "together"], [608, "."], [609, "research"], [609, "domain"], [609, "criteria"], [609, "-"], [609, "drive"], [609, "preclinical"], [609, "model"], [609, "of"], [609, "isolated"], [609, "behavior"], [609, "and"], [609, "domain"], [609, "involve"], [609, "in"], [609, "mania"], [609, "and"], [609, "bipolar"], [609, "disorder"], [609, "will"], [609, "ultimately"], [609, "inform"], [609, "movement"], [609, "toward"], [609, "nosology"], [609, "support"], [609, "by"], [609, "neurobiology"], [609, "."], [610, "the"], [610, "use"], [610, "of"], [610, "clinical"], [610, "staging"], [610, "model"], [610, "be"], [610, "emerge"], [610, "as"], [610, "a"], [610, "novel"], [610, "and"], [610, "useful"], [610, "paradigm"], [610, "for"], [610, "diagnose"], [610, "severe"], [610, "mental"], [610, "disorder"], [610, "."], [611, "the"], [611, "term"], [611, '"'], [611, "neuroprogression"], [611, '"'], [611, "have"], [611, "be"], [611, "use"], [611, "to"], [611, "define"], [611, "the"], [611, "pathological"], [611, "reorganization"], [611, "of"], [611, "the"], [611, "central"], [611, "nervous"], [611, "system"], [611, "along"], [611, "the"], [611, "course"], [611, "of"], [611, "severe"], [611, "mental"], [611, "disorder"], [611, "."], [612, "in"], [612, "bipolar"], [612, "disorder"], [612, "("], [612, "bd"], [612, ")"], [612, ","], [612, "neural"], [612, "substrate"], [612, "reactivity"], [612, "be"], [612, "change"], [612, "by"], [612, "repeat"], [612, "mood"], [612, "episode"], [612, ","], [612, "promote"], [612, "a"], [612, "brain"], [612, "rewire"], [612, "that"], [612, "lead"], [612, "to"], [612, "an"], [612, "increase"], [612, "vulnerability"], [612, "to"], [612, "life"], [612, "stress"], [612, "."], [613, "a"], [613, "search"], [613, "in"], [613, "the"], [613, "pubmed"], [613, "database"], [613, "be"], [613, "perform"], [613, "with"], [613, "the"], [613, "follow"], [613, "term"], [613, ":"], [613, '"'], [613, "stage"], [613, '"'], [613, ","], [613, '"'], [613, "neuroprogression"], [613, '"'], [613, ","], [613, '"'], [613, "serum"], [613, '"'], [613, ","], [613, '"'], [613, "plasma"], [613, '"'], [613, ","], [613, '"'], [613, "blood"], [613, '"'], [613, ","], [613, '"'], [613, "neuroimage"], [613, '"'], [613, ","], [613, '"'], [613, "pet"], [613, "scan"], [613, '"'], [613, ","], [613, '"'], [613, "fmri"], [613, '"'], [613, ","], [613, '"'], [613, "neurotrophin"], [613, '"'], [613, ","], [613, '"'], [613, "inflammatory"], [613, "marker"], [613, '"'], [613, "and"], [613, '"'], [613, "oxidative"], [613, "stress"], [613, "marker"], [613, '"'], [613, ","], [613, "which"], [613, "be"], [613, "individually"], [613, "cross"], [613, "with"], [613, '"'], [613, "cognition"], [613, '"'], [613, ","], [613, '"'], [613, "functionality"], [613, '"'], [613, ","], [613, '"'], [613, "response"], [613, "to"], [613, "treatment"], [613, '"'], [613, "and"], [613, '"'], [613, "bipolar"], [613, "disorder"], [613, '"'], [613, "."], [614, "the"], [614, "inclusion"], [614, "criterion"], [614, "comprise"], [614, "original"], [614, "paper"], [614, "in"], [614, "the"], [614, "english"], [614, "language"], [614, "."], [615, "abstract"], [615, "from"], [615, "scientific"], [615, "meeting"], [615, "be"], [615, "not"], [615, "include"], [615, "."], [616, "we"], [616, "divide"], [616, "the"], [616, "result"], [616, "accord"], [616, "to"], [616, "the"], [616, "available"], [616, "evidence"], [616, "of"], [616, "serum"], [616, "biomarker"], [616, "as"], [616, "potential"], [616, "mediator"], [616, "of"], [616, "neuroprogression"], [616, ","], [616, "with"], [616, "brain"], [616, "imaging"], [616, ","], [616, "cognition"], [616, ","], [616, "functioning"], [616, "and"], [616, "response"], [616, "to"], [616, "treatment"], [616, "consider"], [616, "as"], [616, "consequence"], [616, "."], [617, "the"], [617, "challenge"], [617, "in"], [617, "bd"], [617, "treatment"], [617, "be"], [617, "translate"], [617, "the"], [617, "knowledge"], [617, "of"], [617, "neuronal"], [617, "plasticity"], [617, "and"], [617, "neurobiology"], [617, "into"], [617, "clinical"], [617, "practice"], [617, "."], [618, "neuroprogression"], [618, "and"], [618, "staging"], [618, "can"], [618, "have"], [618, "important"], [618, "clinical"], [618, "implication"], [618, ","], [618, "give"], [618, "that"], [618, "early"], [618, "and"], [618, "late"], [618, "stage"], [618, "of"], [618, "the"], [618, "disorder"], [618, "appear"], [618, "to"], [618, "present"], [618, "different"], [618, "biological"], [618, "feature"], [618, "and"], [618, "therefore"], [618, "may"], [618, "require"], [618, "different"], [618, "treatment"], [618, "strategy"], [618, "."], [619, "our"], [619, "aim"], [619, "be"], [619, "to"], [619, "review"], [619, "evidence"], [619, "of"], [619, "the"], [619, "role"], [619, "of"], [619, "cognitive"], [619, "deficit"], [619, "in"], [619, "bipolar"], [619, "disorder"], [619, "and"], [619, "their"], [619, "relationship"], [619, "to"], [619, "other"], [619, "factor"], [619, ","], [619, "such"], [619, "as"], [619, "disorder"], [619, "variable"], [619, ","], [619, "treatment"], [619, ","], [619, "additional"], [619, "diagnosis"], [619, ","], [619, "genetic"], [619, "risk"], [619, ","], [619, "and"], [619, "brain"], [619, "imaging"], [619, "finding"], [619, "."], [620, "study"], [620, "that"], [620, "examine"], [620, "cognitive"], [620, "dysfunction"], [620, "in"], [620, "bipolar"], [620, "disorder"], [620, "and"], [620, "its"], [620, "relationship"], [620, "to"], [620, "the"], [620, "variable"], [620, "of"], [620, "clinical"], [620, ","], [620, "genetic"], [620, ","], [620, "and"], [620, "bipolar"], [620, "disorder"], [620, "subtype"], [620, ","], [620, "as"], [620, "well"], [620, "as"], [620, "neuro"], [620, "-"], [620, "anatomical"], [620, "and"], [620, "neuro"], [620, "-"], [620, "functional"], [620, "evidence"], [620, "have"], [620, "be"], [620, "review"], [620, "."], [621, "find"], [621, "from"], [621, "our"], [621, "own"], [621, "study"], [621, "have"], [621, "also"], [621, "be"], [621, "use"], [621, "while"], [621, "conduct"], [621, "the"], [621, "review"], [621, "."], [622, "in"], [622, "bipolar"], [622, "disorder"], [622, ","], [622, "deficit"], [622, "in"], [622, "executive"], [622, "function"], [622, ","], [622, "memory"], [622, ","], [622, "and"], [622, "attention"], [622, "persist"], [622, "in"], [622, "the"], [622, "euthymic"], [622, "state"], [622, "."], [623, "the"], [623, "number"], [623, "of"], [623, "episode"], [623, "and"], [623, "the"], [623, "course"], [623, "of"], [623, "the"], [623, "disorder"], [623, "seem"], [623, "to"], [623, "be"], [623, "relate"], [623, "to"], [623, "the"], [623, "severity"], [623, "of"], [623, "memory"], [623, "dysfunction"], [623, "and"], [623, "psychomotor"], [623, "slowness"], [623, "."], [624, "however"], [624, ","], [624, "symptom"], [624, "of"], [624, "cognitive"], [624, "dysfunction"], [624, "be"], [624, "present"], [624, "at"], [624, "the"], [624, "onset"], [624, "of"], [624, "the"], [624, "disorder"], [624, "."], [625, "moreover"], [625, ","], [625, "cognitive"], [625, "dysfunction"], [625, "have"], [625, "be"], [625, "observe"], [625, "in"], [625, "the"], [625, "healthy"], [625, "relative"], [625, "of"], [625, "bipolar"], [625, "disorder"], [625, "patient"], [625, "."], [626, "cognitive"], [626, "dysfunction"], [626, "in"], [626, "bipolar"], [626, "disorder"], [626, "be"], [626, "associate"], [626, "with"], [626, "functional"], [626, "and"], [626, "possibly"], [626, "structural"], [626, "anomaly"], [626, "in"], [626, "some"], [626, "part"], [626, "of"], [626, "the"], [626, "brain"], [626, ","], [626, "such"], [626, "as"], [626, "the"], [626, "frontal"], [626, "and"], [626, "cingulate"], [626, "cortex"], [626, "."], [627, "some"], [627, "recent"], [627, "study"], [627, "report"], [627, "a"], [627, "relationship"], [627, "between"], [627, "symptom"], [627, "of"], [627, "cognitive"], [627, "dysfunction"], [627, "and"], [627, "genetic"], [627, "variation"], [627, "in"], [627, "bipolar"], [627, "disorder"], [627, "."], [628, "today"], [628, ","], [628, "the"], [628, "presence"], [628, "of"], [628, "cognitive"], [628, "deficit"], [628, "in"], [628, "bipolar"], [628, "disorder"], [628, "be"], [628, "widely"], [628, "accept"], [628, ";"], [628, "however"], [628, ","], [628, "evidence"], [628, "of"], [628, "the"], [628, "neurobiological"], [628, "and"], [628, "clinical"], [628, "correlate"], [628, "of"], [628, "cognitive"], [628, "symptom"], [628, "be"], [628, "still"], [628, "limit"], [628, "."], [629, "more"], [629, "study"], [629, "be"], [629, "nee"], [629, "to"], [629, "investigate"], [629, "the"], [629, "relationship"], [629, "between"], [629, "cognitive"], [629, "dysfunction"], [629, "in"], [629, "bipolar"], [629, "disorder"], [629, "and"], [629, "risk"], [629, "."], [630, "genetic"], [630, "study"], [630, "be"], [630, "just"], [630, "now"], [630, "amend"], [630, "our"], [630, "body"], [630, "of"], [630, "knowledge"], [630, "."], [631, "there"], [631, "have"], [631, "be"], [631, "many"], [631, "conflicting"], [631, "result"], [631, "report"], [631, "by"], [631, "brain"], [631, "imaging"], [631, "study"], [631, "."], [632, "different"], [632, "brain"], [632, "imaging"], [632, "approach"], [632, "and"], [632, "genetic"], [632, "method"], [632, "should"], [632, "be"], [632, "use"], [632, "with"], [632, "more"], [632, "specific"], [632, "cognitive"], [632, "and"], [632, "social"], [632, "-"], [632, "emotional"], [632, "task"], [632, "for"], [632, "increase"], [632, "our"], [632, "knowledge"], [632, "about"], [632, "the"], [632, "nature"], [632, "of"], [632, "cognitive"], [632, "deficit"], [632, "in"], [632, "bipolar"], [632, "disorder"], [632, "."], [633, "bipolar"], [633, "disorder"], [633, ","], [633, "a"], [633, "serious"], [633, "illness"], [633, "result"], [633, "in"], [633, "significant"], [633, "psychosocial"], [633, "morbidity"], [633, "and"], [633, "excess"], [633, "mortality"], [633, ","], [633, "have"], [633, "be"], [633, "report"], [633, "to"], [633, "be"], [633, "frequently"], [633, "underdiagnose"], [633, "."], [634, "however"], [634, ","], [634, "during"], [634, "the"], [634, "past"], [634, "few"], [634, "year"], [634, "we"], [634, "have"], [634, "observe"], [634, "the"], [634, "emergence"], [634, "of"], [634, "an"], [634, "opposite"], [634, "phenomenon"], [634, "--"], [634, "the"], [634, "overdiagnosis"], [634, "of"], [634, "bipolar"], [634, "disorder"], [634, "."], [635, "in"], [635, "the"], [635, "present"], [635, "report"], [635, "from"], [635, "the"], [635, "rhode"], [635, "island"], [635, "method"], [635, "to"], [635, "improve"], [635, "diagnostic"], [635, "assessment"], [635, "and"], [635, "service"], [635, "("], [635, "midas"], [635, ")"], [635, "project"], [635, ","], [635, "we"], [635, "empirically"], [635, "examine"], [635, "whether"], [635, "bipolar"], [635, "disorder"], [635, "be"], [635, "overdiagnose"], [635, "."], [636, "seven"], [636, "hundred"], [636, "psychiatric"], [636, "outpatient"], [636, "be"], [636, "interview"], [636, "with"], [636, "the"], [636, "structured"], [636, "clinical"], [636, "interview"], [636, "for"], [636, "dsm"], [636, "-"], [636, "iv"], [636, "("], [636, "scid"], [636, ")"], [636, "and"], [636, "complete"], [636, "a"], [636, "self"], [636, "-"], [636, "administer"], [636, "questionnaire"], [636, ","], [636, "which"], [636, "ask"], [636, "the"], [636, "patient"], [636, "whether"], [636, "they"], [636, "have"], [636, "be"], [636, "previously"], [636, "diagnose"], [636, "with"], [636, "bipolar"], [636, "or"], [636, "manic"], [636, "-"], [636, "depressive"], [636, "disorder"], [636, "by"], [636, "a"], [636, "health"], [636, "care"], [636, "professional"], [636, "."], [637, "family"], [637, "history"], [637, "information"], [637, "be"], [637, "obtain"], [637, "from"], [637, "the"], [637, "patient"], [637, "regard"], [637, "first"], [637, "-"], [637, "degree"], [637, "relative"], [637, "."], [638, "diagnosis"], [638, "be"], [638, "blind"], [638, "to"], [638, "the"], [638, "result"], [638, "of"], [638, "the"], [638, "self"], [638, "-"], [638, "administer"], [638, "scale"], [638, "."], [639, "the"], [639, "study"], [639, "be"], [639, "conduct"], [639, "from"], [639, "may"], [639, "2001"], [639, "to"], [639, "march"], [639, "2005"], [639, "."], [640, "few"], [640, "than"], [640, "half"], [640, "the"], [640, "patient"], [640, "who"], [640, "report"], [640, "that"], [640, "they"], [640, "have"], [640, "be"], [640, "previously"], [640, "diagnose"], [640, "with"], [640, "bipolar"], [640, "disorder"], [640, "receive"], [640, "a"], [640, "diagnosis"], [640, "of"], [640, "bipolar"], [640, "disorder"], [640, "base"], [640, "on"], [640, "the"], [640, "scid"], [640, "."], [641, "patient"], [641, "with"], [641, "scid"], [641, "-"], [641, "diagnose"], [641, "bipolar"], [641, "disorder"], [641, "have"], [641, "a"], [641, "significantly"], [641, "high"], [641, "morbid"], [641, "risk"], [641, "of"], [641, "bipolar"], [641, "disorder"], [641, "than"], [641, "patient"], [641, "who"], [641, "self"], [641, "-"], [641, "report"], [641, "a"], [641, "previous"], [641, "diagnosis"], [641, "of"], [641, "bipolar"], [641, "disorder"], [641, "that"], [641, "be"], [641, "not"], [641, "confirm"], [641, "by"], [641, "the"], [641, "scid"], [641, "("], [641, "p"], [641, "<"], [641, ".02"], [641, ")"], [641, "."], [642, "patient"], [642, "who"], [642, "self"], [642, "-"], [642, "report"], [642, "a"], [642, "previous"], [642, "diagnosis"], [642, "of"], [642, "bipolar"], [642, "disorder"], [642, "that"], [642, "be"], [642, "not"], [642, "confirm"], [642, "by"], [642, "the"], [642, "scid"], [642, "do"], [642, "not"], [642, "have"], [642, "a"], [642, "significantly"], [642, "high"], [642, "morbid"], [642, "risk"], [642, "for"], [642, "bipolar"], [642, "disorder"], [642, "than"], [642, "the"], [642, "patient"], [642, "who"], [642, "be"], [642, "negative"], [642, "for"], [642, "bipolar"], [642, "disorder"], [642, "by"], [642, "self"], [642, "-"], [642, "report"], [642, "and"], [642, "the"], [642, "scid"], [642, "."], [643, "not"], [643, "only"], [643, "be"], [643, "there"], [643, "a"], [643, "problem"], [643, "with"], [643, "underdiagnosis"], [643, "of"], [643, "bipolar"], [643, "disorder"], [643, ","], [643, "but"], [643, "also"], [643, "an"], [643, "equal"], [643, "if"], [643, "not"], [643, "great"], [643, "problem"], [643, "exist"], [643, "with"], [643, "overdiagnosis"], [643, "."], [644, "adult"], [644, "attention"], [644, "-"], [644, "deficit"], [644, "/"], [644, "hyperactivity"], [644, "disorder"], [644, "("], [644, "adhd"], [644, ")"], [644, "be"], [644, "increasingly"], [644, "recognize"], [644, "and"], [644, "report"], [644, "to"], [644, "frequently"], [644, "coexist"], [644, "with"], [644, "bipolar"], [644, "disorder"], [644, "."], [645, "concurrent"], [645, "diagnosis"], [645, "of"], [645, "adult"], [645, "adhd"], [645, "and"], [645, "bipolar"], [645, "disorder"], [645, "remain"], [645, "controversial"], [645, "."], [646, "in"], [646, "this"], [646, "study"], [646, ","], [646, "we"], [646, "conduct"], [646, "a"], [646, "systematic"], [646, "review"], [646, "to"], [646, "examine"], [646, "the"], [646, "rate"], [646, "and"], [646, "diagnostic"], [646, "validity"], [646, "of"], [646, "the"], [646, "concept"], [646, "of"], [646, "comorbid"], [646, "adult"], [646, "adhd"], [646, "and"], [646, "bipolar"], [646, "disorder"], [646, "."], [647, "medline"], [647, ","], [647, "embase"], [647, ","], [647, "psycinfo"], [647, ","], [647, "and"], [647, "cochrane"], [647, "database"], [647, "be"], [647, "search"], [647, "for"], [647, "article"], [647, "publish"], [647, "before"], [647, "march"], [647, "30"], [647, ","], [647, "2007"], [647, ","], [647, "use"], [647, "the"], [647, "keyword"], [647, "manic"], [647, ","], [647, "bipolar"], [647, ","], [647, "attention"], [647, "deficit"], [647, "hyperactivity"], [647, ","], [647, "and"], [647, "adult"], [647, "."], [648, "the"], [648, "computer"], [648, "search"], [648, "be"], [648, "supplement"], [648, "with"], [648, "bibliographic"], [648, "cro"], [648, "-"], [648, "reference"], [648, "."], [649, "exclusion"], [649, "criterion"], [649, "be"], [649, "study"], [649, "with"], [649, "only"], [649, "pediatric"], [649, "subject"], [649, ","], [649, "childhood"], [649, "adhd"], [649, "only"], [649, "but"], [649, "not"], [649, "adult"], [649, "adhd"], [649, ","], [649, "and"], [649, "either"], [649, "bipolar"], [649, "disorder"], [649, "or"], [649, "adhd"], [649, "only"], [649, ","], [649, "but"], [649, "not"], [649, "both"], [649, ";"], [649, "review"], [649, "article"], [649, ","], [649, "case"], [649, "report"], [649, ";"], [649, "letter"], [649, "to"], [649, "the"], [649, "editor"], [649, ";"], [649, "and"], [649, "book"], [649, "chapter"], [649, "."], [650, "of"], [650, "the"], [650, "262"], [650, "citation"], [650, "find"], [650, ","], [650, "12"], [650, "study"], [650, "meet"], [650, "our"], [650, "inclusion"], [650, "criterion"], [650, "."], [651, "specific"], [651, "diagnostic"], [651, "validate"], [651, "criterion"], [651, "examine"], [651, "be"], [651, "phenomenology"], [651, ","], [651, "course"], [651, "of"], [651, "illness"], [651, ","], [651, "heredity"], [651, ","], [651, "biological"], [651, "marker"], [651, ","], [651, "and"], [651, "treatment"], [651, "response"], [651, "."], [652, "there"], [652, "be"], [652, "6"], [652, "study"], [652, "on"], [652, "comorbid"], [652, "rate"], [652, ","], [652, "4"], [652, "on"], [652, "phenomenology"], [652, ","], [652, "3"], [652, "on"], [652, "course"], [652, "of"], [652, "illness"], [652, ","], [652, "2"], [652, "on"], [652, "heredity"], [652, ","], [652, "none"], [652, "on"], [652, "biological"], [652, "marker"], [652, ","], [652, "and"], [652, "1"], [652, "on"], [652, "treatment"], [652, "response"], [652, "."], [653, "the"], [653, "propose"], [653, "comorbid"], [653, "syndrome"], [653, "be"], [653, "fairly"], [653, "common"], [653, "("], [653, "present"], [653, "in"], [653, "up"], [653, "to"], [653, "47"], [653, "%"], [653, "of"], [653, "adult"], [653, "adhd"], [653, "and"], [653, "21"], [653, "%"], [653, "of"], [653, "bipolar"], [653, "disorder"], [653, "population"], [653, ")"], [653, ","], [653, "with"], [653, "a"], [653, "more"], [653, "severe"], [653, "course"], [653, "of"], [653, "illness"], [653, "compare"], [653, "with"], [653, "that"], [653, "of"], [653, "bipolar"], [653, "disorder"], [653, "alone"], [653, ","], [653, "and"], [653, "high"], [653, "rate"], [653, "of"], [653, "comorbidity"], [653, "with"], [653, "other"], [653, "psychiatric"], [653, "disorder"], [653, "."], [654, "its"], [654, "treatment"], [654, "appear"], [654, "to"], [654, "require"], [654, "initial"], [654, "mood"], [654, "stabilization"], [654, "."], [655, "comorbid"], [655, "adult"], [655, "adhd"], [655, "and"], [655, "bipolar"], [655, "disorder"], [655, "have"], [655, "be"], [655, "insufficiently"], [655, "study"], [655, ","], [655, "with"], [655, "more"], [655, "emphasis"], [655, "on"], [655, "comorbidity"], [655, "rate"], [655, "and"], [655, "few"], [655, "datum"], [655, "on"], [655, "course"], [655, ","], [655, "neurobiology"], [655, ","], [655, "heredity"], [655, ","], [655, "and"], [655, "treatment"], [655, "."], [656, "the"], [656, "diagnostic"], [656, "validity"], [656, "of"], [656, "adult"], [656, "adhd/"], [656, "bipolar"], [656, "disorder"], [656, "as"], [656, "a"], [656, "true"], [656, "comorbidity"], [656, "be"], [656, "not"], [656, "well"], [656, "-"], [656, "establish"], [656, "on"], [656, "the"], [656, "basis"], [656, "of"], [656, "this"], [656, "equivocal"], [656, "and"], [656, "insufficient"], [656, "literature"], [656, "."], [657, "more"], [657, "study"], [657, "be"], [657, "greatly"], [657, "nee"], [657, "to"], [657, "far"], [657, "clarify"], [657, "its"], [657, "diagnostic"], [657, "validity"], [657, "and"], [657, "treatment"], [657, "approach"], [657, "."], [658, "although"], [658, "there"], [658, "be"], [658, "a"], [658, "broad"], [658, "base"], [658, "of"], [658, "literature"], [658, "on"], [658, "depression"], [658, "among"], [658, "elderly"], [658, "patient"], [658, "and"], [658, "on"], [658, "mania"], [658, "in"], [658, "young"], [658, "patient"], [658, ","], [658, "there"], [658, "be"], [658, "a"], [658, "relative"], [658, "paucity"], [658, "of"], [658, "information"], [658, "on"], [658, "bipolar"], [658, "disorder"], [658, "in"], [658, "the"], [658, "elderly"], [658, "population"], [658, "."], [659, "while"], [659, "the"], [659, "quantity"], [659, "of"], [659, "datum"], [659, "reflect"], [659, "the"], [659, "relative"], [659, "prevalence"], [659, "of"], [659, "these"], [659, "illness"], [659, ","], [659, "there"], [659, "be"], [659, "evidence"], [659, "to"], [659, "suggest"], [659, "that"], [659, "classification"], [659, "of"], [659, "mania"], [659, "in"], [659, "the"], [659, "elderly"], [659, "with"], [659, "respect"], [659, "to"], [659, "age"], [659, "of"], [659, "onset"], [659, ","], [659, "natural"], [659, "course"], [659, ","], [659, "family"], [659, "history"], [659, ","], [659, "and"], [659, "pathophysiology"], [659, "may"], [659, "be"], [659, "useful"], [659, "in"], [659, "understand"], [659, "the"], [659, "heterogeneous"], [659, "etiology"], [659, "of"], [659, "this"], [659, "syndrome"], [659, "."], [660, "this"], [660, "paper"], [660, "present"], [660, "a"], [660, "review"], [660, "of"], [660, "the"], [660, "literature"], [660, "on"], [660, "the"], [660, "incidence"], [660, "and"], [660, "course"], [660, "of"], [660, "illness"], [660, "in"], [660, "late"], [660, "-"], [660, "life"], [660, "bipolar"], [660, "disorder"], [660, "."], [661, "far"], [661, ","], [661, "dilemma"], [661, "of"], [661, "diagnostic"], [661, "classification"], [661, "in"], [661, "relation"], [661, "to"], [661, "associate"], [661, "risk"], [661, "factor"], [661, "will"], [661, "be"], [661, "discuss"], [661, "."], [662, "systematic"], [662, "review"], [662, "suggest"], [662, "comorbid"], [662, "borderline"], [662, "personality"], [662, "disorder"], [662, "be"], [662, "present"], [662, "in"], [662, "approximately"], [662, "20"], [662, "%"], [662, "of"], [662, "individual"], [662, "who"], [662, "have"], [662, "bipolar"], [662, "disorder"], [662, ","], [662, "but"], [662, "current"], [662, "diagnostic"], [662, "system"], [662, "demonstrate"], [662, "a"], [662, "move"], [662, "towards"], [662, "dimensional"], [662, "rather"], [662, "than"], [662, "categorical"], [662, "approach"], [662, "to"], [662, "classify"], [662, "personality"], [662, "pathology"], [662, "."], [663, "we"], [663, "aim"], [663, "to"], [663, "examine"], [663, "the"], [663, "presence"], [663, "and"], [663, "severity"], [663, "of"], [663, "borderline"], [663, "personality"], [663, "trait"], [663, "in"], [663, "bipolar"], [663, "i"], [663, "and"], [663, "bipolar"], [663, "ii"], [663, "disorder"], [663, ","], [663, "and"], [663, "to"], [663, "explore"], [663, "association"], [663, "between"], [663, "the"], [663, "presence"], [663, "/"], [663, "severity"], [663, "of"], [663, "borderline"], [663, "personality"], [663, "trait"], [663, "and"], [663, "clinical"], [663, "outcome"], [663, "in"], [663, "bipolar"], [663, "disorder"], [663, "."], [664, "borderline"], [664, "personality"], [664, "trait"], [664, "be"], [664, "measure"], [664, "in"], [664, "1447"], [664, "individual"], [664, "with"], [664, "dsm"], [664, "-"], [664, "iv"], [664, "bipolar"], [664, "disorder"], [664, "("], [664, "1008"], [664, "bipolar"], [664, "i"], [664, "disorder"], [664, "and"], [664, "439"], [664, "bipolar"], [664, "ii"], [664, "disorder"], [664, ")"], [664, "use"], [664, "the"], [664, "borderline"], [664, "evaluation"], [664, "of"], [664, "severity"], [664, "over"], [664, "time"], [664, "("], [664, "good"], [664, ")"], [664, "questionnaire"], [664, "."], [665, "lifetime"], [665, "clinical"], [665, "outcome"], [665, "be"], [665, "assess"], [665, "via"], [665, "schedule"], [665, "for"], [665, "clinical"], [665, "assessment"], [665, "in"], [665, "neuropsychiatry"], [665, "("], [665, "scan"], [665, ")"], [665, "semi"], [665, "-"], [665, "structured"], [665, "interview"], [665, "and"], [665, "clinical"], [665, "case"], [665, "note"], [665, "."], [666, "borderline"], [666, "personality"], [666, "trait"], [666, "be"], [666, "common"], [666, "in"], [666, "both"], [666, "bipolar"], [666, "disorder"], [666, "group"], [666, ","], [666, "with"], [666, "86.2"], [666, "%"], [666, "participant"], [666, "report"], [666, "at"], [666, "least"], [666, "one"], [666, "trait"], [666, "."], [667, "these"], [667, "include"], [667, "trait"], [667, "that"], [667, "overlap"], [667, "with"], [667, "("], [667, "eg"], [667, "mood"], [667, "instability"], [667, ")"], [667, "and"], [667, "those"], [667, "that"], [667, "be"], [667, "distinct"], [667, "from"], [667, "the"], [667, "symptom"], [667, "of"], [667, "bipolar"], [667, "disorder"], [667, "("], [667, "eg"], [667, "fear"], [667, "of"], [667, "abandonment"], [667, ")"], [667, "."], [668, "borderline"], [668, "personality"], [668, "trait"], [668, "be"], [668, "significantly"], [668, "more"], [668, "frequent"], [668, "and"], [668, "more"], [668, "severe"], [668, "in"], [668, "bipolar"], [668, "ii"], [668, "disorder"], [668, "compare"], [668, "to"], [668, "bipolar"], [668, "i"], [668, "disorder"], [668, "."], [669, "more"], [669, "severe"], [669, "borderline"], [669, "trait"], [669, ","], [669, "and"], [669, "even"], [669, "the"], [669, "presence"], [669, "of"], [669, "a"], [669, "single"], [669, "borderline"], [669, "personality"], [669, "trait"], [669, ","], [669, "be"], [669, "significantly"], [669, "associate"], [669, "with"], [669, "young"], [669, "age"], [669, "of"], [669, "bipolar"], [669, "disorder"], [669, "onset"], [669, "and"], [669, "high"], [669, "prevalence"], [669, "of"], [669, "lifetime"], [669, "alcohol"], [669, "misuse"], [669, "in"], [669, "both"], [669, "bipolar"], [669, "disorder"], [669, "group"], [669, "."], [670, "the"], [670, "presence"], [670, "of"], [670, "comorbid"], [670, "borderline"], [670, "personality"], [670, "trait"], [670, "should"], [670, "be"], [670, "consider"], [670, "in"], [670, "the"], [670, "management"], [670, "of"], [670, "all"], [670, "patient"], [670, "with"], [670, "bipolar"], [670, "disorder"], [670, "irrespective"], [670, "of"], [670, "whether"], [670, "criterion"], [670, "for"], [670, "a"], [670, "categorical"], [670, "borderline"], [670, "personality"], [670, "disorder"], [670, "diagnosis"], [670, "be"], [670, "meet"], [670, "."], [671, "in"], [671, "treat"], [671, "bipolar"], [671, "disorder"], [671, ","], [671, "specific"], [671, "psychotherapy"], [671, "in"], [671, "adjunct"], [671, "to"], [671, "pharmacotherapy"], [671, "have"], [671, "be"], [671, "show"], [671, "to"], [671, "be"], [671, "effective"], [671, "in"], [671, "prevent"], [671, "new"], [671, "episode"], [671, "and"], [671, "treat"], [671, "depressive"], [671, "episode"], [671, "."], [672, "among"], [672, "those"], [672, ","], [672, "interpersonal"], [672, "and"], [672, "social"], [672, "rhythm"], [672, "therapy"], [672, "("], [672, "ipsrt"], [672, ")"], [672, "develop"], [672, "by"], [672, "frank"], [672, ","], [672, "amalgamation"], [672, "of"], [672, "interpersonal"], [672, "psychotherapy"], [672, "("], [672, "ipt"], [672, ")"], [672, "with"], [672, "behavioral"], [672, "therapy"], [672, "focus"], [672, "on"], [672, "social"], [672, "rhythm"], [672, "have"], [672, "be"], [672, "show"], [672, "to"], [672, "be"], [672, "an"], [672, "efficacious"], [672, "adjunct"], [672, "to"], [672, "mediation"], [672, "in"], [672, "prevent"], [672, "new"], [672, "episode"], [672, "in"], [672, "bipolar"], [672, "i"], [672, "patient"], [672, "and"], [672, "in"], [672, "treat"], [672, "depression"], [672, "in"], [672, "bipolar"], [672, "i"], [672, "arid"], [672, "ii"], [672, "disorder"], [672, "."], [673, "ipsrt"], [673, "have"], [673, "also"], [673, "be"], [673, "show"], [673, "to"], [673, "enhance"], [673, "total"], [673, "functioning"], [673, ","], [673, "relationship"], [673, "functioning"], [673, "and"], [673, "life"], [673, "satisfaction"], [673, "among"], [673, "patient"], [673, "with"], [673, "bipolar"], [673, "disorder"], [673, ","], [673, "even"], [673, "after"], [673, "pretreatment"], [673, "functioning"], [673, "and"], [673, "concurrent"], [673, "depression"], [673, "be"], [673, "covarie"], [673, "."], [674, "ipsrt"], [674, "be"], [674, "design"], [674, "to"], [674, "directly"], [674, "address"], [674, "the"], [674, "major"], [674, "pathway"], [674, "to"], [674, "recurrence"], [674, "in"], [674, "bipolar"], [674, "disorder"], [674, ","], [674, "namely"], [674, "medication"], [674, "nonadherence"], [674, ","], [674, "stressful"], [674, "life"], [674, "event"], [674, ","], [674, "and"], [674, "disruption"], [674, "in"], [674, "social"], [674, "rhythm"], [674, "."], [675, "ipt"], [675, ","], [675, "originate"], [675, "by"], [675, "klerman"], [675, "et"], [675, "al"], [675, "."], [675, ","], [675, "be"], [675, "a"], [675, "strategic"], [675, "time"], [675, "-"], [675, "limit"], [675, "psychotherapy"], [675, "focus"], [675, "on"], [675, "one"], [675, "or"], [675, "two"], [675, "of"], [675, "four"], [675, "current"], [675, "interpersonal"], [675, "problem"], [675, "area"], [675, "("], [675, "ie"], [675, ","], [675, "grief"], [675, ","], [675, "interpersonal"], [675, "role"], [675, "dispute"], [675, ","], [675, "role"], [675, "transition"], [675, ","], [675, "and"], [675, "interpersonal"], [675, "dificit"], [675, ")"], [675, "."], [676, "in"], [676, "ipsrt"], [676, ","], [676, "the"], [676, "fifth"], [676, "problem"], [676, "area"], [676, '"'], [676, "grief"], [676, "for"], [676, "the"], [676, "lose"], [676, "healthy"], [676, "self"], [676, '"'], [676, "have"], [676, "be"], [676, "add"], [676, "in"], [676, "order"], [676, "to"], [676, "promote"], [676, "acceptance"], [676, "of"], [676, "the"], [676, "diagnosis"], [676, "and"], [676, "the"], [676, "need"], [676, "for"], [676, "life"], [676, "-"], [676, "long"], [676, "treatment"], [676, "."], [677, "social"], [677, "rhythm"], [677, "therapy"], [677, "be"], [677, "a"], [677, "behavioral"], [677, "approach"], [677, "aim"], [677, "at"], [677, "increase"], [677, "regularity"], [677, "of"], [677, "social"], [677, "rhythm"], [677, "use"], [677, "the"], [677, "social"], [677, "rhythm"], [677, "metric"], [677, "("], [677, "srm"], [677, ")"], [677, ","], [677, "a"], [677, "chart"], [677, "to"], [677, "record"], [677, "daily"], [677, "social"], [677, "activity"], [677, "include"], [677, "how"], [677, "stimulate"], [677, "they"], [677, "be"], [677, ","], [677, "develop"], [677, "from"], [677, "observation"], [677, "that"], [677, "disruption"], [677, "in"], [677, "social"], [677, "rhythm"], [677, "often"], [677, "trigger"], [677, "affective"], [677, "episode"], [677, "in"], [677, "patient"], [677, "with"], [677, "bipolar"], [677, "disorder"], [677, "."], [678, "ipsrt"], [678, "also"], [678, "appear"], [678, "to"], [678, "be"], [678, "a"], [678, "promising"], [678, "intervention"], [678, "for"], [678, "a"], [678, "subset"], [678, "of"], [678, "individual"], [678, "with"], [678, "bipolar"], [678, "ii"], [678, "depression"], [678, "as"], [678, "monotherapy"], [678, "for"], [678, "the"], [678, "acute"], [678, "treatment"], [678, "."]];

  // hw4/covid_sents.json
  var covid_sents_default = [[0, "covid-19, cause by sars-cov-2 infection, be mild to moderate in the majority of previously healthy individual, but can cause life-threaten disease or persistent debilitate symptom in some case."], [0, "the most important determinant of disease severity be age, with individual over 65 year have the great risk of require intensive care, and man be more susceptible than woman."], [0, "in contrast to other respiratory viral infection, young child seem to be less severely affect."], [0, "it be now clear that mild to severe acute infection be not the only outcome of covid-19, and long-last symptom be also possible."], [0, "in contrast to severe acute covid-19, such 'long covid' be seemingly more likely in woman than in man."], [0, "also, postinfectious hyperinflammatory disease have be describe as an additional outcome after sars-cov-2 infection."], [0, "here i discuss our current understanding of the immunological determinant of covid-19 disease presentation and severity and relate this to know immune-system difference between young and old people and between man and woman, and other factor associate with different disease presentation and severity."], [1, "coronavirus disease 2019 (covid-19), cause by severe acute respiratory syndrome coronavirus 2 (sars-cov-2), be a global pandemic which have induce unprecedented ramification, severely affect our society due to the long incubation time, unpredictably high prevalence and lack of effective vaccine."], [1, "one of the interesting notion be that there be an association between covid-19 and cancer."], [1, "cancer patient seem to exhibit exacerbate condition and a high mortality rate when expose to the virus."], [1, "therefore, vaccine be the promising solution to minimise the problem amongst cancer patient threaten by the new viral strain."], [1, "however, there be still limitation to be consider, include the efficacy of covid vaccine for immunocompromise individual, possible interaction between the vaccine and cancer, and personalise medicine."], [1, "not only to eradicate the pandemic, but also to make it more effective for immunocompromise patient who be suffer from cancer, a successful vaccine platform be require through the implementation of nanotechnology which can also enable scalable manufacturing and worldwide distribution along with its fast and precise delivery."], [1, "in this review, we summarise the current understanding of covid-19 with clinical perspective, highlight the association between covid-19 and cancer, follow by a vaccine development for this association use nanotechnology."], [1, "we suggest different administration method for the covid-19 vaccine formulation option."], [1, "this study will contribute to pave the way towards the prevention and treatment of covid-19, especially for the immunocompromise individual."], [2, "the coronavirus disease 2019 (covid-19) pandemic be declare a public health emergency of international concern by the world health organization."], [2, "covid-19 have high transmissibility and could result in acute lung injury in a fraction of patient."], [2, "by counterbalance the activity of the renin-angiotensin system, angiotensin-convert enzyme 2, which be the fusion receptor of the virus, play a protective role against the development of complication of this viral infection."], [2, "vitamin\u2009d can induce the expression of angiotensin-convert enzyme 2 and regulate the immune system through different mechanism."], [2, "epidemiologic study of the relationship between vitamin\u2009d and various respiratory infection be review and, here, the postulate mechanism and clinical datum support the protective role of vitamin\u2009d against covid-19-mediate complication be discuss."], [3, "as the current understanding of covid-19 continue to evolve, a synthesis of the literature on the neurological impact of this novel virus may help inform clinical management and highlight potentially important avenue of investigation."], [3, "additionally, understand the potential mechanism of neurologic injury may guide effort to well detect and ameliorate these complication."], [3, "in this review, we synthesize a range of clinical observation and initial case series describe potential neurologic manifestation of covid-19 and place these observation in the context of coronavirus neuro-pathophysiology as it may relate to sars-cov-2 infection."], [3, "report nervous system manifestation range from anosmia and ageusia, to cerebral hemorrhage and infarction."], [3, "while the volume of covid-19-relate case study continue to grow, previous work examine related virus suggest potential mechanism through which the novel coronavirus may impact the cns and result in neurological complication."], [3, "namely, animal study examine the sars-cov have implicate the angiotensin-convert-enzyme-2 receptor as a mediator of coronavirus-relate neuronal damage and have show that sars-cov can infect cerebrovascular endothelium and brain parenchyma, the latter predominantly in the medial temporal lobe, result in apoptosis and necrosis."], [3, "human postmortem brain study indicate that human coronavirus variant and sars-cov can infect neuron and glia, imply sars-cov-2 may have similar neurovirulence."], [3, "additionally, study have demonstrate an increase in cytokine serum level as a result of sars-cov infection, consistent with the notion that cytokine overproduction and toxicity may be a relevant potential mechanism of neurologic injury, parallel a know pathway of pulmonary injury."], [3, "we also discuss evidence that suggest that sars-cov-2 may be a vasculotropic and neurotropic virus."], [3, "early report suggest covid-19 may be associate with severe neurologic complication, and several plausible mechanism exist to account for these observation."], [3, "a heightened awareness of the potential for neurologic involvement and further investigation into the relevant pathophysiology will be necessary to understand and ultimately mitigate sars-cov-2-associate neurologic injury."], [4, "accurate and rapid diagnostic test be critical for achieve control of coronavirus disease 2019 (covid-19), a pandemic illness cause by severe acute respiratory syndrome coronavirus 2 (sars-cov-2)."], [4, "diagnostic test for covid-19 fall into two main category: molecular test that detect viral rna, and serological test that detect anti-sars-cov-2 immunoglobulin."], [4, "reverse transcriptase polymerase chain reaction (rt-pcr), a molecular test, have become the gold standard for diagnosis of covid-19; however, this test have many limitation that include potential false negative result, change in diagnostic accuracy over the disease course, and precarious availability of test material."], [4, "serological test have generate substantial interest as an alternative or complement to rt-pcr and other nucleic acid test in the diagnosis of acute infection, as some might be cheap and easy to implement at the point of care."], [4, "a clear advantage of these test over rt-pcr be that they can identify individual previously infect by sars-cov-2, even if they never undergo testing while acutely ill."], [4, "many serological test for covid-19 have become available in a short period, include some market for use as rapid, point-of-care test."], [4, "the pace of development have, however, exceed that of rigorous evaluation, and important uncertainty about test accuracy remain."], [5, "covid-19 be a novel coronavirus with an outbreak of unusual viral pneumonia in wuhan, china, and then pandemic."], [5, "base on its phylogenetic relationship and genomic structure the covid-19 belong to genera betacoronavirus."], [5, "human betacoronaviruses (sars-cov-2, sars-cov, and mers-cov) have many similarity, but also have difference in their genomic and phenotypic structure that can influence their pathogenesis."], [5, "covid-19 be contain single-strand (positive-sense) rna associate with a nucleoprotein within a capsid comprise of matrix protein."], [5, "a typical cov contain at least six orf in its genome."], [5, "all the structural and accessory protein be translate from the sgrnas of covs."], [5, "four main structural protein be encode by orf 10, 11 on the one-third of the genome near the 3'-terminu."], [5, "the genetic and phenotypic structure of covid-19 in pathogenesis be important."], [5, "this article highlight the most important of these feature compare to other betacoronaviruse."], [6, "the coronavirus disease 2019 (covid\u201119) outbreak, which have cause >46\xA0million confirm infection and >1.2\xA0million coronavirus relate death, be one of the most devastating worldwide crisis in recent year."], [6, "infection with covid\u201119 result in a fever, dry cough, general fatigue, respiratory symptom, diarrhoea and a sore throat, similar to those of acute respiratory distress syndrome."], [6, "the causative agent of covid\u201119, sars\u2011cov\u20112, be a novel coronavirus strain."], [6, "to date, remdesivir have be grant emergency use authorization for use in the management of infection."], [6, "additionally, several efficient diagnostic tool be be actively develop, and novel drug and vaccine be be evaluate for their efficacy as therapeutic agent against covid\u201119, or in the prevention of infection."], [6, "the present review highlight the prevalent clinical manifestation of covid\u201119, characterize the sars\u2011cov\u20112 viral genome sequence and life cycle, highlight the optimal method for prevent viral transmission, and discuss possible molecular pharmacological mechanism and approach in the development of anti\u2011sars\u2011cov\u20112 therapeutic agent."], [6, "in addition, the use of traditional chinese medicine for management of covid\u201119 be discuss."], [6, "it be expect that novel anti\u2011viral agent, vaccine or an effective combination therapy for treatment/management of sars\u2011cov\u20112 infection and spread therapy will be develop and implement in 2021, and we would like to extend our good regard to the frontline health worker across the world in their fight against covid\u201119."], [7, "cholesterol be be recognize as a molecule involve in regulate the entry of the sars-cov-2 virus into the host cell."], [7, "however, the datum about the possible role of cholesterol carry lipoprotein and their receptor in relation to infection be scarce and the connection of lipid-associate pathology with covid-19 disease be in its infancy."], [7, "herein we provide an overview of lipid and lipid metabolism in relation to covid-19, with special attention on different form of cholesterol."], [7, "cholesterol enrich lipid raft represent a platform for virus to enter the host cell by endocytosis."], [7, "generally, high membrane cholesterol coincide with high efficiency of covid-19 entry."], [7, "inversely, patient with covid-19 show lowered level of blood cholesterol, high-density lipoprotein (hdl) and low-density lipoprotein."], [7, "the modulated efficiency of viral entry can be explain by availability of sr-b1 receptor."], [7, "hdl seem to have a variety of role, from be itself a scavenger for virus, an immune modulator and mediator of viral entry."], [7, "due to inverse role of membrane cholesterol and lipoprotein cholesterol in covid-19 infected patient, treatment of these patient with cholesterol lower statin need more attention."], [7, "in conclusion, cholesterol and lipoprotein be potential marker for monitor the viral infection status, while the lipid metabolic pathway and the composition of membrane could be target to selectively inhibit the life cycle of the virus as a basis for antiviral therapy."], [8, "gain further insight into sars-cov-2 route of infection and the underlie pathobiology of covid-19 will support the design of rational treatment target the life cycle of the virus and/or the adverse effect (e.g., multi-organ collapse) that be trigger by covid-19-mediate adult respiratory distress syndrome (ards) and/or other pathology."], [8, "covid-19 be a two-phase disease be mark by (phase 1) increase virus transmission and infection rate due to the wide expression of the main infection-relate ace2, tmprss2 and ctsb/l human gene in tissue of the respiratory and gastrointestinal tract, as well as by (phase 2) host-"], [8, "and probably sex- and/or age-specific uncontrolled inflammatory immune response which drive hyper-cytokinemia, aggressive inflammation and (due to broad organotropism of sars-cov-2) collateral tissue damage and systemic failure likely because of imbalance ace/angii/at1r and ace2/ang(1-7)/masr axis signal."], [8, 'here we discuss sars-cov-2 life cycle and a number of approach aim to suppress viral infection rate or propagation; increase virus antigen presentation in order to activate a robust and durable adaptive immune response from the host, and/or mitigate the ards-relate "cytokine storm" and collateral tissue damage that trigger the severe life-threaten complication of covid-19.'], [9, "currently, there be no treatment option available for the deadly contagious disease, coronavirus disease 2019 (covid-19)."], [9, "drug repurpose be a process of identify new use for approve or investigational drug and it be consider as a very effective strategy for drug discovery as it involve less time and cost to find a therapeutic agent in comparison to the de novo drug discovery process."], [9, "the present review will focus on the repurpose efficacy of the currently use drug against covid-19 and their mechanism of action, pharmacokinetic, dosing, safety, and their future perspective."], [9, "relevant article with experimental study conduct in-silico, in-vitro, in-vivo, clinical trial in human, case report, and news archive be select for the review."], [9, "number of drug such as remdesivir, favipiravir, ribavirin, lopinavir, ritonavir, darunavir, arbidol, chloroquine, hydroxychloroquine, tocilizumab and interferon have show inhibitory effect against the sars-cov2 in-vitro as well as in clinical condition."], [9, "these drug either act through virus-relate target such as rna genome, polypeptide packing and uptake pathway or target host-relate pathway involve angiotensin-convert enzyme-2 (ace2) receptor and inflammatory pathway."], [9, "use the basic knowledge of viral pathogenesis and pharmacodynamic of drug as well as use computational tool, many drug be currently in pipeline to be repurpose."], [9, "in the current scenario, repositioning of the drug could be consider the new avenue for the treatment of covid-19."], [10, "severe acute respiratory syndrome coronavirus-2 (sars-cov-2) be a novel coronavirus that be responsible for the 2019-2020 pandemic."], [10, "in this comprehensive review, we discuss the current publish literature surround the sars-cov-2 virus."], [10, "we examine the fundamental concept include the origin, virology, pathogenesis, clinical manifestation, diagnosis, laboratory, radiology, and histopathologic finding, complication, and treatment."], [10, "give that much of the information have be extrapolate from what we know about other coronaviruse include severe acute respiratory syndrome coronavirus (sars-cov) and middle east respiratory syndrome coronavirus (mers-cov), we identify and provide insight into controversy and research gap for the current pandemic to assist with future research idea."], [10, "finally, we discuss the global response to the coronavirus disease-2019 (covid-19) pandemic and provide thought regard lesson for future pandemic."], [11, "an acute respiratory disease cause by a severe acute respiratory syndrome coronavirus 2 (sars-cov-2) that surface in china in late 2019, continue to spread rapidly across the globe cause serious concern."], [11, "the coronavirus disease 2019 (covid-19) be declare as a public health emergency worldwide by the world health organization (who)."], [11, "increase evidence have demonstrate human-to-human transmission that primarily affect the upper respiratory tract follow by low respiratory tract damage lead to severe pneumonia."], [11, "base on the current status, the elderly population and people with prior co-morbidity be highly susceptible to serious health effect include cytokine up-regulation and acute respiratory distress syndrome (ards)."], [11, "currently, covid-19 research be still in the preliminary stage necessitate rigorous study."], [11, "there be no specific drug or vaccine target sars-cov-2 currently and only symptomatic treatment be be administer, but several antiviral be under active investigation."], [11, "in this review, we have summarize the epidemiology, entry mechanism, immune response, and therapeutic implication, possible drug target, their ongoing clinical trial, and put forward vital question to offer new direction to the covid-19 research."], [12, "in december 2019, twenty-seven pneumonia patient with unknown cause originate in south china seafood market in wuhan."], [12, "the virus infection spread rapidly and sweep through china in less than a month."], [12, "subsequently, the virus be prove a novel coronavirus and name sars-cov-2."], [12, "the outbreak of novel coronavirus have be determine as a public health emergency of international concern (pheic) by who on january 31, 2020."], [12, "similar to other coronaviruse like the middle east respiratory syndrome (mers) cov and severe acute respiratory syndrome (sars) cov, the novel coronavirus be report to spread via respiratory droplet and close contact from human to human, which mean the virus be highly infectious and dangerous."], [12, "unfortunately, till now the virus have spread to over 200 country/territory/area around the world and the coronavirus disease 2019 (covid-19) outbreak be continue to grow."], [12, "currently, information sharing and transparency be essential for risk assessment and epidemic control in all endemic area."], [12, "in this article, we compare sars-cov-2 with sars-cov and influenza virus, discuss current researching progress of covid-19, include clinical characteristic, pathological change, treatment measure, and so on."], [13, "coronavirus disease 2019 (covid-19) be an infectious disease cause by coronavirus-2 (sars-cov-2) that cause a severe acute respiratory syndrome, a characteristic hyperinflammatory response, vascular damage, microangiopathy, angiogenesis and widespread thrombosis."], [13, "four stage of covid-19 have be identify: the first stage be characterise by upper respiratory tract infection; the second by the onset of dyspnoea and pneumonia; the third by a worsen clinical scenario dominate by a cytokine storm and the consequent hyperinflammatory state; and the fourth by death or recovery."], [13, "currently, no treatment can act specifically against the sars-cov-2 infection."], [13, "base on the pathological feature and different clinical phase of covid-19, particularly in patient with moderate to severe covid-19, the class of drug use be antiviral agent, inflammation inhibitor/antirheumatic drug, low molecular weight heparin, plasma, and hyperimmune immunoglobulin."], [13, "during this emergency period of the covid-19 outbreak, clinical researcher be use and test a variety of possible treatment."], [13, "base on these premise, this review aim to discuss the most update pharmacological treatment to effectively act against the sars-cov-2 infection and support researcher and clinician in relation to any current and future development in cure covid-19 patient."], [14, "coronavirus disease 2019 (covid-19) start as an epidemic in wuhan in 2019, and have since become a pandemic."], [14, "group from china identify and sequence the virus responsible for covid-19, name severe acute respiratory syndrome coronavirus 2 (sars-cov-2), and determine that it be a novel coronavirus share high sequence identity with bat- and pangolin-derive sars-like coronaviruse, suggest a zoonotic origin."], [14, "sars-cov-2 be a member of the coronaviridae family of envelop, positive-sense, single-strand rna virus that infect a broad range of vertebrate."], [14, "the rapid release of the sequence of the virus have enable the development of diagnostic tool."], [14, "additionally, serological test can now identify individual who have be infect."], [14, 'sars-cov-2 infection be associate with a fatality rate of around 1-3%, which be commonly link to the development of acute respiratory distress syndrome (ards), likely result from uncontrolled immune activation, the so call "cytokine storm".'], [14, "risk factor for mortality include advanced age, obesity, diabetes, and hypertension."], [14, "drug repurpose have be use to rapidly identify potential treatment for covid-19, which could move quickly to phase iii."], [14, "well knowledge of the virus and its enzyme will aid the development of more potent and specific direct-act antiviral."], [14, "in the long term, a vaccine to prevent infection be crucial; however, even if successful, it might not be available before 2021-22."], [14, "to date, except for intravenous remdesivir and dexamethasone, which have modest effect in moderate to severe covid-19, no strong clinical evidence support the efficacy of any other drug against sars-cov-2."], [14, "the aim of this review be to provide insight on the discovery of sars-cov-2, its virology, diagnostic tool, and the ongoing drug discovery effort."], [15, "the covid-19 pandemic cause by sars-cov-2 have spread rapidly."], [15, "to date, country have rely on the prevention of the disease through isolation, quarantine, and clinical care of affect individual."], [15, "however, study on the role of asymptomatic and mildly infect subject in disease transmission, use of antiviral drug, and vaccination of the general population will be very important for mitigate the effect of the eventual return of this pandemic."], [15, "initial investigation be ongoing to evaluate antigenic structure of sars-cov-2 and the immunogenicity of vaccine candidate."], [15, "there also be a need to comprehensively compile the detail of previous study on sars-relate vaccine that can be extrapolate to identify potent vaccine target for develop covid-19 vaccine."], [15, "this review aim to analyze previous study, current status, and future possibility for produce sars-cov-2 vaccine."], [16, "report that the over-the-counter histamine h receptor antagonist famotidine could help treat the novel coronavirus disease (covid-19) appear from april 2020."], [16, "we, therefore, examine report on interaction between severe acute respiratory syndrome coronavirus 2 (sars-cov-2) and histamine receptor antagonist."], [16, "a systematic literature search be perform by 19 september 2020, and update on 28 october 2020, in pubmed, scopus, cochrane library and google scholar use (covid-19 or coronavirus or sars-cov-2) and (histamine antagonist or famotidine or cimetidine)."], [16, "clinicaltrials.gov be search for covid-19 and (famotidine or histamine)."], [16, "famotidine may be a useful addition in covid-19 treatment, but the result from prospective randomized trial be as yet await."], [16, "bioinformatics/drug repurpose study indicate that, among several medicine, h and h receptor antagonist may interact with key viral enzyme."], [16, "however, in vitro study have to date fail to show a direct inhibition of famotidine on sars-cov-2 replication."], [16, "clinical research into the potential benefit of h receptor antagonist in manage covid-19 inflammation begin from a simple observation and now be be test in multi-centre clinical trial."], [16, "the positive effect of famotidine may be due to h receptor-mediate immunomodulatory action on mast cell histamine-cytokine cross-talk, rather than a direct action on sars-cov-2."], [17, "a fast and accurate self-test tool for covid-19 diagnosis have become a prerequisite to comprehend the exact number of case worldwide and to take medical and governmental action accordingly."], [17, "sars-cov-2 (formerly, 2019-ncov) infection be first report in wuhan (china) in december 2019,"], [17, "and then it have rapidly spread around the world, cause 14 million active case with 582,000 death as of july 2020."], [17, "the diagnosis tool available so far have be base on a) viral gene detection, b) human antibody detection, and c) viral antigen detection, among which the viral gene detection by rt-pcr have be find as the most reliable technique."], [17, 'in this report, the current sars-cov-2 detection kit, exclusively the one that be issue an "emergency use authorization" from the u.s. food and drug administration, be discuss.'], [17, "the key structural component of the virus be present to provide the audience with an understanding of the scientific principle behind the testing tool."], [17, "the method that be still in the early research state be also review in a subsection base on the report available so far."], [18, "at the end of december 2019, a novel coronavirus tentatively name sars-cov-2 in wuhan, a central city in china, be announce by the world health organization."], [18, "sars-cov-2 be an rna virus that have become a major public health concern after the outbreak of the middle east respiratory syndrome-cov (mers-cov) and severe acute respiratory syndrome-cov (sars-cov) in 2002 and 2012, respectively."], [18, "as of 29 october 2020, the total number of covid-19 case have reach over 44 million worldwide, with more than 1.17 million confirm death."], [18, "sars-cov-2 infect patient usually present with severe viral pneumonia."], [18, "similar to sars-cov, the virus enter respiratory tract cell via the angiotensin-convert enzyme receptor 2."], [18, "the structural protein play an essential role in bud the virus particle release from different host cell."], [18, "to date, an approve vaccine or treatment option of a preventive character to avoid severe course of covid-19 be still not available."], [18, "in the present study, we provide a brief review of the general biological feature of covs and explain the pathogenesis, clinical symptom and diagnostic approach regard monitor future infectivity and prevent emerge covid-19 infection."], [19, "severe acute respiratory syndrome coronavirus 2 (sars-cov-2) be a highly transmissible and pathogenic coronavirus that emerge in late 2019 and have cause a pandemic of acute respiratory disease, name 'coronavirus disease 2019' (covid-19), which threaten human health and public safety."], [19, "in this review, we describe the basic virology of sars-cov-2, include genomic characteristic and receptor use, highlight its key difference from previously know coronaviruse."], [19, "we summarize current knowledge of clinical, epidemiological and pathological feature of covid-19, as well as recent progress in animal model and antiviral treatment approach for sars-cov-2 infection."], [19, "we also discuss the potential wildlife host and zoonotic origin of this emerge virus in detail."], [20, "coronavirus disease 2019 (covid-19) have the characteristic of high transmission, diverse clinical manifestation, and a long incubation period."], [20, "in addition to infect the respiratory system, covid-19 also have adverse effect on the cardiovascular system."], [20, "covid-19 cause acute myocardial injury, as well as chronic damage to the cardiovascular system."], [20, "the present review be aim at provide current information on covid-19 and the cardiovascular system."], [20, "pubmed, scopus, science direct, and google scholar be search."], [20, "it be suggest that heart injury cause by covid-19 infection might be an important cause of severe clinical phenotype or adverse event in affected patient."], [20, "myocardial damage be closely relate to the severity of the disease and even the prognosis in patient with covid-19."], [20, "in addition to disorder that be cause by covid-19 on the cardiovascular system, more protection should be employ for patient with preexist cardiovascular disease (cvd)."], [20, "hence, it be very important that once relevant symptom appear, patient with covid-19 be rapidly treat to reduce mortality."], [20, "thus, early measurement of cardiac damage  biomarker follow hospitalization for covid-19 infection in a patient with preexist cvd be recommend, together with careful monitoring of any myocardial injury that might be cause by the infection."], [20, ": : an intensive care unit; : 2019 novel coronavirus; : ace inhibitor; : acute coronary syndrome; : acute respiratory distress syndrome; : ang ii type 1 receptor; : adenosine triphosphate; : american college of cardiology; : angiotensin convert enzyme; : angiotensin ii; : angiotensin ii receptor blocker; : atrioventricular block; : coronary artery disease; : cardiovascular disease; : computerized tomography; : congestive heart failure; : coronary heart disease; :"], [20, "creatine kinase isoenzyme-mb; : c-reactive protein; : cardiac troponin i; : epicardial adipose tissue; : extracorporeal membrane oxygenation; : food and drug administration; : granulocyte colony-stimulate factor; : hf with a reduce ejection fraction; : human isoform of ace2; : interleukin; : intra-aortic balloon counterpulsation; : interferon \u03B3-induce protein 10 kda; : lysophosphatidylcholine; : mitochondrial assembly receptor; : monocyte chemoattractant protein-1; : middle east respiratory syndrome; : macrophage inflammatory protein 1a: : multiple organ failure; : myocardial infarction; : magnetic resonance imaging; : myohe-moglobin; : n-terminal pro-brain natriuretic peptide; : percutaneous cardiopulmonary assistance; : recombinant human ace2; : severe acute respiratory syndrome; : t helper; : renin-angiotensin system; : tumor necrosis factor-\u03B1; : world health organization."], [21, "with the emergence of covid-19 extensive research begin to identify medication, candidate compound and other therapeutic approach."], [21, "the complex virology of covid-19 may provide multiple potential target point for antiviral therapy, and vaccine; extensive global research be underway to exploit these potential opportunity."], [21, "the complex pathophysiology, pulmonary and extrapulmonary disease, and immune mediate effect such as cytokine storm, make medical management more challenging than many viral illness."], [21, "non medication base intervention include hyperbaric oxygen (hbot), extracorporeal membrane oxygenation (ecmo), aggressive dialysis, and other intervention, all with various degree of clinical success, and will be discuss in this section."], [21, "several antiviral approve for other clinical indication be study for repurpose against covid-19, which we highlight, again with vary result."], [21, "in addition to therapeutic, concern be raise over potential risk associate with ace inhibitor and arb use, which be present."], [21, "often the timing of the medication determine its clinical benefit as will be discuss with dexamethasone and other medication."], [21, "as such, this therapeutics review will present prominent and/or promise medication and therapeutic approach with the caveat that 1."], [21, "to date, none be fda approve beyond emergency use authorization (eua), and 2."], [21, "although a comprehensive look at various class of intervention, it be by no mean a complete list of every compound triale against covid-19."], [21, "recognize the knowledge basis upon which we treat covid-19 patient, develop therapeutic, and vaccine continue to evolve as new information be present, every effort nevertheless have be make to provide as timely information as possible."], [21, "it be hope that the information share can help guide the clinician in term of potential option to treat this complex group of patient."], [22, 'coronavirus disease 2019 (covid-19) infection which be cause by severe acute respiratory syndrome coronavirus-2 (sars-cov-2) have lead to a "public health emergency of international concern" (pheic).'], [22, "the infection be highly contagious, have a high mortality rate, and its pathophysiology remains poorly understand."], [22, "pulmonary inflammation with substantial lung damage together with generalize immune dysregulation be major component of covid-19 pathogenesis."], [22, "the former component, lung damage, seem to be at least in part a consequence of immune dysregulation."], [22, "indeed, study have reveal that immune alteration be not merely an association, as it might occur in systemic infection, but, very likely, the core pathogenic element of covid-19."], [22, "in addition, precise management of immune response in covid-19, i.e. enhance anti-viral immunity while inhibit systemic inflammation, may be key to successful treatment."], [22, "herein, we have review current evidence relate to different aspect of covid-19 immunology, include innate and adaptive immune response against the virus and mechanism of virus-induce immune dysregulation."], [22, "consider that current antiviral therapy be chiefly experimental, strategy to do immunotherapy for the management of disease have also be review."], [22, "understand immunology of covid-19 be important in develop effective therapy as well as diagnostic, and prophylactic strategy for this disease."], [23, "sars-cov-2 be a novel virus that cause coronavirus disease-19 (covid-19)."], [23, "antiviral and immunomodulatory agent have be propose as potential treatment."], [23, "azithromycin exhibit both property and therefore may play a role."], [23, "this article review the pharmacology, pharmacokinetic, clinical efficacy, and safety of azithromycin in viral infection, with emphasis on covid-19."], [23, "a literature search of pubmed be conduct on may 30 and update on july 28."], [23, "azithromycin present  activity against sars-cov-2 and could act in different point of the viral cycle."], [23, "its immunomodulatory property include the ability to downregulate cytokine production, maintain epithelial cell integrity or prevent lung fibrosis."], [23, "azithromycin use be associate with a reduction in mortality and ventilation day in other viral infection."], [23, "these property could be beneficial throughout the covid-19."], [23, "however, the evidence of its use be scarce and of low quality."], [23, "azithromycin have be assess in retrospective observational study mainly in combination with hydroxychloroquine, which have show to provide no benefit."], [23, "this macrolide present a well-know safety profile."], [23, "upcoming clinical trial will determine the role of azithromycin in the covid-19 (include the stage of the disease where it offer the great benefit and the effect of its combination with other drug)."], [24, "covid-19, cause by sars-cov-2, emerge as the deadly outbreak that have now become a serious health issue to mankind."], [24, "activation of inflammatory signal pathway and cytokine storm be crucial factor that lead to acute respiratory distress syndrome (ards) in covid-19 patient."], [24, "excessive secretion of pro-inflammatory cytokine and chemokine lead to the dysregulation of the innate immune system."], [24, "the cytokine storm attract many inflammatory cell that infiltrate into the lung tissue and ultimately cause immune damage."], [24, "in addition to the dysregulation of the immune system, dysfunction of the renin-angiotensin system (ras) due to the downregulation of ace2 be also associate with the mortality of covid-19 patient."], [24, "both the mechanism be directly or indirectly associate with cytokine storm that promote vascular hyperpermeability, vascular edema lead to hypercoagulation and hence multiorgan damage."], [24, "as of now, there be no specific treatment available for covid-19, but scientist have purpose several treatment option include cytokine inhibitor, jak inhibitor, immunomodulator, plasma therapy, etc."], [24, "in this article, we have provide the detailed mechanism of occurrence of sars-cov-2 induce inflammatory storm and its connection with the pre-exist inflammatory condition."], [24, "possible treatment option to cope up with the severe clinical manifestation of covid-19 be also discuss."], [25, "currently, the world be in the seventh month of the covid-19 pandemic."], [25, "globally, infection with novel sars-cov-2 virus be continuously rise with mount number of death."], [25, "international and local public health response, almost in synchrony, impose restriction to minimize spread of the virus, overload of health system capacity, and deficit of personal protective equipment (ppe)."], [25, "although in most case the symptom be mild or absent, sars-cov-2 infection can lead to serious acute respiratory disease and multisystem failure."], [25, "the research community respond to this new disease with a high level of transparency and datum sharing; with the aim to well understand the origin, pathophysiology, epidemiology and clinical manifestation."], [25, "the ultimate goal of this research be to develop vaccine for prevention, mitigation strategy, as well as potential therapeutic."], [25, "the aim of this review be to summarize current knowledge regard the novel sars cov-2, include its pathophysiology and epidemiology, as well as, what be know about the potential impact of covid-19 on reproduction, fertility care, pregnancy and neonatal outcome."], [25, "this summary also evaluate the effect of this pandemic on reproductive care and research, from canadian perspective, and discuss future implication."], [25, "in summary, report datum on pregnant woman be limit, suggest that covid-19 symptom and severity of the disease during pregnancy be similar to those in non-pregnant woman, with pregnancy outcome closely relate to severity of maternal disease."], [25, "evidence of sars-cov-2 effect on gamete be limited."], [25, "human reproduction society have issue guideline for practice during covid-19 pandemic that include implementation of mitigation practice and infection control protocol in fertility care unit."], [25, "in canada, impose restriction at the beginning of the pandemic be successful in contain spread of the infection, allow for eventual resumption of assist reproductive treatment under new guideline for practice."], [25, "canada dedicated fund to support covid-19 research include a surveillance study to monitor outcome of covid-19 during pregnancy and assist reproduction."], [25, "continuous evaluation of new evidence must be in place to carefully adjust recommendation on patient management during assist reproductive technology (art) and in pregnancy."], [26, "the severe acute respiratory syndrome coronavirus (sars-cov-2) that emerge in december 2019 as the causative agent of coronavirus 2019 (covid-19) and be declare a pandemic by the world health organization in march 2020 have several distinctive feature, include extensive multiorgan involvement with a robust systemic inflammatory response, significant associate morbidity and mortality, and prolong persistence of viral rna in the clinical specimen of infect individual as detect by reverse transcription polymerase chain reaction (rt-pcr) amplification."], [26, "this review begin with an overview of sars-cov-2 morphology and replication and summarize what be know to date about the detection of the virus in nasal, oropharyngeal, and fecal specimen of patient who have recover from covid-19, with a focus on the factor think to contribute to prolong detection."], [26, "this review also provide a discussion on the infective potential of this material from asymptomatic, pre-symptomatic, and convalesce individual, to include a discussion of the relative persistence and infectious potential of virus in clinical specimen recover from pediatric covid-19 patient."], [27, "the sars-cov-2 novel coronavirus have cause the covid-19 pandemic with over 35 million case and over a million death worldwide as of early october 2020."], [27, "the population most affect be the elderly and especially those with underlying comorbiditie."], [27, "in term of race and ethnicity, black and hispanic population be affect at disproportionately high rate."], [27, "individual with underlying condition that cause an immune-compromise state be consider vulnerable to this infection."], [27, "the immune response be an important determinant in viral infection include coronaviruse, not only in the antiviral defense but also in the disease progression, severity, and clinical outcome of covid-19."], [27, "systemic lupus erythematosus be a chronic autoimmune disease which also disproportionately afflict black and hispanic population."], [27, "in lupus patient, an aberrant immune response be characterize by the presence of circulate autoantibody, lymphopenia, aberrant t cell, and proinflammatory cytokine along with defective regulatory mechanism, lead to immune-mediate damage to tissue."], [27, "lupus patient be often treat with immune-suppressant and therefore be immune-compromise and more susceptible to infection and may be vulnerable to coronavirus infection."], [27, "while the anti-viral immune response be important to protect from coronavirus infection, an uncontrolled proinflammatory cytokine response can lead to cytokine storm which cause damage to the lung and other organ, cause significant morbidity and mortality."], [27, "well understanding of the underlying immune response and therapeutic strategy in lupus and covid-19 be important to guide management of this deadly infectious disease in the context of lupus and vice-versa."], [28, "little be know about the sequelae of sars-cov-2 infection in child."], [28, "in a covid-19 dedicated clinic, we follow-up for 4 month 25 child previously hospitalize for covid-19, perform clinical, laboratory, and lung ultrasound evaluation."], [28, "mid-term sequelae be rarely observe in our covid-19 child's cohort."], [29, "old individual be more susceptible to various infection due to immunological change that occur during the age process."], [29, 'these change name collectively as "immunosenescence" include decrease in both the innate and adaptive immune response in addition to the exacerbate production of inflammatory cytokine.'], [29, "this scenario of immunological dysfunction and its relationship with disease development in old people have be widely study, especially in infection that can be fatal, such as influenza and, more recently, covid-19."], [29, "in the current scenario of sars-cov-2 infection, many mechanism of disease pathogenesis in old individual have be propose."], [29, "to well understand the dynamic of covid-19 in this group, aspect relate to immunological senescence must be well elucidated."], [29, "in this article, we discuss the main mechanism involve in immunosenescence and their possible correlation with the susceptibility of individual of advanced age to sars-cov-2 infection and the more severe condition of the disease."], [30, "covid-19 be cause by sars-cov-2 which be a new envelop virus that belong to the beta coronavirus genus."], [30, "as a major health crisis, sars-cov-2 have infect over a million people around the world."], [30, "there be currently no specific treatment available for patient with covid-19 infection."], [30, "numerous potential therapy, include supportive intervention, immunomodulatory agent, antiviral therapy, and convalescent plasma transfusion, have be use in clinical practice."], [30, "herein, we summarize the current potential therapeutic approach for disease relate to covid-19 infection and discuss the clinical value of blood transfusion-relate technology use in covid-19 treatment."], [31, "exposure to air pollutant have be previously associate with respiratory viral infection, include influenza, measle, mump, rhinovirus, and respiratory syncytial virus."], [31, "epidemiological study have also suggest that air pollution exposure be associate with increase case of sars-cov-2 infection and covid-19-associate mortality, although the molecular mechanism by which pollutant exposure affect viral infection and pathogenesis of covid-19 remain unknown."], [31, "in this review, we suggest potential molecular mechanism that could account for this association."], [31, "we have focus on the potential effect of exposure to nitrogen dioxide (no ), ozone (o ), and particulate matter (pm) since there be study investigate how exposure to these pollutant affect the life cycle of other virus."], [31, "we have conclude that pollutant exposure may affect different stage of the viral life cycle, include inhibition of mucociliary clearance, alteration of viral receptor and protease require for entry, change to antiviral interferon production and viral replication, change in viral assembly mediate by autophagy, prevention of uptake by macrophage, and promotion of viral spread by increase epithelial permeability."], [31, "we believe that exposure to pollutant skews adaptive immune response toward bacterial/allergic immune response, as oppose to antiviral response."], [31, "exposure to air pollutant could also predispose expose population toward develop coivd-19-associate immunopathology, enhance virus-induce tissue inflammation and damage."], [32, "coronavirus disease-2019 (covid-19) be declare a global pandemic on 11 march 2020."], [32, "scientist and clinician must acknowledge that severe acute respiratory syndrome coronavirus 2 (sars-cov-2) have the potential to attack the human body in multiple way simultaneously and exploit any weakness of its host."], [32, "a multipronged attack could potentially explain the severity and extensive variety of sign and symptom observe in patient with covid-19."], [32, "understand the diverse tactic of this virus to infect the human body be both critical and incredibly complex."], [32, "although patient diagnose with covid-19 have primarily present with pulmonary involvement, viral invasion, and injury to diverse end organ be also prevalent and well document in these patient, but have be largely unheeded."], [32, "human organ know for angiotensin-convert enzyme 2 (ace2) expression include the gastrointestinal tract, kidney, heart, adrenal, brain, and testicle be example of extra pulmonary tissue with confirm invasion by sars-cov-2."], [32, "initial multiple organ involvement may present with vague sign and symptom to alert health care professional early in the course of covid-19."], [32, "another example of an ongoing, yet neglect element of the syndromic feature of covid-19, be the reported finding of loss of smell, alter taste, ataxia, headache, dizziness, and loss of consciousness, which suggest a potential for neural involvement."], [32, "in this review, we far deliberate on the neuroinvasive potential of sars-cov-2, the neurologic symptomology observe in covid-19, the host-virus interaction, possible route of sars-cov-2 to invade the central nervous system, other neurologic consideration for patient with covid-19, and a collective call to action."], [33, "coronavirus disease-19 (covid-19) be cause by severe acute respiratory syndrome coronavirus 2 (sars-cov-2)."], [33, "sars-cov-2 be closely relate to two other coronaviruse that cause disease epidemic breakout in human in the last 2 decade, namely, severe acute respiratory distress syndrome coronavirus (sars-cov) and middle east respiratory syndrome coronavirus (mers-cov)."], [33, "the similarity have enable the scientist to apply the basic scientific discovery garner from study the structure and modus operandi of sars-cov and mer-cov to develop therapy that specifically target sars-cov-2 and to develop vaccine to prevent covid-19."], [33, "target therapy include the use of antibody to prevent virus entry, nucleotide analogue to prevent viral replication, and inhibitor of protease to prevent virion formation, among other, be be test for their clinical efficacy."], [33, "likewise, complete sequencing of the sars-cov-2 and identification of its structural and nonstructural protein have enable development of rna-, dna-, and peptide-base vaccine as well attenuate viral vaccine to instigate the host-immune response."], [33, "the clinical impact of the basic science discovery be amply evident on the rapid pace of progress in develop specific antiviral therapy and vaccine against sars-cov-2."], [33, "the progress emphasize the merit of discover the fundamental scientific element, regardless of whether or not they have apparent or immediate clinical application."], [34, "type v and vi crispr enzyme be rna-guide, dna and rna-target effector that allow specific gene knockdown."], [34, "cas12 and cas13 be crispr protein that be efficient agent for diagnosis and combat single-strand rna (ssrna) virus."], [34, "the programmability of these protein pave the way for the detection and degradation of rna virus by target rnas complementary to its crispr rna (crrna)."], [34, "approximately two-third of virus cause disease contain ssrna genome."], [34, "the severe acute respiratory syndrome coronavirus 2 (sars-cov-2) have cause the outbreak of the coronavirus disease 2019 (covid-19), which have infect more than 88 million people worldwide with near 2 million death since december 2019."], [34, "thus, accurate and rapid diagnostic and therapeutic tool be essential for early detection and treatment of this widespread infectious disease."], [34, "for we, the crispr base platform seem to be a plausible new approach for an accurate detection and treatment of sars-cov-2."], [34, "in this review, we talk about cas12 and cas13 crispr system and their application in diagnosis and treatment of rna virus mediate disease."], [34, "in continue, the sars-cov-2 pathogenicity, and its conventional diagnostic and antiviral will be discuss."], [34, "moreover, we highlight novel crispr base diagnostic platform and therapy for covid-19."], [34, "we also discuss the challenge of diagnostic crispr base platform as well as clarify the propose solution for high efficient selective in vivo delivery of crispr component into sars-cov-2-infect cell."], [35, "covid-19, the human coronavirus disease cause by sars-cov-2, be report for the first time in wuhan, china in late 2019."], [35, "covid-19 have no preventive vaccine or prove standard pharmacological treatment, and consequently, the outbreak swiftly become a pandemic affect more than 215 country around the world."], [35, "for the diagnosis of covid-19, the only reliable\xA0diagnostic\xA0be a\xA0qpcr assay."], [35, "among other diagnostic tool, the crispr-cas system be be investigate for rapid and specific diagnosis of covid-19."], [35, "the crispr-cas-base method diagnose the sars-cov-2 infection within an hour."], [35, "apart from its diagnostic ability,\xA0crispr-cas system be also be assess for antiviral therapy development; however, till date, no crispr-base therapy have be approve for human use."], [35, "the prophylactic antiviral crispr in human cell (pac-man), which be cas 13 base strategy, have be develop against coronavirus."], [35, "although this strategy have the potential to be develop as a therapeutic modality, it may face significant challenge for approval in human clinical trial."], [35, "this review be focus on describe potential use and challenge of crispr-cas base approach for the development of rapid and accurate diagnostic technique and/or a possible therapeutic alternative for combat covid-19."], [35, "the assessment of potential risk associate with use of crispr will be important for future clinical advancement."], [36, "the global pandemic of coronavirus disease 2019 (covid-19) have bring the world to a grind halt."], [36, "a major cause of concern be the respiratory distress associate mortality attribute to the cytokine storm."], [36, "despite myriad rapidly approve clinical trial with repurposed drug, and time need to develop a vaccine, accelerate search for repurposed therapeutic be still ongoing."], [36, "in this review, we present nitazoxanide a us-fda approve antiprotozoal drug, as one such promising candidate."], [36, "nitazoxanide which be report to exert broad-spectrum antiviral activity against various viral infection, reveal good in vitro activity against sars-cov-2 in cell culture assay, suggest potential for repurpose in covid-19."], [36, "furthermore, nitazoxanide display the potential to boost host innate immune response and thereby tackle the life-threaten cytokine storm."], [36, "possibility of improve lung, as well as multiple organ damage and provide value addition to covid-19 patient with comorbiditie, be other important facet of the drug."], [36, "the review juxtapose the role of nitazoxanide in fight covid-19 pathogenesis at multiple level highlight the great promise the drug exhibit."], [36, "the in silico datum and in vitro efficacy in cell line confirm the promise of nitazoxanide."], [36, "several approve clinical trial world over far substantiate leverage nitazoxanide for covid-19 therapy."], [37, "the ongoing coronavirus disease 2019 (covid-19) pandemic be a rapidly evolve situation."], [37, "new discovery about covid-19 and its causative virus, severe acute respiratory syndrome coronavirus 2 (sars-cov-2), continue to deepen the understanding of this novel disease."], [37, "as there be currently no covid-19 specific treatment, isolation be the most effective method to prevent transmission."], [37, "moreover, development of a safe and effective covid-19 vaccine will be instrumental in reinstate pre-covid-19 condition."], [37, "as of 31\xA0july\xA02020, there be at least 139 vaccine candidate from around the globe in preclinical evaluation, with another 26 undergo clinical evaluation."], [37, "this paper aim to review the basic of covid-19, include epidemiology, basic biology of sars-cov-2, and transmission."], [37, "we also review covid-19 vaccine development, include animal model, platform under development, and vaccine development in canada."], [38, "the recent emergence of severe acute respiratory syndrome coronavirus 2 (sars-cov-2) lead to a current pandemic of unprecedented scale."], [38, "although diagnostic test be fundamental to the ability to detect and respond, overwhelmed healthcare system be already experience shortage of reagent associate with this test, call for a lean immediately applicable protocol."], [38, "rna extract of positive sample be test for the presence of sars-cov-2 use reverse transcription quantitative polymerase chain reaction, alone or in pool of different size (2-, 4-, 8-, 16-, 32-, and 64-sample pool) with negative sample."], [38, "transport medium of additional 3 positive sample be also test when mix with transport medium of negative sample in pool of 8."], [38, "a single positive sample can be detect in pool of up to 32 sample, use the standard kit and protocol, with an estimate false negative rate of 10%."], [38, "detection of positive sample dilute in even up to 64 sample may also be attainable, although this may require additional amplification cycle."], [38, "single positive sample can be detect when pool either after or prior to rna extraction."], [38, "as it use the standard protocol, reagent, and equipment, this pooling method can be apply immediately in current clinical testing laboratory."], [38, "we hope that such implementation of a pool test for coronavirus disease 2019 would allow expand current screening capacity, thereby enable the expansion of detection in the community, as well as in close organic group, such as hospital department, army unit, or factory shift."], [39, "the coronavirus disease-2019 (covid-19) which cause by severe acute respiratory syndrome-relate coronavirus (sars-cov-2), be a pandemic threat to global public health."], [39, "it have a wide spectrum of clinical manifestation from mild to critical illness, the most serious of which be the complication of acute respiratory distress syndrome (ards)."], [39, "sars-cov-2 infection appear mild in infant and child, however, in adult, it can lead to serious consequence."], [39, "in this review, we highlight the difference between the immune response of the lung in child and adult, immune dysregulation and their possible role in clinical manifestation in covid-19."], [39, "there be a reduction in population of immunocompetent cell during aging and subsequently induce ineffective inflammation in the face of some infection."], [39, "dysregulation in the immune system can lead to an unappropriated local and systemic immune response and subsequently the rapid spread of the virus, lead to severe covid-19 disease."], [39, "therefore, recognize the difference in the immune response of various host as well as to improve the immune system disorder should always be part of research and treatment protocol."], [40, "in the recent sars-cov-2 pandemic, public health expert have emphasize testing, track infected people, and trace their contact as an effective strategy to reduce the spread of the virus."], [40, "several diagnostic method be report for detect the coronavirus in clinical, research, and public health laboratory."], [40, "some test detect the infection directly by detect the viral rna and other test detect the infection indirectly by detect the host antibodie."], [40, "a diagnostic test during the pandemic should help make an appropriate clinical decision in a short period of time."], [40, "recently report diagnostic method for sars-cov-2 have vary throughput, batch capacity, requirement of infrastructure setting, analytical performance, and turnaround time range from a few minute to several hour."], [40, "these factor should be consider while select a reliable and rapid diagnostic method to help make an appropriate decision and prompt public health intervention."], [40, "this paper review recent sars-cov-2 diagnostic method publish in journal and report release by regulatory agency."], [40, "we compare the analytical efficiency include limit of detection, sensitivity, specificity, and throughput."], [40, "in addition, we also look into ease of use, affordability, and availability of accessory."], [40, "finally, we discuss the limitation of the method and provide our perspective on priority for future test development."], [41, "the covid-19 pandemic, cause by severe acute respiratory syndrome coronavirus 2 (sars-cov-2), be a source of significant morbidity and death worldwide, and effective treatment be urgently need."], [41, "clinical trial have focus largely on direct antiviral therapy or on immunomodulation in patient with severe manifestation of covid-19."], [41, "one therapeutic approach that remain to be clinically investigate be disruption of the host-virus relationship through amino acid restriction, a strategy use successfully in the setting of cancer treatment."], [41, "arginine be an amino acid that have be show in nonclinical study to be essential in the life cycle of many virus."], [41, "therefore, arginine depletion may be an effective therapeutic approach against sars-cov-2."], [41, "several arginine-metabolize enzyme in clinical development may be a viable approach to induce a low arginine environment to treat covid-19 and other viral disease."], [41, "herein, we explore the rationale for arginine depletion as a therapeutic approach for covid-19."], [42, "asymptomatic individual with coronavirus disease (covid-19) have be identify via nucleic acid testing for severe acute respiratory syndrome coronavirus 2 (sars-cov-2); however, the epidemiologic characteristic and viral shedding pattern of asymptomatic patient remain largely unknown."], [42, "in this study, serological testing be apply when identify nine asymptomatic case of covid-19 who show persistent negative rt-pcr test result for sars-cov-2 nucleic acid and no symptom of covid-19."], [42, "two asymptomatic case be presume to be index patient who have clear the virus when their close contact develop symptom of covid-19."], [42, "three of the asymptomatic case be local individual who spontaneously recover before their presume index patient develop symptom of covid-19."], [42, "this report present the epidemiologic and clinical characteristic of asymptomatic individual with sars-cov-2 infection that be undetecte on rt-pcr test in previous epidemiologic investigation probably due to the transient viral shed duration."], [43, "severe acute respiratory syndrome coronavirus 2 (sars-cov-2) be a new member of the coronavirus family that can cause coronavirus disease 2019 (covid-19)."], [43, "covid-9 have become a global pandemic with severe health issue around the world."], [43, "identify the accurate immunopathogenesis of the covid-19 and the immune response against sars-cov-2 be necessary for the development of therapeutic approach and rational drug design."], [43, "this paper aim to overview the update clinical datum on the immunopathogenesis of the covid-19 and review the innate and adaptive immune response to sars-cov-2."], [43, "also, challenge of the immune response to sars-cov-2 lead to dysfunctional immune response and their contribution to the progression of the disease have be discuss."], [43, "to achieve a more efficient immune response, multiple method could be apply, include regulation of the immune response, augmentation of the immune system against the virus, inhibition of the dysfunctional immune checkpoint, and inhibition of the viral replication/infection."], [43, "base on the immune response against sars-cov-2 and its dysfunction, we introduce potential immunotherapy as well as review recruit/complete clinical trial of covid-19."], [44, "covid-19 be a new contagious disease cause by a new coronavirus know as severe acute respiratory syndrome coronavirus 2 (sars-cov-2)."], [44, "covid-19 be a disease that have reach every continent in the world; it have overload the medical system worldwide and it have be declare a pandemic by the world health organization."], [44, "currently there be no definite treatment for covid-19."], [44, "we realize that host immunity be a critical factor in the outcome of coronavirus 2 infection."], [44, "here, however, we review the pathophysiology of the disease with a focus on search for what we can do to combat this new disease."], [44, "from this, we find that coronavirus be sensitive to heat."], [44, "we have thus focus on this area of vulnerability of the virus."], [44, "the emphasis of this hypothesis be on the action of body heat-internal (fever) and external (heat treatment)-in activate the immune system and its antiviral activity, and specifically related to the coronavirus."], [44, "we hypothesize from this review that heat treatment have the potential to prevent covid-19 and to decrease the severity of mild and moderate case of coronavirus."], [44, "we propose heat treatment for this uncontrolled worldwide coronavirus pandemic while study be be do to test the effectiveness of heat treatment in the prevention and treatment of covid-19."], [45, "every day additional confirmed case of sars-cov-2 reinfection be be report across the globe."], [45, "in the netherlands more than 50 case of probable reinfection have be identify."], [45, "with more than 500 thousand people in the netherlands who have be infect with sars-cov-2 up till now this number do seem to be quite low."], [45, "still, important question have to be ask."], [45, "how do we define reinfection and how do these reinfection compare to other (corona) virus?"], [45, "what be the immunological significance?"], [45, "what be the duration of protective immunity?"], [45, "and what do covid-19 reinfection mean for the prevention and development of a vaccine?"], [45, "the describe case of re-infection do teach we that a sars-cov-2 vaccine should also be consider for people with a document covid-19 infection in the past and that general precaution, such as the use of face mask and social distancing, still apply to those with a previous sars-cov-2 infection."], [46, "the recent pandemic have pose perhaps the big challenge for pcr to date."], [46, "be pcr likely to be replace or will it continue to stand the test of time?"], [46, "[formula: see text]."], [47, "the recently emerge severe acute respiratory syndrome coronavirus-2 (sars-cov-2) spread all over the world rapidly and cause a global pandemic."], [47, "to prevent the virus from spread to more individual, it be of great importance to identify and isolate infected individual through testing."], [47, "reverse transcription-quantitative polymerase chain reaction (rt-qpcr) be the gold standard method for the diagnosis of coronavirus disease (covid-19) worldwide."], [47, "however, perform rt-qpcr be limit to centralized laboratory because of the need for sophisticated laboratory equipment and skilled personnel."], [47, "far, it can sometimes give false negative or uncertain result."], [47, "recently, new method have be develop for nucleic acid detection and pathogen diagnosis use crispr-cas system."], [47, "these method present rapid and cost-effective diagnostic platform that provide high sensitivity and specificity without the need for complex instrumentation."], [47, "use the crispr-base sars-cov-2 detection method, it be possible to increase the number of daily test in exist laboratory, reduce false negative or uncertain result rate obtain with rt-qpcr, and perform testing in resource-limit setting or at point of need where perform rt-qpcr be not feasible."], [47, "here, we briefly describe the rt-qpcr method, and discuss its limitation in meet the current diagnostic need."], [47, "we explain how the unique property of various crispr-associate enzyme be utilize for nucleic acid detection and pathogen diagnosis."], [47, "then, we highlight the important feature of crispr-base diagnostic method develop for sars-cov-2 detection."], [47, "finally, we examine the advantage and limitation of these method, and discuss how they can contribute to improve the efficiency of the current testing system for combat sars-cov-2."], [48, "the emergence of severe acute respiratory syndrome coronavirus 2 (sars-cov-2) mark the third highly pathogenic coronavirus to spill over into the human population."], [48, "sars-cov-2 be highly transmissible with a broad tissue tropism that be likely perpetuate the pandemic."], [48, "however, important question remain regard its transmissibility and pathogenesis."], [48, "in this review, we summarize current sars-cov-2 research, with an emphasis on transmission, tissue tropism, viral pathogenesis, and immune antagonism."], [48, "we far present advance in animal model that be important for understand the pathogenesis of sars-cov-2, vaccine development, and therapeutic testing."], [48, "when necessary, comparison be make from study with sars to provide further perspective on coronavirus infectious disease 2019 (covid-19), as well as draw inference for future investigation."], [49, "the coronavirus disease-2019 (covid-19) cause by the novel coronavirus severe acute respiratory syndrome coronavirus-2 (sars-cov-2) have rapidly develop into a global pneumonia pandemic."], [49, "cardiovascular disease be the major comorbidity of covid-19 patient and be closely relate to the severity of covid-19."], [49, "sars-cov-2 infection can directly or indirectly cause a series of cardiac complication, include acute myocardial injury and myocarditis, heart failure and cardiac arrest, arrhythmia, acute myocardial infarction, cardiogenic shock, takotsubo cardiomyopathy, and coagulation abnormality."], [49, "intensive research on the sars-cov-2-associate cardiovascular complication be urgently need to elucidate its exact mechanism and to identify potential drug target, which will help to formulate effective prevention and treatment strategy."], [49, "hence, this review will summarize recent progress regard the effect of covid-19 on the cardiovascular system and describe the underlie mechanism of cardiovascular injury cause by sars-cov-2."], [50, "innate immunity impairment lead to disruption in cascade of signal pathway upregulate pro-inflammatory cytokine, diminish interferon, deplete natural killer cell and activate reactive oxygen specie production."], [50, "these condition severely affect body's ability to fight against infectious disease and also play a pivotal role in disease progression."], [50, "here, in emphasis be on nutritional immunity for regulate effective innate immune response for combat against infectious disease like novel coronavirus disease (covid 19)."], [50, "draw from discovery on in-vitro experiment, animal model and human trial, tea polyphenol, micronutrient, and vitamin have the potential to modulate and enhance innate immune response."], [50, "this article provide a comprehensive review on tea ( l infusion (a hot water extract of dry process tea leave prepare from young shoot of tea plant) as an innate immunity modulator."], [50, "tea infusion be rich in polyphenol; epigallocatechin gallate (egcg) and theaflavin (tf), major green and black tea polyphenol, respectively."], [50, "study show their immunomodulatory competence."], [50, "tea infusion be also rich in alkaloid; caffeine and its intermediate, theophylline and theobromine, which have anti-inflammatory property."], [50, "tea plant be an acidophilic perennial crop can accumulate different micronutrient, ., copper (cu), iron (fe), manganese (mn), selenium (se), and zinc (zn) from grow medium, i.e., from soil, which lead to their considerable presence in tea infusion."], [50, "micronutrient be integral part of innate immune response."], [50, "overall, this review present tea infusion as an important source of nutritional immunity which can enhance innate immune response in order to mitigate the unprecedented covid-19 pandemic."], [51, "for covid-19, it be vital to understand if quarantine short than 14 day can be equally effective with judiciously deploy testing."], [51, "here, we develop a mathematical model that quantify the probability of post-quarantine transmission incorporate testing into travel quarantine, quarantine of trace contact with an unknown time of infection, and quarantine of case with a know time of exposure."], [51, "we find that testing on exit (or entry and exit) can reduce the duration of a 14-day quarantine by 50%, while test on entry shorten quarantine by at most one day."], [51, "in a real-world test of our theory apply to offshore oil rig employee, 47 positive be obtain with testing on entry and exit to quarantine, of which 16 have test negative at entry; prevent an expect nine offshore transmission event that each could have lead to outbreak."], [51, "we show that appropriately time testing can make short quarantine effective."], [52, "understand the system biology approach for promote the development of new therapeutic drug be attain importance nowadays."], [52, "the threat of covid-19 outbreak need to be vanish for global welfare, and every section of research be focus on it."], [52, "there be an opportunity for find new, quick, and accurate tool for develop treatment option, include the vaccine against covid-19."], [52, "the review at this moment cover various aspect of pathogenesis and host factor for explore the virus target and develop suitable therapeutic solution through system biology tool."], [52, "furthermore, this review also cover the extensive detail of multiomic tool , transcriptomic, proteomic, genomic, lipidomic, immunomic, and  computational modeling aim towards the study of host-virus interaction in search of therapeutic target against the covid-19."], [53, "the unforeseen emergence of coronavirus disease 2019 (covid-19), a severe acute respiratory syndrome coronavirus 2 (sars-cov-2) at the wuhan province of china in december 2019, subsequently its abrupt spread across the world have severely affect human life."], [53, "in a short span of time, covid-19 have sack more than one million human life and mark as a severe global pandemic, which be drastically accountable for the adverse effect directly to the human society, particularly the health care system and the economy."], [53, "the unavailability of approved and effective drug or vaccine against covid-19 far create condition more adverse and terrifying."], [53, "to win the war against this pandemic within time there be a desperate need for the most adequate therapeutic treatment, which can be achieve by the collaborative research work among scientist worldwide."], [53, "in continuation of our effort to support the scientific community, a review have be present which discuss the structure and the activity of numerous molecule exhibit promise sars-cov-2 and other covs inhibition activity."], [53, "furthermore, this review offer an overview of the structure, a plausible mechanism of action of sars-cov-2, and crucial structural feature substantial to inhibit the primary virus-base and host-base target involve in sars-cov-2 treatment."], [53, "we anticipate optimistically that this perspective will provide the reader and researcher's well understanding regard covid-19 and pave the path in the direction of covid-19 drug discovery and development paradigm."], [54, "to date, sars-cov-2 (the virus that cause covid-19) have spread to almost every region of the world, infect million and result in the death of hundred of thousand of people."], [54, "although it be predict that africa would suffer a massive loss of life due to this pandemic, the number of covid-19 case have be relatively low across the continent."], [54, "researcher have speculate that several factor may be responsible for this outcome in africa, include the extensive experience that country have with infectious disease and the young median age of their population."], [54, "however, it be still important for african country to adopt aggressive and bold approach against covid-19, in case the nature of the pandemic change."], [54, "this short review will summarize the status of the outbreak in africa and propose possible reason for current trend, as well as discuss intervention aim at prevent a rapid increase in the number of covid-19 case in the future."], [55, "despite the unprecedented effort of the scientific community, the novel sars-cov-2 virus have infect more than 46 million people worldwide, kill over one million two hundred thousand."], [55, "understand the mechanism by which some individual be more susceptible to sars-cov-2 infection and why a subgroup of they be prone to experience severe pneumonia, and death should lead to a well approach and more effective treatment for covid-19."], [55, "here, we focus our attention on ace2, a primary receptor of sars-cov-2."], [55, "we will discuss its biology, tissue expression, and post-translational regulation that determine its potential to be employ by sars-cov-2 for cell entry."], [55, "particular attention will be give to how the ace2 soluble form can have a great impact on disease progression and thus be use in a potential therapeutic strategy."], [55, "furthermore, we will discuss repercussion that sars-cov-2/ace2 binding have on the renin-angiotensin system and beyond."], [55, "indeed, although mostly neglect, ace2 can also act on [des-arg 937]-bradykinin of the kinin-kallikrein system regulate coagulation and inflammation."], [55, "thorough comprehension of the role that ace2 play in different pathway will be the key to assess the impact that sars-cov-2/ace2 binding have on organismal physiology and will help we to find well therapy and diagnostic tool."], [56, "the coronavirus disease (covid-19), identify in wuhan, china, on december 2019, be declare a pandemic by the world health organization, on march, 2020."], [56, "since then, effort have be gather to describe its clinical course and to determine preventive measure and treatment strategy."], [56, "adult old than 65 year of age be more susceptible to serious clinical symptom and present high mortality rate."], [56, "angiotensin-convert enzyme 2 (ace2) be a major receptor for some coronavirus infection, include sars-cov-2, but be also a crucial determinant in anti-inflammation process during the renin-angiotensin system (ras) function\xA0- convert angiotensin ii to angiotensin 1-7."], [56, "the decline in ace2 expression that occur with aging have be associate to the high morbidity and mortality rate in old adult."], [56, "these observation highlight the importance of investigate the association between covid-19 and age-relate neurodegenerative disorder, i.e.,\xA0parkinson's and alzheimer's disease."], [56, "a possible option to reduce the risk of covid-19 be vitamin d supplementation, due to its anti-inflammatory and immune-system-modulate effect."], [56, "it have also be suggest that vitamin d supplementation play a role in slow progression of parkinson and alzheimer."], [56, "the present study be a literature review of article publish on the theme covid-19, parkinson and alzheimer's disease, and the role play by vitamin d. pubmed, medline, and embase database be consult."], [56, "result confirm neurodegenerative and neuroinflammatory effect of covid-19, aggravate in parkinson's and alzheimer's patient, and the important role of vitamin d as a possible therapeutic strategy."], [56, "nevertheless, randomize control trial and large population study be still warrant."], [57, "novel coronavirus sars-cov-2, designate as covid-19 by the world health organization (who) on the february 11, 2020, be one of the highly pathogenic \u03B2-coronaviruse which infect human."], [57, "early diagnosis of covid-19 be the most critical step to treat infection."], [57, "the diagnostic tool be generally molecular method, serology and viral culture."], [57, "recently crispr-base method have be investigate to diagnose and treat coronavirus infection."], [57, "the emergence of 2019-ncov during the influenza season, have lead to the extensive use of antibiotic and neuraminidase enzyme inhibitor, take orally and intravenously."], [57, "currently, antiviral inhibitor of sars and mer spike protein, neuraminidase inhibitor, anti-inflammatory drug and ek1 peptide be the available therapeutic option for sars-cov-2 infect individual."], [57, "in addition, chloroquine, which be previously use for malarial and autoimmune disease, have show efficacy in the 2019-ncov infection treatment."], [57, "in severe hypoxaemia, a combination of antibiotic, \u03B1-interferon, lopinavir and mechanical ventilation can effectively mitigate the symptom."], [57, "comprehensive knowledge on the innate and adaptive immune response, will make it possible to propose potent antiviral drug with their effective therapeutic measure for the prevention of viral infection."], [57, "this therapeutic strategy will help patient worldwide to protect themselves against severe and fatal viral infection, that potentially can evolve and develop drug resistance, and to reduce mortality rate."], [58, "since emerge coronaviruse have always become a human health concern globally especially severe acute respiratory syndrome coronavirus 2 (sars-cov) and middle east respiratory syndrome coronavirus and a novel coronavirus be introduce in wuhan, china, in december 2019 (call sars-cov-2), many researcher focus on its epidemic, virological and clinical feature."], [58, "sars-cov-2 be classify as betacoronaviruses genus and sarbecovirus subgenus (lineage b)."], [58, "the virus show a great similarity with sars-cov and bat sars-like coronaviruse."], [58, "in this study, we evaluate sars-cov-2 virus phylogeny and evolution by use current virus and related sequence."], [59, "who have call for increase testing in response to the covid-19 pandemic, but country have take different approach and the effectiveness of alternative strategy be unknown."], [59, "we aim to investigate the potential impact of different testing and isolation strategy on transmission of severe acute respiratory syndrome coronavirus 2 (sars-cov-2)."], [59, "we develop a mathematical model of sars-cov-2 transmission base on infectiousness and pcr test sensitivity over time since infection."], [59, "we estimate the reduction in the effective reproduction number (r) achieve by test and isolate symptomatic individual, regular screening of high-risk group irrespective of symptom, and quarantine of contact of laboratory-confirm case identify through test-and-trace protocol."], [59, "the expect effectiveness of different testing strategy be define as the percentage reduction in r. we review datum on the performance of antibody test report by the foundation for innovative new diagnostics and examine their implication for the use of so-call immunity passport."], [59, "if all individual with symptom compatible with covid-19 self-isolate and self-isolation be 100% effective in reduce onward transmission, self-isolation of symptomatic individual would result in a reduction in r of 47% (95% uncertainty interval [ui] 32-55)."], [59, "pcr testing to identify sars-cov-2 infection soon after symptom onset could reduce the number of individual need to self-isolate, but would also reduce the effectiveness of self-isolation (around 10% would be false negative)."], [59, "weekly screening of health-care worker and other high-risk group irrespective of symptom by use of pcr testing be estimate to reduce their contribution to sars-cov-2 transmission by 23% (95% ui 16-40), on top of reduction achieve by self-isolation follow symptom, assume result be available at 24 h."], [59, "the effectiveness of test and trace depend strongly on coverage and the timeliness of contact tracing, potentially reduce r by 26% (95% ui 14-35) on top of reduction achieve by self-isolation follow symptom, if 80% of case and contact be identify and there be immediate testing follow symptom onset and quarantine of contact within 24 h."], [59, "among currently available antibody test, performance have be highly variable, with specificity around 90% or low for rapid diagnostic test and 95-99% for laboratory-base elisa and chemiluminescent assay."], [59, "molecular testing can play an important role in prevention of sars-cov-2 transmission, especially among health-care worker and other high-risk group, but no single strategy will reduce r below 1 at current level of population immunity."], [59, "immunity passport base on antibody test or test for infection face substantial technical, legal, and ethical challenge."], [59, "uk medical research council."], [60, "it be crucial to use the wealth of information emerge from the ongoing sars-cov-2 pandemic and confront covid-19 with a rational approach."], [60, "there be proactive step to prevent and fight covid-19."], [60, "management of the disease should be accord to clinical feature and laboratory test marker and personalize therapeutic target."], [61, "a novel strain of severe acute respiratory syndrome coronavirus 2 (sars-cov-2) disease (covid-19) have be recently identify as an infectious disease affect the respiratory system of human."], [61, "this disease be cause by sars-cov-2 that be identify in chinese patient have severe pneumonia and flu-like symptom."], [61, "covid-19 be a contagious disease that spread rapidly  droplet particle arise through sneeze and cough action of an infected person."], [61, "the report of asymptomatic carrier change the scenario of symptom base-diagnosis in covid-19 and intensify the need for proper diagnosis of the majority of the population to combat the rapid transmission of virus."], [61, "the diagnosis of positive case be necessary to ensure prompt care to affect people and also to curb further spread of infection in the population."], [61, "collect sample at the right time and from the exact anatomical site be crucial for proper molecular diagnosis."], [61, "after the complete genome sequence be available, china formulate rt-pcr as a primary diagnostic procedure for detect sars-cov-2."], [61, "many in-house and commercial diagnostic kit have be develop or be under development that have a potential to lower the burden of diagnosis on the primary diagnostic technique like rt-pcr."], [61, "serological base diagnosis be another broad category of testing that can detect different serum antibody like igg, igm, and iga in an infected patient."], [61, "pcr-base diagnostic procedure that be commonly use for pathogen detection need sophisticated machine and assistance of a technical expert."], [61, "despite their reliable accuracy, they be not cost-effective test, which a common man can afford, so it become imperative to look for other diagnostic approach, which could be cost effective, rapid, and sensitive with consistent accuracy."], [61, "to make such diagnostic available to the common man, many technique can be exploit among, which be point of care (poc), also know as bed side testing, which be develop as a portable and promise tool in pathogen diagnosis."], [61, "other lateral flow assay (lfa)-base technique like sherlock, crispr-cas12a (aiod-crispr), and fncas9 editor-limit uniform detection assay (feluda), etc. have show promise result in rapid detection of pathogen."], [61, "diagnosis hold a critical importance in the pandemic situation when there be no potential drug for the pathogen available in the market."], [61, "this review sum up the different diagnostic approach design or propose to combat the crisis of widespread diagnosis due to the sudden outbreak of a novel pathogen, sars-cov-2 in 2019."], [62, "the novel severe acute respiratory syndrome coronavirus 2 (sars-cov-2), the causative agent of coronavirus disease 2019 (covid-19), be declare a pandemic infection in march 2020."], [62, "as of december 2020, two covid-19 vaccine have be authorize for emergency use by the u.s. food and drug administration, but there be no effective drug to treat covid-19, and pandemic mitigation effort like physical distancing have have acute social and economic consequence."], [62, "in this perspective, we discuss how the proteomic research community can leverage technology and expertise to address the pandemic by investigate four key area of study in sars-cov-2 biology."], [62, "specifically, we discuss how (1) mass spectrometry-base structural technique can overcome limitation and complement traditional structural approach to inform the dynamic structure of sars-cov-2 protein, complex, and virion; (2) virus-host protein-protein interaction mapping can identify the cellular machinery require for sars-cov-2 replication; (3) global protein abundance and post-translational modification profiling can characterize signal pathway that be rewire during infection; and (4) proteomic technology can aid in biomarker identification, diagnostic, and drug development in order to monitor covid-19 pathology and investigate treatment strategy."], [62, "system-level high-throughput capability of proteomic technology can yield important insight into sars-cov-2 biology that be urgently need during the pandemic, and more broadly, can inform coronavirus virology and host biology."], [63, "the on-go pandemic of covid-19 wreak by a viral infection of sars-cov-2, have generate a catastrophic plight across the globe."], [63, "interestingly, one of the hallmark of covid-19 be the so-call 'cytokine storm' due to attack of sars-cov-2 in the lung."], [63, "consider, mesenchymal stem cell (mscs) therapy could contribute against sars-cov-2 virus attack because of their immune modulatory and anti-inflammatory ability link to their stemness, to the arsenal of treatment for covid-19."], [63, "another novel therapeutic strategy include the blockade of rampant generation of pro-inflammatory mediator like acute respiratory distress syndrome (ards), degradation of viral protein capsid by protac, compose of ubiquitin-proteasome framework, and ubiquitination-independent pathway direct the sars-cov-2 nucleocapsid protein (ncov n) and proteasome activator (pa28\u03B3), etc."], [63, "this review be consequently an endeavour to highlight the several aspect of covid-19 with incorporation of important treatment strategy discover to date and put the real effort on the future direction to put they into the perspective."], [64, "coronavirus disease 2019 (covid-19) be cause by severe acute respiratory syndrome coronavirus 2 (sars-cov-2), a newly emerge coronavirus, and have be pandemic since march 2020 and lead to many fatality."], [64, "vaccine represent the most efficient mean to control and stop the pandemic of covid-19."], [64, "however, currently there be no effective covid-19 vaccine approve to use worldwide except for two human adenovirus vector vaccine, three inactivated vaccine, and one peptide vaccine for early or limited use in china and russia."], [64, "safe and effective vaccine against covid-19 be in urgent need."], [64, "researcher around the world be develop 213 covid-19 candidate vaccine, among which 44 be in human trial."], [64, "in this review, we summarize and analyze vaccine progress against sars-cov, middle-east respiratory syndrome coronavirus (mers-cov), and sars-cov-2, include inactivated vaccine, live attenuate vaccine, subunit vaccine, virus like particle, nucleic acid vaccine, and viral vector vaccine."], [64, "as sars-cov-2, sars-cov, and mer-cov share the common genus, , this review of the major research progress will provide a reference and new insight into the covid-19 vaccine design and development."], [65, "covid-19 be a respiratory illness cause by severe acute respiratory syndrome coronavirus 2 (sars-cov-2) and declare by the world health organization a global public health emergency."], [65, "among the severe outbreak across south america, uruguay have become know for curtail sars-cov-2 exceptionally well."], [65, "to understand the sars-cov-2 introduction, local transmission, and association with genomic and clinical parameter in uruguay, we sequence the viral genome of 44 outpatient and inpatient in a private healthcare system in its capital, montevideo, from march to may 2020."], [65, "we perform a phylogeographic analysis use sequence from our cohort and other study that indicate a minimum of 23 independent introduction into uruguay, result in five major transmission cluster."], [65, "our datum suggest that most introduction result in chain of transmission originate from other south american country, with the early seeding of the virus in late february 2020, week before the border be close to all non-citizen and a partial lockdown implement."], [65, "genetic analysis suggest a dominance of s and g clade (g, gh, gr) that make up >90% of the viral strain in our study."], [65, "in our cohort, lethal outcome of sars-cov-2 infection significantly correlate with arterial hypertension, kidney failure, and icu admission (fdr\u2009<\u20090.01), but not with any mutation in a structural or non-structural protein, such as the spike d614g mutation."], [65, "our study contribute genetic, phylodynamic, and clinical correlation datum about the exceptionally well-curb sars-cov-2 outbreak in uruguay, which further the understanding of disease pattern and regional aspect of the pandemic in latin america."], [66, "severe acute respiratory syndrome coronavirus 2 (sars-cov-2) be a highly contagious zoonotic pathogen that have exact heavy public health, social and economic toll."], [66, "in february 2020, the world health organization acronyme the disease cause by sars-cov-2 as covid-19, for coronavirus disease 2019."], [66, "the number of confirm covid-19 infection, which have be detect in at least 103 country, have reach 1,970,225 worldwide as of april 14, 2020 with 124,544 death, accord to the u.s. centers for disease control and prevention (cdc)."], [66, "many case of covid-19 resolve quickly."], [66, "however, the disease, which, like other respiratory pathogen that cause common cold symptom be believe to be transmit through respiratory droplet."], [66, "infection with covid-19 can also lead to significant morbidity and death; this be particularly the case for cancer patient."], [66, "moreover, because the sign and symptom of covid-19 be easily misattribute to the sequelae of cancer itself, such as pulmonary embolism, or its treatment, such as nausea and diarrhea, diagnosis may be delay or miss."], [66, "potential covid-19 rule out criterion, base on the wells' criterion for pulmonary embolism, another protean disease entity, be provide as a decision-make aid."], [66, "this review summarize the current understanding of the transmission, clinical presentation, diagnosis and differential diagnosis, pathogenesis, rationale to treat the cancer or not, treatment and prevention of covid-19 with an emphasis on implication in cancer."], [67, "accord to the world health organization (who), the covid-19 pandemic have be declare as a priority disease."], [67, "some patient with covid-19 have symptom of multiple organ failure and death."], [67, "the publish article on covid-19 infection be review."], [67, "the origin of sars-cov-2 be still not completely establish."], [67, "person-to-person transmission via droplet, probable aerosol, or close contact be consider as the main mode of transmission."], [67, "with increase mortality due to sars-cov-2, valuable clinical indicator or treatment should be far identify and summarize."], [67, "ct scan play an important role in the diagnosis and evaluation of covid-19 in asymptomatic patient or those with initially negative rt-pcr result."], [67, "no specific antiviral therapy be recommend, except the main supportive treatment, and effective measure should be take into consideration to protect important organ and prevent the development of acute respiratory distress syndrome (ards) in patient with severe infection."], [68, "sars-cov-2 be responsible for the 2019 coronavirus disease (covid-19), a global pandemic that begin in march 2020 and be currently in progress."], [68, "to date, covid-19 have cause about 935,000 death in more than 200 country."], [68, "the respiratory system be most affect by injury cause by covid-19, but other organ may be involve, include the cardiovascular system."], [68, "sars-cov-2 penetrate host cell through the angiotensin 2 conversion enzyme (ace-2)."], [68, "ace-2 be express not only in the lung, but also in other organ, include the cardiovascular system."], [68, "several study have find that a good percentage of patient with severe covid-19 have cardiac lesion, include myocardial fibrosis, edema and pericarditis."], [68, "pathological remodeling of the extracellular matrix cause by viral infection lead to myocardial fibrotic lesion."], [68, "these fibrotic scar can cause cardiac dysfunction, reduce the ejection fraction cause by the presence of stiffen myocardial matrix, or cardiac arrhythmias that cause an alteration in the electrical conduction system of the heart."], [68, "these cardiac dysfunction can cause death."], [68, "it be therefore essential to identify cardiac involvement early in order to act with appropriate therapeutic treatment."], [68, "in this review, we describe what be know about cardiac injury from covid-19, highlight effective pharmacological therapeutic solution to combat cardiac injury, particularly cardiac fibrosis, cause by covid-19."], [69, "urgent treatment, in any modality, to fight sars-cov-2 infection be desire by society in general, by health professional, by estate-leader and, mainly, by the scientific community, because one thing be certain amidst the numerous uncertainty regard covid-19: knowledge be the mean to discover or to produce an effective treatment against this global disease."], [69, "scientist from several area in the world be still committed to this mission, as show by the accelerate scientific production in the first half of 2020 with over 25,000 publish article relate to the new coronavirus."], [69, "three great line of publication relate to covid-19 be identify for build this article:"], [69, "the first refer to knowledge production concern the virus and pathophysiology of covid-19; the second regard effort to produce vaccine against sars-cov-2 at a speed without precedent in the history of science; the third comprehend the attempt to find a market drug that can be use to treat covid-19 by drug repurpose."], [69, "in this review, the drug that have be repurpose so far be group accord to their chemical class."], [69, "their structure will be present to provide well understanding of their structural similarity and possible correlation with mechanism of action."], [69, "this can help identify anti-sars-cov-2 promise therapeutic agent."], [70, "real-time reverse transcription pcr be currently the most sensitive method to detect severe acute respiratory syndrome coronavirus 2 (sars-cov-2)."], [70, "define whether a patient could be contagious or not contagious in the presence of residual sars-cov-2 rna be of extreme importance in the context of public health."], [70, "in this prospective multicenter study, virus isolation be prospectively attempt in 387 nasal swab from clinically recover patient show low viral load (quantification cycle, cq, value great than 30)."], [70, "the median cq value be 36.8 (range 30.0-39.4)."], [70, "overall, a cytopathic effect be detect in nine sample, correspond to a culture positivity rate of 2.3% (9/387)."], [70, "the result of this study help to dissect true virus replication and residual viral rna detection in recovered patient."], [71, "as the sars-cov-2 pandemic unfold across the globe, consistent theme be emerge with regard to aspect of sars-cov-2 infection and its associated disease entity in child."], [71, "overall, child appear to be less frequently infect by, and affect by, sars-cov-2 virus and the clinical disease covid-19."], [71, "large epidemiological study have reveal child represent less than 2% of the total confirm covid-19 case, of whom the majority experience minimal or mild disease that do not require hospitalisation."], [71, "child do not appear to be major driver of sars-cov-2 transmission, with minimal secondary virus transmission demonstrate within family, school and community setting."], [71, "there be several postulated theory regard the relatively low sars-cov-2 morbidity and mortality see in child, which largely relate to difference in immune response compare to adult, as well as difference in angiotensin convert enzyme 2 distribution that potentially limit viral entry and subsequent inflammation, hypoxia and tissue injury."], [71, "the recent emergence of a multisystem inflammatory syndrome bear temporal and serological plausibility for an immune-mediate sars-cov-2-relate disease entity be currently under investigation."], [71, "this article summarise the current available datum regard sars-cov-2 and the paediatric population, include the spectrum of disease in child, the role of child in virus transmission, and host-virus factor that underpin the unique aspect of sars-cov-2 pathogenicity in child."], [72, "the ongoing sars-cov-2 pandemic have lead to the focused application of resource and scientific expertise toward the goal of develop investigational vaccine to prevent covid-19."], [72, "the highly collaborative global effort by private industry, government and non-governmental organization have result in a number of sars-cov-2 vaccine candidate move to phase iii trial in a period of only month since the start of the pandemic."], [72, "in this review, we provide an overview of the preclinical and clinical datum on sars-cov-2 vaccine that be currently in phase iii clinical trial and in few case authorize for emergency use."], [72, "we far discuss relevant vaccine platform and provide a discussion of sars-cov-2 antigen that may be target to increase the breadth and durability of vaccine response."], [73, "the coronavirus disease 2019 (covid-19) pandemic continue to spread across the world."], [73, "hence, there be an urgent need for rapid, simple, and accurate test to diagnose severe acute respiratory syndrome coronavirus 2 (sars-cov-2) infection."], [73, "performance characteristic of the rapid sars-cov-2 antigen detection test should be evaluate and compare with the gold standard real-time reverse transcription-polymerase chain reaction (rt-pcr) test for diagnosis of covid-19 case."], [73, "the rapid sars-cov-2 antigen detection test, standard\u2122 q covid-19 ag kit (sd biosensor\xAE, republic of korea), be compare with the real-time rt-pcr test, allplex\u2122 2019-ncov assay (seegene\xAE, korea) for detection of sars-cov-2 in respiratory specimen."], [73, "four hundred fifty-four respiratory sample (mainly nasopharyngeal and throat swab) be obtain from covid-19 suspect case and contact individual, include pre-operative patient at siriraj hospital, bangkok, thailand during march-may 2020."], [73, "of 454 respiratory sample, 60 (13.2%) be positive, and 394 (86.8%) be negative for sars-cov-2 rna by real-time rt-pcr assay."], [73, "the duration from onset to laboratory test in covid-19 suspect case and contact individual range from 0 to 14\xA0day with a median of 3\xA0day."], [73, "the rapid sars-cov-2 antigen detection test's sensitivity and specificity be 98.33% (95% ci, 91.06-99.96%) and 98.73% (95% ci, 97.06-99.59%), respectively."], [73, "one false negative test result be from a sample with a high real-time rt-pcr cycle threshold (ct), while five false positive test result be from specimen of pre-operative patient."], [73, "the rapid assay for sars-cov-2 antigen detection show comparable sensitivity and specificity with the real-time rt-pcr assay."], [73, "thus, there be a potential use of this rapid and simple sars-cov-2 antigen detection test as a screening assay."], [74, "two new sars-cov-2 lineage with the n501y mutation in the receptor-bind domain of the spike protein spread rapidly in the united kingdom."], [74, "we estimate that the early 501y lineage without amino acid deletion \u03B469/\u03B470, circulate mainly between early september and mid-november, be 10% (6-13%) more transmissible than the 501n lineage, and the 501y lineage with amino acid deletion \u03B469/\u03B470, circulate since late september, be 75% (70-80%) more transmissible than the 501n lineage."], [75, "infection with the severe acute respiratory syndrome coronavirus-2 (sars-cov-2) result in diverse outcome."], [75, "the symptom appear to be more severe in male old than 65 and people with underlie health condition; approximately one in five individual could be at risk worldwide."], [75, "the virus's sequence be rapidly establish day after the first case be report and identify an rna virus from the coronaviridae family closely relate to a betacoronavirus virus find in bat in china."], [75, "sars-cov-2 be the seventh coronavirus know to infect human, and with the severe acute respiratory syndrome (sars) and the middle east respiratory syndrome (mers), the only one to cause severe disease."], [75, "lesson from these two previous outbreak guide the identification of critical therapeutic target such as the spike viral protein promote the virus's cellular entry through the angiotensin-convert enzyme 2 (ace2) receptor express on the surface of multiple type of eukaryotic cell."], [75, "although several therapeutic agent be currently evaluate, none seem to provide a clear path for a cure."], [75, "also, various type of vaccine be develop in record time to address the urgency of efficient sars-cov-2 prevention."], [75, "currently, 58 vaccine be evaluate in clinical trial, include 11 in phase iii, and 3 of they report efficacy above 90 %."], [75, "the result so far from the clinical trial suggest the availability of multiple effective vaccine within month."], [76, "there be several type of research on the covid-19 disease which have be conduct."], [76, "it seem that prevail over the pandemic would be achieve only by master over the virus pathophysiology."], [76, "we try to categorize the massive amount of available information for useful interpretation."], [76, "we search database with different keyword and search strategy that focus on virulence and pathophysiology of covid-19."], [76, "the present review have aim to gather and categorize all implement drug base on the susceptible virulence mechanism, and the pathophysiological event in the host cell, discuss and suggest treatment."], [76, 'as a result, the covid-19 lifecycle be categorize as follow step: "host cell attachment" which be mainly conduct with ace receptor and tmprss2 from the host cell and spike (s) protein, "endocytosis pathway" which be perform mainly by clathrin-mediate endocytosis, and "viral replication" which contain translation and replication of rna viral genome.'], [76, 'the virus pathogenicity be continue by "inflammatory reaction" which mainly cause moderate to severe covid-19 disease.'], [76, "besides, the possible effective therapeutic' mechanism and the pharmaceutical agent that have at least one experience as a preclinical or clinical study on covid-19 be clearly define."], [76, "the treatment protocol would be occasional base on the stage of the infection and the patient situation."], [76, "the cocktail of medicine, which could affect almost all mention stage of covid-19 disease, might be vital for patient with severe phenomena."], [76, "the classification of the possible mechanism of medicine base on covid-19 pathogenicity."], [77, "the sudden emergence of the novel severe acute respiratory syndrome coronavirus 2 (sars-cov-2) cause the coronavirus disease of 2019 (covid-19) have bring the world to a standstill."], [77, "thousand of people across the globe be bite the dust with every pass day and yet more be be test positive for the sars-cov-2 infection."], [77, "in order to dispense this current crisis, numerous treatment option have be try and test and many more be still under scrutiny."], [77, "the development of vaccine may help in the prevention of the global pandemic, however, there be still a need for the development of alternate approach to combat the disease."], [77, "in this review we highlight the new discovery and furtherance in the antibody base therapeutic option and the potent drug, with special emphasis on the development of the monoclonal and polyclonal antibody and the repurpose drug, which may prove to be of significant importance for the treatment of covid-19, in the day to come."], [77, "it be an attempt to evaluate the currently present challenge so as to provide a scope for the ongoing research and assistance in the development of the effective therapeutic option against sars-cov-2."], [78, "covid-19 convalescent plasma (ccp) therapy involve the use of circulate antibody administration from recover covid 19 patient as a practical strategy to provide immediate passive immunity in susceptible recipient in need."], [78, 'global concern over the potential for "second" or "third" wave of infection to occur before effective vaccine or drug therapy be available have many look at other biological source for large-scale production of neutralize sars-cov-2 antibody.'], [78, "this report summarize some of the novel strategy for develop alternative safe source of therapeutic autologous antibody from covid -19 infect patient, and provide some original thought on how to rapidly implement a safe passive immunity in those covid-19 patient who be most in need of intervention."], [78, "covid-19 antibody can be isolate or deliver use a number of other technique include: plasmapheresis, plasma cryoprecipitate reduce (cryosupernatant), antibody hyperconcentrate and advanced cell-base delivery system."], [78, "while these propose technological option may, in some case, be theoretical, the grow concern over the rapid spread of the sars-cov-2 virus have prompt many to pursue innovative and creative solution to reduce the mortality and morbidity result from the current global pandemic."], [78, "a comparative analysis of various strategy currently in use deserve explore and this highlight separately as the essential part of this concise theme."], [79, "sphingolipid be potent bioactive agent involve in the pathogenesis of various respiratory bacterial infection."], [79, "to date, several sphingolipid derivative be know, but s1p (sphingosine-1-phosphate) and ceramide be the well-study sphingolipid derivative in the context of human disease."], [79, "these be membrane-bind lipid that influence host-pathogen interaction."], [79, "base on these feature, we believe that sphingolipid might control sars-cov-2 infection in the host."], [79, "sars-cov-2 utilize the ace-ii receptor (angiotensin-convert enzyme ii receptor) on epithelial cell for its entry and replication."], [79, "activation of the ace-ii receptor be indirectly associate with the activation of s1p receptor 1 signaling which be associate with il-6 drive fibrosis."], [79, "this be expect to promote pathological response during sars-cov-2 infection in covid-19 case."], [79, "give this, mitigate s1p signal by application of either s1p lyase (spl) or s1p analog (fingolimod / fty720) seem to be potential approach for control these pathological outcome."], [79, "however, due to the immunosuppressive nature of fty720, it can modulate hyper-inflammatory response and only provide symptomatic relief, which may not be sufficient for control the novel covid-19 infection."], [79, "since th1 effector immune response be essential for the clearance of infection, we believe that other sphingolipid derivative like cermaide-1 phosphate with antiviral potential and adjuvant immune potential can potentially control sars-cov-2 infection in the host by its ability in enhance autophagy and antigen presentation by dc to promote t cell response which can be helpful in control sars-cov-2 infection in novel covid-19 patient."], [80, "in december 2019, a cluster of case of acute respiratory illness, novel coronavirus-infect pneumonia, occur in wuhan, hubei province, china."], [80, "the false-negative nasopharyngeal swab for sars-cov-2 cause delay diagnosis of covid-19, which hinder the prevention and control of the pandemic."], [80, "the transmission risk of sars-cov-2 in negative nasopharyngeal swab case have rarely be address previously."], [80, "this study evaluate two cluster of covid-19 in six patient, four of whom (66.7%) test negative for rna of sars-cov-2 on rt-pcr of nasopharyngeal swab."], [80, "all epidemiological, clinical, and laboratory datum be collect."], [80, "the first cluster be a nosocomial infection of four health care provider in early january."], [80, "one case result in a sequential familial cluster of infection."], [80, "all patient either self-quarantine at home or be admit to hospital for isolated treatment."], [80, "all recover and be anti-sars-cov-2 igg- and/or igm-positive (100%) for serological detection of sars-cov-2 at the recovery stage."], [80, "our study provide a cautionary warning that negative result for nasopharyngeal swab of suspect sars-cov-2 infection can increase the risk of nosocomial infection among health care provider."], [80, "serologic detection for anti-sars-cov-2 igg and/or igm be an important test in the diagnosis of covid-19."], [81, "current treatment of patient with coronavirus 2019 (covid-19) involve repurpose drug that inhibit viral infection by either bind to their respective target or via modulate cellular signal transduction."], [81, "however, there be still a great deal of efficacy enhancement through combination therapy and derivatization."], [81, "combination therapy should involve agent with significant activity and different mechanism of action."], [81, "the structural map of the interaction between a drug and its target protein will help guide drug discovery for devise safe and effective way to treat covid-19."], [81, "herein, we report numerous synthetic design base on enhance affinity to the viral carbohydrate-rich protein spike and protein-bind site of covid-19."], [82, "the pandemic of coronavirus disease 2019 (covid-19) have have a serious impact on global health."], [82, "covid-19 vaccine may be one of the most effective measure to end the pandemic."], [82, "high infection risk and high serious incident and mortality rate have be show in cancer patient with covid-19."], [82, "therefore, cancer patient should be the priority group for covid-19 prevention."], [82, "until now, datum of covid-19 vaccination for cancer patient be lack."], [82, "we review the interim datum of safety and immune-efficacy of covid-19 vaccination in cancer patient base on the late study."], [82, "due to the complicated immune system of cancer patient cause by the malignancy and anticancer treatment, we propose preliminary specific covid-19 vaccination recommendation for cancer patient with different anticancer treatment and at different stage of the disease."], [82, "prevent covid-19 with vaccination for cancer patient be crucial, and we call for more large-scale clinical trial and real-world study, for further covid-19 vaccination recommendation development."], [82, "."], [83, "coronavirus disease 2019 (covid-19) be a major public health concern currently."], [83, "to date, there be no approve antiviral drug or vaccine against this transmissible disease."], [83, "this report shed light on available information for a well understanding of clinical trial and pharmacotherapy relate to covid-19."], [83, "medline, pubmed, embase, scopus database, web of science, who, and eu clinical trial site be use to perform comparative analysis."], [83, "information be collect on the use of therapeutic agent for human therapy in patient with covid-19 up to may 2020."], [83, "we have extract datum from 60 clinical trial."], [83, "amongst these trial, 34 be from the european union database of clinical trial and 26 from the national institute of health."], [83, "the datum selection procedure include active, complete, and recruitment in progress status."], [83, "most of the clinical trial be ongoing and hence, there be a lack of precise result for the treatment."], [83, "there be a lack of high-quality clinical evidence."], [83, "the protocol to be develop require large randomize clinical trial with a combination of available drug and prospective therapy."], [83, "we propose the usage of a large number of case and different statistical analysis to conduct systematic clinical trial."], [83, "this could provide comprehensive information about the clinical trial and potential therapeutic progress."], [84, "covid-19 vaccine have develop quickly, and vaccination program have start in most country to fight the pandemic."], [84, "the age population be vulnerable to different disease, also include the covid-19."], [84, "a high death rate of covid-19 be note from the vulnerable age population."], [84, "a present scenario regard covid-19 vaccine and vaccination program foraging adult have be discuss."], [84, "this paper review the current status and future projection till 2050 of the age population worldwide."], [84, "it also discuss the immunosenescence and inflammaging issue face elderly adult and how it affect the vaccination such as influenza, pneumococcal, and herpe zoster."], [84, "this paper recommend clinical trial for all approve covid-19 vaccine target the elderly adult population and to project a plan to develop a next-generation covid-19 vaccine."], [84, "the review have map the covid-19 vaccination status from the developed and develop country for the elderly population."], [84, "finally, strategy to vaccinate all elderly adult globally against covid-19 to enhance longevity have be suggest."], [85, "the novel coronavirus disease-19 (covid-19) be a global pandemic that emerge from wuhan, china, and have spread all around the world, affect 216 country or territory with 21,732,472 people infect and 770,866 death globally (as per who covid-19 update of august 18, 2020)."], [85, "continuous effort be be make to repurpose the exist drug and develop vaccine for combat this infection."], [85, "despite, to date, no certify antiviral treatment or vaccine exist."], [85, "although, few candidate have display their efficacy in in vitro study and be be repurpose for covid- 19 treatment."], [85, "this article summarize synthetic and semi-synthetic compound display potent activity in clinical use or study on covid-19 and also focus on the mode of action of drug be reposition against covid-19."], [86, "severe acute respiratory syndrome coronavirus-2 (sars-cov-2) belong to the group of betacoronaviruse."], [86, "the sars-cov-2 be closely relate to sars-cov-1\xA0and probably originate either from bat or pangolin."], [86, "sars-cov-2 be an etiological agent of covid-19, cause mild to severe respiratory disease which escalate to acute respiratory distress syndrome (ards) or multi-organ failure."], [86, "the virus be first report from the animal market in hunan, hubei province of china in the month of december, 2019, and be\xA0rapidly transmit from animal to human and human-to-human."], [86, "the human-to-human transmission can occur directly or via droplet generate during coughing and sneeze."], [86, "globally, around 53.9 million case of covid-19 have be register with 1.31 million confirm death."], [86, "the people\u2009>\u200960\xA0year,\xA0person suffer from comorbid condition and\xA0immunocompromise individual be more susceptible to covid-19 infection."], [86, "the virus primarily target the upper and the low respiratory tract and quickly disseminate to other organ."], [86, "sars-cov-2 dysregulate immune signal pathway which generate cytokine storm and lead to the acute respiratory distress syndrome\xA0and other multisystemic disorder."], [87, 'numerous review have summarize the epidemiology, pathophysiology and the various therapeutic aspect of coronavirus disease 2019 (covid-19), but a practical guide on "how to treat whom with what and when" base on an understanding of the immunological background of the disease stage remain miss.'], [87, "this review attempt to combine the current knowledge about the immunopathology of covid-19 with publish evidence of available and emerge treatment option."], [87, "we recognize that the information about covid-19 and its treatment be rapidly change, but hope that this guide offer those on the frontline of this pandemic an understanding of the host response in covid-19 patient and support their ongoing effort to select the good treatment tailor to their patient's clinical status."], [88, "the causative agent of novel coronavirus disease (covid-19) be severe acute respiratory syndrome coronavirus 2 (sars-cov-2)."], [88, "the sars-cov-2 possess rna as a genetic material with 79% of the match with the bat sars-cov genome, which become epidemic in 2002."], [88, "the sars-cov-2 peripheral spike-fc protein bind specifically to the ace2 receptor present on bronchial epithelial cell and alveolar pneumocyte to downmodulates its expression which lead to severe acute respiratory failure."], [88, "the disease be super infectious from human to human and the symptom be similar to flu."], [88, "the old aged and immunocompromise population be severely affect, and healthcare provider globally apply various strategy for treatment include the repurposing of drug include antimalarial drug, hydroxychloroquine and anti-viral drug."], [88, "herein, we describe the sars-cov-2 pandemic, immune response, possible drug target, vaccine under the trial and correlate the possibility of train immunity induce by bcg vaccination over control of sars-cov-2 infection."], [88, "the country with constraint bcg vaccination policy be struggle badly compare to country with bcg vaccination policy."], [88, "the bcg vaccination policy support either lower the total number of covid-19 case or the increase recovery rate."]];

  // hw4/covid_tokens.json
  var covid_tokens_default = [[0, "covid-19"], [0, ","], [0, "cause"], [0, "by"], [0, "sars"], [0, "-"], [0, "cov-2"], [0, "infection"], [0, ","], [0, "be"], [0, "mild"], [0, "to"], [0, "moderate"], [0, "in"], [0, "the"], [0, "majority"], [0, "of"], [0, "previously"], [0, "healthy"], [0, "individual"], [0, ","], [0, "but"], [0, "can"], [0, "cause"], [0, "life"], [0, "-"], [0, "threaten"], [0, "disease"], [0, "or"], [0, "persistent"], [0, "debilitate"], [0, "symptom"], [0, "in"], [0, "some"], [0, "case"], [0, "."], [1, "the"], [1, "most"], [1, "important"], [1, "determinant"], [1, "of"], [1, "disease"], [1, "severity"], [1, "be"], [1, "age"], [1, ","], [1, "with"], [1, "individual"], [1, "over"], [1, "65"], [1, "year"], [1, "have"], [1, "the"], [1, "great"], [1, "risk"], [1, "of"], [1, "require"], [1, "intensive"], [1, "care"], [1, ","], [1, "and"], [1, "man"], [1, "be"], [1, "more"], [1, "susceptible"], [1, "than"], [1, "woman"], [1, "."], [2, "in"], [2, "contrast"], [2, "to"], [2, "other"], [2, "respiratory"], [2, "viral"], [2, "infection"], [2, ","], [2, "young"], [2, "child"], [2, "seem"], [2, "to"], [2, "be"], [2, "less"], [2, "severely"], [2, "affect"], [2, "."], [3, "it"], [3, "be"], [3, "now"], [3, "clear"], [3, "that"], [3, "mild"], [3, "to"], [3, "severe"], [3, "acute"], [3, "infection"], [3, "be"], [3, "not"], [3, "the"], [3, "only"], [3, "outcome"], [3, "of"], [3, "covid-19"], [3, ","], [3, "and"], [3, "long"], [3, "-"], [3, "last"], [3, "symptom"], [3, "be"], [3, "also"], [3, "possible"], [3, "."], [4, "in"], [4, "contrast"], [4, "to"], [4, "severe"], [4, "acute"], [4, "covid-19"], [4, ","], [4, "such"], [4, "'"], [4, "long"], [4, "covid"], [4, "'"], [4, "be"], [4, "seemingly"], [4, "more"], [4, "likely"], [4, "in"], [4, "woman"], [4, "than"], [4, "in"], [4, "man"], [4, "."], [5, "also"], [5, ","], [5, "postinfectious"], [5, "hyperinflammatory"], [5, "disease"], [5, "have"], [5, "be"], [5, "describe"], [5, "as"], [5, "an"], [5, "additional"], [5, "outcome"], [5, "after"], [5, "sars"], [5, "-"], [5, "cov-2"], [5, "infection"], [5, "."], [6, "here"], [6, "i"], [6, "discuss"], [6, "our"], [6, "current"], [6, "understanding"], [6, "of"], [6, "the"], [6, "immunological"], [6, "determinant"], [6, "of"], [6, "covid-19"], [6, "disease"], [6, "presentation"], [6, "and"], [6, "severity"], [6, "and"], [6, "relate"], [6, "this"], [6, "to"], [6, "know"], [6, "immune"], [6, "-"], [6, "system"], [6, "difference"], [6, "between"], [6, "young"], [6, "and"], [6, "old"], [6, "people"], [6, "and"], [6, "between"], [6, "man"], [6, "and"], [6, "woman"], [6, ","], [6, "and"], [6, "other"], [6, "factor"], [6, "associate"], [6, "with"], [6, "different"], [6, "disease"], [6, "presentation"], [6, "and"], [6, "severity"], [6, "."], [7, "coronavirus"], [7, "disease"], [7, "2019"], [7, "("], [7, "covid-19"], [7, ")"], [7, ","], [7, "cause"], [7, "by"], [7, "severe"], [7, "acute"], [7, "respiratory"], [7, "syndrome"], [7, "coronavirus"], [7, "2"], [7, "("], [7, "sars"], [7, "-"], [7, "cov-2"], [7, ")"], [7, ","], [7, "be"], [7, "a"], [7, "global"], [7, "pandemic"], [7, "which"], [7, "have"], [7, "induce"], [7, "unprecedented"], [7, "ramification"], [7, ","], [7, "severely"], [7, "affect"], [7, "our"], [7, "society"], [7, "due"], [7, "to"], [7, "the"], [7, "long"], [7, "incubation"], [7, "time"], [7, ","], [7, "unpredictably"], [7, "high"], [7, "prevalence"], [7, "and"], [7, "lack"], [7, "of"], [7, "effective"], [7, "vaccine"], [7, "."], [8, "one"], [8, "of"], [8, "the"], [8, "interesting"], [8, "notion"], [8, "be"], [8, "that"], [8, "there"], [8, "be"], [8, "an"], [8, "association"], [8, "between"], [8, "covid-19"], [8, "and"], [8, "cancer"], [8, "."], [9, "cancer"], [9, "patient"], [9, "seem"], [9, "to"], [9, "exhibit"], [9, "exacerbate"], [9, "condition"], [9, "and"], [9, "a"], [9, "high"], [9, "mortality"], [9, "rate"], [9, "when"], [9, "expose"], [9, "to"], [9, "the"], [9, "virus"], [9, "."], [10, "therefore"], [10, ","], [10, "vaccine"], [10, "be"], [10, "the"], [10, "promising"], [10, "solution"], [10, "to"], [10, "minimise"], [10, "the"], [10, "problem"], [10, "amongst"], [10, "cancer"], [10, "patient"], [10, "threaten"], [10, "by"], [10, "the"], [10, "new"], [10, "viral"], [10, "strain"], [10, "."], [11, "however"], [11, ","], [11, "there"], [11, "be"], [11, "still"], [11, "limitation"], [11, "to"], [11, "be"], [11, "consider"], [11, ","], [11, "include"], [11, "the"], [11, "efficacy"], [11, "of"], [11, "covid"], [11, "vaccine"], [11, "for"], [11, "immunocompromise"], [11, "individual"], [11, ","], [11, "possible"], [11, "interaction"], [11, "between"], [11, "the"], [11, "vaccine"], [11, "and"], [11, "cancer"], [11, ","], [11, "and"], [11, "personalise"], [11, "medicine"], [11, "."], [12, "not"], [12, "only"], [12, "to"], [12, "eradicate"], [12, "the"], [12, "pandemic"], [12, ","], [12, "but"], [12, "also"], [12, "to"], [12, "make"], [12, "it"], [12, "more"], [12, "effective"], [12, "for"], [12, "immunocompromise"], [12, "patient"], [12, "who"], [12, "be"], [12, "suffer"], [12, "from"], [12, "cancer"], [12, ","], [12, "a"], [12, "successful"], [12, "vaccine"], [12, "platform"], [12, "be"], [12, "require"], [12, "through"], [12, "the"], [12, "implementation"], [12, "of"], [12, "nanotechnology"], [12, "which"], [12, "can"], [12, "also"], [12, "enable"], [12, "scalable"], [12, "manufacturing"], [12, "and"], [12, "worldwide"], [12, "distribution"], [12, "along"], [12, "with"], [12, "its"], [12, "fast"], [12, "and"], [12, "precise"], [12, "delivery"], [12, "."], [13, "in"], [13, "this"], [13, "review"], [13, ","], [13, "we"], [13, "summarise"], [13, "the"], [13, "current"], [13, "understanding"], [13, "of"], [13, "covid-19"], [13, "with"], [13, "clinical"], [13, "perspective"], [13, ","], [13, "highlight"], [13, "the"], [13, "association"], [13, "between"], [13, "covid-19"], [13, "and"], [13, "cancer"], [13, ","], [13, "follow"], [13, "by"], [13, "a"], [13, "vaccine"], [13, "development"], [13, "for"], [13, "this"], [13, "association"], [13, "use"], [13, "nanotechnology"], [13, "."], [14, "we"], [14, "suggest"], [14, "different"], [14, "administration"], [14, "method"], [14, "for"], [14, "the"], [14, "covid-19"], [14, "vaccine"], [14, "formulation"], [14, "option"], [14, "."], [15, "this"], [15, "study"], [15, "will"], [15, "contribute"], [15, "to"], [15, "pave"], [15, "the"], [15, "way"], [15, "towards"], [15, "the"], [15, "prevention"], [15, "and"], [15, "treatment"], [15, "of"], [15, "covid-19"], [15, ","], [15, "especially"], [15, "for"], [15, "the"], [15, "immunocompromise"], [15, "individual"], [15, "."], [16, "the"], [16, "coronavirus"], [16, "disease"], [16, "2019"], [16, "("], [16, "covid-19"], [16, ")"], [16, "pandemic"], [16, "be"], [16, "declare"], [16, "a"], [16, "public"], [16, "health"], [16, "emergency"], [16, "of"], [16, "international"], [16, "concern"], [16, "by"], [16, "the"], [16, "world"], [16, "health"], [16, "organization"], [16, "."], [17, "covid-19"], [17, "have"], [17, "high"], [17, "transmissibility"], [17, "and"], [17, "could"], [17, "result"], [17, "in"], [17, "acute"], [17, "lung"], [17, "injury"], [17, "in"], [17, "a"], [17, "fraction"], [17, "of"], [17, "patient"], [17, "."], [18, "by"], [18, "counterbalance"], [18, "the"], [18, "activity"], [18, "of"], [18, "the"], [18, "renin"], [18, "-"], [18, "angiotensin"], [18, "system"], [18, ","], [18, "angiotensin"], [18, "-"], [18, "convert"], [18, "enzyme"], [18, "2"], [18, ","], [18, "which"], [18, "be"], [18, "the"], [18, "fusion"], [18, "receptor"], [18, "of"], [18, "the"], [18, "virus"], [18, ","], [18, "play"], [18, "a"], [18, "protective"], [18, "role"], [18, "against"], [18, "the"], [18, "development"], [18, "of"], [18, "complication"], [18, "of"], [18, "this"], [18, "viral"], [18, "infection"], [18, "."], [19, "vitamin"], [19, "\u2009"], [19, "d"], [19, "can"], [19, "induce"], [19, "the"], [19, "expression"], [19, "of"], [19, "angiotensin"], [19, "-"], [19, "convert"], [19, "enzyme"], [19, "2"], [19, "and"], [19, "regulate"], [19, "the"], [19, "immune"], [19, "system"], [19, "through"], [19, "different"], [19, "mechanism"], [19, "."], [20, "epidemiologic"], [20, "study"], [20, "of"], [20, "the"], [20, "relationship"], [20, "between"], [20, "vitamin"], [20, "\u2009"], [20, "d"], [20, "and"], [20, "various"], [20, "respiratory"], [20, "infection"], [20, "be"], [20, "review"], [20, "and"], [20, ","], [20, "here"], [20, ","], [20, "the"], [20, "postulate"], [20, "mechanism"], [20, "and"], [20, "clinical"], [20, "datum"], [20, "support"], [20, "the"], [20, "protective"], [20, "role"], [20, "of"], [20, "vitamin"], [20, "\u2009"], [20, "d"], [20, "against"], [20, "covid-19"], [20, "-"], [20, "mediate"], [20, "complication"], [20, "be"], [20, "discuss"], [20, "."], [21, "as"], [21, "the"], [21, "current"], [21, "understanding"], [21, "of"], [21, "covid-19"], [21, "continue"], [21, "to"], [21, "evolve"], [21, ","], [21, "a"], [21, "synthesis"], [21, "of"], [21, "the"], [21, "literature"], [21, "on"], [21, "the"], [21, "neurological"], [21, "impact"], [21, "of"], [21, "this"], [21, "novel"], [21, "virus"], [21, "may"], [21, "help"], [21, "inform"], [21, "clinical"], [21, "management"], [21, "and"], [21, "highlight"], [21, "potentially"], [21, "important"], [21, "avenue"], [21, "of"], [21, "investigation"], [21, "."], [22, "additionally"], [22, ","], [22, "understand"], [22, "the"], [22, "potential"], [22, "mechanism"], [22, "of"], [22, "neurologic"], [22, "injury"], [22, "may"], [22, "guide"], [22, "effort"], [22, "to"], [22, "well"], [22, "detect"], [22, "and"], [22, "ameliorate"], [22, "these"], [22, "complication"], [22, "."], [23, "in"], [23, "this"], [23, "review"], [23, ","], [23, "we"], [23, "synthesize"], [23, "a"], [23, "range"], [23, "of"], [23, "clinical"], [23, "observation"], [23, "and"], [23, "initial"], [23, "case"], [23, "series"], [23, "describe"], [23, "potential"], [23, "neurologic"], [23, "manifestation"], [23, "of"], [23, "covid-19"], [23, "and"], [23, "place"], [23, "these"], [23, "observation"], [23, "in"], [23, "the"], [23, "context"], [23, "of"], [23, "coronavirus"], [23, "neuro"], [23, "-"], [23, "pathophysiology"], [23, "as"], [23, "it"], [23, "may"], [23, "relate"], [23, "to"], [23, "sars"], [23, "-"], [23, "cov-2"], [23, "infection"], [23, "."], [24, "report"], [24, "nervous"], [24, "system"], [24, "manifestation"], [24, "range"], [24, "from"], [24, "anosmia"], [24, "and"], [24, "ageusia"], [24, ","], [24, "to"], [24, "cerebral"], [24, "hemorrhage"], [24, "and"], [24, "infarction"], [24, "."], [25, "while"], [25, "the"], [25, "volume"], [25, "of"], [25, "covid-19"], [25, "-"], [25, "relate"], [25, "case"], [25, "study"], [25, "continue"], [25, "to"], [25, "grow"], [25, ","], [25, "previous"], [25, "work"], [25, "examine"], [25, "relate"], [25, "virus"], [25, "suggest"], [25, "potential"], [25, "mechanism"], [25, "through"], [25, "which"], [25, "the"], [25, "novel"], [25, "coronavirus"], [25, "may"], [25, "impact"], [25, "the"], [25, "cns"], [25, "and"], [25, "result"], [25, "in"], [25, "neurological"], [25, "complication"], [25, "."], [26, "namely"], [26, ","], [26, "animal"], [26, "study"], [26, "examine"], [26, "the"], [26, "sars"], [26, "-"], [26, "cov"], [26, "have"], [26, "implicate"], [26, "the"], [26, "angiotensin"], [26, "-"], [26, "convert"], [26, "-"], [26, "enzyme-2"], [26, "receptor"], [26, "as"], [26, "a"], [26, "mediator"], [26, "of"], [26, "coronavirus"], [26, "-"], [26, "relate"], [26, "neuronal"], [26, "damage"], [26, "and"], [26, "have"], [26, "show"], [26, "that"], [26, "sars"], [26, "-"], [26, "cov"], [26, "can"], [26, "infect"], [26, "cerebrovascular"], [26, "endothelium"], [26, "and"], [26, "brain"], [26, "parenchyma"], [26, ","], [26, "the"], [26, "latter"], [26, "predominantly"], [26, "in"], [26, "the"], [26, "medial"], [26, "temporal"], [26, "lobe"], [26, ","], [26, "result"], [26, "in"], [26, "apoptosis"], [26, "and"], [26, "necrosis"], [26, "."], [27, "human"], [27, "postmortem"], [27, "brain"], [27, "study"], [27, "indicate"], [27, "that"], [27, "human"], [27, "coronavirus"], [27, "variant"], [27, "and"], [27, "sars"], [27, "-"], [27, "cov"], [27, "can"], [27, "infect"], [27, "neuron"], [27, "and"], [27, "glia"], [27, ","], [27, "imply"], [27, "sars"], [27, "-"], [27, "cov-2"], [27, "may"], [27, "have"], [27, "similar"], [27, "neurovirulence"], [27, "."], [28, "additionally"], [28, ","], [28, "study"], [28, "have"], [28, "demonstrate"], [28, "an"], [28, "increase"], [28, "in"], [28, "cytokine"], [28, "serum"], [28, "level"], [28, "as"], [28, "a"], [28, "result"], [28, "of"], [28, "sars"], [28, "-"], [28, "cov"], [28, "infection"], [28, ","], [28, "consistent"], [28, "with"], [28, "the"], [28, "notion"], [28, "that"], [28, "cytokine"], [28, "overproduction"], [28, "and"], [28, "toxicity"], [28, "may"], [28, "be"], [28, "a"], [28, "relevant"], [28, "potential"], [28, "mechanism"], [28, "of"], [28, "neurologic"], [28, "injury"], [28, ","], [28, "parallel"], [28, "a"], [28, "know"], [28, "pathway"], [28, "of"], [28, "pulmonary"], [28, "injury"], [28, "."], [29, "we"], [29, "also"], [29, "discuss"], [29, "evidence"], [29, "that"], [29, "suggest"], [29, "that"], [29, "sars"], [29, "-"], [29, "cov-2"], [29, "may"], [29, "be"], [29, "a"], [29, "vasculotropic"], [29, "and"], [29, "neurotropic"], [29, "virus"], [29, "."], [30, "early"], [30, "report"], [30, "suggest"], [30, "covid-19"], [30, "may"], [30, "be"], [30, "associate"], [30, "with"], [30, "severe"], [30, "neurologic"], [30, "complication"], [30, ","], [30, "and"], [30, "several"], [30, "plausible"], [30, "mechanism"], [30, "exist"], [30, "to"], [30, "account"], [30, "for"], [30, "these"], [30, "observation"], [30, "."], [31, "a"], [31, "heightened"], [31, "awareness"], [31, "of"], [31, "the"], [31, "potential"], [31, "for"], [31, "neurologic"], [31, "involvement"], [31, "and"], [31, "further"], [31, "investigation"], [31, "into"], [31, "the"], [31, "relevant"], [31, "pathophysiology"], [31, "will"], [31, "be"], [31, "necessary"], [31, "to"], [31, "understand"], [31, "and"], [31, "ultimately"], [31, "mitigate"], [31, "sars"], [31, "-"], [31, "cov-2"], [31, "-"], [31, "associate"], [31, "neurologic"], [31, "injury"], [31, "."], [32, "accurate"], [32, "and"], [32, "rapid"], [32, "diagnostic"], [32, "test"], [32, "be"], [32, "critical"], [32, "for"], [32, "achieve"], [32, "control"], [32, "of"], [32, "coronavirus"], [32, "disease"], [32, "2019"], [32, "("], [32, "covid-19"], [32, ")"], [32, ","], [32, "a"], [32, "pandemic"], [32, "illness"], [32, "cause"], [32, "by"], [32, "severe"], [32, "acute"], [32, "respiratory"], [32, "syndrome"], [32, "coronavirus"], [32, "2"], [32, "("], [32, "sars"], [32, "-"], [32, "cov-2"], [32, ")"], [32, "."], [33, "diagnostic"], [33, "test"], [33, "for"], [33, "covid-19"], [33, "fall"], [33, "into"], [33, "two"], [33, "main"], [33, "category"], [33, ":"], [33, "molecular"], [33, "test"], [33, "that"], [33, "detect"], [33, "viral"], [33, "rna"], [33, ","], [33, "and"], [33, "serological"], [33, "test"], [33, "that"], [33, "detect"], [33, "anti"], [33, "-"], [33, "sars"], [33, "-"], [33, "cov-2"], [33, "immunoglobulin"], [33, "."], [34, "reverse"], [34, "transcriptase"], [34, "polymerase"], [34, "chain"], [34, "reaction"], [34, "("], [34, "rt"], [34, "-"], [34, "pcr"], [34, ")"], [34, ","], [34, "a"], [34, "molecular"], [34, "test"], [34, ","], [34, "have"], [34, "become"], [34, "the"], [34, "gold"], [34, "standard"], [34, "for"], [34, "diagnosis"], [34, "of"], [34, "covid-19"], [34, ";"], [34, "however"], [34, ","], [34, "this"], [34, "test"], [34, "have"], [34, "many"], [34, "limitation"], [34, "that"], [34, "include"], [34, "potential"], [34, "false"], [34, "negative"], [34, "result"], [34, ","], [34, "change"], [34, "in"], [34, "diagnostic"], [34, "accuracy"], [34, "over"], [34, "the"], [34, "disease"], [34, "course"], [34, ","], [34, "and"], [34, "precarious"], [34, "availability"], [34, "of"], [34, "test"], [34, "material"], [34, "."], [35, "serological"], [35, "test"], [35, "have"], [35, "generate"], [35, "substantial"], [35, "interest"], [35, "as"], [35, "an"], [35, "alternative"], [35, "or"], [35, "complement"], [35, "to"], [35, "rt"], [35, "-"], [35, "pcr"], [35, "and"], [35, "other"], [35, "nucleic"], [35, "acid"], [35, "test"], [35, "in"], [35, "the"], [35, "diagnosis"], [35, "of"], [35, "acute"], [35, "infection"], [35, ","], [35, "as"], [35, "some"], [35, "might"], [35, "be"], [35, "cheap"], [35, "and"], [35, "easy"], [35, "to"], [35, "implement"], [35, "at"], [35, "the"], [35, "point"], [35, "of"], [35, "care"], [35, "."], [36, "a"], [36, "clear"], [36, "advantage"], [36, "of"], [36, "these"], [36, "test"], [36, "over"], [36, "rt"], [36, "-"], [36, "pcr"], [36, "be"], [36, "that"], [36, "they"], [36, "can"], [36, "identify"], [36, "individual"], [36, "previously"], [36, "infect"], [36, "by"], [36, "sars"], [36, "-"], [36, "cov-2"], [36, ","], [36, "even"], [36, "if"], [36, "they"], [36, "never"], [36, "undergo"], [36, "testing"], [36, "while"], [36, "acutely"], [36, "ill"], [36, "."], [37, "many"], [37, "serological"], [37, "test"], [37, "for"], [37, "covid-19"], [37, "have"], [37, "become"], [37, "available"], [37, "in"], [37, "a"], [37, "short"], [37, "period"], [37, ","], [37, "include"], [37, "some"], [37, "market"], [37, "for"], [37, "use"], [37, "as"], [37, "rapid"], [37, ","], [37, "point"], [37, "-"], [37, "of"], [37, "-"], [37, "care"], [37, "test"], [37, "."], [38, "the"], [38, "pace"], [38, "of"], [38, "development"], [38, "have"], [38, ","], [38, "however"], [38, ","], [38, "exceed"], [38, "that"], [38, "of"], [38, "rigorous"], [38, "evaluation"], [38, ","], [38, "and"], [38, "important"], [38, "uncertainty"], [38, "about"], [38, "test"], [38, "accuracy"], [38, "remain"], [38, "."], [39, "covid-19"], [39, "be"], [39, "a"], [39, "novel"], [39, "coronavirus"], [39, "with"], [39, "an"], [39, "outbreak"], [39, "of"], [39, "unusual"], [39, "viral"], [39, "pneumonia"], [39, "in"], [39, "wuhan"], [39, ","], [39, "china"], [39, ","], [39, "and"], [39, "then"], [39, "pandemic"], [39, "."], [40, "base"], [40, "on"], [40, "its"], [40, "phylogenetic"], [40, "relationship"], [40, "and"], [40, "genomic"], [40, "structure"], [40, "the"], [40, "covid-19"], [40, "belong"], [40, "to"], [40, "genera"], [40, "betacoronavirus"], [40, "."], [41, "human"], [41, "betacoronaviruse"], [41, "("], [41, "sars"], [41, "-"], [41, "cov-2"], [41, ","], [41, "sars"], [41, "-"], [41, "cov"], [41, ","], [41, "and"], [41, "mer"], [41, "-"], [41, "cov"], [41, ")"], [41, "have"], [41, "many"], [41, "similarity"], [41, ","], [41, "but"], [41, "also"], [41, "have"], [41, "difference"], [41, "in"], [41, "their"], [41, "genomic"], [41, "and"], [41, "phenotypic"], [41, "structure"], [41, "that"], [41, "can"], [41, "influence"], [41, "their"], [41, "pathogenesis"], [41, "."], [42, "covid-19"], [42, "be"], [42, "contain"], [42, "single"], [42, "-"], [42, "strand"], [42, "("], [42, "positive"], [42, "-"], [42, "sense"], [42, ")"], [42, "rna"], [42, "associate"], [42, "with"], [42, "a"], [42, "nucleoprotein"], [42, "within"], [42, "a"], [42, "capsid"], [42, "comprise"], [42, "of"], [42, "matrix"], [42, "protein"], [42, "."], [43, "a"], [43, "typical"], [43, "cov"], [43, "contain"], [43, "at"], [43, "least"], [43, "six"], [43, "orf"], [43, "in"], [43, "its"], [43, "genome"], [43, "."], [44, "all"], [44, "the"], [44, "structural"], [44, "and"], [44, "accessory"], [44, "protein"], [44, "be"], [44, "translate"], [44, "from"], [44, "the"], [44, "sgrna"], [44, "of"], [44, "covs"], [44, "."], [45, "four"], [45, "main"], [45, "structural"], [45, "protein"], [45, "be"], [45, "encode"], [45, "by"], [45, "orf"], [45, "10"], [45, ","], [45, "11"], [45, "on"], [45, "the"], [45, "one"], [45, "-"], [45, "third"], [45, "of"], [45, "the"], [45, "genome"], [45, "near"], [45, "the"], [45, "3'-terminu"], [45, "."], [46, "the"], [46, "genetic"], [46, "and"], [46, "phenotypic"], [46, "structure"], [46, "of"], [46, "covid-19"], [46, "in"], [46, "pathogenesis"], [46, "be"], [46, "important"], [46, "."], [47, "this"], [47, "article"], [47, "highlight"], [47, "the"], [47, "most"], [47, "important"], [47, "of"], [47, "these"], [47, "feature"], [47, "compare"], [47, "to"], [47, "other"], [47, "betacoronaviruse"], [47, "."], [48, "the"], [48, "coronavirus"], [48, "disease"], [48, "2019"], [48, "("], [48, "covid\u201119"], [48, ")"], [48, "outbreak"], [48, ","], [48, "which"], [48, "have"], [48, "cause"], [48, ">"], [48, "46"], [48, "\xA0"], [48, "million"], [48, "confirm"], [48, "infection"], [48, "and"], [48, ">"], [48, "1.2"], [48, "\xA0"], [48, "million"], [48, "coronavirus"], [48, "relate"], [48, "death"], [48, ","], [48, "be"], [48, "one"], [48, "of"], [48, "the"], [48, "most"], [48, "devastating"], [48, "worldwide"], [48, "crisis"], [48, "in"], [48, "recent"], [48, "year"], [48, "."], [49, "infection"], [49, "with"], [49, "covid\u201119"], [49, "result"], [49, "in"], [49, "a"], [49, "fever"], [49, ","], [49, "dry"], [49, "cough"], [49, ","], [49, "general"], [49, "fatigue"], [49, ","], [49, "respiratory"], [49, "symptom"], [49, ","], [49, "diarrhoea"], [49, "and"], [49, "a"], [49, "sore"], [49, "throat"], [49, ","], [49, "similar"], [49, "to"], [49, "those"], [49, "of"], [49, "acute"], [49, "respiratory"], [49, "distress"], [49, "syndrome"], [49, "."], [50, "the"], [50, "causative"], [50, "agent"], [50, "of"], [50, "covid\u201119"], [50, ","], [50, "sars\u2011cov\u20112"], [50, ","], [50, "be"], [50, "a"], [50, "novel"], [50, "coronavirus"], [50, "strain"], [50, "."], [51, "to"], [51, "date"], [51, ","], [51, "remdesivir"], [51, "have"], [51, "be"], [51, "grant"], [51, "emergency"], [51, "use"], [51, "authorization"], [51, "for"], [51, "use"], [51, "in"], [51, "the"], [51, "management"], [51, "of"], [51, "infection"], [51, "."], [52, "additionally"], [52, ","], [52, "several"], [52, "efficient"], [52, "diagnostic"], [52, "tool"], [52, "be"], [52, "be"], [52, "actively"], [52, "develop"], [52, ","], [52, "and"], [52, "novel"], [52, "drug"], [52, "and"], [52, "vaccine"], [52, "be"], [52, "be"], [52, "evaluate"], [52, "for"], [52, "their"], [52, "efficacy"], [52, "as"], [52, "therapeutic"], [52, "agent"], [52, "against"], [52, "covid\u201119"], [52, ","], [52, "or"], [52, "in"], [52, "the"], [52, "prevention"], [52, "of"], [52, "infection"], [52, "."], [53, "the"], [53, "present"], [53, "review"], [53, "highlight"], [53, "the"], [53, "prevalent"], [53, "clinical"], [53, "manifestation"], [53, "of"], [53, "covid\u201119"], [53, ","], [53, "characterize"], [53, "the"], [53, "sars\u2011cov\u20112"], [53, "viral"], [53, "genome"], [53, "sequence"], [53, "and"], [53, "life"], [53, "cycle"], [53, ","], [53, "highlight"], [53, "the"], [53, "optimal"], [53, "method"], [53, "for"], [53, "prevent"], [53, "viral"], [53, "transmission"], [53, ","], [53, "and"], [53, "discuss"], [53, "possible"], [53, "molecular"], [53, "pharmacological"], [53, "mechanism"], [53, "and"], [53, "approach"], [53, "in"], [53, "the"], [53, "development"], [53, "of"], [53, "anti\u2011sars\u2011cov\u20112"], [53, "therapeutic"], [53, "agent"], [53, "."], [54, "in"], [54, "addition"], [54, ","], [54, "the"], [54, "use"], [54, "of"], [54, "traditional"], [54, "chinese"], [54, "medicine"], [54, "for"], [54, "management"], [54, "of"], [54, "covid\u201119"], [54, "be"], [54, "discuss"], [54, "."], [55, "it"], [55, "be"], [55, "expect"], [55, "that"], [55, "novel"], [55, "anti\u2011viral"], [55, "agent"], [55, ","], [55, "vaccine"], [55, "or"], [55, "an"], [55, "effective"], [55, "combination"], [55, "therapy"], [55, "for"], [55, "treatment"], [55, "/"], [55, "management"], [55, "of"], [55, "sars\u2011cov\u20112"], [55, "infection"], [55, "and"], [55, "spread"], [55, "therapy"], [55, "will"], [55, "be"], [55, "develop"], [55, "and"], [55, "implement"], [55, "in"], [55, "2021"], [55, ","], [55, "and"], [55, "we"], [55, "would"], [55, "like"], [55, "to"], [55, "extend"], [55, "our"], [55, "good"], [55, "regard"], [55, "to"], [55, "the"], [55, "frontline"], [55, "health"], [55, "worker"], [55, "across"], [55, "the"], [55, "world"], [55, "in"], [55, "their"], [55, "fight"], [55, "against"], [55, "covid\u201119"], [55, "."], [56, "cholesterol"], [56, "be"], [56, "be"], [56, "recognize"], [56, "as"], [56, "a"], [56, "molecule"], [56, "involve"], [56, "in"], [56, "regulate"], [56, "the"], [56, "entry"], [56, "of"], [56, "the"], [56, "sars"], [56, "-"], [56, "cov-2"], [56, "virus"], [56, "into"], [56, "the"], [56, "host"], [56, "cell"], [56, "."], [57, "however"], [57, ","], [57, "the"], [57, "datum"], [57, "about"], [57, "the"], [57, "possible"], [57, "role"], [57, "of"], [57, "cholesterol"], [57, "carry"], [57, "lipoprotein"], [57, "and"], [57, "their"], [57, "receptor"], [57, "in"], [57, "relation"], [57, "to"], [57, "infection"], [57, "be"], [57, "scarce"], [57, "and"], [57, "the"], [57, "connection"], [57, "of"], [57, "lipid"], [57, "-"], [57, "associate"], [57, "pathology"], [57, "with"], [57, "covid-19"], [57, "disease"], [57, "be"], [57, "in"], [57, "its"], [57, "infancy"], [57, "."], [58, "herein"], [58, "we"], [58, "provide"], [58, "an"], [58, "overview"], [58, "of"], [58, "lipid"], [58, "and"], [58, "lipid"], [58, "metabolism"], [58, "in"], [58, "relation"], [58, "to"], [58, "covid-19"], [58, ","], [58, "with"], [58, "special"], [58, "attention"], [58, "on"], [58, "different"], [58, "form"], [58, "of"], [58, "cholesterol"], [58, "."], [59, "cholesterol"], [59, "enrich"], [59, "lipid"], [59, "raft"], [59, "represent"], [59, "a"], [59, "platform"], [59, "for"], [59, "virus"], [59, "to"], [59, "enter"], [59, "the"], [59, "host"], [59, "cell"], [59, "by"], [59, "endocytosis"], [59, "."], [60, "generally"], [60, ","], [60, "high"], [60, "membrane"], [60, "cholesterol"], [60, "coincide"], [60, "with"], [60, "high"], [60, "efficiency"], [60, "of"], [60, "covid-19"], [60, "entry"], [60, "."], [61, "inversely"], [61, ","], [61, "patient"], [61, "with"], [61, "covid-19"], [61, "show"], [61, "lowered"], [61, "level"], [61, "of"], [61, "blood"], [61, "cholesterol"], [61, ","], [61, "high"], [61, "-"], [61, "density"], [61, "lipoprotein"], [61, "("], [61, "hdl"], [61, ")"], [61, "and"], [61, "low"], [61, "-"], [61, "density"], [61, "lipoprotein"], [61, "."], [62, "the"], [62, "modulate"], [62, "efficiency"], [62, "of"], [62, "viral"], [62, "entry"], [62, "can"], [62, "be"], [62, "explain"], [62, "by"], [62, "availability"], [62, "of"], [62, "sr"], [62, "-"], [62, "b1"], [62, "receptor"], [62, "."], [63, "hdl"], [63, "seem"], [63, "to"], [63, "have"], [63, "a"], [63, "variety"], [63, "of"], [63, "role"], [63, ","], [63, "from"], [63, "be"], [63, "itself"], [63, "a"], [63, "scavenger"], [63, "for"], [63, "virus"], [63, ","], [63, "an"], [63, "immune"], [63, "modulator"], [63, "and"], [63, "mediator"], [63, "of"], [63, "viral"], [63, "entry"], [63, "."], [64, "due"], [64, "to"], [64, "inverse"], [64, "role"], [64, "of"], [64, "membrane"], [64, "cholesterol"], [64, "and"], [64, "lipoprotein"], [64, "cholesterol"], [64, "in"], [64, "covid-19"], [64, "infect"], [64, "patient"], [64, ","], [64, "treatment"], [64, "of"], [64, "these"], [64, "patient"], [64, "with"], [64, "cholesterol"], [64, "low"], [64, "statin"], [64, "need"], [64, "more"], [64, "attention"], [64, "."], [65, "in"], [65, "conclusion"], [65, ","], [65, "cholesterol"], [65, "and"], [65, "lipoprotein"], [65, "be"], [65, "potential"], [65, "marker"], [65, "for"], [65, "monitor"], [65, "the"], [65, "viral"], [65, "infection"], [65, "status"], [65, ","], [65, "while"], [65, "the"], [65, "lipid"], [65, "metabolic"], [65, "pathway"], [65, "and"], [65, "the"], [65, "composition"], [65, "of"], [65, "membrane"], [65, "could"], [65, "be"], [65, "target"], [65, "to"], [65, "selectively"], [65, "inhibit"], [65, "the"], [65, "life"], [65, "cycle"], [65, "of"], [65, "the"], [65, "virus"], [65, "as"], [65, "a"], [65, "basis"], [65, "for"], [65, "antiviral"], [65, "therapy"], [65, "."], [66, "gain"], [66, "further"], [66, "insight"], [66, "into"], [66, "sars"], [66, "-"], [66, "cov-2"], [66, "route"], [66, "of"], [66, "infection"], [66, "and"], [66, "the"], [66, "underlie"], [66, "pathobiology"], [66, "of"], [66, "covid-19"], [66, "will"], [66, "support"], [66, "the"], [66, "design"], [66, "of"], [66, "rational"], [66, "treatment"], [66, "target"], [66, "the"], [66, "life"], [66, "cycle"], [66, "of"], [66, "the"], [66, "virus"], [66, "and/or"], [66, "the"], [66, "adverse"], [66, "effect"], [66, "("], [66, "e.g."], [66, ","], [66, "multi"], [66, "-"], [66, "organ"], [66, "collapse"], [66, ")"], [66, "that"], [66, "be"], [66, "trigger"], [66, "by"], [66, "covid-19"], [66, "-"], [66, "mediate"], [66, "adult"], [66, "respiratory"], [66, "distress"], [66, "syndrome"], [66, "("], [66, "ard"], [66, ")"], [66, "and/or"], [66, "other"], [66, "pathology"], [66, "."], [67, "covid-19"], [67, "be"], [67, "a"], [67, "two"], [67, "-"], [67, "phase"], [67, "disease"], [67, "be"], [67, "mark"], [67, "by"], [67, "("], [67, "phase"], [67, "1"], [67, ")"], [67, "increase"], [67, "virus"], [67, "transmission"], [67, "and"], [67, "infection"], [67, "rate"], [67, "due"], [67, "to"], [67, "the"], [67, "wide"], [67, "expression"], [67, "of"], [67, "the"], [67, "main"], [67, "infection"], [67, "-"], [67, "relate"], [67, "ace2"], [67, ","], [67, "tmprss2"], [67, "and"], [67, "ctsb"], [67, "/"], [67, "l"], [67, "human"], [67, "gene"], [67, "in"], [67, "tissue"], [67, "of"], [67, "the"], [67, "respiratory"], [67, "and"], [67, "gastrointestinal"], [67, "tract"], [67, ","], [67, "as"], [67, "well"], [67, "as"], [67, "by"], [67, "("], [67, "phase"], [67, "2"], [67, ")"], [67, "host-"], [68, "and"], [68, "probably"], [68, "sex-"], [68, "and/or"], [68, "age"], [68, "-"], [68, "specific"], [68, "uncontrolled"], [68, "inflammatory"], [68, "immune"], [68, "response"], [68, "which"], [68, "drive"], [68, "hyper"], [68, "-"], [68, "cytokinemia"], [68, ","], [68, "aggressive"], [68, "inflammation"], [68, "and"], [68, "("], [68, "due"], [68, "to"], [68, "broad"], [68, "organotropism"], [68, "of"], [68, "sars"], [68, "-"], [68, "cov-2"], [68, ")"], [68, "collateral"], [68, "tissue"], [68, "damage"], [68, "and"], [68, "systemic"], [68, "failure"], [68, "likely"], [68, "because"], [68, "of"], [68, "imbalance"], [68, "ace"], [68, "/"], [68, "angii"], [68, "/"], [68, "at1r"], [68, "and"], [68, "ace2"], [68, "/"], [68, "ang(1"], [68, "-"], [68, "7)/masr"], [68, "axis"], [68, "signal"], [68, "."], [69, "here"], [69, "we"], [69, "discuss"], [69, "sars"], [69, "-"], [69, "cov-2"], [69, "life"], [69, "cycle"], [69, "and"], [69, "a"], [69, "number"], [69, "of"], [69, "approach"], [69, "aim"], [69, "to"], [69, "suppress"], [69, "viral"], [69, "infection"], [69, "rate"], [69, "or"], [69, "propagation"], [69, ";"], [69, "increase"], [69, "virus"], [69, "antigen"], [69, "presentation"], [69, "in"], [69, "order"], [69, "to"], [69, "activate"], [69, "a"], [69, "robust"], [69, "and"], [69, "durable"], [69, "adaptive"], [69, "immune"], [69, "response"], [69, "from"], [69, "the"], [69, "host"], [69, ","], [69, "and/or"], [69, "mitigate"], [69, "the"], [69, "ard"], [69, "-"], [69, "relate"], [69, '"'], [69, "cytokine"], [69, "storm"], [69, '"'], [69, "and"], [69, "collateral"], [69, "tissue"], [69, "damage"], [69, "that"], [69, "trigger"], [69, "the"], [69, "severe"], [69, "life"], [69, "-"], [69, "threaten"], [69, "complication"], [69, "of"], [69, "covid-19"], [69, "."], [70, "currently"], [70, ","], [70, "there"], [70, "be"], [70, "no"], [70, "treatment"], [70, "option"], [70, "available"], [70, "for"], [70, "the"], [70, "deadly"], [70, "contagious"], [70, "disease"], [70, ","], [70, "coronavirus"], [70, "disease"], [70, "2019"], [70, "("], [70, "covid-19"], [70, ")"], [70, "."], [71, "drug"], [71, "repurpose"], [71, "be"], [71, "a"], [71, "process"], [71, "of"], [71, "identify"], [71, "new"], [71, "use"], [71, "for"], [71, "approve"], [71, "or"], [71, "investigational"], [71, "drug"], [71, "and"], [71, "it"], [71, "be"], [71, "consider"], [71, "as"], [71, "a"], [71, "very"], [71, "effective"], [71, "strategy"], [71, "for"], [71, "drug"], [71, "discovery"], [71, "as"], [71, "it"], [71, "involve"], [71, "less"], [71, "time"], [71, "and"], [71, "cost"], [71, "to"], [71, "find"], [71, "a"], [71, "therapeutic"], [71, "agent"], [71, "in"], [71, "comparison"], [71, "to"], [71, "the"], [71, "de"], [71, "novo"], [71, "drug"], [71, "discovery"], [71, "process"], [71, "."], [72, "the"], [72, "present"], [72, "review"], [72, "will"], [72, "focus"], [72, "on"], [72, "the"], [72, "repurpose"], [72, "efficacy"], [72, "of"], [72, "the"], [72, "currently"], [72, "use"], [72, "drug"], [72, "against"], [72, "covid-19"], [72, "and"], [72, "their"], [72, "mechanism"], [72, "of"], [72, "action"], [72, ","], [72, "pharmacokinetic"], [72, ","], [72, "dosing"], [72, ","], [72, "safety"], [72, ","], [72, "and"], [72, "their"], [72, "future"], [72, "perspective"], [72, "."], [73, "relevant"], [73, "article"], [73, "with"], [73, "experimental"], [73, "study"], [73, "conduct"], [73, "in"], [73, "-"], [73, "silico"], [73, ","], [73, "in"], [73, "-"], [73, "vitro"], [73, ","], [73, "in"], [73, "-"], [73, "vivo"], [73, ","], [73, "clinical"], [73, "trial"], [73, "in"], [73, "human"], [73, ","], [73, "case"], [73, "report"], [73, ","], [73, "and"], [73, "news"], [73, "archive"], [73, "be"], [73, "select"], [73, "for"], [73, "the"], [73, "review"], [73, "."], [74, "number"], [74, "of"], [74, "drug"], [74, "such"], [74, "as"], [74, "remdesivir"], [74, ","], [74, "favipiravir"], [74, ","], [74, "ribavirin"], [74, ","], [74, "lopinavir"], [74, ","], [74, "ritonavir"], [74, ","], [74, "darunavir"], [74, ","], [74, "arbidol"], [74, ","], [74, "chloroquine"], [74, ","], [74, "hydroxychloroquine"], [74, ","], [74, "tocilizumab"], [74, "and"], [74, "interferon"], [74, "have"], [74, "show"], [74, "inhibitory"], [74, "effect"], [74, "against"], [74, "the"], [74, "sars"], [74, "-"], [74, "cov2"], [74, "in"], [74, "-"], [74, "vitro"], [74, "as"], [74, "well"], [74, "as"], [74, "in"], [74, "clinical"], [74, "condition"], [74, "."], [75, "these"], [75, "drug"], [75, "either"], [75, "act"], [75, "through"], [75, "virus"], [75, "-"], [75, "relate"], [75, "target"], [75, "such"], [75, "as"], [75, "rna"], [75, "genome"], [75, ","], [75, "polypeptide"], [75, "packing"], [75, "and"], [75, "uptake"], [75, "pathway"], [75, "or"], [75, "target"], [75, "host"], [75, "-"], [75, "relate"], [75, "pathway"], [75, "involve"], [75, "angiotensin"], [75, "-"], [75, "convert"], [75, "enzyme-2"], [75, "("], [75, "ace2"], [75, ")"], [75, "receptor"], [75, "and"], [75, "inflammatory"], [75, "pathway"], [75, "."], [76, "use"], [76, "the"], [76, "basic"], [76, "knowledge"], [76, "of"], [76, "viral"], [76, "pathogenesis"], [76, "and"], [76, "pharmacodynamic"], [76, "of"], [76, "drug"], [76, "as"], [76, "well"], [76, "as"], [76, "use"], [76, "computational"], [76, "tool"], [76, ","], [76, "many"], [76, "drug"], [76, "be"], [76, "currently"], [76, "in"], [76, "pipeline"], [76, "to"], [76, "be"], [76, "repurpose"], [76, "."], [77, "in"], [77, "the"], [77, "current"], [77, "scenario"], [77, ","], [77, "repositioning"], [77, "of"], [77, "the"], [77, "drug"], [77, "could"], [77, "be"], [77, "consider"], [77, "the"], [77, "new"], [77, "avenue"], [77, "for"], [77, "the"], [77, "treatment"], [77, "of"], [77, "covid-19"], [77, "."], [78, "severe"], [78, "acute"], [78, "respiratory"], [78, "syndrome"], [78, "coronavirus-2"], [78, "("], [78, "sars"], [78, "-"], [78, "cov-2"], [78, ")"], [78, "be"], [78, "a"], [78, "novel"], [78, "coronavirus"], [78, "that"], [78, "be"], [78, "responsible"], [78, "for"], [78, "the"], [78, "2019"], [78, "-"], [78, "2020"], [78, "pandemic"], [78, "."], [79, "in"], [79, "this"], [79, "comprehensive"], [79, "review"], [79, ","], [79, "we"], [79, "discuss"], [79, "the"], [79, "current"], [79, "publish"], [79, "literature"], [79, "surround"], [79, "the"], [79, "sars"], [79, "-"], [79, "cov-2"], [79, "virus"], [79, "."], [80, "we"], [80, "examine"], [80, "the"], [80, "fundamental"], [80, "concept"], [80, "include"], [80, "the"], [80, "origin"], [80, ","], [80, "virology"], [80, ","], [80, "pathogenesis"], [80, ","], [80, "clinical"], [80, "manifestation"], [80, ","], [80, "diagnosis"], [80, ","], [80, "laboratory"], [80, ","], [80, "radiology"], [80, ","], [80, "and"], [80, "histopathologic"], [80, "finding"], [80, ","], [80, "complication"], [80, ","], [80, "and"], [80, "treatment"], [80, "."], [81, "give"], [81, "that"], [81, "much"], [81, "of"], [81, "the"], [81, "information"], [81, "have"], [81, "be"], [81, "extrapolate"], [81, "from"], [81, "what"], [81, "we"], [81, "know"], [81, "about"], [81, "other"], [81, "coronaviruse"], [81, "include"], [81, "severe"], [81, "acute"], [81, "respiratory"], [81, "syndrome"], [81, "coronavirus"], [81, "("], [81, "sars"], [81, "-"], [81, "cov"], [81, ")"], [81, "and"], [81, "middle"], [81, "east"], [81, "respiratory"], [81, "syndrome"], [81, "coronavirus"], [81, "("], [81, "mer"], [81, "-"], [81, "cov"], [81, ")"], [81, ","], [81, "we"], [81, "identify"], [81, "and"], [81, "provide"], [81, "insight"], [81, "into"], [81, "controversy"], [81, "and"], [81, "research"], [81, "gap"], [81, "for"], [81, "the"], [81, "current"], [81, "pandemic"], [81, "to"], [81, "assist"], [81, "with"], [81, "future"], [81, "research"], [81, "idea"], [81, "."], [82, "finally"], [82, ","], [82, "we"], [82, "discuss"], [82, "the"], [82, "global"], [82, "response"], [82, "to"], [82, "the"], [82, "coronavirus"], [82, "disease-2019"], [82, "("], [82, "covid-19"], [82, ")"], [82, "pandemic"], [82, "and"], [82, "provide"], [82, "thought"], [82, "regard"], [82, "lesson"], [82, "for"], [82, "future"], [82, "pandemic"], [82, "."], [83, "an"], [83, "acute"], [83, "respiratory"], [83, "disease"], [83, "cause"], [83, "by"], [83, "a"], [83, "severe"], [83, "acute"], [83, "respiratory"], [83, "syndrome"], [83, "coronavirus"], [83, "2"], [83, "("], [83, "sars"], [83, "-"], [83, "cov-2"], [83, ")"], [83, "that"], [83, "surface"], [83, "in"], [83, "china"], [83, "in"], [83, "late"], [83, "2019"], [83, ","], [83, "continue"], [83, "to"], [83, "spread"], [83, "rapidly"], [83, "across"], [83, "the"], [83, "globe"], [83, "cause"], [83, "serious"], [83, "concern"], [83, "."], [84, "the"], [84, "coronavirus"], [84, "disease"], [84, "2019"], [84, "("], [84, "covid-19"], [84, ")"], [84, "be"], [84, "declare"], [84, "as"], [84, "a"], [84, "public"], [84, "health"], [84, "emergency"], [84, "worldwide"], [84, "by"], [84, "the"], [84, "world"], [84, "health"], [84, "organization"], [84, "("], [84, "who"], [84, ")"], [84, "."], [85, "increase"], [85, "evidence"], [85, "have"], [85, "demonstrate"], [85, "human"], [85, "-"], [85, "to"], [85, "-"], [85, "human"], [85, "transmission"], [85, "that"], [85, "primarily"], [85, "affect"], [85, "the"], [85, "upper"], [85, "respiratory"], [85, "tract"], [85, "follow"], [85, "by"], [85, "low"], [85, "respiratory"], [85, "tract"], [85, "damage"], [85, "lead"], [85, "to"], [85, "severe"], [85, "pneumonia"], [85, "."], [86, "base"], [86, "on"], [86, "the"], [86, "current"], [86, "status"], [86, ","], [86, "the"], [86, "elderly"], [86, "population"], [86, "and"], [86, "people"], [86, "with"], [86, "prior"], [86, "co"], [86, "-"], [86, "morbidity"], [86, "be"], [86, "highly"], [86, "susceptible"], [86, "to"], [86, "serious"], [86, "health"], [86, "effect"], [86, "include"], [86, "cytokine"], [86, "up"], [86, "-"], [86, "regulation"], [86, "and"], [86, "acute"], [86, "respiratory"], [86, "distress"], [86, "syndrome"], [86, "("], [86, "ard"], [86, ")"], [86, "."], [87, "currently"], [87, ","], [87, "covid-19"], [87, "research"], [87, "be"], [87, "still"], [87, "in"], [87, "the"], [87, "preliminary"], [87, "stage"], [87, "necessitate"], [87, "rigorous"], [87, "study"], [87, "."], [88, "there"], [88, "be"], [88, "no"], [88, "specific"], [88, "drug"], [88, "or"], [88, "vaccine"], [88, "target"], [88, "sars"], [88, "-"], [88, "cov-2"], [88, "currently"], [88, "and"], [88, "only"], [88, "symptomatic"], [88, "treatment"], [88, "be"], [88, "be"], [88, "administer"], [88, ","], [88, "but"], [88, "several"], [88, "antiviral"], [88, "be"], [88, "under"], [88, "active"], [88, "investigation"], [88, "."], [89, "in"], [89, "this"], [89, "review"], [89, ","], [89, "we"], [89, "have"], [89, "summarize"], [89, "the"], [89, "epidemiology"], [89, ","], [89, "entry"], [89, "mechanism"], [89, ","], [89, "immune"], [89, "response"], [89, ","], [89, "and"], [89, "therapeutic"], [89, "implication"], [89, ","], [89, "possible"], [89, "drug"], [89, "target"], [89, ","], [89, "their"], [89, "ongoing"], [89, "clinical"], [89, "trial"], [89, ","], [89, "and"], [89, "put"], [89, "forward"], [89, "vital"], [89, "question"], [89, "to"], [89, "offer"], [89, "new"], [89, "direction"], [89, "to"], [89, "the"], [89, "covid-19"], [89, "research"], [89, "."], [90, "in"], [90, "december"], [90, "2019"], [90, ","], [90, "twenty"], [90, "-"], [90, "seven"], [90, "pneumonia"], [90, "patient"], [90, "with"], [90, "unknown"], [90, "cause"], [90, "originate"], [90, "in"], [90, "south"], [90, "china"], [90, "seafood"], [90, "market"], [90, "in"], [90, "wuhan"], [90, "."], [91, "the"], [91, "virus"], [91, "infection"], [91, "spread"], [91, "rapidly"], [91, "and"], [91, "sweep"], [91, "through"], [91, "china"], [91, "in"], [91, "less"], [91, "than"], [91, "a"], [91, "month"], [91, "."], [92, "subsequently"], [92, ","], [92, "the"], [92, "virus"], [92, "be"], [92, "prove"], [92, "a"], [92, "novel"], [92, "coronavirus"], [92, "and"], [92, "name"], [92, "sars"], [92, "-"], [92, "cov-2"], [92, "."], [93, "the"], [93, "outbreak"], [93, "of"], [93, "novel"], [93, "coronavirus"], [93, "have"], [93, "be"], [93, "determine"], [93, "as"], [93, "a"], [93, "public"], [93, "health"], [93, "emergency"], [93, "of"], [93, "international"], [93, "concern"], [93, "("], [93, "pheic"], [93, ")"], [93, "by"], [93, "who"], [93, "on"], [93, "january"], [93, "31"], [93, ","], [93, "2020"], [93, "."], [94, "similar"], [94, "to"], [94, "other"], [94, "coronaviruse"], [94, "like"], [94, "the"], [94, "middle"], [94, "east"], [94, "respiratory"], [94, "syndrome"], [94, "("], [94, "mer"], [94, ")"], [94, "cov"], [94, "and"], [94, "severe"], [94, "acute"], [94, "respiratory"], [94, "syndrome"], [94, "("], [94, "sars"], [94, ")"], [94, "cov"], [94, ","], [94, "the"], [94, "novel"], [94, "coronavirus"], [94, "be"], [94, "report"], [94, "to"], [94, "spread"], [94, "via"], [94, "respiratory"], [94, "droplet"], [94, "and"], [94, "close"], [94, "contact"], [94, "from"], [94, "human"], [94, "to"], [94, "human"], [94, ","], [94, "which"], [94, "mean"], [94, "the"], [94, "virus"], [94, "be"], [94, "highly"], [94, "infectious"], [94, "and"], [94, "dangerous"], [94, "."], [95, "unfortunately"], [95, ","], [95, "till"], [95, "now"], [95, "the"], [95, "virus"], [95, "have"], [95, "spread"], [95, "to"], [95, "over"], [95, "200"], [95, "country"], [95, "/"], [95, "territory"], [95, "/"], [95, "area"], [95, "around"], [95, "the"], [95, "world"], [95, "and"], [95, "the"], [95, "coronavirus"], [95, "disease"], [95, "2019"], [95, "("], [95, "covid-19"], [95, ")"], [95, "outbreak"], [95, "be"], [95, "continue"], [95, "to"], [95, "grow"], [95, "."], [96, "currently"], [96, ","], [96, "information"], [96, "sharing"], [96, "and"], [96, "transparency"], [96, "be"], [96, "essential"], [96, "for"], [96, "risk"], [96, "assessment"], [96, "and"], [96, "epidemic"], [96, "control"], [96, "in"], [96, "all"], [96, "endemic"], [96, "area"], [96, "."], [97, "in"], [97, "this"], [97, "article"], [97, ","], [97, "we"], [97, "compare"], [97, "sars"], [97, "-"], [97, "cov-2"], [97, "with"], [97, "sars"], [97, "-"], [97, "cov"], [97, "and"], [97, "influenza"], [97, "virus"], [97, ","], [97, "discuss"], [97, "current"], [97, "researching"], [97, "progress"], [97, "of"], [97, "covid-19"], [97, ","], [97, "include"], [97, "clinical"], [97, "characteristic"], [97, ","], [97, "pathological"], [97, "change"], [97, ","], [97, "treatment"], [97, "measure"], [97, ","], [97, "and"], [97, "so"], [97, "on"], [97, "."], [98, "coronavirus"], [98, "disease"], [98, "2019"], [98, "("], [98, "covid-19"], [98, ")"], [98, "be"], [98, "an"], [98, "infectious"], [98, "disease"], [98, "cause"], [98, "by"], [98, "coronavirus-2"], [98, "("], [98, "sars"], [98, "-"], [98, "cov-2"], [98, ")"], [98, "that"], [98, "cause"], [98, "a"], [98, "severe"], [98, "acute"], [98, "respiratory"], [98, "syndrome"], [98, ","], [98, "a"], [98, "characteristic"], [98, "hyperinflammatory"], [98, "response"], [98, ","], [98, "vascular"], [98, "damage"], [98, ","], [98, "microangiopathy"], [98, ","], [98, "angiogenesis"], [98, "and"], [98, "widespread"], [98, "thrombosis"], [98, "."], [99, "four"], [99, "stage"], [99, "of"], [99, "covid-19"], [99, "have"], [99, "be"], [99, "identify"], [99, ":"], [99, "the"], [99, "first"], [99, "stage"], [99, "be"], [99, "characterise"], [99, "by"], [99, "upper"], [99, "respiratory"], [99, "tract"], [99, "infection"], [99, ";"], [99, "the"], [99, "second"], [99, "by"], [99, "the"], [99, "onset"], [99, "of"], [99, "dyspnoea"], [99, "and"], [99, "pneumonia"], [99, ";"], [99, "the"], [99, "third"], [99, "by"], [99, "a"], [99, "worsen"], [99, "clinical"], [99, "scenario"], [99, "dominate"], [99, "by"], [99, "a"], [99, "cytokine"], [99, "storm"], [99, "and"], [99, "the"], [99, "consequent"], [99, "hyperinflammatory"], [99, "state"], [99, ";"], [99, "and"], [99, "the"], [99, "fourth"], [99, "by"], [99, "death"], [99, "or"], [99, "recovery"], [99, "."], [100, "currently"], [100, ","], [100, "no"], [100, "treatment"], [100, "can"], [100, "act"], [100, "specifically"], [100, "against"], [100, "the"], [100, "sars"], [100, "-"], [100, "cov-2"], [100, "infection"], [100, "."], [101, "base"], [101, "on"], [101, "the"], [101, "pathological"], [101, "feature"], [101, "and"], [101, "different"], [101, "clinical"], [101, "phase"], [101, "of"], [101, "covid-19"], [101, ","], [101, "particularly"], [101, "in"], [101, "patient"], [101, "with"], [101, "moderate"], [101, "to"], [101, "severe"], [101, "covid-19"], [101, ","], [101, "the"], [101, "class"], [101, "of"], [101, "drug"], [101, "use"], [101, "be"], [101, "antiviral"], [101, "agent"], [101, ","], [101, "inflammation"], [101, "inhibitor"], [101, "/"], [101, "antirheumatic"], [101, "drug"], [101, ","], [101, "low"], [101, "molecular"], [101, "weight"], [101, "heparin"], [101, ","], [101, "plasma"], [101, ","], [101, "and"], [101, "hyperimmune"], [101, "immunoglobulin"], [101, "."], [102, "during"], [102, "this"], [102, "emergency"], [102, "period"], [102, "of"], [102, "the"], [102, "covid-19"], [102, "outbreak"], [102, ","], [102, "clinical"], [102, "researcher"], [102, "be"], [102, "use"], [102, "and"], [102, "test"], [102, "a"], [102, "variety"], [102, "of"], [102, "possible"], [102, "treatment"], [102, "."], [103, "base"], [103, "on"], [103, "these"], [103, "premise"], [103, ","], [103, "this"], [103, "review"], [103, "aim"], [103, "to"], [103, "discuss"], [103, "the"], [103, "most"], [103, "update"], [103, "pharmacological"], [103, "treatment"], [103, "to"], [103, "effectively"], [103, "act"], [103, "against"], [103, "the"], [103, "sars"], [103, "-"], [103, "cov-2"], [103, "infection"], [103, "and"], [103, "support"], [103, "researcher"], [103, "and"], [103, "clinician"], [103, "in"], [103, "relation"], [103, "to"], [103, "any"], [103, "current"], [103, "and"], [103, "future"], [103, "development"], [103, "in"], [103, "cure"], [103, "covid-19"], [103, "patient"], [103, "."], [104, "coronavirus"], [104, "disease"], [104, "2019"], [104, "("], [104, "covid-19"], [104, ")"], [104, "start"], [104, "as"], [104, "an"], [104, "epidemic"], [104, "in"], [104, "wuhan"], [104, "in"], [104, "2019"], [104, ","], [104, "and"], [104, "have"], [104, "since"], [104, "become"], [104, "a"], [104, "pandemic"], [104, "."], [105, "group"], [105, "from"], [105, "china"], [105, "identify"], [105, "and"], [105, "sequence"], [105, "the"], [105, "virus"], [105, "responsible"], [105, "for"], [105, "covid-19"], [105, ","], [105, "name"], [105, "severe"], [105, "acute"], [105, "respiratory"], [105, "syndrome"], [105, "coronavirus"], [105, "2"], [105, "("], [105, "sars"], [105, "-"], [105, "cov-2"], [105, ")"], [105, ","], [105, "and"], [105, "determine"], [105, "that"], [105, "it"], [105, "be"], [105, "a"], [105, "novel"], [105, "coronavirus"], [105, "share"], [105, "high"], [105, "sequence"], [105, "identity"], [105, "with"], [105, "bat-"], [105, "and"], [105, "pangolin"], [105, "-"], [105, "derive"], [105, "sars"], [105, "-"], [105, "like"], [105, "coronaviruse"], [105, ","], [105, "suggest"], [105, "a"], [105, "zoonotic"], [105, "origin"], [105, "."], [106, "sars"], [106, "-"], [106, "cov-2"], [106, "be"], [106, "a"], [106, "member"], [106, "of"], [106, "the"], [106, "coronaviridae"], [106, "family"], [106, "of"], [106, "envelop"], [106, ","], [106, "positive"], [106, "-"], [106, "sense"], [106, ","], [106, "single"], [106, "-"], [106, "strand"], [106, "rna"], [106, "virus"], [106, "that"], [106, "infect"], [106, "a"], [106, "broad"], [106, "range"], [106, "of"], [106, "vertebrate"], [106, "."], [107, "the"], [107, "rapid"], [107, "release"], [107, "of"], [107, "the"], [107, "sequence"], [107, "of"], [107, "the"], [107, "virus"], [107, "have"], [107, "enable"], [107, "the"], [107, "development"], [107, "of"], [107, "diagnostic"], [107, "tool"], [107, "."], [108, "additionally"], [108, ","], [108, "serological"], [108, "test"], [108, "can"], [108, "now"], [108, "identify"], [108, "individual"], [108, "who"], [108, "have"], [108, "be"], [108, "infect"], [108, "."], [109, "sars"], [109, "-"], [109, "cov-2"], [109, "infection"], [109, "be"], [109, "associate"], [109, "with"], [109, "a"], [109, "fatality"], [109, "rate"], [109, "of"], [109, "around"], [109, "1"], [109, "-"], [109, "3"], [109, "%"], [109, ","], [109, "which"], [109, "be"], [109, "commonly"], [109, "link"], [109, "to"], [109, "the"], [109, "development"], [109, "of"], [109, "acute"], [109, "respiratory"], [109, "distress"], [109, "syndrome"], [109, "("], [109, "ard"], [109, ")"], [109, ","], [109, "likely"], [109, "result"], [109, "from"], [109, "uncontrolled"], [109, "immune"], [109, "activation"], [109, ","], [109, "the"], [109, "so"], [109, "call"], [109, '"'], [109, "cytokine"], [109, "storm"], [109, '"'], [109, "."], [110, "risk"], [110, "factor"], [110, "for"], [110, "mortality"], [110, "include"], [110, "advanced"], [110, "age"], [110, ","], [110, "obesity"], [110, ","], [110, "diabetes"], [110, ","], [110, "and"], [110, "hypertension"], [110, "."], [111, "drug"], [111, "repurpose"], [111, "have"], [111, "be"], [111, "use"], [111, "to"], [111, "rapidly"], [111, "identify"], [111, "potential"], [111, "treatment"], [111, "for"], [111, "covid-19"], [111, ","], [111, "which"], [111, "could"], [111, "move"], [111, "quickly"], [111, "to"], [111, "phase"], [111, "iii"], [111, "."], [112, "well"], [112, "knowledge"], [112, "of"], [112, "the"], [112, "virus"], [112, "and"], [112, "its"], [112, "enzyme"], [112, "will"], [112, "aid"], [112, "the"], [112, "development"], [112, "of"], [112, "more"], [112, "potent"], [112, "and"], [112, "specific"], [112, "direct"], [112, "-"], [112, "act"], [112, "antiviral"], [112, "."], [113, "in"], [113, "the"], [113, "long"], [113, "term"], [113, ","], [113, "a"], [113, "vaccine"], [113, "to"], [113, "prevent"], [113, "infection"], [113, "be"], [113, "crucial"], [113, ";"], [113, "however"], [113, ","], [113, "even"], [113, "if"], [113, "successful"], [113, ","], [113, "it"], [113, "might"], [113, "not"], [113, "be"], [113, "available"], [113, "before"], [113, "2021"], [113, "-"], [113, "22"], [113, "."], [114, "to"], [114, "date"], [114, ","], [114, "except"], [114, "for"], [114, "intravenous"], [114, "remdesivir"], [114, "and"], [114, "dexamethasone"], [114, ","], [114, "which"], [114, "have"], [114, "modest"], [114, "effect"], [114, "in"], [114, "moderate"], [114, "to"], [114, "severe"], [114, "covid-19"], [114, ","], [114, "no"], [114, "strong"], [114, "clinical"], [114, "evidence"], [114, "support"], [114, "the"], [114, "efficacy"], [114, "of"], [114, "any"], [114, "other"], [114, "drug"], [114, "against"], [114, "sars"], [114, "-"], [114, "cov-2"], [114, "."], [115, "the"], [115, "aim"], [115, "of"], [115, "this"], [115, "review"], [115, "be"], [115, "to"], [115, "provide"], [115, "insight"], [115, "on"], [115, "the"], [115, "discovery"], [115, "of"], [115, "sars"], [115, "-"], [115, "cov-2"], [115, ","], [115, "its"], [115, "virology"], [115, ","], [115, "diagnostic"], [115, "tool"], [115, ","], [115, "and"], [115, "the"], [115, "ongoing"], [115, "drug"], [115, "discovery"], [115, "effort"], [115, "."], [116, "the"], [116, "covid-19"], [116, "pandemic"], [116, "cause"], [116, "by"], [116, "sars"], [116, "-"], [116, "cov-2"], [116, "have"], [116, "spread"], [116, "rapidly"], [116, "."], [117, "to"], [117, "date"], [117, ","], [117, "country"], [117, "have"], [117, "rely"], [117, "on"], [117, "the"], [117, "prevention"], [117, "of"], [117, "the"], [117, "disease"], [117, "through"], [117, "isolation"], [117, ","], [117, "quarantine"], [117, ","], [117, "and"], [117, "clinical"], [117, "care"], [117, "of"], [117, "affect"], [117, "individual"], [117, "."], [118, "however"], [118, ","], [118, "study"], [118, "on"], [118, "the"], [118, "role"], [118, "of"], [118, "asymptomatic"], [118, "and"], [118, "mildly"], [118, "infect"], [118, "subject"], [118, "in"], [118, "disease"], [118, "transmission"], [118, ","], [118, "use"], [118, "of"], [118, "antiviral"], [118, "drug"], [118, ","], [118, "and"], [118, "vaccination"], [118, "of"], [118, "the"], [118, "general"], [118, "population"], [118, "will"], [118, "be"], [118, "very"], [118, "important"], [118, "for"], [118, "mitigate"], [118, "the"], [118, "effect"], [118, "of"], [118, "the"], [118, "eventual"], [118, "return"], [118, "of"], [118, "this"], [118, "pandemic"], [118, "."], [119, "initial"], [119, "investigation"], [119, "be"], [119, "ongoing"], [119, "to"], [119, "evaluate"], [119, "antigenic"], [119, "structure"], [119, "of"], [119, "sars"], [119, "-"], [119, "cov-2"], [119, "and"], [119, "the"], [119, "immunogenicity"], [119, "of"], [119, "vaccine"], [119, "candidate"], [119, "."], [120, "there"], [120, "also"], [120, "be"], [120, "a"], [120, "need"], [120, "to"], [120, "comprehensively"], [120, "compile"], [120, "the"], [120, "detail"], [120, "of"], [120, "previous"], [120, "study"], [120, "on"], [120, "sars"], [120, "-"], [120, "relate"], [120, "vaccine"], [120, "that"], [120, "can"], [120, "be"], [120, "extrapolate"], [120, "to"], [120, "identify"], [120, "potent"], [120, "vaccine"], [120, "target"], [120, "for"], [120, "develop"], [120, "covid-19"], [120, "vaccine"], [120, "."], [121, "this"], [121, "review"], [121, "aim"], [121, "to"], [121, "analyze"], [121, "previous"], [121, "study"], [121, ","], [121, "current"], [121, "status"], [121, ","], [121, "and"], [121, "future"], [121, "possibility"], [121, "for"], [121, "produce"], [121, "sars"], [121, "-"], [121, "cov-2"], [121, "vaccine"], [121, "."], [122, "report"], [122, "that"], [122, "the"], [122, "over"], [122, "-"], [122, "the"], [122, "-"], [122, "counter"], [122, "histamine"], [122, "h"], [122, "receptor"], [122, "antagonist"], [122, "famotidine"], [122, "could"], [122, "help"], [122, "treat"], [122, "the"], [122, "novel"], [122, "coronavirus"], [122, "disease"], [122, "("], [122, "covid-19"], [122, ")"], [122, "appear"], [122, "from"], [122, "april"], [122, "2020"], [122, "."], [123, "we"], [123, ","], [123, "therefore"], [123, ","], [123, "examine"], [123, "report"], [123, "on"], [123, "interaction"], [123, "between"], [123, "severe"], [123, "acute"], [123, "respiratory"], [123, "syndrome"], [123, "coronavirus"], [123, "2"], [123, "("], [123, "sars"], [123, "-"], [123, "cov-2"], [123, ")"], [123, "and"], [123, "histamine"], [123, "receptor"], [123, "antagonist"], [123, "."], [124, "a"], [124, "systematic"], [124, "literature"], [124, "search"], [124, "be"], [124, "perform"], [124, "by"], [124, "19"], [124, "september"], [124, "2020"], [124, ","], [124, "and"], [124, "update"], [124, "on"], [124, "28"], [124, "october"], [124, "2020"], [124, ","], [124, "in"], [124, "pubmed"], [124, ","], [124, "scopus"], [124, ","], [124, "cochrane"], [124, "library"], [124, "and"], [124, "google"], [124, "scholar"], [124, "use"], [124, "("], [124, "covid-19"], [124, "or"], [124, "coronavirus"], [124, "or"], [124, "sars"], [124, "-"], [124, "cov-2"], [124, ")"], [124, "and"], [124, "("], [124, "histamine"], [124, "antagonist"], [124, "or"], [124, "famotidine"], [124, "or"], [124, "cimetidine"], [124, ")"], [124, "."], [125, "clinicaltrials.gov"], [125, "be"], [125, "search"], [125, "for"], [125, "covid-19"], [125, "and"], [125, "("], [125, "famotidine"], [125, "or"], [125, "histamine"], [125, ")"], [125, "."], [126, "famotidine"], [126, "may"], [126, "be"], [126, "a"], [126, "useful"], [126, "addition"], [126, "in"], [126, "covid-19"], [126, "treatment"], [126, ","], [126, "but"], [126, "the"], [126, "result"], [126, "from"], [126, "prospective"], [126, "randomized"], [126, "trial"], [126, "be"], [126, "as"], [126, "yet"], [126, "await"], [126, "."], [127, "bioinformatic"], [127, "/"], [127, "drug"], [127, "repurpose"], [127, "study"], [127, "indicate"], [127, "that"], [127, ","], [127, "among"], [127, "several"], [127, "medicine"], [127, ","], [127, "h"], [127, "and"], [127, "h"], [127, "receptor"], [127, "antagonist"], [127, "may"], [127, "interact"], [127, "with"], [127, "key"], [127, "viral"], [127, "enzyme"], [127, "."], [128, "however"], [128, ","], [128, "in"], [128, "vitro"], [128, "study"], [128, "have"], [128, "to"], [128, "date"], [128, "fail"], [128, "to"], [128, "show"], [128, "a"], [128, "direct"], [128, "inhibition"], [128, "of"], [128, "famotidine"], [128, "on"], [128, "sars"], [128, "-"], [128, "cov-2"], [128, "replication"], [128, "."], [129, "clinical"], [129, "research"], [129, "into"], [129, "the"], [129, "potential"], [129, "benefit"], [129, "of"], [129, "h"], [129, "receptor"], [129, "antagonist"], [129, "in"], [129, "manage"], [129, "covid-19"], [129, "inflammation"], [129, "begin"], [129, "from"], [129, "a"], [129, "simple"], [129, "observation"], [129, "and"], [129, "now"], [129, "be"], [129, "be"], [129, "test"], [129, "in"], [129, "multi"], [129, "-"], [129, "centre"], [129, "clinical"], [129, "trial"], [129, "."], [130, "the"], [130, "positive"], [130, "effect"], [130, "of"], [130, "famotidine"], [130, "may"], [130, "be"], [130, "due"], [130, "to"], [130, "h"], [130, "receptor"], [130, "-"], [130, "mediate"], [130, "immunomodulatory"], [130, "action"], [130, "on"], [130, "mast"], [130, "cell"], [130, "histamine"], [130, "-"], [130, "cytokine"], [130, "cross"], [130, "-"], [130, "talk"], [130, ","], [130, "rather"], [130, "than"], [130, "a"], [130, "direct"], [130, "action"], [130, "on"], [130, "sars"], [130, "-"], [130, "cov-2"], [130, "."], [131, "a"], [131, "fast"], [131, "and"], [131, "accurate"], [131, "self"], [131, "-"], [131, "test"], [131, "tool"], [131, "for"], [131, "covid-19"], [131, "diagnosis"], [131, "have"], [131, "become"], [131, "a"], [131, "prerequisite"], [131, "to"], [131, "comprehend"], [131, "the"], [131, "exact"], [131, "number"], [131, "of"], [131, "case"], [131, "worldwide"], [131, "and"], [131, "to"], [131, "take"], [131, "medical"], [131, "and"], [131, "governmental"], [131, "action"], [131, "accordingly"], [131, "."], [132, "sars"], [132, "-"], [132, "cov-2"], [132, "("], [132, "formerly"], [132, ","], [132, "2019"], [132, "-"], [132, "ncov"], [132, ")"], [132, "infection"], [132, "be"], [132, "first"], [132, "report"], [132, "in"], [132, "wuhan"], [132, "("], [132, "china"], [132, ")"], [132, "in"], [132, "december"], [132, "2019"], [132, ","], [133, "and"], [133, "then"], [133, "it"], [133, "have"], [133, "rapidly"], [133, "spread"], [133, "around"], [133, "the"], [133, "world"], [133, ","], [133, "cause"], [133, "14"], [133, "million"], [133, "active"], [133, "case"], [133, "with"], [133, "582,000"], [133, "death"], [133, "as"], [133, "of"], [133, "july"], [133, "2020"], [133, "."], [134, "the"], [134, "diagnosis"], [134, "tool"], [134, "available"], [134, "so"], [134, "far"], [134, "have"], [134, "be"], [134, "base"], [134, "on"], [134, "a"], [134, ")"], [134, "viral"], [134, "gene"], [134, "detection"], [134, ","], [134, "b"], [134, ")"], [134, "human"], [134, "antibody"], [134, "detection"], [134, ","], [134, "and"], [134, "c"], [134, ")"], [134, "viral"], [134, "antigen"], [134, "detection"], [134, ","], [134, "among"], [134, "which"], [134, "the"], [134, "viral"], [134, "gene"], [134, "detection"], [134, "by"], [134, "rt"], [134, "-"], [134, "pcr"], [134, "have"], [134, "be"], [134, "find"], [134, "as"], [134, "the"], [134, "most"], [134, "reliable"], [134, "technique"], [134, "."], [135, "in"], [135, "this"], [135, "report"], [135, ","], [135, "the"], [135, "current"], [135, "sars"], [135, "-"], [135, "cov-2"], [135, "detection"], [135, "kit"], [135, ","], [135, "exclusively"], [135, "the"], [135, "one"], [135, "that"], [135, "be"], [135, "issue"], [135, "an"], [135, '"'], [135, "emergency"], [135, "use"], [135, "authorization"], [135, '"'], [135, "from"], [135, "the"], [135, "u.s"], [135, "."], [135, "food"], [135, "and"], [135, "drug"], [135, "administration"], [135, ","], [135, "be"], [135, "discuss"], [135, "."], [136, "the"], [136, "key"], [136, "structural"], [136, "component"], [136, "of"], [136, "the"], [136, "virus"], [136, "be"], [136, "present"], [136, "to"], [136, "provide"], [136, "the"], [136, "audience"], [136, "with"], [136, "an"], [136, "understanding"], [136, "of"], [136, "the"], [136, "scientific"], [136, "principle"], [136, "behind"], [136, "the"], [136, "testing"], [136, "tool"], [136, "."], [137, "the"], [137, "method"], [137, "that"], [137, "be"], [137, "still"], [137, "in"], [137, "the"], [137, "early"], [137, "research"], [137, "state"], [137, "be"], [137, "also"], [137, "review"], [137, "in"], [137, "a"], [137, "subsection"], [137, "base"], [137, "on"], [137, "the"], [137, "report"], [137, "available"], [137, "so"], [137, "far"], [137, "."], [138, "at"], [138, "the"], [138, "end"], [138, "of"], [138, "december"], [138, "2019"], [138, ","], [138, "a"], [138, "novel"], [138, "coronavirus"], [138, "tentatively"], [138, "name"], [138, "sars"], [138, "-"], [138, "cov-2"], [138, "in"], [138, "wuhan"], [138, ","], [138, "a"], [138, "central"], [138, "city"], [138, "in"], [138, "china"], [138, ","], [138, "be"], [138, "announce"], [138, "by"], [138, "the"], [138, "world"], [138, "health"], [138, "organization"], [138, "."], [139, "sars"], [139, "-"], [139, "cov-2"], [139, "be"], [139, "an"], [139, "rna"], [139, "virus"], [139, "that"], [139, "have"], [139, "become"], [139, "a"], [139, "major"], [139, "public"], [139, "health"], [139, "concern"], [139, "after"], [139, "the"], [139, "outbreak"], [139, "of"], [139, "the"], [139, "middle"], [139, "east"], [139, "respiratory"], [139, "syndrome"], [139, "-"], [139, "cov"], [139, "("], [139, "mer"], [139, "-"], [139, "cov"], [139, ")"], [139, "and"], [139, "severe"], [139, "acute"], [139, "respiratory"], [139, "syndrome"], [139, "-"], [139, "cov"], [139, "("], [139, "sars"], [139, "-"], [139, "cov"], [139, ")"], [139, "in"], [139, "2002"], [139, "and"], [139, "2012"], [139, ","], [139, "respectively"], [139, "."], [140, "as"], [140, "of"], [140, "29"], [140, "october"], [140, "2020"], [140, ","], [140, "the"], [140, "total"], [140, "number"], [140, "of"], [140, "covid-19"], [140, "case"], [140, "have"], [140, "reach"], [140, "over"], [140, "44"], [140, "million"], [140, "worldwide"], [140, ","], [140, "with"], [140, "more"], [140, "than"], [140, "1.17"], [140, "million"], [140, "confirm"], [140, "death"], [140, "."], [141, "sars"], [141, "-"], [141, "cov-2"], [141, "infect"], [141, "patient"], [141, "usually"], [141, "present"], [141, "with"], [141, "severe"], [141, "viral"], [141, "pneumonia"], [141, "."], [142, "similar"], [142, "to"], [142, "sars"], [142, "-"], [142, "cov"], [142, ","], [142, "the"], [142, "virus"], [142, "enter"], [142, "respiratory"], [142, "tract"], [142, "cell"], [142, "via"], [142, "the"], [142, "angiotensin"], [142, "-"], [142, "convert"], [142, "enzyme"], [142, "receptor"], [142, "2"], [142, "."], [143, "the"], [143, "structural"], [143, "protein"], [143, "play"], [143, "an"], [143, "essential"], [143, "role"], [143, "in"], [143, "bud"], [143, "the"], [143, "virus"], [143, "particle"], [143, "release"], [143, "from"], [143, "different"], [143, "host"], [143, "cell"], [143, "."], [144, "to"], [144, "date"], [144, ","], [144, "an"], [144, "approve"], [144, "vaccine"], [144, "or"], [144, "treatment"], [144, "option"], [144, "of"], [144, "a"], [144, "preventive"], [144, "character"], [144, "to"], [144, "avoid"], [144, "severe"], [144, "course"], [144, "of"], [144, "covid-19"], [144, "be"], [144, "still"], [144, "not"], [144, "available"], [144, "."], [145, "in"], [145, "the"], [145, "present"], [145, "study"], [145, ","], [145, "we"], [145, "provide"], [145, "a"], [145, "brief"], [145, "review"], [145, "of"], [145, "the"], [145, "general"], [145, "biological"], [145, "feature"], [145, "of"], [145, "covs"], [145, "and"], [145, "explain"], [145, "the"], [145, "pathogenesis"], [145, ","], [145, "clinical"], [145, "symptom"], [145, "and"], [145, "diagnostic"], [145, "approach"], [145, "regard"], [145, "monitor"], [145, "future"], [145, "infectivity"], [145, "and"], [145, "prevent"], [145, "emerge"], [145, "covid-19"], [145, "infection"], [145, "."], [146, "severe"], [146, "acute"], [146, "respiratory"], [146, "syndrome"], [146, "coronavirus"], [146, "2"], [146, "("], [146, "sars"], [146, "-"], [146, "cov-2"], [146, ")"], [146, "be"], [146, "a"], [146, "highly"], [146, "transmissible"], [146, "and"], [146, "pathogenic"], [146, "coronavirus"], [146, "that"], [146, "emerge"], [146, "in"], [146, "late"], [146, "2019"], [146, "and"], [146, "have"], [146, "cause"], [146, "a"], [146, "pandemic"], [146, "of"], [146, "acute"], [146, "respiratory"], [146, "disease"], [146, ","], [146, "name"], [146, "'"], [146, "coronavirus"], [146, "disease"], [146, "2019"], [146, "'"], [146, "("], [146, "covid-19"], [146, ")"], [146, ","], [146, "which"], [146, "threaten"], [146, "human"], [146, "health"], [146, "and"], [146, "public"], [146, "safety"], [146, "."], [147, "in"], [147, "this"], [147, "review"], [147, ","], [147, "we"], [147, "describe"], [147, "the"], [147, "basic"], [147, "virology"], [147, "of"], [147, "sars"], [147, "-"], [147, "cov-2"], [147, ","], [147, "include"], [147, "genomic"], [147, "characteristic"], [147, "and"], [147, "receptor"], [147, "use"], [147, ","], [147, "highlight"], [147, "its"], [147, "key"], [147, "difference"], [147, "from"], [147, "previously"], [147, "know"], [147, "coronaviruse"], [147, "."], [148, "we"], [148, "summarize"], [148, "current"], [148, "knowledge"], [148, "of"], [148, "clinical"], [148, ","], [148, "epidemiological"], [148, "and"], [148, "pathological"], [148, "feature"], [148, "of"], [148, "covid-19"], [148, ","], [148, "as"], [148, "well"], [148, "as"], [148, "recent"], [148, "progress"], [148, "in"], [148, "animal"], [148, "model"], [148, "and"], [148, "antiviral"], [148, "treatment"], [148, "approach"], [148, "for"], [148, "sars"], [148, "-"], [148, "cov-2"], [148, "infection"], [148, "."], [149, "we"], [149, "also"], [149, "discuss"], [149, "the"], [149, "potential"], [149, "wildlife"], [149, "host"], [149, "and"], [149, "zoonotic"], [149, "origin"], [149, "of"], [149, "this"], [149, "emerge"], [149, "virus"], [149, "in"], [149, "detail"], [149, "."], [150, "coronavirus"], [150, "disease"], [150, "2019"], [150, "("], [150, "covid-19"], [150, ")"], [150, "have"], [150, "the"], [150, "characteristic"], [150, "of"], [150, "high"], [150, "transmission"], [150, ","], [150, "diverse"], [150, "clinical"], [150, "manifestation"], [150, ","], [150, "and"], [150, "a"], [150, "long"], [150, "incubation"], [150, "period"], [150, "."], [151, "in"], [151, "addition"], [151, "to"], [151, "infect"], [151, "the"], [151, "respiratory"], [151, "system"], [151, ","], [151, "covid-19"], [151, "also"], [151, "have"], [151, "adverse"], [151, "effect"], [151, "on"], [151, "the"], [151, "cardiovascular"], [151, "system"], [151, "."], [152, "covid-19"], [152, "cause"], [152, "acute"], [152, "myocardial"], [152, "injury"], [152, ","], [152, "as"], [152, "well"], [152, "as"], [152, "chronic"], [152, "damage"], [152, "to"], [152, "the"], [152, "cardiovascular"], [152, "system"], [152, "."], [153, "the"], [153, "present"], [153, "review"], [153, "be"], [153, "aim"], [153, "at"], [153, "provide"], [153, "current"], [153, "information"], [153, "on"], [153, "covid-19"], [153, "and"], [153, "the"], [153, "cardiovascular"], [153, "system"], [153, "."], [154, "pubme"], [154, ","], [154, "scopus"], [154, ","], [154, "science"], [154, "direct"], [154, ","], [154, "and"], [154, "google"], [154, "scholar"], [154, "be"], [154, "search"], [154, "."], [155, "it"], [155, "be"], [155, "suggest"], [155, "that"], [155, "heart"], [155, "injury"], [155, "cause"], [155, "by"], [155, "covid-19"], [155, "infection"], [155, "might"], [155, "be"], [155, "an"], [155, "important"], [155, "cause"], [155, "of"], [155, "severe"], [155, "clinical"], [155, "phenotype"], [155, "or"], [155, "adverse"], [155, "event"], [155, "in"], [155, "affect"], [155, "patient"], [155, "."], [156, "myocardial"], [156, "damage"], [156, "be"], [156, "closely"], [156, "relate"], [156, "to"], [156, "the"], [156, "severity"], [156, "of"], [156, "the"], [156, "disease"], [156, "and"], [156, "even"], [156, "the"], [156, "prognosis"], [156, "in"], [156, "patient"], [156, "with"], [156, "covid-19"], [156, "."], [157, "in"], [157, "addition"], [157, "to"], [157, "disorder"], [157, "that"], [157, "be"], [157, "cause"], [157, "by"], [157, "covid-19"], [157, "on"], [157, "the"], [157, "cardiovascular"], [157, "system"], [157, ","], [157, "more"], [157, "protection"], [157, "should"], [157, "be"], [157, "employ"], [157, "for"], [157, "patient"], [157, "with"], [157, "preexist"], [157, "cardiovascular"], [157, "disease"], [157, "("], [157, "cvd"], [157, ")"], [157, "."], [158, "hence"], [158, ","], [158, "it"], [158, "be"], [158, "very"], [158, "important"], [158, "that"], [158, "once"], [158, "relevant"], [158, "symptom"], [158, "appear"], [158, ","], [158, "patient"], [158, "with"], [158, "covid-19"], [158, "be"], [158, "rapidly"], [158, "treat"], [158, "to"], [158, "reduce"], [158, "mortality"], [158, "."], [159, "thus"], [159, ","], [159, "early"], [159, "measurement"], [159, "of"], [159, "cardiac"], [159, "damage"], [159, " "], [159, "biomarker"], [159, "follow"], [159, "hospitalization"], [159, "for"], [159, "covid-19"], [159, "infection"], [159, "in"], [159, "a"], [159, "patient"], [159, "with"], [159, "preexist"], [159, "cvd"], [159, "be"], [159, "recommend"], [159, ","], [159, "together"], [159, "with"], [159, "careful"], [159, "monitoring"], [159, "of"], [159, "any"], [159, "myocardial"], [159, "injury"], [159, "that"], [159, "might"], [159, "be"], [159, "cause"], [159, "by"], [159, "the"], [159, "infection"], [159, "."], [160, ":"], [160, ":"], [160, "an"], [160, "intensive"], [160, "care"], [160, "unit"], [160, ";"], [160, ":"], [160, "2019"], [160, "novel"], [160, "coronavirus"], [160, ";"], [160, ":"], [160, "ace"], [160, "inhibitor"], [160, ";"], [160, ":"], [160, "acute"], [160, "coronary"], [160, "syndrome"], [160, ";"], [160, ":"], [160, "acute"], [160, "respiratory"], [160, "distress"], [160, "syndrome"], [160, ";"], [160, ":"], [160, "ang"], [160, "ii"], [160, "type"], [160, "1"], [160, "receptor"], [160, ";"], [160, ":"], [160, "adenosine"], [160, "triphosphate"], [160, ";"], [160, ":"], [160, "american"], [160, "college"], [160, "of"], [160, "cardiology"], [160, ";"], [160, ":"], [160, "angiotensin"], [160, "convert"], [160, "enzyme"], [160, ";"], [160, ":"], [160, "angiotensin"], [160, "ii"], [160, ";"], [160, ":"], [160, "angiotensin"], [160, "ii"], [160, "receptor"], [160, "blocker"], [160, ";"], [160, ":"], [160, "atrioventricular"], [160, "block"], [160, ";"], [160, ":"], [160, "coronary"], [160, "artery"], [160, "disease"], [160, ";"], [160, ":"], [160, "cardiovascular"], [160, "disease"], [160, ";"], [160, ":"], [160, "computerized"], [160, "tomography"], [160, ";"], [160, ":"], [160, "congestive"], [160, "heart"], [160, "failure"], [160, ";"], [160, ":"], [160, "coronary"], [160, "heart"], [160, "disease"], [160, ";"], [160, ":"], [161, "creatine"], [161, "kinase"], [161, "isoenzyme"], [161, "-"], [161, "mb"], [161, ";"], [161, ":"], [161, "c"], [161, "-"], [161, "reactive"], [161, "protein"], [161, ";"], [161, ":"], [161, "cardiac"], [161, "troponin"], [161, "i"], [161, ";"], [161, ":"], [161, "epicardial"], [161, "adipose"], [161, "tissue"], [161, ";"], [161, ":"], [161, "extracorporeal"], [161, "membrane"], [161, "oxygenation"], [161, ";"], [161, ":"], [161, "food"], [161, "and"], [161, "drug"], [161, "administration"], [161, ";"], [161, ":"], [161, "granulocyte"], [161, "colony"], [161, "-"], [161, "stimulate"], [161, "factor"], [161, ";"], [161, ":"], [161, "hf"], [161, "with"], [161, "a"], [161, "reduce"], [161, "ejection"], [161, "fraction"], [161, ";"], [161, ":"], [161, "human"], [161, "isoform"], [161, "of"], [161, "ace2"], [161, ";"], [161, ":"], [161, "interleukin"], [161, ";"], [161, ":"], [161, "intra"], [161, "-"], [161, "aortic"], [161, "balloon"], [161, "counterpulsation"], [161, ";"], [161, ":"], [161, "interferon"], [161, "\u03B3"], [161, "-"], [161, "induce"], [161, "protein"], [161, "10"], [161, "kda"], [161, ";"], [161, ":"], [161, "lysophosphatidylcholine"], [161, ";"], [161, ":"], [161, "mitochondrial"], [161, "assembly"], [161, "receptor"], [161, ";"], [161, ":"], [161, "monocyte"], [161, "chemoattractant"], [161, "protein-1"], [161, ";"], [161, ":"], [161, "middle"], [161, "east"], [161, "respiratory"], [161, "syndrome"], [161, ";"], [161, ":"], [161, "macrophage"], [161, "inflammatory"], [161, "protein"], [161, "1a"], [161, ":"], [161, ":"], [161, "multiple"], [161, "organ"], [161, "failure"], [161, ";"], [161, ":"], [161, "myocardial"], [161, "infarction"], [161, ";"], [161, ":"], [161, "magnetic"], [161, "resonance"], [161, "imaging"], [161, ";"], [161, ":"], [161, "myohe"], [161, "-"], [161, "moglobin"], [161, ";"], [161, ":"], [161, "n"], [161, "-"], [161, "terminal"], [161, "pro"], [161, "-"], [161, "brain"], [161, "natriuretic"], [161, "peptide"], [161, ";"], [161, ":"], [161, "percutaneous"], [161, "cardiopulmonary"], [161, "assistance"], [161, ";"], [161, ":"], [161, "recombinant"], [161, "human"], [161, "ace2"], [161, ";"], [161, ":"], [161, "severe"], [161, "acute"], [161, "respiratory"], [161, "syndrome"], [161, ";"], [161, ":"], [161, "t"], [161, "helper"], [161, ";"], [161, ":"], [161, "renin"], [161, "-"], [161, "angiotensin"], [161, "system"], [161, ";"], [161, ":"], [161, "tumor"], [161, "necrosis"], [161, "factor"], [161, "-"], [161, "\u03B1"], [161, ";"], [161, ":"], [161, "world"], [161, "health"], [161, "organization"], [161, "."], [162, "with"], [162, "the"], [162, "emergence"], [162, "of"], [162, "covid-19"], [162, "extensive"], [162, "research"], [162, "begin"], [162, "to"], [162, "identify"], [162, "medication"], [162, ","], [162, "candidate"], [162, "compound"], [162, "and"], [162, "other"], [162, "therapeutic"], [162, "approach"], [162, "."], [163, "the"], [163, "complex"], [163, "virology"], [163, "of"], [163, "covid-19"], [163, "may"], [163, "provide"], [163, "multiple"], [163, "potential"], [163, "target"], [163, "point"], [163, "for"], [163, "antiviral"], [163, "therapy"], [163, ","], [163, "and"], [163, "vaccine"], [163, ";"], [163, "extensive"], [163, "global"], [163, "research"], [163, "be"], [163, "underway"], [163, "to"], [163, "exploit"], [163, "these"], [163, "potential"], [163, "opportunity"], [163, "."], [164, "the"], [164, "complex"], [164, "pathophysiology"], [164, ","], [164, "pulmonary"], [164, "and"], [164, "extrapulmonary"], [164, "disease"], [164, ","], [164, "and"], [164, "immune"], [164, "mediate"], [164, "effect"], [164, "such"], [164, "as"], [164, "cytokine"], [164, "storm"], [164, ","], [164, "make"], [164, "medical"], [164, "management"], [164, "more"], [164, "challenging"], [164, "than"], [164, "many"], [164, "viral"], [164, "illness"], [164, "."], [165, "non"], [165, "medication"], [165, "base"], [165, "intervention"], [165, "include"], [165, "hyperbaric"], [165, "oxygen"], [165, "("], [165, "hbot"], [165, ")"], [165, ","], [165, "extracorporeal"], [165, "membrane"], [165, "oxygenation"], [165, "("], [165, "ecmo"], [165, ")"], [165, ","], [165, "aggressive"], [165, "dialysis"], [165, ","], [165, "and"], [165, "other"], [165, "intervention"], [165, ","], [165, "all"], [165, "with"], [165, "various"], [165, "degree"], [165, "of"], [165, "clinical"], [165, "success"], [165, ","], [165, "and"], [165, "will"], [165, "be"], [165, "discuss"], [165, "in"], [165, "this"], [165, "section"], [165, "."], [166, "several"], [166, "antiviral"], [166, "approve"], [166, "for"], [166, "other"], [166, "clinical"], [166, "indication"], [166, "be"], [166, "study"], [166, "for"], [166, "repurpose"], [166, "against"], [166, "covid-19"], [166, ","], [166, "which"], [166, "we"], [166, "highlight"], [166, ","], [166, "again"], [166, "with"], [166, "vary"], [166, "result"], [166, "."], [167, "in"], [167, "addition"], [167, "to"], [167, "therapeutic"], [167, ","], [167, "concern"], [167, "be"], [167, "raise"], [167, "over"], [167, "potential"], [167, "risk"], [167, "associate"], [167, "with"], [167, "ace"], [167, "inhibitor"], [167, "and"], [167, "arb"], [167, "use"], [167, ","], [167, "which"], [167, "be"], [167, "present"], [167, "."], [168, "often"], [168, "the"], [168, "timing"], [168, "of"], [168, "the"], [168, "medication"], [168, "determine"], [168, "its"], [168, "clinical"], [168, "benefit"], [168, "as"], [168, "will"], [168, "be"], [168, "discuss"], [168, "with"], [168, "dexamethasone"], [168, "and"], [168, "other"], [168, "medication"], [168, "."], [169, "as"], [169, "such"], [169, ","], [169, "this"], [169, "therapeutic"], [169, "review"], [169, "will"], [169, "present"], [169, "prominent"], [169, "and/or"], [169, "promise"], [169, "medication"], [169, "and"], [169, "therapeutic"], [169, "approach"], [169, "with"], [169, "the"], [169, "caveat"], [169, "that"], [169, "1"], [169, "."], [170, "to"], [170, "date"], [170, ","], [170, "none"], [170, "be"], [170, "fda"], [170, "approve"], [170, "beyond"], [170, "emergency"], [170, "use"], [170, "authorization"], [170, "("], [170, "eua"], [170, ")"], [170, ","], [170, "and"], [170, "2"], [170, "."], [171, "although"], [171, "a"], [171, "comprehensive"], [171, "look"], [171, "at"], [171, "various"], [171, "class"], [171, "of"], [171, "intervention"], [171, ","], [171, "it"], [171, "be"], [171, "by"], [171, "no"], [171, "mean"], [171, "a"], [171, "complete"], [171, "list"], [171, "of"], [171, "every"], [171, "compound"], [171, "triale"], [171, "against"], [171, "covid-19"], [171, "."], [172, "recognize"], [172, "the"], [172, "knowledge"], [172, "basis"], [172, "upon"], [172, "which"], [172, "we"], [172, "treat"], [172, "covid-19"], [172, "patient"], [172, ","], [172, "develop"], [172, "therapeutic"], [172, ","], [172, "and"], [172, "vaccine"], [172, "continue"], [172, "to"], [172, "evolve"], [172, "as"], [172, "new"], [172, "information"], [172, "be"], [172, "present"], [172, ","], [172, "every"], [172, "effort"], [172, "nevertheless"], [172, "have"], [172, "be"], [172, "make"], [172, "to"], [172, "provide"], [172, "as"], [172, "timely"], [172, "information"], [172, "as"], [172, "possible"], [172, "."], [173, "it"], [173, "be"], [173, "hope"], [173, "that"], [173, "the"], [173, "information"], [173, "share"], [173, "can"], [173, "help"], [173, "guide"], [173, "the"], [173, "clinician"], [173, "in"], [173, "term"], [173, "of"], [173, "potential"], [173, "option"], [173, "to"], [173, "treat"], [173, "this"], [173, "complex"], [173, "group"], [173, "of"], [173, "patient"], [173, "."], [174, "coronavirus"], [174, "disease"], [174, "2019"], [174, "("], [174, "covid-19"], [174, ")"], [174, "infection"], [174, "which"], [174, "be"], [174, "cause"], [174, "by"], [174, "severe"], [174, "acute"], [174, "respiratory"], [174, "syndrome"], [174, "coronavirus-2"], [174, "("], [174, "sars"], [174, "-"], [174, "cov-2"], [174, ")"], [174, "have"], [174, "lead"], [174, "to"], [174, "a"], [174, '"'], [174, "public"], [174, "health"], [174, "emergency"], [174, "of"], [174, "international"], [174, "concern"], [174, '"'], [174, "("], [174, "pheic"], [174, ")"], [174, "."], [175, "the"], [175, "infection"], [175, "be"], [175, "highly"], [175, "contagious"], [175, ","], [175, "have"], [175, "a"], [175, "high"], [175, "mortality"], [175, "rate"], [175, ","], [175, "and"], [175, "its"], [175, "pathophysiology"], [175, "remain"], [175, "poorly"], [175, "understand"], [175, "."], [176, "pulmonary"], [176, "inflammation"], [176, "with"], [176, "substantial"], [176, "lung"], [176, "damage"], [176, "together"], [176, "with"], [176, "generalize"], [176, "immune"], [176, "dysregulation"], [176, "be"], [176, "major"], [176, "component"], [176, "of"], [176, "covid-19"], [176, "pathogenesis"], [176, "."], [177, "the"], [177, "former"], [177, "component"], [177, ","], [177, "lung"], [177, "damage"], [177, ","], [177, "seem"], [177, "to"], [177, "be"], [177, "at"], [177, "least"], [177, "in"], [177, "part"], [177, "a"], [177, "consequence"], [177, "of"], [177, "immune"], [177, "dysregulation"], [177, "."], [178, "indeed"], [178, ","], [178, "study"], [178, "have"], [178, "reveal"], [178, "that"], [178, "immune"], [178, "alteration"], [178, "be"], [178, "not"], [178, "merely"], [178, "an"], [178, "association"], [178, ","], [178, "as"], [178, "it"], [178, "might"], [178, "occur"], [178, "in"], [178, "systemic"], [178, "infection"], [178, ","], [178, "but"], [178, ","], [178, "very"], [178, "likely"], [178, ","], [178, "the"], [178, "core"], [178, "pathogenic"], [178, "element"], [178, "of"], [178, "covid-19"], [178, "."], [179, "in"], [179, "addition"], [179, ","], [179, "precise"], [179, "management"], [179, "of"], [179, "immune"], [179, "response"], [179, "in"], [179, "covid-19"], [179, ","], [179, "i.e."], [179, "enhance"], [179, "anti"], [179, "-"], [179, "viral"], [179, "immunity"], [179, "while"], [179, "inhibit"], [179, "systemic"], [179, "inflammation"], [179, ","], [179, "may"], [179, "be"], [179, "key"], [179, "to"], [179, "successful"], [179, "treatment"], [179, "."], [180, "herein"], [180, ","], [180, "we"], [180, "have"], [180, "review"], [180, "current"], [180, "evidence"], [180, "relate"], [180, "to"], [180, "different"], [180, "aspect"], [180, "of"], [180, "covid-19"], [180, "immunology"], [180, ","], [180, "include"], [180, "innate"], [180, "and"], [180, "adaptive"], [180, "immune"], [180, "response"], [180, "against"], [180, "the"], [180, "virus"], [180, "and"], [180, "mechanism"], [180, "of"], [180, "virus"], [180, "-"], [180, "induce"], [180, "immune"], [180, "dysregulation"], [180, "."], [181, "consider"], [181, "that"], [181, "current"], [181, "antiviral"], [181, "therapy"], [181, "be"], [181, "chiefly"], [181, "experimental"], [181, ","], [181, "strategy"], [181, "to"], [181, "do"], [181, "immunotherapy"], [181, "for"], [181, "the"], [181, "management"], [181, "of"], [181, "disease"], [181, "have"], [181, "also"], [181, "be"], [181, "review"], [181, "."], [182, "understand"], [182, "immunology"], [182, "of"], [182, "covid-19"], [182, "be"], [182, "important"], [182, "in"], [182, "develop"], [182, "effective"], [182, "therapy"], [182, "as"], [182, "well"], [182, "as"], [182, "diagnostic"], [182, ","], [182, "and"], [182, "prophylactic"], [182, "strategy"], [182, "for"], [182, "this"], [182, "disease"], [182, "."], [183, "sars"], [183, "-"], [183, "cov-2"], [183, "be"], [183, "a"], [183, "novel"], [183, "virus"], [183, "that"], [183, "cause"], [183, "coronavirus"], [183, "disease-19"], [183, "("], [183, "covid-19"], [183, ")"], [183, "."], [184, "antiviral"], [184, "and"], [184, "immunomodulatory"], [184, "agent"], [184, "have"], [184, "be"], [184, "propose"], [184, "as"], [184, "potential"], [184, "treatment"], [184, "."], [185, "azithromycin"], [185, "exhibit"], [185, "both"], [185, "property"], [185, "and"], [185, "therefore"], [185, "may"], [185, "play"], [185, "a"], [185, "role"], [185, "."], [186, "this"], [186, "article"], [186, "review"], [186, "the"], [186, "pharmacology"], [186, ","], [186, "pharmacokinetic"], [186, ","], [186, "clinical"], [186, "efficacy"], [186, ","], [186, "and"], [186, "safety"], [186, "of"], [186, "azithromycin"], [186, "in"], [186, "viral"], [186, "infection"], [186, ","], [186, "with"], [186, "emphasis"], [186, "on"], [186, "covid-19"], [186, "."], [187, "a"], [187, "literature"], [187, "search"], [187, "of"], [187, "pubmed"], [187, "be"], [187, "conduct"], [187, "on"], [187, "may"], [187, "30"], [187, "and"], [187, "update"], [187, "on"], [187, "july"], [187, "28"], [187, "."], [188, "azithromycin"], [188, "present"], [188, " "], [188, "activity"], [188, "against"], [188, "sars"], [188, "-"], [188, "cov-2"], [188, "and"], [188, "could"], [188, "act"], [188, "in"], [188, "different"], [188, "point"], [188, "of"], [188, "the"], [188, "viral"], [188, "cycle"], [188, "."], [189, "its"], [189, "immunomodulatory"], [189, "property"], [189, "include"], [189, "the"], [189, "ability"], [189, "to"], [189, "downregulate"], [189, "cytokine"], [189, "production"], [189, ","], [189, "maintain"], [189, "epithelial"], [189, "cell"], [189, "integrity"], [189, "or"], [189, "prevent"], [189, "lung"], [189, "fibrosis"], [189, "."], [190, "azithromycin"], [190, "use"], [190, "be"], [190, "associate"], [190, "with"], [190, "a"], [190, "reduction"], [190, "in"], [190, "mortality"], [190, "and"], [190, "ventilation"], [190, "day"], [190, "in"], [190, "other"], [190, "viral"], [190, "infection"], [190, "."], [191, "these"], [191, "property"], [191, "could"], [191, "be"], [191, "beneficial"], [191, "throughout"], [191, "the"], [191, "covid-19"], [191, "."], [192, "however"], [192, ","], [192, "the"], [192, "evidence"], [192, "of"], [192, "its"], [192, "use"], [192, "be"], [192, "scarce"], [192, "and"], [192, "of"], [192, "low"], [192, "quality"], [192, "."], [193, "azithromycin"], [193, "have"], [193, "be"], [193, "assess"], [193, "in"], [193, "retrospective"], [193, "observational"], [193, "study"], [193, "mainly"], [193, "in"], [193, "combination"], [193, "with"], [193, "hydroxychloroquine"], [193, ","], [193, "which"], [193, "have"], [193, "show"], [193, "to"], [193, "provide"], [193, "no"], [193, "benefit"], [193, "."], [194, "this"], [194, "macrolide"], [194, "present"], [194, "a"], [194, "well"], [194, "-"], [194, "know"], [194, "safety"], [194, "profile"], [194, "."], [195, "upcoming"], [195, "clinical"], [195, "trial"], [195, "will"], [195, "determine"], [195, "the"], [195, "role"], [195, "of"], [195, "azithromycin"], [195, "in"], [195, "the"], [195, "covid-19"], [195, "("], [195, "include"], [195, "the"], [195, "stage"], [195, "of"], [195, "the"], [195, "disease"], [195, "where"], [195, "it"], [195, "offer"], [195, "the"], [195, "great"], [195, "benefit"], [195, "and"], [195, "the"], [195, "effect"], [195, "of"], [195, "its"], [195, "combination"], [195, "with"], [195, "other"], [195, "drug"], [195, ")"], [195, "."], [196, "covid-19"], [196, ","], [196, "cause"], [196, "by"], [196, "sars"], [196, "-"], [196, "cov-2"], [196, ","], [196, "emerge"], [196, "as"], [196, "the"], [196, "deadly"], [196, "outbreak"], [196, "that"], [196, "have"], [196, "now"], [196, "become"], [196, "a"], [196, "serious"], [196, "health"], [196, "issue"], [196, "to"], [196, "mankind"], [196, "."], [197, "activation"], [197, "of"], [197, "inflammatory"], [197, "signal"], [197, "pathway"], [197, "and"], [197, "cytokine"], [197, "storm"], [197, "be"], [197, "crucial"], [197, "factor"], [197, "that"], [197, "lead"], [197, "to"], [197, "acute"], [197, "respiratory"], [197, "distress"], [197, "syndrome"], [197, "("], [197, "ard"], [197, ")"], [197, "in"], [197, "covid-19"], [197, "patient"], [197, "."], [198, "excessive"], [198, "secretion"], [198, "of"], [198, "pro"], [198, "-"], [198, "inflammatory"], [198, "cytokine"], [198, "and"], [198, "chemokine"], [198, "lead"], [198, "to"], [198, "the"], [198, "dysregulation"], [198, "of"], [198, "the"], [198, "innate"], [198, "immune"], [198, "system"], [198, "."], [199, "the"], [199, "cytokine"], [199, "storm"], [199, "attract"], [199, "many"], [199, "inflammatory"], [199, "cell"], [199, "that"], [199, "infiltrate"], [199, "into"], [199, "the"], [199, "lung"], [199, "tissue"], [199, "and"], [199, "ultimately"], [199, "cause"], [199, "immune"], [199, "damage"], [199, "."], [200, "in"], [200, "addition"], [200, "to"], [200, "the"], [200, "dysregulation"], [200, "of"], [200, "the"], [200, "immune"], [200, "system"], [200, ","], [200, "dysfunction"], [200, "of"], [200, "the"], [200, "renin"], [200, "-"], [200, "angiotensin"], [200, "system"], [200, "("], [200, "ras"], [200, ")"], [200, "due"], [200, "to"], [200, "the"], [200, "downregulation"], [200, "of"], [200, "ace2"], [200, "be"], [200, "also"], [200, "associate"], [200, "with"], [200, "the"], [200, "mortality"], [200, "of"], [200, "covid-19"], [200, "patient"], [200, "."], [201, "both"], [201, "the"], [201, "mechanism"], [201, "be"], [201, "directly"], [201, "or"], [201, "indirectly"], [201, "associate"], [201, "with"], [201, "cytokine"], [201, "storm"], [201, "that"], [201, "promote"], [201, "vascular"], [201, "hyperpermeability"], [201, ","], [201, "vascular"], [201, "edema"], [201, "lead"], [201, "to"], [201, "hypercoagulation"], [201, "and"], [201, "hence"], [201, "multiorgan"], [201, "damage"], [201, "."], [202, "as"], [202, "of"], [202, "now"], [202, ","], [202, "there"], [202, "be"], [202, "no"], [202, "specific"], [202, "treatment"], [202, "available"], [202, "for"], [202, "covid-19"], [202, ","], [202, "but"], [202, "scientist"], [202, "have"], [202, "purpose"], [202, "several"], [202, "treatment"], [202, "option"], [202, "include"], [202, "cytokine"], [202, "inhibitor"], [202, ","], [202, "jak"], [202, "inhibitor"], [202, ","], [202, "immunomodulator"], [202, ","], [202, "plasma"], [202, "therapy"], [202, ","], [202, "etc"], [202, "."], [203, "in"], [203, "this"], [203, "article"], [203, ","], [203, "we"], [203, "have"], [203, "provide"], [203, "the"], [203, "detailed"], [203, "mechanism"], [203, "of"], [203, "occurrence"], [203, "of"], [203, "sars"], [203, "-"], [203, "cov-2"], [203, "induce"], [203, "inflammatory"], [203, "storm"], [203, "and"], [203, "its"], [203, "connection"], [203, "with"], [203, "the"], [203, "pre"], [203, "-"], [203, "exist"], [203, "inflammatory"], [203, "condition"], [203, "."], [204, "possible"], [204, "treatment"], [204, "option"], [204, "to"], [204, "cope"], [204, "up"], [204, "with"], [204, "the"], [204, "severe"], [204, "clinical"], [204, "manifestation"], [204, "of"], [204, "covid-19"], [204, "be"], [204, "also"], [204, "discuss"], [204, "."], [205, "currently"], [205, ","], [205, "the"], [205, "world"], [205, "be"], [205, "in"], [205, "the"], [205, "seventh"], [205, "month"], [205, "of"], [205, "the"], [205, "covid-19"], [205, "pandemic"], [205, "."], [206, "globally"], [206, ","], [206, "infection"], [206, "with"], [206, "novel"], [206, "sars"], [206, "-"], [206, "cov-2"], [206, "virus"], [206, "be"], [206, "continuously"], [206, "rise"], [206, "with"], [206, "mount"], [206, "number"], [206, "of"], [206, "death"], [206, "."], [207, "international"], [207, "and"], [207, "local"], [207, "public"], [207, "health"], [207, "response"], [207, ","], [207, "almost"], [207, "in"], [207, "synchrony"], [207, ","], [207, "impose"], [207, "restriction"], [207, "to"], [207, "minimize"], [207, "spread"], [207, "of"], [207, "the"], [207, "virus"], [207, ","], [207, "overload"], [207, "of"], [207, "health"], [207, "system"], [207, "capacity"], [207, ","], [207, "and"], [207, "deficit"], [207, "of"], [207, "personal"], [207, "protective"], [207, "equipment"], [207, "("], [207, "ppe"], [207, ")"], [207, "."], [208, "although"], [208, "in"], [208, "most"], [208, "case"], [208, "the"], [208, "symptom"], [208, "be"], [208, "mild"], [208, "or"], [208, "absent"], [208, ","], [208, "sars"], [208, "-"], [208, "cov-2"], [208, "infection"], [208, "can"], [208, "lead"], [208, "to"], [208, "serious"], [208, "acute"], [208, "respiratory"], [208, "disease"], [208, "and"], [208, "multisystem"], [208, "failure"], [208, "."], [209, "the"], [209, "research"], [209, "community"], [209, "respond"], [209, "to"], [209, "this"], [209, "new"], [209, "disease"], [209, "with"], [209, "a"], [209, "high"], [209, "level"], [209, "of"], [209, "transparency"], [209, "and"], [209, "datum"], [209, "sharing"], [209, ";"], [209, "with"], [209, "the"], [209, "aim"], [209, "to"], [209, "well"], [209, "understand"], [209, "the"], [209, "origin"], [209, ","], [209, "pathophysiology"], [209, ","], [209, "epidemiology"], [209, "and"], [209, "clinical"], [209, "manifestation"], [209, "."], [210, "the"], [210, "ultimate"], [210, "goal"], [210, "of"], [210, "this"], [210, "research"], [210, "be"], [210, "to"], [210, "develop"], [210, "vaccine"], [210, "for"], [210, "prevention"], [210, ","], [210, "mitigation"], [210, "strategy"], [210, ","], [210, "as"], [210, "well"], [210, "as"], [210, "potential"], [210, "therapeutic"], [210, "."], [211, "the"], [211, "aim"], [211, "of"], [211, "this"], [211, "review"], [211, "be"], [211, "to"], [211, "summarize"], [211, "current"], [211, "knowledge"], [211, "regard"], [211, "the"], [211, "novel"], [211, "sars"], [211, "cov-2"], [211, ","], [211, "include"], [211, "its"], [211, "pathophysiology"], [211, "and"], [211, "epidemiology"], [211, ","], [211, "as"], [211, "well"], [211, "as"], [211, ","], [211, "what"], [211, "be"], [211, "know"], [211, "about"], [211, "the"], [211, "potential"], [211, "impact"], [211, "of"], [211, "covid-19"], [211, "on"], [211, "reproduction"], [211, ","], [211, "fertility"], [211, "care"], [211, ","], [211, "pregnancy"], [211, "and"], [211, "neonatal"], [211, "outcome"], [211, "."], [212, "this"], [212, "summary"], [212, "also"], [212, "evaluate"], [212, "the"], [212, "effect"], [212, "of"], [212, "this"], [212, "pandemic"], [212, "on"], [212, "reproductive"], [212, "care"], [212, "and"], [212, "research"], [212, ","], [212, "from"], [212, "canadian"], [212, "perspective"], [212, ","], [212, "and"], [212, "discuss"], [212, "future"], [212, "implication"], [212, "."], [213, "in"], [213, "summary"], [213, ","], [213, "report"], [213, "datum"], [213, "on"], [213, "pregnant"], [213, "woman"], [213, "be"], [213, "limit"], [213, ","], [213, "suggest"], [213, "that"], [213, "covid-19"], [213, "symptom"], [213, "and"], [213, "severity"], [213, "of"], [213, "the"], [213, "disease"], [213, "during"], [213, "pregnancy"], [213, "be"], [213, "similar"], [213, "to"], [213, "those"], [213, "in"], [213, "non"], [213, "-"], [213, "pregnant"], [213, "woman"], [213, ","], [213, "with"], [213, "pregnancy"], [213, "outcome"], [213, "closely"], [213, "relate"], [213, "to"], [213, "severity"], [213, "of"], [213, "maternal"], [213, "disease"], [213, "."], [214, "evidence"], [214, "of"], [214, "sars"], [214, "-"], [214, "cov-2"], [214, "effect"], [214, "on"], [214, "gamete"], [214, "be"], [214, "limit"], [214, "."], [215, "human"], [215, "reproduction"], [215, "society"], [215, "have"], [215, "issue"], [215, "guideline"], [215, "for"], [215, "practice"], [215, "during"], [215, "covid-19"], [215, "pandemic"], [215, "that"], [215, "include"], [215, "implementation"], [215, "of"], [215, "mitigation"], [215, "practice"], [215, "and"], [215, "infection"], [215, "control"], [215, "protocol"], [215, "in"], [215, "fertility"], [215, "care"], [215, "unit"], [215, "."], [216, "in"], [216, "canada"], [216, ","], [216, "impose"], [216, "restriction"], [216, "at"], [216, "the"], [216, "beginning"], [216, "of"], [216, "the"], [216, "pandemic"], [216, "be"], [216, "successful"], [216, "in"], [216, "contain"], [216, "spread"], [216, "of"], [216, "the"], [216, "infection"], [216, ","], [216, "allow"], [216, "for"], [216, "eventual"], [216, "resumption"], [216, "of"], [216, "assist"], [216, "reproductive"], [216, "treatment"], [216, "under"], [216, "new"], [216, "guideline"], [216, "for"], [216, "practice"], [216, "."], [217, "canada"], [217, "dedicated"], [217, "fund"], [217, "to"], [217, "support"], [217, "covid-19"], [217, "research"], [217, "include"], [217, "a"], [217, "surveillance"], [217, "study"], [217, "to"], [217, "monitor"], [217, "outcome"], [217, "of"], [217, "covid-19"], [217, "during"], [217, "pregnancy"], [217, "and"], [217, "assist"], [217, "reproduction"], [217, "."], [218, "continuous"], [218, "evaluation"], [218, "of"], [218, "new"], [218, "evidence"], [218, "must"], [218, "be"], [218, "in"], [218, "place"], [218, "to"], [218, "carefully"], [218, "adjust"], [218, "recommendation"], [218, "on"], [218, "patient"], [218, "management"], [218, "during"], [218, "assist"], [218, "reproductive"], [218, "technology"], [218, "("], [218, "art"], [218, ")"], [218, "and"], [218, "in"], [218, "pregnancy"], [218, "."], [219, "the"], [219, "severe"], [219, "acute"], [219, "respiratory"], [219, "syndrome"], [219, "coronavirus"], [219, "("], [219, "sars"], [219, "-"], [219, "cov-2"], [219, ")"], [219, "that"], [219, "emerge"], [219, "in"], [219, "december"], [219, "2019"], [219, "as"], [219, "the"], [219, "causative"], [219, "agent"], [219, "of"], [219, "coronavirus"], [219, "2019"], [219, "("], [219, "covid-19"], [219, ")"], [219, "and"], [219, "be"], [219, "declare"], [219, "a"], [219, "pandemic"], [219, "by"], [219, "the"], [219, "world"], [219, "health"], [219, "organization"], [219, "in"], [219, "march"], [219, "2020"], [219, "have"], [219, "several"], [219, "distinctive"], [219, "feature"], [219, ","], [219, "include"], [219, "extensive"], [219, "multiorgan"], [219, "involvement"], [219, "with"], [219, "a"], [219, "robust"], [219, "systemic"], [219, "inflammatory"], [219, "response"], [219, ","], [219, "significant"], [219, "associate"], [219, "morbidity"], [219, "and"], [219, "mortality"], [219, ","], [219, "and"], [219, "prolong"], [219, "persistence"], [219, "of"], [219, "viral"], [219, "rna"], [219, "in"], [219, "the"], [219, "clinical"], [219, "speciman"], [219, "of"], [219, "infect"], [219, "individual"], [219, "as"], [219, "detect"], [219, "by"], [219, "reverse"], [219, "transcription"], [219, "polymerase"], [219, "chain"], [219, "reaction"], [219, "("], [219, "rt"], [219, "-"], [219, "pcr"], [219, ")"], [219, "amplification"], [219, "."], [220, "this"], [220, "review"], [220, "begin"], [220, "with"], [220, "an"], [220, "overview"], [220, "of"], [220, "sars"], [220, "-"], [220, "cov-2"], [220, "morphology"], [220, "and"], [220, "replication"], [220, "and"], [220, "summarize"], [220, "what"], [220, "be"], [220, "know"], [220, "to"], [220, "date"], [220, "about"], [220, "the"], [220, "detection"], [220, "of"], [220, "the"], [220, "virus"], [220, "in"], [220, "nasal"], [220, ","], [220, "oropharyngeal"], [220, ","], [220, "and"], [220, "fecal"], [220, "speciman"], [220, "of"], [220, "patient"], [220, "who"], [220, "have"], [220, "recover"], [220, "from"], [220, "covid-19"], [220, ","], [220, "with"], [220, "a"], [220, "focus"], [220, "on"], [220, "the"], [220, "factor"], [220, "think"], [220, "to"], [220, "contribute"], [220, "to"], [220, "prolong"], [220, "detection"], [220, "."], [221, "this"], [221, "review"], [221, "also"], [221, "provide"], [221, "a"], [221, "discussion"], [221, "on"], [221, "the"], [221, "infective"], [221, "potential"], [221, "of"], [221, "this"], [221, "material"], [221, "from"], [221, "asymptomatic"], [221, ","], [221, "pre"], [221, "-"], [221, "symptomatic"], [221, ","], [221, "and"], [221, "convalesce"], [221, "individual"], [221, ","], [221, "to"], [221, "include"], [221, "a"], [221, "discussion"], [221, "of"], [221, "the"], [221, "relative"], [221, "persistence"], [221, "and"], [221, "infectious"], [221, "potential"], [221, "of"], [221, "virus"], [221, "in"], [221, "clinical"], [221, "speciman"], [221, "recover"], [221, "from"], [221, "pediatric"], [221, "covid-19"], [221, "patient"], [221, "."], [222, "the"], [222, "sars"], [222, "-"], [222, "cov-2"], [222, "novel"], [222, "coronavirus"], [222, "have"], [222, "cause"], [222, "the"], [222, "covid-19"], [222, "pandemic"], [222, "with"], [222, "over"], [222, "35"], [222, "million"], [222, "case"], [222, "and"], [222, "over"], [222, "a"], [222, "million"], [222, "death"], [222, "worldwide"], [222, "as"], [222, "of"], [222, "early"], [222, "october"], [222, "2020"], [222, "."], [223, "the"], [223, "population"], [223, "most"], [223, "affect"], [223, "be"], [223, "the"], [223, "elderly"], [223, "and"], [223, "especially"], [223, "those"], [223, "with"], [223, "underlying"], [223, "comorbiditie"], [223, "."], [224, "in"], [224, "term"], [224, "of"], [224, "race"], [224, "and"], [224, "ethnicity"], [224, ","], [224, "black"], [224, "and"], [224, "hispanic"], [224, "population"], [224, "be"], [224, "affect"], [224, "at"], [224, "disproportionately"], [224, "high"], [224, "rate"], [224, "."], [225, "individual"], [225, "with"], [225, "underlie"], [225, "condition"], [225, "that"], [225, "cause"], [225, "an"], [225, "immune"], [225, "-"], [225, "compromise"], [225, "state"], [225, "be"], [225, "consider"], [225, "vulnerable"], [225, "to"], [225, "this"], [225, "infection"], [225, "."], [226, "the"], [226, "immune"], [226, "response"], [226, "be"], [226, "an"], [226, "important"], [226, "determinant"], [226, "in"], [226, "viral"], [226, "infection"], [226, "include"], [226, "coronaviruse"], [226, ","], [226, "not"], [226, "only"], [226, "in"], [226, "the"], [226, "antiviral"], [226, "defense"], [226, "but"], [226, "also"], [226, "in"], [226, "the"], [226, "disease"], [226, "progression"], [226, ","], [226, "severity"], [226, ","], [226, "and"], [226, "clinical"], [226, "outcome"], [226, "of"], [226, "covid-19"], [226, "."], [227, "systemic"], [227, "lupus"], [227, "erythematosus"], [227, "be"], [227, "a"], [227, "chronic"], [227, "autoimmune"], [227, "disease"], [227, "which"], [227, "also"], [227, "disproportionately"], [227, "afflict"], [227, "black"], [227, "and"], [227, "hispanic"], [227, "population"], [227, "."], [228, "in"], [228, "lupus"], [228, "patient"], [228, ","], [228, "an"], [228, "aberrant"], [228, "immune"], [228, "response"], [228, "be"], [228, "characterize"], [228, "by"], [228, "the"], [228, "presence"], [228, "of"], [228, "circulate"], [228, "autoantibody"], [228, ","], [228, "lymphopenia"], [228, ","], [228, "aberrant"], [228, "t"], [228, "cell"], [228, ","], [228, "and"], [228, "proinflammatory"], [228, "cytokine"], [228, "along"], [228, "with"], [228, "defective"], [228, "regulatory"], [228, "mechanism"], [228, ","], [228, "lead"], [228, "to"], [228, "immune"], [228, "-"], [228, "mediate"], [228, "damage"], [228, "to"], [228, "tissue"], [228, "."], [229, "lupus"], [229, "patient"], [229, "be"], [229, "often"], [229, "treat"], [229, "with"], [229, "immune"], [229, "-"], [229, "suppressant"], [229, "and"], [229, "therefore"], [229, "be"], [229, "immune"], [229, "-"], [229, "compromise"], [229, "and"], [229, "more"], [229, "susceptible"], [229, "to"], [229, "infection"], [229, "and"], [229, "may"], [229, "be"], [229, "vulnerable"], [229, "to"], [229, "coronavirus"], [229, "infection"], [229, "."], [230, "while"], [230, "the"], [230, "anti"], [230, "-"], [230, "viral"], [230, "immune"], [230, "response"], [230, "be"], [230, "important"], [230, "to"], [230, "protect"], [230, "from"], [230, "coronavirus"], [230, "infection"], [230, ","], [230, "an"], [230, "uncontrolled"], [230, "proinflammatory"], [230, "cytokine"], [230, "response"], [230, "can"], [230, "lead"], [230, "to"], [230, "cytokine"], [230, "storm"], [230, "which"], [230, "cause"], [230, "damage"], [230, "to"], [230, "the"], [230, "lung"], [230, "and"], [230, "other"], [230, "organ"], [230, ","], [230, "cause"], [230, "significant"], [230, "morbidity"], [230, "and"], [230, "mortality"], [230, "."], [231, "well"], [231, "understanding"], [231, "of"], [231, "the"], [231, "underlying"], [231, "immune"], [231, "response"], [231, "and"], [231, "therapeutic"], [231, "strategy"], [231, "in"], [231, "lupus"], [231, "and"], [231, "covid-19"], [231, "be"], [231, "important"], [231, "to"], [231, "guide"], [231, "management"], [231, "of"], [231, "this"], [231, "deadly"], [231, "infectious"], [231, "disease"], [231, "in"], [231, "the"], [231, "context"], [231, "of"], [231, "lupus"], [231, "and"], [231, "vice"], [231, "-"], [231, "versa"], [231, "."], [232, "little"], [232, "be"], [232, "know"], [232, "about"], [232, "the"], [232, "sequelae"], [232, "of"], [232, "sars"], [232, "-"], [232, "cov-2"], [232, "infection"], [232, "in"], [232, "child"], [232, "."], [233, "in"], [233, "a"], [233, "covid-19"], [233, "dedicated"], [233, "clinic"], [233, ","], [233, "we"], [233, "follow"], [233, "-"], [233, "up"], [233, "for"], [233, "4"], [233, "month"], [233, "25"], [233, "child"], [233, "previously"], [233, "hospitalize"], [233, "for"], [233, "covid-19"], [233, ","], [233, "perform"], [233, "clinical"], [233, ","], [233, "laboratory"], [233, ","], [233, "and"], [233, "lung"], [233, "ultrasound"], [233, "evaluation"], [233, "."], [234, "mid"], [234, "-"], [234, "term"], [234, "sequelae"], [234, "be"], [234, "rarely"], [234, "observe"], [234, "in"], [234, "our"], [234, "covid-19"], [234, "child"], [234, "'s"], [234, "cohort"], [234, "."], [235, "old"], [235, "individual"], [235, "be"], [235, "more"], [235, "susceptible"], [235, "to"], [235, "various"], [235, "infection"], [235, "due"], [235, "to"], [235, "immunological"], [235, "change"], [235, "that"], [235, "occur"], [235, "during"], [235, "the"], [235, "age"], [235, "process"], [235, "."], [236, "these"], [236, "change"], [236, "name"], [236, "collectively"], [236, "as"], [236, '"'], [236, "immunosenescence"], [236, '"'], [236, "include"], [236, "decrease"], [236, "in"], [236, "both"], [236, "the"], [236, "innate"], [236, "and"], [236, "adaptive"], [236, "immune"], [236, "response"], [236, "in"], [236, "addition"], [236, "to"], [236, "the"], [236, "exacerbate"], [236, "production"], [236, "of"], [236, "inflammatory"], [236, "cytokine"], [236, "."], [237, "this"], [237, "scenario"], [237, "of"], [237, "immunological"], [237, "dysfunction"], [237, "and"], [237, "its"], [237, "relationship"], [237, "with"], [237, "disease"], [237, "development"], [237, "in"], [237, "old"], [237, "people"], [237, "have"], [237, "be"], [237, "widely"], [237, "study"], [237, ","], [237, "especially"], [237, "in"], [237, "infection"], [237, "that"], [237, "can"], [237, "be"], [237, "fatal"], [237, ","], [237, "such"], [237, "as"], [237, "influenza"], [237, "and"], [237, ","], [237, "more"], [237, "recently"], [237, ","], [237, "covid-19"], [237, "."], [238, "in"], [238, "the"], [238, "current"], [238, "scenario"], [238, "of"], [238, "sars"], [238, "-"], [238, "cov-2"], [238, "infection"], [238, ","], [238, "many"], [238, "mechanism"], [238, "of"], [238, "disease"], [238, "pathogenesis"], [238, "in"], [238, "old"], [238, "individual"], [238, "have"], [238, "be"], [238, "propose"], [238, "."], [239, "to"], [239, "well"], [239, "understand"], [239, "the"], [239, "dynamic"], [239, "of"], [239, "covid-19"], [239, "in"], [239, "this"], [239, "group"], [239, ","], [239, "aspect"], [239, "relate"], [239, "to"], [239, "immunological"], [239, "senescence"], [239, "must"], [239, "be"], [239, "well"], [239, "elucidated"], [239, "."], [240, "in"], [240, "this"], [240, "article"], [240, ","], [240, "we"], [240, "discuss"], [240, "the"], [240, "main"], [240, "mechanism"], [240, "involve"], [240, "in"], [240, "immunosenescence"], [240, "and"], [240, "their"], [240, "possible"], [240, "correlation"], [240, "with"], [240, "the"], [240, "susceptibility"], [240, "of"], [240, "individual"], [240, "of"], [240, "advanced"], [240, "age"], [240, "to"], [240, "sars"], [240, "-"], [240, "cov-2"], [240, "infection"], [240, "and"], [240, "the"], [240, "more"], [240, "severe"], [240, "condition"], [240, "of"], [240, "the"], [240, "disease"], [240, "."], [241, "covid-19"], [241, "be"], [241, "cause"], [241, "by"], [241, "sars"], [241, "-"], [241, "cov-2"], [241, "which"], [241, "be"], [241, "a"], [241, "new"], [241, "envelop"], [241, "virus"], [241, "that"], [241, "belong"], [241, "to"], [241, "the"], [241, "beta"], [241, "coronavirus"], [241, "genus"], [241, "."], [242, "as"], [242, "a"], [242, "major"], [242, "health"], [242, "crisis"], [242, ","], [242, "sars"], [242, "-"], [242, "cov-2"], [242, "have"], [242, "infect"], [242, "over"], [242, "a"], [242, "million"], [242, "people"], [242, "around"], [242, "the"], [242, "world"], [242, "."], [243, "there"], [243, "be"], [243, "currently"], [243, "no"], [243, "specific"], [243, "treatment"], [243, "available"], [243, "for"], [243, "patient"], [243, "with"], [243, "covid-19"], [243, "infection"], [243, "."], [244, "numerous"], [244, "potential"], [244, "therapy"], [244, ","], [244, "include"], [244, "supportive"], [244, "intervention"], [244, ","], [244, "immunomodulatory"], [244, "agent"], [244, ","], [244, "antiviral"], [244, "therapy"], [244, ","], [244, "and"], [244, "convalescent"], [244, "plasma"], [244, "transfusion"], [244, ","], [244, "have"], [244, "be"], [244, "use"], [244, "in"], [244, "clinical"], [244, "practice"], [244, "."], [245, "herein"], [245, ","], [245, "we"], [245, "summarize"], [245, "the"], [245, "current"], [245, "potential"], [245, "therapeutic"], [245, "approach"], [245, "for"], [245, "disease"], [245, "relate"], [245, "to"], [245, "covid-19"], [245, "infection"], [245, "and"], [245, "discuss"], [245, "the"], [245, "clinical"], [245, "value"], [245, "of"], [245, "blood"], [245, "transfusion"], [245, "-"], [245, "relate"], [245, "technology"], [245, "use"], [245, "in"], [245, "covid-19"], [245, "treatment"], [245, "."], [246, "exposure"], [246, "to"], [246, "air"], [246, "pollutant"], [246, "have"], [246, "be"], [246, "previously"], [246, "associate"], [246, "with"], [246, "respiratory"], [246, "viral"], [246, "infection"], [246, ","], [246, "include"], [246, "influenza"], [246, ","], [246, "measle"], [246, ","], [246, "mump"], [246, ","], [246, "rhinovirus"], [246, ","], [246, "and"], [246, "respiratory"], [246, "syncytial"], [246, "virus"], [246, "."], [247, "epidemiological"], [247, "study"], [247, "have"], [247, "also"], [247, "suggest"], [247, "that"], [247, "air"], [247, "pollution"], [247, "exposure"], [247, "be"], [247, "associate"], [247, "with"], [247, "increase"], [247, "case"], [247, "of"], [247, "sars"], [247, "-"], [247, "cov-2"], [247, "infection"], [247, "and"], [247, "covid-19"], [247, "-"], [247, "associate"], [247, "mortality"], [247, ","], [247, "although"], [247, "the"], [247, "molecular"], [247, "mechanism"], [247, "by"], [247, "which"], [247, "pollutant"], [247, "exposure"], [247, "affect"], [247, "viral"], [247, "infection"], [247, "and"], [247, "pathogenesis"], [247, "of"], [247, "covid-19"], [247, "remain"], [247, "unknown"], [247, "."], [248, "in"], [248, "this"], [248, "review"], [248, ","], [248, "we"], [248, "suggest"], [248, "potential"], [248, "molecular"], [248, "mechanism"], [248, "that"], [248, "could"], [248, "account"], [248, "for"], [248, "this"], [248, "association"], [248, "."], [249, "we"], [249, "have"], [249, "focus"], [249, "on"], [249, "the"], [249, "potential"], [249, "effect"], [249, "of"], [249, "exposure"], [249, "to"], [249, "nitrogen"], [249, "dioxide"], [249, "("], [249, "no"], [249, ")"], [249, ","], [249, "ozone"], [249, "("], [249, "o"], [249, ")"], [249, ","], [249, "and"], [249, "particulate"], [249, "matter"], [249, "("], [249, "pm"], [249, ")"], [249, "since"], [249, "there"], [249, "be"], [249, "study"], [249, "investigate"], [249, "how"], [249, "exposure"], [249, "to"], [249, "these"], [249, "pollutant"], [249, "affect"], [249, "the"], [249, "life"], [249, "cycle"], [249, "of"], [249, "other"], [249, "virus"], [249, "."], [250, "we"], [250, "have"], [250, "conclude"], [250, "that"], [250, "pollutant"], [250, "exposure"], [250, "may"], [250, "affect"], [250, "different"], [250, "stage"], [250, "of"], [250, "the"], [250, "viral"], [250, "life"], [250, "cycle"], [250, ","], [250, "include"], [250, "inhibition"], [250, "of"], [250, "mucociliary"], [250, "clearance"], [250, ","], [250, "alteration"], [250, "of"], [250, "viral"], [250, "receptor"], [250, "and"], [250, "protease"], [250, "require"], [250, "for"], [250, "entry"], [250, ","], [250, "change"], [250, "to"], [250, "antiviral"], [250, "interferon"], [250, "production"], [250, "and"], [250, "viral"], [250, "replication"], [250, ","], [250, "change"], [250, "in"], [250, "viral"], [250, "assembly"], [250, "mediate"], [250, "by"], [250, "autophagy"], [250, ","], [250, "prevention"], [250, "of"], [250, "uptake"], [250, "by"], [250, "macrophage"], [250, ","], [250, "and"], [250, "promotion"], [250, "of"], [250, "viral"], [250, "spread"], [250, "by"], [250, "increase"], [250, "epithelial"], [250, "permeability"], [250, "."], [251, "we"], [251, "believe"], [251, "that"], [251, "exposure"], [251, "to"], [251, "pollutant"], [251, "skews"], [251, "adaptive"], [251, "immune"], [251, "response"], [251, "toward"], [251, "bacterial"], [251, "/"], [251, "allergic"], [251, "immune"], [251, "response"], [251, ","], [251, "as"], [251, "oppose"], [251, "to"], [251, "antiviral"], [251, "response"], [251, "."], [252, "exposure"], [252, "to"], [252, "air"], [252, "pollutant"], [252, "could"], [252, "also"], [252, "predispose"], [252, "expose"], [252, "population"], [252, "toward"], [252, "develop"], [252, "coivd-19"], [252, "-"], [252, "associate"], [252, "immunopathology"], [252, ","], [252, "enhance"], [252, "virus"], [252, "-"], [252, "induce"], [252, "tissue"], [252, "inflammation"], [252, "and"], [252, "damage"], [252, "."], [253, "coronavirus"], [253, "disease-2019"], [253, "("], [253, "covid-19"], [253, ")"], [253, "be"], [253, "declare"], [253, "a"], [253, "global"], [253, "pandemic"], [253, "on"], [253, "11"], [253, "march"], [253, "2020"], [253, "."], [254, "scientist"], [254, "and"], [254, "clinician"], [254, "must"], [254, "acknowledge"], [254, "that"], [254, "severe"], [254, "acute"], [254, "respiratory"], [254, "syndrome"], [254, "coronavirus"], [254, "2"], [254, "("], [254, "sars"], [254, "-"], [254, "cov-2"], [254, ")"], [254, "have"], [254, "the"], [254, "potential"], [254, "to"], [254, "attack"], [254, "the"], [254, "human"], [254, "body"], [254, "in"], [254, "multiple"], [254, "way"], [254, "simultaneously"], [254, "and"], [254, "exploit"], [254, "any"], [254, "weakness"], [254, "of"], [254, "its"], [254, "host"], [254, "."], [255, "a"], [255, "multipronged"], [255, "attack"], [255, "could"], [255, "potentially"], [255, "explain"], [255, "the"], [255, "severity"], [255, "and"], [255, "extensive"], [255, "variety"], [255, "of"], [255, "sign"], [255, "and"], [255, "symptom"], [255, "observe"], [255, "in"], [255, "patient"], [255, "with"], [255, "covid-19"], [255, "."], [256, "understand"], [256, "the"], [256, "diverse"], [256, "tactic"], [256, "of"], [256, "this"], [256, "virus"], [256, "to"], [256, "infect"], [256, "the"], [256, "human"], [256, "body"], [256, "be"], [256, "both"], [256, "critical"], [256, "and"], [256, "incredibly"], [256, "complex"], [256, "."], [257, "although"], [257, "patient"], [257, "diagnose"], [257, "with"], [257, "covid-19"], [257, "have"], [257, "primarily"], [257, "present"], [257, "with"], [257, "pulmonary"], [257, "involvement"], [257, ","], [257, "viral"], [257, "invasion"], [257, ","], [257, "and"], [257, "injury"], [257, "to"], [257, "diverse"], [257, "end"], [257, "organ"], [257, "be"], [257, "also"], [257, "prevalent"], [257, "and"], [257, "well"], [257, "document"], [257, "in"], [257, "these"], [257, "patient"], [257, ","], [257, "but"], [257, "have"], [257, "be"], [257, "largely"], [257, "unheeded"], [257, "."], [258, "human"], [258, "organ"], [258, "know"], [258, "for"], [258, "angiotensin"], [258, "-"], [258, "convert"], [258, "enzyme"], [258, "2"], [258, "("], [258, "ace2"], [258, ")"], [258, "expression"], [258, "include"], [258, "the"], [258, "gastrointestinal"], [258, "tract"], [258, ","], [258, "kidney"], [258, ","], [258, "heart"], [258, ","], [258, "adrenal"], [258, ","], [258, "brain"], [258, ","], [258, "and"], [258, "testicle"], [258, "be"], [258, "example"], [258, "of"], [258, "extra"], [258, "pulmonary"], [258, "tissue"], [258, "with"], [258, "confirm"], [258, "invasion"], [258, "by"], [258, "sars"], [258, "-"], [258, "cov-2"], [258, "."], [259, "initial"], [259, "multiple"], [259, "organ"], [259, "involvement"], [259, "may"], [259, "present"], [259, "with"], [259, "vague"], [259, "sign"], [259, "and"], [259, "symptom"], [259, "to"], [259, "alert"], [259, "health"], [259, "care"], [259, "professional"], [259, "early"], [259, "in"], [259, "the"], [259, "course"], [259, "of"], [259, "covid-19"], [259, "."], [260, "another"], [260, "example"], [260, "of"], [260, "an"], [260, "ongoing"], [260, ","], [260, "yet"], [260, "neglect"], [260, "element"], [260, "of"], [260, "the"], [260, "syndromic"], [260, "feature"], [260, "of"], [260, "covid-19"], [260, ","], [260, "be"], [260, "the"], [260, "reported"], [260, "finding"], [260, "of"], [260, "loss"], [260, "of"], [260, "smell"], [260, ","], [260, "alter"], [260, "taste"], [260, ","], [260, "ataxia"], [260, ","], [260, "headache"], [260, ","], [260, "dizziness"], [260, ","], [260, "and"], [260, "loss"], [260, "of"], [260, "consciousness"], [260, ","], [260, "which"], [260, "suggest"], [260, "a"], [260, "potential"], [260, "for"], [260, "neural"], [260, "involvement"], [260, "."], [261, "in"], [261, "this"], [261, "review"], [261, ","], [261, "we"], [261, "far"], [261, "deliberate"], [261, "on"], [261, "the"], [261, "neuroinvasive"], [261, "potential"], [261, "of"], [261, "sars"], [261, "-"], [261, "cov-2"], [261, ","], [261, "the"], [261, "neurologic"], [261, "symptomology"], [261, "observe"], [261, "in"], [261, "covid-19"], [261, ","], [261, "the"], [261, "host"], [261, "-"], [261, "virus"], [261, "interaction"], [261, ","], [261, "possible"], [261, "route"], [261, "of"], [261, "sars"], [261, "-"], [261, "cov-2"], [261, "to"], [261, "invade"], [261, "the"], [261, "central"], [261, "nervous"], [261, "system"], [261, ","], [261, "other"], [261, "neurologic"], [261, "consideration"], [261, "for"], [261, "patient"], [261, "with"], [261, "covid-19"], [261, ","], [261, "and"], [261, "a"], [261, "collective"], [261, "call"], [261, "to"], [261, "action"], [261, "."], [262, "coronavirus"], [262, "disease-19"], [262, "("], [262, "covid-19"], [262, ")"], [262, "be"], [262, "cause"], [262, "by"], [262, "severe"], [262, "acute"], [262, "respiratory"], [262, "syndrome"], [262, "coronavirus"], [262, "2"], [262, "("], [262, "sars"], [262, "-"], [262, "cov-2"], [262, ")"], [262, "."], [263, "sars"], [263, "-"], [263, "cov-2"], [263, "be"], [263, "closely"], [263, "relate"], [263, "to"], [263, "two"], [263, "other"], [263, "coronaviruse"], [263, "that"], [263, "cause"], [263, "disease"], [263, "epidemic"], [263, "breakout"], [263, "in"], [263, "human"], [263, "in"], [263, "the"], [263, "last"], [263, "2"], [263, "decade"], [263, ","], [263, "namely"], [263, ","], [263, "severe"], [263, "acute"], [263, "respiratory"], [263, "distress"], [263, "syndrome"], [263, "coronavirus"], [263, "("], [263, "sars"], [263, "-"], [263, "cov"], [263, ")"], [263, "and"], [263, "middle"], [263, "east"], [263, "respiratory"], [263, "syndrome"], [263, "coronavirus"], [263, "("], [263, "mer"], [263, "-"], [263, "cov"], [263, ")"], [263, "."], [264, "the"], [264, "similarity"], [264, "have"], [264, "enable"], [264, "the"], [264, "scientist"], [264, "to"], [264, "apply"], [264, "the"], [264, "basic"], [264, "scientific"], [264, "discovery"], [264, "garner"], [264, "from"], [264, "study"], [264, "the"], [264, "structure"], [264, "and"], [264, "modus"], [264, "operandi"], [264, "of"], [264, "sars"], [264, "-"], [264, "cov"], [264, "and"], [264, "mer"], [264, "-"], [264, "cov"], [264, "to"], [264, "develop"], [264, "therapy"], [264, "that"], [264, "specifically"], [264, "target"], [264, "sars"], [264, "-"], [264, "cov-2"], [264, "and"], [264, "to"], [264, "develop"], [264, "vaccine"], [264, "to"], [264, "prevent"], [264, "covid-19"], [264, "."], [265, "target"], [265, "therapy"], [265, "include"], [265, "the"], [265, "use"], [265, "of"], [265, "antibody"], [265, "to"], [265, "prevent"], [265, "virus"], [265, "entry"], [265, ","], [265, "nucleotide"], [265, "analogue"], [265, "to"], [265, "prevent"], [265, "viral"], [265, "replication"], [265, ","], [265, "and"], [265, "inhibitor"], [265, "of"], [265, "protease"], [265, "to"], [265, "prevent"], [265, "virion"], [265, "formation"], [265, ","], [265, "among"], [265, "other"], [265, ","], [265, "be"], [265, "be"], [265, "test"], [265, "for"], [265, "their"], [265, "clinical"], [265, "efficacy"], [265, "."], [266, "likewise"], [266, ","], [266, "complete"], [266, "sequence"], [266, "of"], [266, "the"], [266, "sars"], [266, "-"], [266, "cov-2"], [266, "and"], [266, "identification"], [266, "of"], [266, "its"], [266, "structural"], [266, "and"], [266, "nonstructural"], [266, "protein"], [266, "have"], [266, "enable"], [266, "development"], [266, "of"], [266, "rna-"], [266, ","], [266, "dna-"], [266, ","], [266, "and"], [266, "peptide"], [266, "-"], [266, "base"], [266, "vaccine"], [266, "as"], [266, "well"], [266, "attenuate"], [266, "viral"], [266, "vaccine"], [266, "to"], [266, "instigate"], [266, "the"], [266, "host"], [266, "-"], [266, "immune"], [266, "response"], [266, "."], [267, "the"], [267, "clinical"], [267, "impact"], [267, "of"], [267, "the"], [267, "basic"], [267, "science"], [267, "discovery"], [267, "be"], [267, "amply"], [267, "evident"], [267, "on"], [267, "the"], [267, "rapid"], [267, "pace"], [267, "of"], [267, "progress"], [267, "in"], [267, "develop"], [267, "specific"], [267, "antiviral"], [267, "therapy"], [267, "and"], [267, "vaccine"], [267, "against"], [267, "sars"], [267, "-"], [267, "cov-2"], [267, "."], [268, "the"], [268, "progress"], [268, "emphasize"], [268, "the"], [268, "merit"], [268, "of"], [268, "discover"], [268, "the"], [268, "fundamental"], [268, "scientific"], [268, "element"], [268, ","], [268, "regardless"], [268, "of"], [268, "whether"], [268, "or"], [268, "not"], [268, "they"], [268, "have"], [268, "apparent"], [268, "or"], [268, "immediate"], [268, "clinical"], [268, "application"], [268, "."], [269, "type"], [269, "v"], [269, "and"], [269, "vi"], [269, "crispr"], [269, "enzyme"], [269, "be"], [269, "rna"], [269, "-"], [269, "guide"], [269, ","], [269, "dna"], [269, "and"], [269, "rna"], [269, "-"], [269, "target"], [269, "effector"], [269, "that"], [269, "allow"], [269, "specific"], [269, "gene"], [269, "knockdown"], [269, "."], [270, "cas12"], [270, "and"], [270, "cas13"], [270, "be"], [270, "crispr"], [270, "protein"], [270, "that"], [270, "be"], [270, "efficient"], [270, "agent"], [270, "for"], [270, "diagnosis"], [270, "and"], [270, "combat"], [270, "single"], [270, "-"], [270, "strand"], [270, "rna"], [270, "("], [270, "ssrna"], [270, ")"], [270, "virus"], [270, "."], [271, "the"], [271, "programmability"], [271, "of"], [271, "these"], [271, "protein"], [271, "pave"], [271, "the"], [271, "way"], [271, "for"], [271, "the"], [271, "detection"], [271, "and"], [271, "degradation"], [271, "of"], [271, "rna"], [271, "virus"], [271, "by"], [271, "target"], [271, "rna"], [271, "complementary"], [271, "to"], [271, "its"], [271, "crispr"], [271, "rna"], [271, "("], [271, "crrna"], [271, ")"], [271, "."], [272, "approximately"], [272, "two"], [272, "-"], [272, "third"], [272, "of"], [272, "virus"], [272, "cause"], [272, "disease"], [272, "contain"], [272, "ssrna"], [272, "genome"], [272, "."], [273, "the"], [273, "severe"], [273, "acute"], [273, "respiratory"], [273, "syndrome"], [273, "coronavirus"], [273, "2"], [273, "("], [273, "sars"], [273, "-"], [273, "cov-2"], [273, ")"], [273, "have"], [273, "cause"], [273, "the"], [273, "outbreak"], [273, "of"], [273, "the"], [273, "coronavirus"], [273, "disease"], [273, "2019"], [273, "("], [273, "covid-19"], [273, ")"], [273, ","], [273, "which"], [273, "have"], [273, "infect"], [273, "more"], [273, "than"], [273, "88"], [273, "million"], [273, "people"], [273, "worldwide"], [273, "with"], [273, "near"], [273, "2"], [273, "million"], [273, "death"], [273, "since"], [273, "december"], [273, "2019"], [273, "."], [274, "thus"], [274, ","], [274, "accurate"], [274, "and"], [274, "rapid"], [274, "diagnostic"], [274, "and"], [274, "therapeutic"], [274, "tool"], [274, "be"], [274, "essential"], [274, "for"], [274, "early"], [274, "detection"], [274, "and"], [274, "treatment"], [274, "of"], [274, "this"], [274, "widespread"], [274, "infectious"], [274, "disease"], [274, "."], [275, "for"], [275, "we"], [275, ","], [275, "the"], [275, "crispr"], [275, "base"], [275, "platform"], [275, "seem"], [275, "to"], [275, "be"], [275, "a"], [275, "plausible"], [275, "new"], [275, "approach"], [275, "for"], [275, "an"], [275, "accurate"], [275, "detection"], [275, "and"], [275, "treatment"], [275, "of"], [275, "sars"], [275, "-"], [275, "cov-2"], [275, "."], [276, "in"], [276, "this"], [276, "review"], [276, ","], [276, "we"], [276, "talk"], [276, "about"], [276, "cas12"], [276, "and"], [276, "cas13"], [276, "crispr"], [276, "system"], [276, "and"], [276, "their"], [276, "application"], [276, "in"], [276, "diagnosis"], [276, "and"], [276, "treatment"], [276, "of"], [276, "rna"], [276, "virus"], [276, "mediate"], [276, "disease"], [276, "."], [277, "in"], [277, "continue"], [277, ","], [277, "the"], [277, "sars"], [277, "-"], [277, "cov-2"], [277, "pathogenicity"], [277, ","], [277, "and"], [277, "its"], [277, "conventional"], [277, "diagnostic"], [277, "and"], [277, "antiviral"], [277, "will"], [277, "be"], [277, "discuss"], [277, "."], [278, "moreover"], [278, ","], [278, "we"], [278, "highlight"], [278, "novel"], [278, "crispr"], [278, "base"], [278, "diagnostic"], [278, "platform"], [278, "and"], [278, "therapy"], [278, "for"], [278, "covid-19"], [278, "."], [279, "we"], [279, "also"], [279, "discuss"], [279, "the"], [279, "challenge"], [279, "of"], [279, "diagnostic"], [279, "crispr"], [279, "base"], [279, "platform"], [279, "as"], [279, "well"], [279, "as"], [279, "clarify"], [279, "the"], [279, "propose"], [279, "solution"], [279, "for"], [279, "high"], [279, "efficient"], [279, "selective"], [279, "in"], [279, "vivo"], [279, "delivery"], [279, "of"], [279, "crispr"], [279, "component"], [279, "into"], [279, "sars"], [279, "-"], [279, "cov-2"], [279, "-"], [279, "infect"], [279, "cell"], [279, "."], [280, "covid-19"], [280, ","], [280, "the"], [280, "human"], [280, "coronavirus"], [280, "disease"], [280, "cause"], [280, "by"], [280, "sars"], [280, "-"], [280, "cov-2"], [280, ","], [280, "be"], [280, "report"], [280, "for"], [280, "the"], [280, "first"], [280, "time"], [280, "in"], [280, "wuhan"], [280, ","], [280, "china"], [280, "in"], [280, "late"], [280, "2019"], [280, "."], [281, "covid-19"], [281, "have"], [281, "no"], [281, "preventive"], [281, "vaccine"], [281, "or"], [281, "prove"], [281, "standard"], [281, "pharmacological"], [281, "treatment"], [281, ","], [281, "and"], [281, "consequently"], [281, ","], [281, "the"], [281, "outbreak"], [281, "swiftly"], [281, "become"], [281, "a"], [281, "pandemic"], [281, "affect"], [281, "more"], [281, "than"], [281, "215"], [281, "country"], [281, "around"], [281, "the"], [281, "world"], [281, "."], [282, "for"], [282, "the"], [282, "diagnosis"], [282, "of"], [282, "covid-19"], [282, ","], [282, "the"], [282, "only"], [282, "reliable"], [282, "\xA0"], [282, "diagnostic"], [282, "\xA0"], [282, "be"], [282, "a"], [282, "\xA0"], [282, "qpcr"], [282, "assay"], [282, "."], [283, "among"], [283, "other"], [283, "diagnostic"], [283, "tool"], [283, ","], [283, "the"], [283, "crispr"], [283, "-"], [283, "cas"], [283, "system"], [283, "be"], [283, "be"], [283, "investigate"], [283, "for"], [283, "rapid"], [283, "and"], [283, "specific"], [283, "diagnosis"], [283, "of"], [283, "covid-19"], [283, "."], [284, "the"], [284, "crispr"], [284, "-"], [284, "cas"], [284, "-"], [284, "base"], [284, "method"], [284, "diagnose"], [284, "the"], [284, "sars"], [284, "-"], [284, "cov-2"], [284, "infection"], [284, "within"], [284, "an"], [284, "hour"], [284, "."], [285, "apart"], [285, "from"], [285, "its"], [285, "diagnostic"], [285, "ability"], [285, ","], [285, "\xA0"], [285, "crispr"], [285, "-"], [285, "cas"], [285, "system"], [285, "be"], [285, "also"], [285, "be"], [285, "assess"], [285, "for"], [285, "antiviral"], [285, "therapy"], [285, "development"], [285, ";"], [285, "however"], [285, ","], [285, "till"], [285, "date"], [285, ","], [285, "no"], [285, "crispr"], [285, "-"], [285, "base"], [285, "therapy"], [285, "have"], [285, "be"], [285, "approve"], [285, "for"], [285, "human"], [285, "use"], [285, "."], [286, "the"], [286, "prophylactic"], [286, "antiviral"], [286, "crispr"], [286, "in"], [286, "human"], [286, "cell"], [286, "("], [286, "pac"], [286, "-"], [286, "man"], [286, ")"], [286, ","], [286, "which"], [286, "be"], [286, "cas"], [286, "13"], [286, "base"], [286, "strategy"], [286, ","], [286, "have"], [286, "be"], [286, "develop"], [286, "against"], [286, "coronavirus"], [286, "."], [287, "although"], [287, "this"], [287, "strategy"], [287, "have"], [287, "the"], [287, "potential"], [287, "to"], [287, "be"], [287, "develop"], [287, "as"], [287, "a"], [287, "therapeutic"], [287, "modality"], [287, ","], [287, "it"], [287, "may"], [287, "face"], [287, "significant"], [287, "challenge"], [287, "for"], [287, "approval"], [287, "in"], [287, "human"], [287, "clinical"], [287, "trial"], [287, "."], [288, "this"], [288, "review"], [288, "be"], [288, "focus"], [288, "on"], [288, "describe"], [288, "potential"], [288, "use"], [288, "and"], [288, "challenge"], [288, "of"], [288, "crispr"], [288, "-"], [288, "cas"], [288, "base"], [288, "approach"], [288, "for"], [288, "the"], [288, "development"], [288, "of"], [288, "rapid"], [288, "and"], [288, "accurate"], [288, "diagnostic"], [288, "technique"], [288, "and/or"], [288, "a"], [288, "possible"], [288, "therapeutic"], [288, "alternative"], [288, "for"], [288, "combat"], [288, "covid-19"], [288, "."], [289, "the"], [289, "assessment"], [289, "of"], [289, "potential"], [289, "risk"], [289, "associate"], [289, "with"], [289, "use"], [289, "of"], [289, "crispr"], [289, "will"], [289, "be"], [289, "important"], [289, "for"], [289, "future"], [289, "clinical"], [289, "advancement"], [289, "."], [290, "the"], [290, "global"], [290, "pandemic"], [290, "of"], [290, "coronavirus"], [290, "disease"], [290, "2019"], [290, "("], [290, "covid-19"], [290, ")"], [290, "have"], [290, "bre"], [290, "the"], [290, "world"], [290, "to"], [290, "a"], [290, "grind"], [290, "halt"], [290, "."], [291, "a"], [291, "major"], [291, "cause"], [291, "of"], [291, "concern"], [291, "be"], [291, "the"], [291, "respiratory"], [291, "distress"], [291, "associate"], [291, "mortality"], [291, "attribute"], [291, "to"], [291, "the"], [291, "cytokine"], [291, "storm"], [291, "."], [292, "despite"], [292, "myriad"], [292, "rapidly"], [292, "approve"], [292, "clinical"], [292, "trial"], [292, "with"], [292, "repurposed"], [292, "drug"], [292, ","], [292, "and"], [292, "time"], [292, "need"], [292, "to"], [292, "develop"], [292, "a"], [292, "vaccine"], [292, ","], [292, "accelerate"], [292, "search"], [292, "for"], [292, "repurposed"], [292, "therapeutic"], [292, "be"], [292, "still"], [292, "ongoing"], [292, "."], [293, "in"], [293, "this"], [293, "review"], [293, ","], [293, "we"], [293, "present"], [293, "nitazoxanide"], [293, "a"], [293, "us"], [293, "-"], [293, "fda"], [293, "approve"], [293, "antiprotozoal"], [293, "drug"], [293, ","], [293, "as"], [293, "one"], [293, "such"], [293, "promising"], [293, "candidate"], [293, "."], [294, "nitazoxanide"], [294, "which"], [294, "be"], [294, "report"], [294, "to"], [294, "exert"], [294, "broad"], [294, "-"], [294, "spectrum"], [294, "antiviral"], [294, "activity"], [294, "against"], [294, "various"], [294, "viral"], [294, "infection"], [294, ","], [294, "reveal"], [294, "good"], [294, "in"], [294, "vitro"], [294, "activity"], [294, "against"], [294, "sars"], [294, "-"], [294, "cov-2"], [294, "in"], [294, "cell"], [294, "culture"], [294, "assay"], [294, ","], [294, "suggest"], [294, "potential"], [294, "for"], [294, "repurpose"], [294, "in"], [294, "covid-19"], [294, "."], [295, "furthermore"], [295, ","], [295, "nitazoxanide"], [295, "display"], [295, "the"], [295, "potential"], [295, "to"], [295, "boost"], [295, "host"], [295, "innate"], [295, "immune"], [295, "response"], [295, "and"], [295, "thereby"], [295, "tackle"], [295, "the"], [295, "life"], [295, "-"], [295, "threaten"], [295, "cytokine"], [295, "storm"], [295, "."], [296, "possibility"], [296, "of"], [296, "improve"], [296, "lung"], [296, ","], [296, "as"], [296, "well"], [296, "as"], [296, "multiple"], [296, "organ"], [296, "damage"], [296, "and"], [296, "provide"], [296, "value"], [296, "addition"], [296, "to"], [296, "covid-19"], [296, "patient"], [296, "with"], [296, "comorbiditie"], [296, ","], [296, "be"], [296, "other"], [296, "important"], [296, "facet"], [296, "of"], [296, "the"], [296, "drug"], [296, "."], [297, "the"], [297, "review"], [297, "juxtapose"], [297, "the"], [297, "role"], [297, "of"], [297, "nitazoxanide"], [297, "in"], [297, "fight"], [297, "covid-19"], [297, "pathogenesis"], [297, "at"], [297, "multiple"], [297, "level"], [297, "highlight"], [297, "the"], [297, "great"], [297, "promise"], [297, "the"], [297, "drug"], [297, "exhibit"], [297, "."], [298, "the"], [298, "in"], [298, "silico"], [298, "datum"], [298, "and"], [298, "in"], [298, "vitro"], [298, "efficacy"], [298, "in"], [298, "cell"], [298, "line"], [298, "confirm"], [298, "the"], [298, "promise"], [298, "of"], [298, "nitazoxanide"], [298, "."], [299, "several"], [299, "approve"], [299, "clinical"], [299, "trial"], [299, "world"], [299, "over"], [299, "far"], [299, "substantiate"], [299, "leverage"], [299, "nitazoxanide"], [299, "for"], [299, "covid-19"], [299, "therapy"], [299, "."], [300, "the"], [300, "ongoing"], [300, "coronavirus"], [300, "disease"], [300, "2019"], [300, "("], [300, "covid-19"], [300, ")"], [300, "pandemic"], [300, "be"], [300, "a"], [300, "rapidly"], [300, "evolve"], [300, "situation"], [300, "."], [301, "new"], [301, "discovery"], [301, "about"], [301, "covid-19"], [301, "and"], [301, "its"], [301, "causative"], [301, "virus"], [301, ","], [301, "severe"], [301, "acute"], [301, "respiratory"], [301, "syndrome"], [301, "coronavirus"], [301, "2"], [301, "("], [301, "sars"], [301, "-"], [301, "cov-2"], [301, ")"], [301, ","], [301, "continue"], [301, "to"], [301, "deepen"], [301, "the"], [301, "understanding"], [301, "of"], [301, "this"], [301, "novel"], [301, "disease"], [301, "."], [302, "as"], [302, "there"], [302, "be"], [302, "currently"], [302, "no"], [302, "covid-19"], [302, "specific"], [302, "treatment"], [302, ","], [302, "isolation"], [302, "be"], [302, "the"], [302, "most"], [302, "effective"], [302, "method"], [302, "to"], [302, "prevent"], [302, "transmission"], [302, "."], [303, "moreover"], [303, ","], [303, "development"], [303, "of"], [303, "a"], [303, "safe"], [303, "and"], [303, "effective"], [303, "covid-19"], [303, "vaccine"], [303, "will"], [303, "be"], [303, "instrumental"], [303, "in"], [303, "reinstate"], [303, "pre"], [303, "-"], [303, "covid-19"], [303, "condition"], [303, "."], [304, "as"], [304, "of"], [304, "31"], [304, "\xA0"], [304, "july"], [304, "\xA0"], [304, "2020"], [304, ","], [304, "there"], [304, "be"], [304, "at"], [304, "least"], [304, "139"], [304, "vaccine"], [304, "candidate"], [304, "from"], [304, "around"], [304, "the"], [304, "globe"], [304, "in"], [304, "preclinical"], [304, "evaluation"], [304, ","], [304, "with"], [304, "another"], [304, "26"], [304, "undergo"], [304, "clinical"], [304, "evaluation"], [304, "."], [305, "this"], [305, "paper"], [305, "aim"], [305, "to"], [305, "review"], [305, "the"], [305, "basic"], [305, "of"], [305, "covid-19"], [305, ","], [305, "include"], [305, "epidemiology"], [305, ","], [305, "basic"], [305, "biology"], [305, "of"], [305, "sars"], [305, "-"], [305, "cov-2"], [305, ","], [305, "and"], [305, "transmission"], [305, "."], [306, "we"], [306, "also"], [306, "review"], [306, "covid-19"], [306, "vaccine"], [306, "development"], [306, ","], [306, "include"], [306, "animal"], [306, "model"], [306, ","], [306, "platform"], [306, "under"], [306, "development"], [306, ","], [306, "and"], [306, "vaccine"], [306, "development"], [306, "in"], [306, "canada"], [306, "."], [307, "the"], [307, "recent"], [307, "emergence"], [307, "of"], [307, "severe"], [307, "acute"], [307, "respiratory"], [307, "syndrome"], [307, "coronavirus"], [307, "2"], [307, "("], [307, "sars"], [307, "-"], [307, "cov-2"], [307, ")"], [307, "lead"], [307, "to"], [307, "a"], [307, "current"], [307, "pandemic"], [307, "of"], [307, "unprecedented"], [307, "scale"], [307, "."], [308, "although"], [308, "diagnostic"], [308, "test"], [308, "be"], [308, "fundamental"], [308, "to"], [308, "the"], [308, "ability"], [308, "to"], [308, "detect"], [308, "and"], [308, "respond"], [308, ","], [308, "overwhelmed"], [308, "healthcare"], [308, "system"], [308, "be"], [308, "already"], [308, "experience"], [308, "shortage"], [308, "of"], [308, "reagent"], [308, "associate"], [308, "with"], [308, "this"], [308, "test"], [308, ","], [308, "call"], [308, "for"], [308, "a"], [308, "lean"], [308, "immediately"], [308, "applicable"], [308, "protocol"], [308, "."], [309, "rna"], [309, "extract"], [309, "of"], [309, "positive"], [309, "sample"], [309, "be"], [309, "test"], [309, "for"], [309, "the"], [309, "presence"], [309, "of"], [309, "sars"], [309, "-"], [309, "cov-2"], [309, "use"], [309, "reverse"], [309, "transcription"], [309, "quantitative"], [309, "polymerase"], [309, "chain"], [309, "reaction"], [309, ","], [309, "alone"], [309, "or"], [309, "in"], [309, "pool"], [309, "of"], [309, "different"], [309, "size"], [309, "("], [309, "2-"], [309, ","], [309, "4-"], [309, ","], [309, "8-"], [309, ","], [309, "16-"], [309, ","], [309, "32-"], [309, ","], [309, "and"], [309, "64"], [309, "-"], [309, "sample"], [309, "pool"], [309, ")"], [309, "with"], [309, "negative"], [309, "sample"], [309, "."], [310, "transport"], [310, "medium"], [310, "of"], [310, "additional"], [310, "3"], [310, "positive"], [310, "sample"], [310, "be"], [310, "also"], [310, "test"], [310, "when"], [310, "mix"], [310, "with"], [310, "transport"], [310, "medium"], [310, "of"], [310, "negative"], [310, "sample"], [310, "in"], [310, "pool"], [310, "of"], [310, "8"], [310, "."], [311, "a"], [311, "single"], [311, "positive"], [311, "sample"], [311, "can"], [311, "be"], [311, "detect"], [311, "in"], [311, "pool"], [311, "of"], [311, "up"], [311, "to"], [311, "32"], [311, "sample"], [311, ","], [311, "use"], [311, "the"], [311, "standard"], [311, "kit"], [311, "and"], [311, "protocol"], [311, ","], [311, "with"], [311, "an"], [311, "estimate"], [311, "false"], [311, "negative"], [311, "rate"], [311, "of"], [311, "10"], [311, "%"], [311, "."], [312, "detection"], [312, "of"], [312, "positive"], [312, "sample"], [312, "dilute"], [312, "in"], [312, "even"], [312, "up"], [312, "to"], [312, "64"], [312, "sample"], [312, "may"], [312, "also"], [312, "be"], [312, "attainable"], [312, ","], [312, "although"], [312, "this"], [312, "may"], [312, "require"], [312, "additional"], [312, "amplification"], [312, "cycle"], [312, "."], [313, "single"], [313, "positive"], [313, "sample"], [313, "can"], [313, "be"], [313, "detect"], [313, "when"], [313, "pool"], [313, "either"], [313, "after"], [313, "or"], [313, "prior"], [313, "to"], [313, "rna"], [313, "extraction"], [313, "."], [314, "as"], [314, "it"], [314, "use"], [314, "the"], [314, "standard"], [314, "protocol"], [314, ","], [314, "reagent"], [314, ","], [314, "and"], [314, "equipment"], [314, ","], [314, "this"], [314, "pooling"], [314, "method"], [314, "can"], [314, "be"], [314, "apply"], [314, "immediately"], [314, "in"], [314, "current"], [314, "clinical"], [314, "testing"], [314, "laboratory"], [314, "."], [315, "we"], [315, "hope"], [315, "that"], [315, "such"], [315, "implementation"], [315, "of"], [315, "a"], [315, "pool"], [315, "test"], [315, "for"], [315, "coronavirus"], [315, "disease"], [315, "2019"], [315, "would"], [315, "allow"], [315, "expand"], [315, "current"], [315, "screening"], [315, "capacity"], [315, ","], [315, "thereby"], [315, "enable"], [315, "the"], [315, "expansion"], [315, "of"], [315, "detection"], [315, "in"], [315, "the"], [315, "community"], [315, ","], [315, "as"], [315, "well"], [315, "as"], [315, "in"], [315, "close"], [315, "organic"], [315, "group"], [315, ","], [315, "such"], [315, "as"], [315, "hospital"], [315, "department"], [315, ","], [315, "army"], [315, "unit"], [315, ","], [315, "or"], [315, "factory"], [315, "shift"], [315, "."], [316, "the"], [316, "coronavirus"], [316, "disease-2019"], [316, "("], [316, "covid-19"], [316, ")"], [316, "which"], [316, "cause"], [316, "by"], [316, "severe"], [316, "acute"], [316, "respiratory"], [316, "syndrome"], [316, "-"], [316, "relate"], [316, "coronavirus"], [316, "("], [316, "sars"], [316, "-"], [316, "cov-2"], [316, ")"], [316, ","], [316, "be"], [316, "a"], [316, "pandemic"], [316, "threat"], [316, "to"], [316, "global"], [316, "public"], [316, "health"], [316, "."], [317, "it"], [317, "have"], [317, "a"], [317, "wide"], [317, "spectrum"], [317, "of"], [317, "clinical"], [317, "manifestation"], [317, "from"], [317, "mild"], [317, "to"], [317, "critical"], [317, "illness"], [317, ","], [317, "the"], [317, "most"], [317, "serious"], [317, "of"], [317, "which"], [317, "be"], [317, "the"], [317, "complication"], [317, "of"], [317, "acute"], [317, "respiratory"], [317, "distress"], [317, "syndrome"], [317, "("], [317, "ard"], [317, ")"], [317, "."], [318, "sars"], [318, "-"], [318, "cov-2"], [318, "infection"], [318, "appear"], [318, "mild"], [318, "in"], [318, "infant"], [318, "and"], [318, "child"], [318, ","], [318, "however"], [318, ","], [318, "in"], [318, "adult"], [318, ","], [318, "it"], [318, "can"], [318, "lead"], [318, "to"], [318, "serious"], [318, "consequence"], [318, "."], [319, "in"], [319, "this"], [319, "review"], [319, ","], [319, "we"], [319, "highlight"], [319, "the"], [319, "difference"], [319, "between"], [319, "the"], [319, "immune"], [319, "response"], [319, "of"], [319, "the"], [319, "lung"], [319, "in"], [319, "child"], [319, "and"], [319, "adult"], [319, ","], [319, "immune"], [319, "dysregulation"], [319, "and"], [319, "their"], [319, "possible"], [319, "role"], [319, "in"], [319, "clinical"], [319, "manifestation"], [319, "in"], [319, "covid-19"], [319, "."], [320, "there"], [320, "be"], [320, "a"], [320, "reduction"], [320, "in"], [320, "population"], [320, "of"], [320, "immunocompetent"], [320, "cell"], [320, "during"], [320, "age"], [320, "and"], [320, "subsequently"], [320, "induce"], [320, "ineffective"], [320, "inflammation"], [320, "in"], [320, "the"], [320, "face"], [320, "of"], [320, "some"], [320, "infection"], [320, "."], [321, "dysregulation"], [321, "in"], [321, "the"], [321, "immune"], [321, "system"], [321, "can"], [321, "lead"], [321, "to"], [321, "an"], [321, "unappropriated"], [321, "local"], [321, "and"], [321, "systemic"], [321, "immune"], [321, "response"], [321, "and"], [321, "subsequently"], [321, "the"], [321, "rapid"], [321, "spread"], [321, "of"], [321, "the"], [321, "virus"], [321, ","], [321, "lead"], [321, "to"], [321, "severe"], [321, "covid-19"], [321, "disease"], [321, "."], [322, "therefore"], [322, ","], [322, "recognize"], [322, "the"], [322, "difference"], [322, "in"], [322, "the"], [322, "immune"], [322, "response"], [322, "of"], [322, "various"], [322, "host"], [322, "as"], [322, "well"], [322, "as"], [322, "to"], [322, "improve"], [322, "the"], [322, "immune"], [322, "system"], [322, "disorder"], [322, "should"], [322, "always"], [322, "be"], [322, "part"], [322, "of"], [322, "research"], [322, "and"], [322, "treatment"], [322, "protocol"], [322, "."], [323, "in"], [323, "the"], [323, "recent"], [323, "sars"], [323, "-"], [323, "cov-2"], [323, "pandemic"], [323, ","], [323, "public"], [323, "health"], [323, "expert"], [323, "have"], [323, "emphasize"], [323, "testing"], [323, ","], [323, "track"], [323, "infected"], [323, "people"], [323, ","], [323, "and"], [323, "trace"], [323, "their"], [323, "contact"], [323, "as"], [323, "an"], [323, "effective"], [323, "strategy"], [323, "to"], [323, "reduce"], [323, "the"], [323, "spread"], [323, "of"], [323, "the"], [323, "virus"], [323, "."], [324, "several"], [324, "diagnostic"], [324, "method"], [324, "be"], [324, "report"], [324, "for"], [324, "detect"], [324, "the"], [324, "coronavirus"], [324, "in"], [324, "clinical"], [324, ","], [324, "research"], [324, ","], [324, "and"], [324, "public"], [324, "health"], [324, "laboratory"], [324, "."], [325, "some"], [325, "test"], [325, "detect"], [325, "the"], [325, "infection"], [325, "directly"], [325, "by"], [325, "detect"], [325, "the"], [325, "viral"], [325, "rna"], [325, "and"], [325, "other"], [325, "test"], [325, "detect"], [325, "the"], [325, "infection"], [325, "indirectly"], [325, "by"], [325, "detect"], [325, "the"], [325, "host"], [325, "antibodie"], [325, "."], [326, "a"], [326, "diagnostic"], [326, "test"], [326, "during"], [326, "the"], [326, "pandemic"], [326, "should"], [326, "help"], [326, "make"], [326, "an"], [326, "appropriate"], [326, "clinical"], [326, "decision"], [326, "in"], [326, "a"], [326, "short"], [326, "period"], [326, "of"], [326, "time"], [326, "."], [327, "recently"], [327, "report"], [327, "diagnostic"], [327, "method"], [327, "for"], [327, "sars"], [327, "-"], [327, "cov-2"], [327, "have"], [327, "vary"], [327, "throughput"], [327, ","], [327, "batch"], [327, "capacity"], [327, ","], [327, "requirement"], [327, "of"], [327, "infrastructure"], [327, "setting"], [327, ","], [327, "analytical"], [327, "performance"], [327, ","], [327, "and"], [327, "turnaround"], [327, "time"], [327, "range"], [327, "from"], [327, "a"], [327, "few"], [327, "minute"], [327, "to"], [327, "several"], [327, "hour"], [327, "."], [328, "these"], [328, "factor"], [328, "should"], [328, "be"], [328, "consider"], [328, "while"], [328, "select"], [328, "a"], [328, "reliable"], [328, "and"], [328, "rapid"], [328, "diagnostic"], [328, "method"], [328, "to"], [328, "help"], [328, "make"], [328, "an"], [328, "appropriate"], [328, "decision"], [328, "and"], [328, "prompt"], [328, "public"], [328, "health"], [328, "intervention"], [328, "."], [329, "this"], [329, "paper"], [329, "review"], [329, "recent"], [329, "sars"], [329, "-"], [329, "cov-2"], [329, "diagnostic"], [329, "method"], [329, "publish"], [329, "in"], [329, "journal"], [329, "and"], [329, "report"], [329, "release"], [329, "by"], [329, "regulatory"], [329, "agency"], [329, "."], [330, "we"], [330, "compare"], [330, "the"], [330, "analytical"], [330, "efficiency"], [330, "include"], [330, "limit"], [330, "of"], [330, "detection"], [330, ","], [330, "sensitivity"], [330, ","], [330, "specificity"], [330, ","], [330, "and"], [330, "throughput"], [330, "."], [331, "in"], [331, "addition"], [331, ","], [331, "we"], [331, "also"], [331, "look"], [331, "into"], [331, "ease"], [331, "of"], [331, "use"], [331, ","], [331, "affordability"], [331, ","], [331, "and"], [331, "availability"], [331, "of"], [331, "accessory"], [331, "."], [332, "finally"], [332, ","], [332, "we"], [332, "discuss"], [332, "the"], [332, "limitation"], [332, "of"], [332, "the"], [332, "method"], [332, "and"], [332, "provide"], [332, "our"], [332, "perspective"], [332, "on"], [332, "priority"], [332, "for"], [332, "future"], [332, "test"], [332, "development"], [332, "."], [333, "the"], [333, "covid-19"], [333, "pandemic"], [333, ","], [333, "cause"], [333, "by"], [333, "severe"], [333, "acute"], [333, "respiratory"], [333, "syndrome"], [333, "coronavirus"], [333, "2"], [333, "("], [333, "sars"], [333, "-"], [333, "cov-2"], [333, ")"], [333, ","], [333, "be"], [333, "a"], [333, "source"], [333, "of"], [333, "significant"], [333, "morbidity"], [333, "and"], [333, "death"], [333, "worldwide"], [333, ","], [333, "and"], [333, "effective"], [333, "treatment"], [333, "be"], [333, "urgently"], [333, "nee"], [333, "."], [334, "clinical"], [334, "trial"], [334, "have"], [334, "focus"], [334, "largely"], [334, "on"], [334, "direct"], [334, "antiviral"], [334, "therapy"], [334, "or"], [334, "on"], [334, "immunomodulation"], [334, "in"], [334, "patient"], [334, "with"], [334, "severe"], [334, "manifestation"], [334, "of"], [334, "covid-19"], [334, "."], [335, "one"], [335, "therapeutic"], [335, "approach"], [335, "that"], [335, "remain"], [335, "to"], [335, "be"], [335, "clinically"], [335, "investigate"], [335, "be"], [335, "disruption"], [335, "of"], [335, "the"], [335, "host"], [335, "-"], [335, "virus"], [335, "relationship"], [335, "through"], [335, "amino"], [335, "acid"], [335, "restriction"], [335, ","], [335, "a"], [335, "strategy"], [335, "use"], [335, "successfully"], [335, "in"], [335, "the"], [335, "setting"], [335, "of"], [335, "cancer"], [335, "treatment"], [335, "."], [336, "arginine"], [336, "be"], [336, "an"], [336, "amino"], [336, "acid"], [336, "that"], [336, "have"], [336, "be"], [336, "show"], [336, "in"], [336, "nonclinical"], [336, "study"], [336, "to"], [336, "be"], [336, "essential"], [336, "in"], [336, "the"], [336, "life"], [336, "cycle"], [336, "of"], [336, "many"], [336, "virus"], [336, "."], [337, "therefore"], [337, ","], [337, "arginine"], [337, "depletion"], [337, "may"], [337, "be"], [337, "an"], [337, "effective"], [337, "therapeutic"], [337, "approach"], [337, "against"], [337, "sars"], [337, "-"], [337, "cov-2"], [337, "."], [338, "several"], [338, "arginine"], [338, "-"], [338, "metabolize"], [338, "enzyme"], [338, "in"], [338, "clinical"], [338, "development"], [338, "may"], [338, "be"], [338, "a"], [338, "viable"], [338, "approach"], [338, "to"], [338, "induce"], [338, "a"], [338, "low"], [338, "arginine"], [338, "environment"], [338, "to"], [338, "treat"], [338, "covid-19"], [338, "and"], [338, "other"], [338, "viral"], [338, "disease"], [338, "."], [339, "herein"], [339, ","], [339, "we"], [339, "explore"], [339, "the"], [339, "rationale"], [339, "for"], [339, "arginine"], [339, "depletion"], [339, "as"], [339, "a"], [339, "therapeutic"], [339, "approach"], [339, "for"], [339, "covid-19"], [339, "."], [340, "asymptomatic"], [340, "individual"], [340, "with"], [340, "coronavirus"], [340, "disease"], [340, "("], [340, "covid-19"], [340, ")"], [340, "have"], [340, "be"], [340, "identify"], [340, "via"], [340, "nucleic"], [340, "acid"], [340, "testing"], [340, "for"], [340, "severe"], [340, "acute"], [340, "respiratory"], [340, "syndrome"], [340, "coronavirus"], [340, "2"], [340, "("], [340, "sars"], [340, "-"], [340, "cov-2"], [340, ")"], [340, ";"], [340, "however"], [340, ","], [340, "the"], [340, "epidemiologic"], [340, "characteristic"], [340, "and"], [340, "viral"], [340, "shedding"], [340, "pattern"], [340, "of"], [340, "asymptomatic"], [340, "patient"], [340, "remain"], [340, "largely"], [340, "unknown"], [340, "."], [341, "in"], [341, "this"], [341, "study"], [341, ","], [341, "serological"], [341, "testing"], [341, "be"], [341, "apply"], [341, "when"], [341, "identify"], [341, "nine"], [341, "asymptomatic"], [341, "case"], [341, "of"], [341, "covid-19"], [341, "who"], [341, "show"], [341, "persistent"], [341, "negative"], [341, "rt"], [341, "-"], [341, "pcr"], [341, "test"], [341, "result"], [341, "for"], [341, "sars"], [341, "-"], [341, "cov-2"], [341, "nucleic"], [341, "acid"], [341, "and"], [341, "no"], [341, "symptom"], [341, "of"], [341, "covid-19"], [341, "."], [342, "two"], [342, "asymptomatic"], [342, "case"], [342, "be"], [342, "presume"], [342, "to"], [342, "be"], [342, "index"], [342, "patient"], [342, "who"], [342, "have"], [342, "clear"], [342, "the"], [342, "virus"], [342, "when"], [342, "their"], [342, "close"], [342, "contact"], [342, "develop"], [342, "symptom"], [342, "of"], [342, "covid-19"], [342, "."], [343, "three"], [343, "of"], [343, "the"], [343, "asymptomatic"], [343, "case"], [343, "be"], [343, "local"], [343, "individual"], [343, "who"], [343, "spontaneously"], [343, "recover"], [343, "before"], [343, "their"], [343, "presume"], [343, "index"], [343, "patient"], [343, "develop"], [343, "symptom"], [343, "of"], [343, "covid-19"], [343, "."], [344, "this"], [344, "report"], [344, "present"], [344, "the"], [344, "epidemiologic"], [344, "and"], [344, "clinical"], [344, "characteristic"], [344, "of"], [344, "asymptomatic"], [344, "individual"], [344, "with"], [344, "sars"], [344, "-"], [344, "cov-2"], [344, "infection"], [344, "that"], [344, "be"], [344, "undetecte"], [344, "on"], [344, "rt"], [344, "-"], [344, "pcr"], [344, "test"], [344, "in"], [344, "previous"], [344, "epidemiologic"], [344, "investigation"], [344, "probably"], [344, "due"], [344, "to"], [344, "the"], [344, "transient"], [344, "viral"], [344, "shed"], [344, "duration"], [344, "."], [345, "severe"], [345, "acute"], [345, "respiratory"], [345, "syndrome"], [345, "coronavirus"], [345, "2"], [345, "("], [345, "sars"], [345, "-"], [345, "cov-2"], [345, ")"], [345, "be"], [345, "a"], [345, "new"], [345, "member"], [345, "of"], [345, "the"], [345, "coronavirus"], [345, "family"], [345, "that"], [345, "can"], [345, "cause"], [345, "coronavirus"], [345, "disease"], [345, "2019"], [345, "("], [345, "covid-19"], [345, ")"], [345, "."], [346, "covid-9"], [346, "have"], [346, "become"], [346, "a"], [346, "global"], [346, "pandemic"], [346, "with"], [346, "severe"], [346, "health"], [346, "issue"], [346, "around"], [346, "the"], [346, "world"], [346, "."], [347, "identify"], [347, "the"], [347, "accurate"], [347, "immunopathogenesis"], [347, "of"], [347, "the"], [347, "covid-19"], [347, "and"], [347, "the"], [347, "immune"], [347, "response"], [347, "against"], [347, "sars"], [347, "-"], [347, "cov-2"], [347, "be"], [347, "necessary"], [347, "for"], [347, "the"], [347, "development"], [347, "of"], [347, "therapeutic"], [347, "approach"], [347, "and"], [347, "rational"], [347, "drug"], [347, "design"], [347, "."], [348, "this"], [348, "paper"], [348, "aim"], [348, "to"], [348, "overview"], [348, "the"], [348, "update"], [348, "clinical"], [348, "datum"], [348, "on"], [348, "the"], [348, "immunopathogenesis"], [348, "of"], [348, "the"], [348, "covid-19"], [348, "and"], [348, "review"], [348, "the"], [348, "innate"], [348, "and"], [348, "adaptive"], [348, "immune"], [348, "response"], [348, "to"], [348, "sars"], [348, "-"], [348, "cov-2"], [348, "."], [349, "also"], [349, ","], [349, "challenge"], [349, "of"], [349, "the"], [349, "immune"], [349, "response"], [349, "to"], [349, "sars"], [349, "-"], [349, "cov-2"], [349, "lead"], [349, "to"], [349, "dysfunctional"], [349, "immune"], [349, "response"], [349, "and"], [349, "their"], [349, "contribution"], [349, "to"], [349, "the"], [349, "progression"], [349, "of"], [349, "the"], [349, "disease"], [349, "have"], [349, "be"], [349, "discuss"], [349, "."], [350, "to"], [350, "achieve"], [350, "a"], [350, "more"], [350, "efficient"], [350, "immune"], [350, "response"], [350, ","], [350, "multiple"], [350, "method"], [350, "could"], [350, "be"], [350, "apply"], [350, ","], [350, "include"], [350, "regulation"], [350, "of"], [350, "the"], [350, "immune"], [350, "response"], [350, ","], [350, "augmentation"], [350, "of"], [350, "the"], [350, "immune"], [350, "system"], [350, "against"], [350, "the"], [350, "virus"], [350, ","], [350, "inhibition"], [350, "of"], [350, "the"], [350, "dysfunctional"], [350, "immune"], [350, "checkpoint"], [350, ","], [350, "and"], [350, "inhibition"], [350, "of"], [350, "the"], [350, "viral"], [350, "replication"], [350, "/"], [350, "infection"], [350, "."], [351, "base"], [351, "on"], [351, "the"], [351, "immune"], [351, "response"], [351, "against"], [351, "sars"], [351, "-"], [351, "cov-2"], [351, "and"], [351, "its"], [351, "dysfunction"], [351, ","], [351, "we"], [351, "introduce"], [351, "potential"], [351, "immunotherapy"], [351, "as"], [351, "well"], [351, "as"], [351, "review"], [351, "recruit"], [351, "/"], [351, "complete"], [351, "clinical"], [351, "trial"], [351, "of"], [351, "covid-19"], [351, "."], [352, "covid-19"], [352, "be"], [352, "a"], [352, "new"], [352, "contagious"], [352, "disease"], [352, "cause"], [352, "by"], [352, "a"], [352, "new"], [352, "coronavirus"], [352, "know"], [352, "as"], [352, "severe"], [352, "acute"], [352, "respiratory"], [352, "syndrome"], [352, "coronavirus"], [352, "2"], [352, "("], [352, "sars"], [352, "-"], [352, "cov-2"], [352, ")"], [352, "."], [353, "covid-19"], [353, "be"], [353, "a"], [353, "disease"], [353, "that"], [353, "have"], [353, "reach"], [353, "every"], [353, "continent"], [353, "in"], [353, "the"], [353, "world"], [353, ";"], [353, "it"], [353, "have"], [353, "overload"], [353, "the"], [353, "medical"], [353, "system"], [353, "worldwide"], [353, "and"], [353, "it"], [353, "have"], [353, "be"], [353, "declare"], [353, "a"], [353, "pandemic"], [353, "by"], [353, "the"], [353, "world"], [353, "health"], [353, "organization"], [353, "."], [354, "currently"], [354, "there"], [354, "be"], [354, "no"], [354, "definite"], [354, "treatment"], [354, "for"], [354, "covid-19"], [354, "."], [355, "we"], [355, "realize"], [355, "that"], [355, "host"], [355, "immunity"], [355, "be"], [355, "a"], [355, "critical"], [355, "factor"], [355, "in"], [355, "the"], [355, "outcome"], [355, "of"], [355, "coronavirus"], [355, "2"], [355, "infection"], [355, "."], [356, "here"], [356, ","], [356, "however"], [356, ","], [356, "we"], [356, "review"], [356, "the"], [356, "pathophysiology"], [356, "of"], [356, "the"], [356, "disease"], [356, "with"], [356, "a"], [356, "focus"], [356, "on"], [356, "search"], [356, "for"], [356, "what"], [356, "we"], [356, "can"], [356, "do"], [356, "to"], [356, "combat"], [356, "this"], [356, "new"], [356, "disease"], [356, "."], [357, "from"], [357, "this"], [357, ","], [357, "we"], [357, "find"], [357, "that"], [357, "coronavirus"], [357, "be"], [357, "sensitive"], [357, "to"], [357, "heat"], [357, "."], [358, "we"], [358, "have"], [358, "thus"], [358, "focus"], [358, "on"], [358, "this"], [358, "area"], [358, "of"], [358, "vulnerability"], [358, "of"], [358, "the"], [358, "virus"], [358, "."], [359, "the"], [359, "emphasis"], [359, "of"], [359, "this"], [359, "hypothesis"], [359, "be"], [359, "on"], [359, "the"], [359, "action"], [359, "of"], [359, "body"], [359, "heat"], [359, "-"], [359, "internal"], [359, "("], [359, "fever"], [359, ")"], [359, "and"], [359, "external"], [359, "("], [359, "heat"], [359, "treatment)-in"], [359, "activate"], [359, "the"], [359, "immune"], [359, "system"], [359, "and"], [359, "its"], [359, "antiviral"], [359, "activity"], [359, ","], [359, "and"], [359, "specifically"], [359, "related"], [359, "to"], [359, "the"], [359, "coronavirus"], [359, "."], [360, "we"], [360, "hypothesize"], [360, "from"], [360, "this"], [360, "review"], [360, "that"], [360, "heat"], [360, "treatment"], [360, "have"], [360, "the"], [360, "potential"], [360, "to"], [360, "prevent"], [360, "covid-19"], [360, "and"], [360, "to"], [360, "decrease"], [360, "the"], [360, "severity"], [360, "of"], [360, "mild"], [360, "and"], [360, "moderate"], [360, "case"], [360, "of"], [360, "coronavirus"], [360, "."], [361, "we"], [361, "propose"], [361, "heat"], [361, "treatment"], [361, "for"], [361, "this"], [361, "uncontrolled"], [361, "worldwide"], [361, "coronavirus"], [361, "pandemic"], [361, "while"], [361, "study"], [361, "be"], [361, "be"], [361, "do"], [361, "to"], [361, "test"], [361, "the"], [361, "effectiveness"], [361, "of"], [361, "heat"], [361, "treatment"], [361, "in"], [361, "the"], [361, "prevention"], [361, "and"], [361, "treatment"], [361, "of"], [361, "covid-19"], [361, "."], [362, "every"], [362, "day"], [362, "additional"], [362, "confirmed"], [362, "case"], [362, "of"], [362, "sars"], [362, "-"], [362, "cov-2"], [362, "reinfection"], [362, "be"], [362, "be"], [362, "report"], [362, "across"], [362, "the"], [362, "globe"], [362, "."], [363, "in"], [363, "the"], [363, "netherland"], [363, "more"], [363, "than"], [363, "50"], [363, "case"], [363, "of"], [363, "probable"], [363, "reinfection"], [363, "have"], [363, "be"], [363, "identify"], [363, "."], [364, "with"], [364, "more"], [364, "than"], [364, "500"], [364, "thousand"], [364, "people"], [364, "in"], [364, "the"], [364, "netherland"], [364, "who"], [364, "have"], [364, "be"], [364, "infect"], [364, "with"], [364, "sars"], [364, "-"], [364, "cov-2"], [364, "up"], [364, "till"], [364, "now"], [364, "this"], [364, "number"], [364, "do"], [364, "seem"], [364, "to"], [364, "be"], [364, "quite"], [364, "low"], [364, "."], [365, "still"], [365, ","], [365, "important"], [365, "question"], [365, "have"], [365, "to"], [365, "be"], [365, "ask"], [365, "."], [366, "how"], [366, "do"], [366, "we"], [366, "define"], [366, "reinfection"], [366, "and"], [366, "how"], [366, "do"], [366, "these"], [366, "reinfection"], [366, "compare"], [366, "to"], [366, "other"], [366, "("], [366, "corona"], [366, ")"], [366, "virus"], [366, "?"], [367, "what"], [367, "be"], [367, "the"], [367, "immunological"], [367, "significance"], [367, "?"], [368, "what"], [368, "be"], [368, "the"], [368, "duration"], [368, "of"], [368, "protective"], [368, "immunity"], [368, "?"], [369, "and"], [369, "what"], [369, "do"], [369, "covid-19"], [369, "reinfection"], [369, "mean"], [369, "for"], [369, "the"], [369, "prevention"], [369, "and"], [369, "development"], [369, "of"], [369, "a"], [369, "vaccine"], [369, "?"], [370, "the"], [370, "describe"], [370, "case"], [370, "of"], [370, "re"], [370, "-"], [370, "infection"], [370, "do"], [370, "teach"], [370, "we"], [370, "that"], [370, "a"], [370, "sars"], [370, "-"], [370, "cov-2"], [370, "vaccine"], [370, "should"], [370, "also"], [370, "be"], [370, "consider"], [370, "for"], [370, "people"], [370, "with"], [370, "a"], [370, "document"], [370, "covid-19"], [370, "infection"], [370, "in"], [370, "the"], [370, "past"], [370, "and"], [370, "that"], [370, "general"], [370, "precaution"], [370, ","], [370, "such"], [370, "as"], [370, "the"], [370, "use"], [370, "of"], [370, "face"], [370, "mask"], [370, "and"], [370, "social"], [370, "distancing"], [370, ","], [370, "still"], [370, "apply"], [370, "to"], [370, "those"], [370, "with"], [370, "a"], [370, "previous"], [370, "sars"], [370, "-"], [370, "cov-2"], [370, "infection"], [370, "."], [371, "the"], [371, "recent"], [371, "pandemic"], [371, "have"], [371, "pose"], [371, "perhaps"], [371, "the"], [371, "big"], [371, "challenge"], [371, "for"], [371, "pcr"], [371, "to"], [371, "date"], [371, "."], [372, "be"], [372, "pcr"], [372, "likely"], [372, "to"], [372, "be"], [372, "replace"], [372, "or"], [372, "will"], [372, "it"], [372, "continue"], [372, "to"], [372, "stand"], [372, "the"], [372, "test"], [372, "of"], [372, "time"], [372, "?"], [373, "["], [373, "formula"], [373, ":"], [373, "see"], [373, "text"], [373, "]"], [373, "."], [374, "the"], [374, "recently"], [374, "emerge"], [374, "severe"], [374, "acute"], [374, "respiratory"], [374, "syndrome"], [374, "coronavirus-2"], [374, "("], [374, "sars"], [374, "-"], [374, "cov-2"], [374, ")"], [374, "spread"], [374, "all"], [374, "over"], [374, "the"], [374, "world"], [374, "rapidly"], [374, "and"], [374, "cause"], [374, "a"], [374, "global"], [374, "pandemic"], [374, "."], [375, "to"], [375, "prevent"], [375, "the"], [375, "virus"], [375, "from"], [375, "spread"], [375, "to"], [375, "more"], [375, "individual"], [375, ","], [375, "it"], [375, "be"], [375, "of"], [375, "great"], [375, "importance"], [375, "to"], [375, "identify"], [375, "and"], [375, "isolate"], [375, "infect"], [375, "individual"], [375, "through"], [375, "testing"], [375, "."], [376, "reverse"], [376, "transcription"], [376, "-"], [376, "quantitative"], [376, "polymerase"], [376, "chain"], [376, "reaction"], [376, "("], [376, "rt"], [376, "-"], [376, "qpcr"], [376, ")"], [376, "be"], [376, "the"], [376, "gold"], [376, "standard"], [376, "method"], [376, "for"], [376, "the"], [376, "diagnosis"], [376, "of"], [376, "coronavirus"], [376, "disease"], [376, "("], [376, "covid-19"], [376, ")"], [376, "worldwide"], [376, "."], [377, "however"], [377, ","], [377, "perform"], [377, "rt"], [377, "-"], [377, "qpcr"], [377, "be"], [377, "limit"], [377, "to"], [377, "centralized"], [377, "laboratory"], [377, "because"], [377, "of"], [377, "the"], [377, "need"], [377, "for"], [377, "sophisticated"], [377, "laboratory"], [377, "equipment"], [377, "and"], [377, "skilled"], [377, "personnel"], [377, "."], [378, "far"], [378, ","], [378, "it"], [378, "can"], [378, "sometimes"], [378, "give"], [378, "false"], [378, "negative"], [378, "or"], [378, "uncertain"], [378, "result"], [378, "."], [379, "recently"], [379, ","], [379, "new"], [379, "method"], [379, "have"], [379, "be"], [379, "develop"], [379, "for"], [379, "nucleic"], [379, "acid"], [379, "detection"], [379, "and"], [379, "pathogen"], [379, "diagnosis"], [379, "use"], [379, "crispr"], [379, "-"], [379, "cas"], [379, "system"], [379, "."], [380, "these"], [380, "method"], [380, "present"], [380, "rapid"], [380, "and"], [380, "cost"], [380, "-"], [380, "effective"], [380, "diagnostic"], [380, "platform"], [380, "that"], [380, "provide"], [380, "high"], [380, "sensitivity"], [380, "and"], [380, "specificity"], [380, "without"], [380, "the"], [380, "need"], [380, "for"], [380, "complex"], [380, "instrumentation"], [380, "."], [381, "use"], [381, "the"], [381, "crispr"], [381, "-"], [381, "base"], [381, "sars"], [381, "-"], [381, "cov-2"], [381, "detection"], [381, "method"], [381, ","], [381, "it"], [381, "be"], [381, "possible"], [381, "to"], [381, "increase"], [381, "the"], [381, "number"], [381, "of"], [381, "daily"], [381, "test"], [381, "in"], [381, "exist"], [381, "laboratory"], [381, ","], [381, "reduce"], [381, "false"], [381, "negative"], [381, "or"], [381, "uncertain"], [381, "result"], [381, "rate"], [381, "obtain"], [381, "with"], [381, "rt"], [381, "-"], [381, "qpcr"], [381, ","], [381, "and"], [381, "perform"], [381, "testing"], [381, "in"], [381, "resource"], [381, "-"], [381, "limit"], [381, "setting"], [381, "or"], [381, "at"], [381, "point"], [381, "of"], [381, "need"], [381, "where"], [381, "perform"], [381, "rt"], [381, "-"], [381, "qpcr"], [381, "be"], [381, "not"], [381, "feasible"], [381, "."], [382, "here"], [382, ","], [382, "we"], [382, "briefly"], [382, "describe"], [382, "the"], [382, "rt"], [382, "-"], [382, "qpcr"], [382, "method"], [382, ","], [382, "and"], [382, "discuss"], [382, "its"], [382, "limitation"], [382, "in"], [382, "meet"], [382, "the"], [382, "current"], [382, "diagnostic"], [382, "need"], [382, "."], [383, "we"], [383, "explain"], [383, "how"], [383, "the"], [383, "unique"], [383, "property"], [383, "of"], [383, "various"], [383, "crispr"], [383, "-"], [383, "associate"], [383, "enzyme"], [383, "be"], [383, "utilize"], [383, "for"], [383, "nucleic"], [383, "acid"], [383, "detection"], [383, "and"], [383, "pathogen"], [383, "diagnosis"], [383, "."], [384, "then"], [384, ","], [384, "we"], [384, "highlight"], [384, "the"], [384, "important"], [384, "feature"], [384, "of"], [384, "crispr"], [384, "-"], [384, "base"], [384, "diagnostic"], [384, "method"], [384, "develop"], [384, "for"], [384, "sars"], [384, "-"], [384, "cov-2"], [384, "detection"], [384, "."], [385, "finally"], [385, ","], [385, "we"], [385, "examine"], [385, "the"], [385, "advantage"], [385, "and"], [385, "limitation"], [385, "of"], [385, "these"], [385, "method"], [385, ","], [385, "and"], [385, "discuss"], [385, "how"], [385, "they"], [385, "can"], [385, "contribute"], [385, "to"], [385, "improve"], [385, "the"], [385, "efficiency"], [385, "of"], [385, "the"], [385, "current"], [385, "testing"], [385, "system"], [385, "for"], [385, "combat"], [385, "sars"], [385, "-"], [385, "cov-2"], [385, "."], [386, "the"], [386, "emergence"], [386, "of"], [386, "severe"], [386, "acute"], [386, "respiratory"], [386, "syndrome"], [386, "coronavirus"], [386, "2"], [386, "("], [386, "sars"], [386, "-"], [386, "cov-2"], [386, ")"], [386, "mark"], [386, "the"], [386, "third"], [386, "highly"], [386, "pathogenic"], [386, "coronavirus"], [386, "to"], [386, "spill"], [386, "over"], [386, "into"], [386, "the"], [386, "human"], [386, "population"], [386, "."], [387, "sars"], [387, "-"], [387, "cov-2"], [387, "be"], [387, "highly"], [387, "transmissible"], [387, "with"], [387, "a"], [387, "broad"], [387, "tissue"], [387, "tropism"], [387, "that"], [387, "be"], [387, "likely"], [387, "perpetuate"], [387, "the"], [387, "pandemic"], [387, "."], [388, "however"], [388, ","], [388, "important"], [388, "question"], [388, "remain"], [388, "regard"], [388, "its"], [388, "transmissibility"], [388, "and"], [388, "pathogenesis"], [388, "."], [389, "in"], [389, "this"], [389, "review"], [389, ","], [389, "we"], [389, "summarize"], [389, "current"], [389, "sars"], [389, "-"], [389, "cov-2"], [389, "research"], [389, ","], [389, "with"], [389, "an"], [389, "emphasis"], [389, "on"], [389, "transmission"], [389, ","], [389, "tissue"], [389, "tropism"], [389, ","], [389, "viral"], [389, "pathogenesis"], [389, ","], [389, "and"], [389, "immune"], [389, "antagonism"], [389, "."], [390, "we"], [390, "far"], [390, "present"], [390, "advance"], [390, "in"], [390, "animal"], [390, "model"], [390, "that"], [390, "be"], [390, "important"], [390, "for"], [390, "understand"], [390, "the"], [390, "pathogenesis"], [390, "of"], [390, "sars"], [390, "-"], [390, "cov-2"], [390, ","], [390, "vaccine"], [390, "development"], [390, ","], [390, "and"], [390, "therapeutic"], [390, "testing"], [390, "."], [391, "when"], [391, "necessary"], [391, ","], [391, "comparison"], [391, "be"], [391, "make"], [391, "from"], [391, "study"], [391, "with"], [391, "sars"], [391, "to"], [391, "provide"], [391, "further"], [391, "perspective"], [391, "on"], [391, "coronavirus"], [391, "infectious"], [391, "disease"], [391, "2019"], [391, "("], [391, "covid-19"], [391, ")"], [391, ","], [391, "as"], [391, "well"], [391, "as"], [391, "draw"], [391, "inference"], [391, "for"], [391, "future"], [391, "investigation"], [391, "."], [392, "the"], [392, "coronavirus"], [392, "disease-2019"], [392, "("], [392, "covid-19"], [392, ")"], [392, "cause"], [392, "by"], [392, "the"], [392, "novel"], [392, "coronavirus"], [392, "severe"], [392, "acute"], [392, "respiratory"], [392, "syndrome"], [392, "coronavirus-2"], [392, "("], [392, "sars"], [392, "-"], [392, "cov-2"], [392, ")"], [392, "have"], [392, "rapidly"], [392, "develop"], [392, "into"], [392, "a"], [392, "global"], [392, "pneumonia"], [392, "pandemic"], [392, "."], [393, "cardiovascular"], [393, "disease"], [393, "be"], [393, "the"], [393, "major"], [393, "comorbidity"], [393, "of"], [393, "covid-19"], [393, "patient"], [393, "and"], [393, "be"], [393, "closely"], [393, "relate"], [393, "to"], [393, "the"], [393, "severity"], [393, "of"], [393, "covid-19"], [393, "."], [394, "sars"], [394, "-"], [394, "cov-2"], [394, "infection"], [394, "can"], [394, "directly"], [394, "or"], [394, "indirectly"], [394, "cause"], [394, "a"], [394, "series"], [394, "of"], [394, "cardiac"], [394, "complication"], [394, ","], [394, "include"], [394, "acute"], [394, "myocardial"], [394, "injury"], [394, "and"], [394, "myocarditis"], [394, ","], [394, "heart"], [394, "failure"], [394, "and"], [394, "cardiac"], [394, "arrest"], [394, ","], [394, "arrhythmia"], [394, ","], [394, "acute"], [394, "myocardial"], [394, "infarction"], [394, ","], [394, "cardiogenic"], [394, "shock"], [394, ","], [394, "takotsubo"], [394, "cardiomyopathy"], [394, ","], [394, "and"], [394, "coagulation"], [394, "abnormality"], [394, "."], [395, "intensive"], [395, "research"], [395, "on"], [395, "the"], [395, "sars"], [395, "-"], [395, "cov-2"], [395, "-"], [395, "associate"], [395, "cardiovascular"], [395, "complication"], [395, "be"], [395, "urgently"], [395, "nee"], [395, "to"], [395, "elucidate"], [395, "its"], [395, "exact"], [395, "mechanism"], [395, "and"], [395, "to"], [395, "identify"], [395, "potential"], [395, "drug"], [395, "target"], [395, ","], [395, "which"], [395, "will"], [395, "help"], [395, "to"], [395, "formulate"], [395, "effective"], [395, "prevention"], [395, "and"], [395, "treatment"], [395, "strategy"], [395, "."], [396, "hence"], [396, ","], [396, "this"], [396, "review"], [396, "will"], [396, "summarize"], [396, "recent"], [396, "progress"], [396, "regard"], [396, "the"], [396, "effect"], [396, "of"], [396, "covid-19"], [396, "on"], [396, "the"], [396, "cardiovascular"], [396, "system"], [396, "and"], [396, "describe"], [396, "the"], [396, "underlie"], [396, "mechanism"], [396, "of"], [396, "cardiovascular"], [396, "injury"], [396, "cause"], [396, "by"], [396, "sars"], [396, "-"], [396, "cov-2"], [396, "."], [397, "innate"], [397, "immunity"], [397, "impairment"], [397, "lead"], [397, "to"], [397, "disruption"], [397, "in"], [397, "cascade"], [397, "of"], [397, "signal"], [397, "pathway"], [397, "upregulate"], [397, "pro"], [397, "-"], [397, "inflammatory"], [397, "cytokine"], [397, ","], [397, "diminish"], [397, "interferon"], [397, ","], [397, "deplete"], [397, "natural"], [397, "killer"], [397, "cell"], [397, "and"], [397, "activate"], [397, "reactive"], [397, "oxygen"], [397, "specie"], [397, "production"], [397, "."], [398, "these"], [398, "condition"], [398, "severely"], [398, "affect"], [398, "body"], [398, "'s"], [398, "ability"], [398, "to"], [398, "fight"], [398, "against"], [398, "infectious"], [398, "disease"], [398, "and"], [398, "also"], [398, "play"], [398, "a"], [398, "pivotal"], [398, "role"], [398, "in"], [398, "disease"], [398, "progression"], [398, "."], [399, "here"], [399, ","], [399, "in"], [399, "emphasis"], [399, "be"], [399, "on"], [399, "nutritional"], [399, "immunity"], [399, "for"], [399, "regulate"], [399, "effective"], [399, "innate"], [399, "immune"], [399, "response"], [399, "for"], [399, "combat"], [399, "against"], [399, "infectious"], [399, "disease"], [399, "like"], [399, "novel"], [399, "coronavirus"], [399, "disease"], [399, "("], [399, "covid"], [399, "19"], [399, ")"], [399, "."], [400, "draw"], [400, "from"], [400, "discovery"], [400, "on"], [400, "in"], [400, "-"], [400, "vitro"], [400, "experiment"], [400, ","], [400, "animal"], [400, "model"], [400, "and"], [400, "human"], [400, "trial"], [400, ","], [400, "tea"], [400, "polyphenol"], [400, ","], [400, "micronutrient"], [400, ","], [400, "and"], [400, "vitamin"], [400, "have"], [400, "the"], [400, "potential"], [400, "to"], [400, "modulate"], [400, "and"], [400, "enhance"], [400, "innate"], [400, "immune"], [400, "response"], [400, "."], [401, "this"], [401, "article"], [401, "provide"], [401, "a"], [401, "comprehensive"], [401, "review"], [401, "on"], [401, "tea"], [401, "("], [401, "l"], [401, "infusion"], [401, "("], [401, "a"], [401, "hot"], [401, "water"], [401, "extract"], [401, "of"], [401, "dry"], [401, "process"], [401, "tea"], [401, "leave"], [401, "prepare"], [401, "from"], [401, "young"], [401, "shoot"], [401, "of"], [401, "tea"], [401, "plant"], [401, ")"], [401, "as"], [401, "an"], [401, "innate"], [401, "immunity"], [401, "modulator"], [401, "."], [402, "tea"], [402, "infusion"], [402, "be"], [402, "rich"], [402, "in"], [402, "polyphenol"], [402, ";"], [402, "epigallocatechin"], [402, "gallate"], [402, "("], [402, "egcg"], [402, ")"], [402, "and"], [402, "theaflavin"], [402, "("], [402, "tf"], [402, ")"], [402, ","], [402, "major"], [402, "green"], [402, "and"], [402, "black"], [402, "tea"], [402, "polyphenol"], [402, ","], [402, "respectively"], [402, "."], [403, "study"], [403, "show"], [403, "their"], [403, "immunomodulatory"], [403, "competence"], [403, "."], [404, "tea"], [404, "infusion"], [404, "be"], [404, "also"], [404, "rich"], [404, "in"], [404, "alkaloid"], [404, ";"], [404, "caffeine"], [404, "and"], [404, "its"], [404, "intermediate"], [404, ","], [404, "theophylline"], [404, "and"], [404, "theobromine"], [404, ","], [404, "which"], [404, "have"], [404, "anti"], [404, "-"], [404, "inflammatory"], [404, "property"], [404, "."], [405, "tea"], [405, "plant"], [405, "be"], [405, "an"], [405, "acidophilic"], [405, "perennial"], [405, "crop"], [405, "can"], [405, "accumulate"], [405, "different"], [405, "micronutrient"], [405, ","], [405, "."], [405, ","], [405, "copper"], [405, "("], [405, "cu"], [405, ")"], [405, ","], [405, "iron"], [405, "("], [405, "fe"], [405, ")"], [405, ","], [405, "manganese"], [405, "("], [405, "mn"], [405, ")"], [405, ","], [405, "selenium"], [405, "("], [405, "se"], [405, ")"], [405, ","], [405, "and"], [405, "zinc"], [405, "("], [405, "zn"], [405, ")"], [405, "from"], [405, "grow"], [405, "medium"], [405, ","], [405, "i.e."], [405, ","], [405, "from"], [405, "soil"], [405, ","], [405, "which"], [405, "lead"], [405, "to"], [405, "their"], [405, "considerable"], [405, "presence"], [405, "in"], [405, "tea"], [405, "infusion"], [405, "."], [406, "micronutrient"], [406, "be"], [406, "integral"], [406, "part"], [406, "of"], [406, "innate"], [406, "immune"], [406, "response"], [406, "."], [407, "overall"], [407, ","], [407, "this"], [407, "review"], [407, "present"], [407, "tea"], [407, "infusion"], [407, "as"], [407, "an"], [407, "important"], [407, "source"], [407, "of"], [407, "nutritional"], [407, "immunity"], [407, "which"], [407, "can"], [407, "enhance"], [407, "innate"], [407, "immune"], [407, "response"], [407, "in"], [407, "order"], [407, "to"], [407, "mitigate"], [407, "the"], [407, "unprecedented"], [407, "covid-19"], [407, "pandemic"], [407, "."], [408, "for"], [408, "covid-19"], [408, ","], [408, "it"], [408, "be"], [408, "vital"], [408, "to"], [408, "understand"], [408, "if"], [408, "quarantine"], [408, "short"], [408, "than"], [408, "14"], [408, "day"], [408, "can"], [408, "be"], [408, "equally"], [408, "effective"], [408, "with"], [408, "judiciously"], [408, "deploy"], [408, "testing"], [408, "."], [409, "here"], [409, ","], [409, "we"], [409, "develop"], [409, "a"], [409, "mathematical"], [409, "model"], [409, "that"], [409, "quantify"], [409, "the"], [409, "probability"], [409, "of"], [409, "post"], [409, "-"], [409, "quarantine"], [409, "transmission"], [409, "incorporate"], [409, "test"], [409, "into"], [409, "travel"], [409, "quarantine"], [409, ","], [409, "quarantine"], [409, "of"], [409, "trace"], [409, "contact"], [409, "with"], [409, "an"], [409, "unknown"], [409, "time"], [409, "of"], [409, "infection"], [409, ","], [409, "and"], [409, "quarantine"], [409, "of"], [409, "case"], [409, "with"], [409, "a"], [409, "know"], [409, "time"], [409, "of"], [409, "exposure"], [409, "."], [410, "we"], [410, "find"], [410, "that"], [410, "testing"], [410, "on"], [410, "exit"], [410, "("], [410, "or"], [410, "entry"], [410, "and"], [410, "exit"], [410, ")"], [410, "can"], [410, "reduce"], [410, "the"], [410, "duration"], [410, "of"], [410, "a"], [410, "14"], [410, "-"], [410, "day"], [410, "quarantine"], [410, "by"], [410, "50"], [410, "%"], [410, ","], [410, "while"], [410, "test"], [410, "on"], [410, "entry"], [410, "shorten"], [410, "quarantine"], [410, "by"], [410, "at"], [410, "most"], [410, "one"], [410, "day"], [410, "."], [411, "in"], [411, "a"], [411, "real"], [411, "-"], [411, "world"], [411, "test"], [411, "of"], [411, "our"], [411, "theory"], [411, "apply"], [411, "to"], [411, "offshore"], [411, "oil"], [411, "rig"], [411, "employee"], [411, ","], [411, "47"], [411, "positive"], [411, "be"], [411, "obtain"], [411, "with"], [411, "testing"], [411, "on"], [411, "entry"], [411, "and"], [411, "exit"], [411, "to"], [411, "quarantine"], [411, ","], [411, "of"], [411, "which"], [411, "16"], [411, "have"], [411, "test"], [411, "negative"], [411, "at"], [411, "entry"], [411, ";"], [411, "prevent"], [411, "an"], [411, "expect"], [411, "nine"], [411, "offshore"], [411, "transmission"], [411, "event"], [411, "that"], [411, "each"], [411, "could"], [411, "have"], [411, "lead"], [411, "to"], [411, "outbreak"], [411, "."], [412, "we"], [412, "show"], [412, "that"], [412, "appropriately"], [412, "time"], [412, "testing"], [412, "can"], [412, "make"], [412, "short"], [412, "quarantine"], [412, "effective"], [412, "."], [413, "understand"], [413, "the"], [413, "system"], [413, "biology"], [413, "approach"], [413, "for"], [413, "promote"], [413, "the"], [413, "development"], [413, "of"], [413, "new"], [413, "therapeutic"], [413, "drug"], [413, "be"], [413, "attain"], [413, "importance"], [413, "nowadays"], [413, "."], [414, "the"], [414, "threat"], [414, "of"], [414, "covid-19"], [414, "outbreak"], [414, "need"], [414, "to"], [414, "be"], [414, "vanish"], [414, "for"], [414, "global"], [414, "welfare"], [414, ","], [414, "and"], [414, "every"], [414, "section"], [414, "of"], [414, "research"], [414, "be"], [414, "focus"], [414, "on"], [414, "it"], [414, "."], [415, "there"], [415, "be"], [415, "an"], [415, "opportunity"], [415, "for"], [415, "find"], [415, "new"], [415, ","], [415, "quick"], [415, ","], [415, "and"], [415, "accurate"], [415, "tool"], [415, "for"], [415, "develop"], [415, "treatment"], [415, "option"], [415, ","], [415, "include"], [415, "the"], [415, "vaccine"], [415, "against"], [415, "covid-19"], [415, "."], [416, "the"], [416, "review"], [416, "at"], [416, "this"], [416, "moment"], [416, "cover"], [416, "various"], [416, "aspect"], [416, "of"], [416, "pathogenesis"], [416, "and"], [416, "host"], [416, "factor"], [416, "for"], [416, "explore"], [416, "the"], [416, "virus"], [416, "target"], [416, "and"], [416, "develop"], [416, "suitable"], [416, "therapeutic"], [416, "solution"], [416, "through"], [416, "system"], [416, "biology"], [416, "tool"], [416, "."], [417, "furthermore"], [417, ","], [417, "this"], [417, "review"], [417, "also"], [417, "cover"], [417, "the"], [417, "extensive"], [417, "detail"], [417, "of"], [417, "multiomic"], [417, "tool"], [417, ","], [417, "transcriptomic"], [417, ","], [417, "proteomic"], [417, ","], [417, "genomic"], [417, ","], [417, "lipidomic"], [417, ","], [417, "immunomic"], [417, ","], [417, "and"], [417, " "], [417, "computational"], [417, "modeling"], [417, "aim"], [417, "towards"], [417, "the"], [417, "study"], [417, "of"], [417, "host"], [417, "-"], [417, "virus"], [417, "interaction"], [417, "in"], [417, "search"], [417, "of"], [417, "therapeutic"], [417, "target"], [417, "against"], [417, "the"], [417, "covid-19"], [417, "."], [418, "the"], [418, "unforeseen"], [418, "emergence"], [418, "of"], [418, "coronavirus"], [418, "disease"], [418, "2019"], [418, "("], [418, "covid-19"], [418, ")"], [418, ","], [418, "a"], [418, "severe"], [418, "acute"], [418, "respiratory"], [418, "syndrome"], [418, "coronavirus"], [418, "2"], [418, "("], [418, "sars"], [418, "-"], [418, "cov-2"], [418, ")"], [418, "at"], [418, "the"], [418, "wuhan"], [418, "province"], [418, "of"], [418, "china"], [418, "in"], [418, "december"], [418, "2019"], [418, ","], [418, "subsequently"], [418, "its"], [418, "abrupt"], [418, "spread"], [418, "across"], [418, "the"], [418, "world"], [418, "have"], [418, "severely"], [418, "affect"], [418, "human"], [418, "life"], [418, "."], [419, "in"], [419, "a"], [419, "short"], [419, "span"], [419, "of"], [419, "time"], [419, ","], [419, "covid-19"], [419, "have"], [419, "sack"], [419, "more"], [419, "than"], [419, "one"], [419, "million"], [419, "human"], [419, "life"], [419, "and"], [419, "mark"], [419, "as"], [419, "a"], [419, "severe"], [419, "global"], [419, "pandemic"], [419, ","], [419, "which"], [419, "be"], [419, "drastically"], [419, "accountable"], [419, "for"], [419, "the"], [419, "adverse"], [419, "effect"], [419, "directly"], [419, "to"], [419, "the"], [419, "human"], [419, "society"], [419, ","], [419, "particularly"], [419, "the"], [419, "health"], [419, "care"], [419, "system"], [419, "and"], [419, "the"], [419, "economy"], [419, "."], [420, "the"], [420, "unavailability"], [420, "of"], [420, "approved"], [420, "and"], [420, "effective"], [420, "drug"], [420, "or"], [420, "vaccine"], [420, "against"], [420, "covid-19"], [420, "far"], [420, "create"], [420, "condition"], [420, "more"], [420, "adverse"], [420, "and"], [420, "terrifying"], [420, "."], [421, "to"], [421, "win"], [421, "the"], [421, "war"], [421, "against"], [421, "this"], [421, "pandemic"], [421, "within"], [421, "time"], [421, "there"], [421, "be"], [421, "a"], [421, "desperate"], [421, "need"], [421, "for"], [421, "the"], [421, "most"], [421, "adequate"], [421, "therapeutic"], [421, "treatment"], [421, ","], [421, "which"], [421, "can"], [421, "be"], [421, "achieve"], [421, "by"], [421, "the"], [421, "collaborative"], [421, "research"], [421, "work"], [421, "among"], [421, "scientist"], [421, "worldwide"], [421, "."], [422, "in"], [422, "continuation"], [422, "of"], [422, "our"], [422, "effort"], [422, "to"], [422, "support"], [422, "the"], [422, "scientific"], [422, "community"], [422, ","], [422, "a"], [422, "review"], [422, "have"], [422, "be"], [422, "present"], [422, "which"], [422, "discuss"], [422, "the"], [422, "structure"], [422, "and"], [422, "the"], [422, "activity"], [422, "of"], [422, "numerous"], [422, "molecule"], [422, "exhibit"], [422, "promise"], [422, "sars"], [422, "-"], [422, "cov-2"], [422, "and"], [422, "other"], [422, "covs"], [422, "inhibition"], [422, "activity"], [422, "."], [423, "furthermore"], [423, ","], [423, "this"], [423, "review"], [423, "offer"], [423, "an"], [423, "overview"], [423, "of"], [423, "the"], [423, "structure"], [423, ","], [423, "a"], [423, "plausible"], [423, "mechanism"], [423, "of"], [423, "action"], [423, "of"], [423, "sars"], [423, "-"], [423, "cov-2"], [423, ","], [423, "and"], [423, "crucial"], [423, "structural"], [423, "feature"], [423, "substantial"], [423, "to"], [423, "inhibit"], [423, "the"], [423, "primary"], [423, "virus"], [423, "-"], [423, "base"], [423, "and"], [423, "host"], [423, "-"], [423, "base"], [423, "target"], [423, "involve"], [423, "in"], [423, "sars"], [423, "-"], [423, "cov-2"], [423, "treatment"], [423, "."], [424, "we"], [424, "anticipate"], [424, "optimistically"], [424, "that"], [424, "this"], [424, "perspective"], [424, "will"], [424, "provide"], [424, "the"], [424, "reader"], [424, "and"], [424, "researcher"], [424, "'s"], [424, "well"], [424, "understanding"], [424, "regard"], [424, "covid-19"], [424, "and"], [424, "pave"], [424, "the"], [424, "path"], [424, "in"], [424, "the"], [424, "direction"], [424, "of"], [424, "covid-19"], [424, "drug"], [424, "discovery"], [424, "and"], [424, "development"], [424, "paradigm"], [424, "."], [425, "to"], [425, "date"], [425, ","], [425, "sars"], [425, "-"], [425, "cov-2"], [425, "("], [425, "the"], [425, "virus"], [425, "that"], [425, "cause"], [425, "covid-19"], [425, ")"], [425, "have"], [425, "spread"], [425, "to"], [425, "almost"], [425, "every"], [425, "region"], [425, "of"], [425, "the"], [425, "world"], [425, ","], [425, "infect"], [425, "million"], [425, "and"], [425, "result"], [425, "in"], [425, "the"], [425, "death"], [425, "of"], [425, "hundred"], [425, "of"], [425, "thousand"], [425, "of"], [425, "people"], [425, "."], [426, "although"], [426, "it"], [426, "be"], [426, "predict"], [426, "that"], [426, "africa"], [426, "would"], [426, "suffer"], [426, "a"], [426, "massive"], [426, "loss"], [426, "of"], [426, "life"], [426, "due"], [426, "to"], [426, "this"], [426, "pandemic"], [426, ","], [426, "the"], [426, "number"], [426, "of"], [426, "covid-19"], [426, "case"], [426, "have"], [426, "be"], [426, "relatively"], [426, "low"], [426, "across"], [426, "the"], [426, "continent"], [426, "."], [427, "researcher"], [427, "have"], [427, "speculate"], [427, "that"], [427, "several"], [427, "factor"], [427, "may"], [427, "be"], [427, "responsible"], [427, "for"], [427, "this"], [427, "outcome"], [427, "in"], [427, "africa"], [427, ","], [427, "include"], [427, "the"], [427, "extensive"], [427, "experience"], [427, "that"], [427, "country"], [427, "have"], [427, "with"], [427, "infectious"], [427, "disease"], [427, "and"], [427, "the"], [427, "young"], [427, "median"], [427, "age"], [427, "of"], [427, "their"], [427, "population"], [427, "."], [428, "however"], [428, ","], [428, "it"], [428, "be"], [428, "still"], [428, "important"], [428, "for"], [428, "african"], [428, "country"], [428, "to"], [428, "adopt"], [428, "aggressive"], [428, "and"], [428, "bold"], [428, "approach"], [428, "against"], [428, "covid-19"], [428, ","], [428, "in"], [428, "case"], [428, "the"], [428, "nature"], [428, "of"], [428, "the"], [428, "pandemic"], [428, "change"], [428, "."], [429, "this"], [429, "short"], [429, "review"], [429, "will"], [429, "summarize"], [429, "the"], [429, "status"], [429, "of"], [429, "the"], [429, "outbreak"], [429, "in"], [429, "africa"], [429, "and"], [429, "propose"], [429, "possible"], [429, "reason"], [429, "for"], [429, "current"], [429, "trend"], [429, ","], [429, "as"], [429, "well"], [429, "as"], [429, "discuss"], [429, "intervention"], [429, "aim"], [429, "at"], [429, "prevent"], [429, "a"], [429, "rapid"], [429, "increase"], [429, "in"], [429, "the"], [429, "number"], [429, "of"], [429, "covid-19"], [429, "case"], [429, "in"], [429, "the"], [429, "future"], [429, "."], [430, "despite"], [430, "the"], [430, "unprecedented"], [430, "effort"], [430, "of"], [430, "the"], [430, "scientific"], [430, "community"], [430, ","], [430, "the"], [430, "novel"], [430, "sars"], [430, "-"], [430, "cov-2"], [430, "virus"], [430, "have"], [430, "infect"], [430, "more"], [430, "than"], [430, "46"], [430, "million"], [430, "people"], [430, "worldwide"], [430, ","], [430, "kill"], [430, "over"], [430, "one"], [430, "million"], [430, "two"], [430, "hundred"], [430, "thousand"], [430, "."], [431, "understand"], [431, "the"], [431, "mechanism"], [431, "by"], [431, "which"], [431, "some"], [431, "individual"], [431, "be"], [431, "more"], [431, "susceptible"], [431, "to"], [431, "sars"], [431, "-"], [431, "cov-2"], [431, "infection"], [431, "and"], [431, "why"], [431, "a"], [431, "subgroup"], [431, "of"], [431, "they"], [431, "be"], [431, "prone"], [431, "to"], [431, "experience"], [431, "severe"], [431, "pneumonia"], [431, ","], [431, "and"], [431, "death"], [431, "should"], [431, "lead"], [431, "to"], [431, "a"], [431, "well"], [431, "approach"], [431, "and"], [431, "more"], [431, "effective"], [431, "treatment"], [431, "for"], [431, "covid-19"], [431, "."], [432, "here"], [432, ","], [432, "we"], [432, "focus"], [432, "our"], [432, "attention"], [432, "on"], [432, "ace2"], [432, ","], [432, "a"], [432, "primary"], [432, "receptor"], [432, "of"], [432, "sars"], [432, "-"], [432, "cov-2"], [432, "."], [433, "we"], [433, "will"], [433, "discuss"], [433, "its"], [433, "biology"], [433, ","], [433, "tissue"], [433, "expression"], [433, ","], [433, "and"], [433, "post"], [433, "-"], [433, "translational"], [433, "regulation"], [433, "that"], [433, "determine"], [433, "its"], [433, "potential"], [433, "to"], [433, "be"], [433, "employ"], [433, "by"], [433, "sars"], [433, "-"], [433, "cov-2"], [433, "for"], [433, "cell"], [433, "entry"], [433, "."], [434, "particular"], [434, "attention"], [434, "will"], [434, "be"], [434, "give"], [434, "to"], [434, "how"], [434, "the"], [434, "ace2"], [434, "soluble"], [434, "form"], [434, "can"], [434, "have"], [434, "a"], [434, "great"], [434, "impact"], [434, "on"], [434, "disease"], [434, "progression"], [434, "and"], [434, "thus"], [434, "be"], [434, "use"], [434, "in"], [434, "a"], [434, "potential"], [434, "therapeutic"], [434, "strategy"], [434, "."], [435, "furthermore"], [435, ","], [435, "we"], [435, "will"], [435, "discuss"], [435, "repercussion"], [435, "that"], [435, "sars"], [435, "-"], [435, "cov-2"], [435, "/"], [435, "ace2"], [435, "binding"], [435, "have"], [435, "on"], [435, "the"], [435, "renin"], [435, "-"], [435, "angiotensin"], [435, "system"], [435, "and"], [435, "beyond"], [435, "."], [436, "indeed"], [436, ","], [436, "although"], [436, "mostly"], [436, "neglect"], [436, ","], [436, "ace2"], [436, "can"], [436, "also"], [436, "act"], [436, "on"], [436, "["], [436, "des"], [436, "-"], [436, "arg"], [436, "937]-bradykinin"], [436, "of"], [436, "the"], [436, "kinin"], [436, "-"], [436, "kallikrein"], [436, "system"], [436, "regulate"], [436, "coagulation"], [436, "and"], [436, "inflammation"], [436, "."], [437, "thorough"], [437, "comprehension"], [437, "of"], [437, "the"], [437, "role"], [437, "that"], [437, "ace2"], [437, "play"], [437, "in"], [437, "different"], [437, "pathway"], [437, "will"], [437, "be"], [437, "the"], [437, "key"], [437, "to"], [437, "assess"], [437, "the"], [437, "impact"], [437, "that"], [437, "sars"], [437, "-"], [437, "cov-2"], [437, "/"], [437, "ace2"], [437, "binding"], [437, "have"], [437, "on"], [437, "organismal"], [437, "physiology"], [437, "and"], [437, "will"], [437, "help"], [437, "we"], [437, "to"], [437, "find"], [437, "well"], [437, "therapy"], [437, "and"], [437, "diagnostic"], [437, "tool"], [437, "."], [438, "the"], [438, "coronavirus"], [438, "disease"], [438, "("], [438, "covid-19"], [438, ")"], [438, ","], [438, "identify"], [438, "in"], [438, "wuhan"], [438, ","], [438, "china"], [438, ","], [438, "on"], [438, "december"], [438, "2019"], [438, ","], [438, "be"], [438, "declare"], [438, "a"], [438, "pandemic"], [438, "by"], [438, "the"], [438, "world"], [438, "health"], [438, "organization"], [438, ","], [438, "on"], [438, "march"], [438, ","], [438, "2020"], [438, "."], [439, "since"], [439, "then"], [439, ","], [439, "effort"], [439, "have"], [439, "be"], [439, "gather"], [439, "to"], [439, "describe"], [439, "its"], [439, "clinical"], [439, "course"], [439, "and"], [439, "to"], [439, "determine"], [439, "preventive"], [439, "measure"], [439, "and"], [439, "treatment"], [439, "strategy"], [439, "."], [440, "adult"], [440, "old"], [440, "than"], [440, "65"], [440, "year"], [440, "of"], [440, "age"], [440, "be"], [440, "more"], [440, "susceptible"], [440, "to"], [440, "serious"], [440, "clinical"], [440, "symptom"], [440, "and"], [440, "present"], [440, "high"], [440, "mortality"], [440, "rate"], [440, "."], [441, "angiotensin"], [441, "-"], [441, "convert"], [441, "enzyme"], [441, "2"], [441, "("], [441, "ace2"], [441, ")"], [441, "be"], [441, "a"], [441, "major"], [441, "receptor"], [441, "for"], [441, "some"], [441, "coronavirus"], [441, "infection"], [441, ","], [441, "include"], [441, "sars"], [441, "-"], [441, "cov-2"], [441, ","], [441, "but"], [441, "be"], [441, "also"], [441, "a"], [441, "crucial"], [441, "determinant"], [441, "in"], [441, "anti"], [441, "-"], [441, "inflammation"], [441, "process"], [441, "during"], [441, "the"], [441, "renin"], [441, "-"], [441, "angiotensin"], [441, "system"], [441, "("], [441, "ras"], [441, ")"], [441, "function"], [441, "\xA0"], [441, "-"], [441, "convert"], [441, "angiotensin"], [441, "ii"], [441, "to"], [441, "angiotensin"], [441, "1"], [441, "-"], [441, "7"], [441, "."], [442, "the"], [442, "decline"], [442, "in"], [442, "ace2"], [442, "expression"], [442, "that"], [442, "occur"], [442, "with"], [442, "aging"], [442, "have"], [442, "be"], [442, "associate"], [442, "to"], [442, "the"], [442, "high"], [442, "morbidity"], [442, "and"], [442, "mortality"], [442, "rate"], [442, "in"], [442, "old"], [442, "adult"], [442, "."], [443, "these"], [443, "observation"], [443, "highlight"], [443, "the"], [443, "importance"], [443, "of"], [443, "investigate"], [443, "the"], [443, "association"], [443, "between"], [443, "covid-19"], [443, "and"], [443, "age"], [443, "-"], [443, "relate"], [443, "neurodegenerative"], [443, "disorder"], [443, ","], [443, "i.e."], [443, ","], [443, "\xA0"], [443, "parkinson"], [443, "'s"], [443, "and"], [443, "alzheimer"], [443, "'s"], [443, "disease"], [443, "."], [444, "a"], [444, "possible"], [444, "option"], [444, "to"], [444, "reduce"], [444, "the"], [444, "risk"], [444, "of"], [444, "covid-19"], [444, "be"], [444, "vitamin"], [444, "d"], [444, "supplementation"], [444, ","], [444, "due"], [444, "to"], [444, "its"], [444, "anti"], [444, "-"], [444, "inflammatory"], [444, "and"], [444, "immune"], [444, "-"], [444, "system"], [444, "-"], [444, "modulate"], [444, "effect"], [444, "."], [445, "it"], [445, "have"], [445, "also"], [445, "be"], [445, "suggest"], [445, "that"], [445, "vitamin"], [445, "d"], [445, "supplementation"], [445, "play"], [445, "a"], [445, "role"], [445, "in"], [445, "slow"], [445, "progression"], [445, "of"], [445, "parkinson"], [445, "and"], [445, "alzheimer"], [445, "."], [446, "the"], [446, "present"], [446, "study"], [446, "be"], [446, "a"], [446, "literature"], [446, "review"], [446, "of"], [446, "article"], [446, "publish"], [446, "on"], [446, "the"], [446, "theme"], [446, "covid-19"], [446, ","], [446, "parkinson"], [446, "and"], [446, "alzheimer"], [446, "'s"], [446, "disease"], [446, ","], [446, "and"], [446, "the"], [446, "role"], [446, "play"], [446, "by"], [446, "vitamin"], [446, "d."], [446, "pubme"], [446, ","], [446, "medline"], [446, ","], [446, "and"], [446, "embase"], [446, "database"], [446, "be"], [446, "consult"], [446, "."], [447, "result"], [447, "confirm"], [447, "neurodegenerative"], [447, "and"], [447, "neuroinflammatory"], [447, "effect"], [447, "of"], [447, "covid-19"], [447, ","], [447, "aggravate"], [447, "in"], [447, "parkinson"], [447, "'s"], [447, "and"], [447, "alzheimer"], [447, "'s"], [447, "patient"], [447, ","], [447, "and"], [447, "the"], [447, "important"], [447, "role"], [447, "of"], [447, "vitamin"], [447, "d"], [447, "as"], [447, "a"], [447, "possible"], [447, "therapeutic"], [447, "strategy"], [447, "."], [448, "nevertheless"], [448, ","], [448, "randomize"], [448, "control"], [448, "trial"], [448, "and"], [448, "large"], [448, "population"], [448, "study"], [448, "be"], [448, "still"], [448, "warrant"], [448, "."], [449, "novel"], [449, "coronavirus"], [449, "sars"], [449, "-"], [449, "cov-2"], [449, ","], [449, "designate"], [449, "as"], [449, "covid-19"], [449, "by"], [449, "the"], [449, "world"], [449, "health"], [449, "organization"], [449, "("], [449, "who"], [449, ")"], [449, "on"], [449, "the"], [449, "february"], [449, "11"], [449, ","], [449, "2020"], [449, ","], [449, "be"], [449, "one"], [449, "of"], [449, "the"], [449, "highly"], [449, "pathogenic"], [449, "\u03B2"], [449, "-"], [449, "coronaviruse"], [449, "which"], [449, "infect"], [449, "human"], [449, "."], [450, "early"], [450, "diagnosis"], [450, "of"], [450, "covid-19"], [450, "be"], [450, "the"], [450, "most"], [450, "critical"], [450, "step"], [450, "to"], [450, "treat"], [450, "infection"], [450, "."], [451, "the"], [451, "diagnostic"], [451, "tool"], [451, "be"], [451, "generally"], [451, "molecular"], [451, "method"], [451, ","], [451, "serology"], [451, "and"], [451, "viral"], [451, "culture"], [451, "."], [452, "recently"], [452, "crispr"], [452, "-"], [452, "base"], [452, "method"], [452, "have"], [452, "be"], [452, "investigate"], [452, "to"], [452, "diagnose"], [452, "and"], [452, "treat"], [452, "coronavirus"], [452, "infection"], [452, "."], [453, "the"], [453, "emergence"], [453, "of"], [453, "2019"], [453, "-"], [453, "ncov"], [453, "during"], [453, "the"], [453, "influenza"], [453, "season"], [453, ","], [453, "have"], [453, "lead"], [453, "to"], [453, "the"], [453, "extensive"], [453, "use"], [453, "of"], [453, "antibiotic"], [453, "and"], [453, "neuraminidase"], [453, "enzyme"], [453, "inhibitor"], [453, ","], [453, "take"], [453, "orally"], [453, "and"], [453, "intravenously"], [453, "."], [454, "currently"], [454, ","], [454, "antiviral"], [454, "inhibitor"], [454, "of"], [454, "sars"], [454, "and"], [454, "mer"], [454, "spike"], [454, "protein"], [454, ","], [454, "neuraminidase"], [454, "inhibitor"], [454, ","], [454, "anti"], [454, "-"], [454, "inflammatory"], [454, "drug"], [454, "and"], [454, "ek1"], [454, "peptide"], [454, "be"], [454, "the"], [454, "available"], [454, "therapeutic"], [454, "option"], [454, "for"], [454, "sars"], [454, "-"], [454, "cov-2"], [454, "infect"], [454, "individual"], [454, "."], [455, "in"], [455, "addition"], [455, ","], [455, "chloroquine"], [455, ","], [455, "which"], [455, "be"], [455, "previously"], [455, "use"], [455, "for"], [455, "malarial"], [455, "and"], [455, "autoimmune"], [455, "disease"], [455, ","], [455, "have"], [455, "show"], [455, "efficacy"], [455, "in"], [455, "the"], [455, "2019"], [455, "-"], [455, "ncov"], [455, "infection"], [455, "treatment"], [455, "."], [456, "in"], [456, "severe"], [456, "hypoxaemia"], [456, ","], [456, "a"], [456, "combination"], [456, "of"], [456, "antibiotic"], [456, ","], [456, "\u03B1"], [456, "-"], [456, "interferon"], [456, ","], [456, "lopinavir"], [456, "and"], [456, "mechanical"], [456, "ventilation"], [456, "can"], [456, "effectively"], [456, "mitigate"], [456, "the"], [456, "symptom"], [456, "."], [457, "comprehensive"], [457, "knowledge"], [457, "on"], [457, "the"], [457, "innate"], [457, "and"], [457, "adaptive"], [457, "immune"], [457, "response"], [457, ","], [457, "will"], [457, "make"], [457, "it"], [457, "possible"], [457, "to"], [457, "propose"], [457, "potent"], [457, "antiviral"], [457, "drug"], [457, "with"], [457, "their"], [457, "effective"], [457, "therapeutic"], [457, "measure"], [457, "for"], [457, "the"], [457, "prevention"], [457, "of"], [457, "viral"], [457, "infection"], [457, "."], [458, "this"], [458, "therapeutic"], [458, "strategy"], [458, "will"], [458, "help"], [458, "patient"], [458, "worldwide"], [458, "to"], [458, "protect"], [458, "themselves"], [458, "against"], [458, "severe"], [458, "and"], [458, "fatal"], [458, "viral"], [458, "infection"], [458, ","], [458, "that"], [458, "potentially"], [458, "can"], [458, "evolve"], [458, "and"], [458, "develop"], [458, "drug"], [458, "resistance"], [458, ","], [458, "and"], [458, "to"], [458, "reduce"], [458, "mortality"], [458, "rate"], [458, "."], [459, "since"], [459, "emerge"], [459, "coronaviruse"], [459, "have"], [459, "always"], [459, "become"], [459, "a"], [459, "human"], [459, "health"], [459, "concern"], [459, "globally"], [459, "especially"], [459, "severe"], [459, "acute"], [459, "respiratory"], [459, "syndrome"], [459, "coronavirus"], [459, "2"], [459, "("], [459, "sars"], [459, "-"], [459, "cov"], [459, ")"], [459, "and"], [459, "middle"], [459, "east"], [459, "respiratory"], [459, "syndrome"], [459, "coronavirus"], [459, "and"], [459, "a"], [459, "novel"], [459, "coronavirus"], [459, "be"], [459, "introduce"], [459, "in"], [459, "wuhan"], [459, ","], [459, "china"], [459, ","], [459, "in"], [459, "december"], [459, "2019"], [459, "("], [459, "call"], [459, "sars"], [459, "-"], [459, "cov-2"], [459, ")"], [459, ","], [459, "many"], [459, "researcher"], [459, "focus"], [459, "on"], [459, "its"], [459, "epidemic"], [459, ","], [459, "virological"], [459, "and"], [459, "clinical"], [459, "feature"], [459, "."], [460, "sars"], [460, "-"], [460, "cov-2"], [460, "be"], [460, "classify"], [460, "as"], [460, "betacoronaviruse"], [460, "genus"], [460, "and"], [460, "sarbecovirus"], [460, "subgenu"], [460, "("], [460, "lineage"], [460, "b"], [460, ")"], [460, "."], [461, "the"], [461, "virus"], [461, "show"], [461, "a"], [461, "great"], [461, "similarity"], [461, "with"], [461, "sars"], [461, "-"], [461, "cov"], [461, "and"], [461, "bat"], [461, "sars"], [461, "-"], [461, "like"], [461, "coronaviruse"], [461, "."], [462, "in"], [462, "this"], [462, "study"], [462, ","], [462, "we"], [462, "evaluate"], [462, "sars"], [462, "-"], [462, "cov-2"], [462, "virus"], [462, "phylogeny"], [462, "and"], [462, "evolution"], [462, "by"], [462, "use"], [462, "current"], [462, "virus"], [462, "and"], [462, "related"], [462, "sequence"], [462, "."], [463, "who"], [463, "have"], [463, "call"], [463, "for"], [463, "increase"], [463, "testing"], [463, "in"], [463, "response"], [463, "to"], [463, "the"], [463, "covid-19"], [463, "pandemic"], [463, ","], [463, "but"], [463, "country"], [463, "have"], [463, "take"], [463, "different"], [463, "approach"], [463, "and"], [463, "the"], [463, "effectiveness"], [463, "of"], [463, "alternative"], [463, "strategy"], [463, "be"], [463, "unknown"], [463, "."], [464, "we"], [464, "aim"], [464, "to"], [464, "investigate"], [464, "the"], [464, "potential"], [464, "impact"], [464, "of"], [464, "different"], [464, "testing"], [464, "and"], [464, "isolation"], [464, "strategy"], [464, "on"], [464, "transmission"], [464, "of"], [464, "severe"], [464, "acute"], [464, "respiratory"], [464, "syndrome"], [464, "coronavirus"], [464, "2"], [464, "("], [464, "sars"], [464, "-"], [464, "cov-2"], [464, ")"], [464, "."], [465, "we"], [465, "develop"], [465, "a"], [465, "mathematical"], [465, "model"], [465, "of"], [465, "sars"], [465, "-"], [465, "cov-2"], [465, "transmission"], [465, "base"], [465, "on"], [465, "infectiousness"], [465, "and"], [465, "pcr"], [465, "test"], [465, "sensitivity"], [465, "over"], [465, "time"], [465, "since"], [465, "infection"], [465, "."], [466, "we"], [466, "estimate"], [466, "the"], [466, "reduction"], [466, "in"], [466, "the"], [466, "effective"], [466, "reproduction"], [466, "number"], [466, "("], [466, "r"], [466, ")"], [466, "achieve"], [466, "by"], [466, "test"], [466, "and"], [466, "isolate"], [466, "symptomatic"], [466, "individual"], [466, ","], [466, "regular"], [466, "screening"], [466, "of"], [466, "high"], [466, "-"], [466, "risk"], [466, "group"], [466, "irrespective"], [466, "of"], [466, "symptom"], [466, ","], [466, "and"], [466, "quarantine"], [466, "of"], [466, "contact"], [466, "of"], [466, "laboratory"], [466, "-"], [466, "confirm"], [466, "case"], [466, "identify"], [466, "through"], [466, "test"], [466, "-"], [466, "and"], [466, "-"], [466, "trace"], [466, "protocol"], [466, "."], [467, "the"], [467, "expect"], [467, "effectiveness"], [467, "of"], [467, "different"], [467, "testing"], [467, "strategy"], [467, "be"], [467, "define"], [467, "as"], [467, "the"], [467, "percentage"], [467, "reduction"], [467, "in"], [467, "r."], [467, "we"], [467, "review"], [467, "datum"], [467, "on"], [467, "the"], [467, "performance"], [467, "of"], [467, "antibody"], [467, "test"], [467, "report"], [467, "by"], [467, "the"], [467, "foundation"], [467, "for"], [467, "innovative"], [467, "new"], [467, "diagnostic"], [467, "and"], [467, "examine"], [467, "their"], [467, "implication"], [467, "for"], [467, "the"], [467, "use"], [467, "of"], [467, "so"], [467, "-"], [467, "call"], [467, "immunity"], [467, "passport"], [467, "."], [468, "if"], [468, "all"], [468, "individual"], [468, "with"], [468, "symptom"], [468, "compatible"], [468, "with"], [468, "covid-19"], [468, "self"], [468, "-"], [468, "isolate"], [468, "and"], [468, "self"], [468, "-"], [468, "isolation"], [468, "be"], [468, "100"], [468, "%"], [468, "effective"], [468, "in"], [468, "reduce"], [468, "onward"], [468, "transmission"], [468, ","], [468, "self"], [468, "-"], [468, "isolation"], [468, "of"], [468, "symptomatic"], [468, "individual"], [468, "would"], [468, "result"], [468, "in"], [468, "a"], [468, "reduction"], [468, "in"], [468, "r"], [468, "of"], [468, "47"], [468, "%"], [468, "("], [468, "95"], [468, "%"], [468, "uncertainty"], [468, "interval"], [468, "["], [468, "ui"], [468, "]"], [468, "32"], [468, "-"], [468, "55"], [468, ")"], [468, "."], [469, "pcr"], [469, "testing"], [469, "to"], [469, "identify"], [469, "sars"], [469, "-"], [469, "cov-2"], [469, "infection"], [469, "soon"], [469, "after"], [469, "symptom"], [469, "onset"], [469, "could"], [469, "reduce"], [469, "the"], [469, "number"], [469, "of"], [469, "individual"], [469, "need"], [469, "to"], [469, "self"], [469, "-"], [469, "isolate"], [469, ","], [469, "but"], [469, "would"], [469, "also"], [469, "reduce"], [469, "the"], [469, "effectiveness"], [469, "of"], [469, "self"], [469, "-"], [469, "isolation"], [469, "("], [469, "around"], [469, "10"], [469, "%"], [469, "would"], [469, "be"], [469, "false"], [469, "negative"], [469, ")"], [469, "."], [470, "weekly"], [470, "screening"], [470, "of"], [470, "health"], [470, "-"], [470, "care"], [470, "worker"], [470, "and"], [470, "other"], [470, "high"], [470, "-"], [470, "risk"], [470, "group"], [470, "irrespective"], [470, "of"], [470, "symptom"], [470, "by"], [470, "use"], [470, "of"], [470, "pcr"], [470, "testing"], [470, "be"], [470, "estimate"], [470, "to"], [470, "reduce"], [470, "their"], [470, "contribution"], [470, "to"], [470, "sars"], [470, "-"], [470, "cov-2"], [470, "transmission"], [470, "by"], [470, "23"], [470, "%"], [470, "("], [470, "95"], [470, "%"], [470, "ui"], [470, "16"], [470, "-"], [470, "40"], [470, ")"], [470, ","], [470, "on"], [470, "top"], [470, "of"], [470, "reduction"], [470, "achieve"], [470, "by"], [470, "self"], [470, "-"], [470, "isolation"], [470, "follow"], [470, "symptom"], [470, ","], [470, "assume"], [470, "result"], [470, "be"], [470, "available"], [470, "at"], [470, "24"], [470, "h."], [471, "the"], [471, "effectiveness"], [471, "of"], [471, "test"], [471, "and"], [471, "trace"], [471, "depend"], [471, "strongly"], [471, "on"], [471, "coverage"], [471, "and"], [471, "the"], [471, "timeliness"], [471, "of"], [471, "contact"], [471, "tracing"], [471, ","], [471, "potentially"], [471, "reduce"], [471, "r"], [471, "by"], [471, "26"], [471, "%"], [471, "("], [471, "95"], [471, "%"], [471, "ui"], [471, "14"], [471, "-"], [471, "35"], [471, ")"], [471, "on"], [471, "top"], [471, "of"], [471, "reduction"], [471, "achieve"], [471, "by"], [471, "self"], [471, "-"], [471, "isolation"], [471, "follow"], [471, "symptom"], [471, ","], [471, "if"], [471, "80"], [471, "%"], [471, "of"], [471, "case"], [471, "and"], [471, "contact"], [471, "be"], [471, "identify"], [471, "and"], [471, "there"], [471, "be"], [471, "immediate"], [471, "testing"], [471, "follow"], [471, "symptom"], [471, "onset"], [471, "and"], [471, "quarantine"], [471, "of"], [471, "contact"], [471, "within"], [471, "24"], [471, "h."], [472, "among"], [472, "currently"], [472, "available"], [472, "antibody"], [472, "test"], [472, ","], [472, "performance"], [472, "have"], [472, "be"], [472, "highly"], [472, "variable"], [472, ","], [472, "with"], [472, "specificity"], [472, "around"], [472, "90"], [472, "%"], [472, "or"], [472, "low"], [472, "for"], [472, "rapid"], [472, "diagnostic"], [472, "test"], [472, "and"], [472, "95"], [472, "-"], [472, "99"], [472, "%"], [472, "for"], [472, "laboratory"], [472, "-"], [472, "base"], [472, "elisa"], [472, "and"], [472, "chemiluminescent"], [472, "assay"], [472, "."], [473, "molecular"], [473, "testing"], [473, "can"], [473, "play"], [473, "an"], [473, "important"], [473, "role"], [473, "in"], [473, "prevention"], [473, "of"], [473, "sars"], [473, "-"], [473, "cov-2"], [473, "transmission"], [473, ","], [473, "especially"], [473, "among"], [473, "health"], [473, "-"], [473, "care"], [473, "worker"], [473, "and"], [473, "other"], [473, "high"], [473, "-"], [473, "risk"], [473, "group"], [473, ","], [473, "but"], [473, "no"], [473, "single"], [473, "strategy"], [473, "will"], [473, "reduce"], [473, "r"], [473, "below"], [473, "1"], [473, "at"], [473, "current"], [473, "level"], [473, "of"], [473, "population"], [473, "immunity"], [473, "."], [474, "immunity"], [474, "passport"], [474, "base"], [474, "on"], [474, "antibody"], [474, "test"], [474, "or"], [474, "test"], [474, "for"], [474, "infection"], [474, "face"], [474, "substantial"], [474, "technical"], [474, ","], [474, "legal"], [474, ","], [474, "and"], [474, "ethical"], [474, "challenge"], [474, "."], [475, "uk"], [475, "medical"], [475, "research"], [475, "council"], [475, "."], [476, "it"], [476, "be"], [476, "crucial"], [476, "to"], [476, "use"], [476, "the"], [476, "wealth"], [476, "of"], [476, "information"], [476, "emerge"], [476, "from"], [476, "the"], [476, "ongoing"], [476, "sars"], [476, "-"], [476, "cov-2"], [476, "pandemic"], [476, "and"], [476, "confront"], [476, "covid-19"], [476, "with"], [476, "a"], [476, "rational"], [476, "approach"], [476, "."], [477, "there"], [477, "be"], [477, "proactive"], [477, "step"], [477, "to"], [477, "prevent"], [477, "and"], [477, "fight"], [477, "covid-19"], [477, "."], [478, "management"], [478, "of"], [478, "the"], [478, "disease"], [478, "should"], [478, "be"], [478, "accord"], [478, "to"], [478, "clinical"], [478, "feature"], [478, "and"], [478, "laboratory"], [478, "test"], [478, "marker"], [478, "and"], [478, "personalize"], [478, "therapeutic"], [478, "target"], [478, "."], [479, "a"], [479, "novel"], [479, "strain"], [479, "of"], [479, "severe"], [479, "acute"], [479, "respiratory"], [479, "syndrome"], [479, "coronavirus"], [479, "2"], [479, "("], [479, "sars"], [479, "-"], [479, "cov-2"], [479, ")"], [479, "disease"], [479, "("], [479, "covid-19"], [479, ")"], [479, "have"], [479, "be"], [479, "recently"], [479, "identify"], [479, "as"], [479, "an"], [479, "infectious"], [479, "disease"], [479, "affect"], [479, "the"], [479, "respiratory"], [479, "system"], [479, "of"], [479, "human"], [479, "."], [480, "this"], [480, "disease"], [480, "be"], [480, "cause"], [480, "by"], [480, "sars"], [480, "-"], [480, "cov-2"], [480, "that"], [480, "be"], [480, "identify"], [480, "in"], [480, "chinese"], [480, "patient"], [480, "have"], [480, "severe"], [480, "pneumonia"], [480, "and"], [480, "flu"], [480, "-"], [480, "like"], [480, "symptom"], [480, "."], [481, "covid-19"], [481, "be"], [481, "a"], [481, "contagious"], [481, "disease"], [481, "that"], [481, "spread"], [481, "rapidly"], [481, " "], [481, "droplet"], [481, "particle"], [481, "arise"], [481, "through"], [481, "sneeze"], [481, "and"], [481, "cough"], [481, "action"], [481, "of"], [481, "an"], [481, "infected"], [481, "person"], [481, "."], [482, "the"], [482, "report"], [482, "of"], [482, "asymptomatic"], [482, "carrier"], [482, "change"], [482, "the"], [482, "scenario"], [482, "of"], [482, "symptom"], [482, "base"], [482, "-"], [482, "diagnosis"], [482, "in"], [482, "covid-19"], [482, "and"], [482, "intensify"], [482, "the"], [482, "need"], [482, "for"], [482, "proper"], [482, "diagnosis"], [482, "of"], [482, "the"], [482, "majority"], [482, "of"], [482, "the"], [482, "population"], [482, "to"], [482, "combat"], [482, "the"], [482, "rapid"], [482, "transmission"], [482, "of"], [482, "virus"], [482, "."], [483, "the"], [483, "diagnosis"], [483, "of"], [483, "positive"], [483, "case"], [483, "be"], [483, "necessary"], [483, "to"], [483, "ensure"], [483, "prompt"], [483, "care"], [483, "to"], [483, "affect"], [483, "people"], [483, "and"], [483, "also"], [483, "to"], [483, "curb"], [483, "further"], [483, "spread"], [483, "of"], [483, "infection"], [483, "in"], [483, "the"], [483, "population"], [483, "."], [484, "collect"], [484, "sample"], [484, "at"], [484, "the"], [484, "right"], [484, "time"], [484, "and"], [484, "from"], [484, "the"], [484, "exact"], [484, "anatomical"], [484, "site"], [484, "be"], [484, "crucial"], [484, "for"], [484, "proper"], [484, "molecular"], [484, "diagnosis"], [484, "."], [485, "after"], [485, "the"], [485, "complete"], [485, "genome"], [485, "sequence"], [485, "be"], [485, "available"], [485, ","], [485, "china"], [485, "formulate"], [485, "rt"], [485, "-"], [485, "pcr"], [485, "as"], [485, "a"], [485, "primary"], [485, "diagnostic"], [485, "procedure"], [485, "for"], [485, "detect"], [485, "sars"], [485, "-"], [485, "cov-2"], [485, "."], [486, "many"], [486, "in"], [486, "-"], [486, "house"], [486, "and"], [486, "commercial"], [486, "diagnostic"], [486, "kit"], [486, "have"], [486, "be"], [486, "develop"], [486, "or"], [486, "be"], [486, "under"], [486, "development"], [486, "that"], [486, "have"], [486, "a"], [486, "potential"], [486, "to"], [486, "lower"], [486, "the"], [486, "burden"], [486, "of"], [486, "diagnosis"], [486, "on"], [486, "the"], [486, "primary"], [486, "diagnostic"], [486, "technique"], [486, "like"], [486, "rt"], [486, "-"], [486, "pcr"], [486, "."], [487, "serological"], [487, "base"], [487, "diagnosis"], [487, "be"], [487, "another"], [487, "broad"], [487, "category"], [487, "of"], [487, "testing"], [487, "that"], [487, "can"], [487, "detect"], [487, "different"], [487, "serum"], [487, "antibody"], [487, "like"], [487, "igg"], [487, ","], [487, "igm"], [487, ","], [487, "and"], [487, "iga"], [487, "in"], [487, "an"], [487, "infected"], [487, "patient"], [487, "."], [488, "pcr"], [488, "-"], [488, "base"], [488, "diagnostic"], [488, "procedure"], [488, "that"], [488, "be"], [488, "commonly"], [488, "use"], [488, "for"], [488, "pathogen"], [488, "detection"], [488, "need"], [488, "sophisticated"], [488, "machine"], [488, "and"], [488, "assistance"], [488, "of"], [488, "a"], [488, "technical"], [488, "expert"], [488, "."], [489, "despite"], [489, "their"], [489, "reliable"], [489, "accuracy"], [489, ","], [489, "they"], [489, "be"], [489, "not"], [489, "cost"], [489, "-"], [489, "effective"], [489, "test"], [489, ","], [489, "which"], [489, "a"], [489, "common"], [489, "man"], [489, "can"], [489, "afford"], [489, ","], [489, "so"], [489, "it"], [489, "become"], [489, "imperative"], [489, "to"], [489, "look"], [489, "for"], [489, "other"], [489, "diagnostic"], [489, "approach"], [489, ","], [489, "which"], [489, "could"], [489, "be"], [489, "cost"], [489, "effective"], [489, ","], [489, "rapid"], [489, ","], [489, "and"], [489, "sensitive"], [489, "with"], [489, "consistent"], [489, "accuracy"], [489, "."], [490, "to"], [490, "make"], [490, "such"], [490, "diagnostic"], [490, "available"], [490, "to"], [490, "the"], [490, "common"], [490, "man"], [490, ","], [490, "many"], [490, "technique"], [490, "can"], [490, "be"], [490, "exploit"], [490, "among"], [490, ","], [490, "which"], [490, "be"], [490, "point"], [490, "of"], [490, "care"], [490, "("], [490, "poc"], [490, ")"], [490, ","], [490, "also"], [490, "know"], [490, "as"], [490, "bed"], [490, "side"], [490, "testing"], [490, ","], [490, "which"], [490, "be"], [490, "develop"], [490, "as"], [490, "a"], [490, "portable"], [490, "and"], [490, "promise"], [490, "tool"], [490, "in"], [490, "pathogen"], [490, "diagnosis"], [490, "."], [491, "other"], [491, "lateral"], [491, "flow"], [491, "assay"], [491, "("], [491, "lfa)-base"], [491, "technique"], [491, "like"], [491, "sherlock"], [491, ","], [491, "crispr"], [491, "-"], [491, "cas12a"], [491, "("], [491, "aiod"], [491, "-"], [491, "crispr"], [491, ")"], [491, ","], [491, "and"], [491, "fncas9"], [491, "editor"], [491, "-"], [491, "limit"], [491, "uniform"], [491, "detection"], [491, "assay"], [491, "("], [491, "feluda"], [491, ")"], [491, ","], [491, "etc"], [491, "."], [491, "have"], [491, "show"], [491, "promise"], [491, "result"], [491, "in"], [491, "rapid"], [491, "detection"], [491, "of"], [491, "pathogen"], [491, "."], [492, "diagnosis"], [492, "hold"], [492, "a"], [492, "critical"], [492, "importance"], [492, "in"], [492, "the"], [492, "pandemic"], [492, "situation"], [492, "when"], [492, "there"], [492, "be"], [492, "no"], [492, "potential"], [492, "drug"], [492, "for"], [492, "the"], [492, "pathogen"], [492, "available"], [492, "in"], [492, "the"], [492, "market"], [492, "."], [493, "this"], [493, "review"], [493, "sum"], [493, "up"], [493, "the"], [493, "different"], [493, "diagnostic"], [493, "approach"], [493, "design"], [493, "or"], [493, "propose"], [493, "to"], [493, "combat"], [493, "the"], [493, "crisis"], [493, "of"], [493, "widespread"], [493, "diagnosis"], [493, "due"], [493, "to"], [493, "the"], [493, "sudden"], [493, "outbreak"], [493, "of"], [493, "a"], [493, "novel"], [493, "pathogen"], [493, ","], [493, "sars"], [493, "-"], [493, "cov-2"], [493, "in"], [493, "2019"], [493, "."], [494, "the"], [494, "novel"], [494, "severe"], [494, "acute"], [494, "respiratory"], [494, "syndrome"], [494, "coronavirus"], [494, "2"], [494, "("], [494, "sars"], [494, "-"], [494, "cov-2"], [494, ")"], [494, ","], [494, "the"], [494, "causative"], [494, "agent"], [494, "of"], [494, "coronavirus"], [494, "disease"], [494, "2019"], [494, "("], [494, "covid-19"], [494, ")"], [494, ","], [494, "be"], [494, "declare"], [494, "a"], [494, "pandemic"], [494, "infection"], [494, "in"], [494, "march"], [494, "2020"], [494, "."], [495, "as"], [495, "of"], [495, "december"], [495, "2020"], [495, ","], [495, "two"], [495, "covid-19"], [495, "vaccine"], [495, "have"], [495, "be"], [495, "authorize"], [495, "for"], [495, "emergency"], [495, "use"], [495, "by"], [495, "the"], [495, "u.s"], [495, "."], [495, "food"], [495, "and"], [495, "drug"], [495, "administration"], [495, ","], [495, "but"], [495, "there"], [495, "be"], [495, "no"], [495, "effective"], [495, "drug"], [495, "to"], [495, "treat"], [495, "covid-19"], [495, ","], [495, "and"], [495, "pandemic"], [495, "mitigation"], [495, "effort"], [495, "like"], [495, "physical"], [495, "distancing"], [495, "have"], [495, "have"], [495, "acute"], [495, "social"], [495, "and"], [495, "economic"], [495, "consequence"], [495, "."], [496, "in"], [496, "this"], [496, "perspective"], [496, ","], [496, "we"], [496, "discuss"], [496, "how"], [496, "the"], [496, "proteomic"], [496, "research"], [496, "community"], [496, "can"], [496, "leverage"], [496, "technology"], [496, "and"], [496, "expertise"], [496, "to"], [496, "address"], [496, "the"], [496, "pandemic"], [496, "by"], [496, "investigate"], [496, "four"], [496, "key"], [496, "area"], [496, "of"], [496, "study"], [496, "in"], [496, "sars"], [496, "-"], [496, "cov-2"], [496, "biology"], [496, "."], [497, "specifically"], [497, ","], [497, "we"], [497, "discuss"], [497, "how"], [497, "("], [497, "1"], [497, ")"], [497, "mass"], [497, "spectrometry"], [497, "-"], [497, "base"], [497, "structural"], [497, "technique"], [497, "can"], [497, "overcome"], [497, "limitation"], [497, "and"], [497, "complement"], [497, "traditional"], [497, "structural"], [497, "approach"], [497, "to"], [497, "inform"], [497, "the"], [497, "dynamic"], [497, "structure"], [497, "of"], [497, "sars"], [497, "-"], [497, "cov-2"], [497, "protein"], [497, ","], [497, "complex"], [497, ","], [497, "and"], [497, "virion"], [497, ";"], [497, "("], [497, "2"], [497, ")"], [497, "virus"], [497, "-"], [497, "host"], [497, "protein"], [497, "-"], [497, "protein"], [497, "interaction"], [497, "mapping"], [497, "can"], [497, "identify"], [497, "the"], [497, "cellular"], [497, "machinery"], [497, "require"], [497, "for"], [497, "sars"], [497, "-"], [497, "cov-2"], [497, "replication"], [497, ";"], [497, "("], [497, "3"], [497, ")"], [497, "global"], [497, "protein"], [497, "abundance"], [497, "and"], [497, "post"], [497, "-"], [497, "translational"], [497, "modification"], [497, "profiling"], [497, "can"], [497, "characterize"], [497, "signal"], [497, "pathway"], [497, "that"], [497, "be"], [497, "rewire"], [497, "during"], [497, "infection"], [497, ";"], [497, "and"], [497, "("], [497, "4"], [497, ")"], [497, "proteomic"], [497, "technology"], [497, "can"], [497, "aid"], [497, "in"], [497, "biomarker"], [497, "identification"], [497, ","], [497, "diagnostic"], [497, ","], [497, "and"], [497, "drug"], [497, "development"], [497, "in"], [497, "order"], [497, "to"], [497, "monitor"], [497, "covid-19"], [497, "pathology"], [497, "and"], [497, "investigate"], [497, "treatment"], [497, "strategy"], [497, "."], [498, "system"], [498, "-"], [498, "level"], [498, "high"], [498, "-"], [498, "throughput"], [498, "capability"], [498, "of"], [498, "proteomic"], [498, "technology"], [498, "can"], [498, "yield"], [498, "important"], [498, "insight"], [498, "into"], [498, "sars"], [498, "-"], [498, "cov-2"], [498, "biology"], [498, "that"], [498, "be"], [498, "urgently"], [498, "nee"], [498, "during"], [498, "the"], [498, "pandemic"], [498, ","], [498, "and"], [498, "more"], [498, "broadly"], [498, ","], [498, "can"], [498, "inform"], [498, "coronavirus"], [498, "virology"], [498, "and"], [498, "host"], [498, "biology"], [498, "."], [499, "the"], [499, "on"], [499, "-"], [499, "go"], [499, "pandemic"], [499, "of"], [499, "covid-19"], [499, "wreak"], [499, "by"], [499, "a"], [499, "viral"], [499, "infection"], [499, "of"], [499, "sars"], [499, "-"], [499, "cov-2"], [499, ","], [499, "have"], [499, "generate"], [499, "a"], [499, "catastrophic"], [499, "plight"], [499, "across"], [499, "the"], [499, "globe"], [499, "."], [500, "interestingly"], [500, ","], [500, "one"], [500, "of"], [500, "the"], [500, "hallmark"], [500, "of"], [500, "covid-19"], [500, "be"], [500, "the"], [500, "so"], [500, "-"], [500, "call"], [500, "'"], [500, "cytokine"], [500, "storm"], [500, "'"], [500, "due"], [500, "to"], [500, "attack"], [500, "of"], [500, "sars"], [500, "-"], [500, "cov-2"], [500, "in"], [500, "the"], [500, "lung"], [500, "."], [501, "consider"], [501, ","], [501, "mesenchymal"], [501, "stem"], [501, "cell"], [501, "("], [501, "mscs"], [501, ")"], [501, "therapy"], [501, "could"], [501, "contribute"], [501, "against"], [501, "sars"], [501, "-"], [501, "cov-2"], [501, "virus"], [501, "attack"], [501, "because"], [501, "of"], [501, "their"], [501, "immune"], [501, "modulatory"], [501, "and"], [501, "anti"], [501, "-"], [501, "inflammatory"], [501, "ability"], [501, "link"], [501, "to"], [501, "their"], [501, "stemness"], [501, ","], [501, "to"], [501, "the"], [501, "arsenal"], [501, "of"], [501, "treatment"], [501, "for"], [501, "covid-19"], [501, "."], [502, "another"], [502, "novel"], [502, "therapeutic"], [502, "strategy"], [502, "include"], [502, "the"], [502, "blockade"], [502, "of"], [502, "rampant"], [502, "generation"], [502, "of"], [502, "pro"], [502, "-"], [502, "inflammatory"], [502, "mediator"], [502, "like"], [502, "acute"], [502, "respiratory"], [502, "distress"], [502, "syndrome"], [502, "("], [502, "ard"], [502, ")"], [502, ","], [502, "degradation"], [502, "of"], [502, "viral"], [502, "protein"], [502, "capsid"], [502, "by"], [502, "protac"], [502, ","], [502, "compose"], [502, "of"], [502, "ubiquitin"], [502, "-"], [502, "proteasome"], [502, "framework"], [502, ","], [502, "and"], [502, "ubiquitination"], [502, "-"], [502, "independent"], [502, "pathway"], [502, "direct"], [502, "the"], [502, "sars"], [502, "-"], [502, "cov-2"], [502, "nucleocapsid"], [502, "protein"], [502, "("], [502, "ncov"], [502, "n"], [502, ")"], [502, "and"], [502, "proteasome"], [502, "activator"], [502, "("], [502, "pa28\u03B3"], [502, ")"], [502, ","], [502, "etc"], [502, "."], [503, "this"], [503, "review"], [503, "be"], [503, "consequently"], [503, "an"], [503, "endeavour"], [503, "to"], [503, "highlight"], [503, "the"], [503, "several"], [503, "aspect"], [503, "of"], [503, "covid-19"], [503, "with"], [503, "incorporation"], [503, "of"], [503, "important"], [503, "treatment"], [503, "strategy"], [503, "discover"], [503, "to"], [503, "date"], [503, "and"], [503, "put"], [503, "the"], [503, "real"], [503, "effort"], [503, "on"], [503, "the"], [503, "future"], [503, "direction"], [503, "to"], [503, "put"], [503, "they"], [503, "into"], [503, "the"], [503, "perspective"], [503, "."], [504, "coronavirus"], [504, "disease"], [504, "2019"], [504, "("], [504, "covid-19"], [504, ")"], [504, "be"], [504, "cause"], [504, "by"], [504, "severe"], [504, "acute"], [504, "respiratory"], [504, "syndrome"], [504, "coronavirus"], [504, "2"], [504, "("], [504, "sars"], [504, "-"], [504, "cov-2"], [504, ")"], [504, ","], [504, "a"], [504, "newly"], [504, "emerge"], [504, "coronavirus"], [504, ","], [504, "and"], [504, "have"], [504, "be"], [504, "pandemic"], [504, "since"], [504, "march"], [504, "2020"], [504, "and"], [504, "lead"], [504, "to"], [504, "many"], [504, "fatality"], [504, "."], [505, "vaccine"], [505, "represent"], [505, "the"], [505, "most"], [505, "efficient"], [505, "mean"], [505, "to"], [505, "control"], [505, "and"], [505, "stop"], [505, "the"], [505, "pandemic"], [505, "of"], [505, "covid-19"], [505, "."], [506, "however"], [506, ","], [506, "currently"], [506, "there"], [506, "be"], [506, "no"], [506, "effective"], [506, "covid-19"], [506, "vaccine"], [506, "approve"], [506, "to"], [506, "use"], [506, "worldwide"], [506, "except"], [506, "for"], [506, "two"], [506, "human"], [506, "adenovirus"], [506, "vector"], [506, "vaccine"], [506, ","], [506, "three"], [506, "inactivated"], [506, "vaccine"], [506, ","], [506, "and"], [506, "one"], [506, "peptide"], [506, "vaccine"], [506, "for"], [506, "early"], [506, "or"], [506, "limited"], [506, "use"], [506, "in"], [506, "china"], [506, "and"], [506, "russia"], [506, "."], [507, "safe"], [507, "and"], [507, "effective"], [507, "vaccine"], [507, "against"], [507, "covid-19"], [507, "be"], [507, "in"], [507, "urgent"], [507, "need"], [507, "."], [508, "researcher"], [508, "around"], [508, "the"], [508, "world"], [508, "be"], [508, "develop"], [508, "213"], [508, "covid-19"], [508, "candidate"], [508, "vaccine"], [508, ","], [508, "among"], [508, "which"], [508, "44"], [508, "be"], [508, "in"], [508, "human"], [508, "trial"], [508, "."], [509, "in"], [509, "this"], [509, "review"], [509, ","], [509, "we"], [509, "summarize"], [509, "and"], [509, "analyze"], [509, "vaccine"], [509, "progress"], [509, "against"], [509, "sars"], [509, "-"], [509, "cov"], [509, ","], [509, "middle"], [509, "-"], [509, "east"], [509, "respiratory"], [509, "syndrome"], [509, "coronavirus"], [509, "("], [509, "mer"], [509, "-"], [509, "cov"], [509, ")"], [509, ","], [509, "and"], [509, "sars"], [509, "-"], [509, "cov-2"], [509, ","], [509, "include"], [509, "inactivated"], [509, "vaccine"], [509, ","], [509, "live"], [509, "attenuate"], [509, "vaccine"], [509, ","], [509, "subunit"], [509, "vaccine"], [509, ","], [509, "virus"], [509, "like"], [509, "particle"], [509, ","], [509, "nucleic"], [509, "acid"], [509, "vaccine"], [509, ","], [509, "and"], [509, "viral"], [509, "vector"], [509, "vaccine"], [509, "."], [510, "as"], [510, "sars"], [510, "-"], [510, "cov-2"], [510, ","], [510, "sars"], [510, "-"], [510, "cov"], [510, ","], [510, "and"], [510, "mer"], [510, "-"], [510, "cov"], [510, "share"], [510, "the"], [510, "common"], [510, "genus"], [510, ","], [510, ","], [510, "this"], [510, "review"], [510, "of"], [510, "the"], [510, "major"], [510, "research"], [510, "progress"], [510, "will"], [510, "provide"], [510, "a"], [510, "reference"], [510, "and"], [510, "new"], [510, "insight"], [510, "into"], [510, "the"], [510, "covid-19"], [510, "vaccine"], [510, "design"], [510, "and"], [510, "development"], [510, "."], [511, "covid-19"], [511, "be"], [511, "a"], [511, "respiratory"], [511, "illness"], [511, "cause"], [511, "by"], [511, "severe"], [511, "acute"], [511, "respiratory"], [511, "syndrome"], [511, "coronavirus"], [511, "2"], [511, "("], [511, "sars"], [511, "-"], [511, "cov-2"], [511, ")"], [511, "and"], [511, "declare"], [511, "by"], [511, "the"], [511, "world"], [511, "health"], [511, "organization"], [511, "a"], [511, "global"], [511, "public"], [511, "health"], [511, "emergency"], [511, "."], [512, "among"], [512, "the"], [512, "severe"], [512, "outbreak"], [512, "across"], [512, "south"], [512, "america"], [512, ","], [512, "uruguay"], [512, "have"], [512, "become"], [512, "know"], [512, "for"], [512, "curtail"], [512, "sars"], [512, "-"], [512, "cov-2"], [512, "exceptionally"], [512, "well"], [512, "."], [513, "to"], [513, "understand"], [513, "the"], [513, "sars"], [513, "-"], [513, "cov-2"], [513, "introduction"], [513, ","], [513, "local"], [513, "transmission"], [513, ","], [513, "and"], [513, "association"], [513, "with"], [513, "genomic"], [513, "and"], [513, "clinical"], [513, "parameter"], [513, "in"], [513, "uruguay"], [513, ","], [513, "we"], [513, "sequence"], [513, "the"], [513, "viral"], [513, "genome"], [513, "of"], [513, "44"], [513, "outpatient"], [513, "and"], [513, "inpatient"], [513, "in"], [513, "a"], [513, "private"], [513, "healthcare"], [513, "system"], [513, "in"], [513, "its"], [513, "capital"], [513, ","], [513, "montevideo"], [513, ","], [513, "from"], [513, "march"], [513, "to"], [513, "may"], [513, "2020"], [513, "."], [514, "we"], [514, "perform"], [514, "a"], [514, "phylogeographic"], [514, "analysis"], [514, "use"], [514, "sequence"], [514, "from"], [514, "our"], [514, "cohort"], [514, "and"], [514, "other"], [514, "study"], [514, "that"], [514, "indicate"], [514, "a"], [514, "minimum"], [514, "of"], [514, "23"], [514, "independent"], [514, "introduction"], [514, "into"], [514, "uruguay"], [514, ","], [514, "result"], [514, "in"], [514, "five"], [514, "major"], [514, "transmission"], [514, "cluster"], [514, "."], [515, "our"], [515, "datum"], [515, "suggest"], [515, "that"], [515, "most"], [515, "introduction"], [515, "result"], [515, "in"], [515, "chain"], [515, "of"], [515, "transmission"], [515, "originate"], [515, "from"], [515, "other"], [515, "south"], [515, "american"], [515, "country"], [515, ","], [515, "with"], [515, "the"], [515, "early"], [515, "seeding"], [515, "of"], [515, "the"], [515, "virus"], [515, "in"], [515, "late"], [515, "february"], [515, "2020"], [515, ","], [515, "week"], [515, "before"], [515, "the"], [515, "border"], [515, "be"], [515, "close"], [515, "to"], [515, "all"], [515, "non"], [515, "-"], [515, "citizen"], [515, "and"], [515, "a"], [515, "partial"], [515, "lockdown"], [515, "implement"], [515, "."], [516, "genetic"], [516, "analysis"], [516, "suggest"], [516, "a"], [516, "dominance"], [516, "of"], [516, "s"], [516, "and"], [516, "g"], [516, "clade"], [516, "("], [516, "g"], [516, ","], [516, "gh"], [516, ","], [516, "gr"], [516, ")"], [516, "that"], [516, "make"], [516, "up"], [516, ">"], [516, "90"], [516, "%"], [516, "of"], [516, "the"], [516, "viral"], [516, "strain"], [516, "in"], [516, "our"], [516, "study"], [516, "."], [517, "in"], [517, "our"], [517, "cohort"], [517, ","], [517, "lethal"], [517, "outcome"], [517, "of"], [517, "sars"], [517, "-"], [517, "cov-2"], [517, "infection"], [517, "significantly"], [517, "correlate"], [517, "with"], [517, "arterial"], [517, "hypertension"], [517, ","], [517, "kidney"], [517, "failure"], [517, ","], [517, "and"], [517, "icu"], [517, "admission"], [517, "("], [517, "fdr"], [517, "\u2009"], [517, "<"], [517, "\u2009"], [517, "0.01"], [517, ")"], [517, ","], [517, "but"], [517, "not"], [517, "with"], [517, "any"], [517, "mutation"], [517, "in"], [517, "a"], [517, "structural"], [517, "or"], [517, "non"], [517, "-"], [517, "structural"], [517, "protein"], [517, ","], [517, "such"], [517, "as"], [517, "the"], [517, "spike"], [517, "d614"], [517, "g"], [517, "mutation"], [517, "."], [518, "our"], [518, "study"], [518, "contribute"], [518, "genetic"], [518, ","], [518, "phylodynamic"], [518, ","], [518, "and"], [518, "clinical"], [518, "correlation"], [518, "datum"], [518, "about"], [518, "the"], [518, "exceptionally"], [518, "well"], [518, "-"], [518, "curb"], [518, "sars"], [518, "-"], [518, "cov-2"], [518, "outbreak"], [518, "in"], [518, "uruguay"], [518, ","], [518, "which"], [518, "far"], [518, "the"], [518, "understanding"], [518, "of"], [518, "disease"], [518, "pattern"], [518, "and"], [518, "regional"], [518, "aspect"], [518, "of"], [518, "the"], [518, "pandemic"], [518, "in"], [518, "latin"], [518, "america"], [518, "."], [519, "severe"], [519, "acute"], [519, "respiratory"], [519, "syndrome"], [519, "coronavirus"], [519, "2"], [519, "("], [519, "sars"], [519, "-"], [519, "cov-2"], [519, ")"], [519, "be"], [519, "a"], [519, "highly"], [519, "contagious"], [519, "zoonotic"], [519, "pathogen"], [519, "that"], [519, "have"], [519, "exact"], [519, "heavy"], [519, "public"], [519, "health"], [519, ","], [519, "social"], [519, "and"], [519, "economic"], [519, "toll"], [519, "."], [520, "in"], [520, "february"], [520, "2020"], [520, ","], [520, "the"], [520, "world"], [520, "health"], [520, "organization"], [520, "acronyme"], [520, "the"], [520, "disease"], [520, "cause"], [520, "by"], [520, "sars"], [520, "-"], [520, "cov-2"], [520, "as"], [520, "covid-19"], [520, ","], [520, "for"], [520, "coronavirus"], [520, "disease"], [520, "2019"], [520, "."], [521, "the"], [521, "number"], [521, "of"], [521, "confirm"], [521, "covid-19"], [521, "infection"], [521, ","], [521, "which"], [521, "have"], [521, "be"], [521, "detect"], [521, "in"], [521, "at"], [521, "least"], [521, "103"], [521, "country"], [521, ","], [521, "have"], [521, "reach"], [521, "1,970,225"], [521, "worldwide"], [521, "as"], [521, "of"], [521, "april"], [521, "14"], [521, ","], [521, "2020"], [521, "with"], [521, "124,544"], [521, "death"], [521, ","], [521, "accord"], [521, "to"], [521, "the"], [521, "u.s"], [521, "."], [521, "center"], [521, "for"], [521, "disease"], [521, "control"], [521, "and"], [521, "prevention"], [521, "("], [521, "cdc"], [521, ")"], [521, "."], [522, "many"], [522, "case"], [522, "of"], [522, "covid-19"], [522, "resolve"], [522, "quickly"], [522, "."], [523, "however"], [523, ","], [523, "the"], [523, "disease"], [523, ","], [523, "which"], [523, ","], [523, "like"], [523, "other"], [523, "respiratory"], [523, "pathogen"], [523, "that"], [523, "cause"], [523, "common"], [523, "cold"], [523, "symptom"], [523, "be"], [523, "believe"], [523, "to"], [523, "be"], [523, "transmit"], [523, "through"], [523, "respiratory"], [523, "droplet"], [523, "."], [524, "infection"], [524, "with"], [524, "covid-19"], [524, "can"], [524, "also"], [524, "lead"], [524, "to"], [524, "significant"], [524, "morbidity"], [524, "and"], [524, "death"], [524, ";"], [524, "this"], [524, "be"], [524, "particularly"], [524, "the"], [524, "case"], [524, "for"], [524, "cancer"], [524, "patient"], [524, "."], [525, "moreover"], [525, ","], [525, "because"], [525, "the"], [525, "sign"], [525, "and"], [525, "symptom"], [525, "of"], [525, "covid-19"], [525, "be"], [525, "easily"], [525, "misattribute"], [525, "to"], [525, "the"], [525, "sequelae"], [525, "of"], [525, "cancer"], [525, "itself"], [525, ","], [525, "such"], [525, "as"], [525, "pulmonary"], [525, "embolism"], [525, ","], [525, "or"], [525, "its"], [525, "treatment"], [525, ","], [525, "such"], [525, "as"], [525, "nausea"], [525, "and"], [525, "diarrhea"], [525, ","], [525, "diagnosis"], [525, "may"], [525, "be"], [525, "delay"], [525, "or"], [525, "miss"], [525, "."], [526, "potential"], [526, "covid-19"], [526, "rule"], [526, "out"], [526, "criterion"], [526, ","], [526, "base"], [526, "on"], [526, "the"], [526, "well"], [526, "'"], [526, "criterion"], [526, "for"], [526, "pulmonary"], [526, "embolism"], [526, ","], [526, "another"], [526, "protean"], [526, "disease"], [526, "entity"], [526, ","], [526, "be"], [526, "provide"], [526, "as"], [526, "a"], [526, "decision"], [526, "-"], [526, "make"], [526, "aid"], [526, "."], [527, "this"], [527, "review"], [527, "summarize"], [527, "the"], [527, "current"], [527, "understanding"], [527, "of"], [527, "the"], [527, "transmission"], [527, ","], [527, "clinical"], [527, "presentation"], [527, ","], [527, "diagnosis"], [527, "and"], [527, "differential"], [527, "diagnosis"], [527, ","], [527, "pathogenesis"], [527, ","], [527, "rationale"], [527, "to"], [527, "treat"], [527, "the"], [527, "cancer"], [527, "or"], [527, "not"], [527, ","], [527, "treatment"], [527, "and"], [527, "prevention"], [527, "of"], [527, "covid-19"], [527, "with"], [527, "an"], [527, "emphasis"], [527, "on"], [527, "implication"], [527, "in"], [527, "cancer"], [527, "."], [528, "accord"], [528, "to"], [528, "the"], [528, "world"], [528, "health"], [528, "organization"], [528, "("], [528, "who"], [528, ")"], [528, ","], [528, "the"], [528, "covid-19"], [528, "pandemic"], [528, "have"], [528, "be"], [528, "declare"], [528, "as"], [528, "a"], [528, "priority"], [528, "disease"], [528, "."], [529, "some"], [529, "patient"], [529, "with"], [529, "covid-19"], [529, "have"], [529, "symptom"], [529, "of"], [529, "multiple"], [529, "organ"], [529, "failure"], [529, "and"], [529, "death"], [529, "."], [530, "the"], [530, "publish"], [530, "article"], [530, "on"], [530, "covid-19"], [530, "infection"], [530, "be"], [530, "review"], [530, "."], [531, "the"], [531, "origin"], [531, "of"], [531, "sars"], [531, "-"], [531, "cov-2"], [531, "be"], [531, "still"], [531, "not"], [531, "completely"], [531, "establish"], [531, "."], [532, "person"], [532, "-"], [532, "to"], [532, "-"], [532, "person"], [532, "transmission"], [532, "via"], [532, "droplet"], [532, ","], [532, "probable"], [532, "aerosol"], [532, ","], [532, "or"], [532, "close"], [532, "contact"], [532, "be"], [532, "consider"], [532, "as"], [532, "the"], [532, "main"], [532, "mode"], [532, "of"], [532, "transmission"], [532, "."], [533, "with"], [533, "increase"], [533, "mortality"], [533, "due"], [533, "to"], [533, "sars"], [533, "-"], [533, "cov-2"], [533, ","], [533, "valuable"], [533, "clinical"], [533, "indicator"], [533, "or"], [533, "treatment"], [533, "should"], [533, "be"], [533, "far"], [533, "identify"], [533, "and"], [533, "summarize"], [533, "."], [534, "ct"], [534, "scan"], [534, "play"], [534, "an"], [534, "important"], [534, "role"], [534, "in"], [534, "the"], [534, "diagnosis"], [534, "and"], [534, "evaluation"], [534, "of"], [534, "covid-19"], [534, "in"], [534, "asymptomatic"], [534, "patient"], [534, "or"], [534, "those"], [534, "with"], [534, "initially"], [534, "negative"], [534, "rt"], [534, "-"], [534, "pcr"], [534, "result"], [534, "."], [535, "no"], [535, "specific"], [535, "antiviral"], [535, "therapy"], [535, "be"], [535, "recommend"], [535, ","], [535, "except"], [535, "the"], [535, "main"], [535, "supportive"], [535, "treatment"], [535, ","], [535, "and"], [535, "effective"], [535, "measure"], [535, "should"], [535, "be"], [535, "take"], [535, "into"], [535, "consideration"], [535, "to"], [535, "protect"], [535, "important"], [535, "organ"], [535, "and"], [535, "prevent"], [535, "the"], [535, "development"], [535, "of"], [535, "acute"], [535, "respiratory"], [535, "distress"], [535, "syndrome"], [535, "("], [535, "ard"], [535, ")"], [535, "in"], [535, "patient"], [535, "with"], [535, "severe"], [535, "infection"], [535, "."], [536, "sars"], [536, "-"], [536, "cov-2"], [536, "be"], [536, "responsible"], [536, "for"], [536, "the"], [536, "2019"], [536, "coronavirus"], [536, "disease"], [536, "("], [536, "covid-19"], [536, ")"], [536, ","], [536, "a"], [536, "global"], [536, "pandemic"], [536, "that"], [536, "begin"], [536, "in"], [536, "march"], [536, "2020"], [536, "and"], [536, "be"], [536, "currently"], [536, "in"], [536, "progress"], [536, "."], [537, "to"], [537, "date"], [537, ","], [537, "covid-19"], [537, "have"], [537, "cause"], [537, "about"], [537, "935,000"], [537, "death"], [537, "in"], [537, "more"], [537, "than"], [537, "200"], [537, "country"], [537, "."], [538, "the"], [538, "respiratory"], [538, "system"], [538, "be"], [538, "most"], [538, "affect"], [538, "by"], [538, "injury"], [538, "cause"], [538, "by"], [538, "covid-19"], [538, ","], [538, "but"], [538, "other"], [538, "organ"], [538, "may"], [538, "be"], [538, "involve"], [538, ","], [538, "include"], [538, "the"], [538, "cardiovascular"], [538, "system"], [538, "."], [539, "sars"], [539, "-"], [539, "cov-2"], [539, "penetrate"], [539, "host"], [539, "cell"], [539, "through"], [539, "the"], [539, "angiotensin"], [539, "2"], [539, "conversion"], [539, "enzyme"], [539, "("], [539, "ace-2"], [539, ")"], [539, "."], [540, "ace-2"], [540, "be"], [540, "express"], [540, "not"], [540, "only"], [540, "in"], [540, "the"], [540, "lung"], [540, ","], [540, "but"], [540, "also"], [540, "in"], [540, "other"], [540, "organ"], [540, ","], [540, "include"], [540, "the"], [540, "cardiovascular"], [540, "system"], [540, "."], [541, "several"], [541, "study"], [541, "have"], [541, "find"], [541, "that"], [541, "a"], [541, "good"], [541, "percentage"], [541, "of"], [541, "patient"], [541, "with"], [541, "severe"], [541, "covid-19"], [541, "have"], [541, "cardiac"], [541, "lesion"], [541, ","], [541, "include"], [541, "myocardial"], [541, "fibrosis"], [541, ","], [541, "edema"], [541, "and"], [541, "pericarditis"], [541, "."], [542, "pathological"], [542, "remodeling"], [542, "of"], [542, "the"], [542, "extracellular"], [542, "matrix"], [542, "cause"], [542, "by"], [542, "viral"], [542, "infection"], [542, "lead"], [542, "to"], [542, "myocardial"], [542, "fibrotic"], [542, "lesion"], [542, "."], [543, "these"], [543, "fibrotic"], [543, "scar"], [543, "can"], [543, "cause"], [543, "cardiac"], [543, "dysfunction"], [543, ","], [543, "reduce"], [543, "the"], [543, "ejection"], [543, "fraction"], [543, "cause"], [543, "by"], [543, "the"], [543, "presence"], [543, "of"], [543, "stiffen"], [543, "myocardial"], [543, "matrix"], [543, ","], [543, "or"], [543, "cardiac"], [543, "arrhythmias"], [543, "that"], [543, "cause"], [543, "an"], [543, "alteration"], [543, "in"], [543, "the"], [543, "electrical"], [543, "conduction"], [543, "system"], [543, "of"], [543, "the"], [543, "heart"], [543, "."], [544, "these"], [544, "cardiac"], [544, "dysfunction"], [544, "can"], [544, "cause"], [544, "death"], [544, "."], [545, "it"], [545, "be"], [545, "therefore"], [545, "essential"], [545, "to"], [545, "identify"], [545, "cardiac"], [545, "involvement"], [545, "early"], [545, "in"], [545, "order"], [545, "to"], [545, "act"], [545, "with"], [545, "appropriate"], [545, "therapeutic"], [545, "treatment"], [545, "."], [546, "in"], [546, "this"], [546, "review"], [546, ","], [546, "we"], [546, "describe"], [546, "what"], [546, "be"], [546, "know"], [546, "about"], [546, "cardiac"], [546, "injury"], [546, "from"], [546, "covid-19"], [546, ","], [546, "highlight"], [546, "effective"], [546, "pharmacological"], [546, "therapeutic"], [546, "solution"], [546, "to"], [546, "combat"], [546, "cardiac"], [546, "injury"], [546, ","], [546, "particularly"], [546, "cardiac"], [546, "fibrosis"], [546, ","], [546, "cause"], [546, "by"], [546, "covid-19"], [546, "."], [547, "urgent"], [547, "treatment"], [547, ","], [547, "in"], [547, "any"], [547, "modality"], [547, ","], [547, "to"], [547, "fight"], [547, "sars"], [547, "-"], [547, "cov-2"], [547, "infection"], [547, "be"], [547, "desire"], [547, "by"], [547, "society"], [547, "in"], [547, "general"], [547, ","], [547, "by"], [547, "health"], [547, "professional"], [547, ","], [547, "by"], [547, "estate"], [547, "-"], [547, "leader"], [547, "and"], [547, ","], [547, "mainly"], [547, ","], [547, "by"], [547, "the"], [547, "scientific"], [547, "community"], [547, ","], [547, "because"], [547, "one"], [547, "thing"], [547, "be"], [547, "certain"], [547, "amidst"], [547, "the"], [547, "numerous"], [547, "uncertainty"], [547, "regard"], [547, "covid-19"], [547, ":"], [547, "knowledge"], [547, "be"], [547, "the"], [547, "mean"], [547, "to"], [547, "discover"], [547, "or"], [547, "to"], [547, "produce"], [547, "an"], [547, "effective"], [547, "treatment"], [547, "against"], [547, "this"], [547, "global"], [547, "disease"], [547, "."], [548, "scientist"], [548, "from"], [548, "several"], [548, "area"], [548, "in"], [548, "the"], [548, "world"], [548, "be"], [548, "still"], [548, "commit"], [548, "to"], [548, "this"], [548, "mission"], [548, ","], [548, "as"], [548, "show"], [548, "by"], [548, "the"], [548, "accelerate"], [548, "scientific"], [548, "production"], [548, "in"], [548, "the"], [548, "first"], [548, "half"], [548, "of"], [548, "2020"], [548, "with"], [548, "over"], [548, "25,000"], [548, "publish"], [548, "article"], [548, "relate"], [548, "to"], [548, "the"], [548, "new"], [548, "coronavirus"], [548, "."], [549, "three"], [549, "great"], [549, "line"], [549, "of"], [549, "publication"], [549, "relate"], [549, "to"], [549, "covid-19"], [549, "be"], [549, "identify"], [549, "for"], [549, "build"], [549, "this"], [549, "article"], [549, ":"], [550, "the"], [550, "first"], [550, "refer"], [550, "to"], [550, "knowledge"], [550, "production"], [550, "concern"], [550, "the"], [550, "virus"], [550, "and"], [550, "pathophysiology"], [550, "of"], [550, "covid-19"], [550, ";"], [550, "the"], [550, "second"], [550, "regard"], [550, "effort"], [550, "to"], [550, "produce"], [550, "vaccine"], [550, "against"], [550, "sars"], [550, "-"], [550, "cov-2"], [550, "at"], [550, "a"], [550, "speed"], [550, "without"], [550, "precedent"], [550, "in"], [550, "the"], [550, "history"], [550, "of"], [550, "science"], [550, ";"], [550, "the"], [550, "third"], [550, "comprehend"], [550, "the"], [550, "attempt"], [550, "to"], [550, "find"], [550, "a"], [550, "market"], [550, "drug"], [550, "that"], [550, "can"], [550, "be"], [550, "use"], [550, "to"], [550, "treat"], [550, "covid-19"], [550, "by"], [550, "drug"], [550, "repurpose"], [550, "."], [551, "in"], [551, "this"], [551, "review"], [551, ","], [551, "the"], [551, "drug"], [551, "that"], [551, "have"], [551, "be"], [551, "repurpose"], [551, "so"], [551, "far"], [551, "be"], [551, "group"], [551, "accord"], [551, "to"], [551, "their"], [551, "chemical"], [551, "class"], [551, "."], [552, "their"], [552, "structure"], [552, "will"], [552, "be"], [552, "present"], [552, "to"], [552, "provide"], [552, "well"], [552, "understanding"], [552, "of"], [552, "their"], [552, "structural"], [552, "similarity"], [552, "and"], [552, "possible"], [552, "correlation"], [552, "with"], [552, "mechanism"], [552, "of"], [552, "action"], [552, "."], [553, "this"], [553, "can"], [553, "help"], [553, "identify"], [553, "anti"], [553, "-"], [553, "sar"], [553, "-"], [553, "cov-2"], [553, "promise"], [553, "therapeutic"], [553, "agent"], [553, "."], [554, "real"], [554, "-"], [554, "time"], [554, "reverse"], [554, "transcription"], [554, "pcr"], [554, "be"], [554, "currently"], [554, "the"], [554, "most"], [554, "sensitive"], [554, "method"], [554, "to"], [554, "detect"], [554, "severe"], [554, "acute"], [554, "respiratory"], [554, "syndrome"], [554, "coronavirus"], [554, "2"], [554, "("], [554, "sars"], [554, "-"], [554, "cov-2"], [554, ")"], [554, "."], [555, "define"], [555, "whether"], [555, "a"], [555, "patient"], [555, "could"], [555, "be"], [555, "contagious"], [555, "or"], [555, "not"], [555, "contagious"], [555, "in"], [555, "the"], [555, "presence"], [555, "of"], [555, "residual"], [555, "sars"], [555, "-"], [555, "cov-2"], [555, "rna"], [555, "be"], [555, "of"], [555, "extreme"], [555, "importance"], [555, "in"], [555, "the"], [555, "context"], [555, "of"], [555, "public"], [555, "health"], [555, "."], [556, "in"], [556, "this"], [556, "prospective"], [556, "multicenter"], [556, "study"], [556, ","], [556, "virus"], [556, "isolation"], [556, "be"], [556, "prospectively"], [556, "attempt"], [556, "in"], [556, "387"], [556, "nasal"], [556, "swab"], [556, "from"], [556, "clinically"], [556, "recover"], [556, "patient"], [556, "show"], [556, "low"], [556, "viral"], [556, "load"], [556, "("], [556, "quantification"], [556, "cycle"], [556, ","], [556, "cq"], [556, ","], [556, "value"], [556, "great"], [556, "than"], [556, "30"], [556, ")"], [556, "."], [557, "the"], [557, "median"], [557, "cq"], [557, "value"], [557, "be"], [557, "36.8"], [557, "("], [557, "range"], [557, "30.0"], [557, "-"], [557, "39.4"], [557, ")"], [557, "."], [558, "overall"], [558, ","], [558, "a"], [558, "cytopathic"], [558, "effect"], [558, "be"], [558, "detect"], [558, "in"], [558, "nine"], [558, "sample"], [558, ","], [558, "correspond"], [558, "to"], [558, "a"], [558, "culture"], [558, "positivity"], [558, "rate"], [558, "of"], [558, "2.3"], [558, "%"], [558, "("], [558, "9/387"], [558, ")"], [558, "."], [559, "the"], [559, "result"], [559, "of"], [559, "this"], [559, "study"], [559, "help"], [559, "to"], [559, "dissect"], [559, "true"], [559, "virus"], [559, "replication"], [559, "and"], [559, "residual"], [559, "viral"], [559, "rna"], [559, "detection"], [559, "in"], [559, "recover"], [559, "patient"], [559, "."], [560, "as"], [560, "the"], [560, "sars"], [560, "-"], [560, "cov-2"], [560, "pandemic"], [560, "unfold"], [560, "across"], [560, "the"], [560, "globe"], [560, ","], [560, "consistent"], [560, "theme"], [560, "be"], [560, "emerge"], [560, "with"], [560, "regard"], [560, "to"], [560, "aspect"], [560, "of"], [560, "sars"], [560, "-"], [560, "cov-2"], [560, "infection"], [560, "and"], [560, "its"], [560, "associated"], [560, "disease"], [560, "entity"], [560, "in"], [560, "child"], [560, "."], [561, "overall"], [561, ","], [561, "child"], [561, "appear"], [561, "to"], [561, "be"], [561, "less"], [561, "frequently"], [561, "infect"], [561, "by"], [561, ","], [561, "and"], [561, "affect"], [561, "by"], [561, ","], [561, "sars"], [561, "-"], [561, "cov-2"], [561, "virus"], [561, "and"], [561, "the"], [561, "clinical"], [561, "disease"], [561, "covid-19"], [561, "."], [562, "large"], [562, "epidemiological"], [562, "study"], [562, "have"], [562, "reveal"], [562, "child"], [562, "represent"], [562, "less"], [562, "than"], [562, "2"], [562, "%"], [562, "of"], [562, "the"], [562, "total"], [562, "confirm"], [562, "covid-19"], [562, "case"], [562, ","], [562, "of"], [562, "whom"], [562, "the"], [562, "majority"], [562, "experience"], [562, "minimal"], [562, "or"], [562, "mild"], [562, "disease"], [562, "that"], [562, "do"], [562, "not"], [562, "require"], [562, "hospitalisation"], [562, "."], [563, "child"], [563, "do"], [563, "not"], [563, "appear"], [563, "to"], [563, "be"], [563, "major"], [563, "driver"], [563, "of"], [563, "sars"], [563, "-"], [563, "cov-2"], [563, "transmission"], [563, ","], [563, "with"], [563, "minimal"], [563, "secondary"], [563, "virus"], [563, "transmission"], [563, "demonstrate"], [563, "within"], [563, "family"], [563, ","], [563, "school"], [563, "and"], [563, "community"], [563, "setting"], [563, "."], [564, "there"], [564, "be"], [564, "several"], [564, "postulated"], [564, "theory"], [564, "regard"], [564, "the"], [564, "relatively"], [564, "low"], [564, "sars"], [564, "-"], [564, "cov-2"], [564, "morbidity"], [564, "and"], [564, "mortality"], [564, "see"], [564, "in"], [564, "child"], [564, ","], [564, "which"], [564, "largely"], [564, "relate"], [564, "to"], [564, "difference"], [564, "in"], [564, "immune"], [564, "response"], [564, "compare"], [564, "to"], [564, "adult"], [564, ","], [564, "as"], [564, "well"], [564, "as"], [564, "difference"], [564, "in"], [564, "angiotensin"], [564, "convert"], [564, "enzyme"], [564, "2"], [564, "distribution"], [564, "that"], [564, "potentially"], [564, "limit"], [564, "viral"], [564, "entry"], [564, "and"], [564, "subsequent"], [564, "inflammation"], [564, ","], [564, "hypoxia"], [564, "and"], [564, "tissue"], [564, "injury"], [564, "."], [565, "the"], [565, "recent"], [565, "emergence"], [565, "of"], [565, "a"], [565, "multisystem"], [565, "inflammatory"], [565, "syndrome"], [565, "bear"], [565, "temporal"], [565, "and"], [565, "serological"], [565, "plausibility"], [565, "for"], [565, "an"], [565, "immune"], [565, "-"], [565, "mediate"], [565, "sars"], [565, "-"], [565, "cov-2"], [565, "-"], [565, "relate"], [565, "disease"], [565, "entity"], [565, "be"], [565, "currently"], [565, "under"], [565, "investigation"], [565, "."], [566, "this"], [566, "article"], [566, "summarise"], [566, "the"], [566, "current"], [566, "available"], [566, "datum"], [566, "regard"], [566, "sars"], [566, "-"], [566, "cov-2"], [566, "and"], [566, "the"], [566, "paediatric"], [566, "population"], [566, ","], [566, "include"], [566, "the"], [566, "spectrum"], [566, "of"], [566, "disease"], [566, "in"], [566, "child"], [566, ","], [566, "the"], [566, "role"], [566, "of"], [566, "child"], [566, "in"], [566, "virus"], [566, "transmission"], [566, ","], [566, "and"], [566, "host"], [566, "-"], [566, "virus"], [566, "factor"], [566, "that"], [566, "underpin"], [566, "the"], [566, "unique"], [566, "aspect"], [566, "of"], [566, "sars"], [566, "-"], [566, "cov-2"], [566, "pathogenicity"], [566, "in"], [566, "child"], [566, "."], [567, "the"], [567, "ongoing"], [567, "sars"], [567, "-"], [567, "cov-2"], [567, "pandemic"], [567, "have"], [567, "lead"], [567, "to"], [567, "the"], [567, "focused"], [567, "application"], [567, "of"], [567, "resource"], [567, "and"], [567, "scientific"], [567, "expertise"], [567, "toward"], [567, "the"], [567, "goal"], [567, "of"], [567, "develop"], [567, "investigational"], [567, "vaccine"], [567, "to"], [567, "prevent"], [567, "covid-19"], [567, "."], [568, "the"], [568, "highly"], [568, "collaborative"], [568, "global"], [568, "effort"], [568, "by"], [568, "private"], [568, "industry"], [568, ","], [568, "government"], [568, "and"], [568, "non"], [568, "-"], [568, "governmental"], [568, "organization"], [568, "have"], [568, "result"], [568, "in"], [568, "a"], [568, "number"], [568, "of"], [568, "sars"], [568, "-"], [568, "cov-2"], [568, "vaccine"], [568, "candidate"], [568, "move"], [568, "to"], [568, "phase"], [568, "iii"], [568, "trial"], [568, "in"], [568, "a"], [568, "period"], [568, "of"], [568, "only"], [568, "month"], [568, "since"], [568, "the"], [568, "start"], [568, "of"], [568, "the"], [568, "pandemic"], [568, "."], [569, "in"], [569, "this"], [569, "review"], [569, ","], [569, "we"], [569, "provide"], [569, "an"], [569, "overview"], [569, "of"], [569, "the"], [569, "preclinical"], [569, "and"], [569, "clinical"], [569, "datum"], [569, "on"], [569, "sars"], [569, "-"], [569, "cov-2"], [569, "vaccine"], [569, "that"], [569, "be"], [569, "currently"], [569, "in"], [569, "phase"], [569, "iii"], [569, "clinical"], [569, "trial"], [569, "and"], [569, "in"], [569, "few"], [569, "case"], [569, "authorize"], [569, "for"], [569, "emergency"], [569, "use"], [569, "."], [570, "we"], [570, "far"], [570, "discuss"], [570, "relevant"], [570, "vaccine"], [570, "platform"], [570, "and"], [570, "provide"], [570, "a"], [570, "discussion"], [570, "of"], [570, "sars"], [570, "-"], [570, "cov-2"], [570, "antigen"], [570, "that"], [570, "may"], [570, "be"], [570, "target"], [570, "to"], [570, "increase"], [570, "the"], [570, "breadth"], [570, "and"], [570, "durability"], [570, "of"], [570, "vaccine"], [570, "response"], [570, "."], [571, "the"], [571, "coronavirus"], [571, "disease"], [571, "2019"], [571, "("], [571, "covid-19"], [571, ")"], [571, "pandemic"], [571, "continue"], [571, "to"], [571, "spread"], [571, "across"], [571, "the"], [571, "world"], [571, "."], [572, "hence"], [572, ","], [572, "there"], [572, "be"], [572, "an"], [572, "urgent"], [572, "need"], [572, "for"], [572, "rapid"], [572, ","], [572, "simple"], [572, ","], [572, "and"], [572, "accurate"], [572, "test"], [572, "to"], [572, "diagnose"], [572, "severe"], [572, "acute"], [572, "respiratory"], [572, "syndrome"], [572, "coronavirus"], [572, "2"], [572, "("], [572, "sars"], [572, "-"], [572, "cov-2"], [572, ")"], [572, "infection"], [572, "."], [573, "performance"], [573, "characteristic"], [573, "of"], [573, "the"], [573, "rapid"], [573, "sars"], [573, "-"], [573, "cov-2"], [573, "antigen"], [573, "detection"], [573, "test"], [573, "should"], [573, "be"], [573, "evaluate"], [573, "and"], [573, "compare"], [573, "with"], [573, "the"], [573, "gold"], [573, "standard"], [573, "real"], [573, "-"], [573, "time"], [573, "reverse"], [573, "transcription"], [573, "-"], [573, "polymerase"], [573, "chain"], [573, "reaction"], [573, "("], [573, "rt"], [573, "-"], [573, "pcr"], [573, ")"], [573, "test"], [573, "for"], [573, "diagnosis"], [573, "of"], [573, "covid-19"], [573, "case"], [573, "."], [574, "the"], [574, "rapid"], [574, "sars"], [574, "-"], [574, "cov-2"], [574, "antigen"], [574, "detection"], [574, "test"], [574, ","], [574, "standard"], [574, "\u2122"], [574, "q"], [574, "covid-19"], [574, "ag"], [574, "kit"], [574, "("], [574, "sd"], [574, "biosensor"], [574, "\xAE"], [574, ","], [574, "republic"], [574, "of"], [574, "korea"], [574, ")"], [574, ","], [574, "be"], [574, "compare"], [574, "with"], [574, "the"], [574, "real"], [574, "-"], [574, "time"], [574, "rt"], [574, "-"], [574, "pcr"], [574, "test"], [574, ","], [574, "allplex"], [574, "\u2122"], [574, "2019"], [574, "-"], [574, "ncov"], [574, "assay"], [574, "("], [574, "seegene"], [574, "\xAE"], [574, ","], [574, "korea"], [574, ")"], [574, "for"], [574, "detection"], [574, "of"], [574, "sars"], [574, "-"], [574, "cov-2"], [574, "in"], [574, "respiratory"], [574, "speciman"], [574, "."], [575, "four"], [575, "hundred"], [575, "fifty"], [575, "-"], [575, "four"], [575, "respiratory"], [575, "sample"], [575, "("], [575, "mainly"], [575, "nasopharyngeal"], [575, "and"], [575, "throat"], [575, "swab"], [575, ")"], [575, "be"], [575, "obtain"], [575, "from"], [575, "covid-19"], [575, "suspect"], [575, "case"], [575, "and"], [575, "contact"], [575, "individual"], [575, ","], [575, "include"], [575, "pre"], [575, "-"], [575, "operative"], [575, "patient"], [575, "at"], [575, "siriraj"], [575, "hospital"], [575, ","], [575, "bangkok"], [575, ","], [575, "thailand"], [575, "during"], [575, "march"], [575, "-"], [575, "may"], [575, "2020"], [575, "."], [576, "of"], [576, "454"], [576, "respiratory"], [576, "sample"], [576, ","], [576, "60"], [576, "("], [576, "13.2"], [576, "%"], [576, ")"], [576, "be"], [576, "positive"], [576, ","], [576, "and"], [576, "394"], [576, "("], [576, "86.8"], [576, "%"], [576, ")"], [576, "be"], [576, "negative"], [576, "for"], [576, "sars"], [576, "-"], [576, "cov-2"], [576, "rna"], [576, "by"], [576, "real"], [576, "-"], [576, "time"], [576, "rt"], [576, "-"], [576, "pcr"], [576, "assay"], [576, "."], [577, "the"], [577, "duration"], [577, "from"], [577, "onset"], [577, "to"], [577, "laboratory"], [577, "test"], [577, "in"], [577, "covid-19"], [577, "suspect"], [577, "case"], [577, "and"], [577, "contact"], [577, "individual"], [577, "range"], [577, "from"], [577, "0"], [577, "to"], [577, "14"], [577, "\xA0"], [577, "day"], [577, "with"], [577, "a"], [577, "median"], [577, "of"], [577, "3"], [577, "\xA0"], [577, "day"], [577, "."], [578, "the"], [578, "rapid"], [578, "sars"], [578, "-"], [578, "cov-2"], [578, "antigen"], [578, "detection"], [578, "test"], [578, "'s"], [578, "sensitivity"], [578, "and"], [578, "specificity"], [578, "be"], [578, "98.33"], [578, "%"], [578, "("], [578, "95"], [578, "%"], [578, "ci"], [578, ","], [578, "91.06"], [578, "-"], [578, "99.96"], [578, "%"], [578, ")"], [578, "and"], [578, "98.73"], [578, "%"], [578, "("], [578, "95"], [578, "%"], [578, "ci"], [578, ","], [578, "97.06"], [578, "-"], [578, "99.59"], [578, "%"], [578, ")"], [578, ","], [578, "respectively"], [578, "."], [579, "one"], [579, "false"], [579, "negative"], [579, "test"], [579, "result"], [579, "be"], [579, "from"], [579, "a"], [579, "sample"], [579, "with"], [579, "a"], [579, "high"], [579, "real"], [579, "-"], [579, "time"], [579, "rt"], [579, "-"], [579, "pcr"], [579, "cycle"], [579, "threshold"], [579, "("], [579, "ct"], [579, ")"], [579, ","], [579, "while"], [579, "five"], [579, "false"], [579, "positive"], [579, "test"], [579, "result"], [579, "be"], [579, "from"], [579, "speciman"], [579, "of"], [579, "pre"], [579, "-"], [579, "operative"], [579, "patient"], [579, "."], [580, "the"], [580, "rapid"], [580, "assay"], [580, "for"], [580, "sars"], [580, "-"], [580, "cov-2"], [580, "antigen"], [580, "detection"], [580, "show"], [580, "comparable"], [580, "sensitivity"], [580, "and"], [580, "specificity"], [580, "with"], [580, "the"], [580, "real"], [580, "-"], [580, "time"], [580, "rt"], [580, "-"], [580, "pcr"], [580, "assay"], [580, "."], [581, "thus"], [581, ","], [581, "there"], [581, "be"], [581, "a"], [581, "potential"], [581, "use"], [581, "of"], [581, "this"], [581, "rapid"], [581, "and"], [581, "simple"], [581, "sars"], [581, "-"], [581, "cov-2"], [581, "antigen"], [581, "detection"], [581, "test"], [581, "as"], [581, "a"], [581, "screening"], [581, "assay"], [581, "."], [582, "two"], [582, "new"], [582, "sars"], [582, "-"], [582, "cov-2"], [582, "lineage"], [582, "with"], [582, "the"], [582, "n501y"], [582, "mutation"], [582, "in"], [582, "the"], [582, "receptor"], [582, "-"], [582, "bind"], [582, "domain"], [582, "of"], [582, "the"], [582, "spike"], [582, "protein"], [582, "spread"], [582, "rapidly"], [582, "in"], [582, "the"], [582, "united"], [582, "kingdom"], [582, "."], [583, "we"], [583, "estimate"], [583, "that"], [583, "the"], [583, "early"], [583, "501y"], [583, "lineage"], [583, "without"], [583, "amino"], [583, "acid"], [583, "deletion"], [583, "\u03B469"], [583, "/"], [583, "\u03B470"], [583, ","], [583, "circulate"], [583, "mainly"], [583, "between"], [583, "early"], [583, "september"], [583, "and"], [583, "mid"], [583, "-"], [583, "november"], [583, ","], [583, "be"], [583, "10"], [583, "%"], [583, "("], [583, "6"], [583, "-"], [583, "13"], [583, "%"], [583, ")"], [583, "more"], [583, "transmissible"], [583, "than"], [583, "the"], [583, "501n"], [583, "lineage"], [583, ","], [583, "and"], [583, "the"], [583, "501y"], [583, "lineage"], [583, "with"], [583, "amino"], [583, "acid"], [583, "deletion"], [583, "\u03B469"], [583, "/"], [583, "\u03B470"], [583, ","], [583, "circulate"], [583, "since"], [583, "late"], [583, "september"], [583, ","], [583, "be"], [583, "75"], [583, "%"], [583, "("], [583, "70"], [583, "-"], [583, "80"], [583, "%"], [583, ")"], [583, "more"], [583, "transmissible"], [583, "than"], [583, "the"], [583, "501n"], [583, "lineage"], [583, "."], [584, "infection"], [584, "with"], [584, "the"], [584, "severe"], [584, "acute"], [584, "respiratory"], [584, "syndrome"], [584, "coronavirus-2"], [584, "("], [584, "sars"], [584, "-"], [584, "cov-2"], [584, ")"], [584, "result"], [584, "in"], [584, "diverse"], [584, "outcome"], [584, "."], [585, "the"], [585, "symptom"], [585, "appear"], [585, "to"], [585, "be"], [585, "more"], [585, "severe"], [585, "in"], [585, "male"], [585, "old"], [585, "than"], [585, "65"], [585, "and"], [585, "people"], [585, "with"], [585, "underlie"], [585, "health"], [585, "condition"], [585, ";"], [585, "approximately"], [585, "one"], [585, "in"], [585, "five"], [585, "individual"], [585, "could"], [585, "be"], [585, "at"], [585, "risk"], [585, "worldwide"], [585, "."], [586, "the"], [586, "virus"], [586, "'s"], [586, "sequence"], [586, "be"], [586, "rapidly"], [586, "establish"], [586, "day"], [586, "after"], [586, "the"], [586, "first"], [586, "case"], [586, "be"], [586, "report"], [586, "and"], [586, "identify"], [586, "an"], [586, "rna"], [586, "virus"], [586, "from"], [586, "the"], [586, "coronaviridae"], [586, "family"], [586, "closely"], [586, "relate"], [586, "to"], [586, "a"], [586, "betacoronavirus"], [586, "virus"], [586, "find"], [586, "in"], [586, "bat"], [586, "in"], [586, "china"], [586, "."], [587, "sars"], [587, "-"], [587, "cov-2"], [587, "be"], [587, "the"], [587, "seventh"], [587, "coronavirus"], [587, "know"], [587, "to"], [587, "infect"], [587, "human"], [587, ","], [587, "and"], [587, "with"], [587, "the"], [587, "severe"], [587, "acute"], [587, "respiratory"], [587, "syndrome"], [587, "("], [587, "sars"], [587, ")"], [587, "and"], [587, "the"], [587, "middle"], [587, "east"], [587, "respiratory"], [587, "syndrome"], [587, "("], [587, "mer"], [587, ")"], [587, ","], [587, "the"], [587, "only"], [587, "one"], [587, "to"], [587, "cause"], [587, "severe"], [587, "disease"], [587, "."], [588, "lesson"], [588, "from"], [588, "these"], [588, "two"], [588, "previous"], [588, "outbreak"], [588, "guide"], [588, "the"], [588, "identification"], [588, "of"], [588, "critical"], [588, "therapeutic"], [588, "target"], [588, "such"], [588, "as"], [588, "the"], [588, "spike"], [588, "viral"], [588, "protein"], [588, "promote"], [588, "the"], [588, "virus"], [588, "'s"], [588, "cellular"], [588, "entry"], [588, "through"], [588, "the"], [588, "angiotensin"], [588, "-"], [588, "convert"], [588, "enzyme"], [588, "2"], [588, "("], [588, "ace2"], [588, ")"], [588, "receptor"], [588, "express"], [588, "on"], [588, "the"], [588, "surface"], [588, "of"], [588, "multiple"], [588, "type"], [588, "of"], [588, "eukaryotic"], [588, "cell"], [588, "."], [589, "although"], [589, "several"], [589, "therapeutic"], [589, "agent"], [589, "be"], [589, "currently"], [589, "evaluate"], [589, ","], [589, "none"], [589, "seem"], [589, "to"], [589, "provide"], [589, "a"], [589, "clear"], [589, "path"], [589, "for"], [589, "a"], [589, "cure"], [589, "."], [590, "also"], [590, ","], [590, "various"], [590, "type"], [590, "of"], [590, "vaccine"], [590, "be"], [590, "develop"], [590, "in"], [590, "record"], [590, "time"], [590, "to"], [590, "address"], [590, "the"], [590, "urgency"], [590, "of"], [590, "efficient"], [590, "sars"], [590, "-"], [590, "cov-2"], [590, "prevention"], [590, "."], [591, "currently"], [591, ","], [591, "58"], [591, "vaccine"], [591, "be"], [591, "evaluate"], [591, "in"], [591, "clinical"], [591, "trial"], [591, ","], [591, "include"], [591, "11"], [591, "in"], [591, "phase"], [591, "iii"], [591, ","], [591, "and"], [591, "3"], [591, "of"], [591, "they"], [591, "report"], [591, "efficacy"], [591, "above"], [591, "90"], [591, "%"], [591, "."], [592, "the"], [592, "result"], [592, "so"], [592, "far"], [592, "from"], [592, "the"], [592, "clinical"], [592, "trial"], [592, "suggest"], [592, "the"], [592, "availability"], [592, "of"], [592, "multiple"], [592, "effective"], [592, "vaccine"], [592, "within"], [592, "month"], [592, "."], [593, "there"], [593, "be"], [593, "several"], [593, "type"], [593, "of"], [593, "research"], [593, "on"], [593, "the"], [593, "covid-19"], [593, "disease"], [593, "which"], [593, "have"], [593, "be"], [593, "conduct"], [593, "."], [594, "it"], [594, "seem"], [594, "that"], [594, "prevail"], [594, "over"], [594, "the"], [594, "pandemic"], [594, "would"], [594, "be"], [594, "achieve"], [594, "only"], [594, "by"], [594, "master"], [594, "over"], [594, "the"], [594, "virus"], [594, "pathophysiology"], [594, "."], [595, "we"], [595, "try"], [595, "to"], [595, "categorize"], [595, "the"], [595, "massive"], [595, "amount"], [595, "of"], [595, "available"], [595, "information"], [595, "for"], [595, "useful"], [595, "interpretation"], [595, "."], [596, "we"], [596, "search"], [596, "database"], [596, "with"], [596, "different"], [596, "keyword"], [596, "and"], [596, "search"], [596, "strategy"], [596, "that"], [596, "focus"], [596, "on"], [596, "virulence"], [596, "and"], [596, "pathophysiology"], [596, "of"], [596, "covid-19"], [596, "."], [597, "the"], [597, "present"], [597, "review"], [597, "have"], [597, "aim"], [597, "to"], [597, "gather"], [597, "and"], [597, "categorize"], [597, "all"], [597, "implement"], [597, "drug"], [597, "base"], [597, "on"], [597, "the"], [597, "susceptible"], [597, "virulence"], [597, "mechanism"], [597, ","], [597, "and"], [597, "the"], [597, "pathophysiological"], [597, "event"], [597, "in"], [597, "the"], [597, "host"], [597, "cell"], [597, ","], [597, "discuss"], [597, "and"], [597, "suggest"], [597, "treatment"], [597, "."], [598, "as"], [598, "a"], [598, "result"], [598, ","], [598, "the"], [598, "covid-19"], [598, "lifecycle"], [598, "be"], [598, "categorize"], [598, "as"], [598, "follow"], [598, "step"], [598, ":"], [598, '"'], [598, "host"], [598, "cell"], [598, "attachment"], [598, '"'], [598, "which"], [598, "be"], [598, "mainly"], [598, "conduct"], [598, "with"], [598, "ace"], [598, "receptor"], [598, "and"], [598, "tmprss2"], [598, "from"], [598, "the"], [598, "host"], [598, "cell"], [598, "and"], [598, "spike"], [598, "("], [598, "s"], [598, ")"], [598, "protein"], [598, ","], [598, '"'], [598, "endocytosis"], [598, "pathway"], [598, '"'], [598, "which"], [598, "be"], [598, "perform"], [598, "mainly"], [598, "by"], [598, "clathrin"], [598, "-"], [598, "mediate"], [598, "endocytosis"], [598, ","], [598, "and"], [598, '"'], [598, "viral"], [598, "replication"], [598, '"'], [598, "which"], [598, "contain"], [598, "translation"], [598, "and"], [598, "replication"], [598, "of"], [598, "rna"], [598, "viral"], [598, "genome"], [598, "."], [599, "the"], [599, "virus"], [599, "pathogenicity"], [599, "be"], [599, "continue"], [599, "by"], [599, '"'], [599, "inflammatory"], [599, "reaction"], [599, '"'], [599, "which"], [599, "mainly"], [599, "cause"], [599, "moderate"], [599, "to"], [599, "severe"], [599, "covid-19"], [599, "disease"], [599, "."], [600, "besides"], [600, ","], [600, "the"], [600, "possible"], [600, "effective"], [600, "therapeutic"], [600, "'"], [600, "mechanism"], [600, "and"], [600, "the"], [600, "pharmaceutical"], [600, "agent"], [600, "that"], [600, "have"], [600, "at"], [600, "least"], [600, "one"], [600, "experience"], [600, "as"], [600, "a"], [600, "preclinical"], [600, "or"], [600, "clinical"], [600, "study"], [600, "on"], [600, "covid-19"], [600, "be"], [600, "clearly"], [600, "define"], [600, "."], [601, "the"], [601, "treatment"], [601, "protocol"], [601, "would"], [601, "be"], [601, "occasional"], [601, "base"], [601, "on"], [601, "the"], [601, "stage"], [601, "of"], [601, "the"], [601, "infection"], [601, "and"], [601, "the"], [601, "patient"], [601, "situation"], [601, "."], [602, "the"], [602, "cocktail"], [602, "of"], [602, "medicine"], [602, ","], [602, "which"], [602, "could"], [602, "affect"], [602, "almost"], [602, "all"], [602, "mention"], [602, "stage"], [602, "of"], [602, "covid-19"], [602, "disease"], [602, ","], [602, "might"], [602, "be"], [602, "vital"], [602, "for"], [602, "patient"], [602, "with"], [602, "severe"], [602, "phenomena"], [602, "."], [603, "the"], [603, "classification"], [603, "of"], [603, "the"], [603, "possible"], [603, "mechanism"], [603, "of"], [603, "medicine"], [603, "base"], [603, "on"], [603, "covid-19"], [603, "pathogenicity"], [603, "."], [604, "the"], [604, "sudden"], [604, "emergence"], [604, "of"], [604, "the"], [604, "novel"], [604, "severe"], [604, "acute"], [604, "respiratory"], [604, "syndrome"], [604, "coronavirus"], [604, "2"], [604, "("], [604, "sars"], [604, "-"], [604, "cov-2"], [604, ")"], [604, "cause"], [604, "the"], [604, "coronavirus"], [604, "disease"], [604, "of"], [604, "2019"], [604, "("], [604, "covid-19"], [604, ")"], [604, "have"], [604, "bre"], [604, "the"], [604, "world"], [604, "to"], [604, "a"], [604, "standstill"], [604, "."], [605, "thousand"], [605, "of"], [605, "people"], [605, "across"], [605, "the"], [605, "globe"], [605, "be"], [605, "bite"], [605, "the"], [605, "dust"], [605, "with"], [605, "every"], [605, "pass"], [605, "day"], [605, "and"], [605, "yet"], [605, "more"], [605, "be"], [605, "be"], [605, "test"], [605, "positive"], [605, "for"], [605, "the"], [605, "sars"], [605, "-"], [605, "cov-2"], [605, "infection"], [605, "."], [606, "in"], [606, "order"], [606, "to"], [606, "dispense"], [606, "this"], [606, "current"], [606, "crisis"], [606, ","], [606, "numerous"], [606, "treatment"], [606, "option"], [606, "have"], [606, "be"], [606, "try"], [606, "and"], [606, "test"], [606, "and"], [606, "many"], [606, "more"], [606, "be"], [606, "still"], [606, "under"], [606, "scrutiny"], [606, "."], [607, "the"], [607, "development"], [607, "of"], [607, "vaccine"], [607, "may"], [607, "help"], [607, "in"], [607, "the"], [607, "prevention"], [607, "of"], [607, "the"], [607, "global"], [607, "pandemic"], [607, ","], [607, "however"], [607, ","], [607, "there"], [607, "be"], [607, "still"], [607, "a"], [607, "need"], [607, "for"], [607, "the"], [607, "development"], [607, "of"], [607, "alternate"], [607, "approach"], [607, "to"], [607, "combat"], [607, "the"], [607, "disease"], [607, "."], [608, "in"], [608, "this"], [608, "review"], [608, "we"], [608, "highlight"], [608, "the"], [608, "new"], [608, "discovery"], [608, "and"], [608, "furtherance"], [608, "in"], [608, "the"], [608, "antibody"], [608, "base"], [608, "therapeutic"], [608, "option"], [608, "and"], [608, "the"], [608, "potent"], [608, "drug"], [608, ","], [608, "with"], [608, "special"], [608, "emphasis"], [608, "on"], [608, "the"], [608, "development"], [608, "of"], [608, "the"], [608, "monoclonal"], [608, "and"], [608, "polyclonal"], [608, "antibody"], [608, "and"], [608, "the"], [608, "repurpose"], [608, "drug"], [608, ","], [608, "which"], [608, "may"], [608, "prove"], [608, "to"], [608, "be"], [608, "of"], [608, "significant"], [608, "importance"], [608, "for"], [608, "the"], [608, "treatment"], [608, "of"], [608, "covid-19"], [608, ","], [608, "in"], [608, "the"], [608, "day"], [608, "to"], [608, "come"], [608, "."], [609, "it"], [609, "be"], [609, "an"], [609, "attempt"], [609, "to"], [609, "evaluate"], [609, "the"], [609, "currently"], [609, "present"], [609, "challenge"], [609, "so"], [609, "as"], [609, "to"], [609, "provide"], [609, "a"], [609, "scope"], [609, "for"], [609, "the"], [609, "ongoing"], [609, "research"], [609, "and"], [609, "assistance"], [609, "in"], [609, "the"], [609, "development"], [609, "of"], [609, "the"], [609, "effective"], [609, "therapeutic"], [609, "option"], [609, "against"], [609, "sars"], [609, "-"], [609, "cov-2"], [609, "."], [610, "covid-19"], [610, "convalescent"], [610, "plasma"], [610, "("], [610, "ccp"], [610, ")"], [610, "therapy"], [610, "involve"], [610, "the"], [610, "use"], [610, "of"], [610, "circulate"], [610, "antibody"], [610, "administration"], [610, "from"], [610, "recover"], [610, "covid"], [610, "19"], [610, "patient"], [610, "as"], [610, "a"], [610, "practical"], [610, "strategy"], [610, "to"], [610, "provide"], [610, "immediate"], [610, "passive"], [610, "immunity"], [610, "in"], [610, "susceptible"], [610, "recipient"], [610, "in"], [610, "need"], [610, "."], [611, "global"], [611, "concern"], [611, "over"], [611, "the"], [611, "potential"], [611, "for"], [611, '"'], [611, "second"], [611, '"'], [611, "or"], [611, '"'], [611, "third"], [611, '"'], [611, "wave"], [611, "of"], [611, "infection"], [611, "to"], [611, "occur"], [611, "before"], [611, "effective"], [611, "vaccine"], [611, "or"], [611, "drug"], [611, "therapy"], [611, "be"], [611, "available"], [611, "have"], [611, "many"], [611, "look"], [611, "at"], [611, "other"], [611, "biological"], [611, "source"], [611, "for"], [611, "large"], [611, "-"], [611, "scale"], [611, "production"], [611, "of"], [611, "neutralize"], [611, "sars"], [611, "-"], [611, "cov-2"], [611, "antibody"], [611, "."], [612, "this"], [612, "report"], [612, "summarize"], [612, "some"], [612, "of"], [612, "the"], [612, "novel"], [612, "strategy"], [612, "for"], [612, "develop"], [612, "alternative"], [612, "safe"], [612, "source"], [612, "of"], [612, "therapeutic"], [612, "autologous"], [612, "antibody"], [612, "from"], [612, "covid"], [612, "-19"], [612, "infect"], [612, "patient"], [612, ","], [612, "and"], [612, "provide"], [612, "some"], [612, "original"], [612, "thought"], [612, "on"], [612, "how"], [612, "to"], [612, "rapidly"], [612, "implement"], [612, "a"], [612, "safe"], [612, "passive"], [612, "immunity"], [612, "in"], [612, "those"], [612, "covid-19"], [612, "patient"], [612, "who"], [612, "be"], [612, "most"], [612, "in"], [612, "need"], [612, "of"], [612, "intervention"], [612, "."], [613, "covid-19"], [613, "antibody"], [613, "can"], [613, "be"], [613, "isolate"], [613, "or"], [613, "deliver"], [613, "use"], [613, "a"], [613, "number"], [613, "of"], [613, "other"], [613, "technique"], [613, "include"], [613, ":"], [613, "plasmapheresis"], [613, ","], [613, "plasma"], [613, "cryoprecipitate"], [613, "reduce"], [613, "("], [613, "cryosupernatant"], [613, ")"], [613, ","], [613, "antibody"], [613, "hyperconcentrate"], [613, "and"], [613, "advanced"], [613, "cell"], [613, "-"], [613, "base"], [613, "delivery"], [613, "system"], [613, "."], [614, "while"], [614, "these"], [614, "propose"], [614, "technological"], [614, "option"], [614, "may"], [614, ","], [614, "in"], [614, "some"], [614, "case"], [614, ","], [614, "be"], [614, "theoretical"], [614, ","], [614, "the"], [614, "grow"], [614, "concern"], [614, "over"], [614, "the"], [614, "rapid"], [614, "spread"], [614, "of"], [614, "the"], [614, "sars"], [614, "-"], [614, "cov-2"], [614, "virus"], [614, "have"], [614, "prompt"], [614, "many"], [614, "to"], [614, "pursue"], [614, "innovative"], [614, "and"], [614, "creative"], [614, "solution"], [614, "to"], [614, "reduce"], [614, "the"], [614, "mortality"], [614, "and"], [614, "morbidity"], [614, "result"], [614, "from"], [614, "the"], [614, "current"], [614, "global"], [614, "pandemic"], [614, "."], [615, "a"], [615, "comparative"], [615, "analysis"], [615, "of"], [615, "various"], [615, "strategy"], [615, "currently"], [615, "in"], [615, "use"], [615, "deserve"], [615, "explore"], [615, "and"], [615, "this"], [615, "highlight"], [615, "separately"], [615, "as"], [615, "the"], [615, "essential"], [615, "part"], [615, "of"], [615, "this"], [615, "concise"], [615, "theme"], [615, "."], [616, "sphingolipid"], [616, "be"], [616, "potent"], [616, "bioactive"], [616, "agent"], [616, "involve"], [616, "in"], [616, "the"], [616, "pathogenesis"], [616, "of"], [616, "various"], [616, "respiratory"], [616, "bacterial"], [616, "infection"], [616, "."], [617, "to"], [617, "date"], [617, ","], [617, "several"], [617, "sphingolipid"], [617, "derivative"], [617, "be"], [617, "know"], [617, ","], [617, "but"], [617, "s1p"], [617, "("], [617, "sphingosine-1"], [617, "-"], [617, "phosphate"], [617, ")"], [617, "and"], [617, "ceramide"], [617, "be"], [617, "the"], [617, "well"], [617, "-"], [617, "study"], [617, "sphingolipid"], [617, "derivative"], [617, "in"], [617, "the"], [617, "context"], [617, "of"], [617, "human"], [617, "disease"], [617, "."], [618, "these"], [618, "be"], [618, "membrane"], [618, "-"], [618, "bind"], [618, "lipid"], [618, "that"], [618, "influence"], [618, "host"], [618, "-"], [618, "pathogen"], [618, "interaction"], [618, "."], [619, "base"], [619, "on"], [619, "these"], [619, "feature"], [619, ","], [619, "we"], [619, "believe"], [619, "that"], [619, "sphingolipid"], [619, "might"], [619, "control"], [619, "sars"], [619, "-"], [619, "cov-2"], [619, "infection"], [619, "in"], [619, "the"], [619, "host"], [619, "."], [620, "sars"], [620, "-"], [620, "cov-2"], [620, "utilize"], [620, "the"], [620, "ace"], [620, "-"], [620, "ii"], [620, "receptor"], [620, "("], [620, "angiotensin"], [620, "-"], [620, "convert"], [620, "enzyme"], [620, "ii"], [620, "receptor"], [620, ")"], [620, "on"], [620, "epithelial"], [620, "cell"], [620, "for"], [620, "its"], [620, "entry"], [620, "and"], [620, "replication"], [620, "."], [621, "activation"], [621, "of"], [621, "the"], [621, "ace"], [621, "-"], [621, "ii"], [621, "receptor"], [621, "be"], [621, "indirectly"], [621, "associate"], [621, "with"], [621, "the"], [621, "activation"], [621, "of"], [621, "s1p"], [621, "receptor"], [621, "1"], [621, "signaling"], [621, "which"], [621, "be"], [621, "associate"], [621, "with"], [621, "il-6"], [621, "drive"], [621, "fibrosis"], [621, "."], [622, "this"], [622, "be"], [622, "expect"], [622, "to"], [622, "promote"], [622, "pathological"], [622, "response"], [622, "during"], [622, "sars"], [622, "-"], [622, "cov-2"], [622, "infection"], [622, "in"], [622, "covid-19"], [622, "case"], [622, "."], [623, "give"], [623, "this"], [623, ","], [623, "mitigate"], [623, "s1p"], [623, "signal"], [623, "by"], [623, "application"], [623, "of"], [623, "either"], [623, "s1p"], [623, "lyase"], [623, "("], [623, "spl"], [623, ")"], [623, "or"], [623, "s1p"], [623, "analog"], [623, "("], [623, "fingolimod"], [623, "/"], [623, "fty720"], [623, ")"], [623, "seem"], [623, "to"], [623, "be"], [623, "potential"], [623, "approach"], [623, "for"], [623, "control"], [623, "these"], [623, "pathological"], [623, "outcome"], [623, "."], [624, "however"], [624, ","], [624, "due"], [624, "to"], [624, "the"], [624, "immunosuppressive"], [624, "nature"], [624, "of"], [624, "fty720"], [624, ","], [624, "it"], [624, "can"], [624, "modulate"], [624, "hyper"], [624, "-"], [624, "inflammatory"], [624, "response"], [624, "and"], [624, "only"], [624, "provide"], [624, "symptomatic"], [624, "relief"], [624, ","], [624, "which"], [624, "may"], [624, "not"], [624, "be"], [624, "sufficient"], [624, "for"], [624, "control"], [624, "the"], [624, "novel"], [624, "covid-19"], [624, "infection"], [624, "."], [625, "since"], [625, "th1"], [625, "effector"], [625, "immune"], [625, "response"], [625, "be"], [625, "essential"], [625, "for"], [625, "the"], [625, "clearance"], [625, "of"], [625, "infection"], [625, ","], [625, "we"], [625, "believe"], [625, "that"], [625, "other"], [625, "sphingolipid"], [625, "derivative"], [625, "like"], [625, "cermaide-1"], [625, "phosphate"], [625, "with"], [625, "antiviral"], [625, "potential"], [625, "and"], [625, "adjuvant"], [625, "immune"], [625, "potential"], [625, "can"], [625, "potentially"], [625, "control"], [625, "sars"], [625, "-"], [625, "cov-2"], [625, "infection"], [625, "in"], [625, "the"], [625, "host"], [625, "by"], [625, "its"], [625, "ability"], [625, "in"], [625, "enhance"], [625, "autophagy"], [625, "and"], [625, "antigen"], [625, "presentation"], [625, "by"], [625, "dc"], [625, "to"], [625, "promote"], [625, "t"], [625, "cell"], [625, "response"], [625, "which"], [625, "can"], [625, "be"], [625, "helpful"], [625, "in"], [625, "control"], [625, "sars"], [625, "-"], [625, "cov-2"], [625, "infection"], [625, "in"], [625, "novel"], [625, "covid-19"], [625, "patient"], [625, "."], [626, "in"], [626, "december"], [626, "2019"], [626, ","], [626, "a"], [626, "cluster"], [626, "of"], [626, "case"], [626, "of"], [626, "acute"], [626, "respiratory"], [626, "illness"], [626, ","], [626, "novel"], [626, "coronavirus"], [626, "-"], [626, "infect"], [626, "pneumonia"], [626, ","], [626, "occur"], [626, "in"], [626, "wuhan"], [626, ","], [626, "hubei"], [626, "province"], [626, ","], [626, "china"], [626, "."], [627, "the"], [627, "false"], [627, "-"], [627, "negative"], [627, "nasopharyngeal"], [627, "swab"], [627, "for"], [627, "sars"], [627, "-"], [627, "cov-2"], [627, "cause"], [627, "delay"], [627, "diagnosis"], [627, "of"], [627, "covid-19"], [627, ","], [627, "which"], [627, "hinder"], [627, "the"], [627, "prevention"], [627, "and"], [627, "control"], [627, "of"], [627, "the"], [627, "pandemic"], [627, "."], [628, "the"], [628, "transmission"], [628, "risk"], [628, "of"], [628, "sars"], [628, "-"], [628, "cov-2"], [628, "in"], [628, "negative"], [628, "nasopharyngeal"], [628, "swab"], [628, "case"], [628, "have"], [628, "rarely"], [628, "be"], [628, "address"], [628, "previously"], [628, "."], [629, "this"], [629, "study"], [629, "evaluate"], [629, "two"], [629, "cluster"], [629, "of"], [629, "covid-19"], [629, "in"], [629, "six"], [629, "patient"], [629, ","], [629, "four"], [629, "of"], [629, "whom"], [629, "("], [629, "66.7"], [629, "%"], [629, ")"], [629, "test"], [629, "negative"], [629, "for"], [629, "rna"], [629, "of"], [629, "sars"], [629, "-"], [629, "cov-2"], [629, "on"], [629, "rt"], [629, "-"], [629, "pcr"], [629, "of"], [629, "nasopharyngeal"], [629, "swab"], [629, "."], [630, "all"], [630, "epidemiological"], [630, ","], [630, "clinical"], [630, ","], [630, "and"], [630, "laboratory"], [630, "datum"], [630, "be"], [630, "collect"], [630, "."], [631, "the"], [631, "first"], [631, "cluster"], [631, "be"], [631, "a"], [631, "nosocomial"], [631, "infection"], [631, "of"], [631, "four"], [631, "health"], [631, "care"], [631, "provider"], [631, "in"], [631, "early"], [631, "january"], [631, "."], [632, "one"], [632, "case"], [632, "result"], [632, "in"], [632, "a"], [632, "sequential"], [632, "familial"], [632, "cluster"], [632, "of"], [632, "infection"], [632, "."], [633, "all"], [633, "patient"], [633, "either"], [633, "self"], [633, "-"], [633, "quarantine"], [633, "at"], [633, "home"], [633, "or"], [633, "be"], [633, "admit"], [633, "to"], [633, "hospital"], [633, "for"], [633, "isolated"], [633, "treatment"], [633, "."], [634, "all"], [634, "recover"], [634, "and"], [634, "be"], [634, "anti"], [634, "-"], [634, "sar"], [634, "-"], [634, "cov-2"], [634, "igg-"], [634, "and/or"], [634, "igm"], [634, "-"], [634, "positive"], [634, "("], [634, "100"], [634, "%"], [634, ")"], [634, "for"], [634, "serological"], [634, "detection"], [634, "of"], [634, "sars"], [634, "-"], [634, "cov-2"], [634, "at"], [634, "the"], [634, "recovery"], [634, "stage"], [634, "."], [635, "our"], [635, "study"], [635, "provide"], [635, "a"], [635, "cautionary"], [635, "warning"], [635, "that"], [635, "negative"], [635, "result"], [635, "for"], [635, "nasopharyngeal"], [635, "swab"], [635, "of"], [635, "suspect"], [635, "sars"], [635, "-"], [635, "cov-2"], [635, "infection"], [635, "can"], [635, "increase"], [635, "the"], [635, "risk"], [635, "of"], [635, "nosocomial"], [635, "infection"], [635, "among"], [635, "health"], [635, "care"], [635, "provider"], [635, "."], [636, "serologic"], [636, "detection"], [636, "for"], [636, "anti"], [636, "-"], [636, "sars"], [636, "-"], [636, "cov-2"], [636, "igg"], [636, "and/or"], [636, "igm"], [636, "be"], [636, "an"], [636, "important"], [636, "test"], [636, "in"], [636, "the"], [636, "diagnosis"], [636, "of"], [636, "covid-19"], [636, "."], [637, "current"], [637, "treatment"], [637, "of"], [637, "patient"], [637, "with"], [637, "coronavirus"], [637, "2019"], [637, "("], [637, "covid-19"], [637, ")"], [637, "involve"], [637, "repurpose"], [637, "drug"], [637, "that"], [637, "inhibit"], [637, "viral"], [637, "infection"], [637, "by"], [637, "either"], [637, "bind"], [637, "to"], [637, "their"], [637, "respective"], [637, "target"], [637, "or"], [637, "via"], [637, "modulate"], [637, "cellular"], [637, "signal"], [637, "transduction"], [637, "."], [638, "however"], [638, ","], [638, "there"], [638, "be"], [638, "still"], [638, "a"], [638, "great"], [638, "deal"], [638, "of"], [638, "efficacy"], [638, "enhancement"], [638, "through"], [638, "combination"], [638, "therapy"], [638, "and"], [638, "derivatization"], [638, "."], [639, "combination"], [639, "therapy"], [639, "should"], [639, "involve"], [639, "agent"], [639, "with"], [639, "significant"], [639, "activity"], [639, "and"], [639, "different"], [639, "mechanism"], [639, "of"], [639, "action"], [639, "."], [640, "the"], [640, "structural"], [640, "map"], [640, "of"], [640, "the"], [640, "interaction"], [640, "between"], [640, "a"], [640, "drug"], [640, "and"], [640, "its"], [640, "target"], [640, "protein"], [640, "will"], [640, "help"], [640, "guide"], [640, "drug"], [640, "discovery"], [640, "for"], [640, "devise"], [640, "safe"], [640, "and"], [640, "effective"], [640, "way"], [640, "to"], [640, "treat"], [640, "covid-19"], [640, "."], [641, "herein"], [641, ","], [641, "we"], [641, "report"], [641, "numerous"], [641, "synthetic"], [641, "design"], [641, "base"], [641, "on"], [641, "enhance"], [641, "affinity"], [641, "to"], [641, "the"], [641, "viral"], [641, "carbohydrate"], [641, "-"], [641, "rich"], [641, "protein"], [641, "spike"], [641, "and"], [641, "protein"], [641, "-"], [641, "bind"], [641, "site"], [641, "of"], [641, "covid-19"], [641, "."], [642, "the"], [642, "pandemic"], [642, "of"], [642, "coronavirus"], [642, "disease"], [642, "2019"], [642, "("], [642, "covid-19"], [642, ")"], [642, "have"], [642, "have"], [642, "a"], [642, "serious"], [642, "impact"], [642, "on"], [642, "global"], [642, "health"], [642, "."], [643, "covid-19"], [643, "vaccine"], [643, "may"], [643, "be"], [643, "one"], [643, "of"], [643, "the"], [643, "most"], [643, "effective"], [643, "measure"], [643, "to"], [643, "end"], [643, "the"], [643, "pandemic"], [643, "."], [644, "high"], [644, "infection"], [644, "risk"], [644, "and"], [644, "high"], [644, "serious"], [644, "incident"], [644, "and"], [644, "mortality"], [644, "rate"], [644, "have"], [644, "be"], [644, "show"], [644, "in"], [644, "cancer"], [644, "patient"], [644, "with"], [644, "covid-19"], [644, "."], [645, "therefore"], [645, ","], [645, "cancer"], [645, "patient"], [645, "should"], [645, "be"], [645, "the"], [645, "priority"], [645, "group"], [645, "for"], [645, "covid-19"], [645, "prevention"], [645, "."], [646, "until"], [646, "now"], [646, ","], [646, "datum"], [646, "of"], [646, "covid-19"], [646, "vaccination"], [646, "for"], [646, "cancer"], [646, "patient"], [646, "be"], [646, "lack"], [646, "."], [647, "we"], [647, "review"], [647, "the"], [647, "interim"], [647, "datum"], [647, "of"], [647, "safety"], [647, "and"], [647, "immune"], [647, "-"], [647, "efficacy"], [647, "of"], [647, "covid-19"], [647, "vaccination"], [647, "in"], [647, "cancer"], [647, "patient"], [647, "base"], [647, "on"], [647, "the"], [647, "late"], [647, "study"], [647, "."], [648, "due"], [648, "to"], [648, "the"], [648, "complicated"], [648, "immune"], [648, "system"], [648, "of"], [648, "cancer"], [648, "patient"], [648, "cause"], [648, "by"], [648, "the"], [648, "malignancy"], [648, "and"], [648, "anticancer"], [648, "treatment"], [648, ","], [648, "we"], [648, "propose"], [648, "preliminary"], [648, "specific"], [648, "covid-19"], [648, "vaccination"], [648, "recommendation"], [648, "for"], [648, "cancer"], [648, "patient"], [648, "with"], [648, "different"], [648, "anticancer"], [648, "treatment"], [648, "and"], [648, "at"], [648, "different"], [648, "stage"], [648, "of"], [648, "the"], [648, "disease"], [648, "."], [649, "prevent"], [649, "covid-19"], [649, "with"], [649, "vaccination"], [649, "for"], [649, "cancer"], [649, "patient"], [649, "be"], [649, "crucial"], [649, ","], [649, "and"], [649, "we"], [649, "call"], [649, "for"], [649, "more"], [649, "large"], [649, "-"], [649, "scale"], [649, "clinical"], [649, "trial"], [649, "and"], [649, "real"], [649, "-"], [649, "world"], [649, "study"], [649, ","], [649, "for"], [649, "further"], [649, "covid-19"], [649, "vaccination"], [649, "recommendation"], [649, "development"], [649, "."], [650, "."], [651, "coronavirus"], [651, "disease"], [651, "2019"], [651, "("], [651, "covid-19"], [651, ")"], [651, "be"], [651, "a"], [651, "major"], [651, "public"], [651, "health"], [651, "concern"], [651, "currently"], [651, "."], [652, "to"], [652, "date"], [652, ","], [652, "there"], [652, "be"], [652, "no"], [652, "approve"], [652, "antiviral"], [652, "drug"], [652, "or"], [652, "vaccine"], [652, "against"], [652, "this"], [652, "transmissible"], [652, "disease"], [652, "."], [653, "this"], [653, "report"], [653, "shed"], [653, "light"], [653, "on"], [653, "available"], [653, "information"], [653, "for"], [653, "a"], [653, "well"], [653, "understanding"], [653, "of"], [653, "clinical"], [653, "trial"], [653, "and"], [653, "pharmacotherapy"], [653, "relate"], [653, "to"], [653, "covid-19"], [653, "."], [654, "medline"], [654, ","], [654, "pubme"], [654, ","], [654, "embase"], [654, ","], [654, "scopus"], [654, "database"], [654, ","], [654, "web"], [654, "of"], [654, "science"], [654, ","], [654, "who"], [654, ","], [654, "and"], [654, "eu"], [654, "clinical"], [654, "trial"], [654, "site"], [654, "be"], [654, "use"], [654, "to"], [654, "perform"], [654, "comparative"], [654, "analysis"], [654, "."], [655, "information"], [655, "be"], [655, "collect"], [655, "on"], [655, "the"], [655, "use"], [655, "of"], [655, "therapeutic"], [655, "agent"], [655, "for"], [655, "human"], [655, "therapy"], [655, "in"], [655, "patient"], [655, "with"], [655, "covid-19"], [655, "up"], [655, "to"], [655, "may"], [655, "2020"], [655, "."], [656, "we"], [656, "have"], [656, "extract"], [656, "datum"], [656, "from"], [656, "60"], [656, "clinical"], [656, "trial"], [656, "."], [657, "amongst"], [657, "these"], [657, "trial"], [657, ","], [657, "34"], [657, "be"], [657, "from"], [657, "the"], [657, "european"], [657, "union"], [657, "database"], [657, "of"], [657, "clinical"], [657, "trial"], [657, "and"], [657, "26"], [657, "from"], [657, "the"], [657, "national"], [657, "institute"], [657, "of"], [657, "health"], [657, "."], [658, "the"], [658, "datum"], [658, "selection"], [658, "procedure"], [658, "include"], [658, "active"], [658, ","], [658, "complete"], [658, ","], [658, "and"], [658, "recruitment"], [658, "in"], [658, "progress"], [658, "status"], [658, "."], [659, "most"], [659, "of"], [659, "the"], [659, "clinical"], [659, "trial"], [659, "be"], [659, "ongoing"], [659, "and"], [659, "hence"], [659, ","], [659, "there"], [659, "be"], [659, "a"], [659, "lack"], [659, "of"], [659, "precise"], [659, "result"], [659, "for"], [659, "the"], [659, "treatment"], [659, "."], [660, "there"], [660, "be"], [660, "a"], [660, "lack"], [660, "of"], [660, "high"], [660, "-"], [660, "quality"], [660, "clinical"], [660, "evidence"], [660, "."], [661, "the"], [661, "protocol"], [661, "to"], [661, "be"], [661, "develop"], [661, "require"], [661, "large"], [661, "randomize"], [661, "clinical"], [661, "trial"], [661, "with"], [661, "a"], [661, "combination"], [661, "of"], [661, "available"], [661, "drug"], [661, "and"], [661, "prospective"], [661, "therapy"], [661, "."], [662, "we"], [662, "propose"], [662, "the"], [662, "usage"], [662, "of"], [662, "a"], [662, "large"], [662, "number"], [662, "of"], [662, "case"], [662, "and"], [662, "different"], [662, "statistical"], [662, "analysis"], [662, "to"], [662, "conduct"], [662, "systematic"], [662, "clinical"], [662, "trial"], [662, "."], [663, "this"], [663, "could"], [663, "provide"], [663, "comprehensive"], [663, "information"], [663, "about"], [663, "the"], [663, "clinical"], [663, "trial"], [663, "and"], [663, "potential"], [663, "therapeutic"], [663, "progress"], [663, "."], [664, "covid-19"], [664, "vaccine"], [664, "have"], [664, "develop"], [664, "quickly"], [664, ","], [664, "and"], [664, "vaccination"], [664, "program"], [664, "have"], [664, "start"], [664, "in"], [664, "most"], [664, "country"], [664, "to"], [664, "fight"], [664, "the"], [664, "pandemic"], [664, "."], [665, "the"], [665, "age"], [665, "population"], [665, "be"], [665, "vulnerable"], [665, "to"], [665, "different"], [665, "disease"], [665, ","], [665, "also"], [665, "include"], [665, "the"], [665, "covid-19"], [665, "."], [666, "a"], [666, "high"], [666, "death"], [666, "rate"], [666, "of"], [666, "covid-19"], [666, "be"], [666, "note"], [666, "from"], [666, "the"], [666, "vulnerable"], [666, "age"], [666, "population"], [666, "."], [667, "a"], [667, "present"], [667, "scenario"], [667, "regard"], [667, "covid-19"], [667, "vaccine"], [667, "and"], [667, "vaccination"], [667, "program"], [667, "forage"], [667, "adult"], [667, "have"], [667, "be"], [667, "discuss"], [667, "."], [668, "this"], [668, "paper"], [668, "review"], [668, "the"], [668, "current"], [668, "status"], [668, "and"], [668, "future"], [668, "projection"], [668, "till"], [668, "2050"], [668, "of"], [668, "the"], [668, "age"], [668, "population"], [668, "worldwide"], [668, "."], [669, "it"], [669, "also"], [669, "discuss"], [669, "the"], [669, "immunosenescence"], [669, "and"], [669, "inflammage"], [669, "issue"], [669, "face"], [669, "elderly"], [669, "adult"], [669, "and"], [669, "how"], [669, "it"], [669, "affect"], [669, "the"], [669, "vaccination"], [669, "such"], [669, "as"], [669, "influenza"], [669, ","], [669, "pneumococcal"], [669, ","], [669, "and"], [669, "herpe"], [669, "zoster"], [669, "."], [670, "this"], [670, "paper"], [670, "recommend"], [670, "clinical"], [670, "trial"], [670, "for"], [670, "all"], [670, "approve"], [670, "covid-19"], [670, "vaccine"], [670, "target"], [670, "the"], [670, "elderly"], [670, "adult"], [670, "population"], [670, "and"], [670, "to"], [670, "project"], [670, "a"], [670, "plan"], [670, "to"], [670, "develop"], [670, "a"], [670, "next"], [670, "-"], [670, "generation"], [670, "covid-19"], [670, "vaccine"], [670, "."], [671, "the"], [671, "review"], [671, "have"], [671, "map"], [671, "the"], [671, "covid-19"], [671, "vaccination"], [671, "status"], [671, "from"], [671, "the"], [671, "developed"], [671, "and"], [671, "develop"], [671, "country"], [671, "for"], [671, "the"], [671, "elderly"], [671, "population"], [671, "."], [672, "finally"], [672, ","], [672, "strategy"], [672, "to"], [672, "vaccinate"], [672, "all"], [672, "elderly"], [672, "adult"], [672, "globally"], [672, "against"], [672, "covid-19"], [672, "to"], [672, "enhance"], [672, "longevity"], [672, "have"], [672, "be"], [672, "suggest"], [672, "."], [673, "the"], [673, "novel"], [673, "coronavirus"], [673, "disease-19"], [673, "("], [673, "covid-19"], [673, ")"], [673, "be"], [673, "a"], [673, "global"], [673, "pandemic"], [673, "that"], [673, "emerge"], [673, "from"], [673, "wuhan"], [673, ","], [673, "china"], [673, ","], [673, "and"], [673, "have"], [673, "spread"], [673, "all"], [673, "around"], [673, "the"], [673, "world"], [673, ","], [673, "affect"], [673, "216"], [673, "country"], [673, "or"], [673, "territory"], [673, "with"], [673, "21,732,472"], [673, "people"], [673, "infect"], [673, "and"], [673, "770,866"], [673, "death"], [673, "globally"], [673, "("], [673, "as"], [673, "per"], [673, "who"], [673, "covid-19"], [673, "update"], [673, "of"], [673, "august"], [673, "18"], [673, ","], [673, "2020"], [673, ")"], [673, "."], [674, "continuous"], [674, "effort"], [674, "be"], [674, "be"], [674, "make"], [674, "to"], [674, "repurpose"], [674, "the"], [674, "exist"], [674, "drug"], [674, "and"], [674, "develop"], [674, "vaccine"], [674, "for"], [674, "combat"], [674, "this"], [674, "infection"], [674, "."], [675, "despite"], [675, ","], [675, "to"], [675, "date"], [675, ","], [675, "no"], [675, "certify"], [675, "antiviral"], [675, "treatment"], [675, "or"], [675, "vaccine"], [675, "exist"], [675, "."], [676, "although"], [676, ","], [676, "few"], [676, "candidate"], [676, "have"], [676, "display"], [676, "their"], [676, "efficacy"], [676, "in"], [676, "in"], [676, "vitro"], [676, "study"], [676, "and"], [676, "be"], [676, "be"], [676, "repurpose"], [676, "for"], [676, "covid-"], [676, "19"], [676, "treatment"], [676, "."], [677, "this"], [677, "article"], [677, "summarize"], [677, "synthetic"], [677, "and"], [677, "semi"], [677, "-"], [677, "synthetic"], [677, "compound"], [677, "display"], [677, "potent"], [677, "activity"], [677, "in"], [677, "clinical"], [677, "use"], [677, "or"], [677, "study"], [677, "on"], [677, "covid-19"], [677, "and"], [677, "also"], [677, "focus"], [677, "on"], [677, "the"], [677, "mode"], [677, "of"], [677, "action"], [677, "of"], [677, "drug"], [677, "be"], [677, "reposition"], [677, "against"], [677, "covid-19"], [677, "."], [678, "severe"], [678, "acute"], [678, "respiratory"], [678, "syndrome"], [678, "coronavirus-2"], [678, "("], [678, "sars"], [678, "-"], [678, "cov-2"], [678, ")"], [678, "belong"], [678, "to"], [678, "the"], [678, "group"], [678, "of"], [678, "betacoronaviruse"], [678, "."], [679, "the"], [679, "sars"], [679, "-"], [679, "cov-2"], [679, "be"], [679, "closely"], [679, "relate"], [679, "to"], [679, "sars"], [679, "-"], [679, "cov-1"], [679, "\xA0"], [679, "and"], [679, "probably"], [679, "originate"], [679, "either"], [679, "from"], [679, "bat"], [679, "or"], [679, "pangolin"], [679, "."], [680, "sars"], [680, "-"], [680, "cov-2"], [680, "be"], [680, "an"], [680, "etiological"], [680, "agent"], [680, "of"], [680, "covid-19"], [680, ","], [680, "cause"], [680, "mild"], [680, "to"], [680, "severe"], [680, "respiratory"], [680, "disease"], [680, "which"], [680, "escalate"], [680, "to"], [680, "acute"], [680, "respiratory"], [680, "distress"], [680, "syndrome"], [680, "("], [680, "ard"], [680, ")"], [680, "or"], [680, "multi"], [680, "-"], [680, "organ"], [680, "failure"], [680, "."], [681, "the"], [681, "virus"], [681, "be"], [681, "first"], [681, "report"], [681, "from"], [681, "the"], [681, "animal"], [681, "market"], [681, "in"], [681, "hunan"], [681, ","], [681, "hubei"], [681, "province"], [681, "of"], [681, "china"], [681, "in"], [681, "the"], [681, "month"], [681, "of"], [681, "december"], [681, ","], [681, "2019"], [681, ","], [681, "and"], [681, "be"], [681, "\xA0"], [681, "rapidly"], [681, "transmit"], [681, "from"], [681, "animal"], [681, "to"], [681, "human"], [681, "and"], [681, "human"], [681, "-"], [681, "to"], [681, "-"], [681, "human"], [681, "."], [682, "the"], [682, "human"], [682, "-"], [682, "to"], [682, "-"], [682, "human"], [682, "transmission"], [682, "can"], [682, "occur"], [682, "directly"], [682, "or"], [682, "via"], [682, "droplet"], [682, "generate"], [682, "during"], [682, "coughing"], [682, "and"], [682, "sneeze"], [682, "."], [683, "globally"], [683, ","], [683, "around"], [683, "53.9"], [683, "million"], [683, "case"], [683, "of"], [683, "covid-19"], [683, "have"], [683, "be"], [683, "register"], [683, "with"], [683, "1.31"], [683, "million"], [683, "confirm"], [683, "death"], [683, "."], [684, "the"], [684, "people"], [684, "\u2009"], [684, ">"], [684, "\u2009"], [684, "60"], [684, "\xA0"], [684, "year"], [684, ","], [684, "\xA0"], [684, "person"], [684, "suffer"], [684, "from"], [684, "comorbid"], [684, "condition"], [684, "and"], [684, "\xA0"], [684, "immunocompromise"], [684, "individual"], [684, "be"], [684, "more"], [684, "susceptible"], [684, "to"], [684, "covid-19"], [684, "infection"], [684, "."], [685, "the"], [685, "virus"], [685, "primarily"], [685, "target"], [685, "the"], [685, "upper"], [685, "and"], [685, "the"], [685, "low"], [685, "respiratory"], [685, "tract"], [685, "and"], [685, "quickly"], [685, "disseminate"], [685, "to"], [685, "other"], [685, "organ"], [685, "."], [686, "sars"], [686, "-"], [686, "cov-2"], [686, "dysregulate"], [686, "immune"], [686, "signal"], [686, "pathway"], [686, "which"], [686, "generate"], [686, "cytokine"], [686, "storm"], [686, "and"], [686, "lead"], [686, "to"], [686, "the"], [686, "acute"], [686, "respiratory"], [686, "distress"], [686, "syndrome"], [686, "\xA0"], [686, "and"], [686, "other"], [686, "multisystemic"], [686, "disorder"], [686, "."], [687, "numerous"], [687, "review"], [687, "have"], [687, "summarize"], [687, "the"], [687, "epidemiology"], [687, ","], [687, "pathophysiology"], [687, "and"], [687, "the"], [687, "various"], [687, "therapeutic"], [687, "aspect"], [687, "of"], [687, "coronavirus"], [687, "disease"], [687, "2019"], [687, "("], [687, "covid-19"], [687, ")"], [687, ","], [687, "but"], [687, "a"], [687, "practical"], [687, "guide"], [687, "on"], [687, '"'], [687, "how"], [687, "to"], [687, "treat"], [687, "whom"], [687, "with"], [687, "what"], [687, "and"], [687, "when"], [687, '"'], [687, "base"], [687, "on"], [687, "an"], [687, "understanding"], [687, "of"], [687, "the"], [687, "immunological"], [687, "background"], [687, "of"], [687, "the"], [687, "disease"], [687, "stage"], [687, "remain"], [687, "miss"], [687, "."], [688, "this"], [688, "review"], [688, "attempt"], [688, "to"], [688, "combine"], [688, "the"], [688, "current"], [688, "knowledge"], [688, "about"], [688, "the"], [688, "immunopathology"], [688, "of"], [688, "covid-19"], [688, "with"], [688, "publish"], [688, "evidence"], [688, "of"], [688, "available"], [688, "and"], [688, "emerge"], [688, "treatment"], [688, "option"], [688, "."], [689, "we"], [689, "recognize"], [689, "that"], [689, "the"], [689, "information"], [689, "about"], [689, "covid-19"], [689, "and"], [689, "its"], [689, "treatment"], [689, "be"], [689, "rapidly"], [689, "change"], [689, ","], [689, "but"], [689, "hope"], [689, "that"], [689, "this"], [689, "guide"], [689, "offer"], [689, "those"], [689, "on"], [689, "the"], [689, "frontline"], [689, "of"], [689, "this"], [689, "pandemic"], [689, "an"], [689, "understanding"], [689, "of"], [689, "the"], [689, "host"], [689, "response"], [689, "in"], [689, "covid-19"], [689, "patient"], [689, "and"], [689, "support"], [689, "their"], [689, "ongoing"], [689, "effort"], [689, "to"], [689, "select"], [689, "the"], [689, "good"], [689, "treatment"], [689, "tailor"], [689, "to"], [689, "their"], [689, "patient"], [689, "'s"], [689, "clinical"], [689, "status"], [689, "."], [690, "the"], [690, "causative"], [690, "agent"], [690, "of"], [690, "novel"], [690, "coronavirus"], [690, "disease"], [690, "("], [690, "covid-19"], [690, ")"], [690, "be"], [690, "severe"], [690, "acute"], [690, "respiratory"], [690, "syndrome"], [690, "coronavirus"], [690, "2"], [690, "("], [690, "sars"], [690, "-"], [690, "cov-2"], [690, ")"], [690, "."], [691, "the"], [691, "sars"], [691, "-"], [691, "cov-2"], [691, "possess"], [691, "rna"], [691, "as"], [691, "a"], [691, "genetic"], [691, "material"], [691, "with"], [691, "79"], [691, "%"], [691, "of"], [691, "the"], [691, "match"], [691, "with"], [691, "the"], [691, "bat"], [691, "sars"], [691, "-"], [691, "cov"], [691, "genome"], [691, ","], [691, "which"], [691, "become"], [691, "epidemic"], [691, "in"], [691, "2002"], [691, "."], [692, "the"], [692, "sars"], [692, "-"], [692, "cov-2"], [692, "peripheral"], [692, "spike"], [692, "-"], [692, "fc"], [692, "protein"], [692, "bind"], [692, "specifically"], [692, "to"], [692, "the"], [692, "ace2"], [692, "receptor"], [692, "present"], [692, "on"], [692, "bronchial"], [692, "epithelial"], [692, "cell"], [692, "and"], [692, "alveolar"], [692, "pneumocyte"], [692, "to"], [692, "downmodulates"], [692, "its"], [692, "expression"], [692, "which"], [692, "lead"], [692, "to"], [692, "severe"], [692, "acute"], [692, "respiratory"], [692, "failure"], [692, "."], [693, "the"], [693, "disease"], [693, "be"], [693, "super"], [693, "infectious"], [693, "from"], [693, "human"], [693, "to"], [693, "human"], [693, "and"], [693, "the"], [693, "symptom"], [693, "be"], [693, "similar"], [693, "to"], [693, "flu"], [693, "."], [694, "the"], [694, "old"], [694, "aged"], [694, "and"], [694, "immunocompromise"], [694, "population"], [694, "be"], [694, "severely"], [694, "affect"], [694, ","], [694, "and"], [694, "healthcare"], [694, "provider"], [694, "globally"], [694, "apply"], [694, "various"], [694, "strategy"], [694, "for"], [694, "treatment"], [694, "include"], [694, "the"], [694, "repurposing"], [694, "of"], [694, "drug"], [694, "include"], [694, "antimalarial"], [694, "drug"], [694, ","], [694, "hydroxychloroquine"], [694, "and"], [694, "anti"], [694, "-"], [694, "viral"], [694, "drug"], [694, "."], [695, "herein"], [695, ","], [695, "we"], [695, "describe"], [695, "the"], [695, "sars"], [695, "-"], [695, "cov-2"], [695, "pandemic"], [695, ","], [695, "immune"], [695, "response"], [695, ","], [695, "possible"], [695, "drug"], [695, "target"], [695, ","], [695, "vaccine"], [695, "under"], [695, "the"], [695, "trial"], [695, "and"], [695, "correlate"], [695, "the"], [695, "possibility"], [695, "of"], [695, "train"], [695, "immunity"], [695, "induce"], [695, "by"], [695, "bcg"], [695, "vaccination"], [695, "over"], [695, "control"], [695, "of"], [695, "sars"], [695, "-"], [695, "cov-2"], [695, "infection"], [695, "."], [696, "the"], [696, "country"], [696, "with"], [696, "constraint"], [696, "bcg"], [696, "vaccination"], [696, "policy"], [696, "be"], [696, "struggle"], [696, "badly"], [696, "compare"], [696, "to"], [696, "country"], [696, "with"], [696, "bcg"], [696, "vaccination"], [696, "policy"], [696, "."], [697, "the"], [697, "bcg"], [697, "vaccination"], [697, "policy"], [697, "support"], [697, "either"], [697, "low"], [697, "the"], [697, "total"], [697, "number"], [697, "of"], [697, "covid-19"], [697, "case"], [697, "or"], [697, "the"], [697, "increase"], [697, "recovery"], [697, "rate"], [697, "."]];

  // hw4/metadata.tsv
  var metadata_default = `<unk>
,
the
of
.
and
be
-
to
in
a
disorder
bipolar
with
for
(
)
have
covid-19
sars
that
as
cov-2
treatment
this
on
by
patient
clinical
disease
we
study
or
review
coronavirus
infection
an
from
"
use
diagnosis
can
respiratory
severe
which
may
include
more
virus
it
;
acute
depression
also
syndrome
symptom
early
well
%
cause
vaccine
:
pandemic
diagnostic
test
there
mania
drug
other
immune
at
ii
its
potential
illness
research
viral
identify
bd
response
these
but
base
effective
their
associate
health
not
provide
high
risk
therapeutic
2019
age
case
course
system
will
2
current
episode
individual
mood
report
discuss
human
development
onset
such
than
increase
result
develop
evidence
need
present
child
datum
novel
article
i
suggest
between
outcome
therapy
time
condition
most
strategy
against
over
however
important
new
adult
approach
both
care
effect
factor
lead
search
bpd
cognitive
different
intervention
rate
should
target
trial
genetic
literature
many
relate
term
available
diagnose
life
number
population
affect
detection
several
world
/
control
focus
specific
long
mechanism
no
possible
rapid
treat
although
change
feature
prevention
\xA0
cov
find
host
management
one
some
agent
antiviral
cell
currently
into
regard
show
transmission
follow
receptor
role
who
year
2020
adhd
all
comorbidity
consider
cytokine
hypomania
method
model
mortality
only
protein
recent
require
support
about
childhood
great
group
make
manic
prevent
reduce
testing
understanding
biomarker
characterize
could
family
infect
inflammatory
lithium
pcr
severity
significant
chronic
crispr
first
know
medical
negative
psychiatric
rna
spread
while
'
angiotensin
comorbid
criterion
during
examine
global
major
medication
often
our
personality
rt
stage
through
two
activity
among
bp
conduct
date
due
finding
gene
how
still
those
tool
aim
attention
death
depressive
efficacy
future
help
highlight
impairment
knowledge
positive
sample
self
spectrum
staging
's
association
brain
cancer
challenge
complex
detect
emerge
far
functional
marker
morbidity
option
pathophysiology
people
pharmacological
rapidly
up
various
when
worldwide
ace2
addition
china
common
compare
demonstrate
describe
dsm
dysfunction
function
highly
large
like
now
pathogenesis
prevalence
psychosocial
recurrent
summarize
1
because
become
borderline
characteristic
damage
do
enzyme
further
improve
information
involve
issue
iv
key
million
outbreak
period
presentation
public
seem
social
structural
across
appear
around
assessment
cycle
deficit
define
despite
effort
entry
exist
injury
manifestation
molecular
multiple
pathway
presence
relevant
since
state
substantial
they
trait
understand
10
antidepressant
biological
concern
country
duration
epidemiology
identification
impact
old
overview
paper
phase
potentially
previously
primary
prodrome
propose
relationship
therefore
vaccination
accurate
action
after
anti
antibody
cardiovascular
clinician
difference
distress
enhance
here
immunity
importance
lifetime
limit
mixed
neurologic
order
organ
part
perform
quarantine
range
recognition
remain
repurpose
schizophrenia
setting
storm
type
unipolar
young
achieve
and/or
approve
area
cardiac
combination
confirm
continue
convert
direct
estimate
experience
grow
history
induce
inflammation
influence
innate
laboratory
late
likely
limited
low
mainly
ongoing
organization
practice
progress
publish
pubmed
recognize
replication
screening
serious
signal
subtype
tissue
acid
address
affective
animal
apply
approximately
aspect
behavior
broad
burden
candidate
clear
complication
comprehensive
contact
day
december
delay
discovery
domain
emergency
essential
evaluate
expression
failure
few
frequently
guide
guideline
if
imaging
infectious
inform
investigation
lung
occur
particularly
play
process
progression
promise
recently
single
so
structure
substance
suicide
under
variable
what
wuhan
abuse
accord
assay
asymptomatic
cholesterol
clinically
combat
community
contribute
critical
database
declare
design
differential
elderly
even
exposure
extensive
false
finally
four
interaction
investigate
least
level
march
mediate
might
mild
neuroimaging
oabd
pathogen
perspective
phenomenology
prognosis
psychotic
quality
recommendation
recurrence
scientific
sequence
susceptible
systematic
tea
think
thus
total
whether
`;

  // hw4/vectors.tsv
  var vectors_default = "0.535644	-0.36242977	0.18351263	-0.041202884	0.26836058	-0.29179794	-0.013313606	-0.12716724	0.26164278	0.76700467	0.120221965	0.29700658	0.42265677	-0.041851204	0.26293308	0.20913175	1.1656609	0.12132919	0.8370943	0.6593017	-0.36089587	-1.2687281	0.8090297	-0.044174332	-0.22819407	-0.118423894	0.3851936	0.18532035	1.1756194	1.431869	-1.3769225	0.28653842	0.5645546	-0.98244107	0.25771794	-0.21979155	-0.13330011	0.49077022	-0.7469192	-0.045425683	-0.88288164	-0.044538736	-1.2068858	-0.18505916	0.5537446	-1.1519418	-0.22977324	-0.32876325	0.6044223	-0.885193	-0.071131825	-0.5810743	-0.18510066	-1.077933	0.59165263	0.90577424	1.731754	0.4880734	-0.033460785	0.9554191	-0.2575351	0.10729258	0.030822294	0.0093997065\n0.6875593	-0.49113986	0.8298613	1.858993	-0.5671813	-0.74869186	1.8906696	-0.8055019	-0.19572213	0.16662069	-1.4602765	1.0328416	-0.4423378	-0.28417385	-0.7469355	0.24448326	-0.11730795	1.3416247	-1.4857122	-1.112389	0.91284716	1.0627033	-0.07054302	-1.4123372	1.8610648	-0.3172378	-0.2385527	0.67136586	-1.4089445	0.2707844	0.29694313	0.041820858	0.87441075	1.432067	-1.8073529	-0.24554594	-0.55102795	-0.9368601	0.02312186	-0.12139648	-0.34049842	-1.3168311	0.087423824	-0.20672917	-0.12056123	-1.7261611	0.41603705	0.31234285	-0.63118607	0.8023691	-0.38890812	0.5973081	-0.32848048	2.312425	-1.6802181	-2.1924405	-1.3909224	1.6063216	-1.890912	-0.61105204	-0.58141184	-1.3047101	-0.79584146	0.18449667\n0.19647576	0.9149653	-0.53308576	-1.3429337	0.33511233	0.1641487	-1.1607475	-0.47974724	-0.71671796	-2.2109134	1.7688591	-0.29028895	-0.6163015	0.9047524	-0.12114265	-0.037864964	0.11574818	-2.2742074	-2.1783922	0.7502458	1.7230862	-0.14658207	0.69277227	-2.8854527	-2.163087	-0.8607194	0.21561204	-0.2841589	0.40101966	-2.1552334	-0.11653097	1.0284883	-1.9229454	0.37862486	-0.29360062	-0.8348189	0.23931783	-0.7523467	-1.1153263	-0.8385137	-0.7682768	-0.18192768	0.9222339	1.3993239	-0.055987325	-1.3487777	0.77159274	-0.6366997	-1.200044	-0.8555068	-0.46018514	1.2954407	-1.0368706	-0.20248374	-1.5825094	-1.0835154	1.5338714	-2.2521553	-0.48420346	-0.45732933	0.50375825	-0.07171337	-0.016628362	-0.8457358\n-1.9718856	-0.106403396	0.09158348	-0.6677009	0.029210245	-0.9899492	-2.5032222	2.0453598	0.30295852	-0.3450804	-0.31962582	1.4245629	0.8543111	-2.213796	0.40104103	-0.0473101	0.22043176	0.0036144382	2.56957	-0.74880826	-0.3087124	1.9968002	-2.9085612	0.97806	-0.15929459	0.005976225	-1.0222684	2.5229986	0.88930553	-1.3094361	0.25403482	-2.4443507	1.6085455	-0.84273875	-0.16942151	0.5867744	-1.0247136	0.19908935	1.3441448	1.2771839	-1.5037	1.8908825	-0.19961011	0.16382025	0.7425764	-0.042346776	-0.41635677	-0.24626791	-1.4218222	1.9234256	-0.46308902	-0.81497145	0.23813692	1.8422006	-0.6029759	-1.5576458	-0.37120998	0.27420244	1.8152307	-1.2398494	-0.47574994	-0.67207515	0.7246947	-1.5016918\n0.8296002	0.6718776	-0.9167541	0.5962424	2.373306	-1.0056491	1.6077347	-0.12739284	-0.6885077	-0.41061243	0.48965368	0.0223538	0.01674686	-0.9128873	-1.7170515	0.075726494	0.46770787	0.2194061	0.45710686	-2.3581367	-0.10899617	1.166274	0.4322658	0.47554982	-0.5541248	-1.2476723	-4.135098	-0.19275683	1.7806557	-0.3796152	1.1797895	1.6658322	-0.151628	0.7008934	-1.1390468	-3.4386692	-0.43707392	0.8638171	1.0691216	-0.5892604	-1.0181836	-0.2969429	1.6938789	-1.7910388	-1.0357753	-0.818713	3.4324965	0.83355755	0.026506213	-1.6696565	-0.47950637	-0.3814918	-0.10942909	0.1640114	0.42343295	-0.2599921	-0.49139267	-1.1841117	-1.6726508	-0.43365973	0.5553349	-0.2616689	-2.157268	1.67364\n-1.0711775	0.9790775	-0.29133245	1.0712409	-3.651434	-0.20554164	0.22437662	-0.6707928	-2.4264727	1.3925319	-1.515451	-0.52861303	1.1253823	0.8185707	0.22924316	-1.3056579	-1.2496322	0.74989295	1.3261822	-0.27373388	-0.9288712	-0.27605596	-1.60332	-0.43749526	1.3055815	1.3085495	-0.28349003	-1.056913	0.5716156	-2.0344138	0.016897196	0.2380865	-0.29186592	0.67381483	0.20812315	-0.3974984	1.3222417	-0.3002254	-1.6928664	-0.566276	1.4457816	0.38140446	2.420546	-1.1860174	0.2984567	0.85961735	0.15580492	-0.14376353	-0.89016473	-1.5198344	1.4867635	-0.57973987	-0.56217694	-0.13653089	-2.6944354	-0.06266768	0.75050235	-0.16180727	1.1154048	-2.6568522	1.5608139	-0.010977411	1.9129739	0.84021187\n-1.2399632	-0.51997477	2.032847	-1.2008348	-1.9248313	-0.5248568	-0.7467778	-0.20041843	0.41013834	-1.7560105	-0.5338208	0.4828625	1.093607	0.87748367	-0.93319404	-0.3488074	0.3672965	1.9278877	-0.91597944	-2.5809066	0.25125468	0.21965507	-0.5113395	2.692452	0.13525344	0.55795085	-1.5566441	-3.6174524	-2.0405254	-0.46641308	0.16191985	-0.20099975	-1.013972	0.02725854	0.6858815	-0.30815572	-0.032099318	0.1864885	0.5001321	-0.30024406	2.090183	-1.1462774	-0.0960971	0.680907	-0.67006016	-3.613342	-0.36806792	0.8319571	0.6071637	1.5276682	0.2879518	1.8530517	1.7312062	-1.2968695	1.92384	-0.8478096	1.5736041	-1.0072459	0.4552564	-1.2015988	-1.3968074	-1.2633107	0.09108926	1.3365084\n1.8980029	-0.3961547	1.0967858	0.065905094	-0.21348082	2.4845352	0.5481428	-0.93915904	-1.4688988	0.23770292	0.20793025	-0.8767511	-0.2789805	-2.3486462	0.43549266	0.1660929	0.5739443	2.2154982	0.7295723	0.97064877	-0.72112036	1.4123639	0.21782023	-0.047684312	0.29694912	-1.3691496	-2.3898985	0.6514495	-0.1812221	0.523717	1.9499326	-2.3091564	-0.89612687	-0.6203336	-0.9624651	0.681437	0.078710966	2.4301214	-2.304694	0.7747382	1.4024891	2.2985632	-2.888028	-0.49682498	-0.9012067	3.9583073	1.8175335	-0.013761179	2.055185	1.4229856	-0.6247691	1.0656066	-1.6054306	0.51943266	-2.9350877	-3.5901914	-2.7929537	-0.0855542	0.7646127	-0.40264955	0.6573285	0.4218966	1.3503592	1.625071\n-0.33145073	1.4194704	-1.216641	0.9511484	0.26040077	2.150413	1.6547008	1.252279	2.6747124	0.22808129	1.1892399	0.4767516	1.239817	0.68983984	-1.0099587	2.637216	0.90739757	-0.81599927	-1.7266681	-0.15507911	-1.058278	1.7011282	-1.0217009	-0.4538602	0.7960946	0.48567656	-2.3137794	1.2217166	-1.1039943	-1.8617376	-0.612108	-1.83498	1.0704194	1.3660741	3.296156	0.50959855	-0.83347774	0.40297976	-0.42415494	-0.4650063	0.37367553	-0.45446095	1.5161748	3.2127886	1.1429781	0.4454563	0.2688987	1.2521998	1.0337476	-0.51738816	-1.5636866	-0.77885795	0.6504989	-1.9573035	2.523152	0.47578484	0.56564474	0.03897471	-1.2808334	1.6138723	1.8515599	-0.40510383	1.6604921	0.28985235\n-0.59727585	0.36548355	0.6081501	1.4640654	0.34943417	1.1504699	0.993248	3.1168287	-0.13741313	0.89793587	0.68250823	0.5130261	0.559445	1.044588	0.7213148	0.157868	-2.2722995	1.8396668	0.4114649	-0.55721146	0.19238839	1.6773455	1.7365551	-0.7105776	-0.9127195	1.0331174	0.47834384	0.7421685	0.070449226	0.10459744	-1.1130036	-0.67520446	-1.5186784	2.6957517	-0.21624209	1.2447821	-0.5655154	0.95265436	1.7961248	-1.9044392	1.8122611	-0.07655654	-0.893764	1.208758	0.5970756	-0.026321158	2.0189312	0.30252334	-0.037197802	-1.9711696	2.0137353	-1.4165978	-0.2754631	-1.9750844	-1.3830636	-0.8474346	0.17132282	1.4860786	2.3329105	-0.36535183	1.5315368	0.084871605	-0.56122017	-3.4717386\n-1.0658077	0.6552005	-0.22178388	-0.37682912	0.5518305	-0.7919682	1.1520835	0.60139966	0.4624814	-0.25273922	-2.3852446	-2.4365478	-1.5048459	-0.8166464	0.49861497	0.5119294	-1.3045517	-0.86630493	-4.2197366	-1.2856221	-0.27796683	0.60743463	0.18156369	-1.2959727	-0.14545839	0.7216495	1.6721747	-1.8212312	1.6121584	-0.6029036	-0.35304663	-3.273597	2.6202126	-0.5691011	0.28334415	-1.5782881	1.0410137	0.12896785	-3.4139993	-3.0583568	0.33587563	1.4212501	-0.10213698	0.529393	0.42387238	1.3023432	-0.187045	3.006925	-1.3161783	1.5729666	1.0631275	-0.35967237	-2.9411619	0.014659326	-1.7675359	1.2945197	-1.5872043	0.17760442	-0.9218893	0.6764061	-1.1763625	0.36189002	0.4386859	0.03219953\n-0.12685962	1.496917	-1.2983632	-0.9483369	0.88386625	1.7313046	1.5596575	-1.5542175	0.12582655	1.9727676	0.5935774	-1.7869182	-1.7106441	3.0343623	-2.3030977	-0.794458	0.36104503	0.83506036	0.7567417	0.48388374	2.7753956	-0.3815509	1.1231046	-1.4066068	2.561893	-0.561034	0.33770993	-2.0526865	-0.4456007	-0.28077748	0.24354199	-1.0764806	-0.4737987	1.7295095	-3.039895	1.7780105	-1.7271048	2.4148707	1.0945512	0.7312493	-0.19989792	0.16125137	-0.5842559	-1.197411	-0.38539425	-0.2462173	-1.2778369	-0.21130432	0.9593917	0.34923428	0.62652737	-1.6672566	0.3437634	0.6210164	2.4623897	0.72986084	1.4447007	-0.8353584	3.3114955	0.7976672	0.22135481	-1.9474168	1.4804748	0.17254867\n-1.6150953	0.7759157	-0.19657981	2.9642243	0.69526035	2.1022663	2.286328	-1.5113513	-0.052374754	-2.5686393	-0.74758714	0.017922942	1.8706098	-0.706983	-0.75989	-0.947693	0.25894386	0.7223559	0.9918836	-0.4998674	-2.0408907	0.33574784	0.5185406	0.4574073	1.383509	0.34996787	-0.8391455	0.9065373	-2.452863	-0.04738872	-0.45730978	-1.9513954	-2.3225951	-1.6790698	1.2724987	-1.6906701	-0.6975103	0.12034664	-0.26323417	-1.1422397	-1.3972228	0.8065207	1.9553175	-2.6685054	-2.988143	1.3968793	-0.75561464	-0.12571879	-1.1122545	-0.88648105	-2.357419	2.3257072	-1.8193876	1.0543183	1.4066916	2.4871907	0.13402423	-0.38549668	1.5462486	0.8649625	0.25558653	3.4644215	-1.5588374	-0.47241795\n2.4461908	0.7998478	-0.902821	-1.8066506	-0.83420706	-0.67507803	-0.6229234	1.5401983	-1.5616657	0.6956975	1.1244172	0.048471007	-0.8817738	-0.96884924	1.1515921	2.5408807	-0.62854546	-1.2188382	0.62126595	-2.277608	2.2565272	1.3266561	0.71055394	-0.5923447	1.5417036	0.43788856	0.021506889	1.737072	-0.15502813	-0.06860951	-0.8262006	-0.13894838	-2.6828506	-0.8759766	1.2798893	-1.1252389	2.6599865	0.664141	-0.8059727	0.3541013	-0.5190714	-2.9299755	-0.65060437	-1.533015	0.9177504	-0.16836464	-0.3083086	0.7772554	0.7154504	-0.33631417	1.0004742	2.0062695	2.499776	-0.56506956	1.0844167	-0.53082454	-0.005527113	0.43737215	2.8535485	-1.2564569	-0.32149026	-1.6390942	-2.0067697	-2.2273343\n0.5642075	0.6534916	0.990074	-0.62726635	-0.6998275	-2.1839519	0.29706818	0.117326565	1.4507663	1.3504807	2.0357192	1.7536072	0.18669625	-1.7704135	0.8723215	-0.9268881	-1.9279376	1.2085077	1.4382969	2.8888786	2.1188455	1.6601963	0.1370133	0.21856862	1.7217565	3.47823	-0.48641962	2.1114135	-1.4236165	-1.1207105	-0.85647947	1.6337558	0.39062977	1.5674877	-1.7968103	-0.518572	0.7811947	0.95109606	-0.7741435	-0.75107783	-3.3685749	0.65043527	1.8699619	1.4559783	0.11795194	2.2187731	1.5146946	-0.5560564	-3.0561993	3.2951698	-1.1926452	-0.58476	2.1149046	-0.6636009	1.0232694	0.51557374	2.0810378	-0.4698257	0.2321461	0.5809978	0.7569292	0.54980433	1.0444126	1.1031454\n1.5802321	-0.82216895	-1.2363108	-3.048751	1.1543835	0.3441511	-0.91425735	-1.3304344	0.45130727	2.2123356	-0.9848219	-0.28617153	-0.48023233	-1.4638062	1.417163	-0.6449784	-2.484068	1.1902238	-1.1052486	0.14924692	-0.6013957	1.0208341	1.9008366	1.407594	-0.60865	3.1991313	-2.512237	1.0347087	-1.0150794	-1.9918842	2.5781767	-1.1130143	-0.5045743	1.6905504	0.10878989	0.38704255	2.67549	0.3867403	0.48577684	-0.8963573	-2.6058674	-0.81372774	2.1938121	2.0822852	-0.71825516	-1.8632321	0.5955727	2.0117724	1.1880654	2.1973176	0.39712942	1.6768801	-2.3925843	-0.2896521	-0.48177025	-0.8501032	1.3799893	0.28526816	-1.5547999	-2.2171125	-1.6876125	0.2339009	-0.8452856	-2.02915\n-0.07137375	0.038792767	-1.4295787	-1.5884367	0.8662332	1.061258	1.6223929	2.3819585	1.8257146	1.1741748	-1.073571	0.5613754	0.1878348	-3.250761	0.08696376	-0.97111523	1.0320567	2.1694493	-4.1087065	1.202184	1.3720976	0.5749335	-1.2892114	2.5695784	-0.0016531636	0.28131196	-0.27232677	-1.2502322	2.0539079	-2.4552855	-1.1167386	4.08172	-0.63501126	-0.7131552	-0.36146724	-0.3138986	-0.044449728	-1.0738811	-0.44790223	0.051680997	2.2686424	1.5127491	-1.1518172	0.32257965	-1.4215232	0.17737241	-1.7264136	-1.4897162	1.8156772	-0.14811032	-4.8459606	-0.3223795	-0.70290786	0.9054916	0.77309793	0.51277846	2.1833718	-1.1461282	0.009456547	1.5574133	0.833435	-1.5813259	0.8703954	1.2958093\n0.02762786	1.0192899	1.4618759	0.91296464	-0.38753554	-1.5042535	0.99007297	0.712332	1.1929828	0.89038235	-1.1209545	1.6423827	-0.1381946	-0.45399317	1.0729915	-1.2177974	0.816846	0.43214595	0.19684482	0.014042888	-1.1639779	0.846253	-1.0042117	0.7520294	-0.76325524	0.8741432	1.356535	1.9832964	0.74122643	-0.88712645	2.1041224	-0.70382863	-1.1666129	1.3156327	-1.4837917	1.1834543	0.18035458	0.041301463	-0.71027476	-2.395542	0.570848	3.5482597	-1.1860851	2.0981555	0.3539506	-1.5654594	-0.7731741	0.059672914	0.17218642	0.83030194	2.6305406	1.9572135	0.77483237	3.1428728	3.4257312	0.13419738	-0.8424846	-0.06703225	-1.6682285	1.8027256	1.7526015	-0.07308076	0.4844111	1.657551\n0.13974458	1.2525094	0.637086	3.2906785	0.7269809	1.3774177	0.8137404	1.3238639	3.8895285	-0.49514872	-0.7646357	-0.5311851	-0.053554706	1.0051436	1.8439964	0.46547905	1.015268	-0.49700263	-3.5184531	0.5815875	0.61827284	-0.88918227	1.45399	-1.0349277	-0.8921547	-0.49618822	-0.44480768	-0.6407422	1.7607343	2.699184	1.6065096	-3.2711916	-0.4104235	-1.8165	-0.09007239	-0.24017468	2.1425138	0.33884645	1.0348608	1.629833	3.2738774	0.64644605	0.51917195	-0.7635669	0.85232186	0.7279812	-1.5419995	-0.24843894	-2.4268575	2.0084796	-0.23345488	0.841054	1.2385366	0.3685822	0.036073778	-2.0830274	0.13524145	-1.0873642	-0.63680035	-1.8118944	2.747562	-0.4728093	0.17110142	0.13719667\n-1.5377016	1.0045868	-0.6779384	-2.4083319	0.6668936	-1.4404955	-2.2890399	-1.4198747	-1.0924907	0.49045026	-1.1746068	-0.9054845	-2.0391643	-1.5846405	-1.1035573	-0.3401403	1.2408979	-0.5028144	-2.5081105	1.6807011	-0.050275203	-3.683371	-0.4101896	-1.9396753	-0.8443791	0.80181843	-0.22996573	-2.2142625	1.2394085	2.6332533	1.0247554	-0.07321736	1.5259838	2.278319	0.8036584	1.4850265	0.39443702	0.6998721	1.2062001	-0.19241153	-0.48290136	-0.19707617	2.0826437	1.4939378	1.6320884	1.7671795	0.84842914	-2.1401052	-0.8742278	-0.351958	2.709269	-1.2693796	1.2239192	-2.4407365	1.4808962	-1.499852	0.18223873	-0.8462363	2.2231333	1.7908626	0.94920486	0.0029183722	-2.7948117	-0.5258088\n1.1533386	1.8333088	0.50833344	0.1749609	0.8331358	1.6055733	-0.15617806	1.1122962	-2.3102405	-1.6452447	-1.465618	0.023601089	-2.072512	0.18556392	-1.013453	-0.7044157	-0.08005425	-0.008556972	2.1627328	-0.7487922	-1.6725291	0.8099241	-0.54432863	0.7492128	0.0649425	-0.47601393	-0.19568451	0.2912692	1.404814	0.36601123	-0.7108482	-0.98704964	-2.619839	1.2084447	-2.119441	1.8738416	0.13165213	0.6428324	-2.9959917	1.3661748	0.17494676	0.3080123	1.2428122	0.9604303	0.505633	-1.1261952	1.0289729	2.5161088	-2.627048	0.88984156	-0.23222683	0.6659183	-0.58915704	1.5726119	0.9177974	-1.2249445	-1.0353209	0.7846005	-0.16054326	-2.0823505	-0.5965338	0.6260717	-0.7301909	0.48432386\n-1.3804667	3.5621269	0.38788334	-1.9688084	1.2351367	1.1304344	2.4674375	0.9697006	-0.6140041	-0.49624592	0.3668456	1.6958747	2.5822742	-0.64927495	-0.6526735	1.6248686	0.2850701	-0.1312143	0.425673	0.87871265	0.26826552	0.5371184	0.45977423	-3.0339644	-2.3437922	1.0526032	2.3608885	-0.48108804	0.893332	0.5148093	-0.4007244	-0.98553866	1.6460457	1.2257416	-1.8666879	1.2426875	2.8396242	-0.38407034	-0.4355873	-0.08778558	1.4736341	-4.7739086	0.27550018	-1.6813141	-0.6638778	0.20688415	-0.92274815	0.7180158	-0.71398365	-0.79897374	0.66948855	2.1401033	-1.6627659	0.48032713	0.02044598	-0.10833896	-1.7408786	0.37856933	-0.553633	0.5756663	-0.3391048	-1.0713843	-0.81191504	0.50084203\n-0.2281008	1.214192	-1.6803572	0.0977819	1.5202458	-2.795067	1.4958769	0.043735694	-2.5578356	-1.4063281	-1.4882709	1.3916705	1.7753521	0.44818345	1.6052983	0.29358125	-2.0242372	-0.4772506	-0.9678226	-0.3972597	-0.9028805	3.8762877	3.3708513	-0.2117529	0.3924229	1.0400631	1.2056689	-0.2899241	2.2426865	-0.73133695	1.9027452	0.5811279	1.0945947	-2.9598207	1.7023464	0.78482074	1.1902105	-2.088774	1.1127636	-0.38286906	2.4482002	-1.0896534	-2.2112217	0.84383786	0.16020098	-0.27075532	0.36087492	-0.7891433	-1.5880282	-1.4072542	-3.396004	2.2677064	1.4023944	2.0183938	2.4799674	1.2149655	-1.7155303	0.95719904	1.5660383	0.14185746	4.189166	0.10120444	-2.043826	2.0247948\n-0.8889804	-0.8946971	0.031924132	-0.78161484	1.9431427	0.46480075	3.6486845	1.407294	-0.3320057	-2.7919922	2.2041435	-0.7130633	1.7410138	1.2820741	-0.6185299	-2.6821792	1.9653987	-0.5250858	1.3734093	1.5046028	0.9318572	0.54445994	-0.88264436	-0.16945246	-1.5301912	-2.6240222	2.145794	-1.593837	-0.007338425	1.5322704	-0.5820463	2.435601	3.765346	-1.5520064	1.9969193	-1.0771831	-1.3846812	-0.81643814	0.50040627	0.6272708	-0.5357525	-1.512298	0.5086445	1.5614146	-1.2790718	1.9579839	2.2040358	2.9078531	-1.466871	1.1384062	-0.77230686	0.4459101	0.7275663	-0.48352545	-1.2400072	-2.1932862	-1.5232396	-0.21586019	1.2868391	-0.58084565	0.26665658	0.08474161	0.20249355	0.21278128\n-0.027321829	0.40997973	0.41457394	0.7923421	0.98536074	2.044363	0.50345415	1.5459858	0.7721744	1.411583	0.8358038	0.14815111	-0.26154432	0.7154924	-2.7746453	2.6195447	0.69989735	-3.9824865	-1.7609719	-2.7053268	2.8694835	-0.90565485	-1.4157503	0.17270459	-0.45189503	0.15861651	2.9139051	-0.6092852	-1.7949833	-0.15632185	0.45446247	-0.33818287	-0.59565055	1.3398476	0.78659254	0.7163044	-0.19731459	-0.65839475	-1.6103474	-1.8826257	1.7797782	1.5925175	-2.3096583	-0.5378512	-1.427358	-0.78301704	-0.6387766	-4.8474054	-2.930176	0.16715273	-0.8478699	1.6295692	1.8773423	0.3277893	0.6153148	-2.1899455	1.4025127	-0.90244323	-0.95993996	-0.709861	0.45104963	3.5785518	-0.20680715	-0.33014292\n0.62426114	0.18202364	0.19470434	1.4458216	0.08809121	-2.48362	-0.20389786	1.2890029	1.3328463	-1.4682717	0.6644881	0.1439915	2.4234557	-1.2248261	-1.87083	-0.77021825	0.17525825	3.9886582	-0.58709776	1.4123043	0.45882824	-0.23636906	-1.7765471	0.29754573	1.7918239	1.0919496	1.5487775	0.3991412	1.015786	0.1582177	1.9796137	-0.3265805	0.1974818	0.20415117	-1.6647893	0.3667432	1.5146376	-1.4348649	1.5338854	-1.254654	-0.51306254	-0.07496607	1.2721311	1.1449323	-0.7202145	0.3930709	-0.2942828	0.26125008	2.2011893	-2.1288328	2.233933	2.6328163	-0.20697583	-1.6902608	-1.1137505	-0.12335952	0.2527044	0.91593724	3.4622402	2.134798	-1.2061087	-3.029256	2.1158857	1.5174233\n0.5310508	1.730639	0.14815621	0.3927317	1.2638297	3.0024343	-1.2986151	0.24477872	-1.0743102	2.4321125	-0.82338834	1.0637589	-0.24498118	-2.9230566	-1.0645921	1.1253954	0.25922304	-1.1306639	-0.86250836	-0.45606264	-1.8359733	-1.1166819	-0.0781453	-1.5272247	-0.2761938	-1.8207569	-0.99983084	1.4025992	-1.887295	0.043292966	-0.062281683	0.78100705	-0.43233174	0.8921266	-3.4417086	-1.2618839	-0.6104984	-0.4598728	-1.2275004	-0.39451694	2.094354	0.45023036	1.7159846	-0.41233355	0.3696698	0.13098767	0.5310554	3.7371225	-1.0584952	-2.1529946	0.3759627	1.3107634	1.5488153	0.5633553	-0.28810236	0.5273411	-0.21603972	2.4270601	-0.5029651	0.5813158	-0.30722558	0.31379113	1.4047457	-2.3565288\n-0.23380059	0.77217984	0.5425498	-0.3158712	0.02924502	0.26609355	-2.8521519	-2.3218358	1.5116272	2.7942286	1.667764	-1.796771	-2.418664	-0.5071256	-1.5555247	-2.849813	-1.4627389	-2.1548734	-1.6294218	-1.1520958	1.0381663	-2.6546302	-0.37423912	-2.616876	1.1512764	-2.669597	-1.8839483	2.9853013	-0.33016038	-0.85367566	-2.7832632	-0.5918359	0.7241971	-0.56252635	-1.1950588	-0.52178246	0.50467366	-1.782642	2.4118536	-0.16949923	1.9313619	-0.376507	1.9426466	0.55693835	-2.640583	1.1471349	-0.5295878	1.5044142	1.3575236	0.7770184	0.49299702	-0.7927784	-0.4718808	-0.774717	2.045628	-0.4846973	0.17895445	1.2788785	1.0008837	0.99195856	0.98772484	-1.5423758	3.084159	2.6339483\n0.71214765	0.1295968	-2.729744	-1.4397666	0.0050864764	-0.5261845	0.10220187	0.26909915	1.1208255	1.299667	2.1883755	0.6969259	0.2638562	1.3479168	-0.39527544	1.9441551	-1.4637805	1.6518782	1.5909816	0.49214098	0.82942885	0.25645608	-1.372097	0.55544233	0.7386432	-2.110397	0.35737044	-1.336177	-1.2580775	-1.6779417	0.59475607	-2.1120524	0.6093761	2.45559	1.2518823	-0.15782174	-2.333105	-1.6686217	0.03494162	1.5091629	0.41469562	0.87898386	-1.4412154	-3.2030113	-3.4850583	-1.3577287	0.50871414	0.30851886	-0.50800735	-2.8155398	-0.34851557	1.4897344	-0.47043946	-3.0182178	-0.36214215	0.6176426	-0.9849554	-0.6751225	-2.5147705	0.38300973	1.9147505	0.8942312	0.324786	0.0033623977\n-0.54484004	-0.9930845	-1.2861329	-1.8605855	-0.3134018	1.1907431	0.54729676	-0.9289343	-0.021998107	-2.3647199	-0.11991627	-1.559962	-0.26076433	0.0035570646	-0.17833497	-1.4272585	-0.78920823	-2.6193213	0.29524544	0.34885162	-1.4356891	0.37184215	-2.6738944	1.3534621	1.4068578	0.42897505	0.1737244	-1.4036046	1.6963316	-0.3185586	1.650557	0.96390086	0.73146904	-0.8624929	-2.7944224	-0.8643058	-0.0073370817	0.8652558	-0.8823191	-1.3129959	-0.7057186	-0.4463153	0.6140904	0.97347504	-3.024744	-1.0196246	-2.606341	0.90606207	-0.7570413	-0.38220438	-0.07116404	-0.9037473	1.1341192	0.82201827	-1.6687167	-1.9234669	-1.4498912	2.783033	-1.2074604	0.5647493	2.6784005	0.33573636	-1.1077242	-0.45016906\n0.9604715	0.06567679	2.7619507	-2.1179543	-2.3196084	2.7460477	-3.2034392	0.2617686	-1.2295793	-0.50386596	-0.29890066	-0.77462035	2.2069604	0.8952826	1.4551573	2.2222815	0.76399714	-1.1855743	-1.0135375	-1.93344	0.37210926	-1.2033155	-2.7946746	0.6296028	-0.97495234	1.919193	-0.030032814	1.177467	-3.3697066	-1.3400073	-1.3320442	2.4920855	-0.8933977	-0.03566676	-1.3716704	-1.3895632	-0.6950398	1.5801346	0.7163768	-3.083084	-1.8516504	-0.72102946	-0.5801708	1.6679294	-0.9803612	1.1614023	-0.271625	-2.765159	-0.1374437	-0.57780147	1.4558859	-0.10865204	2.179345	2.4075484	-0.47161713	-2.012847	-3.2986166	0.39155558	2.6891553	2.4839666	-1.438028	0.43582985	-0.064427964	1.0553076\n-0.5887669	-2.5948899	0.24035367	-1.8038627	0.16543414	1.6263043	-1.9237428	-1.4109596	-1.9719359	-0.8764242	0.12539221	-0.29019666	0.02674583	-1.7078629	-0.048869234	1.7603006	1.9952819	1.1579841	-1.0974748	-0.7235596	2.0532014	1.9497375	1.720357	0.2609308	-1.5862229	2.8520525	-0.33358866	0.3973468	-0.6715168	0.81909645	-0.27861428	1.4454613	0.26401174	-0.99093056	-2.3155408	-0.17113924	-1.3707869	-0.35464033	0.6765679	-0.38807595	-3.2660093	1.7837197	0.98061556	0.58839184	-1.6529415	-0.8360052	0.03610007	0.19536833	-1.8710395	-0.2948383	0.8078079	-1.645631	-0.9229789	-0.57102144	2.7025075	0.40552282	-0.6350273	-2.413312	-0.6901351	-2.1442645	2.5842605	2.0201666	-1.9705559	-0.06803636\n-2.116606	2.6007402	-1.6798476	0.11674809	3.2708058	1.2364014	2.1197941	-1.71848	0.11449803	0.5657532	-0.17176226	0.99941456	0.54448813	-1.5827248	0.42184454	-3.0563118	0.17639689	-0.34488973	0.22123212	1.3682691	-0.30236864	0.49045685	-0.3048084	-1.5471653	-1.4374292	1.055855	0.07769778	0.44127753	-1.0696443	-0.06983111	-1.6263459	0.47151902	-1.5671719	-0.957926	1.244921	0.8065292	0.41143203	-0.5309852	-1.2247776	-1.2805301	2.4896653	-1.5606288	-1.2205191	0.3202688	-2.246007	-1.7355682	-1.6661962	-1.8714631	1.8438989	1.1421206	2.7043717	-2.1987262	-0.35424626	-0.24495038	-3.3444817	-0.83022094	-0.28394544	-0.26361457	0.41018897	-0.57937354	1.343147	-0.550494	3.0907	1.117156\n-2.4993374	0.9359556	2.7675865	-0.71374714	0.09523213	0.6930119	-1.9941535	-2.312696	1.2449358	0.52839714	-0.97045344	-0.7884596	-0.6914053	-0.08762977	-0.95320743	2.4284492	-1.6793897	-0.16336414	-0.14810424	0.4168025	1.2903585	0.65894365	-0.29497415	-1.007278	0.012018058	2.457828	2.1082335	1.7827914	2.4273849	1.9535258	-1.7699658	2.3534284	-2.1082268	0.2167082	-3.2003624	0.7208574	-1.3403584	0.24146274	0.66856587	0.505739	1.4081839	1.0789315	2.0605717	-0.12715796	-1.6509502	1.6980401	-1.94146	-0.6945649	0.47878605	0.8207184	-0.8457462	-0.42173392	0.058380187	-1.9988613	-2.8191726	0.8059463	-0.69849414	-0.2912031	-2.0251985	0.8449431	-0.3489929	-0.71023655	-0.6529938	-2.7253237\n-0.71859163	-1.9846592	-0.08269634	0.24596348	2.266166	0.44065323	-0.0022529473	0.23873916	-0.99233687	0.39870268	-1.3981193	-0.32107827	-0.7095352	0.13839878	-0.70764256	0.5456707	-0.9564148	0.7891996	0.5117889	1.864275	-0.20244269	-0.88516307	1.0229527	1.2954475	-0.3476799	-0.35378292	-2.4930203	-1.6743844	3.5412505	0.38457218	-0.25433853	-0.10377248	0.5949168	-1.7006799	1.5264245	-0.33739746	0.4771549	-1.478136	2.3411207	-0.53047186	0.7768781	1.3455034	1.521342	1.640725	-0.2860142	-1.917095	-0.29526046	0.031909604	-0.49539787	-1.0520246	-0.9700715	2.3445454	1.8391899	1.2551346	-1.4278331	2.6678648	-1.8172059	1.2523632	-1.329628	1.6288254	0.79768777	-1.1812619	2.2765932	-0.6250577\n1.6717662	-0.81857395	-1.3494649	-0.7276069	0.4256899	0.6798664	-0.4036246	-0.054452132	-0.8990155	0.83799535	-2.2419693	-1.019707	-0.13334519	-0.054395214	0.06277581	0.3077679	-0.6043095	-1.4221115	-1.7531068	-0.10930051	-0.20103121	0.12227396	-0.7929685	0.90894085	2.3685284	-1.6956586	0.4957297	-0.4871328	-0.06808577	0.50661325	2.2340457	2.2563267	1.8931929	1.6739581	-0.35894015	-2.394117	1.8644452	-1.46534	-0.5147716	2.5767162	-0.45649517	-0.78149426	-0.57823604	-0.55597883	-0.2282329	-0.16315107	-0.31527063	1.0487434	0.03951613	-0.34716183	0.5287252	1.4544584	-1.0753125	-2.1744494	-0.13572903	0.6764024	0.50807047	0.96274275	0.7764015	0.1270138	0.30145812	-2.2400632	-1.1822624	-0.51533556\n2.7297964	-2.582236	1.0223179	0.75491667	1.7419541	-3.4813888	-0.35143265	0.061519206	0.25567445	1.517345	1.3580028	0.042264197	-1.9168571	-0.106412485	0.48828882	0.6840045	-1.9830875	-2.1547651	-1.3059194	0.025925541	-4.2772245	-0.46834752	0.8051585	-0.7553558	0.23378263	-1.0521094	-0.6745843	-1.0460882	-3.360441	-1.5295639	-2.4323308	-2.096907	0.35741195	2.9045951	-0.3777186	-1.8601099	0.9650386	1.0795413	-0.02808229	-1.2805465	-0.16015933	-1.0794351	2.4002151	-1.5763757	1.1493856	-0.74365467	-0.3659348	-0.61325485	-0.24157354	1.319069	0.33530602	-1.1247956	-0.1722302	-1.5431222	-0.71531296	1.028295	2.0278559	-3.995477	0.33211815	0.9797484	1.719777	1.8129374	0.091957204	0.9691012\n0.60335743	0.9754699	-0.019719545	-0.16056094	-2.1633449	-2.045163	-1.4486462	-0.13105164	-0.73814756	0.12871097	0.844227	-1.076072	-0.20584406	0.7811424	2.223371	-0.8764641	-1.1018593	-0.417021	-0.35740736	-0.5523829	1.3304558	-0.71150434	-0.39993417	0.75436985	1.3141925	2.9141803	1.7985871	1.1529467	-1.2209048	-1.3457631	-0.58856946	1.5140004	0.05165011	1.2403073	-1.9920574	-1.0784595	0.35091874	-0.29104596	2.6956089	-1.7709833	1.6052042	-1.317524	-1.1637691	-0.75797504	1.2149582	1.4090759	1.9097052	0.45228493	-0.30588397	1.4253653	-1.7721663	-0.6764295	0.4523402	-2.5635922	-0.7018328	-1.4429988	-1.8288455	2.9988236	0.21932644	-1.077744	1.1022068	-3.115811	2.0959527	-1.3258643\n0.10515404	-0.08565727	2.2698567	-1.75763	0.31489727	-0.14320575	0.1093874	1.0270854	0.31227693	0.6988289	-0.24856733	-1.5194697	-0.37586993	0.58646685	-1.7880794	0.3815899	0.11039764	-0.31644422	-1.8204032	0.0066483533	1.9473054	-1.8251514	0.6054998	2.5400743	-0.588984	-1.2524433	-1.533209	3.832046	0.31580335	-1.6776768	0.96577513	0.35249227	1.1479087	-0.73916674	0.8595865	-0.10205399	-0.98717844	-1.5095499	0.17652638	-1.3747056	-0.123800434	-1.30273	-1.1118419	0.41333628	1.8540552	1.6527218	0.78525174	0.3389527	-0.47569513	1.2528957	-0.54500633	-0.83609986	0.15635988	0.9842698	-0.014830922	0.7019554	-0.71689326	-2.2857263	1.8466988	0.052881774	-1.6729857	-1.8874488	0.016216325	0.258986\n-1.3726088	-0.068022996	0.22573408	-0.34681556	-2.1407673	-0.89555776	-1.9085948	1.2175972	-0.9772977	-0.3172275	-1.118484	0.51745874	-0.91342145	1.0682874	2.319	2.7318082	-0.1356132	0.66905105	0.6308071	1.1262378	1.3962137	0.27024302	0.33584878	-0.26904753	0.808521	0.39963743	-1.5124446	0.23189573	2.410548	0.120611094	-1.8080708	1.55712	0.5139324	-0.55517745	0.44221154	-0.9612751	-2.1596065	-1.8400453	-2.1531417	3.4322548	2.2928367	-1.8181218	0.50388825	-0.6394201	-1.4108609	-1.0713648	0.22624776	1.4054828	2.4080226	1.825903	-0.24152811	0.96840906	0.8710988	0.67964315	0.9558793	1.2716593	0.84894246	0.17604738	0.9776707	0.70185417	1.8332148	-1.2339954	-0.47161734	1.3420724\n-1.0962847	2.6630511	2.8446655	0.80724657	-0.5918435	-0.62314403	0.052746467	1.3403571	0.26574683	-0.39477697	-0.94547206	-1.036075	0.65479136	-1.4451528	-0.5206712	-1.3563533	-0.5589733	0.81264436	2.233799	0.29127732	1.071725	-2.311862	1.0061495	-0.50935477	0.009811988	-1.04964	-1.1431073	-2.829973	2.389554	-1.3770086	2.0776255	0.28106937	1.7333709	3.0396435	-0.15226409	-0.14407855	-1.1409959	-1.589256	-0.13807961	-0.9729274	-2.3813367	2.819387	1.096742	0.07978374	1.7524216	0.9279192	-1.3349667	-0.6400446	0.22688627	-0.3729826	1.710478	-2.2644243	-0.50264925	-1.096551	-0.5780011	0.8097931	1.7674656	-0.69777757	-0.6451472	0.27576068	-2.4355733	2.279591	-0.85164446	-1.8092896\n0.88797265	3.3809128	0.95035577	2.1043398	2.175541	1.536127	-0.20054775	-0.25074527	-2.31295	-0.9733089	1.6910384	0.26682898	1.4400218	-0.19017285	-0.2247904	2.466632	-1.5118824	-0.6825523	-1.3312056	0.21102874	-2.5578172	1.9974046	0.62506664	0.78454226	-0.83817506	-2.1757722	-0.26586312	0.5595408	-1.6683431	1.1173595	-1.0497226	1.0959735	-0.24383447	0.13251996	-0.2699143	2.113303	-0.4570458	0.11995212	0.096043214	-1.8655841	0.45853466	0.8026881	2.1549232	0.30747858	0.7420427	-1.2217581	-0.1339998	-1.0140473	0.84456646	1.1969098	0.008611952	1.0576656	1.6403087	1.9989911	-0.23894066	0.90558326	3.0280576	-0.7070476	0.116595864	-1.2369428	2.2479131	-1.5056584	0.6360222	0.20707184\n-1.754323	-1.5527766	-1.7527863	-2.9675655	0.19064456	-1.8974559	0.6894827	-1.0272334	-1.0098547	-0.39734316	0.3822982	-0.9357912	-1.7609642	0.9233981	-0.9300419	0.023245309	-0.58668697	-1.1046902	-0.8006967	2.5341976	-2.1642213	1.0822741	-1.4531151	-1.2987626	-0.9429268	-0.99139905	-0.51149696	3.4746346	1.808048	-0.92928493	-1.662867	0.12969704	-1.0040945	0.7278315	-1.7029582	0.9422137	-1.1859648	-0.61889476	0.43767408	-2.555371	-0.44526848	-0.19657399	-0.10194222	-1.0434046	0.37491947	3.0889883	-0.013230459	0.2890655	-0.5170706	-3.237309	0.8682121	1.0451083	2.6947427	1.2100302	2.1052635	-2.1611607	3.3844593	1.1528859	-1.798774	-1.8371711	0.3247248	-1.7653515	-2.7737174	-0.061778318\n-1.7413512	-0.6386949	0.9195253	0.56018174	-0.6098577	-0.07753603	-0.01250235	-1.9200548	-0.30884317	0.65348005	4.142725	-1.9955368	0.9654647	-1.9591596	2.6922488	-0.22149062	-3.111926	-2.736523	-0.8492589	-0.6210421	-2.2153218	-0.47741485	1.0597293	0.4761332	-0.05874875	0.62103206	-0.28629106	0.3758569	3.2835023	2.0321476	1.735667	-1.1786852	0.22211273	1.2064706	0.45243183	-1.8435061	-0.45387754	-1.0252521	0.9347235	-0.10279932	2.434593	-4.626618	-0.7931751	0.1027394	-1.2614356	-1.7629659	1.6354774	-0.66167945	0.17369932	1.3008251	1.2214487	0.6574962	-0.33955804	0.9818726	0.09683109	-2.0645137	1.6789637	0.09060027	1.3509855	-2.726127	-3.042763	0.42824504	-3.2648354	-0.27379534\n1.3454161	0.34949812	-1.0779164	-0.34728527	-0.7235155	1.1757362	-1.6178759	-1.3752478	-2.2582717	-0.19189435	1.3784462	-1.1896361	0.30492815	2.300722	1.062387	0.68134946	-0.60366714	0.5402182	0.16475852	-1.9556067	0.57896435	0.20870344	1.4442466	0.56136864	-2.3575687	0.70792323	0.95070606	1.3063892	0.4339571	-0.38049597	-0.22546592	0.8417469	-2.2649934	2.6241596	-1.138226	-0.30423966	1.0728555	0.8706961	-1.9389688	0.76071423	2.1558554	0.54556406	1.6648849	1.3214077	1.1162136	0.24798636	1.3390852	-1.4255284	-1.1653222	-1.8490763	-1.5784771	1.0808953	1.6375016	0.38428062	1.4149479	1.0923047	-0.706275	0.6697257	-1.3985631	-1.6263553	-2.6348119	0.75668293	-0.45088974	1.8143678\n2.3373468	-1.4125295	-1.3289167	-1.076053	1.6194072	0.66822606	0.10409126	-0.21046758	0.35320142	1.0785809	1.0628356	-1.8418882	1.6370943	1.3489758	0.6466249	1.235511	-1.3809559	1.0015386	-0.63589245	-0.9742736	-0.8151219	1.9761349	-0.14883916	-0.07957387	1.4859388	0.3150735	1.1140013	-2.4718554	1.002609	0.4281836	-1.2768576	-0.4274391	0.46589172	0.57363725	-0.7121807	-0.5506199	0.47199947	-1.5302157	-0.3601817	2.0229914	-0.47522062	0.81259793	2.1779428	-0.52451444	-0.2727453	-2.0061603	-0.19583926	2.3889146	-0.87348324	0.48844087	0.21169391	1.3801554	2.1911778	2.7404578	0.021018313	0.26805663	-2.0447614	0.7766874	0.30677047	1.3899285	0.68798846	-1.0331527	-0.50516033	0.6814992\n-1.4647524	-1.6620439	-2.645128	-3.1981108	-1.5379031	-1.2659546	-0.29507732	0.8513088	-0.6894025	0.8945404	2.1425366	-1.9642491	1.3115423	0.12576005	1.3268124	0.6204065	2.6771834	-1.2006512	0.5224728	-1.4313716	0.43257797	-0.43247238	1.0911436	0.64423436	1.3895441	2.0544028	-0.7071918	0.7073861	-0.6159623	-1.4607618	0.68627435	2.8231456	0.6857129	1.0903424	0.36814216	0.6792724	-0.3706903	0.6869448	-0.05576854	-0.50998396	2.9816372	0.16273828	2.2829762	-2.383212	1.4712919	1.7828017	0.73388433	0.42232916	-0.27607685	-3.3794289	-0.09993542	2.4435506	1.2038727	2.4654946	-3.0608358	-1.7166618	-1.2330108	-0.26414126	3.021357	-0.8856354	-1.3043387	0.2788388	-0.56933784	-2.1166344\n-0.32246464	0.62169987	1.553088	-0.79375875	-2.790899	-0.9686631	1.1803267	-0.18894821	-1.4962468	0.6594956	-1.714288	-3.0650015	-1.6220573	-1.50441	-0.7821094	-1.8630911	0.8623341	0.43021446	-0.38620314	-3.634096	0.51264185	0.8530095	0.521623	-0.38333684	-0.15306655	-1.4293997	2.7028103	2.9254465	-0.12622844	-0.16451661	-2.5288913	-0.12401028	0.4078453	-1.3327552	-2.2628176	0.9725963	-1.8511345	-0.0073377793	-0.10018827	1.6964543	0.63413715	-0.15202	0.8540934	1.8018448	1.5234556	1.8672271	2.0285532	-1.0257821	1.7329658	1.7620107	-1.1112648	0.94207036	1.5775176	-1.4141706	-0.7494424	-1.2097471	1.8190545	-3.3437433	-2.1670046	-0.7828017	-1.4443719	-0.6087952	0.07889747	-0.6224046\n1.5294976	-1.113156	1.0375865	-1.3554839	0.72331876	-0.26171744	0.52377033	-1.101103	-0.60463244	-0.052397724	-0.12848052	-3.5626998	0.81827354	0.18995774	-0.4303046	0.905711	-1.9310778	-0.10128628	0.49103662	2.0712178	0.46524933	-0.6326551	-0.6553034	0.6960257	0.1323379	0.7139237	-0.6441444	-0.57427335	0.5529995	1.1109098	0.8268823	0.098791815	0.022488441	0.5512926	0.3757565	0.07306866	-1.0707209	0.16582844	0.58071834	3.197302	-2.064301	1.6664938	1.6017922	1.1570346	-0.34137017	0.5297613	-2.92808	0.7060268	-1.5397527	-0.98913205	-1.7533184	1.4773601	-0.9989462	-1.4759532	1.4794655	-0.90398145	-1.9236524	4.0117216	-0.9535921	0.8141487	-0.9093413	-1.8503304	-0.58630174	-0.53990406\n-1.6019852	-0.6070348	0.01850848	2.317695	0.9560178	0.84285384	-3.655319	-1.2637378	-1.5713238	0.061997388	-0.46381652	-0.6001307	1.1417578	3.6431108	-0.20342101	1.9263581	-0.10282273	0.58385116	1.6389087	-0.15568449	-0.97424227	2.7125478	-0.27573037	2.1018496	3.1322627	-0.08713546	1.6426009	0.52688324	0.5185563	2.3522434	1.0324717	0.78009903	-0.63765466	1.7253906	-0.26119068	-1.5082504	1.6206621	-1.4201939	-3.6063254	-2.3258502	1.2495263	-0.6767434	2.246709	-0.16514792	-0.19039573	1.0636292	-2.249412	2.826454	0.8740787	0.029247163	0.6110607	0.5319602	0.4838449	0.014194553	1.4312019	-0.8236723	2.1448524	-2.1380796	1.62948	1.4836646	-2.1209555	1.0194223	-0.12616722	-2.0257614\n0.42138135	1.9097718	1.8506829	0.59551024	1.2271477	-1.0625507	1.5368252	0.75033575	0.34669316	-0.6568052	1.0774701	0.33389038	0.6000239	1.3876793	-0.6942477	1.0136603	-0.06688676	0.11499213	-1.5550458	0.06935594	0.33481267	1.1940402	0.36155516	1.9176298	-0.5748115	-1.5465477	-2.7011676	0.842272	-1.7967162	-2.8605967	1.5279608	-1.4893328	-1.030305	0.12548879	3.1068373	2.2779567	-0.3603456	-0.69344604	2.3880594	0.9660278	-2.3454247	1.7493572	1.8107563	-1.7969398	0.36792096	-2.7509072	0.62594825	-2.019097	-0.7291247	-1.1364543	0.43397078	-1.4295374	1.2988704	-0.876056	-1.514075	-0.5951139	-1.2293247	1.1547031	-1.3166201	-1.0093263	-1.259789	2.628381	0.99583673	1.5248246\n-0.7975856	-0.92873496	0.6453942	-1.5410047	-0.80250657	0.792727	-0.7628523	0.19718385	-0.13358198	1.0073563	-2.494345	-0.74529254	-1.6287719	0.474665	-0.78016996	1.0672368	-0.95680666	-0.92943233	0.9783726	2.764857	1.1915518	1.201935	-0.89967746	1.1572459	0.054526996	-0.88479406	-0.0022432483	-1.3605111	2.0947833	-0.5247741	1.9290682	0.4640273	-1.6517171	0.4451394	1.5585384	0.48939785	-1.2003896	-0.94143236	-0.5166841	0.23031564	1.6664809	0.46461684	1.5607003	-1.275276	-0.82943475	-0.557051	-0.58610505	0.13174638	-1.4265432	0.83745843	-0.25153714	1.3285404	-1.6054257	1.1890757	1.7974554	-3.737999	2.7184496	0.6640656	-0.83769023	1.5123874	1.0736674	2.3402052	-0.0041583395	0.32551914\n1.6467335	1.0977802	-0.86371547	-2.733542	0.14277725	0.70892024	1.4702059	0.6911203	0.94369376	1.6084346	-2.8008687	-0.2355283	-2.1767135	1.4939433	-1.0116704	-0.5656011	-0.024321107	1.9166703	0.16267592	2.0155437	0.055797875	-1.9856716	-1.0936506	-0.74698997	-1.1233945	-0.07576906	0.024291229	-1.4308095	-0.7663369	0.70574456	0.48346314	4.0688076	0.5069305	2.353516	1.6023414	0.018391646	-1.8080531	1.2004253	2.4667654	1.09587	1.7540497	1.8093301	0.0076322197	-0.90241164	0.5585819	-1.13604	-2.4736872	1.3254969	-1.2124889	0.45712823	1.9696063	-0.39221948	1.4109155	0.5010133	-0.1540694	0.9851953	-1.262863	-1.7756411	0.444491	4.0791116	-1.2598844	0.8600431	-0.47706908	-0.5852084\n-0.7380514	-0.4709232	-0.6635377	-0.54105264	0.15640172	0.7231677	-0.9236448	1.2263108	-2.6930645	0.120550126	0.5861041	1.7825296	-0.44957194	2.1302698	0.43427253	1.0799143	-0.5523751	0.79957676	0.33479914	-1.024088	3.610294	-0.2683819	-1.1830302	-0.5706113	-1.2018439	0.60588306	0.76050436	0.6913413	0.9789875	-1.0227433	-1.5431776	-0.8830232	-0.47421116	2.988318	1.0903068	0.56575805	3.5966892	0.4595388	0.1534625	-1.8454235	-0.5130373	2.4040902	1.0984194	-3.0041876	-3.6417465	0.29797965	-0.6542273	-0.39443538	3.7374022	0.84812725	-0.25387865	0.8544269	0.53269637	0.015710961	2.4565907	1.5698909	-0.7920565	1.4673426	-0.6455975	0.74217534	-1.5965254	0.2620144	1.2557744	1.3641417\n0.106279925	0.80885714	-0.8548557	3.3701835	0.82142884	1.1994306	-0.9237846	-0.32883134	-0.7907676	0.18847305	-0.2599424	1.238147	-1.8380017	0.6602297	-2.8210523	-0.43106183	1.105813	-1.6078494	2.5905178	0.57185656	-0.704354	-0.8819485	2.1820328	1.3535085	1.537274	-4.556297	-0.89427406	-1.0415686	-2.176795	-1.3614285	3.3890274	2.068055	1.606704	1.3463305	4.5882263	0.8286746	2.6010842	3.1966982	-0.2261567	-0.13524437	-1.2443058	-3.0115497	1.9364767	-1.2714994	-1.1207407	-1.2475208	-0.25992963	-0.14694409	1.9883094	-0.4096528	-2.2364354	-1.5376654	0.6345802	3.5818143	-0.39273334	-1.714688	1.001942	2.2320986	-1.8419694	-0.9304341	-0.57567275	-1.4229418	2.1863508	-0.19266237\n0.24066517	-2.5475082	1.77521	0.2637605	0.26061454	-0.062190246	4.281476	-1.3465886	0.8188105	0.6242765	-2.1969597	-0.12251678	1.5846428	-0.41863924	3.3296647	0.99997634	2.7458327	0.81158286	-0.9647383	-1.8035163	1.4559602	-0.9381098	1.5506374	1.946118	-1.345023	1.0775921	0.95222133	-0.77056587	-0.37965178	0.34628364	1.1527307	1.5052701	-1.9887133	-0.26493824	-0.22576125	0.127328	1.0970788	-0.95788676	0.04487022	0.37612858	-1.5599921	0.2391137	0.36216348	0.09624496	-2.6763294	1.5572954	0.2009035	2.1185138	-0.5386021	0.11608449	0.53618926	-1.8044707	-0.7287643	2.550145	-0.5472845	0.30738556	1.4223931	0.3532267	-0.2237878	-1.0873367	1.5969021	-0.243719	-0.20725834	-1.7280539\n0.8199555	-0.65574104	4.059703	-0.30213785	0.49691528	-0.72105914	-0.37747464	-0.22235762	-0.2793349	-0.5079544	-0.21893582	-0.88863856	-0.23830089	-0.76758033	0.6259162	0.50481117	-0.53074855	-0.22808404	0.24448565	1.2534363	2.428384	-0.50456274	0.25386706	1.832197	3.1775916	1.4661286	0.5901365	0.928675	1.0807513	-1.212421	2.2584865	-1.861172	0.08047253	1.1719278	-0.47675943	0.51893246	-1.2959411	2.7100475	1.5232944	-0.69319	1.0475798	-1.7549542	1.7711997	-1.076085	-0.85779685	-1.7217411	1.035179	-0.11325664	-1.2523837	0.7411854	0.8493563	1.7874346	-2.894142	2.1679852	1.5646682	2.0708318	0.20707943	-1.3979502	-3.3325956	1.444446	3.7829425	1.8076422	-0.12287637	0.22529843\n-2.2249312	1.8580959	-2.637516	-0.37433156	-1.257157	-2.223286	2.3355358	-1.2840288	-1.7372757	1.0491481	-0.15589347	-3.2540984	-2.3709128	0.32003734	-1.1640364	2.9538376	2.417878	-1.7602469	-1.2645351	1.0681008	-0.23721014	3.8090143	2.0690234	-0.5940227	-2.1941469	-0.26497445	-1.5992396	-0.5455438	-0.6535705	0.3559017	2.4934916	-0.020515919	1.5903944	0.49738696	-1.6384608	-3.4731586	-1.2125345	1.5143876	-0.74621964	0.21772951	-0.5326232	1.4972903	0.13847154	0.8806339	0.41859534	-2.6264868	1.9399297	-1.7277175	1.9078747	-0.28334925	-1.6280195	-0.4735908	5.1658354	2.2640982	-0.685805	0.684719	-0.31732285	0.6873979	1.0331997	1.3536999	0.05416592	3.1818695	0.81457144	-1.7937001\n1.1511358	0.27891523	0.3990976	0.6757847	0.046343274	-0.23891912	-0.40246344	-0.66799927	-0.88034475	-1.5961572	2.8278625	-0.39077678	0.4510752	-1.1145458	1.0207596	-1.6339365	0.033302452	1.9403201	-0.42347738	2.7880635	-1.8649333	-1.2509502	0.2473554	-1.8009443	-2.5244977	0.85211474	2.1497574	-1.1243857	-2.3753183	-1.2797009	-0.49071294	-0.7420601	1.2896869	0.64376605	1.3826461	-0.34927145	0.72866917	0.54638904	-0.6686626	-1.3653008	0.88843477	3.2673054	-0.17759927	-0.13773318	-2.1714234	0.77921927	1.4523832	-1.0594646	2.518405	-0.08036287	0.26151	-0.21094948	1.5548414	-3.5695205	0.9775272	-1.1878151	-0.4655264	0.22035189	-1.8039135	-0.43723112	-0.6333293	-0.1443979	-3.514436	-0.12425591\n2.4493716	0.93313617	-0.4563078	-0.31437936	-0.8864319	-1.1721305	-2.2744853	0.72068185	0.6116025	0.8770299	-2.805289	-1.2806926	-0.010419932	0.113245964	-1.8205512	0.6811736	0.06047456	-2.1881938	-0.8405404	0.14291738	0.6424199	1.4435924	0.03874351	1.709631	-0.6757147	0.31449914	1.1499683	-0.7622942	3.1816273	-1.6024554	0.7804051	1.1129166	-1.35182	-1.7412581	1.7351812	-0.713676	0.44973603	1.4790655	4.2365413	-2.1774669	-3.3910866	-3.1617768	-0.044535685	-1.2639399	1.0247225	1.5829929	-1.4695388	-0.45825177	0.30030182	-2.144473	4.0604115	-0.5697509	0.56206274	1.1090264	0.51414126	-2.28749	-0.9228031	-2.0012267	-0.42502216	-1.0946773	-0.42345122	-0.68207955	-1.0319229	0.91153306\n-0.845516	0.32178944	-1.3172103	-0.2868714	-1.4619695	1.0552142	1.9766611	0.4431969	3.1165655	-0.139053	-1.3821031	-0.083856426	-0.8959297	0.6967326	2.486109	-0.09305171	0.8280869	-2.7695596	0.18330966	0.42055106	-0.4244218	0.26605117	-0.014296738	0.44981244	-0.943127	-1.7475114	-1.3134735	0.79267174	-0.5469275	2.2842088	0.07042212	-0.74710304	1.3538563	-0.8357341	1.6457163	2.7345517	0.8374618	-0.4390658	0.23481649	-0.62430966	0.05044269	-0.29071456	-0.60740215	-1.1872435	-1.112674	0.07546294	0.64021426	0.6767388	-0.9458292	0.6972421	2.4499924	-0.9863207	-0.7340996	-0.66168606	-1.4750289	1.2648332	-0.065963835	3.7356267	-2.553806	1.3184298	-0.8728647	-0.15482034	-0.07495364	4.357888\n2.1879523	0.5363444	-1.8400198	0.5630203	0.53181463	0.9331196	0.23337653	0.10592932	-3.0132444	0.20400515	-1.3271381	-0.45525667	1.1875083	-0.45206067	-2.8358772	-2.3094995	0.7864002	0.16913977	1.048872	2.1115277	-0.9118779	-0.20372197	0.37559614	2.4093328	0.21561474	1.53266	-0.35747063	0.16805552	0.46883556	-2.9296873	0.5106713	-1.2581433	0.48940596	0.12811197	-1.4632535	0.58919495	-0.4033741	0.6935037	-0.011513703	-5.2527757	0.20950496	-1.6356139	-0.4117923	-1.5252479	-0.21356383	-0.57313854	1.8334643	2.3161838	-0.64818686	3.0246894	-0.39234075	2.1372225	0.0023878603	0.8790384	-0.3979782	-0.14663342	1.6193544	1.8116945	-0.9320763	0.07623527	1.9154152	0.80172294	-1.0891253	-1.8415139\n-1.5050014	-0.3485315	1.7051438	-1.3270526	2.4849455	1.6480291	0.34251744	-1.1091124	2.7494934	-0.009280852	0.8996189	-0.23509948	-0.45755523	-1.5486308	-1.3817976	0.32587445	0.005920693	-2.0332017	0.19804223	1.6443391	0.52362394	1.8060975	-1.6927586	1.3185589	0.77620566	-1.0379317	0.05862278	-0.106921084	1.5260353	-0.25670773	0.88057965	3.5494425	-0.09674694	0.994866	0.339173	2.0235167	1.4843552	-0.5735033	0.977062	-0.93876	-0.12568338	-0.31647706	-0.5251055	2.0203888	0.56980157	0.93022686	0.055383973	0.2787253	0.5882084	-0.4577288	-0.022154428	-1.6634098	-3.585594	-0.057533212	1.2782911	1.5486354	2.167742	-1.2012783	-0.7440091	-1.14165	0.4008044	-2.3690276	-1.7310139	-2.8235428\n0.4401696	-0.07844616	-0.625832	1.726095	-0.43951085	-0.39119658	-0.80051154	1.340901	4.3329535	0.16760233	-0.4395176	0.66881126	1.9861767	0.6419283	0.8718052	1.0998666	-1.8769954	-0.3235215	0.5058816	-0.32748723	1.6572124	0.740316	0.25317916	-1.0184445	0.6855542	-0.9067888	-2.6523745	-2.0354402	-1.7762747	-1.8598686	0.55119026	1.9062905	1.5646082	1.2646608	0.20496224	0.6982629	-2.944896	0.26258802	1.479637	0.8936993	-2.6863885	0.7688175	-2.147922	0.47190648	-0.8179112	-0.5875347	1.7090151	-2.5893748	1.2942431	-0.43325675	1.1241143	0.14988114	-0.7056293	-0.97097147	-1.0775837	-0.110999025	1.2542858	0.40197474	-1.4877921	-1.226797	-0.36399105	0.5383769	-0.16159281	1.5720757\n-1.0781739	-2.8588948	-1.485868	-0.82283634	-1.1172811	2.3302681	-0.78600174	-0.1878764	1.1988161	-0.79461676	-1.0861732	0.72496635	1.192673	0.26364174	1.8711278	1.3460782	1.9723241	-0.2998073	-0.15193927	-1.7746568	0.35109964	-0.74906236	2.1761754	1.1550555	1.088792	-1.632854	0.3663779	-0.5973622	1.2900238	1.6135856	0.3085625	1.0697439	0.8314539	-1.3919953	-0.2783091	2.9939744	-0.5962192	-1.0351517	1.8715626	-2.793378	-0.25379407	1.8298653	1.7080762	-3.2100239	2.6302586	-2.3914216	2.9245498	-0.8029222	-0.126271	-0.7927369	1.0628617	0.31255683	-0.69393116	0.32132643	-0.8391917	-0.30632	1.1619303	-3.4162047	-0.29005247	0.3201739	1.5750457	0.14596316	-0.94833547	0.22151522\n1.3342743	2.7843742	-0.9232552	0.6833682	-0.15331219	1.121305	-0.48311123	0.22653396	-1.2389773	-0.18621051	-0.12759195	-2.4064171	-1.789804	-2.8584898	1.0883967	-2.2698245	-0.93889076	-0.7384574	0.1233223	-3.8675442	-1.8392538	-0.3257698	-0.9317657	-3.3893487	-0.5974742	1.0384293	0.541216	1.0367292	-0.28979358	-0.10556779	0.8009444	2.1329458	3.0127993	0.45155686	1.7614135	-0.7947112	-1.970603	-1.4389136	-0.052652568	-0.6984667	-1.6008444	2.3957279	-1.9408861	-0.10261569	0.038931206	1.0313865	-0.29784614	-0.46009722	0.6018807	0.07891602	2.222294	-0.8942884	2.2275105	0.8981714	2.210477	-2.4719698	-1.4297082	0.08078009	-1.5454915	2.917489	-2.185119	0.12660511	1.9656006	-0.47033116\n0.46577808	-2.2775652	-0.09791123	0.106708616	-0.7357392	-0.32488072	1.0564597	-0.9612974	1.9583246	0.14050885	1.7210275	1.1188332	-1.523573	-2.0751526	-0.58374834	-1.8919097	-0.76550746	0.38228738	-0.8620476	1.2851197	0.8667498	2.388825	1.5723343	-2.1057742	1.9607431	0.99577534	0.78612006	-3.298463	0.387485	-0.05853994	-0.16149487	-1.153879	1.2572418	0.89251256	-0.49068385	-0.554512	-1.5943396	-0.00967151	-1.0596215	2.1775513	2.2237418	0.38055924	2.2503412	-0.83724016	-0.010833331	0.09877065	-2.189379	-0.85630846	1.8326229	0.9971672	2.1270502	0.654009	0.6501396	-0.63680655	1.9445597	0.9211435	0.40015882	-1.4863771	-0.97096694	-1.87146	0.018158922	-0.86212504	-2.165992	1.220993\n-0.5826324	-0.97256356	-0.45685533	-0.04647656	-1.5739189	0.3636918	1.7444783	4.9070463	-0.92630625	0.6981414	-1.6274968	-2.0958912	-2.0197551	0.21968086	1.7159492	-0.9502728	-0.82250905	0.6967617	-0.18512985	2.1027398	0.16692503	-1.183049	0.24889262	-0.28881758	-2.1359463	-0.6857804	0.37960443	-0.55817896	-2.1191006	-1.67704	0.21881112	0.7089497	0.19120887	1.1105188	0.456066	1.894085	1.9883099	1.5770965	-0.2578457	1.7709532	-0.4338029	-1.8147128	-0.6803936	0.8153966	0.07327066	1.8745375	0.91201645	0.63105094	0.22674966	-2.1988986	1.2121009	-1.8141555	0.4968152	-1.1584125	-0.23922317	-0.20207146	0.86581045	0.14190607	-1.2366021	2.2690744	-0.121784426	0.8875603	-2.6674037	0.5476404\n1.164013	1.4185567	-0.53116953	0.5168721	-0.06899586	-0.86370635	-0.423109	0.15751116	2.0922806	-0.48905218	1.187328	-1.2160324	0.71817183	-1.6497223	1.4311274	0.7860133	-2.6071537	1.0292712	0.025123073	1.2734619	-1.5540038	-1.8842663	0.75502104	0.061169	0.44839928	1.0451702	0.25587404	-1.2515613	1.6879053	-0.6802691	-3.0045269	-1.0629766	-0.37784198	1.4659008	-0.6777805	0.9457539	-0.61191666	-0.09639405	1.1325246	2.6256993	2.867096	-0.38568166	-1.0026165	0.3070673	-1.5756975	1.049993	1.8514887	-1.837186	1.0824829	-0.37536204	-0.5234583	2.8071916	-0.8842099	1.5430408	-1.5280458	-1.2367052	-0.3807731	-1.5046713	-2.0153906	0.15292172	-2.4646873	0.6135724	-2.7177796	-0.96145594\n1.0168821	1.8881917	0.06909736	-0.31023437	1.0729511	1.3541034	-0.33895558	0.43476006	0.20514728	2.3686774	-0.74982846	2.5097501	2.33489	0.17302138	0.6950467	0.22321603	0.3810737	-2.186263	-0.4129217	-1.9587146	-0.27034655	-0.9719424	2.1192513	-0.081051566	-2.7303352	0.8411772	-0.6505689	0.6129401	-2.5651953	-0.63780373	0.37381247	0.7215868	2.1456387	-0.70143753	-1.710561	2.2157803	2.48284	-2.8379467	-0.5066196	2.9201717	-0.86222446	-1.1638709	-0.23060858	-1.0847827	-0.7990693	-0.120852105	-0.73355633	1.5568062	0.81064856	-0.4296479	-1.4479502	0.40245873	0.20580134	1.1220326	3.8280349	-1.7370365	-0.43592086	-2.845304	-0.47584504	0.25918508	-0.82575065	2.7889216	1.2325741	-1.9666882\n1.2130235	2.4628735	0.48750407	0.051604263	1.817307	-2.2041233	-0.12528051	0.14545366	-0.73909926	2.6369576	1.9293513	0.40139598	-0.7796296	0.23767184	1.2324708	-1.8013676	2.2962399	0.61708874	-0.4166278	-0.47000837	-0.64060134	-0.7858977	-1.5055742	-0.8712062	0.76905024	0.123216085	0.5797209	-2.2558537	0.73903435	-1.6791061	-1.6000384	0.5473768	1.1798306	0.44412228	-1.3626653	3.0424304	2.3190057	1.2437335	1.1763899	2.775287	-2.0486822	-0.56976247	2.8668423	0.5569256	-0.9133715	-1.105622	-0.32593918	-0.44620404	-4.33436	1.7486929	-0.40204164	1.6971861	1.3318335	-1.6558456	-0.96372205	-0.28260046	0.18324156	-1.0921403	1.6421804	-2.2534726	1.6157826	-1.3545681	-0.42636415	-4.0396624\n-0.38180998	-0.9811016	-0.3041906	-0.7734471	1.0130289	1.2900032	-2.0750248	3.3442798	-0.68267304	1.7314132	-2.0564814	-1.3110949	-2.6575544	-0.06398167	-0.17002533	1.3563434	0.7686568	-0.796926	1.3036938	0.95281136	0.86283785	0.050314654	2.025963	-1.4104763	-0.34631684	0.32592732	0.21800464	2.107129	-0.94154966	0.041655812	0.16578716	-1.3215631	0.06294861	0.8300061	0.15353744	0.84687597	0.18345061	-0.25125167	0.86910313	0.4919904	-0.10424103	1.2360749	0.33759025	-0.72687596	-1.215748	-0.28317255	0.47516167	1.1697404	1.633416	-1.0604825	-2.1827762	1.5802402	-0.8760753	-0.15068398	-0.42989722	4.06769	-1.3893617	-2.3738332	1.7351046	-0.76330596	-0.62103534	-0.7478376	-0.36773664	0.7376178\n0.4830574	-1.904647	-1.6281964	-2.4503613	0.14977717	3.4297802	0.49041632	-1.4221008	-0.8165616	2.374385	0.316052	1.2679807	-0.21848695	2.120192	-0.07087988	-0.38981298	0.08804206	1.2000039	-0.6417793	-2.5308359	1.0559051	-0.13772954	0.5503085	-0.920848	-1.3961743	-1.4329486	-0.42475012	-0.0021991136	1.415224	-0.7134437	1.277892	-0.474409	0.94801897	1.0655359	0.27093393	-1.559691	-0.93787116	0.17183684	-1.3277524	0.6929459	0.5414502	0.008757936	-2.9312122	1.5471689	0.8302098	-2.5796437	-1.1624354	-0.96941906	2.3109698	0.8811856	1.9657011	2.4478211	-0.62342936	0.39990333	-2.908173	1.1477958	0.4241824	0.32075483	-0.3094995	2.193109	0.67258745	1.9819872	0.073484786	0.27248287\n-1.0676132	-1.4549204	0.2686519	1.8041202	-1.1498698	-0.32477492	-2.858171	2.0626695	-1.9764009	-1.0226033	-0.3118875	-0.60743827	0.9558192	0.33681485	2.1749039	-1.3251641	0.4350377	-0.62852347	-3.975431	-1.2272862	-1.3235127	1.1155795	-0.503815	0.22381046	-0.60844535	0.86479044	1.4277169	-1.8222487	1.3834131	-1.592441	1.3133433	0.6096637	-2.5672178	-1.1927007	2.1578083	1.085092	-1.5893424	1.0823079	2.327396	0.27484244	0.870592	0.45598146	-1.5677196	-1.3989496	-0.6638308	0.63064426	1.9530469	-1.8930569	-0.9937295	0.08257921	-0.40212864	0.04980185	-1.6176419	0.04923898	-2.7400467	1.1876274	-0.6072005	1.3894961	-2.9228032	-0.14324422	-1.2203242	2.9670777	-0.2501517	3.105099\n-2.3229618	0.3110954	-1.3886019	-0.44919235	-0.57836765	2.9329152	2.409135	-0.0076177446	-1.9260176	-0.39995313	-1.5116414	1.2386233	-0.54275125	1.9535587	0.0138866715	0.80511516	-1.544396	-2.171401	0.6056942	0.6477268	-1.253656	-0.9431619	1.3327132	-1.7699077	0.13154396	1.0395756	1.1107469	-2.2600996	-0.9133249	1.4861295	0.073077425	-0.75967747	-0.91463304	3.736155	1.2176408	-0.8272769	-0.86117667	-1.7923878	-0.47968805	0.83732677	1.0960464	0.63519293	-1.5628829	-0.5318831	-1.5549532	1.2217679	0.14000799	0.7063957	2.624157	0.09704519	0.18936825	-0.8873916	-1.3420621	0.88822705	-0.6306499	-0.4089219	-0.35239694	-2.5685503	-1.3603817	0.16862829	-0.027248502	-1.9789062	2.3581088	-0.049491625\n-1.8643081	0.35488334	1.3761451	-0.6313079	0.70036614	2.7443707	-0.65104675	-2.0345335	0.20030932	-3.9844565	-0.14393069	0.1111033	-2.103913	0.24106975	0.41986123	-0.0061228885	0.198402	-2.4555852	2.2854228	-0.26556635	1.6108836	0.086668216	-1.2160513	2.0550942	1.4107884	-0.29233262	-1.3999627	2.308915	-0.8653184	0.2122407	-1.3972493	-0.659778	-0.3067709	-0.39747736	-1.424097	0.8622522	-0.8057105	-0.24933438	-1.1205677	-0.61951965	1.9630914	0.29867542	-0.17591497	-0.55940336	2.3143244	-0.49212196	-1.1983769	0.58771473	1.6090299	-2.2812176	-0.16073684	0.34426966	-0.84074783	1.4244355	1.2295176	1.0914074	0.521329	0.21097912	-0.67188984	-0.6895514	2.0842164	1.214075	-0.46599925	0.24445368\n1.3401396	0.03199194	1.3471315	-0.13986543	0.73689395	-0.8675208	-1.7015089	1.3748478	-0.7150268	0.30774158	-0.59031194	0.098613806	0.08435194	-0.4956676	0.21834485	2.642465	-1.4909987	2.1596367	-1.2202957	1.9806675	0.5447835	-1.8902776	1.9066801	1.7529207	2.825389	-1.3813049	-1.89049	-2.154731	1.5953691	-2.516607	0.46398067	-0.16451381	-0.43005046	-1.7213346	2.9486601	0.64906853	-0.3311775	0.40806046	0.30697173	0.63542444	0.053271312	2.1615338	0.4184088	-3.7436953	-0.83308434	0.2954847	0.690872	0.73604596	-3.283259	-1.9358919	1.958899	-1.329909	0.88068557	-1.1351328	2.6648116	-1.8359125	-2.5756078	-0.8486279	-0.05430025	1.3773885	0.9513679	0.5621757	0.15027861	0.978115\n0.13079207	1.2951376	-0.5692885	-0.36161044	-0.14235057	-1.822228	-1.4626424	-1.848044	1.3350232	-2.405966	1.499604	-1.6091026	-0.0972427	0.98440874	2.9034107	-0.18787773	0.2599498	-0.13859425	1.5762923	-0.57773066	-0.5211466	1.4036442	-1.8142288	-1.5921777	0.14930905	-0.008078752	0.90700436	0.4561821	1.1847812	1.8650404	1.2015827	0.17521116	-0.21346988	0.96101433	-0.6072815	1.2225022	0.6130055	0.18800762	1.7042719	-0.25733164	1.551089	0.14226104	-0.84832174	0.060997885	-0.70767623	-1.3795669	-1.8493273	2.8463078	2.3761652	-0.4294399	-0.39727548	-1.4402074	0.368503	-2.1187174	0.05566241	0.2434969	-0.5411232	-0.37843573	-1.3314203	0.4151141	-0.025385557	0.17306478	-1.3769625	-0.90878516\n0.0031279793	-0.8263317	-1.925463	0.4640145	0.5834398	0.3489259	2.338029	-0.6461809	-0.99471784	0.072535515	-1.2176809	2.3052309	-1.3778687	-1.417359	3.3569963	-3.2700977	-0.56947213	-0.34375957	-0.30856264	-1.6071463	1.2328085	-0.40190575	-0.110987365	0.45240825	0.58669084	1.0471598	0.53273284	-0.5769	1.2444474	-2.0326173	-2.5934255	1.0840923	0.41708535	1.3055956	0.14566968	2.7899983	0.25214958	-0.112614624	3.160176	0.5704072	0.5070647	-1.8692104	-1.816989	0.19726431	-1.9883211	-1.4853445	-3.126021	0.7678556	-1.9485339	1.2432839	1.0136675	-0.3593997	3.3188674	0.67310405	0.8436423	-0.49981385	-0.6696672	-1.085758	0.09183675	2.3751264	2.54581	2.9905455	-0.70196515	0.48709914\n1.5602007	-0.6099364	-1.6407316	-0.9588971	1.7770981	-0.9585114	-2.1308317	-0.882131	-1.1616534	0.28812268	1.563237	1.5500103	-0.5444059	0.5969829	0.768702	0.2599629	1.6650484	-0.07525348	0.69104195	-1.1460404	-1.9101807	-1.3062493	-0.98375577	-1.5024773	1.5640625	-0.90120524	-1.262295	0.71071845	1.4155551	0.2987032	-0.07426083	-1.4128308	-2.3034024	3.0327022	-2.5022469	-0.5949006	4.296212	0.37476003	0.4789135	-0.82747287	1.7263446	0.77117133	-2.381542	-1.1559372	-0.4407385	1.6684622	-1.3649708	-1.8934345	-2.057879	-1.1473792	-1.73666	-2.3456445	-0.6168922	1.6065184	-1.4349083	3.6316578	-0.77143216	1.707579	-0.09066547	-1.3741705	-0.99608886	1.6134261	0.8031173	0.844911\n1.1385128	-0.71334785	0.5755581	-1.5030628	0.5737888	-0.13712274	-0.4603596	-2.223214	0.112197645	0.6858209	-0.17238274	0.049549375	0.18244877	2.7342663	0.38092652	0.7892836	-0.5654132	1.0106441	-1.6454862	0.25691047	-2.2157643	-0.793272	-0.10856439	-1.1926534	-0.43158403	0.5967684	-0.064073555	-0.6979217	-1.1671962	-0.51836324	2.8971686	0.03501505	1.6507901	-1.4063072	-0.72364056	-3.194061	0.3770106	1.3986166	-1.025775	-1.8955688	-2.0080464	1.3367944	0.4977269	-1.5502841	2.7806473	0.55763626	-1.8756427	0.66875064	-1.8306367	-0.34436038	-1.6619939	2.2402542	-0.108992696	-0.51426274	0.8009306	0.6622699	-2.2158768	-0.9384304	1.340943	-0.6040432	0.48560756	-0.9937715	0.98203063	-1.488173\n0.13961715	2.7535625	-1.1469698	0.24150145	-1.3200027	1.2122834	-0.7427434	-1.2651904	0.8954906	0.533781	-0.22182144	-3.200605	0.6008098	-0.39290443	1.9938923	0.91988087	1.4248757	1.0536337	0.2657087	0.22723937	-0.7985593	0.0796918	1.6207474	2.6095386	-0.6148133	0.44408968	0.7950582	-1.4309345	-0.26451036	-3.9593072	0.0937001	0.8350908	0.3505016	1.5395315	0.31608713	0.17333163	-0.32572365	0.09276926	-1.5624776	-0.37986	1.5514423	-1.2117604	0.893755	-0.71319044	-0.9901982	0.74843127	-1.7107633	1.8170735	-0.5962526	-0.90538096	-1.2948257	0.6157795	-1.3273708	2.1569448	2.052036	0.2533684	0.66493624	0.7560177	-0.92126167	-1.1832572	-2.0942323	0.7981134	2.8017015	-2.1850505\n-0.6436786	0.071199805	-0.7357824	0.15868601	0.2683836	1.3114616	-1.261224	1.6244045	-0.6084054	0.21210493	-0.70619524	0.29877082	2.2491465	0.13242905	0.761554	2.1688628	-0.06720862	-0.77691585	-1.0308367	-4.459973	-0.3618364	-0.9168945	-0.3378582	-0.066940054	-1.5077289	-0.3612104	-1.6310823	-1.8273443	0.72909	2.9613628	-1.8601972	-2.1279476	0.3301745	1.260518	0.26377615	-0.057153698	-3.021639	-2.7137718	0.8078948	0.3382262	-0.4150607	-0.2457168	1.1002669	0.32463706	1.6432825	0.64273727	0.42451733	-3.5114317	-1.4513366	2.9284825	-0.10766609	0.17632288	-2.0423186	0.9732789	0.1886597	-0.10720027	-0.2714379	0.86598516	1.8519567	1.1998401	0.32717142	-0.38924074	1.1192205	-2.767533\n-0.7180943	-1.6567652	-1.7685645	0.18473105	-0.2469772	-0.8347083	-0.75844944	-1.931194	0.17587014	2.6388028	2.343372	1.7805525	0.54283273	0.62386197	-0.5860695	0.27467442	0.59786063	0.59434485	0.51718616	0.66998357	-0.35551745	-0.50569195	-0.38328704	0.88045216	-0.16310753	-1.1995482	-0.22487669	-0.5830288	0.40103802	-0.99632597	1.5049717	1.6179125	0.10928779	-0.23571947	0.5380928	0.24244215	-3.5368094	-1.9883933	-0.63164985	-2.0790138	-0.76830244	-2.5469193	-0.6311373	0.77496374	1.512262	2.2658432	0.5781212	-1.6019974	-1.9530973	3.1661637	-1.0422295	-0.3601198	1.2744331	1.118853	0.3157264	-0.27169782	0.49589223	1.6682562	-2.9035378	0.7572344	-0.16536719	-0.03984936	0.8234423	-0.87408525\n0.6008296	-0.83915097	1.6559069	-1.1526607	2.3485787	-0.7282504	-0.3785382	0.84604204	1.5388619	-0.32430246	1.4743267	1.200817	0.63043714	0.46143126	0.68223363	-0.48664033	-0.43797207	2.1309676	1.474947	-4.0977435	-0.10890942	-0.74897003	1.6146766	-0.72567797	0.20123367	-4.3721595	-1.680297	0.1512052	1.2148939	0.30984148	1.8812761	1.4894496	1.4021538	-0.3277595	2.3090768	0.24623482	0.75460374	2.4957023	0.44751075	-2.963497	2.3397582	-0.37691963	-0.19692177	2.0363448	-2.241963	-0.44346902	-0.33350283	-0.20779738	-0.7765523	1.4868362	-0.508019	0.38836125	-0.80364376	1.3224938	-3.0362158	0.77513236	1.4929967	1.58384	-1.0737945	0.041083854	0.4902436	0.6793886	2.5236843	1.8592092\n-0.5387303	-0.13662569	2.163158	0.58609486	0.14971708	0.3701402	-1.0546917	2.0988278	1.1579063	-1.7968901	0.58215034	-1.9262502	1.643231	-1.7763506	-3.695199	-1.6016799	-1.8240057	1.1953084	2.5473545	-0.28434736	-1.4644425	-1.0255071	0.94755846	0.71204174	-1.3850703	0.56576335	3.7562342	0.11348091	1.2293167	1.0447081	-2.8946257	-1.9846631	2.6085045	3.7707992	3.8161714	0.98953646	2.5155375	-3.848925	2.2832365	0.24882515	-0.6546226	-0.5469959	0.41878423	0.8707773	-0.32089046	0.24632984	-0.68743634	1.8196535	1.1466366	-0.41049993	-0.2010181	-2.1910598	-0.28621083	1.3824153	-0.24040656	-0.30339596	-0.7278109	2.9443986	-1.4184716	0.790602	0.93375516	0.30253437	-1.7355032	-1.5316427\n1.0867195	1.3854301	2.7836354	-1.5483907	-3.8918812	-0.723208	-1.4082487	-0.24392599	-0.7082019	-1.8828441	-0.08129305	0.16302396	-1.0526055	-0.6520414	-1.9740882	-0.047085542	-0.468794	-1.702088	-0.89307415	-1.2261977	-1.6022968	0.798293	-1.3671955	1.170839	-0.8193897	-1.5207635	-0.14962032	1.5514808	-1.2741492	-1.1310583	-0.65683	2.8479257	-2.4399552	-2.361543	-0.90238225	1.0122124	0.5229484	-0.30140212	3.086382	0.94889647	2.552074	-0.8111961	-2.4873383	-3.0448186	-0.68605936	-1.6973345	1.1572536	0.8810183	0.4217757	-0.4612935	-0.8644635	-3.7991366	-0.24927002	1.6927567	2.3484519	-0.7085888	-1.1150484	-2.06011	0.30693325	-1.1283847	-1.3419523	1.0318778	1.5636632	-3.1510463\n-0.16431846	-0.70213825	-0.6017435	0.2710346	2.0330446	3.061651	-2.6048012	-0.7474294	0.99928296	0.5622095	0.10955336	1.5987031	-1.1494595	2.039031	-0.6950257	1.7325846	-1.3239777	0.5539385	2.4499657	-0.433448	-0.74590254	1.2454257	1.0956783	0.5764454	-1.8498267	2.0281663	1.8083622	-0.12923858	-3.292571	1.2639282	-2.973031	0.30781603	0.039670184	-0.007457079	2.8374429	-0.7983859	0.54227644	-1.0435917	-1.6682485	-0.42798862	-0.5959521	-0.924897	0.5189881	-3.2201526	3.4857912	1.2916225	-0.82934475	0.98403084	-0.60755414	-0.08488892	-1.3616006	0.20330419	0.44569683	4.3826466	-2.2931178	0.54572284	1.52168	-0.32804415	-1.5956933	0.12960216	0.010253489	0.63757545	1.225617	0.95393693\n-2.4336343	1.1494508	0.061046496	-0.67752516	-0.059465613	1.4224151	-0.47103843	1.3903749	-1.2664939	-1.8136524	1.4471525	0.48289543	0.1632006	0.80044794	-0.79335296	0.8441177	0.9443049	-0.69505143	-1.0361129	-2.4921737	-0.4276577	1.7786713	2.8364687	-3.2543392	-0.53060865	-0.0023550626	0.24817136	-0.77894074	-1.7970928	2.0171475	-0.38533396	-0.20178717	0.96960944	-0.12213376	1.6030394	-0.2231476	-0.7852128	0.6256192	-1.4555858	1.8542243	-1.5720334	2.9453828	-1.7069825	2.0347228	-2.6978734	0.8617533	0.6117397	-1.5663396	0.1257858	1.8024526	1.7839781	1.8878049	1.5202069	1.4052814	-0.1553427	0.98852897	-0.83075076	1.8564178	-1.6134199	1.4334474	-1.1206526	0.17955981	-0.25408792	1.0644705\n-1.886548	-0.67931926	0.5135209	0.65082955	-0.90322846	-0.28746554	-1.0042682	1.780553	-5.28241	1.5841172	-0.014484884	1.6164011	-1.4325876	1.1886531	2.0434315	-0.46070576	0.8366336	0.50093925	-0.5217997	-1.5326608	0.19098972	-0.75597936	-0.33244517	0.14034086	0.8169931	-1.0442997	-2.4268985	0.46742243	1.1239661	0.6836078	-0.7243777	-0.3923883	-0.0062367124	-1.4010416	0.97330475	-0.16043857	-1.2879825	0.684011	0.47972545	-0.8323725	-2.5915618	-0.7364247	4.26483	2.5460515	-1.9007956	-0.7825463	-1.0760558	0.90484047	2.319153	-1.8954891	-2.5903847	-0.685887	-0.39034167	-0.011011927	1.115116	1.7076998	-1.9745674	-1.8921344	-1.3092067	-0.3949324	0.20385545	2.7649221	-2.9203565	-0.4172102\n0.0717384	3.5952308	1.6019555	-1.5345395	1.366663	-0.40853608	0.7627065	0.44007796	1.9406866	0.9012392	-0.4792825	-1.0155667	-0.13473783	2.1575785	1.7808312	-2.2839944	-0.24917668	-2.1462035	-0.76847154	-0.54767233	-0.6200138	0.54893637	3.4719446	0.36474717	0.76162463	-0.048987262	0.83069485	1.79556	0.8888844	0.024677588	-0.7807734	-2.8844135	-1.8283262	0.07457342	-0.6536902	-3.0233154	0.22392692	1.901979	-0.5696924	0.7547615	1.8562459	-0.3743743	-1.0649408	-0.9192795	-3.7317414	-0.8746188	-1.4196235	-0.24034265	-0.4967935	-2.4222977	0.53324276	0.07136769	0.6491046	0.68293875	3.0931404	-0.036914986	-2.4918985	0.66501087	-0.4927824	0.6047777	0.51730555	0.062233794	-1.3711424	0.2979495\n-0.40617365	0.5228541	-3.1211874	0.1706227	-0.740303	1.7867333	-0.20935902	1.0250622	-0.33204842	0.9583375	-0.46184474	-0.84802175	-1.4689957	-1.0631641	0.70676565	0.5827521	-1.2541015	2.863603	1.4659423	0.22399968	0.3311188	0.43987742	-0.95075417	-1.2896084	-1.0124921	-2.890637	-0.5010767	-0.97265583	-0.6633096	0.3983284	0.28630498	1.3233541	1.022055	-1.0173423	0.2720822	-2.1625993	-2.2305844	-1.6021359	3.2276242	0.1741256	-0.41544083	1.1914743	-0.13737449	3.798132	0.021626612	0.065700784	-0.39799052	-1.2098984	-1.1162723	0.8802703	0.6111155	1.0939626	-1.5983107	-1.5852091	-0.80739546	-1.1670387	3.3917484	-0.53471047	-0.45210788	0.7194831	2.5364177	1.3787338	-0.9940576	-0.85245705\n0.50612366	-1.9898958	-2.2219877	0.30726895	1.5075659	-1.4771408	1.1842093	-1.9122722	2.5344355	-0.5011647	-0.8221192	-1.7989912	-2.3793447	0.33541366	-2.9602146	-3.795111	2.5916853	-1.1054081	0.6064102	1.0877879	-0.68579686	1.001947	-0.22533132	0.9467487	-0.86439896	0.98566645	-0.08945506	-0.25488093	0.48626146	-0.79038495	0.23354036	0.85248655	0.21047455	1.623635	1.4936678	-0.5909071	2.040963	0.83198273	0.44719532	3.086456	5.6078267	1.8512793	0.8815283	1.9638164	-0.76397634	-1.5004264	0.0616097	-1.2410077	-0.12281998	2.8944528	-1.4040668	-0.95155174	2.0315344	-1.7704946	-0.78930324	0.70067173	-1.139321	2.1794863	-0.65407646	-2.9287632	-2.1381028	0.6707132	-1.8929622	0.3553502\n1.4431672	1.897481	1.6676588	0.070735574	1.2243603	-0.023446554	-0.63312286	-1.7872721	1.4040391	-1.3247865	3.9491463	1.106752	0.025599137	1.0011784	-0.93717957	-0.18899606	0.78930587	1.599503	-1.0292805	1.514948	1.8000547	0.20698944	1.1177748	-0.7265442	-0.02084613	0.7942379	1.6808729	0.32486764	1.0121276	-0.548783	1.1691077	1.6327436	1.1886233	-0.3240412	1.7274598	0.6493127	-3.5320446	-0.35680172	-1.1323905	1.2158757	2.0076408	-0.02513753	-0.13668759	-0.831204	-0.81668437	0.08077018	-0.62909853	1.6450695	-0.18275088	1.2860285	-2.5106924	-2.5649502	2.6804712	2.486173	0.2539664	-0.69971865	0.02147234	0.025682574	2.7577038	-3.7803786	0.44985917	2.041568	-3.288414	2.9964056\n-0.73006797	-2.1098638	-0.9033957	1.2412691	1.8279235	-2.530667	0.1667755	-1.4956253	-1.6838808	1.7770495	0.8056478	0.23709467	-1.544471	-0.79036987	1.4042927	0.2106819	0.9847831	-2.8406684	-1.3555006	-0.022812046	1.7956971	-0.14772217	-0.8777029	-2.5989559	2.693714	-1.0739039	0.7874462	-1.0782331	1.7789658	0.30830723	3.187512	0.5732436	1.6120349	0.7652199	-0.39149404	-1.0376797	-0.42718408	0.10148499	1.164593	-1.8551239	1.1324587	1.8698256	1.5255646	-0.5105882	-0.12808113	1.5518595	1.7718166	0.84947777	0.23118621	-0.9598264	1.1760384	-0.88212264	1.9551349	-0.38725877	0.6330822	1.5932509	-0.78896964	3.3609273	0.16043463	-0.5706909	-0.47915718	-2.8009233	0.95791	0.56048566\n1.1400893	0.53468394	-0.33221266	-1.3538231	-1.133924	-2.0971086	1.6950382	1.4082257	-0.53408027	-1.7608516	-0.28139764	0.68656725	-0.42898795	-1.2220944	0.7691221	-1.3572878	0.38796467	0.47829956	1.7827592	-3.6303024	0.41669008	-1.4491359	0.13880308	-0.5225635	0.552346	-0.7430347	-0.2568215	-2.0965507	-0.20293099	-1.7935994	0.13180605	-1.2408651	-0.32298335	-2.1341136	1.5443345	-1.9155923	-1.5261375	-0.052190043	0.7777649	-0.7377876	-0.3940909	-0.85292673	0.33464265	-0.11608844	2.5769057	1.2746975	-2.6983495	0.3074486	-0.008588944	1.090636	-1.17073	-4.077892	1.356366	-0.658781	-0.27288675	3.3555837	0.22624347	2.438218	-2.6378603	0.17637601	-2.4872122	1.5372732	0.527299	-2.2017498\n-0.5057786	0.88370514	0.7210026	1.7365347	0.40852442	-0.91998047	0.66756225	3.1019576	2.8812718	1.7868745	-0.31788206	2.2835605	-1.5378308	1.2166308	-0.3504551	3.4330606	-1.554303	-0.25924656	-1.3652117	0.362701	-1.2339318	2.2366407	0.28967723	2.0233448	-1.4044917	0.6854687	2.158663	-1.5731059	2.1473575	1.0430231	0.18573947	2.7037039	-0.46294472	-0.18662842	0.56463665	-0.14179176	-1.6579313	0.69191027	-0.31226334	0.3259156	-3.0604026	1.0855393	1.5588571	0.9137265	0.49832875	1.4112061	0.6472078	-3.6788301	2.0980234	-1.2240144	-0.36442253	-1.4196628	-2.3620124	1.2698905	-1.409353	-0.15231897	-0.68500996	2.8304772	0.2800738	-1.685081	0.6912317	-0.10657841	1.0552441	0.17516509\n-0.62272465	1.0714767	3.2297485	1.0130144	0.4742418	-0.6754277	2.3816423	1.9864057	-0.5895594	-0.6766464	2.3381042	-2.8963006	0.29386678	0.5023579	0.6807756	-0.55209	-1.1938177	-1.4667196	-2.0426452	-2.3144703	-1.6949944	0.9661954	-1.6568902	0.07140301	2.9215188	-1.9008584	0.5020901	2.7603142	-3.435912	-1.1325865	-0.037583165	0.75865954	-1.734695	0.544725	-1.4623826	1.0039631	-0.04850757	-0.4893784	0.9716734	0.020312445	0.7527548	1.4618125	0.84458095	0.31668758	1.2493732	-0.86065954	-0.2551616	1.3201694	-1.6752086	1.7802228	0.92292464	-1.8918855	-0.5030707	-1.5168195	-1.723582	-0.43427265	-0.61176485	-0.2468598	-2.414519	0.54771453	-0.82236874	-0.3212173	-0.735602	2.950874\n2.207424	-2.730569	-0.35680115	0.5961661	-3.8603177	1.0882752	0.9696183	0.23169635	0.8138564	-1.2607422	-0.2143984	1.933055	1.9428083	1.8507046	-2.0229056	-0.35938433	-1.8055451	-1.7618618	-3.050078	-1.843358	-3.1612325	0.22678727	-1.47475	-0.14594339	-1.397927	1.3030792	0.4867146	2.4508152	-0.497719	-0.31988811	0.8889293	1.3086555	3.4084485	0.113618635	1.8775085	-3.089952	2.2404764	3.1223717	1.7527859	2.6237419	-1.1758251	0.021523742	0.6800151	0.6594928	-1.3468156	-0.76728696	-0.7534298	-1.2327908	-0.41255003	0.6276771	-0.94287246	0.9202843	-1.3546821	-0.6314672	2.6443157	-1.2270392	2.0104933	-0.36528453	1.5501193	-0.9368627	-0.120233275	0.7739778	-0.13369238	1.9210644\n-1.6389714	-1.5497447	-0.09599335	-0.8597905	-0.9283482	0.03373852	-1.8834181	2.106585	1.488143	-0.6221355	1.4046501	0.9316417	-1.4623351	-0.4757029	0.4363146	0.023299072	1.0460556	3.2555242	0.62615705	0.21215041	0.23879367	-0.5764754	-1.6802691	-1.7372136	-1.2644161	0.25610012	-0.42178	0.72059995	0.6689787	-0.27803755	1.2779785	-0.7179447	0.48298028	-0.65975624	-2.5144496	-2.1926475	0.32033142	1.8103606	-1.5235021	-0.6048631	2.2612424	-0.4805564	-0.8369773	0.3066825	-0.6026688	-1.3587227	-0.81230867	0.26273358	-1.4576043	0.19654575	0.6901151	1.0985051	1.711973	-0.91054326	-1.085053	1.7780485	-0.79990304	1.030174	-0.3270743	-0.8070799	1.2562777	2.4550982	0.4496693	0.39795947\n1.7348887	-2.2537937	-0.48497555	0.45763782	-3.1107564	-0.74572515	0.008995185	-0.57484734	0.2384513	-2.1099386	0.09223899	0.23261182	-1.2246845	-1.7379373	-1.1914257	0.06589662	1.252646	0.31228974	0.89443934	1.8183751	-0.36494994	-1.0965891	-3.3206403	-1.4952649	-1.773275	-0.5284145	1.5942775	-0.8737456	2.4556084	-0.7307992	0.8554476	-1.2329581	-1.5701176	0.4144405	-1.8017671	-1.6713717	-2.2863119	1.5112021	-0.13158746	0.59425706	-0.64913183	-0.46035522	-1.0948876	-1.195175	-0.007973527	-1.3589791	-1.4168129	2.0383866	-0.78587943	-0.33599436	-3.2885602	-2.6160023	0.20675965	0.8996057	-0.299449	2.2101307	1.3456161	-2.585371	-0.6077709	2.1805332	1.7006688	0.9852412	1.785873	0.2200088\n2.8440974	-1.2799425	-0.099255174	0.8634724	-0.9001595	0.7229588	-0.78700405	1.592699	-0.9160883	2.0315266	2.89184	0.19854586	-0.6493046	1.8756205	0.42238882	-2.5192082	-0.11421737	-2.2420065	0.16903797	1.5058768	-1.3794802	-1.7687937	1.9559686	-0.53580946	-0.19213459	-1.8577989	-1.460373	-0.39527902	1.1828637	-0.6506314	-2.560286	-2.701731	0.84399676	0.5185007	-0.73609006	-0.4918211	1.7149429	-0.94963634	3.5751503	1.3039623	-0.68985856	2.747054	1.2027587	-0.68107384	-1.6718435	-0.25765133	1.3446727	1.7337964	1.9062061	2.8540773	-0.015931385	0.3812026	-0.32613954	-0.19512188	-1.6370809	-2.851907	0.951669	-0.54084015	0.34890813	0.3991165	-2.1121562	1.7921821	0.46370003	-0.34658045\n0.10564544	1.9862205	-0.122542694	-2.376162	-0.8037584	-1.299482	0.49775997	0.51581854	-2.1960552	-0.90819937	0.89720845	0.5834737	-0.72278327	0.9585982	-0.08032586	-0.6098536	-0.060437337	0.41080403	-0.8903723	0.58043426	-0.87107515	-2.6127784	-1.2496549	1.9153727	0.2699778	-0.9618577	-0.38858935	-0.40682444	-1.7818714	1.0169523	-1.6212769	-0.59851795	0.14618067	-0.49823382	1.6994613	-0.079599984	-2.429914	0.34343085	-0.8131165	-0.6712107	-1.3953456	-0.83998764	-0.51843005	0.9938569	0.1298079	-1.3577358	-3.1112337	-0.3380979	-0.06693828	-1.4431295	0.9437063	-1.5871075	-1.4259517	1.9646704	-0.1680676	-1.6497697	1.5057223	-2.0579376	-1.6280247	0.6466646	1.7219543	0.04492569	-0.7811479	-2.5690734\n-1.747968	1.8062836	1.3205423	2.7524467	-0.17989421	0.5703795	0.3358931	0.0056564827	2.299241	-0.26242504	-1.4553668	0.45230475	1.0235051	1.5547003	1.5574636	-1.85331	2.2809188	-4.1408544	-0.6182462	1.2089055	-1.5167676	1.3494586	-1.5450997	1.0596547	-0.55037904	2.402777	0.49162742	-0.59296346	1.1208919	-0.9824522	-1.7920082	-0.6491578	-0.70518464	-1.8786149	1.4159945	0.20093963	0.009830289	-1.2345815	-0.940756	3.0093012	-1.0522467	1.9062941	-1.4316372	0.43839365	-2.6346507	3.16224	0.040879812	-0.2855344	-2.5786839	-0.5481381	-0.18289015	-1.3841949	0.75358653	-0.5109004	1.3317132	-1.3425539	1.4701555	-3.3786535	0.452166	3.368736	-2.0917327	-3.1152399	0.316611	-1.913096\n-1.5196826	0.63411564	-0.24021745	-0.80284595	-2.391361	0.5417919	1.0140628	-1.7640574	2.1935234	-2.9037607	2.4039505	0.45525303	0.41627586	1.1743461	0.86801684	1.9807801	-2.7688363	-1.2613384	-0.5843832	0.7247987	-0.41807085	-0.14219107	-0.028114438	0.9459502	0.31368187	0.49498177	0.8794121	0.017512744	0.47526732	-1.1775702	-1.2105476	1.0809443	0.691703	1.0056207	-1.40799	1.2099606	1.3981383	-1.267472	-1.0683684	0.26627117	-0.5625655	-1.6876179	-0.46219304	-1.653106	2.0787103	-0.103655346	0.17749971	-1.7986673	2.8628297	-0.6268406	-1.6473961	-0.6439809	1.3427817	0.067164004	0.68707705	-0.1664176	1.9284716	1.4722593	-0.43360582	1.7733301	0.76320255	3.103877	0.098758996	1.5419792\n0.9470561	-0.8245663	-1.0304804	-0.6220833	0.44929096	-0.79163617	-0.61743826	0.7584579	1.1591686	-0.5510904	0.37479156	-0.28356603	-0.91870743	1.0334265	-2.7466857	1.8160311	1.6081458	-1.3978326	1.7491852	-0.75587237	-0.41679898	-0.47469682	-3.7879663	-0.59793794	0.02841681	1.3281653	-0.09092773	0.34038275	1.9692011	3.5129766	0.019000273	-0.52130306	1.455402	-0.04979341	-1.0147659	-0.8045316	3.2213576	-0.92099124	0.044852275	-0.010726215	-0.26588124	1.5772371	-0.6870302	-2.8263369	-2.567363	-1.5491604	-0.4382004	1.6939015	-1.3136348	-2.565379	-0.21492766	-1.4971293	0.053109072	1.3272808	-1.2637384	-1.1293378	0.11732417	-1.0815859	1.0276293	-0.11393107	-1.3765825	-1.1920816	-1.3704045	2.7743301\n-0.023802888	-0.5437148	1.0101041	0.4434246	1.2227978	-0.7173852	-0.062176045	-1.1321642	1.7930727	-0.38741478	-0.38484508	-0.93719774	1.1158217	2.341208	0.66104925	2.1286488	-0.12500891	-0.04332015	0.39136752	0.57457083	0.22527422	-0.7890079	1.3222045	-0.70743716	2.8466039	2.5844464	-1.7001935	0.9464597	1.1076475	0.622067	-0.5350396	0.9155448	-0.48870367	-1.4796658	2.5200334	-0.69101095	-3.156328	-1.5806469	-0.36237323	0.19428699	0.11489521	-0.5963351	0.25523728	-2.2122755	2.724067	0.8607402	-0.1044941	-1.1713002	-0.4695246	1.4623897	1.0328908	-1.8656373	-0.25230423	-2.7292001	1.1708741	-2.4885664	1.510429	0.6231779	0.47610965	1.6597047	-1.1653883	3.2578087	0.18207884	1.5133618\n2.5477955	2.0991051	-2.2834885	-0.3992812	-2.360153	-0.3091994	0.05637214	0.89629817	3.7180865	0.8278057	-1.0212883	1.3476607	0.12671462	-2.1738083	-0.1582048	-0.9250361	3.0386643	-1.3979875	-1.377338	0.98922694	1.422147	-0.37294906	1.3408436	1.0966258	2.2234604	2.0666654	1.4101295	-1.9938046	-1.6284705	0.65970266	2.0842981	-0.13970125	-1.0171567	0.5400628	1.3478773	2.0770526	-1.1656667	2.2731287	-1.1731204	0.300019	-0.52126044	-0.57040477	-0.17675072	-2.089228	-2.0008104	1.9710575	-4.143067	-0.33598202	-2.0699642	0.10084271	1.411713	-0.774075	-0.41961634	1.1987462	-1.2993304	-0.3399169	1.5622733	0.63128275	0.88709724	-1.4896603	-0.29215768	3.2717323	-0.6819231	-2.1802502\n-1.1513164	1.2416221	-1.0744213	-1.0870018	-0.11717969	-0.6789743	-3.6001952	-0.08345503	0.46709204	1.2046063	-1.503009	-3.3838625	-0.35030007	-1.7346745	-0.9807683	3.143754	-1.109531	1.2706861	1.3258369	3.8785007	-1.2242403	-0.18616666	2.7537496	-1.8302232	-1.9045504	-1.783548	1.5170261	1.3643515	0.7018421	-0.7855236	-1.2528825	-1.251877	2.5489326	-1.6545025	-1.5152444	-2.499311	0.6306972	-0.302649	0.5764297	1.8627843	0.45406535	-2.5867305	-0.65085554	4.134089	1.8713875	-1.0359659	1.6335117	-2.2495852	1.0007077	1.9177336	1.9747199	1.2249156	-1.0216131	0.7535282	-1.3021016	2.5795746	0.44302675	-2.4456413	-1.3238466	-2.046852	0.052696135	1.9211329	3.1252165	-0.01390036\n2.0785906	1.0863314	1.0376792	0.87940776	-0.15120219	2.5868244	0.32163125	1.049976	-0.10055941	0.620701	1.4028685	1.8337775	-2.1412978	-1.2769771	2.114643	-1.7388699	0.4442806	3.5971608	0.7006767	-1.5908971	0.6115338	-0.35216773	-0.8813106	-1.1701529	0.4769454	1.9248122	-4.1239953	2.1938467	-0.673463	1.884529	-3.8194065	0.45852742	1.7780991	0.4610544	1.6594081	-1.2280202	0.5187301	0.02831629	-3.5152974	0.6450563	0.7223453	0.19572066	2.1979415	-0.30473408	0.6367266	-1.5243565	-1.0985656	1.1584078	-1.3688079	2.2394629	0.7235868	-0.8785174	0.34923717	-2.945667	0.37106302	1.4980779	-0.94171876	-0.8810201	-0.63976586	-0.6057163	1.3995715	-3.7879815	1.452058	-0.1907798\n-1.9160951	-0.8787702	1.9760925	2.1572497	-0.5457955	-3.4136832	-2.1601026	-0.21597959	-0.47529352	-0.48096538	0.89973176	2.6782534	-1.8604083	1.2045553	-0.42492926	1.0184386	1.127811	0.006985097	1.749209	0.3325286	-1.1738611	1.5141205	-0.8330721	-3.7423236	2.624289	-0.27488706	-0.10982745	-0.19594662	0.5503723	1.8645902	-0.6027018	-1.4242401	-0.23768578	1.2354717	2.6441934	1.2049859	1.4051743	-2.3440154	1.0470244	1.6209692	0.94085276	-0.97083557	0.3872103	0.5962711	1.0197216	1.1853844	-3.4454863	-0.68614686	-0.22818394	-1.0593293	0.8544622	0.06400218	-1.6813997	-1.9114649	-0.46736562	-1.2796242	-0.0027110546	0.15617889	1.4054363	0.06831579	1.2310554	2.094985	-1.1850954	1.002041\n-0.31431425	-2.7770405	-1.302186	-0.16307405	-0.7505158	0.67215395	0.6746627	-2.1224937	-0.20925497	-2.8897302	0.07822779	-1.132976	-0.48307735	-3.242488	1.0769937	1.0121336	0.19058582	-1.3829142	-1.7877694	-0.7961635	3.2694976	-1.8683925	-1.4054196	-1.7261164	3.9293752	-0.99038893	1.7389715	1.1099714	1.9174082	-0.017689846	1.1866329	0.8134426	-0.50556976	0.26019508	3.1759627	1.0871251	1.9693863	1.5320569	1.0780367	1.4636483	2.6068873	2.0275998	0.56998307	-0.18250194	-2.2311358	-2.22415	1.3504531	1.182433	-0.054738175	1.1727881	2.8315425	2.6486568	-1.4720125	0.17603768	-0.3502097	2.4121776	-0.56008357	0.44760266	1.032753	0.6732431	-0.60607123	-0.70379627	1.479636	1.2632004\n-0.6564379	1.3669882	-1.4628065	1.9210031	1.9361076	-1.9257424	-1.5555573	0.84882826	2.4642196	-1.320844	0.4499989	-0.36892775	-1.8392615	-0.63432944	-0.755678	-1.187447	-0.052253142	-2.4488	-0.13336179	1.2118793	-0.7700769	-1.3154056	0.16748372	0.00078652805	-0.9550372	0.6497341	-0.3351945	0.9472939	-1.5589032	1.2978504	-0.95168793	0.8977523	-2.8162804	0.9785141	0.164748	-0.9799157	-0.060072232	3.7868497	-1.528191	1.7464077	-0.49354467	-0.67318386	-0.9049727	-0.8984499	2.3376145	-0.98148656	-2.5271022	-0.35077313	-0.25090626	1.4014502	-0.69298023	-2.2603257	0.35449478	-1.3106452	-1.1561077	-1.9220923	-1.556402	-1.0192791	1.3492162	-0.12694734	-1.2548664	-1.0958965	-1.9066603	0.33597535\n-0.98667556	-1.5898087	-1.1028672	1.6167955	0.05648242	1.414647	-0.7437858	-0.3588223	0.8783874	-1.3057141	0.24097297	-1.2621412	-1.1154641	0.2468042	-1.1966145	1.151144	1.0155021	-1.8736179	-1.5720096	1.1622286	0.7538333	0.78063685	-1.1799395	0.47129002	-1.6725183	1.0268115	0.79600054	-0.8645788	-0.6041297	1.5679449	1.1293364	-0.64297515	2.32535	-0.88456005	-1.0974251	1.26736	-0.15654825	-0.050886337	-0.7427525	-3.056296	-1.065137	-0.5511246	1.2998819	-0.92305243	1.0652523	2.0235581	1.6544288	-0.6004856	1.0299177	1.4044256	1.0149316	-2.0204453	1.6028651	-1.174002	0.87623775	0.1541018	-1.1912171	1.0914308	-1.5042772	-1.7795331	-0.49484745	0.9813497	-0.18328568	3.7778583\n2.9657946	2.4584262	1.6521987	-0.78408045	-0.72088325	-0.056391925	-0.88847685	-0.4767063	1.0618653	0.20307797	0.8529424	0.77025163	1.2492597	0.68897897	1.7433114	-1.7767276	0.25801626	-1.7110819	-0.2352195	-1.0734711	0.9454305	1.4970862	-0.20765536	0.43966463	0.06429307	0.62987703	-2.3142698	0.99704707	2.0868146	-1.8502575	0.781308	2.2186677	0.46566656	-3.6816196	1.4029483	-0.040463496	-1.4924141	-0.5542412	-0.3279799	1.153073	0.3773385	-1.3692857	-2.0506854	-3.618004	1.9655341	-0.42375812	-0.536351	-1.243123	-0.61714864	-0.833418	3.167456	3.2529204	1.3965385	2.0025082	1.7780049	2.1289961	0.44163373	-0.9161381	0.18437713	1.9341338	0.90001297	-0.3258436	-1.6831096	-0.7118761\n0.7335907	0.6838918	-1.5690618	-0.5610184	0.57765913	1.3493264	-0.8167813	3.5077062	-1.806492	1.2015117	0.63925344	-0.4243588	-0.50860435	-0.74250305	-2.3567193	0.69257224	-0.23059358	0.58640796	-1.6152503	-1.497643	-0.4079037	-0.42806754	-2.2337239	-1.0771265	-0.43383443	-0.6831217	0.72200173	-1.567005	0.7705235	0.15797918	-0.67486393	0.46385053	1.3388542	-0.15030077	-1.2337674	0.0022082464	-1.2593399	-0.26227674	0.28245795	0.7805301	-0.8322929	-3.2901685	-0.8554785	-0.45038727	1.134648	1.0398784	-2.3062572	-1.7089614	0.33660746	0.85798407	-0.66385496	0.7471249	-0.9609182	0.4293899	2.6794906	-0.76789457	-1.4682969	0.29398283	1.0206968	-2.7832582	-1.2198445	1.6922647	-1.0930041	3.0459504\n-0.30272287	-0.84873927	-1.0435523	-1.1909325	3.4645505	-0.25200167	-1.4932133	0.9573442	3.5696282	0.79513824	0.47435224	-0.24945474	-0.6856532	1.2713273	-1.5199165	1.1109707	-1.5141209	-0.4871536	1.0380161	-1.0854037	0.51254463	-0.7481908	0.34656557	0.48135436	0.58862126	0.13415258	-0.85387665	-1.1872498	-0.7079529	-2.6308918	0.38291806	0.59993356	1.6172574	0.14363746	-0.50804913	0.04547439	-0.41102502	1.5544475	-0.81972533	-1.4848403	0.17632657	-1.0976855	0.64795506	0.81771517	-2.069207	1.9325551	0.58309346	-1.6433597	0.28344512	0.26549298	0.5849372	-3.022672	-0.34798113	2.549789	1.8832449	-2.1270616	-0.4245127	-0.8168615	-1.1143441	0.50951797	-1.1276041	1.3539789	-1.6323209	0.15793243\n-1.1402225	-0.16939676	-1.4041818	-0.6020703	1.2178053	1.9297211	1.4318814	-0.7118745	-0.44827962	-0.8070255	-1.8973926	0.41641262	-1.7158833	2.938429	-1.1740693	1.6635604	-1.0930673	-0.8937363	-0.8648917	-2.2930813	-1.0673156	-0.15678655	-1.7401713	1.8925288	0.8239335	2.803542	-3.2653165	0.08521682	-1.4707977	1.2103574	1.8382211	0.17001422	1.9907361	-1.9633485	-0.0066766613	-0.08288925	1.364657	-0.21558118	0.20435399	0.7269629	-0.72000194	1.0148689	-2.7198608	1.9459321	1.5260563	-0.23063731	0.4691142	1.1582026	-2.1886194	1.9263312	1.6228439	-0.868296	0.17522572	1.348052	-0.97230405	2.267746	-2.2753382	0.7278978	3.5439587	-0.22732952	0.76048404	2.2427564	-0.81003857	-0.6395284\n2.0251265	1.5367515	1.8965394	1.0777706	-2.3977332	2.0103688	-0.17565735	0.6642573	2.0969858	-0.7311725	-0.108229846	0.15008444	0.3169109	-0.5476015	-1.1392361	-1.3464015	-1.052978	-0.79851454	1.0280687	0.46005848	-3.384368	4.292838	-0.6287484	0.33338693	-0.7336549	0.7041062	0.851799	-0.91932625	2.4645672	1.2418259	1.6556232	-1.0421839	0.67485374	1.9874483	2.7440953	0.55522037	1.3717697	0.9716764	2.9536738	-1.0555978	-0.33822414	-0.17464082	-0.510869	0.4357662	-0.08167539	1.9009078	-1.1782438	-1.5417821	-1.3294973	-0.22577739	0.66458696	-0.51351404	1.7593008	2.0829172	-0.7339504	0.6527648	1.7423809	0.44124416	-0.24640691	2.7561612	0.27032143	1.2432687	-0.89009273	2.0255108\n-0.13294756	-0.6443831	-0.41914603	-2.0773544	-3.8630424	3.2069116	0.0031561027	0.3578217	-0.8478356	0.13463794	0.48407003	1.1708474	-2.4040806	0.12696223	-1.2923677	1.650637	1.8698096	-0.7990658	0.61620027	0.20209552	-0.14551023	1.3933798	-0.712025	-0.8708496	-0.06046834	-0.26490402	0.5048536	0.47457495	2.1334908	-0.06748741	-1.0908493	-2.0528023	-2.0163522	0.095000125	0.2477918	1.0820699	-1.3615245	0.09607579	-1.4985052	0.14109491	1.1848724	0.25854668	0.017273325	2.0840063	0.5158822	-0.62773496	-1.4613909	-1.364462	-0.7802715	1.1530013	-0.53703344	-1.4728918	-0.7665502	1.2908652	-0.0054664155	-0.1585017	-0.22001158	1.7788804	-1.7137182	0.98295975	-0.35543647	0.5055148	-0.23800941	1.8332564\n-0.038013835	1.623813	-1.7732722	-0.8337976	0.4976943	-0.085708596	1.2099348	0.47302508	-2.0478678	0.4928654	-2.4276016	-3.342406	-1.6541107	-0.20887373	2.1709342	-0.314166	0.36418495	-0.046906002	-0.14233671	-0.2920893	0.21307176	0.51195824	-0.6232457	-0.9047292	-0.2876889	-2.7058842	-0.48388943	1.152938	-0.091258444	-1.4701847	-0.058190387	0.22471304	0.15979078	0.7956579	2.808584	2.5608141	1.0622003	1.1806412	-0.24010357	2.4275973	-2.5687478	0.11395228	-1.0761642	2.6216378	-0.072927594	-0.75511754	-0.10334179	1.7771922	0.33810395	0.44990623	2.0953853	1.7168422	-2.239602	0.24012241	1.4638284	0.44198048	1.8017185	-3.2437246	0.95111114	-1.1444309	1.3692816	-0.6422159	-1.9622033	-0.73797387\n-0.6429223	-0.5285162	0.34279728	0.12458195	-2.6158755	-1.3106992	-0.17500122	-0.38421112	2.8810258	0.3191667	1.2911155	-0.23608677	1.7570448	-0.8251174	-2.65252	0.4193029	-1.760728	-0.55334175	-0.82176757	2.206735	1.5882026	0.9932249	0.5764748	-0.06919187	1.4597155	-1.2907288	1.2977039	2.2397606	0.6719593	3.9893324	-1.6592758	0.9844836	-0.58002335	0.34080824	-1.2766473	-0.46702942	-1.8024162	3.1059024	-0.009421444	-0.9702733	0.20931853	-2.1803508	-0.20930226	0.52731115	1.1632864	-0.902976	-0.49103686	0.32445338	-2.3550606	1.4162652	1.9449238	0.1251907	-2.3813884	-2.3942428	1.6818742	-0.80413747	-2.916762	-1.9120255	0.74668145	-3.9956012	-0.945135	1.8522674	1.8738773	0.8488531\n-0.39902058	-0.0648424	1.3011982	-2.420431	-0.28210977	0.48647597	0.6604654	2.4525213	-1.3702626	1.6737278	1.0426499	0.32599783	0.8957254	-1.251478	1.4892297	-0.25031254	0.6752637	0.30356753	0.6632801	-0.3252502	2.1637006	2.3610458	-0.47211263	1.4704905	0.7219262	0.2961735	-1.1371098	0.68963474	-1.2049391	2.481231	-1.606803	-0.27460185	-3.8477569	1.470436	-2.0844045	2.874057	0.5942592	1.406679	0.29773748	1.9126067	-0.92038417	0.6498544	-0.25259078	-2.1466913	0.74151945	0.5250472	-2.9560354	0.68591356	-2.0765753	0.6592666	0.38348472	-2.6498728	0.037685227	-0.21931349	1.5930017	-1.7758838	-3.8789184	1.7581518	-0.5903409	2.1282592	3.1852736	1.2721449	-0.12182117	-1.942219\n0.508264	0.2788928	-2.1614423	0.43735504	1.7352648	2.0239553	0.5598569	-1.1008247	2.4503882	-0.07487924	-1.3128207	0.3985934	2.1811407	1.9168915	-2.1274707	-1.5752696	-0.65179133	0.1016017	2.136702	-1.0568568	1.1779294	0.92860055	-0.12412445	-1.6775651	1.7047005	-0.047256574	-2.8388622	-2.1576557	-0.04009403	-1.1574423	1.9544643	0.08365181	-1.2859149	-1.2736858	1.5345273	0.35993063	0.60613286	0.033394746	2.0042531	-0.7112121	-1.3868345	0.1656583	1.267028	1.8818384	-1.2568569	0.6434542	-1.4125046	-0.53484344	-0.4102635	-1.3678534	1.7219181	-1.7905314	0.78525376	0.6157329	-0.97927845	0.021416288	-2.0266485	-1.9705724	-0.50470823	1.1007422	-2.168975	-1.1727123	-2.1323488	-0.09259583\n1.0284866	2.3550496	-0.41631946	1.3153143	-0.3653493	-0.25465608	3.74281	0.6439203	0.18078035	2.0387964	-0.7217349	-1.0169392	-0.68937975	1.4627587	0.85774654	0.027045311	-0.39470324	-0.83999836	-0.1783239	1.8149085	-0.5743581	-0.022299264	0.13833448	0.8488853	-1.2240145	1.411457	-1.0502067	0.03251507	-0.7005494	-0.1388326	0.9087546	-0.712085	0.5445911	-1.2895706	1.330909	0.70751256	1.1818068	0.8481856	-0.1664143	0.59690905	2.318043	0.98654604	-0.059487857	-0.85004073	-0.6670469	-0.5633241	0.8789818	-0.27075362	4.554715	1.0099103	-0.9083034	0.37144026	1.929556	-1.0008883	-0.30381545	-0.22437727	-0.9187839	-2.919785	-3.7700408	1.6686419	1.4913723	1.4988543	1.2485318	1.0183167\n-1.4848351	-1.8755625	0.30335814	0.07908418	0.8055904	-0.9704422	-0.9344323	-1.6470237	1.3199148	-1.3688285	1.6431228	0.6564649	0.9300032	-1.5830916	-1.8860593	-1.2793007	-3.893489	-0.537136	-0.5565213	0.639526	-0.68167156	-1.3870384	-0.104615875	-0.41785127	-0.8439769	1.810855	0.21067986	1.4174868	-4.08231	1.7721022	-0.18040793	-0.067313716	1.0689992	1.0228056	0.92982346	-1.2790803	1.3531406	-0.9779068	1.6639543	2.154206	1.2949501	0.66367686	1.8655838	-1.402393	1.2588438	-0.050286017	0.7724401	-1.8339565	1.5355909	1.9670831	1.3643054	-1.718693	-0.8188076	-0.91942906	1.004753	-1.5611312	-0.20120803	-0.71104616	0.28915852	2.4870768	0.0540354	0.11615108	0.8759367	-0.5494679\n-1.8324338	0.120907396	-0.21856016	-3.1692822	1.1222107	1.9560695	-0.7293852	-0.49694696	1.5241479	1.357926	-0.8617381	-1.2870511	-1.4754313	0.46808222	0.507328	3.0911758	2.495784	-1.525013	2.3011346	0.39665645	-1.2343522	0.6132162	1.337372	-0.67882437	1.6577628	1.6559132	-0.09842592	-3.0932984	-0.8726023	-2.1184373	-0.69243854	2.0877814	-1.6682236	0.8134586	-0.36228225	-3.8331895	0.3608659	0.33790168	0.8401351	-1.2151322	-1.3639195	0.734116	-2.5804703	0.10607865	-0.07856446	0.014433408	-0.61924386	0.6767402	-2.3147714	1.3004664	0.5830856	-2.9433918	1.0991645	0.8958536	-0.16215132	1.3708793	-3.0427043	-1.2680308	-0.0077611804	-1.1845587	0.7484203	0.4958912	-0.46458828	0.82910085\n0.07331445	-0.4093247	0.20481265	1.9999912	-1.2242815	-1.277924	-1.487122	-2.4793332	-0.92698663	0.71875954	-2.1076176	-0.6104643	-0.5858274	0.66887474	-2.1322272	2.3851407	0.9362006	2.89864	1.0190991	-0.90674907	-0.47224617	0.28008863	-1.9376559	-0.71467125	-2.5997424	1.678257	1.6125937	-1.6103084	-1.1965276	-2.615179	0.4967659	-0.97848284	-0.25044465	0.3153458	-1.5491674	-0.5678497	1.5459639	1.8799018	3.7010486	1.2257363	-0.8655806	-0.47584537	-0.7593958	0.75157845	3.3065748	0.45439908	0.61238885	-1.0885665	1.7404313	1.3097085	-1.5120744	-0.4873319	0.66444343	-2.2500136	1.2807832	1.2911783	-2.489148	0.09191238	-3.0641954	-0.24015804	0.4687499	-2.4990864	2.5793526	0.75383717\n0.31470248	-0.17535605	-2.2684147	2.5536938	1.4251323	-2.092566	-0.06915102	1.2497925	-0.043763578	-0.47352442	-3.1998017	-1.3073447	2.029657	-0.20884307	0.38862815	-1.8578755	-2.5351524	1.0905817	-0.26478237	-0.9708736	0.56572884	-0.8706061	-1.2695097	0.95484143	-1.7378151	-1.4227095	0.75946724	0.92957765	-2.6196053	3.4124503	3.38713	-1.7183653	-1.3958732	1.0222079	1.6168984	-0.09608225	-2.1029003	2.4350429	-0.051935844	-0.23622087	1.62612	0.7363961	-1.07374	-1.9220989	-0.9810947	-1.6491746	-0.51403624	-0.012631014	-0.9992553	-1.2760723	-0.88579226	-0.725369	-1.8083397	0.7793508	0.6158972	-1.8338943	-1.5191393	0.04827138	-2.1434128	-0.07854193	-0.5329204	1.6352642	0.74281096	2.8054261\n-0.007832292	1.0275147	-1.3310688	0.8420999	3.0141704	-1.519222	0.5818986	-1.2165105	2.845166	1.2556218	-2.8286173	0.22689472	0.42683402	-0.1962696	0.07550898	2.9307048	0.7501409	-1.8589071	3.4080508	-0.38093993	0.053362247	-0.20203619	-0.5036106	-1.1493458	-2.605809	-1.1880527	0.8435092	-0.44877434	0.2867234	-2.581683	-1.137277	1.2660145	-1.9420136	-0.1701347	-0.63579476	0.59747505	1.8303559	-0.39731792	1.234536	0.19302861	-0.6385997	-2.3413968	0.93455034	1.5599397	0.323509	-0.43250272	0.9846642	1.467076	1.0992969	-0.13258189	1.418073	1.8897442	0.5358922	0.3087467	-1.997549	-1.9093382	1.3990908	1.2830876	1.5316685	1.451803	1.2969983	-0.4208052	1.0696541	0.03548495\n0.22782895	1.6616764	1.4142302	-3.2762213	-0.106704004	-0.67356247	1.1928371	1.0791961	-1.4801155	0.31665516	-0.29331848	0.24488856	-1.2402576	-1.9485018	0.46307155	0.37835103	0.09612438	-1.1697516	0.7467211	-1.7346735	0.15430711	2.3544438	-1.7211254	-0.82752824	2.4319882	-0.5805866	1.2839198	0.7900505	1.8518707	-2.1199985	-0.809459	-0.9120621	0.4212406	1.1048089	0.32831752	1.3282557	-0.8163555	-1.0341355	1.0547211	-0.34327173	0.13848913	0.8389817	1.4633911	1.6714047	-0.6251016	-0.6290741	0.010992403	2.3811285	0.39741656	0.26929247	1.6626887	-1.4053354	1.5876441	-0.27295712	-1.5963601	0.12702703	0.32264432	1.477637	-0.57458454	-0.63078034	-0.34529647	0.54044837	0.32815665	0.42945805\n-0.5146505	0.5700876	2.0818195	1.8928119	-2.4543629	-0.3130921	-0.45782408	-0.84020585	-0.7907461	-1.5301554	1.2700758	-4.7915154	0.8089611	2.0697398	0.0009268281	2.1404905	2.9980447	-1.378962	1.9134557	0.58593816	-0.7286418	0.100136735	1.267838	0.32867333	-1.4674699	0.47977993	1.0224407	1.9619943	-1.0222529	0.25612783	1.6650076	-0.30919594	1.7341225	1.3231939	2.5325384	1.0779407	0.9629947	0.4996515	-1.3646139	0.33554322	1.968637	0.2913282	-1.8652402	1.1004199	0.027926872	4.0861816	-1.2888321	-2.358224	-0.022308026	1.0038095	3.0710604	-0.03557658	-1.5885695	-1.4270037	2.3963535	-0.78951687	4.198384	-1.466028	-0.59559953	-1.1527516	0.44315678	-2.768505	3.0036337	0.3938103\n-1.5526958	0.22457257	2.4032245	0.31624332	-0.97350997	1.9150195	-1.7911264	-3.301101	-0.7520866	-0.50656974	0.62424743	-2.3425007	-0.9401826	-0.5597023	-0.3810418	0.35795018	-1.0394844	-0.53118134	2.0818634	-2.7869065	-1.4021548	-1.1056049	-1.3523935	-0.7168483	2.9823713	-0.5255311	-0.0171064	-0.6927079	-0.41041636	-1.2456002	1.1040872	1.911638	-0.48138833	-0.28059968	2.976836	0.36831903	1.3330507	-0.7030101	-1.7995373	0.16748159	-1.0414332	-0.53130555	0.49174285	0.59055686	-1.7324421	0.647584	1.765787	2.1331244	0.9619143	1.2068655	1.6998876	0.29966602	0.8944376	-0.16999687	0.47112337	0.52215695	0.941238	0.3012355	-1.0278319	-0.1675744	0.60505736	-0.7880466	0.7158453	2.463621\n-0.17251535	-0.82072073	-2.1328857	1.1162535	2.6156213	-0.7163562	-3.4288964	0.62607056	2.5519536	2.3865268	0.39794326	-0.32794052	0.40474415	2.2414262	1.1463939	-2.5710633	0.41542563	-0.21902177	-1.5302595	-1.2525207	-0.25225252	0.5461529	-1.116893	1.3438216	2.0403152	-0.26616693	-0.17989422	-0.14423656	-1.1124228	1.1428252	1.4634335	-3.4474673	0.61736053	3.2655804	-0.5726246	0.9279884	-0.6473978	-0.99447346	1.0390704	1.004068	1.1525245	0.39852387	-0.7096464	-0.7022688	1.2585334	-1.4832244	0.42726412	-0.5368103	-3.5316548	-0.84440285	1.4786509	-0.7133414	0.6407175	-0.58178663	0.53595144	0.29767603	2.0356102	-0.9807893	-1.2411197	0.24955253	-0.22254418	0.06645154	0.097542904	1.8832271\n0.49547338	-1.5975046	2.6555037	-0.5015503	0.16422258	-0.3913712	-2.0627048	1.1962734	2.3076684	0.594141	-0.7413931	-0.27190685	-0.6718497	-0.026480405	-0.7132209	-1.2068108	-0.245505	0.029754316	0.4361499	2.5752358	-1.2616227	2.928333	1.348913	-0.7766182	0.09457911	-2.7137673	-0.8072999	-2.3213344	0.5782194	0.21977884	0.37577018	-0.018636066	2.2084873	1.4716297	-1.2007715	-1.6407237	-1.0755045	1.5995753	1.4161313	-1.4290203	-2.4662006	-0.49875236	0.4392415	-2.8756995	-1.2418225	0.20138066	-0.055677965	-0.32180017	1.4704823	0.73387915	-0.16350111	-1.2911454	-0.93141216	1.8136692	-1.4912834	-0.26221833	-3.6077175	-1.0398959	0.70318973	-0.45893326	1.9549758	1.0627977	-1.8252689	-0.32930702\n0.99481165	-0.820714	-2.255967	-1.3093722	-0.2735598	0.17538288	0.7781858	-0.20323195	1.4929048	0.63089013	0.9041907	-1.066589	1.309545	2.3512852	-3.5137422	1.3313904	-0.81435823	-2.709824	2.1350393	-0.02907616	-0.27763656	-0.4875921	-2.5375798	0.6800446	-0.45502666	0.2703256	-2.6931832	2.1101556	3.486343	4.4941087	1.4098457	-0.0798926	0.06384799	-1.6861115	-0.14251718	-0.5126874	0.79523903	1.4174782	2.2273638	-1.6302617	0.39793977	-1.5482692	0.40555954	-0.8786007	-0.18601684	-0.13105105	0.23550278	-0.3049975	-0.098855086	1.4636271	-0.277853	0.360657	-0.19670089	0.8912192	-1.7033974	0.1587773	-0.9199999	1.9629531	-1.6988683	1.703966	-0.83428776	0.4521616	-1.4280424	-1.6280655\n0.7402938	-1.375691	-2.8863394	1.0543246	1.8796654	-0.68372047	0.48676357	-0.5419777	-2.8329008	-1.4884851	0.8730906	0.5080255	-1.7707233	-1.0786668	0.43590936	-0.026894439	-0.43659464	-0.0045205234	-0.8634023	1.5079794	0.45366332	1.1639606	-0.4241674	-0.07061799	-1.7093502	-1.1506776	-0.47001407	-0.121191226	0.95346373	-1.2948316	-1.2468557	-1.7457997	1.2522818	0.6548618	-0.3826576	2.0774283	1.8972728	0.5306363	0.8936968	2.8877566	-0.71122235	1.9773408	0.4369694	-0.37008548	1.4982222	0.034237877	-0.23384476	-0.47204438	0.8197362	0.15330626	-0.27977705	1.1278596	-0.57994294	1.2362542	-1.1207271	2.6648092	3.3701015	-3.1938598	-1.2222099	-1.525838	-1.0887514	-0.33941507	0.07152065	-3.8952243\n1.4344538	0.6742872	0.14558046	1.2106988	3.080754	-0.45700204	3.117608	1.7096975	-0.239431	-0.3892323	-1.0237396	1.2798299	2.38693	3.2016616	0.8969246	1.1576445	0.16328248	0.117538646	1.1889176	-1.1161553	1.6249623	-0.7337436	-2.3132107	0.07031013	-0.7231807	1.1372441	0.8533261	-2.4339569	-1.6922147	-0.026628342	0.42748347	2.5447032	-1.5194162	0.9089341	0.26871648	-0.9683132	-2.5893037	-0.3637568	1.956084	0.3124517	1.3891628	1.859294	0.5127415	2.0958729	0.23944633	-2.2833345	1.7116692	0.3768003	-0.5632677	0.6688496	-1.4735188	-1.109403	-2.1887379	3.135993	1.5173072	-0.9646503	1.3481929	2.8930929	0.24352282	0.02900371	-0.587466	-0.8211453	-0.023341613	1.6127051\n1.8194828	-0.06809228	0.8319559	2.929714	-0.24857181	-1.489476	-0.68361264	0.9657813	-0.78755367	0.49174252	0.4752679	1.2111771	-1.3667269	-0.84737223	0.1718479	-0.19117184	2.6072845	-0.8883624	0.14789885	1.4567065	1.934036	3.7902691	0.7958602	-0.495096	0.76968414	-1.5007093	-0.25597176	-1.4002345	-0.14821973	0.723903	0.11182211	3.3858457	-0.6907885	-1.9073634	0.61586756	-1.073223	-0.67419094	-2.183827	-1.1045082	-1.0511804	1.8135405	1.3651493	0.9821039	-0.37826186	1.9057791	-1.592091	-0.059710495	2.0867603	1.5274314	-0.5139823	0.48653746	0.59420776	-1.9517077	-1.6749378	1.5686809	0.23148477	-0.2823907	-0.68111354	-0.5484561	-0.3046764	1.4354538	1.4233506	0.93921185	1.6839213\n0.3734135	-0.77340806	-2.1061852	0.102790415	-0.218909	1.0943018	-2.1712997	-0.5227048	-0.771123	2.4614823	-1.7870774	-0.5655809	-2.6278145	0.91571295	1.649182	0.29849863	-2.6531823	0.21861286	-0.32766753	0.6622221	-0.8026317	0.85637844	-1.3858086	-0.6540147	1.5585355	-0.08770427	-2.6010475	-0.43097186	-1.1231315	2.1359866	-1.1718966	-0.19376917	-0.51813114	0.5383086	1.7538868	3.3551207	2.4568896	1.0569603	0.06583197	-0.6629175	-0.17191216	0.25315252	-1.138133	1.9944037	-0.61043054	2.6511643	0.71447337	0.89861816	-0.29733527	-0.93101084	-1.3064119	-2.3550854	-1.0421766	-0.02702183	0.18878323	1.107133	0.8976136	0.4299188	-1.0480856	0.9282077	-1.2134131	2.7280385	1.1179082	-3.1466622\n-0.20788662	0.87140775	1.8504628	-0.26112798	0.70060706	-2.6301444	0.40781718	1.1146276	2.1757438	1.1357404	-0.8003366	-1.8421313	0.799573	-0.14860916	0.22737826	-0.94441503	0.82699025	-2.6954658	2.122497	-1.6292467	2.0883503	-0.31912258	2.3967648	1.6605417	-0.078688405	-1.062469	-1.4871175	-2.323854	0.9722847	-0.0030743657	2.9104524	-1.0256826	-1.2419915	-1.3118504	-1.2102354	1.3441323	1.4593945	0.54640913	-1.9951591	-0.56919456	0.8949477	-1.3479325	-2.9573793	-3.3919215	-0.11488667	-0.55680734	0.64913785	-0.022374634	-1.6871046	2.1350334	0.764158	2.3499455	1.5544932	-2.5998895	-0.1455826	0.56989104	-3.1651459	-0.43069842	-0.8253534	-5.4370775	-3.806137	0.5482376	0.71931416	-0.24297068\n-1.042715	1.0115923	-1.0980381	-2.318002	0.117022924	-0.7748761	-0.7708635	0.12296404	-0.6877266	-1.8829548	-0.95064044	0.6968416	-1.5095185	0.33639666	-0.43932992	-1.4387887	1.3181499	0.0523157	-3.8128414	0.8635088	0.9682707	-1.8431851	-1.9548763	0.81553674	0.49765733	0.4024196	1.2125367	-1.2934957	2.8539734	-0.840244	0.7925224	1.4930089	1.0313303	2.0550442	2.279813	-0.40965256	-2.685012	2.3433096	0.28639385	1.5689107	0.87537384	-0.6003138	0.8872679	-1.00408	0.579093	-1.657585	0.7324692	-0.4656487	-0.3263079	-0.21016316	-0.25544012	-1.367639	2.3218915	-0.7135228	-3.3082485	2.4619203	-2.8080716	-0.6700001	-2.1528907	1.511748	-0.24788892	-2.605277	-1.5158471	0.28170386\n0.48871562	-2.6558225	-1.0558826	2.3399615	-0.8998756	0.44112164	1.1232507	3.9576547	-0.37227142	-0.6509148	-4.696482	-0.51702577	-1.535358	-0.59558994	-0.3763526	-0.6745447	-2.848272	-1.2098396	0.9858725	-1.0424174	-0.5652131	-0.10649501	0.61866254	0.800419	2.2706106	0.07298142	1.7598987	0.24255703	1.1136296	-0.85858047	0.22924125	2.4410849	-0.044316296	0.008746012	-1.6566035	-0.15942861	-0.5713213	0.8234392	2.1025858	-0.095555924	-3.6126523	1.4275343	1.0976727	0.56988704	-3.1404595	1.2032601	-2.4070747	0.069829755	-1.4970498	2.3406277	-2.73098	0.7247944	-1.558979	0.07573662	-2.4690988	1.207558	0.19623844	-2.7119918	0.673568	-0.21694966	0.6403544	-0.37075594	-0.6782763	-1.6302501\n1.2679695	3.2807992	0.943119	-0.17455141	-0.73242414	-0.5614035	-1.5550481	1.0188818	2.787761	1.8458128	-0.2835064	-0.59634054	-2.211852	0.10386172	-0.9770956	-2.4697802	-1.50006	-0.53961134	0.09166536	-0.49179453	1.5740653	-0.64924574	0.58136773	1.9572159	0.7375338	-3.4546125	-1.1816157	-1.8590726	0.16180572	-0.1339894	0.55003893	-1.7338974	-0.26900166	-0.6241413	0.98040986	0.31333932	-1.0240856	1.4801468	-1.6617953	1.8180351	-0.3263086	-1.0994185	0.44279304	-0.09216838	0.84878653	0.021167198	2.1677194	-1.2976265	2.9576495	0.19594823	2.2561915	-3.4792323	-0.7447883	1.7874582	0.7703921	-2.6178164	1.6779913	-0.33484077	1.1262357	-1.2869562	-0.82785356	3.0577648	1.599137	2.1596465\n-2.0870593	-0.7127286	1.3708966	1.4660274	0.22538932	-1.4685863	0.33952194	-1.9926891	0.31572816	-0.5236312	-0.4959204	-1.9773805	-1.0637864	1.9195111	-0.00026116232	-0.8449733	0.06817114	0.055263415	-2.231874	-0.18443839	0.85201144	1.7869269	-1.2763519	0.16665548	1.1605759	1.3872479	-0.11135552	0.36687848	-1.4566634	0.28783968	0.034237806	-1.5970742	-0.51426685	-1.5958737	1.613591	-2.2416365	-0.13167278	-0.4628319	-1.9680221	-0.38703895	-0.72345686	0.59065175	-0.586447	0.9137773	0.49871755	1.8584045	-1.0661432	-0.78699565	-0.8181257	-0.8717192	-0.069113426	2.3408768	-0.45848605	1.4738413	1.8562514	-3.3488548	-0.036057424	0.46782583	-1.2941794	1.771336	2.867626	1.5896201	0.10942101	0.3852597\n1.5488944	-1.0845716	-1.6823194	-0.2533484	0.014485746	-1.1701962	-0.2662227	1.3456124	-0.5300922	-1.7874335	-0.5711396	-1.4068829	-0.28045008	2.6379657	-1.2995981	-2.413461	-1.0340377	1.7101382	2.5559103	-0.7760803	-0.10092099	3.430138	0.9864122	-0.21412586	0.30429557	-1.0514263	0.06108304	1.2918487	0.7891052	0.40794298	0.10418701	1.1207328	0.57437015	-1.1325905	1.2670326	0.7597371	-1.3201084	1.0923933	-2.1478477	-1.1494066	0.5211062	0.3409756	-0.8878184	-0.13053249	0.37159583	0.7056462	0.6424295	-0.91384864	-0.43769044	0.97423744	0.60277	-3.9420538	-0.81234986	0.7236291	-0.58722216	0.35382813	-1.8629963	-0.41813087	-0.89026445	-1.2900966	-0.18685944	-0.25951207	-4.2062025	1.967122\n-0.14117353	-0.42505834	-1.1257268	-2.1344497	0.34746543	-1.2794626	-0.37488717	-1.2066329	0.5495434	0.28670505	-0.8484321	1.3651911	-0.829456	1.889566	-1.526962	-4.0433693	1.0291964	1.2075347	-0.42728266	-1.1513152	-1.3473407	0.50788426	1.4694825	-3.198231	0.780946	-0.88146806	-0.23213863	-0.6634383	-0.34654325	0.6779575	-0.48279527	0.43558434	-1.2640946	1.6519731	0.3437406	-0.32318544	1.2389945	-0.20586102	-1.3301427	-0.064517625	0.0025874563	2.490843	-1.529233	-0.08760612	2.3000867	2.1424294	0.19562592	-0.851868	0.2848231	1.0519768	0.55529654	-0.06998043	-1.1532242	1.6335672	1.2641292	-0.4771905	0.16410938	1.2754362	0.27284405	0.32206064	-0.40139818	0.8945739	-0.63166666	0.26612553\n-1.4606525	1.6221439	2.3421812	0.4326314	1.5404705	0.65360653	0.032105826	-2.5227327	-0.50058657	-1.3342768	1.3565048	0.43247372	-0.3940283	1.7143006	-1.333205	-0.25303194	1.3255723	0.7520978	-0.22845228	-2.3329167	0.5671632	0.7132406	-0.08589912	-0.0076637915	1.7930176	0.042121623	-0.0044010906	1.9035763	1.7920789	-0.70052165	0.88230824	-1.6643345	-0.13347204	2.0530517	1.7910378	1.120665	-0.23229738	-4.484947	-1.90275	0.12002839	0.37353376	-1.1946744	0.3756585	3.042991	1.6185431	2.0323095	0.39132077	-0.55309945	-0.18880744	1.2965554	-0.18557203	0.8466675	2.2158825	2.9310338	-0.006482318	0.48278093	-1.2034482	-0.40921694	0.9042332	0.5324619	-0.84010166	0.6081307	-1.5960355	0.5545167\n-0.5288988	-1.0394815	0.24647605	-1.076158	0.17583625	0.36132	-0.9440448	2.9433608	0.34075758	-1.2554756	-0.13172255	1.1758416	0.03653671	1.0795479	-1.6028966	0.97676456	-0.37758064	-0.7380946	2.3655708	0.16774495	0.25042602	1.263487	2.049557	2.458398	-0.055536073	-1.0145051	-1.4047875	-0.16555329	0.3005615	0.53183055	-0.27503243	0.94667256	0.32143965	-2.3714	-1.26834	-1.0235348	-1.4913371	0.8306318	0.3197856	-3.1763642	2.311373	-0.46669814	0.1467993	-1.1389308	-0.09774749	0.86780965	0.08429173	0.9431786	-0.7022796	-0.858558	0.28472993	-0.64121175	2.000849	-1.2136408	-1.844414	-0.371235	0.3349114	0.13919006	0.7504935	1.3378481	2.1027238	1.6376057	0.13457835	2.3224313\n0.4759996	0.2810226	-2.294191	-0.83765507	-0.6419466	1.032782	-0.5589574	0.037242956	-1.6944214	0.2374606	0.61321586	-0.30143258	0.7026219	-2.0761259	-3.9597685	1.7276688	-3.3614652	-2.4622393	-1.934453	0.49488	-0.47536957	-1.7817727	-0.19373585	0.46608305	-1.2515829	0.33911565	-2.395488	0.02376096	-0.6819638	1.0984215	1.0353626	-0.4288995	-0.60852104	-1.7073383	-0.11023358	-0.29376903	0.2576922	-1.697209	0.65554994	3.0656786	1.2881681	0.11427515	-2.1176531	-0.3900011	2.5101428	-1.5508205	-1.0278528	1.0858623	-1.5777034	0.5047294	1.0179435	-1.7276248	-1.1084168	0.45637146	-1.065542	2.3551	0.19623102	-2.065929	0.15794225	0.7703627	1.841433	-1.9459757	-0.42078218	-0.17940713\n-1.9347286	0.4149195	-1.8688637	-0.28553808	0.38313192	-0.32923448	0.46645346	0.86892027	-0.3397029	0.55501056	1.9400963	0.03924138	-3.0377343	2.5397687	0.57382196	1.6722484	0.5734727	1.0460494	2.893683	-1.0702997	2.1577826	-0.27321926	-2.2084591	-0.31118497	1.4066546	1.0770892	-0.69356483	-0.24529962	-0.059360567	-0.19273487	0.1578712	-0.84238076	2.907062	-1.1528302	-2.0372343	-0.12695536	0.87046015	0.35675314	0.07768373	-0.10607467	0.11578291	-0.65666157	-0.6867218	0.79902387	1.0358548	0.85393703	0.3695446	0.49324167	-0.011195262	0.7479785	-0.19856624	-1.4345074	-1.4403077	-0.5198683	1.2554544	-1.0144626	-1.7184896	-0.42232177	-0.56901324	-1.3886926	0.39150393	0.6898906	0.8606104	-0.65332043\n1.8272679	-0.7714898	-1.9936373	2.149227	-0.737882	-0.43427154	0.68554187	1.9302616	-3.4237592	-1.6275357	1.3432949	0.7334843	-1.5524153	-0.7353166	1.347308	2.1577296	2.1253822	1.407461	-0.39384332	2.3064377	4.9839187	0.5094718	0.24266356	1.2670579	-0.31627142	2.1489785	0.74752325	1.0184828	-2.981008	-0.008538227	-0.95587987	-0.34125474	-1.7288665	-0.7471425	0.85760707	0.5568628	0.29457694	-0.92915314	-3.0612748	2.0603633	-0.059893265	-2.6175044	-2.63564	-1.8666315	-0.3295731	0.35636264	-0.5058235	0.6228585	1.1929592	1.0175732	0.07432502	-1.438352	-1.2103336	2.7531037	-1.7457222	2.2201095	1.0126785	3.7201695	-0.016088793	0.14059189	0.95478964	-1.7440926	2.4804873	-0.60914075\n-0.6154806	-1.5826226	-0.18131141	-0.54603595	-0.44728476	1.6877754	-3.0594733	-1.7731627	2.2633417	-0.57945997	1.2403411	-0.5790306	-0.50906867	1.3654878	1.6134194	0.6308684	-1.9980872	-0.86195904	0.8130383	-1.4637793	1.4011188	0.17548516	0.9439272	1.3558308	-0.9620229	2.539417	1.22093	0.6542337	0.42680466	0.44932595	-0.07082273	-2.4546409	-1.2834209	1.3188405	0.35183442	1.1744633	-0.041804064	0.91025305	0.14598349	-1.9855298	3.104929	-1.8625183	-1.6357851	0.34042582	0.124355115	-2.4491498	-1.3316598	-0.3224193	1.8415488	-1.6036242	-1.9053578	0.33668777	1.2156098	1.5510777	-2.1733632	-0.007773558	-1.466454	-1.0167767	0.15247843	-1.9479249	0.78871685	0.52438635	-0.106543034	-0.017954515\n-1.8393227	-0.29615968	-0.78024924	-1.469778	-2.2670603	-3.9123077	0.19078575	-2.786059	-0.8171349	-1.9396881	-0.7931211	-1.7124759	-0.9761332	0.35542098	-0.9628379	-0.95000154	1.151765	-0.48379144	-1.7508281	-3.184806	0.9083514	1.8462232	1.1701976	-2.7004554	-2.4968908	-3.0700977	-0.26332128	-2.897681	1.2025642	1.1012764	-0.17214786	1.4277631	-0.9262085	1.1449809	1.6826215	4.9992476	1.8780984	0.24958979	1.463509	-0.96807057	-2.7333238	3.075666	0.1762302	-1.6051995	0.22926335	0.5928657	1.2769954	1.2761726	-0.94782376	0.9008626	1.5706742	-0.8901398	-0.12375835	-0.38184172	1.560585	-0.19237034	1.3740448	-0.025156487	1.1570474	0.9288732	-1.3964314	0.9627137	2.248918	-0.81977254\n1.7723264	-0.78871274	-1.7219293	-0.7404201	2.4392326	-3.1350324	3.9347072	-0.27217755	0.91487336	-1.5644904	-1.8774413	-1.5835141	1.694007	0.2728351	-2.6879847	0.44299313	0.3621366	-1.6330241	-0.44258836	1.3931631	1.6533642	-0.87016547	-0.19013414	0.9749169	0.99215955	0.4816132	0.231908	-2.4382849	0.871408	1.9325603	-1.8623481	-2.0572927	1.2349898	0.25652474	0.4039921	1.1769655	0.053415753	-3.4553475	2.2978504	-0.019920649	1.0951524	1.4268897	0.122250296	-0.9170607	0.24222344	2.1855824	-0.1291997	2.0563998	0.28357413	-0.052721944	1.8353534	-0.058842994	0.74397725	-1.0946057	-0.6884074	-1.9319379	0.06556835	1.2550769	1.9515598	-1.3195264	0.8609493	1.7686031	1.1642321	3.2263284\n-3.3483043	-0.7902937	1.0533099	0.6019269	2.4795961	0.37195504	-0.2816097	0.6273023	-0.040663797	-0.3663536	-1.2695374	-0.7875441	-1.2618275	0.08142462	0.6150955	0.024503615	2.0559988	-2.3009617	2.0375066	-1.6917613	1.0487068	-2.2377372	0.023865568	-1.798344	-1.3984923	2.660814	-0.3478335	0.85752344	2.584722	-0.661658	-0.056915324	-0.13258772	0.15146238	2.482198	-2.9561052	1.7045243	0.1575466	1.7655989	1.9948049	1.0203987	-0.74942505	-0.97793967	-1.3654538	-1.9221534	-1.1887037	-0.08244605	-0.8793708	-1.2683009	0.2923953	0.8136439	0.5418983	-0.22636147	1.7553834	-0.77893037	0.35940978	2.1390872	0.7601459	0.6717459	1.6976248	-0.4072939	-0.061019167	0.6821796	0.3142342	0.8258262\n-0.15209061	-0.14967135	2.8836663	1.2895622	-0.97720975	-0.0012745165	-1.4685867	-0.9409513	0.9022685	-1.9229704	0.49364287	0.9876073	1.6389399	-0.525164	-0.42298633	1.6730058	-0.9830894	0.49517992	2.0353043	0.17254347	-0.7474026	-0.5639498	1.3981044	-1.5962596	0.22437418	-0.6043003	0.86617255	2.470569	-2.1002967	-1.0935637	-3.2999527	0.722005	-1.6405886	0.89042354	-0.0018802423	-0.13592781	-3.496741	-2.35664	2.8187351	1.6393348	1.4220468	2.0724914	-1.1380649	-2.7934892	-0.8938246	0.7277646	-1.2053262	0.70060366	1.6007917	2.569945	-1.0838784	0.13426925	-0.15676717	1.5949616	0.18258277	-0.741777	1.7461783	-2.1405487	-0.8491583	2.253767	1.5824304	-1.604544	-0.6375421	-0.08372811\n1.4146504	1.5141352	-2.2717535	-1.211028	0.73004127	0.29184115	-1.1038074	-0.5869148	0.42038974	-0.93843603	-1.0750511	0.68303597	1.9651155	0.21025345	-1.8368796	1.9141451	-0.01948478	1.0872991	0.17138985	-1.887351	1.5891621	0.7502681	-0.516167	2.4335043	0.82733446	1.8859884	0.4214429	-0.26646832	-0.9753789	-0.88511866	0.5478333	1.8942736	-1.2539718	0.2954394	1.8124542	-0.5486502	2.8509808	0.8466281	-0.22005443	3.301017	-2.361054	0.9726741	2.4522455	-1.0782367	1.8998351	-0.88053906	-0.6549063	0.08856413	0.84687704	0.74994695	-1.638737	-0.06901849	-1.4369195	-2.8961463	3.0387495	0.09660095	1.1681421	0.28501922	0.80185103	0.54269856	-1.7342578	1.3622286	-0.73864347	0.1713234\n1.2442969	-1.7801349	-4.0585227	0.99662584	-0.95848614	1.2272998	-1.4293102	-0.5885684	0.9748705	0.32830665	1.6758367	-2.569618	-2.7539341	-2.3549151	1.2233505	-0.3300457	2.1437612	0.337521	1.2291368	-0.07476591	-0.8688474	2.2582288	2.0316827	-4.6154017	1.7339214	-0.8186342	0.90574753	0.57481	-2.8456306	-0.47957033	2.5428097	-1.4940383	0.20972215	-0.44685146	-0.009684095	-1.2396398	-0.38656333	-1.9164937	-0.41744453	0.41247118	0.091922775	-0.010680377	0.26679343	1.0416422	0.47384977	1.0679471	-1.7443519	0.6558282	2.4435077	-0.61715513	-0.89810747	0.24272826	1.4841385	-1.646459	-1.570031	1.6262561	-0.6181386	1.1316212	-0.73606014	-0.81164837	-1.9241322	-0.4660404	-0.88083214	0.23497179\n1.8043035	-1.2941225	2.5533319	-4.153843	1.1339668	0.41810253	0.081456445	-0.34545812	-0.5384854	-1.2734088	1.606612	2.2570767	-1.4217447	-0.8827118	-0.38987842	-0.99507046	-1.8499364	-0.061263334	0.39305303	-1.8841012	2.4971776	-0.06656288	-3.0920713	2.1159768	-3.0755494	0.67037296	2.0445662	-2.096423	-1.5702082	2.1992743	-0.50869036	-0.40947857	-0.8165813	-0.41118205	-2.054578	-0.52777463	-0.20986165	-0.47691014	1.8120172	2.2387292	-0.848138	1.3917674	-1.3136562	-0.7252799	-1.1113681	1.139447	0.5165153	-1.6788015	0.58418155	-1.5247364	-1.8898691	0.81783706	-0.07736472	-0.21560726	-0.18901464	-1.6133839	1.6616739	1.9062291	-0.34943947	-3.558417	1.8901551	-1.456303	1.2597884	2.1637654\n1.5987775	0.47738642	-0.3676602	-0.45440242	-1.700535	0.92653435	-0.457359	2.4394522	1.1200417	0.2766386	1.0514374	2.3614109	-0.00986991	2.1799119	-1.9622405	2.438906	3.1473346	0.71272814	-0.5633361	0.33073255	-2.2194033	0.988411	1.1594156	0.49650016	-1.754536	-0.72422653	1.5560305	0.3641026	0.6308692	-1.7914166	0.4909222	0.8774698	-0.59569484	-0.34615004	-0.9310385	-1.0202447	-1.8692169	-1.0458341	0.32282585	-0.6202304	-1.2077963	0.39706886	0.60185504	-0.6753878	-2.0112846	-2.3681946	-0.54951817	0.69077194	-1.6917713	1.2275445	-2.2835157	1.5702202	-1.4602741	0.43319407	0.04481213	-0.24578084	-0.0687789	-1.3024248	0.093947336	-0.23792697	-0.67957366	-1.0146358	-0.42529282	-2.6667566\n2.150254	1.92755	0.20121603	2.0971339	-0.32389694	1.2417604	-0.5959469	-0.057799276	-0.5083985	1.0887676	-1.7170852	0.66714877	0.43077853	2.3798182	-2.0881603	-3.2590044	1.1007526	-0.05898656	-0.53045195	0.61564106	3.2460601	2.2550128	1.3471076	1.8527462	-1.1013116	0.11579721	-2.2177258	1.7109928	-1.536326	0.9318588	1.7393062	-2.2532897	3.658045	-0.8637801	-0.5719429	-0.37659624	1.6473683	-0.39952552	-1.6095914	0.23051527	-0.13013187	-0.8251483	1.8500038	-1.5134888	0.4773214	-0.9822419	1.4849366	1.0476624	0.20036536	-0.7006791	-1.2575382	0.14809863	-2.356993	-0.6539005	0.5556352	0.21963376	-0.785395	-0.6451968	0.3772807	1.1185821	-0.83647513	-0.50914544	-0.5828803	1.2416729\n-0.30640197	0.46653506	0.028870728	3.8542027	0.0048190765	0.28951585	-1.3873061	-3.0385478	0.6683049	-0.50916994	1.3966757	-2.487222	-1.8316674	1.984848	1.1934298	1.5881714	2.0710237	3.02764	0.4408927	-0.28368893	1.5530361	0.14175087	1.3432558	-0.5532389	-0.824245	-1.1518109	-1.5642835	-1.4174149	-0.5498876	0.22185184	-0.506014	-1.8844671	0.28420958	1.4041182	0.780907	1.5255758	1.0605564	2.2045593	-2.419133	-0.45278257	0.4222841	-0.28896844	0.86637884	0.11491939	-1.3587328	-0.5017498	-0.9140861	0.85999596	-0.085681	2.9060597	1.954169	-0.065253235	-0.9801518	1.6512778	-2.1154106	0.26712856	-1.439338	1.5801321	-0.48966774	0.27716953	0.32870942	-0.91974086	-0.795843	1.3055162\n2.3515406	-0.0386976	3.0474157	-1.4674016	0.6187145	2.5626948	-0.25388896	-1.2907608	4.0168834	3.023287	0.4314142	0.5466884	-2.0735683	-1.2832239	-0.706947	-1.9300597	1.0177066	-2.4623222	0.9832745	1.1731125	-1.1875638	0.1874811	-2.9627407	1.8355973	-1.4828993	-1.7520615	1.6317888	0.69185627	0.17750017	0.09192877	-0.57596976	0.06952623	1.9176792	0.52886194	1.1176021	0.49078676	-0.6502149	1.8234915	2.0467427	0.40057337	1.7704588	1.2250441	-1.5340397	0.053562053	0.70981413	-0.5491067	-0.771627	0.2158105	2.6180923	-0.5526078	-0.74562734	-0.6794336	0.9195645	-0.69241565	2.652029	-0.7913751	1.4269675	2.791528	-1.8928176	-0.2986033	-0.2085997	-0.19476426	1.8982161	2.1468394\n1.9020125	0.33316538	3.3790774	-0.24103647	-0.38583413	-1.1088549	0.47046837	-0.5889878	-1.1593065	0.49126273	-2.1360104	3.402111	-2.1315234	-1.7076206	0.5485901	-0.7192578	0.12053888	0.9985247	-2.874037	1.3013006	1.5059932	-0.2995713	-0.86627096	1.3723149	0.76317424	0.27409557	-1.7175617	2.2800865	-1.0115045	-1.2748046	-0.14390957	-1.2379438	-1.0598661	2.1952972	-0.7738529	-0.72901446	2.7127438	1.0318213	2.3087723	1.2475882	-1.340055	1.0640409	1.9811645	-1.8440157	0.5701601	-1.9064697	0.27996367	1.2715901	-0.12868184	-1.2297924	-0.69363624	-0.81312907	0.05935646	-1.1383156	-3.21974	-0.36892733	1.271618	0.19541804	1.731221	1.474155	-0.51503253	-1.3003594	-1.5758753	1.6637366\n-0.04776953	-1.2646363	-1.8391972	0.037142564	-0.4111135	-2.4209697	0.987252	1.2583807	-0.8418084	-1.0008032	1.310702	1.0897791	-0.16017964	0.74437237	-0.8155581	0.14615624	-0.28928134	-0.8496337	3.481987	-2.408397	0.31361985	-0.38287365	-0.46723834	1.1959879	0.19442962	0.41859883	1.2870791	0.37947404	0.60664195	0.92083645	0.2382588	0.57128954	-0.023797788	0.8581946	0.13001356	-0.14113314	-1.5137079	1.6907405	0.62508	1.1161839	2.3614674	1.2109843	-2.4677649	2.4853506	-0.12203557	-1.1028184	0.80109614	1.7940114	1.2046182	-1.2417884	3.996472	-1.0115654	-0.96031183	-2.0084665	-0.22762603	-1.8893383	0.3985475	-2.8714354	0.2056093	-0.5189342	1.0013188	0.5833705	0.29556218	-0.016250765\n-0.5102537	2.1377578	-0.987968	0.39125088	-2.1240795	3.064685	-0.23724775	-0.94848996	-0.43833464	-3.063827	2.0070333	-0.5286433	-0.6969106	0.9824051	2.4786022	0.65701145	-1.6205934	-1.443481	0.47529653	-0.70318514	1.328454	-0.5235083	0.68126994	1.9474974	1.3567828	1.4767927	-1.1657444	0.25146836	-1.6859505	1.1705987	-1.8262949	-2.505375	0.26498467	0.111614704	-0.2974762	-0.20044039	0.8946883	-1.4764174	-1.4890392	-0.048276734	4.113975	1.9093782	-0.5596075	1.0757611	-0.8142438	1.7156852	-0.8285142	-0.68228465	-0.942075	0.25981498	0.18933783	-2.5881977	-5.244194	0.38461474	0.77630997	0.31651655	-0.56907684	-0.175138	0.1705455	-1.674083	0.7565259	-1.1051228	-0.4633049	0.18465279\n-0.29190475	-1.3653609	1.4929385	0.5853715	0.3077035	1.765161	-2.7349157	-0.35396644	-2.2956905	1.741592	-0.14365236	-0.07774316	0.7012286	-0.8151179	-0.58105665	-1.8515463	3.2496867	-0.24584337	0.3024859	-0.026948754	1.7392303	0.97433525	-0.48648447	-0.55182606	-0.82196903	-1.4043128	1.1064944	0.035660215	1.8625629	0.6687107	0.70075697	0.9960421	0.31107378	2.0268812	0.6576915	-1.380889	0.9962695	1.5329504	-1.4602549	-1.5069375	1.4374123	1.3359225	-1.6812924	1.6765232	-1.3245405	0.17059179	1.5928894	2.8459847	-0.16375235	1.9492462	0.84025	-2.545597	1.3873563	-0.2702301	1.1085988	0.9589289	0.20190497	-0.08471392	-0.10275625	0.48249862	-1.0879539	2.7426069	-1.9865998	0.33690137\n0.8017412	2.614985	-2.2657783	-0.5117394	-0.31165007	0.3121604	-2.541497	-3.9947422	-0.9625017	-1.5559921	-1.2254653	0.49305496	-0.66664195	0.06509675	-3.3740103	-1.2822081	-0.53487164	-1.2918435	0.6619999	-1.869241	-2.2836041	2.3943	0.35588458	-1.9375863	0.05160137	-0.06664489	-0.61357605	-2.4330828	0.92685574	0.29178897	1.3279426	1.8578005	0.93272287	2.059336	0.2894948	-1.0940211	-1.1700536	0.8762369	0.18764876	-0.79014504	0.569851	0.54727155	0.35313243	1.80878	3.7831068	1.6594995	0.12400652	0.39824972	-0.7410478	-2.7508888	0.44409662	1.1209469	0.79909354	1.5947133	1.0164324	1.6862637	-0.8326598	1.2461013	2.1640904	2.5728111	-1.9732146	-1.1015084	-1.2512846	-2.6536674\n-2.8906517	-0.28510323	1.1700149	-2.3484027	-0.014443711	-2.1647422	-0.32581156	1.1397638	0.111904144	1.208214	-1.6125414	-2.179058	-0.5211285	1.2877613	1.7085996	0.5637331	-1.3463135	0.4845429	-0.7539328	-0.11605246	-1.5996183	0.07490867	1.0498891	-0.6967221	0.39535168	-2.9426498	1.1897538	1.7537519	-2.1304538	1.6911914	2.1348872	1.1400411	1.7125016	-0.35752013	1.1309988	0.90513927	-1.2853405	0.82256144	2.182621	0.03336585	-0.39733434	-0.21100745	1.1165049	1.728862	0.06863099	0.89872557	1.2632883	3.6906908	0.68811333	-2.0352352	-0.4897481	-1.3033632	2.3116357	-1.7701716	-0.8592094	0.1254429	2.080761	-0.4868102	-1.0181755	-3.0655165	1.6563122	0.55050534	-0.3526073	-0.16696389\n-0.5081832	0.90795034	-2.900962	0.90239865	0.5484576	1.9340335	0.29517484	0.35522234	-1.9104216	0.89059526	-1.7040323	0.856589	-1.3398075	-0.08402588	1.6756941	0.25784898	-1.7721562	-0.07966332	1.5133609	0.3565408	1.0219839	-0.21325436	0.22563589	0.1416405	2.297762	-1.4503847	-2.1660345	0.87342423	0.7263028	-2.379288	1.3572052	-0.39505693	-0.41887078	-0.5667054	3.1214359	2.3403854	0.6561522	2.920502	-0.001413643	2.1200776	1.6323197	-3.8168082	-0.7626025	1.3507787	0.7109512	0.3881409	-3.5519626	0.29879364	0.5426606	4.335858	-0.56479895	-1.8333553	0.76585156	-0.9129522	-1.8891466	0.09170679	-1.8027838	-0.7593234	0.25759447	2.1804721	-1.252902	1.6635728	1.7151002	1.5956218\n-1.679082	-1.5275248	0.1786076	-0.066015005	-0.03657944	-0.3905174	-0.80821455	0.7656046	-2.067356	-1.5513321	1.8680105	-3.2454126	-0.9712104	0.8135947	1.7462031	-0.73895985	-1.8446234	2.2362046	-1.6522213	2.026034	-2.2346337	-1.2022392	-1.5481268	-1.5553353	2.3662884	-0.73963785	0.19797055	1.6972423	1.9036958	-0.09974508	1.0065751	0.38397244	-0.22802022	0.98313075	0.24024001	-1.6621306	-0.5942383	2.1091816	1.3252898	0.90173143	0.35450605	-2.1764307	-1.7972242	-0.9766426	-0.027584217	0.68835205	1.0211507	0.9351074	-0.7877928	-1.0914122	0.042766865	2.914873	-0.36296865	0.09656839	-0.6696482	-1.8756334	-0.5045273	-0.30057976	-1.3039596	0.63381815	-1.1534435	2.2002678	-0.3425787	0.5048782\n0.69184077	1.1198579	0.020891182	-1.2039924	1.6483266	3.5400205	2.0639684	-1.4683937	-0.54974174	-1.8841492	2.6335468	1.5300333	4.0158763	-1.2210771	0.75780344	-1.9085479	-0.54363155	-0.19412677	1.1974844	0.994205	-1.4059303	-0.34312198	-0.025005013	2.0289357	0.4428432	0.23635633	-0.8726007	0.54338163	1.3794066	0.75553507	1.9277236	-1.7818496	2.0742617	-0.80235964	0.7894671	0.44647515	0.66638607	0.47762337	-0.33407077	4.060133	0.22920787	1.7879227	2.4917085	0.7062351	-0.66518396	0.9311848	0.8675875	-1.4797834	0.16141352	-0.75364906	1.70791	1.5995656	0.17498043	2.4766188	-1.4075768	1.0603238	0.03976474	-0.6245236	-2.373871	1.6546446	-0.93214744	1.4446795	-0.85414994	0.01652927\n0.60354656	-0.29245207	-0.2939808	0.723368	-3.7608752	-1.437209	0.72753966	-1.8747746	1.242572	-0.6484522	1.6659768	0.8908677	1.6013594	-0.30605456	-0.36256257	-0.40150073	-0.28803685	0.1582903	0.7445116	-2.1870747	0.5571712	1.0676451	1.4992449	1.1500291	0.14837775	-3.2172995	2.377934	-0.6090583	-0.18528698	1.2297014	-2.0684721	-0.20983313	-0.53891623	-0.28985876	0.9976383	-0.48786065	0.38174492	0.33500335	0.050144333	2.1731029	-0.8716372	0.7859954	0.39390123	-0.9118084	-1.5110513	-0.036244072	3.4707022	-0.89116484	0.41079122	2.6326218	2.0478797	-0.82566875	0.0021186038	-1.4337751	-1.219039	2.8724332	1.0363294	1.4841584	0.09282	0.27499345	-1.2720771	-1.8039018	-0.137936	-0.088076346\n0.56955534	1.2708986	-0.8933551	1.5863134	-2.5435536	0.08748879	-0.02918176	1.5547451	1.3101196	-0.28504762	2.7535653	-1.0471563	-1.2879832	-0.46746382	-1.8040835	-0.97023106	-0.6475341	-0.22160095	-0.8507291	0.3327186	-2.137771	0.55133	-0.7397597	-0.68203324	-0.49914545	-0.5494146	1.6332463	0.9193174	1.556552	0.03166819	-2.5908089	3.2105358	1.807374	0.42742237	1.872522	0.5308822	-1.4154333	1.8111806	1.489443	-0.59343153	2.165008	1.8745066	0.7942112	1.7864228	0.58187187	-1.0171992	-0.3327657	0.29526278	-2.3741097	-0.54700863	0.22009444	-1.4733944	1.7505449	1.071396	0.36978048	0.5775905	0.36686283	0.8443696	-0.20540515	-0.15472916	-2.309139	0.31632257	0.28799847	-0.7878495\n-0.3596218	1.7561315	3.037565	0.11058773	0.13511726	1.8994787	0.015869966	-1.315421	2.5059211	1.6348357	-0.8960584	-1.9891518	-0.8707347	0.19420724	1.0532748	1.6571691	-2.0040195	0.40087485	0.05512299	1.1832082	2.5780814	-1.7465714	0.53008425	-0.28223687	-1.3964281	-1.0947098	-2.0176654	-1.3350643	0.59527653	-2.153215	-1.1663947	0.03758779	0.8437861	-0.81336755	0.2144283	-3.6589613	1.2644868	0.16456352	1.5313079	0.38131928	0.63743263	-1.1710653	-0.9759161	-3.502631	1.1604606	0.049600586	-2.1372945	-1.8846817	1.2616296	-0.5493656	0.529058	1.038772	0.59820867	1.2943277	-1.1221676	-0.9288746	0.008733671	0.2932082	0.70591396	-2.0031135	-0.22957033	0.44237816	0.18968429	-2.608885\n1.1351362	-0.26233178	-1.8727975	1.0523338	2.9435563	2.3712401	-0.7124133	2.6648896	-2.1201217	-0.21955155	1.1048938	-1.7315592	1.1424514	1.0219125	1.3977003	-2.0186992	0.24944448	-1.3088864	1.0188816	1.5555913	1.0830096	-0.60537577	2.9296148	2.614028	1.9890587	0.5879507	-0.9353857	1.128248	1.4890823	3.415634	2.4693544	-1.1302378	0.0077502485	0.65754694	-0.626405	-0.72372174	0.06717759	-1.0115454	0.070940785	-1.8842742	-2.0970953	-0.18688665	1.1642237	1.2211756	1.0565647	1.0152568	0.04786203	-1.5487226	0.12483926	-0.95785177	-0.8442806	-0.076950245	0.4916257	0.7800562	-0.2750765	-2.7870972	-1.1514057	-0.17727652	-2.3462431	1.805593	0.33077163	1.307489	2.2776098	-2.2816648\n-3.1347022	-2.2572486	0.34299436	-1.0840126	-0.5545687	-0.51771367	1.1003232	1.8750274	-0.3534062	-0.06891467	-1.5582453	0.60558444	2.523277	0.16300635	-0.33020705	-1.5578322	0.42118758	-2.7658641	1.1003969	0.7940221	0.46229535	-0.14218232	1.2287222	-2.2354076	1.1725022	-0.9856653	0.24804963	-1.9469374	-0.99798775	-1.7137985	-1.3004254	-0.00023808658	2.0494018	-2.6205826	-0.7983724	0.18206066	0.011114824	1.1990622	0.26540655	1.95572	1.9770907	0.06507411	0.056434732	0.2345586	-0.07208499	1.9676481	-0.88949865	1.0251305	-1.052486	1.0150428	0.8949787	-0.623414	0.21567746	-1.6708611	-0.00021082982	1.5758086	0.26044077	0.034091845	-3.3481905	-0.8196038	-0.20586261	-0.51162565	-1.5693209	-0.8551766\n-0.4081062	1.6987962	-0.6077225	0.025249863	0.111639604	-0.48691794	0.89330566	-0.016400732	-0.52321976	1.1604694	0.5348722	1.7015823	0.48223537	-0.61473495	-0.77130824	-0.21574117	-5.284608	1.0259349	-1.6296297	-0.8901719	-2.088631	-0.7810739	-1.0314598	0.94070125	0.70501316	-1.0636663	1.0299757	1.8519404	0.6222708	0.2153075	1.1102598	1.5182272	0.5688808	-2.670582	2.2913942	-0.1188668	0.7257006	-0.30962765	-1.8850827	0.9297427	-0.8361057	-1.8977889	0.07110579	3.4651015	0.53082085	-0.0320092	1.2342423	-0.06753029	0.51328576	0.38860562	-0.5165025	-0.74908257	-0.8031923	-0.25983226	0.25363955	0.09265147	-1.1349077	0.50545746	0.43813393	-0.062264744	-1.481944	-1.6884291	-0.0018009396	-1.2044235\n0.75117457	0.30356273	-3.9235442	-0.8434681	1.2336439	-0.7857995	1.742162	-0.069999486	-3.0975118	-1.6156709	-0.96776825	0.4402649	0.16301097	1.4201816	0.5219425	1.2516856	-2.0130403	-0.25108352	0.7149994	-0.050672453	-0.35323995	-1.3436863	1.3667412	3.2441428	1.1712945	-1.1736861	1.9320397	-1.2548229	0.19578609	1.0601424	-0.29016432	-0.90510017	2.5573514	2.199076	0.92141575	1.0400894	0.17493223	-1.324714	0.33585235	-0.4652589	-0.8233965	3.3161392	0.090672	1.4079081	-0.8448291	2.136484	1.9851308	2.0757017	-0.22018646	-4.308711	1.2939202	1.1764494	1.5354848	-0.660409	0.4259479	-0.76931757	-1.5624465	0.5712196	1.0934446	0.0985007	-1.6341838	1.6835924	0.88998634	0.6541841\n1.1575009	0.23069148	0.6404285	1.9396889	-1.783729	-0.84000695	-2.7370913	1.137579	-0.18603092	1.170257	1.4245172	1.8893872	1.1001483	1.6405214	0.16249968	-0.5903258	-0.9436099	0.8739872	1.3427693	-1.6105745	-1.2963946	1.2761972	1.8216009	-2.1238756	-0.2914002	0.64085627	1.3450074	-0.83337945	1.172601	0.98676676	0.99495107	-1.7784415	2.5431564	-1.8169247	-1.3965952	3.3808925	-2.011104	-1.0215298	-1.1024944	0.69789845	0.4237219	-0.6834379	-0.21070682	0.6373674	-2.5513752	-1.7711325	1.2829922	0.6216342	2.329946	1.1799067	-0.47353128	0.47609827	-0.49661887	-1.0502502	0.04454323	1.5739905	-0.02535841	-0.59390485	-1.5124776	2.7255886	-2.250926	3.1547687	0.8160889	-0.75997496\n2.7656841	0.05596747	0.74489254	-1.5985206	-2.8621302	2.1582432	-1.6976087	0.3833009	2.3417656	-0.96017474	-1.6359315	-0.08993249	2.1917846	0.6705385	2.5594423	-0.65783435	0.32721856	0.8014516	0.91246814	0.7158667	0.17409553	0.2841026	0.27259088	-1.3495272	-1.1117073	-3.0766587	1.2408214	0.6491138	3.8679202	3.3065865	-0.9546362	0.31685868	-0.2842042	1.3074982	1.5982621	1.5302886	0.6906052	0.0087084435	1.9200634	1.8864644	-0.5870499	-2.9807918	0.97962576	0.36552507	-1.2461009	-2.6677618	2.0048873	-0.8480042	-0.6409134	-0.9209103	-1.4161359	0.7399403	3.4425066	2.8766768	-0.03494231	-0.057008594	-0.33452195	-0.6579288	0.6443791	-0.8787211	0.5541699	1.9440919	-0.79072714	3.7179773\n1.7280414	-0.9110788	-2.12567	-0.032734033	2.397344	0.95181465	1.8525873	-2.0928793	1.2030481	-0.8921886	-0.6718559	-0.734089	-1.3909127	1.56412	0.38411248	-0.9835289	0.5457871	-0.6614306	-0.23048458	-0.10695432	0.94234645	0.08424556	-1.248767	1.685255	-0.16142532	-0.15371238	0.8852789	-1.0958126	-1.9927047	-0.9102022	-1.8141947	-0.45361012	1.376609	-0.25121835	0.29722068	-2.5249815	-1.7763071	0.018773686	-0.12723225	-1.0787678	-0.87539476	0.6003669	0.53285664	-1.5846562	0.27113232	2.0560973	-0.48117173	-1.7523229	-1.1716783	0.5469358	-0.7479342	-0.089376606	0.40804	-0.7629521	-2.8653305	-2.36152	0.0252893	-0.32831836	0.15422496	-1.2298301	-0.4967303	1.5158147	-1.8795573	0.17515938\n0.19514003	-2.750313	-0.026042538	-0.8701361	0.18867138	-1.4637313	-0.6142787	2.27218	0.9306574	-0.9855941	0.1693163	0.46779147	-1.9754645	1.5209506	0.51089925	1.0351038	1.0704418	0.4417794	-0.20537542	-1.4796988	-0.6407426	-0.5951839	0.43038392	1.6190116	-2.1041017	-0.23303188	-1.7245752	-0.15443489	-1.446051	-0.5736433	-0.9613713	0.41111347	0.890185	-0.5137226	-0.11592877	1.4724634	-1.7724104	-1.0637661	0.3341217	0.63104004	3.5355058	0.9573607	-0.050061326	-0.35313928	1.2965752	-0.70622635	-2.05653	-1.771854	-1.1051917	-0.55746865	-1.6373683	-0.49733698	0.4880156	0.66524404	0.839376	1.8410202	0.14168288	0.1973129	1.4352134	0.23039307	0.22451794	-0.69018525	0.0610465	1.2071961\n2.0911608	-1.2564185	2.2177567	-1.2140265	2.1724534	0.9955918	0.06274856	0.4144113	0.004264627	-0.9835579	0.22645116	-1.8275753	1.0435033	1.5515627	0.39884672	0.38529184	0.81846684	1.9584693	-0.634111	0.40694016	-0.68921494	-0.06254645	-0.30236834	0.28906748	-1.6920795	-1.0034547	0.68063885	-1.4865322	1.0243696	0.07813756	0.58170736	0.01646564	1.2859939	0.20362386	0.33799657	-0.0056788037	-1.2451569	-0.46149573	-0.009353362	-1.5071868	1.6102846	0.20988387	1.9630859	0.53682256	-0.20844574	-0.6406652	0.5727908	-3.1224093	0.17473692	1.6448021	0.78275925	0.58792245	-1.6421542	-0.75589365	-0.5681923	-0.5263598	-1.378507	0.31315622	0.24472778	-0.026383528	-1.5583996	2.1067789	-1.222431	-0.9833992\n-1.4210014	-1.7829171	-0.3249572	2.8914442	0.6579559	0.14121401	0.34153017	-0.015513396	-0.71060395	2.6778347	0.98737687	-0.7992521	-1.3819045	0.46064752	-2.0889287	0.65452194	0.11818289	-0.62552035	0.3948286	3.913915	-0.06591921	-1.8101863	-1.1737664	-0.19222744	-2.795487	-0.74237734	0.040970437	0.21181479	1.1825677	1.2370797	-1.4422361	1.9923222	1.8047942	0.7889141	1.1238189	-0.30367708	-1.4035982	-0.75684327	0.2119321	-1.0267824	1.9647286	-0.29043782	1.5938215	1.9872888	-0.61178756	0.039458122	-1.2658324	1.619696	0.7899136	-0.91414577	-1.8983047	-0.23464133	-0.9159213	0.26459986	-0.72895014	-2.4265776	1.0315983	2.06969	-0.54249084	0.2603308	-3.1442826	1.1105253	-0.46988994	3.1728797\n0.7484372	-0.22810595	-1.562179	2.7691066	1.8112974	-0.46466443	0.6747818	1.4182217	-0.82253164	-0.04027395	-1.1670024	-0.5571838	-0.7725068	0.80324435	0.025240727	-1.1974508	-3.3301952	0.6225047	1.5311881	0.5986728	1.7683622	-1.5573753	0.41718292	-0.53131914	0.05975973	0.7287439	-1.9683753	2.049954	-1.2068614	0.1785964	-2.7082691	1.8618237	-0.327734	-0.8500459	-2.561937	-0.6387363	0.37443906	-0.7852599	-0.6553915	2.1903815	0.14604987	-0.2503378	-0.9851805	-0.016883075	0.40022105	-0.32910523	0.45714542	-0.2705655	-0.37635428	0.4665644	1.6767497	-0.9721597	1.5326502	1.147566	-0.81481373	0.64297825	1.2854888	1.0555481	-0.5794251	0.43029225	0.52714294	1.9536195	-0.48201856	1.5300292\n1.732433	0.08128804	3.9139273	-1.4417435	0.651433	2.3629234	0.39906502	-0.07873088	-0.74167687	2.529429	-2.6253934	1.4209393	1.3139088	2.3386853	0.57221377	0.2397148	-1.7458322	-1.1836774	-1.9961033	-1.4333743	-0.14749065	-0.94345856	-0.6849504	0.15462734	1.40271	-1.2895526	-3.7091813	-2.3900926	-0.9374155	-0.8488559	-0.17689037	-1.2306054	1.8865329	0.4295908	1.2228972	-1.0269489	0.65032893	-1.532079	-0.54409486	0.12982243	1.1899704	0.9989644	0.81588286	0.56141865	-0.33468205	1.6876634	-1.0630836	-2.8828123	0.74056536	-1.2071425	-0.12261218	-3.4911551	-0.03454449	1.1123629	0.58555555	0.5317233	1.7020301	1.2903086	0.07690847	-0.7920559	0.82997394	-2.973777	-1.5144987	0.13724667\n0.62161064	-1.6161202	-1.6427203	0.68482864	0.06841421	-2.5975351	-0.8840891	-2.0233848	1.2407937	3.114833	-0.41680905	0.90324754	0.12088108	0.84524107	-0.48725432	-1.2341975	-1.763996	-0.96671814	-1.3534453	-0.5083444	-0.5984953	1.5026289	-0.15791889	-1.5778043	-0.98573416	1.0754533	0.2728626	0.560872	-0.5663775	-1.9603844	-0.34050152	1.5029722	-0.6225252	-0.78182876	-2.751329	0.12827143	-0.8701221	-0.021976018	-1.2000337	-0.27293217	-1.3677921	2.021618	0.18801294	-0.25070474	0.5213352	1.4734122	0.022941865	0.016818179	1.3607999	1.7336017	1.0999175	0.46999413	1.4696612	1.2105116	-0.3018158	-0.8734545	1.7667626	0.2903188	-1.3742677	1.1745539	1.6306909	-1.2997987	-1.8514785	0.365777\n0.46468237	-1.083113	-0.83752793	1.0736226	0.21161067	-1.354497	-0.44819823	0.7529567	0.5646096	-0.38209602	1.3621484	0.7255195	3.3451688	-0.056710664	0.89709896	-1.3915268	-0.12500355	0.040849622	1.4851577	-2.1141748	0.0648569	0.33847234	-2.463887	-1.2936654	0.2833853	0.6128732	-1.3738155	-0.7948159	0.09524709	0.080044135	-2.531667	0.090485014	-0.45863354	-0.07163434	0.35176802	0.28457576	2.5052814	0.28012022	-0.8620238	-1.1250385	-0.45436135	1.5822355	0.18368727	0.24995238	-1.0920808	0.88696116	-0.04351828	2.446018	0.89393175	-2.1003864	-1.2817552	1.6180006	1.53253	-0.36978903	-0.2954334	-0.36568993	-0.23012635	0.4637994	-2.1360338	1.4455644	1.3956238	0.19659509	0.2975011	1.3491676\n-0.6687017	1.1954831	0.6175117	0.039810404	2.3428183	-1.3232512	1.5197905	-0.15393429	1.7573475	-1.2625934	0.8193287	-0.8361758	0.6245033	1.1027713	-0.6839758	-0.8571447	-1.8966346	1.2783043	-0.19139594	2.1648412	2.6128733	0.7165845	-2.2833273	2.1647904	-0.77331424	0.9063015	0.67524356	3.1167355	1.0041571	0.64508957	0.17087999	-1.4613453	-0.19466363	1.4733891	1.7690614	1.1476278	0.63336575	-2.2442448	0.27609143	-2.2714155	0.21341223	-2.4579213	-0.90635747	0.38865122	2.441162	2.640335	2.051584	0.9701174	-2.0132732	1.9157468	-1.1785194	2.6951964	-1.4919313	-1.8190677	-1.6403319	-0.15903664	0.54364824	0.124410406	1.2872368	0.9646252	-3.3651032	-1.4185224	-0.25061238	1.8216308\n-1.8301209	0.2512849	-2.6325917	1.5288712	1.5375682	-1.1162686	-1.5874168	0.50026757	-0.16223985	-0.6145135	1.7478461	0.59283143	0.31099457	-1.1807485	-0.78320765	-1.372657	-0.39342672	-0.4795648	-1.0708861	-1.6844097	1.0986112	-0.34048918	-0.023536744	3.115045	-0.56192946	-0.8598116	0.9585817	-0.64578557	-1.3419367	1.8843755	1.8263988	0.7599205	-1.8361274	2.0138195	1.1364716	4.1871676	0.1397697	1.1509438	1.336324	-0.26033744	0.34414652	0.5860599	-1.7677699	1.2168828	0.14186703	-2.369167	-3.3637545	0.121785566	-0.98059857	-1.7512398	0.7590015	-0.61289936	0.25012043	0.6838411	-3.1394916	-3.4851782	0.11342454	-1.6246457	1.2660488	-0.80337644	-1.0677274	1.1537999	-0.58447117	0.77702975\n-0.21083662	-0.6397287	-1.7795067	-0.49105918	-0.95889723	-0.61905265	-1.0761153	-2.4129071	-1.3149946	1.1803937	-1.2617902	0.9910654	0.76670307	1.8026074	1.5308529	0.54353535	-0.33250752	-4.1417594	-0.72870284	1.6615151	1.2817695	-1.9144202	-0.6168507	-0.57333547	-2.3233428	1.2355583	1.2467139	1.583646	-0.5607099	-0.5435137	0.121043585	-2.2077737	4.0139394	0.4902017	2.018697	-0.66143125	-0.5772055	-0.45744297	-0.9739037	0.3341383	2.7132282	-1.0677817	-3.1465943	1.2141976	-1.0581629	-1.8516312	0.41475448	0.43802345	0.4335698	1.1763408	3.8239393	0.48639363	-1.1932093	-0.13416317	0.4611405	-0.75528806	-2.6938405	-0.51536816	-1.71693	1.0432103	-0.05304614	-0.18121214	-0.4926766	0.4720057\n-1.0592018	2.3065343	3.0569572	-1.0591259	1.6379818	3.5804534	0.8210583	-1.0633113	0.42789534	0.2702654	-1.9756998	0.63797104	0.2545983	-0.3482625	-1.5276608	2.1487942	2.93616	-1.0834311	2.0255938	1.5110542	-0.4457016	-3.439567	-1.2195622	0.84849983	1.1031728	-1.4686325	0.1734182	0.7024764	-0.46957058	-0.63587946	0.5341769	0.9710877	-2.8492324	1.9370505	1.9617537	-0.4106001	1.0320978	-0.69067353	1.00114	2.3341675	1.5521058	-0.46123353	-0.19224685	0.12030632	1.1990007	0.030220168	0.29426473	0.0463017	-0.7546766	1.2807055	-0.9587889	0.7989763	1.0135069	-1.5030776	1.8009462	0.35756627	-2.9130225	-0.028451227	-0.7766462	1.8970878	0.41144782	-0.7715226	-1.4169133	-1.0793339\n-0.43040487	-3.519307	0.28665736	-0.65777403	1.0711365	-0.21065556	0.70547956	0.3977428	-0.18586712	-1.7271394	0.047275804	1.9379904	-0.9423087	-0.0064173765	-0.8484995	-1.1726267	-1.4386196	-2.226116	-1.2822648	0.9209862	-2.0053074	1.3432928	-0.85572135	-2.3401427	-0.10857201	-0.6474189	-1.1061954	0.49671078	-1.2506986	2.740336	-0.12306585	-0.5359233	-0.17694491	1.3442695	2.070933	-1.2535691	1.9691203	-0.7522104	-1.0578767	2.0866084	-0.5156295	2.2263324	0.53959566	-1.13719	-0.60101736	-4.3528605	0.72437584	-1.134204	0.5165004	0.062047414	-1.2704158	-1.040662	-0.8995906	-1.4875481	-0.7467824	-2.0053859	-0.16307878	0.57377934	-1.5118256	0.21096273	-1.6612519	1.5882064	-0.05228433	0.47525054\n1.3458917	-2.0619168	1.6158445	1.146474	2.0503829	-0.7907211	0.25841105	0.012990101	-1.045385	-0.8917383	0.7492822	1.3747499	0.0904917	1.4678328	1.2046267	2.0669882	0.39570323	0.38914922	0.31471366	-0.82595223	0.7995298	-0.55302656	0.23262832	0.17212407	-0.97115546	-1.6114587	-0.24370119	-0.9891528	-0.016345376	-0.79073346	-0.32785156	2.7183723	0.13343546	-0.76205385	0.91350853	-2.5762126	-0.25087368	0.5388658	1.4416747	-0.41894677	-0.06141524	0.6387172	-0.54317826	0.82201076	-0.78429943	1.8039421	-1.2576871	-0.8531809	0.14721872	0.6475777	2.0401638	3.114981	-1.6032858	-2.2704272	-0.5952878	-3.0123463	0.53470236	0.7129409	-0.92563444	0.94365865	0.7560554	1.6136116	-1.8777803	-0.12048759\n0.9955603	-0.034731686	2.0355735	0.4574831	0.12496601	0.055624045	0.18659969	-1.3089504	1.6501665	-2.4663758	-2.1211832	-0.7050624	-4.236794	-1.036082	0.974449	0.8469288	2.473823	-1.3557485	1.6781998	-1.3435175	0.4291435	0.3060485	1.035175	-0.71674794	1.7697878	0.03171235	-0.49987277	2.069029	-0.9471208	-0.48019177	-1.501721	0.281429	-1.1442046	0.73111385	1.817443	-0.80874574	-1.8464327	0.9212142	1.2261086	-1.4996717	0.7476293	-0.6388942	-1.0129275	0.37789774	0.96813077	-2.8688905	-0.48876527	0.04668255	-2.347166	-2.5585458	-2.381046	2.1290877	-0.7793954	-1.2013714	-0.14114776	0.04673458	-3.2401712	0.8895151	1.8628545	-1.424527	1.2252719	-1.577097	-0.44017336	0.5740915\n1.8661016	-1.70617	0.4298818	-3.2743943	2.1680677	0.20683873	-2.5276108	0.45899868	0.93084246	-0.39311415	-0.796588	0.78647715	0.45323366	0.2302539	-0.52982205	-2.3225996	-0.19233645	0.77430606	-0.35481638	-0.12019206	-0.0016084629	3.5315197	-1.8993144	1.9418503	1.8003979	-0.12502052	0.9366183	0.7709897	-3.0171063	3.1368637	0.38017872	-0.8293463	-0.03689825	1.1726186	-0.22074564	-0.7559383	-2.7687736	-0.646119	-0.81073266	0.13860478	0.8717061	2.7722385	-0.049986344	2.3913016	0.3928062	0.6756796	-0.4459989	1.5095451	1.693921	0.51448643	2.0642467	0.72937894	0.81291205	-0.5824823	0.123825066	-1.4511274	-1.3945866	1.2175789	1.029597	-0.05975272	-1.5711223	1.2323465	-0.30469295	-2.442088\n0.40228036	-2.9356637	-1.625462	-1.1407472	-0.6552899	-0.65177166	-2.477708	0.66096526	1.9641821	0.37242034	-2.6689591	-0.24421084	-3.118201	2.8599744	-0.29194984	-0.2814186	0.04279049	-0.260906	2.2030852	0.37910095	3.5583882	-0.83656186	0.5121688	1.6324635	-0.24239361	1.0995109	2.7294753	0.0106322095	0.35846964	-0.6913544	1.2900065	-1.2378755	0.55958825	0.14885622	0.4636676	-2.173262	-1.2022878	0.46103436	0.046716347	1.7790865	1.1758703	-0.08014359	2.5818446	-1.2348642	-0.8693788	-1.7668543	0.11957297	-1.0388623	2.6481698	1.9171622	0.2487518	-0.037126504	1.9059334	0.21817248	-0.5196161	-1.8145064	-1.7540653	0.46074238	-0.08513269	-1.9565427	0.5468167	-2.823829	-0.05724181	1.2638338\n0.026578734	-3.4582434	-0.7568868	0.09095096	1.2832408	0.22294693	2.30976	-0.8646303	-0.5166823	0.7183375	1.494189	-1.8017942	-2.188774	0.37964448	-0.5460397	2.408359	-1.1771252	3.3752139	-0.39014775	0.22915845	1.2908072	0.15220033	-0.77102697	-2.0316904	1.1861404	-0.2916563	3.1725543	-0.9722108	-3.2489293	-1.2356347	-1.0911605	2.3189275	0.64122856	-3.753848	1.3093938	-0.45248508	2.3737807	-0.63794404	1.9681826	0.035559736	0.22064233	0.6266365	-1.9399387	1.0663388	-3.1107068	-1.8671458	2.4185033	-1.4170856	-0.91383064	-1.3344488	-2.251013	-1.1500697	0.011137434	0.23669629	0.67740804	0.65868527	0.2665427	-1.7986774	1.0421572	-0.546628	-0.031029237	1.0739983	-1.4831347	-2.1473775\n0.42344257	0.91522413	1.2290974	1.7496104	0.13305487	0.16253385	-2.0904171	-0.7166459	-0.38204283	1.4874518	-2.4405787	-0.8590527	0.36656868	-0.08423314	-2.4354064	0.32638934	1.2135834	-1.7285413	2.6244087	-0.08084009	-0.05651571	0.76871955	1.0735462	-0.27193397	-1.8879641	1.2064725	0.79179114	-1.05501	-0.6125817	1.0345207	-0.14817561	-0.5417599	-1.6155258	0.55830574	-0.7140321	-3.2949748	3.851155	-1.6425102	0.029788028	0.07128889	-1.1412237	-1.1953057	-1.3695871	-0.9642311	-1.2533457	-1.8288277	-1.043481	0.046342984	0.73198146	0.85870975	0.26239988	-0.031028057	2.4411774	-2.27549	0.5576409	-0.08388075	-1.433997	-0.9105523	-0.59494245	-1.3763582	-0.076768026	0.29112732	0.77763695	2.1085742\n-1.4418944	0.058159303	0.45487848	0.8517523	0.1242125	1.8133973	0.9993857	-0.6592612	-0.96562815	-0.7944501	1.414916	0.1194493	2.736172	-1.5834824	0.47290787	-3.7588875	-0.1713883	-0.65140563	1.6362242	1.0077306	0.23677018	-1.7545246	1.5162991	-1.0908425	-0.7685213	0.89768636	-0.039455343	1.6279851	-3.1732616	0.762408	-1.0269893	1.916824	0.6206209	0.5771282	-0.5014122	-1.2682849	0.337036	-0.36764547	1.786176	-0.80599606	-2.6106806	0.755433	2.1169488	-0.95678365	-2.0016658	-1.1567545	-1.2437184	-0.41653267	2.098874	-0.1448947	2.5747151	0.07721174	1.6632493	-2.7500467	-0.21776219	-0.07379022	-1.6097919	-0.42928407	-1.3333453	0.64008266	0.11892504	1.8315284	-0.40125373	-1.1441895\n-2.9623497	0.08651724	1.3558487	1.9656305	1.382626	0.98183495	1.0508238	2.2743738	-1.0005459	-0.04975182	-0.08970189	-1.7607081	1.504297	1.0887662	1.0217822	-0.63252026	-2.4910789	0.49084294	0.42453447	-1.282842	-1.2143129	-0.20710993	-1.5185171	1.9092779	1.2249262	-0.2683144	-1.2197562	0.919624	1.3361932	1.8016516	0.18822503	-0.80567414	-1.7220982	-2.4548683	-2.0998485	0.39302686	-0.98767763	-0.6244613	0.7351242	0.3830369	0.09361237	-1.8671844	2.7125373	-0.16707058	-2.0521252	-1.8825781	0.45024183	-2.16342	0.3976965	-0.16372882	-0.89648795	-0.7600927	-0.52467793	0.21407181	0.5779995	-0.3318744	-1.0839753	-0.5865825	0.35822144	1.3567501	-1.4975882	2.428115	0.90708137	-1.837401\n-2.9384818	-0.35999325	-0.46238685	-3.4780142	1.4854772	0.36153215	-0.5530436	-0.5733026	0.17553125	2.4891336	-1.1788677	1.8280809	2.1116471	2.300526	-1.5222743	-1.4188055	-3.044227	0.7917085	-1.9178457	0.6928495	1.0586902	0.3237073	0.42468125	-1.5978328	1.2827059	-2.4910605	-0.84002227	0.2252455	0.24591808	1.9497842	0.9260682	0.43146873	-1.6107945	-1.9012814	2.3009996	0.25376	0.4318027	0.25107306	1.940014	1.0490737	0.2820379	0.35706678	0.6835635	1.8270056	1.3373501	-3.143155	0.6325666	-1.0071026	0.5245439	0.39589658	-2.2032566	0.14346513	0.66680896	2.2108467	2.438532	-0.90807736	0.09881402	1.5920532	-2.6379352	-0.308043	-1.7924985	0.28714648	-0.6209881	0.41616833\n-1.7789317	2.0290377	-0.45944613	0.6818769	-1.7843745	-1.2457148	2.2714806	0.9455675	0.29501763	-0.20126584	0.875479	0.5364239	-1.393599	1.0350685	-0.20585833	-2.091086	3.0776427	0.83348995	-0.36223376	1.454363	1.0267117	1.3098675	0.6004124	0.13969333	3.4844472	0.61301506	0.8060714	-1.078753	-0.05690222	-0.52759665	0.24569055	-0.12413774	-0.64753056	-1.654179	1.171253	-2.952023	-1.4081706	-1.857941	-1.2483376	0.196931	0.3742883	-0.096446194	-1.5550438	0.30006883	-2.4674857	-2.0297	-0.2975033	-1.0375262	0.34830013	-1.4578133	0.72489965	-1.0302038	0.29949012	-1.4532208	2.17151	-0.09874131	-0.7462945	0.8757234	-0.088954404	1.5915276	-1.1187292	-0.96570474	0.41853917	-1.953819\n0.24141121	0.61483943	-0.58576596	-0.020803131	-0.34856388	0.12800306	-0.9510265	1.3927509	1.8867483	0.49831495	0.14342836	0.8122032	-1.4671181	0.27804765	1.6428163	0.03159324	-0.89284706	-0.16698352	0.817434	-2.3538697	0.5056052	-2.1681123	-2.0479424	-0.75058377	-2.522955	-1.2287568	0.09502192	-1.3330677	0.7550108	-0.55255675	-2.6834857	-0.20820807	-0.013590172	-0.13083626	-2.1954086	3.0542805	0.9215928	-0.23838691	3.5253448	1.8327128	1.4739394	-0.24789894	2.5088735	0.99766374	1.5502335	0.37178206	2.5770805	-1.3082072	1.2185975	-2.6021805	-2.2814424	1.392165	-1.4031467	2.956391	-0.028995547	0.68714786	0.08772853	-1.9367194	0.7365292	-0.29074764	-1.5279486	-1.3970996	1.6013062	3.0512445\n2.050623	0.50747114	-0.27398166	0.059910618	1.9211305	-3.8993878	-0.7788427	-0.5343818	0.57436985	1.0298749	0.8027699	-0.5303286	1.0122874	-2.5274746	-2.9328842	1.6314267	-0.49931264	-1.3963896	1.1984061	1.9487182	0.40986273	2.0492938	1.7347655	0.21387455	0.56208557	-0.70012593	-2.8803236	-1.9201547	-2.2780194	0.6712684	-1.0699117	-1.6259927	-0.15833633	0.65462697	1.4293135	-0.5153949	0.029958377	-0.73083824	0.23114061	1.5440845	-2.3549213	1.9531584	-0.46498832	0.37454918	-0.19574109	3.8111422	0.3977867	2.5413265	-1.2295395	0.1894016	-2.1502168	0.9722882	-0.7979426	-0.5379248	-2.606867	0.6225223	-1.1196346	-2.0548449	-0.8419072	-0.17198	-1.6153207	-0.6544869	0.9520568	0.94528764\n-1.4852891	1.32323	0.19465351	3.1247904	0.59030324	-0.80424434	0.7093023	1.7837147	1.8998103	3.530034	1.870542	1.6089162	0.7525805	-1.9652119	3.4472823	-2.010494	2.3244126	-2.3913014	-0.9003688	-0.6006225	2.1830194	1.3080361	-0.52974206	3.0527508	-1.5584139	-0.48598346	1.4403869	-1.6010528	-1.3055736	0.1568737	0.17840719	1.0052466	-1.0573648	-0.13355225	0.84805036	1.37247	-0.83057296	2.4340045	-0.6836616	1.6147364	-1.2073636	-0.9847023	-1.6717224	-0.18071744	1.8002793	1.9912889	-0.7738842	-0.4486252	4.766066	-0.2492556	-0.6841892	-1.0999888	-0.8559263	2.511135	-0.42281163	0.4676887	0.37143862	-0.72867024	1.0653393	0.18519871	-1.3423147	1.2505393	-0.52610797	0.40465888\n1.4542686	-0.02915488	-0.8434892	-0.12588236	0.48885843	2.2528203	1.2645077	-1.7953326	1.0513366	0.6942837	-0.29584494	-0.8686556	1.8002288	-1.3584127	1.1275502	1.9965354	2.0625741	1.6672692	-1.3605258	0.85084206	0.32591155	-2.385892	0.22926834	-3.2666116	-1.2590604	0.72357124	1.2301707	0.30518073	-1.9409822	-1.1526582	1.5631329	-0.9487566	1.1290933	0.8577251	-3.3943675	2.2068863	-0.83403057	1.0091248	-0.6267135	0.37068608	0.29942262	0.1126704	0.3120801	-0.63519514	0.28478894	-1.0216967	-0.0139781395	0.9796721	-0.90612507	0.6334848	0.31679228	-1.0104663	0.32299015	-0.4107615	4.267226	-2.2175295	-1.8099402	1.082573	-0.6646461	2.1920562	-2.4090164	-0.10989271	-0.030758176	-1.561379\n-0.063280605	3.0607827	-0.011131402	0.12607852	-0.8280614	0.8471644	-3.4224303	-0.95315886	0.03540675	-1.2556598	-2.07206	0.16501246	1.5218008	0.5481624	0.43292552	1.0647757	0.18988746	0.19570105	-0.25093263	-0.23801889	-2.3606977	-1.6171248	-0.69627166	0.1432246	-0.2617653	-0.26864362	-1.5014749	1.6890951	0.36755654	-0.8009414	0.12220699	0.7250721	2.3561122	-1.0262717	0.15798059	1.4254721	0.7449659	-1.0874175	-2.2522883	0.12693366	0.91528904	1.7272354	-0.821854	-2.2739143	0.4879345	1.0341392	0.45586655	1.1026151	0.36119556	0.180789	-0.76391757	-0.06383117	-0.9583901	0.36743918	-1.1788117	0.83917534	-0.61324483	-1.1696056	-0.37637734	2.70457	-0.6466799	1.8791378	-2.0362945	-0.6638466\n-0.4770122	-0.8416192	2.2682712	-2.4963114	-0.85519964	1.5994086	-1.461325	-0.631478	1.6075767	-1.1473129	-1.2115482	-0.8897727	2.6809132	-0.5545962	0.024897177	-0.6680847	2.374556	-0.7490279	0.81247836	-0.04544905	1.037163	0.25948092	-0.3891673	-1.1853282	-0.36178538	1.5711212	0.8865043	1.7302663	0.17245983	-1.6660314	2.5541155	-0.73439306	0.31032354	-1.4940678	1.1113199	-0.80016536	0.3605452	-0.40084168	-0.9774728	0.59559816	0.23965442	-0.30568108	-1.6329978	0.08042607	3.5242586	-1.1652676	-0.46989697	1.1291851	1.4175947	0.8450148	0.17039192	-0.9914162	2.389087	0.09790534	1.3603753	1.5700854	0.7350058	-0.44731137	1.9145576	0.22409493	-1.234528	1.1928267	-1.2331408	1.0578085\n1.8316501	0.6659405	1.6733798	-0.96252674	1.1042463	1.0818648	0.4718847	1.8707881	-1.874185	1.382098	1.4260229	-1.5705042	0.1335142	1.3183808	-0.60843647	-0.7839531	1.0311044	0.27788135	0.1094001	1.937382	-0.22776002	1.585564	0.056274623	0.7496373	1.7761052	0.9871169	-1.8047125	-2.3132977	0.17298956	1.4924062	-1.2751502	-0.3094439	-1.0053937	-1.1885656	0.9280723	0.33693364	-0.74268514	-1.2820898	0.47744474	-0.4335281	0.9124433	-1.5238466	-0.4974558	-0.4867354	1.1320112	-0.5011189	0.82123274	0.37437975	-0.03604345	0.37160006	0.8679173	0.35420442	1.5318288	-0.18500239	-0.7040501	1.324292	-1.4772472	-0.6842013	-0.5788853	0.14772435	-0.07006111	-1.677324	-1.0292662	-2.150943\n-1.069532	1.715116	1.6454707	-0.29068017	1.21237	-0.4546226	-1.4638534	1.9072299	1.9477189	-0.8289717	-0.034514785	0.37685925	-0.051730704	0.3554754	1.1802669	3.0999393	2.6229918	1.3070598	0.58061534	1.8823394	0.7565357	0.12984417	0.8042082	-1.9084725	-0.6077078	0.35020003	2.207889	-0.74919915	-3.970074	3.227504	0.36629716	1.2499305	-1.0179956	-0.06530957	0.4001266	0.9465573	0.397483	1.3614621	2.132046	-0.93863934	-2.507195	-0.018564956	0.71082455	0.5457923	0.23391701	-1.3583369	-0.71127766	1.7124697	-0.7660723	0.3728747	1.6022761	-1.6070632	-0.63967115	-0.23207219	-0.6013412	0.16961536	-1.5743623	-1.8706486	-0.060665052	1.0253137	0.38969305	0.27493155	2.3785753	0.71993977\n-0.64432126	0.49416822	-0.04744525	-2.6875176	-1.1908761	-0.13827677	-0.5949076	1.508583	1.0046322	1.2951491	1.7497456	-0.3239415	0.54271674	-0.4344604	0.7709375	-0.42252973	-1.2060167	-1.1899773	0.012742538	-1.8704876	-1.4429134	0.85322905	-0.50613856	1.8532633	2.6614053	1.2033145	-2.783139	-0.8312977	0.87839526	-1.0737808	-0.5795923	2.5239015	-0.10093238	1.1860504	-3.42707	-0.21019702	-0.57498026	-0.42883778	1.3797888	0.5732821	1.043933	1.296605	-1.4107718	-0.9932175	-2.0631707	0.4002063	3.661427	1.1884391	0.3653148	-0.8549919	-1.1256391	2.0560079	1.2906523	-2.394114	-2.043995	1.6815174	0.18509853	0.6117105	-0.89794654	1.6560518	1.4126891	-0.52426183	-0.35252005	-0.20077546\n1.5992378	0.269275	2.5830705	2.1899362	1.110021	-0.1507826	2.4992204	1.2560873	-1.9826026	0.035364594	1.241372	-0.76015633	-1.0095068	-0.28660503	0.45851046	-0.448819	-0.22753763	-0.98218524	1.0640858	0.99802685	1.2812202	-1.8113742	-1.7441808	1.0688035	1.306273	0.93491244	0.52545935	-1.1670858	0.38225976	0.67140883	-2.3151546	-1.837315	-0.81656355	0.65894115	1.2381113	0.28443578	2.9520252	0.9086506	0.8645696	-1.1942546	-0.3848599	2.0119154	-0.43594956	-0.2919188	-0.7767886	0.17554781	-3.0426514	-1.0808786	-1.0785254	-0.39363983	-0.9756862	-2.7308245	-0.49991414	1.8322849	1.9508574	0.27140832	-0.7232285	-3.2543554	1.227406	-0.37431958	-1.1128672	-0.14855893	-1.2808437	1.6536453\n-2.8138921	-2.1785936	0.3100724	1.7305005	1.9094048	0.12056628	0.04414935	0.947855	-1.9443691	0.66844743	-1.7306159	0.5382725	0.92298055	-1.9140522	1.1494924	-1.1390133	0.3674125	2.2239468	0.5567157	-0.80194473	0.082807	-2.010103	-0.84855235	-0.26234517	2.5817146	-0.91147834	0.05000815	0.624061	0.5233463	-1.362458	-1.2267872	-3.2906373	-2.1155117	-0.38768497	-0.33415577	-0.1142082	-2.3982275	-0.7916583	1.1841334	0.59225583	2.5159118	-2.3974578	-0.0002370839	0.9263975	1.6276971	-0.58883405	0.48775867	0.47249162	0.32680708	-3.724852	-1.0251842	0.15644988	-0.78658396	-0.016600009	0.5878789	0.863013	-0.6891264	1.1251144	-0.82662296	-0.026165156	0.06739886	0.594706	0.6791049	-0.8668741\n-0.112196594	2.2548847	-0.2876665	-3.0015767	0.9497801	0.54967546	-0.7608857	-3.546661	-0.23771372	-0.09137056	0.10427647	-0.6906507	-0.7234931	0.5525685	-0.06172904	-1.1121079	4.393767	-0.220662	2.594799	0.14050803	-0.8394284	0.34539217	-1.2378688	-0.43479353	0.1982084	1.0085225	0.25271705	-0.29870677	-2.7365935	-0.10238453	2.4981117	0.19639225	-0.8066005	0.91030246	-1.0778916	-0.24929024	-1.064451	-2.073121	0.9290022	0.16128038	1.5183866	-2.9462924	0.2117257	1.302406	1.1452942	-0.059536684	0.8743691	-1.2218478	-1.2294103	0.6802325	0.87396675	-3.6262145	0.7533346	-0.022188624	-4.433444	2.0650284	1.1964108	0.056620363	1.4758687	-0.55964965	1.275305	-2.265007	1.2756296	1.4677799\n0.60791534	-0.73235655	-2.1138692	0.9009745	-1.71895	3.150608	-1.3072094	-2.0803404	-1.4461331	0.66383094	2.2880845	2.419688	-2.212861	0.01465562	-0.8883742	0.5847718	-0.7341319	-0.5455609	1.3449657	0.7949405	-0.7137647	-0.7584266	-0.7243369	3.2854216	0.54330635	0.14564845	0.012916623	-0.82188207	-0.790572	1.1201141	-1.4177638	0.32058203	1.1095437	0.5493625	-1.9356622	-0.695643	3.2955608	-1.3728575	0.38377228	-1.8289433	-2.2871306	0.051021043	1.0308576	0.65103334	1.2160698	1.4673394	0.025948681	0.5741915	0.7923906	1.490018	1.7240747	0.03687636	2.65556	1.8113587	-0.71177125	-0.1830358	1.0305206	-1.8542275	0.64202	0.43879536	-1.0039612	0.28500828	0.8666088	1.2341821\n-2.6391265	0.7359344	2.8927708	-0.9193456	1.8309935	-1.2869211	1.5382674	-1.8870298	-1.4905965	1.8937616	1.0533828	0.7676771	1.6678656	-0.35884497	-1.6239922	0.44055176	-1.3947549	-1.4956279	1.7215006	1.6461501	-1.3164972	-0.44375843	1.8272438	-1.5696646	1.1216595	-0.81226116	0.7335732	1.7927402	-0.16177948	-1.681572	-0.16930477	1.1927967	2.9115815	0.46487534	0.26213932	0.48532507	-0.14425032	0.5525846	2.233978	1.0200204	0.0812651	1.510015	0.6346731	-0.0952555	0.83485526	1.6455172	-0.244023	2.550441	2.1678157	2.0838044	-0.02348091	-2.4407072	2.7705445	-1.1237397	-2.0761755	2.990869	-1.1728553	-2.2385325	-0.28147295	0.8439837	-1.5871676	-0.36583918	0.45310816	-1.3742708\n-1.567919	1.7412457	-0.3687664	-0.63071537	-0.6926374	-0.26630253	-0.33167115	-1.5065707	1.9063317	-1.5496184	-3.3877563	2.7103107	0.976147	0.28015468	0.06530818	-1.3204134	-1.1508442	0.5390189	-0.050599497	-0.82882744	1.2929599	-2.026171	0.18742438	-0.8913776	-0.8284486	-3.454841	-1.3296971	-1.6702722	-0.72434855	0.14296784	2.556988	-1.6379877	-3.5740929	0.09783189	-1.8870127	-1.2872092	0.9999979	-0.8398809	-1.4773655	1.973552	0.7479981	-2.7068906	0.7157491	-0.9370808	2.8401973	0.4644461	0.098963834	1.2518635	-0.06265111	-2.2932272	-2.977948	2.9185102	0.09901502	-2.2634745	-1.4868547	1.1500599	1.2190205	0.8691314	0.24017796	2.382731	-1.2562	3.2830486	1.3461099	0.33244336\n-0.6436512	-0.56164664	-0.6517652	0.22137316	0.7662681	1.676201	0.89081675	1.9247096	-1.0925068	-1.0852627	1.9705744	0.34688646	1.2520188	0.14987427	-2.192088	-0.14777292	-0.74603367	-0.1804325	1.6418966	2.513043	-0.8490479	1.4813547	0.4428428	0.76608944	1.5587956	-0.02238001	1.9697139	-0.7197803	0.06633829	-4.180701	1.2729781	-1.3306702	2.4392066	-2.9094565	1.5492829	-0.2596627	-2.2982857	1.3265672	0.8917637	2.4191523	1.0741707	-1.4728098	0.8460516	2.4099655	0.5283859	-0.99879044	-0.4446632	0.9145966	1.7702193	2.3865	0.24235734	3.5028107	-2.8430138	-2.7050278	-0.43640813	2.517013	-0.6430421	0.13997237	-1.207614	-1.4161302	-1.3239009	0.08649256	-1.001266	0.5723852\n0.8126406	-0.4256203	-0.16450028	2.301852	1.4533368	0.09485741	0.2676029	-2.668008	-1.9063712	-0.23453388	-0.8607238	0.09952654	0.5252415	1.6905444	-0.07562249	-0.49307293	-0.07544168	-2.196864	1.486375	0.83019173	0.8696431	-1.7622119	-1.2645824	-0.28103158	2.9698794	-0.3618457	-0.1958659	1.0695143	-0.05963213	-2.2718542	-1.109476	-0.38287425	0.11759915	-0.41378063	0.86403364	2.8319721	-0.87008595	-0.36158356	1.3498499	-0.46216556	0.88162637	-2.0272152	0.55984765	-0.4518268	0.08142138	1.7085046	2.063534	-0.8472495	0.71563995	1.5276364	0.26550126	0.14927498	-1.0084027	2.575615	3.2465231	0.66899806	0.66337705	0.507298	-1.1722746	1.5924528	0.79112583	-0.5982478	-2.4860427	0.18459485\n-0.6051081	-0.9856478	1.5461925	-0.9418289	3.0334244	1.0835634	-1.5039153	3.3280077	-1.593887	-0.7022608	-0.37806672	0.13798775	0.52812856	1.3703398	-0.3940377	-0.161829	-2.7234092	-4.0029078	1.2325915	0.39392588	0.7966781	-1.0761555	-0.470867	0.66101867	1.663188	0.7945841	0.44829753	-1.3350763	2.3291805	0.7256868	1.6139027	-0.65944326	0.3164341	-0.2746704	0.9009612	0.2514094	-3.903313	-2.482252	0.8531286	-2.360317	1.2859449	-0.71462816	0.9991937	-0.2600278	-0.28184897	1.8247445	-1.1654532	0.6559255	0.46778846	-1.4103535	2.0975635	-0.5988935	-1.3433539	-1.4237652	-1.5131937	-0.26339874	-1.6867714	1.7459391	-2.5619822	-1.3927696	0.29225913	-2.036199	0.49605483	0.94984996\n-2.7260616	0.5799705	0.8401397	-0.7733788	-0.2015172	-0.23923703	-2.7497005	-1.1315722	1.4084888	-0.42400125	-1.2400845	-1.2041546	-0.32631132	3.246084	-1.2764971	-1.2776294	1.173483	2.138055	-0.26876035	-0.047405407	0.66910064	0.42171475	1.035534	-0.79888844	0.8233603	-1.3312328	1.1377307	-2.606604	-1.2970974	1.8765943	0.6599024	-0.5166642	1.7993855	0.40629953	0.39828902	-2.0009522	-0.7060226	0.53377956	-1.5803843	-0.42743272	1.0457318	0.2505933	-1.0181661	2.4589448	0.35198662	0.66807467	-1.8351243	-0.13854815	-1.0568647	-1.0883316	0.18333082	1.1601063	-0.27183044	-1.3636143	-0.5669881	0.69993955	-1.6148689	0.27759013	-0.10794656	-0.33141848	1.2475806	-0.52542037	-0.3231785	3.219324\n-1.3924763	-0.60880554	1.737421	1.3007027	-0.48219633	1.0340307	0.5471485	1.9372143	0.61331546	-1.5798303	1.0178552	-0.6922424	-0.39504457	-1.9218848	-2.1476834	-1.9305825	0.57703316	2.1172688	0.091598466	4.0157127	-0.7900632	1.1956633	-0.61152923	-0.86471397	-0.8902456	-2.3428035	-0.17192574	0.96339273	-0.12636751	-1.1830982	2.3283398	2.3735516	0.056722634	-1.2753406	1.8802813	-0.80857015	1.3293806	2.029514	-0.09007257	-0.10729518	-1.562075	-0.7089276	-2.3690617	-3.4697535	2.4259372	0.043723498	-2.648762	-2.3632467	1.48574	1.8923547	1.4863503	2.3857262	-0.8042362	-2.9963527	-0.11850616	0.9462889	-2.773128	0.7322984	-0.56992626	-0.080594726	2.2033532	-1.2690245	-0.122616455	-1.3850355\n1.2816072	0.7619604	-0.48535293	0.41462195	2.9010687	-0.20600975	-1.510787	0.24133989	1.9229441	2.1253133	-0.3831361	-0.5296656	1.5661048	0.8501575	0.50907457	0.09774546	1.7825425	1.7704241	-0.5562187	0.1907019	-2.5462148	0.13653468	0.0043194196	-0.9523915	-0.09696187	0.36014667	1.7946877	1.0389847	-1.1928397	0.45120493	-1.733621	0.49096665	0.84040934	-0.57700074	-0.022328543	0.23313646	-1.7015625	-1.5821204	-2.4174347	-1.2120725	1.4969771	2.1190948	-1.2954619	0.7108653	-0.21501648	1.8842503	-2.9781642	1.6814725	-0.17346169	1.7910656	-0.29141155	0.00011513081	1.4239619	-0.10659653	-0.577339	2.053161	-2.4236948	4.0734773	0.24134861	-1.2003344	3.272254	1.2025589	0.9703342	-0.045958303\n2.6990104	0.44965416	-0.36404696	0.36753866	-0.4185056	-0.8620015	1.157583	-1.7084436	0.3733736	-2.4537048	2.1739457	1.7089655	-1.4176526	1.1726955	1.549355	-0.49278945	-0.7126857	1.2627271	-0.79064274	0.16094193	-2.5048468	1.2638435	1.9151571	0.9607646	1.4496713	0.8880561	1.1150836	1.0529537	0.17435206	1.6389945	0.073010996	-0.25833866	-0.0979131	1.1504431	0.07581442	-0.7810501	1.5283667	0.040319633	0.07182937	1.6957697	-0.27451155	-0.40266573	-1.6298532	1.7111666	-1.1728791	1.0079212	-0.004474121	-1.7053891	0.59625137	-0.75806856	2.252369	-0.45237032	-0.79243374	-2.7556937	-3.4493506	0.3578821	-1.0867903	-1.6302024	-2.7938423	0.54423517	-1.6454624	0.6218155	1.3940494	-0.9283927\n0.60159063	-0.303148	-0.13306426	-2.414628	-0.34731704	-1.0565569	0.36367023	-1.8692912	-0.35242623	0.40647107	1.8784962	1.8865503	-0.5741877	1.2055745	0.13490933	-1.5961047	0.80274624	-0.42494747	-2.3762817	-0.2769561	1.0608153	-0.15665944	-0.7085635	3.3154776	-0.8641167	-0.19554922	-0.81935114	-1.3555357	1.3386551	0.15701677	0.531124	0.18637237	0.278235	1.7476028	-0.96245545	-0.41827735	1.9837073	0.3010634	2.8968422	-0.2813893	-1.3344936	-0.34906277	0.66667265	1.3432621	1.6737161	-1.3172737	-0.99199826	-2.5084841	0.81744075	0.051936746	-1.4656159	-1.0365573	3.2745688	0.5178907	1.4456942	1.5110345	-1.033762	0.5678673	-0.98468095	-2.113706	1.1322074	-1.5890961	1.4344251	-2.919641\n1.710129	-0.31318942	-0.50077343	0.38322553	2.7106543	-0.03128032	1.0698166	1.7643287	-0.481727	1.7747144	0.070706934	-0.31420982	1.6627378	-1.106269	-0.5069864	-1.7707105	-1.3771516	2.7713974	-2.1915567	3.3108714	-1.9790791	2.1857674	1.201379	-0.6595293	-0.2670285	-0.39512968	-2.335795	0.82252824	-0.46106565	0.7247609	-1.4702184	1.3167359	2.043758	-0.40214986	-1.6117529	1.8653598	0.26582626	-1.00276	1.609982	-0.29154205	-0.079429165	-0.45941806	-0.07126641	0.54029477	-0.8828329	-1.1301945	0.9509817	-1.1845415	-1.351545	-2.6063976	0.39526683	-2.3022318	0.4510606	-2.2327147	1.2024794	0.728423	0.5476705	-0.6101115	0.06987786	-1.7651088	-1.7495064	-0.15072656	-0.49452847	-1.0472082\n0.14261337	-0.859413	-0.40381375	-0.27688268	0.35197777	1.1681089	2.597211	-0.07905392	-0.4685457	-2.5682788	-0.2161028	2.6013064	-0.12873246	2.490633	-0.027272627	1.4990907	1.1318527	2.4666262	0.061037477	0.18741982	-1.6660129	-0.17935906	0.25202984	-0.7181875	-0.044014875	-0.13580397	-1.3805947	2.3907948	0.61511207	1.729518	1.0101023	1.2112876	0.69888026	-0.27220583	-1.1683214	1.3687238	1.8633908	-1.9158946	1.6975611	1.1205544	-2.1123252	-0.56106037	1.5938631	-0.21048418	-0.6813367	-0.58606684	-0.8359811	0.90301025	-0.52787894	-0.4501744	0.52392745	-1.3143789	-0.947212	-1.8424587	3.6803207	1.4045775	1.2602015	-2.2147686	0.6936606	-2.491019	-0.19833444	-0.47083738	-0.73095393	0.17104621\n0.76847535	0.931251	0.2682085	-0.24951841	-0.4357334	0.91834086	-0.4130272	1.3859551	-0.37620986	-2.0306067	0.28190365	0.42522186	-0.07160618	0.57264954	-1.5518488	-1.8367004	-1.2187037	-1.5636998	-2.5716708	-0.8416242	0.42163894	-0.8111059	1.3909216	-3.688439	-1.230137	0.4804687	-0.42531818	-2.1441765	0.8969145	-2.1322181	-0.4753933	0.93050873	-0.44625703	0.35639468	0.7863094	-0.5597452	-2.838414	1.6724057	1.0712917	-0.31790435	-0.7410181	-0.45628825	0.49892646	1.0882331	-0.82971793	-1.18078	0.13692856	-0.13912138	1.883963	0.06403339	-1.6786858	-0.64569765	-0.69396174	0.69715524	-0.54027843	2.2106998	-0.28731975	0.99375176	1.861845	-0.35934058	-0.36559793	-3.0110996	-1.7202342	1.1273082\n-1.2957354	-1.5535656	-1.3173808	-0.6508822	0.48945352	1.3778987	-0.5165995	-1.5559477	-2.023572	1.3529245	-1.643817	1.5511836	-3.7528312	-0.2560173	-0.43093547	-1.7706163	1.1954538	-1.1050576	0.059924033	0.81311303	-1.0028698	-1.2427726	3.1846883	2.9187398	0.6737095	0.87524736	-0.32206666	1.158033	-0.056574352	-0.09927695	2.240029	0.77889764	-2.0577106	-0.93419856	0.8225035	-0.8039788	-3.628981	0.367804	0.4166783	-0.7911127	-1.1191057	-2.4784286	-0.7224266	0.47148478	-1.1491262	3.1630197	1.9134059	-2.0960383	0.14495811	-0.5295259	4.358061	-0.13894731	0.17397101	-0.36472067	-0.5050475	1.0172291	2.411618	-0.038491536	-1.9740261	2.1254706	-2.550096	0.730966	3.3016188	-1.6122208\n0.70081335	-0.482634	-1.063408	1.2525945	1.6319103	0.88007444	-0.28867248	-0.4465395	2.6083705	0.7039652	1.6907989	-0.1280273	-0.72154456	-1.4307103	0.6366269	-1.8087159	0.03833042	-1.0133334	1.28051	1.3954449	-2.2482157	2.35557	-0.16650108	0.78382283	0.6202988	0.2875337	0.8892807	-0.9999456	-0.118194334	0.25432616	1.0272791	-0.95976543	-2.5934527	-0.10370733	-0.9298341	-1.536822	1.386894	0.12501372	2.239041	1.0199922	2.4784763	-1.4756286	-0.95138407	-2.0147808	2.109801	1.1053466	-0.3203171	3.5740907	-0.67754	2.2973087	-0.71830136	-0.98428106	-1.5672506	0.52667284	1.1655524	-0.850373	0.13559844	-0.07632645	0.69470906	3.507306	-1.6167418	-1.5966755	-1.2816968	-0.49735397\n-1.1443216	-0.03465509	-0.85728693	-1.2733762	-1.1634226	0.23796086	1.5284657	-0.7227278	1.2811428	1.4226471	-0.05516976	-0.49912354	0.92808354	-0.816487	-1.0279284	-0.9898737	-1.2386303	0.74768096	-2.7088337	-1.3438181	-0.33964097	0.82262546	1.8550999	1.9244685	-1.3488055	-1.3972391	2.6643517	0.19482169	2.0392754	1.5797727	2.5231664	0.24927042	0.21234766	-0.9684603	-0.0769368	2.1567776	0.76945764	-3.0575783	-1.091882	0.3757055	-0.86117977	0.6384546	-0.67620367	0.24590886	-0.22010949	-1.3134825	1.1876649	-1.9710999	0.8250002	-1.7082627	2.1402547	-2.097232	1.1362082	0.2075656	2.261079	-1.975198	0.32303596	-0.790809	1.3212646	-2.430914	-1.7449204	0.12591498	1.6692553	-2.48487\n3.1109273	-0.37002638	0.5330899	-0.8546993	-2.703457	-2.408091	-0.66612536	0.9165062	-0.98945194	2.9217477	-0.855486	-0.12740166	0.64895624	0.876339	-1.9325504	-1.5171353	-2.249255	0.8459361	-0.8014324	1.0819427	1.6875715	-0.6387461	-0.030938381	0.36251843	-1.1584712	-0.80580324	2.3969564	1.4460287	-1.8352743	0.74229825	0.57471323	1.5121043	-1.8050246	-0.8898308	1.9662205	-0.3479963	-1.3552935	1.1769949	0.092967704	1.7457421	0.91496646	-0.52334857	1.3147496	3.1824079	-3.1192238	2.9092195	1.2513115	-0.55140126	1.3283899	-2.1018012	-1.6146961	-1.1916244	-0.11149859	-0.72710705	0.3291269	-0.8319771	-0.08565609	-0.3250529	0.0820923	1.4245267	3.4992375	1.5457944	2.6541004	1.3029046\n1.1099564	0.3173179	-0.13305776	1.2814322	-2.6149848	2.3460526	-0.46382326	0.03043669	0.77064365	-1.2070607	-2.394381	-2.1847522	-0.6308908	-1.5359018	1.3767911	1.689843	-0.33379418	2.369883	0.1692842	0.78995335	-2.4533074	-0.61145043	-2.6016579	0.82666713	-1.0359163	1.033203	-1.0972698	0.46261016	1.9837734	0.12587303	1.8656509	-1.6909857	-1.2038165	0.31241935	0.2344496	0.42862675	-0.9388784	-1.2456454	-1.8640558	0.105798855	-0.45117941	0.080271356	3.5036376	-0.32229868	0.61987853	0.28160244	1.29765	0.059868753	0.078433685	0.5891929	-1.2660171	-3.2219496	1.2343777	0.1741392	1.0644369	0.4042947	-0.8040012	0.71216315	1.4898981	0.95227104	-0.33982342	1.2042263	-1.5887386	-1.1061456\n-0.2956053	2.2342877	0.28071433	1.8416809	-1.62749	1.300555	-2.798419	0.063988134	2.9183629	-1.3825567	1.0224313	0.7424397	-1.4372668	-0.96273834	0.47952786	-0.30092806	0.82939273	-0.76897717	0.7267084	-0.2825599	0.21605337	-2.1445394	-0.9401927	1.8618329	-2.2182443	-0.47266737	1.5116351	1.827744	0.6199751	2.8968139	0.3527035	-1.1191452	0.48294532	-2.177996	-2.0092058	0.057187	0.7063392	-0.40625137	1.4659712	-0.7869954	-3.634007	0.684365	1.0327607	0.4915059	-0.91850424	-0.56697756	-0.2953358	0.27124536	2.2876866	0.49280944	1.3890165	-0.64022374	0.5146351	-0.16228417	-0.805095	2.317235	-0.6625346	-2.0611014	-1.9854552	-2.11076	2.6834137	0.6611527	0.6075663	2.7076142\n-2.0787895	-0.39261025	1.2123684	0.025598949	0.3640947	-1.256548	0.30658743	1.223688	1.0601691	1.124404	0.2604208	2.2171364	-0.81418294	0.12578702	0.9297717	-0.5606546	-0.7547989	-1.2775786	-0.98772687	0.96369314	3.7410443	-1.1928049	-1.085058	-0.17271997	-1.7704005	-1.9361008	1.2638823	1.9497437	0.9631992	-0.029991698	1.74425	-1.6758888	-0.26446334	0.80552816	-0.6849517	-1.8460022	-0.99493057	0.4435104	-1.5461962	-0.21391934	1.1036481	-3.6379483	0.32293773	-2.495646	-0.49243578	0.95731354	-0.656987	1.8151499	-2.4698825	-0.37729898	-2.720275	0.08444887	0.085929185	0.4749198	-0.33455434	-1.0470772	-0.33128312	-1.6467445	-0.7321903	-1.892983	0.7965298	2.3387842	-0.42593375	-1.6763614\n3.1360226	1.4645104	1.6726025	-0.96535873	-1.8658458	1.6735528	-0.9382237	-0.6955999	1.0892311	-0.90412545	-1.2359939	0.8754876	-0.24929981	2.3527427	-2.2393827	-0.19959024	-0.62759316	-1.8088074	0.005307238	-0.38292664	-1.300708	0.78402746	1.3008626	-1.6270835	1.9877993	1.439636	2.7154434	0.18154548	-1.0667299	-1.1470153	-0.6614825	-0.9066593	1.7400334	-1.5842358	0.46362782	2.2329724	-1.4743243	-2.7167523	-0.52881306	-0.6729714	-1.7441026	0.8676218	-1.6944271	-0.9406045	1.1831661	-2.047414	-0.22398973	-1.6842976	0.87264174	1.9249082	-0.9703031	-0.040079046	-0.6202465	1.8298594	-0.9272076	-0.201935	-1.1955097	1.2924026	0.06345524	-2.1632874	-0.0067925737	1.2657567	-2.7120583	-0.16277269\n-0.79419994	-0.7978361	0.46452597	0.83966357	1.0837623	-0.52119035	1.8323992	3.2524054	-0.00869024	-0.8421172	1.4695847	1.6106716	-1.0701715	0.49931207	-2.291524	-1.5584342	-1.649129	0.05171925	0.2701369	0.0741634	-2.391341	0.21835461	0.053008046	-0.42696607	2.3136115	0.76398134	1.3726071	-1.3542427	-0.08663858	-0.3442427	-1.187061	1.0209554	0.22368702	-0.4092113	1.2029092	-2.011831	1.4356166	-0.7975979	-0.034283746	-0.020915283	-1.0363784	-0.62060314	-0.66621387	2.2906516	0.77358204	0.35749406	-2.6290574	1.4899223	0.26540533	-0.4150638	0.058512278	0.8209558	2.6064253	4.1041794	-1.2670609	-0.7303804	-0.011762855	-0.3351489	-1.2712941	-0.7528625	-3.0566561	0.7102358	-0.8526015	-0.25507003\n-0.7046676	0.24918233	1.1186272	0.7751681	-0.9604936	-2.1588092	-0.8859769	0.876308	0.07310225	-2.2429936	-3.0609477	0.5807436	-2.0240817	-0.6558898	-1.2593702	2.458973	-2.2098906	2.0516453	-2.7936776	-0.70854515	-0.51592547	-1.582034	-0.29717255	-1.3581364	1.0918221	-0.9317324	-0.9664858	2.1914737	1.338463	2.0062077	0.46680218	0.929595	0.75095487	0.2588458	-0.08653978	1.2704737	2.3529875	-2.46141	-2.2752612	1.439931	2.7373068	2.0562475	-2.4963202	0.67987627	-0.652574	-0.5146369	-1.2339803	-0.9228441	0.1323125	-0.29392466	0.1470134	-1.6387845	1.2304641	-0.3367153	-0.8585256	0.98738796	0.35498804	0.3993743	1.1996526	1.0383881	1.3046814	-0.64736044	-0.6885959	-0.6112932\n2.0346327	-1.335315	1.685664	0.20747478	2.569166	0.6084129	-2.675386	-0.6979462	-2.9010253	-2.003593	-0.6543384	2.079342	1.4805253	-0.18892075	4.039907	0.85945725	-1.4183158	-1.23496	-0.5996142	1.2886453	-0.5361297	-0.93185145	0.37927362	0.15898316	-2.9490218	-1.6998875	-0.9700452	-1.9675434	0.4427793	-2.9319925	2.1370938	0.8114436	0.5951077	0.3152273	0.1494421	-1.6892219	0.12879124	-0.87182915	0.8768965	0.063235365	1.7692173	-1.1634749	-1.0071379	1.1635634	-0.8697951	0.18864365	0.57434154	-0.2233123	-1.311823	-0.2625825	-0.86405295	-0.0672834	0.77510756	-2.2539132	1.1377374	-2.4120607	-0.25645745	0.85624593	-1.4344614	2.0835528	-3.3892674	-0.07646938	0.53774387	1.4763749\n0.5869677	2.3763752	1.6248926	-0.37089407	-1.7958657	-1.3917001	2.378985	0.318993	2.0134296	1.5095123	2.0484774	1.5026425	-1.2010177	-0.084956095	-0.92130154	0.1809373	2.2964036	-1.1060876	-0.2050704	0.20140047	1.3360945	-1.2320473	-3.843273	0.6096065	-1.1776072	1.3765293	1.8515792	2.6439416	-3.8111365	0.59175986	-0.22561331	0.32731667	-0.23598848	0.40121892	1.9860798	0.6796521	1.1123656	-0.6832875	-0.5565429	-3.3897285	-0.534548	-0.6645091	3.4682093	0.07178002	1.1453683	-0.07573981	-0.6369722	-1.365939	-1.9933909	-0.76264304	-0.28849533	1.6222205	0.08293423	-0.9491888	0.6286495	-0.3892606	-1.7816232	0.23312283	3.2480733	-1.745563	-1.8952501	2.1018834	1.0058703	-1.4285885\n0.12685494	0.5388705	-1.3476454	0.5503334	1.0190934	-0.7036871	2.5971248	0.17837107	0.41058975	0.27954403	0.93395936	0.23360795	0.059590954	1.8181025	1.1036407	0.77474475	1.7287357	0.4459475	0.41084817	-0.17447215	1.901147	0.3693946	-2.2391484	0.058673013	-0.014286455	1.8171129	-1.5031146	0.95479184	-1.1373458	1.516802	1.1942284	-0.53061396	-0.6731215	-0.3033026	0.15562473	0.39201695	1.5336946	0.33368438	2.612264	-3.294885	-0.50281185	0.5976998	1.605167	1.0951588	0.2584826	-0.123749375	0.76437604	-1.216863	1.8548123	2.2968452	-1.35171	-1.7348511	-2.0931027	1.9346894	-1.8993535	-1.317322	-1.1557479	0.7457839	2.5050642	-1.7351661	-0.78634644	0.0068978723	1.0582172	1.7312374\n-1.8995456	-0.21460575	1.5049797	0.70513	-2.893139	-1.2936842	-0.5581816	-1.318163	-4.44742	0.41867322	-1.9459417	0.9096185	-0.37331203	0.08652846	-0.3378302	-0.27566645	-1.5992354	0.35286072	1.4262987	-3.028245	0.48699778	-0.59198487	-1.5543756	-0.22726864	-2.0169942	0.5007195	-0.12120419	-0.87407213	-3.9964437	0.13238852	0.7858741	0.79029256	2.1415782	-2.7430453	-1.4540321	-0.8565385	-0.73105705	-1.7587116	1.2046165	-1.761644	1.5366669	1.2584426	2.09812	-1.4460398	-1.1457124	1.6097054	2.3370292	-2.74565	2.4709518	0.69008434	0.5330751	-0.37945962	-0.6175804	-1.5029194	1.4391524	-0.86308897	0.72856295	-0.23981543	2.1832025	1.6812776	-1.6931869	1.1354378	-1.5584283	-0.533698\n-1.5674272	0.033004258	-1.0844488	-0.38884443	0.67900544	0.41528833	0.6956171	0.43616208	-1.5207964	0.367939	0.98838013	1.6737738	-2.0633633	-1.2197809	-1.2423664	-2.157777	-1.3772528	0.44868553	-2.5349996	-1.1015432	-0.7204458	1.052126	-0.5474988	-2.482384	-0.6315289	-1.1987535	0.90954864	0.98115087	-0.6663606	1.4069242	-0.32919157	-0.6220818	1.878835	0.2991773	-0.52293015	-1.3078313	0.5993785	-1.4240878	-1.9322956	1.002522	-0.24205673	1.3024316	1.468115	2.076228	-0.33353388	-1.3377565	-0.6080575	0.076681286	-0.18462822	-2.0527601	-2.3635232	-0.25523376	-0.32706553	-0.7305337	-0.13542531	0.5131622	-1.0602721	-2.3634152	-1.7684208	-1.5734614	-0.8863982	1.8164413	1.6254382	-2.5118675\n-0.7976529	-0.379043	0.06462226	-0.56176025	-2.0022116	-0.9013442	-0.53903675	-1.6502423	-0.18916787	-0.38382044	-0.57719797	0.7724113	0.6137478	1.3264656	-0.37666085	2.0218952	1.1426693	-0.47774103	0.53473943	-0.4260602	1.2389735	-1.0985641	0.22253971	-1.6094544	0.33850828	1.0036092	-0.4700373	0.5912541	1.7362884	2.2814689	-0.39453506	-0.2006304	1.7062417	-0.5877706	-2.155021	0.44342265	-0.6240147	2.660087	0.6164152	-2.876416	-0.7149565	2.4336793	-0.32545552	1.6922916	0.9329777	0.42837262	0.96516556	1.887503	2.221926	0.22419216	0.81272304	0.52140975	-1.6890658	4.8004613	1.400724	-1.8718008	-0.084194176	-0.6291847	-2.255639	4.0353103	0.18815576	-1.0556023	1.4229069	2.9203987\n-2.6613708	-0.12119367	2.5933175	1.8020219	3.3253145	-0.25038308	-0.89548844	1.7314276	1.4442873	1.9144498	0.18011485	0.22190985	2.2887821	0.6923126	0.8875701	1.281231	-0.4083579	-1.0874571	-1.1237502	0.15604474	0.6220281	1.6631098	2.9786847	0.010840108	-3.822206	1.4312241	-1.4388367	2.0658674	-2.0429156	-0.8817976	-4.0052896	-0.6196769	0.90051055	2.8805397	-0.3015531	0.680041	0.19249962	-2.2989664	0.7430445	-0.29157603	0.7490779	0.75465876	1.8547208	-1.0731158	-0.9460309	-0.2302895	1.3168731	0.17760593	-1.581206	-2.1181304	-0.29085913	1.4837724	-2.1644404	-0.5893009	-1.7808635	-0.95332247	0.27290666	1.6111224	2.5896072	-1.8844825	-0.15936945	-1.1780573	0.640774	-0.45403597\n-0.37496865	2.0215425	-1.996418	-0.09130966	-1.0230725	0.09390192	-0.19417168	-1.8011327	-1.574838	0.20590216	0.7190402	3.4568458	0.63356835	-0.48280948	-1.943057	-2.135187	-1.0469258	0.23009719	-0.0264831	-2.1548452	3.015053	-1.0892268	-1.085643	-0.9909336	0.11285922	0.86652786	0.21779542	3.2402258	-1.2425658	1.0340728	0.4617343	0.88497066	0.8974127	-0.7019037	-2.007047	-0.3117829	1.5971564	-0.3535688	2.8352387	-1.5002103	0.2250648	-0.3534072	-2.9440405	-0.69315183	0.20869322	1.5781239	2.1346269	0.50292194	0.28635404	-1.2136316	-1.0433317	-0.43866158	-0.68605125	1.0837691	0.5700064	0.106823154	-4.747473	-0.16539307	-0.021961574	2.3122194	-0.4406517	-1.4005578	1.0846423	2.0852814\n-0.09056791	0.71442276	1.6472659	-1.001631	0.47418883	-0.09883169	-0.5666926	2.8239117	-1.4316024	1.7126167	-1.045088	-2.884497	0.20532845	-8.01149e-05	-0.2027675	2.5582309	1.2057747	-0.64178574	-0.5054535	-0.9448897	-1.1672167	1.7405065	-0.22398609	1.0092678	-0.084064215	0.63747275	-1.535982	-1.5534797	-1.0302544	0.6025885	0.6026948	2.3108723	1.690218	1.0272574	-0.052473187	2.8392394	-0.86859864	-1.3242645	0.243735	0.29535317	2.856497	0.47263712	-2.081204	-2.3880289	-0.938808	0.53986317	-2.7918248	0.5247504	-0.6311488	-0.7519255	0.4289036	0.09527403	0.5800375	-0.04753758	0.22017133	-0.86880744	-0.10603144	-0.6578762	-0.304702	-1.4223406	1.2117957	-0.47527462	-1.6320868	-1.075447\n1.0921279	-1.3464265	3.8873253	-0.06102585	0.94832355	1.7072693	0.88247365	-0.6195647	-1.0754352	-1.5323203	1.0553132	-1.0862637	0.104037106	-0.5221522	1.3029761	-1.9492208	-0.13034281	-0.19492021	-1.3479022	-1.7040403	-0.6112382	-0.73068565	-0.8710656	0.5969509	0.98387045	-0.41581804	0.014885315	0.1854814	0.4115956	0.4061028	2.5143187	-0.2500379	-0.86422026	-0.6576704	0.7245798	0.6388613	1.6870425	-1.2766432	-0.86657554	-1.1123877	0.003327138	-1.8191003	-0.06403431	-0.4844726	-0.07537098	1.1452584	-0.10093792	1.6113129	-1.1932915	-2.0351536	-0.93921393	-0.7398675	0.761392	3.3496523	-0.7911523	2.2375438	0.77188504	-1.3504277	-0.51708376	0.2829569	-1.2585591	0.35871455	1.4597639	-0.4860942\n0.3287091	-0.26452327	-1.9274423	0.6741463	-2.3484175	-1.721519	-0.5505194	-1.9714578	-3.1375606	0.73751694	1.423013	0.40344864	0.84100705	0.046442162	-1.7470319	1.2366859	0.6410404	1.1156507	0.42718452	0.9347373	1.6835368	-0.24187903	-0.43091002	0.248463	0.6076549	-0.68659097	-1.7743474	-0.6164632	-1.4180436	0.22514799	0.40532258	1.3906833	0.9733868	-1.7763553	1.0905799	1.8055685	2.2296162	0.6620746	2.3537753	-0.42017743	0.7059844	2.552805	0.20425954	0.9008855	-0.77247787	0.16569585	-1.3988628	0.30466384	-0.6590217	-2.326069	2.6937191	2.5858436	-0.5550901	0.6708948	-2.2291489	-0.7411142	0.5464371	0.41214314	-1.9897056	2.194948	3.2671099	-0.46671203	-2.6966906	-1.6363393\n-2.3498173	-0.710898	0.7673831	-0.23526376	0.7824831	0.74899644	0.6219455	-0.8585012	-0.614774	1.4461949	0.05728098	-0.021178976	1.4749352	-0.5683308	-1.4331154	1.8357406	1.5624851	2.3702192	-1.6771815	-1.6909924	-3.730886	-0.9520733	0.14878598	-1.020118	-0.050790947	0.91050303	2.6606317	1.0671782	3.5058875	-1.8112936	-0.02784768	-3.155377	-1.5709264	-0.00076086854	0.61848855	-1.0257246	-0.086901374	1.4295131	0.94767755	2.1411283	-0.8158723	0.76987106	1.2775115	1.3289086	-0.91942984	-3.236145	-1.8557575	1.0807432	1.0105814	1.004575	1.1470501	-0.21798716	0.1354149	0.6526559	2.074636	-1.2073172	-0.84617645	-1.583849	-0.05084595	0.051462445	0.33378688	0.21338995	1.4532728	-2.5282454\n1.7386562	2.216119	-1.4798324	0.5959825	0.41910523	-3.0288565	-2.4404192	0.14739668	-0.1753567	-0.8702022	3.3656135	1.0258735	-0.5795029	-2.0893168	1.1819314	-1.4380966	-0.85532415	-2.8000238	-1.5253198	-0.48464096	1.3195996	-2.4233038	0.37428445	-1.169694	-0.9129251	-0.21900146	-2.5851767	-1.2854633	-1.2933351	1.4328647	-1.0218115	-0.7822191	-1.6002293	0.034492467	-1.3217565	-1.0225667	-0.33075255	0.85036147	-0.8972999	-1.3337244	0.31406853	1.5879443	-1.825522	-0.027624497	-2.7185755	-0.5967188	-0.11133406	0.37195298	0.6777086	-0.0076603177	0.051720973	1.3473815	0.7326822	-1.9706662	-0.13380988	1.9696738	1.1259243	0.21771426	-0.6561429	-1.6310029	-0.65119267	-0.6601993	0.30133986	-0.36682436\n0.37223467	-1.5924027	1.6042211	1.6211302	1.4900875	0.36056113	2.7736583	-1.3071544	1.1189702	-1.345135	0.62207544	0.5337493	-1.1698872	-1.8162966	2.4449418	-0.5499766	3.1417155	1.4411157	-1.1887255	-0.8866325	0.53756255	-1.2787573	0.07671205	-0.4325791	-0.042531922	-1.3311443	-0.8738733	1.491438	-1.6453285	2.3977098	-2.8099172	1.9568876	-0.31680432	-0.280713	-0.298613	1.0611684	0.6913025	-1.1498215	-1.967618	-2.2656991	-1.0482106	0.41776577	0.16178894	-0.96895915	-1.4412273	-0.3181976	-1.0035897	-1.2790306	-2.880587	-1.6889064	1.1495425	1.1257172	-2.1865933	2.3446167	1.4977443	0.039774165	-0.18725598	-1.8885915	-0.38424987	-1.7666221	2.112705	-0.2432971	-0.79219383	-0.7868745\n-1.1024641	0.9626074	-1.6839242	-0.74276716	1.4306141	-2.4758205	1.2038648	-2.535958	-0.26672938	-1.6198854	-0.80994105	1.2906497	1.4006889	-0.34685308	-0.84828895	-0.20604952	0.42042416	0.6089457	0.91696197	0.6341442	-2.8536835	0.43804052	1.2025712	2.9085975	0.013507988	1.659278	-0.038706142	-0.07907288	1.4066552	0.40023732	-0.086509325	-0.25817952	2.3177671	1.856328	2.831265	-0.80421185	1.2729936	-2.6415248	-2.046464	0.06426896	-0.26752654	2.2133465	0.5486947	0.764995	1.0131133	0.8633796	1.101644	0.9634768	-0.66234773	0.61371046	-1.5644394	-1.582379	-2.44692	0.4219858	1.6730362	0.42648566	-1.8534079	1.1781433	0.4254665	2.644075	0.86194175	-3.155135	-0.06260786	-1.0588266\n0.55761015	-0.95880413	-0.33740357	-0.18149488	1.4672674	-1.2414062	-0.18533199	2.2853525	2.6106174	-2.2436767	-3.3133311	-1.2514645	0.18710884	-0.3255699	-0.96018696	-1.5243404	1.051815	-0.4106137	-0.17658876	2.8747652	0.72062343	2.1202228	1.004844	0.5213514	0.059107132	2.5822108	-1.7384676	-0.5504649	-0.028458742	-1.0917207	-1.9530017	2.9376209	-1.1148288	-2.0907252	0.37785745	-1.6892432	1.242936	2.101659	-0.19685794	1.1854292	0.80875194	-1.1969956	-1.2595128	-1.6600133	-2.6349618	2.9627352	-2.0621023	-1.6504303	1.1842856	-0.68168926	-0.16937031	-1.8837795	2.415803	0.17457278	0.34250024	1.0038682	0.752315	2.6938407	0.06670286	0.07585664	-0.42790383	1.4595515	2.3703103	-1.1851081\n0.5446351	-1.7202386	0.3339957	-0.6456098	0.6074733	-1.5815796	0.39029777	3.1208658	1.6245667	0.78066075	-1.4739513	3.420927	-0.10047967	0.30677012	-0.9826841	2.0438886	-2.7525952	-2.1088386	0.59647626	-1.7309775	-1.8787003	-2.0091941	-0.37366578	0.14985347	-0.2644028	-0.24015185	-2.7731113	0.563746	-0.7875942	-1.0342666	-0.84550226	-2.653299	0.12372331	1.609845	0.77262324	0.32406026	-1.7774774	0.5298814	0.12034757	-0.8499473	-0.41616756	-0.38227338	0.061672896	-0.15804555	-0.044200044	-1.0164207	1.5694617	1.2475086	-0.8268477	2.0239856	-0.32680777	1.8300129	2.0281084	-1.1755141	-1.4226015	1.0107874	0.9169552	1.3937755	2.8335307	-0.0009909945	0.41134328	0.78780043	0.8662586	-1.7277226\n-0.30359095	-1.8290844	0.98746985	0.7062484	0.19917421	0.8468003	-1.4314162	0.13516732	-0.44448578	-0.8264244	-1.475171	-0.26656616	-0.045839045	1.4731772	1.0835291	1.4551631	0.99159545	-3.251949	0.017392702	2.9063044	1.1547647	-1.0682833	0.23508447	-0.7970647	1.04162	1.3543296	-1.1532415	1.9662498	2.6722903	-3.1528037	2.8809345	-1.598481	1.488845	0.9003497	1.9665825	1.9802514	-1.2350949	-0.96080756	-0.32573432	-2.416434	1.4281882	-1.2767552	-1.2919837	0.9879336	1.7729818	-3.6912851	0.037792917	-0.06537005	-0.3281568	-1.7758733	2.217953	-0.12929057	-0.22940065	0.15967369	2.169435	-1.362261	-1.2307487	1.842242	2.159613	0.21832459	-1.0278306	-2.3043218	-0.48057455	0.4971101\n0.36530486	0.25457588	-1.5734128	2.1035159	-1.0295982	1.7859877	0.36819768	-1.1453544	-2.5884163	1.310385	-2.3530722	3.3718123	1.2693504	-0.17172755	-2.3376749	0.250023	-0.9156461	-1.569603	0.16473408	1.916742	-0.63179356	0.1735804	-2.3984861	-0.43927848	0.49138796	-1.3215744	-0.5126444	-4.830628	2.3395727	-1.2647223	0.06571521	-0.35651192	-2.2837298	-0.57106227	-0.8341902	0.008275989	3.8830786	-0.10274046	0.3500701	2.1726193	-1.774209	1.2581592	-1.2353148	1.7568437	-1.0422074	-0.7995545	1.041313	-0.040149935	0.07139814	-2.0980897	1.4491894	-0.9498177	1.0704446	-0.4045615	0.75107074	-1.331622	0.20434326	-0.31543747	-2.9626143	0.7435767	-0.73050237	-0.34798396	-0.60056937	0.2632084\n0.05900681	-1.2361689	0.14148866	-1.3936753	-2.61561	0.4558424	-1.1985278	2.5799785	0.48738235	0.3235579	2.7572737	-1.3365662	-0.41319185	-0.6662553	0.4231593	2.50558	0.43829703	-0.6533883	-0.5314719	1.0642587	-0.35360226	-1.9262996	-1.2050285	1.2432398	-2.6635103	0.38676998	-0.059079647	0.12106493	-1.9013275	0.26906273	-4.5508924	2.584789	-0.44640484	1.1028216	0.06114713	1.880299	-1.9120758	0.92747927	-0.8919734	-1.0463568	0.5932771	1.0068965	-0.98020923	-0.20591219	-0.14067052	1.4261267	2.1186993	1.2645615	-0.7507982	1.1171439	-1.4016976	0.41699266	1.0464901	1.2907109	-0.58620197	-1.7069112	-0.9395872	1.3566538	1.0949576	-0.469776	1.2293284	1.6042316	1.4465804	0.80185306\n-1.239908	0.62686104	0.55797154	-2.8199375	-1.1312495	3.0024488	-0.3956363	-2.9664176	-1.6253326	-1.3521174	0.30858445	-1.0335739	-1.9405086	-3.6267865	-2.4756217	0.54667234	0.5137923	-1.0514619	-0.47211477	-0.62475806	-1.1592692	0.99736345	0.35608113	-0.5730644	1.1279601	0.3683346	1.2975266	1.7300776	-1.6278114	1.0831906	-0.8194211	1.2079909	1.5942411	-0.040551335	0.88220257	1.5135325	-2.4249976	1.8386358	0.03072353	1.8917128	-0.29758105	-1.5101439	1.1098924	-0.9841237	-1.1098182	-0.28375092	1.2583448	1.970964	1.0329605	-1.2475845	-0.09252523	0.20707983	-0.94656116	1.4558882	1.7358078	-0.95405775	-0.9446829	0.77824444	0.95267457	-0.95206934	2.7746327	3.1958547	1.0040176	1.8357332\n-2.1456053	-2.1595101	-1.0664381	2.8983133	1.4614191	1.321223	1.2600235	0.98489165	-0.44059998	1.1263411	2.2147407e-05	-0.34872544	-1.6153266	0.70763206	1.7655516	-0.23889703	1.7558284	1.2881023	0.9725647	0.8017168	0.4719357	-0.78732425	-0.82494104	-0.33480856	-2.2623405	-2.866012	-0.77140397	-0.06075679	-0.05550219	0.24437733	-1.5073549	-0.018742168	0.07706183	-1.0997223	1.3256505	-1.1909808	-2.4950576	-1.6898686	-0.61436623	-1.5466119	-0.7837596	-0.64073986	1.1063254	0.9447933	1.4745269	-1.0392061	0.44151923	-0.36664072	-1.4441087	-0.45132422	1.627259	-0.7828186	1.2626016	2.2478487	0.0002800018	1.5696981	-0.72294134	1.1455604	2.0730805	-3.057506	1.5657915	0.76358503	-0.14373572	0.7837193\n-1.4704562	0.79338086	1.5889051	0.49204156	1.4198955	-2.1411934	0.98757195	2.6006088	-0.9190918	-1.4010061	2.1697922	-2.556304	-2.553875	1.3259134	0.22454384	0.11686829	2.0284016	-0.6111022	-0.17847298	-0.84102446	2.6675	2.5941646	2.4818578	-0.46721473	1.6665547	-0.19521521	-1.7129747	-1.3477954	0.43759543	0.70258087	0.28543988	2.0886915	1.0849528	-1.1611232	0.20013256	0.7559099	0.97991633	-0.24875043	0.33039522	-0.9522264	0.6765835	-0.24542078	-2.6417	-0.9191825	1.3311933	-1.3864805	0.8514186	-0.8049967	1.4405968	-0.24394464	1.965114	2.1370366	-0.08858977	0.09887094	1.5807732	1.3297707	2.0317297	-2.0490844	0.6150804	0.6765884	-2.0045512	-0.25779718	-1.2730044	0.14853838\n-0.80402505	-1.223565	0.6688792	-2.022343	3.6969376	-2.8693798	-0.64428926	0.54089636	-1.4812359	0.4678045	2.7114043	-2.3809965	1.1517649	3.188311	0.7130723	-3.3409965	-1.9009079	0.65474975	1.88221	2.9959826	-0.7573761	-0.923831	1.6282142	0.9421924	0.61751884	0.9715755	1.7978525	1.0290499	2.2719944	-1.2439629	-0.40385142	-1.3125751	-0.24179067	-0.39326862	-1.6350732	-0.940714	-1.3852915	-1.088979	2.3759522	-1.7863387	0.6322772	2.7140765	-0.8539027	0.033644043	2.0590281	-0.47999713	0.27884609	1.0075556	-2.257411	-0.07696565	-0.6318083	-1.5559907	2.4406047	0.020021806	-0.86883193	0.36986914	0.92226017	1.4456749	0.6233774	-0.903715	-2.200887	0.008448172	3.4543068	0.14148155\n-0.7506673	-2.8235154	2.8985047	1.6797057	1.4450182	-1.1620636	1.6413059	-1.2435747	0.12923394	1.05472	-0.14019302	-0.5028592	-0.753811	-0.86245644	-0.23361652	3.1089697	-2.111214	1.0505826	0.83591944	0.8663155	-0.70590144	-1.8241132	-2.190022	0.36838177	-0.77959484	-0.5658642	-0.2413892	1.4101146	0.31620044	1.8226539	0.35859212	0.08255813	-2.3732257	0.13311218	0.08841694	0.8729198	-1.1218793	1.2009417	-0.4457651	0.37921783	0.21780518	2.3240213	0.30917227	0.47268575	1.1829017	1.2292787	1.3008928	1.2769701	-1.7651393	1.3524156	-1.6409718	-1.3810855	-1.3924918	-0.8653515	-1.0118016	0.102849275	-1.0541736	1.0641018	0.07935389	1.081671	-0.6976781	-0.29360795	0.6066918	-0.0023976013\n-0.6189817	-0.030890506	0.8513319	-2.263181	-0.066750176	1.1224856	-0.7870322	1.7469643	-2.821795	0.7102357	-0.7537244	-1.8881334	1.4495705	-0.79213154	1.6993375	-0.15549977	0.7863269	-0.96164674	0.5082508	-0.5016469	-1.6392204	0.40485227	-0.35617104	1.1616118	1.3261001	0.4595955	1.1254725	1.05375	-1.7110388	0.19604649	1.2051	1.1877263	1.4648134	0.61715263	0.4682167	-0.87422913	-0.8282534	-2.5963504	0.1439996	-0.79946417	0.18924838	2.4477053	-0.4348155	3.0355468	2.1465147	-0.22160491	-0.03104721	0.841916	1.5057594	-0.4200081	-1.1456822	1.610089	-1.5504847	-1.0335213	-0.86750346	1.398758	0.39664406	-0.88875806	1.3944591	1.1179899	0.99976355	1.9036589	-2.8801808	0.18725471\n1.0732225	-0.95943207	0.3950457	-1.8679374	0.19409348	-0.0631602	2.1576283	0.011536863	0.1849283	1.958891	-0.06750267	0.61812824	-1.5085367	1.9211843	-2.0520651	-1.0247246	-1.5659978	3.051762	-0.6745128	-1.0947869	-0.26675573	-1.6778175	-2.8186176	-1.3371801	0.5485887	0.3089234	-0.6324816	-1.5279945	-1.0155709	-1.7263508	-0.2130354	0.5209524	-4.5620565	-0.1766922	-0.96547073	-0.6232985	-1.2013205	1.1058525	1.7906573	1.8887662	-0.95591223	2.5642903	-0.27769998	-1.1894555	2.1052964	-1.9809031	1.0816388	3.3320205	0.5158497	1.1124194	0.50729096	1.209917	0.9010021	-1.5493302	-0.7146945	0.47074464	-1.8731313	2.1189902	-2.980893	-0.5035127	-1.8718724	0.87065697	-0.8522977	-2.7930808\n-0.3085703	2.2216847	-1.1052755	2.1754634	1.3305587	0.25927582	-0.5225572	0.46289778	0.27687663	1.5762354	1.6802346	-1.1645141	-1.3704695	-0.19929007	-0.11317224	-1.3016311	3.2083368	-0.5323541	-1.3836795	-0.5519536	-0.6635437	0.80689913	-1.5895642	0.68527204	1.9623605	2.742107	1.8206108	1.4259183	-0.662008	-1.2755553	-0.1410292	3.4327805	0.21504787	0.29496834	1.972179	-2.0524845	-1.8398415	-1.9227107	-0.35455117	3.1380033	-0.21558574	0.35138613	2.820136	0.59005827	0.32582045	-2.4634278	-0.46320713	-1.4355705	-1.4114772	2.2047472	0.96168315	0.9239032	-0.07203574	0.19317627	-0.2028913	-0.6948342	-0.22763965	-1.594334	0.2517316	-1.587911	-2.583873	-1.4162298	2.3789365	0.030186772\n1.2701696	-1.257012	-0.3529863	-3.040947	2.0293427	-0.2744159	-0.47203872	-0.27820414	0.9185364	0.6859298	0.18204664	0.2739073	-1.1549951	-0.10444137	1.2555553	-1.6343381	-1.6336671	0.9196176	0.16641149	2.0296245	-0.7107178	-0.8401737	-0.2069011	0.32408068	1.4322717	-1.3809041	1.1815999	-2.6770968	0.061682384	-0.27455634	-0.38146898	-0.10960174	-0.5938543	-0.48919582	-1.835969	-1.9063821	1.9903128	-0.32498318	-0.9392369	1.5741286	-3.1593785	1.2662514	0.6383625	3.4726577	-1.7819763	-0.40368944	0.7139115	-0.08529581	0.49042732	1.6518747	-0.52164185	0.5159668	-1.693846	-0.16140011	1.3168496	1.6538923	0.7595382	1.0948699	1.1898985	-0.14903124	-2.5080853	-0.8059384	0.61384994	1.520914\n0.68272376	-0.72469115	-0.08503089	-1.2710654	1.0819126	-0.52688307	0.43392965	2.4148448	0.16353756	-0.7163915	0.11007712	1.4506841	-1.4538503	-0.6320364	2.8445551	-1.7640693	-0.63784784	0.9791916	1.7937977	0.61253405	0.8551545	-2.0253599	0.58402747	-1.7262596	-1.3602346	1.5657103	0.80014014	-0.15889768	-3.752479	-1.5537217	1.5240362	-0.087693386	1.0914142	-1.4482261	-2.8962462	2.1149783	1.0426879	0.13195321	0.30796143	-2.0750978	-0.3864583	2.6203585	1.4429734	-1.2751818	0.9687868	-1.7197766	0.96562135	-2.319459	0.625166	0.575571	0.35530663	-2.2430594	-1.1810477	-1.2627823	0.20187794	-2.106676	2.263271	2.6417315	-0.9634033	0.67791533	-0.083151564	-0.084573165	-2.4484656	1.7569796\n-0.8145722	0.7122938	0.94716865	-2.6476874	-1.2434002	-1.1972088	2.3494744	-0.05208459	-0.16641678	-0.6340116	2.0644841	-0.525006	0.76828194	-1.6238515	0.4735616	0.17377539	3.3432114	-1.7250006	-0.5785164	2.3743474	1.9699728	0.6134605	-2.1359653	1.8780996	0.9132851	-1.7141469	0.2690504	-2.9550421	0.31324086	0.9688393	-0.6711879	0.28258964	-1.1258602	-1.9412646	0.045561153	1.3595608	-1.8393633	0.35280856	-1.3786752	-0.749541	-1.3382634	-2.3214157	-2.2351656	-0.9972635	0.644802	-0.97977716	-2.3667412	-1.0006765	-0.3084878	-0.28786856	-0.9244172	0.38782722	1.0305339	-1.9509617	-0.98711234	-0.30148366	1.2363424	3.2791622	-0.0497842	0.88757586	0.99306613	0.75620705	-1.306129	3.252705\n0.6635743	2.231956	0.13894743	-1.3448246	-0.3012118	-3.084195	-0.55536664	1.1728945	0.06756893	-0.62375265	-1.0302417	-0.9906742	0.041422278	1.2987391	-1.4576076	-0.33200818	-0.008477382	2.3612747	2.255283	2.0306218	0.35607228	1.1191105	0.83386874	-0.8801553	0.23704988	-1.0605452	0.901572	0.9840344	-1.1622481	1.2625096	-0.095347844	-1.9061717	-0.8046864	-0.7147701	1.9218764	-0.15595114	-1.4367241	0.18611868	1.2641927	-0.42697978	2.354816	0.91120785	-2.6469254	-0.0207849	0.14436224	-0.7892458	2.6059256	-1.945514	1.6779605	-0.04638791	-2.514151	0.84626067	-0.27605295	2.732516	-1.8174114	2.5132408	0.46285832	0.61102694	1.5919188	0.18131423	0.95255774	-0.53698456	-2.544675	-0.3353827\n-1.3930433	-1.0976275	0.19636504	1.221265	-0.5339371	0.04175738	0.50792176	-2.256914	-0.015796827	0.29394865	-0.050617743	-1.593391	-0.54379374	-1.7662897	-2.0466743	1.0951453	1.881858	-1.4066104	-1.3086376	-1.5790453	-0.75183856	-2.0618782	2.0832224	-0.3744917	0.9559198	-1.1008966	-0.79710305	1.4292439	0.39700148	-0.7744911	0.935763	-1.5613563	0.017638318	0.9578902	-0.43283623	0.12569043	-1.8251684	-1.6705962	0.07125255	1.6027563	1.020938	-0.28153637	-3.0204294	0.63433516	0.2336583	1.309442	-2.1086152	-1.827494	0.89681596	0.7959	-0.21244869	-1.7602265	-0.794022	0.20343119	-1.5850767	0.9056701	0.65563816	-0.17096347	-0.8144303	-0.29976514	1.4919131	-1.3417572	-0.5015681	0.010037392\n0.8751984	0.35612187	1.5973897	1.1104074	-0.43663964	1.5178366	-1.6939303	1.9511793	-0.5723771	0.25073257	-2.858312	-1.8073124	1.1014977	-0.80453587	2.2163992	1.2602196	-1.3194366	1.2141316	-0.8462859	1.0906435	1.0327163	-1.663908	-0.37319097	1.0811323	0.8784854	-0.8265181	-0.06062788	1.1939827	-3.717607	-0.88606626	2.7547798	1.2850102	0.049960934	0.14871658	2.207224	-0.71707004	-0.54540175	1.9584715	-0.036777176	2.4849286	-0.15470126	-0.47870225	0.82698554	-0.4567627	-1.6674016	0.92523396	-0.23373415	0.60582453	2.658402	-0.13876548	2.9863505	-1.7181628	0.30020055	0.4690274	-1.5840033	-0.89139116	-1.0131671	0.271389	2.3606427	2.8113778	1.3480215	2.6572773	-1.4853868	-2.3875327\n-1.4599383	-1.3123721	1.4463854	1.2377048	0.19668509	-1.038975	-2.200482	1.2133023	-0.7393688	-0.3535994	0.6395166	1.0624816	-1.0052401	-1.6831653	-1.5322882	0.83422935	2.5690773	0.8418132	-1.4210907	-0.042594947	-0.86869615	-2.5255334	0.9960408	-1.0064803	-0.9683677	1.0878813	-0.9190241	-2.817495	0.025979435	1.7412173	1.8911964	-0.21568364	0.49953657	-2.1743677	-2.1188827	0.9323561	-0.18170507	1.2950299	-0.074276865	-2.1758347	0.48815712	0.6639427	2.6716228	1.2497979	-1.3873556	0.67831355	0.0663704	-0.62989575	-1.4735802	-3.540472	-0.2488289	0.41519925	-1.4653289	1.6710784	-0.22965574	-0.336993	1.4353656	-0.3109321	0.57210094	1.2589774	-0.6215027	2.8895087	-2.5670123	1.2595643\n-0.4425812	2.1721122	-3.077026	-1.2879173	-0.01272812	1.6840448	-0.8236832	1.2570692	3.1113098	1.3303658	1.8575047	0.039841246	-4.240565	-0.9443826	-1.209421	1.0698954	0.59520835	0.23332994	0.8500997	0.845622	0.6962948	-1.8042046	-1.0542442	1.3791748	-0.6461985	-0.70704025	-1.1989802	-0.6506075	-0.7312433	1.2771727	-0.8282826	0.943882	0.7121984	-2.043193	0.63850534	-1.8408959	0.01024679	-0.38015997	0.25924662	-2.4123352	0.026428606	-0.5785875	-1.7470502	-2.0365753	0.40329036	-1.1718568	1.9790095	-2.127493	-2.460494	0.88132846	0.048564043	0.88242793	-2.1303673	-0.8979217	-1.2864642	-0.057673905	2.0945508	-2.0960221	-3.314409	0.33074328	1.3443996	2.513073	-0.86631817	0.6834076\n-1.0400515	-0.11464193	-1.9237356	-0.3010562	-1.9849724	1.128219	0.014924341	-0.613943	-0.8455997	2.0497103	0.8988838	0.25264654	-1.0752914	0.14445873	-1.5583758	1.7696638	-1.858478	1.4482727	0.06319593	0.15621638	0.48750663	0.7932513	1.7139674	0.77222407	-0.47166052	-2.6275823	1.0352633	-0.13511147	-0.43982294	1.2230157	-0.52353024	-2.046922	0.4701457	-0.98930734	-1.7208409	0.65919733	0.3439691	1.5568855	-1.3046402	-2.863111	-0.8374506	-0.21738057	-0.36933333	-2.3381035	-1.0011814	1.111389	-0.7666819	-0.28828537	-2.2790601	1.7719378	1.4732128	0.8474597	3.209465	-1.8267455	1.9131457	-0.93367696	1.3084481	0.40560216	-1.1313115	0.08326494	-1.0057634	-0.727666	-0.10028969	4.2650623\n-3.302183	0.44736838	1.1936272	-0.29892728	-0.7171151	-0.6642861	1.24035	1.040586	0.9418824	-0.38877824	2.1095495	-0.18013877	0.07831525	-1.7548833	0.38456526	-0.41084075	-0.5078199	1.2463665	-0.7560546	2.0959346	0.052663516	0.012080792	-1.3410393	4.249747	-1.344314	0.34584436	-1.1080321	1.5836918	-0.48484278	-0.64643544	0.29974994	-0.7555906	1.3037755	-2.4228525	0.9398873	-0.26839915	0.3411195	1.2616365	0.38428986	1.813017	-0.41849947	-2.117892	-1.100814	0.9917196	-0.030118924	0.68747497	0.9679377	2.0287979	-1.6731986	1.193655	-0.71416193	1.6165648	0.019011565	-0.35886782	-0.33000308	-1.9545727	2.4409199	-0.13558972	-0.09113248	2.612904	-1.3235607	-0.57108915	-0.25326142	-0.8632717\n1.3704841	0.86938447	1.2069887	0.8599717	0.4456816	-1.2739004	-0.9562395	-1.2864242	-0.066550106	0.4055542	0.381649	1.676542	-0.34840232	-0.4091849	-0.53837913	1.1398451	-0.9790619	-0.13275437	0.85800606	-1.400925	0.3757763	0.9629466	2.1621747	1.1018132	1.093185	-1.5159465	1.2229909	1.4293058	-1.0634409	0.8572518	3.120029	0.42120978	-0.24367595	0.19878471	3.5617154	-1.5539302	0.053228702	1.5196394	1.3939537	-0.68163276	0.6082535	2.0211093	1.1409589	-1.1106381	-0.38759115	0.70197064	-2.4053366	1.1065586	1.2120798	0.7484335	-0.50911903	-3.119842	-2.1873589	0.1537487	-0.5048575	-0.56949395	2.4530754	-3.5152526	-0.0072800373	0.03601433	0.4804824	1.7420905	0.9465563	-1.5472658\n0.43444532	1.4348837	1.7514884	1.7651916	1.536118	-1.4297042	0.2207939	-0.30014187	0.088865556	0.32516757	0.08709048	1.2439674	-0.77098745	1.6802013	-1.3423904	-0.075079985	-0.8804718	-1.9053928	0.25267735	0.27027315	-0.12876433	-1.7757039	-1.7270329	0.7306447	1.0215347	0.35206968	-0.18697174	1.2049915	0.74944717	-1.957253	0.028524574	-3.68215	-3.2391834	-1.4255501	-0.618146	2.3625672	1.3690858	-2.4258156	1.9968218	0.9051884	-1.8087468	-2.6479723	-0.7575241	-1.3680085	2.9966683	0.80676055	-0.22915007	-2.4000092	-0.365259	-2.3418033	1.1472175	-0.26610962	0.29035977	-1.5173932	1.4201312	1.1542711	-2.3938246	0.042110216	1.143124	0.2996973	1.0312799	-0.73576397	-4.855514	0.5221488\n0.8030364	0.98816967	-0.5486753	0.3724576	1.0516186	-0.03560552	1.026566	-2.3807266	-2.560482	0.019881183	0.70337546	2.1906168	-0.2612804	0.6794818	0.75530964	-2.0696068	-0.33041665	1.8263613	-1.1841339	-0.59557563	4.212523	1.0975738	3.343967	-1.2894882	-1.2280718	-1.1642895	-0.74261	-0.09972494	0.55795115	-1.1252714	0.58521724	0.12729408	0.6245408	0.0247513	2.3508532	1.2530525	-3.37229	0.3871308	1.2870134	0.3191595	0.34030837	-0.30821118	0.7007106	-0.68935597	-0.030955203	-0.16260324	-0.53266114	-3.1738873	0.5491233	1.9844568	-1.939355	1.6625596	-1.3314301	-1.1090848	4.349804	0.14024837	0.6446403	0.48831373	0.44000995	-2.58615	1.8846998	0.9410884	-0.4072931	0.9127472\n-2.4027803	0.588918	1.2289641	-2.0723567	0.94230795	1.4035809	-0.66551024	0.23675957	-0.5622584	-1.9027718	1.7847438	0.73479134	-1.2973094	0.1717393	-0.03480721	1.3000255	0.29878068	-0.3184781	1.8734578	0.89384055	-0.54046327	-2.754278	1.4904089	-2.350982	0.42137083	0.016527157	0.70637286	-0.25127947	-2.4313567	0.92887414	-1.5970061	0.46460974	1.596813	0.3891919	-0.82692546	-1.689799	-0.56955415	-0.624133	0.03406644	0.31780162	0.84298694	2.2321205	-0.5025706	0.8049002	-0.65999943	0.32485038	0.4794239	-0.7374151	1.1484386	1.451438	0.11091443	1.8960642	3.0894656	2.0737922	0.4753898	1.2402371	2.3610218	1.7095801	0.96155053	-2.571757	0.00351738	1.5665971	0.37893155	-0.34182015\n-0.34773397	0.8844835	-1.8171445	-0.94912255	1.7198627	-3.186624	-1.3487419	-1.1017491	1.8585813	-2.1432567	-1.0102053	0.23645139	1.7773247	-2.819891	0.7930849	-0.0049007866	2.0653458	-0.99736387	-1.1419767	-0.007094619	1.0909477	-0.33333904	0.46048164	1.790979	0.25560158	-1.1764368	1.2336265	-0.2489969	-0.58712393	-0.89327586	-0.68670577	2.1399713	1.0101857	0.24075425	-1.8904744	-0.44950438	0.23684753	-0.35912073	2.3872783	3.3714516	1.3370817	0.07679382	0.24400964	3.7984247	2.287545	-1.459742	1.533441	2.4635718	2.716756	1.3359698	-0.027154645	1.0860244	2.5463586	0.07713414	2.2708778	-0.3619727	-1.8895184	0.5304199	1.6126826	-4.0763965	0.900885	-0.1853517	0.11400225	-0.60427314\n-1.5120286	-0.59508306	0.54247934	0.1055702	-1.1015338	0.17992151	0.8104357	1.2191966	-1.7190553	2.1197283	-1.3752059	-2.3372939	-0.43978655	-1.2267517	0.59223306	-1.4067603	1.5455312	-1.458747	1.2994323	1.231573	2.6290655	-1.5908507	0.082251966	1.5382533	-0.94143444	-1.5229392	-1.7535647	-0.90505797	-0.89345694	0.8466719	0.923012	0.33663675	-1.2423095	2.3140936	-2.147578	-1.2637233	-2.110682	1.4270386	-1.1729331	1.0717453	-0.7298192	-0.48221156	0.03543078	1.3376284	2.325303	1.9600025	-0.53312975	2.8669367	3.5295665	-0.04235337	1.0325432	-0.33346623	-0.5609806	0.8233775	0.5302949	0.5808692	0.8145289	1.5183173	0.031861704	-0.98520166	-0.96594167	-0.61302644	-1.3290757	3.0572069\n-0.8103824	1.4190077	1.4344344	1.6653625	1.3825319	1.1323471	2.1596322	0.62693596	0.6493938	-0.025807794	0.43785116	-0.20774353	-0.22549157	1.7182027	-2.303231	1.9119893	1.9369705	-2.7851517	1.842558	-0.23276107	-2.122009	-1.9117845	-2.3817527	1.0904509	1.9020395	1.843778	-0.71862483	0.48891497	1.5158217	0.16177723	0.31437597	0.7904271	0.7820768	-0.99975127	-1.9713299	0.81434864	-0.68646723	2.4006393	-2.1688526	1.6353307	1.9238267	0.0031062118	-1.2656796	-0.1218435	1.2124877	0.3936356	-0.34609935	-2.6353061	2.7738369	-0.2289384	2.623739	-0.084368505	-0.345641	0.7075738	-0.34918255	2.3823066	-0.698745	0.5959142	0.023713896	0.43903396	-1.49281	-1.3675464	0.7404159	-0.7937908\n-0.29725978	2.8037312	-1.4618378	1.0576416	-0.36228085	-0.9730921	-0.45009765	1.1373341	-0.28519246	-0.2944586	-0.5225586	0.18873024	2.084827	-0.3337277	2.9301138	0.6953368	0.4675366	-2.0254395	-0.5126057	0.45647693	-1.5968333	-0.17647843	-1.391605	2.7479901	0.6581328	-1.1487516	0.24066995	1.180681	-1.7187225	-0.19905269	0.1484885	-0.50884813	-1.1148885	1.4111567	1.6580306	-2.1683662	-1.5441849	0.24426499	-0.5568773	1.1148187	-2.0662198	0.5930916	-2.010774	-0.14062026	0.28442454	0.81485313	1.6095666	0.47714937	-1.5719783	-2.9207609	1.8514863	-2.252317	2.3083136	-1.4743665	0.10441988	0.7145419	-0.7235292	0.39000648	-0.53745353	-2.2092526	-0.15268841	0.4951234	2.007378	0.43718317\n-0.14691813	0.9012378	-1.8440689	0.565985	-0.5517577	0.95717204	-0.08365407	2.0305655	-0.39106685	-2.3849814	-0.3477217	-3.0297098	-0.78217494	-0.24147707	0.81782556	0.5500601	-0.38702822	2.7946737	0.7645791	2.0337079	1.2691476	-2.1578636	-1.7320586	4.01935	-0.9061612	-2.8445687	0.71248305	-0.9511957	-0.72699755	-0.6040454	0.6329307	-2.763773	-0.2465186	0.60842544	0.19129057	2.355306	-0.3378363	-1.7272905	1.9452504	0.3509949	-1.8094041	0.018425303	0.12585174	2.642911	0.454527	0.35135552	-0.20958912	-0.3821956	-1.8531866	-2.2562256	-0.06583258	-0.4675896	-0.45327896	0.48088992	0.10069471	0.50196296	-2.307639	-0.5249169	-0.27966407	0.7915138	0.14540336	0.5258361	-2.2138977	0.35468757\n1.792883	-0.4188098	-1.4218264	1.407306	-0.82481515	1.7245181	-0.006256038	0.2271962	-0.3255982	-0.97686076	-0.007606649	0.09048954	2.995777	2.0410528	3.6322196	0.051719263	-0.80260736	0.8313748	1.9607713	3.389621	-0.9215638	0.51571286	-0.40357745	1.9768288	0.28527254	0.40744486	-1.2915657	0.34546545	-0.63112485	-0.07301673	1.0380914	-0.27524248	-1.2855033	-0.3480434	-0.38112488	-0.1863115	0.1515011	-0.056240078	-0.4875825	1.7501783	0.07919273	0.32784337	1.7441697	0.59977096	1.4264954	-1.5269761	-0.019334469	-0.6436501	1.7998126	0.31064612	-0.7374747	0.4150734	0.846354	3.0978286	1.6423684	0.48276243	0.82593185	-0.86319375	-0.5146237	-0.35595337	-1.783586	0.079859495	-0.220194	-0.9396763\n0.02350202	0.53653884	1.1131648	1.3845612	-1.6914308	-0.37982586	-0.45514843	1.3107295	0.8709799	-1.801164	-0.82187027	-1.2466327	2.5418446	2.9151027	2.8452857	1.8835543	-0.4671697	1.3748262	3.6763806	0.75516033	1.0716275	0.009485231	1.4457768	0.3357823	-1.5224352	-1.1686409	0.25072542	3.3573709	2.7246516	-0.16481842	1.5619084	-0.59982854	-2.1543624	2.1224093	1.4925683	-0.63732135	0.19134872	-2.3614714	-1.0698926	1.2142826	-1.3669312	0.04916647	-0.3972067	-1.3046288	0.05791576	-0.99619126	1.7665292	-2.8751874	-1.4368415	2.5521202	1.0442029	2.6309419	-0.5578351	-2.8713946	1.0142508	-1.2419496	-1.5172646	-1.5024861	2.549439	-0.26813206	3.3599591	0.58492756	-2.1281474	0.626861\n-1.774729	0.91528386	2.183889	-0.90879315	-1.3831527	-1.8138896	-2.0886686	-0.53394204	-1.9744568	0.76830196	1.9201396	-0.25665483	-0.8699982	-0.049082503	-0.9658439	1.5398434	-2.5902307	1.1031592	0.06567609	0.99866986	0.937034	0.6069471	0.13783784	0.65110856	-0.79990673	-1.0861647	-0.9510513	-0.8442789	0.73690295	-0.41215682	1.5728692	1.3586746	0.95837915	-1.5559351	-1.2811074	-1.6341504	-0.97207487	1.7149605	-0.29743916	0.95076257	-3.2005532	0.319118	-0.025025707	0.5345461	1.3909086	0.4009682	-2.5770485	0.9878759	2.7176654	-0.43672687	0.9300078	-2.1272554	-0.78455645	1.5329312	1.1122743	-0.94524944	-0.50169384	0.87175864	-0.99375975	2.9062605	0.91255337	0.768735	0.7551053	-1.4132848\n0.9514805	0.6013855	3.4001365	0.9758075	-0.77968615	-2.2875621	-0.6246472	-1.4225798	1.823719	0.1684421	0.69032425	-1.951969	-0.65132004	-0.9666719	1.3647777	-0.96187454	-2.7840486	-2.236975	-0.43976834	1.3541629	-1.1732919	1.8320875	-0.58595866	-0.46376994	2.4986813	-1.0666517	-1.4027256	1.7645516	3.1973457	-0.8195585	0.51371413	0.7042754	-0.38297534	1.1254423	0.5174485	-0.40435258	2.8553648	0.5629877	1.5886894	0.0137153715	0.50972414	-2.8269212	2.0215347	0.73988897	1.2422309	1.3160032	-0.5797482	-1.9611278	1.6813165	-0.2780711	0.81155515	-0.11134088	1.6164029	-0.0026870251	-0.15347837	1.2387025	-1.3413577	-3.7511938	-2.4388561	-0.56939995	-0.1622639	-0.070949875	-0.64770734	-0.11212361\n-1.2540745	2.1003458	-0.2813342	1.3193113	1.6091324	-1.8417348	-0.6530112	-0.29295558	0.8359224	0.7642294	0.53091997	1.5131623	1.89927	3.5674894	-0.76767725	-2.599666	-0.5269993	-1.5521442	-0.8897043	1.3333663	0.3292754	-1.1287127	-0.09668944	4.684947	-0.6665618	-1.4663142	-0.7785028	0.9601752	1.6507022	-0.39697164	1.0142922	-0.5250698	2.3648798	2.3801186	-2.139786	1.1362472	-0.080678836	1.3211032	-0.35768017	0.11535157	1.4675134	0.9932378	-0.029973038	-0.83275366	0.88293403	-0.023215353	-0.7964894	-1.1203532	0.38667	0.7720271	-0.18952638	-1.27791	0.9743388	-0.5192804	0.54430073	-0.5291204	-0.36835673	0.27509072	-1.0306426	2.1590147	0.57502556	0.2032736	-0.10200125	-0.3690299\n-0.93904984	-2.4543934	0.9513385	-0.84053326	-1.1006138	0.90516645	1.0574183	-0.426687	-0.36564776	1.1623751	0.37550515	-0.5643807	-0.504045	-0.9444314	0.9933781	-0.0145868985	-0.89744765	-1.5097462	-1.4873853	-0.7707371	-0.62736636	-0.5373923	0.09873354	0.0650203	-1.2918276	-1.0996447	-1.480147	-0.27709472	-0.3438306	1.6221638	-1.2039322	1.7857071	4.5074315	1.319888	0.5075344	0.65894866	0.10141966	-0.8754567	0.23088856	-0.22402276	-0.05471072	-2.1968894	-1.7589928	-0.48799926	0.014097582	-2.3463206	-3.7221437	0.21814227	-3.458075	0.56451195	0.17618889	-0.69688517	-1.4616181	1.9048499	-1.1903167	1.3226291	-0.6849679	0.289226	-1.1638645	-0.630221	0.8433215	0.97467375	0.7376228	0.15740308\n0.2960166	-0.5674049	1.4370848	0.57136375	0.4965157	1.0099847	-1.1191026	2.6227882	-1.2435669	1.5775881	-0.090024434	0.9271802	-2.2735195	0.8494882	1.48319	2.246458	-1.5704342	0.039913002	0.72851944	-0.4722175	0.8475213	0.39976737	-0.6499263	0.45951754	0.18277968	-1.3428423	-1.0588517	0.49451408	1.5262562	-2.4783185	2.616054	0.56279093	-1.69236	-1.0310748	-1.6062201	0.22398642	1.2941009	-0.32511556	-2.4595466	-0.24834391	1.4285984	-0.9058852	-0.5304942	1.0334595	-0.97502047	-0.8752219	0.77521694	0.5690811	-0.5113602	2.0494645	0.4556319	-0.23820762	-0.21875244	-3.020027	2.2450871	-0.50536484	0.21450879	0.123367876	1.6158645	-1.3844614	2.5091083	0.037627917	0.94787234	-1.3643272\n0.04843877	1.3492949	-0.3013751	2.559123	1.4149438	1.5292994	-2.911821	-0.055851616	0.87377876	0.38115972	0.46400252	2.825738	-3.9774997	-1.6961062	2.5041347	0.82210773	-0.05431	-0.38671994	-1.9240134	-0.97720885	0.409673	-0.877864	-2.9998145	3.9201138	1.4513668	-0.96818835	-0.79603404	0.8536382	0.7404558	-0.7581586	1.0254345	0.32135418	0.3083924	-1.3712791	0.4573014	-0.07910105	-1.4644673	-0.74947923	0.77659786	-0.9944269	0.5828649	-0.56332976	-2.1494336	-0.3305805	-1.5529292	0.27873963	1.6018229	0.19211416	0.29518247	-1.3232805	-1.6711333	-2.7285552	-0.66743004	-0.071260646	-1.3899837	0.25495982	0.5469128	-1.0021733	-3.0932357	-0.19517659	-0.084263	1.2575387	-1.1811767	-0.042724136\n0.479413	2.5135243	-0.44901758	-1.2903506	-0.39753038	1.3756332	-0.78287256	3.484966	0.34287673	-0.84958583	1.5332118	0.3306655	-1.6360388	1.6084566	-1.2993712	-0.4974183	1.5997694	-1.348073	-1.0034227	0.58584344	0.18726982	-0.18401153	0.7686114	-1.7648301	0.96850795	0.32884467	1.4053904	1.4664438	-0.7473372	3.7621627	0.41422546	0.28911975	0.23418672	0.77448994	0.50085145	-1.9866152	0.9503499	0.32567683	0.650692	0.8182769	-0.12512574	-0.11746825	-0.94165623	-0.28667763	1.1561682	-0.09315696	-1.6542501	-0.80866563	-0.44580382	5.014952	-3.3737314	-0.59232664	-0.6461347	1.8122506	0.0155847175	-2.103918	0.8323939	-0.22734563	0.031974487	-0.049710996	0.7813325	2.2401595	-1.3678008	-0.31106153\n0.83771145	-3.569504	-1.2979109	2.8549747	-1.1631387	-0.63118505	-1.6020886	-1.1375303	1.3445491	0.46633336	-1.865073	0.46821493	0.55797976	-1.1056116	-0.12882265	-1.4361513	0.8689868	-1.5562549	0.37252384	0.32979232	1.3263606	2.3683615	0.054986898	0.37728235	-0.16379057	2.394425	1.8569651	0.004709118	-1.786824	-0.9033157	1.4825331	-0.01907349	0.67114925	-0.8792025	-1.8294594	-1.1386644	2.8279426	0.7701744	-0.653603	2.5022464	0.25699908	0.3235986	-0.74140984	-1.9301857	0.98587304	0.15096343	1.1688029	0.3605604	-0.9331539	-3.5309472	-3.2438211	0.13026051	-0.055018008	1.7867919	-0.28116557	0.9559105	0.3349137	-0.47820663	-1.2014353	0.27946913	-1.0785209	-0.16328703	-0.91308296	-3.290266\n-0.83369297	-0.28098586	-1.3249098	1.3843647	2.0506244	1.6266867	-0.7567381	1.1912422	0.6641286	0.3198837	-3.4883044	-0.23690481	1.0699271	0.7501349	-0.32513142	0.08311599	0.9638824	0.47331885	-0.5864015	1.3981715	-0.4568431	3.7268255	0.06240888	-1.0993092	-0.2826236	0.044633448	0.1989332	-2.3412511	0.1970867	-0.0014826002	-0.40950868	0.97813493	-0.9277775	-2.232872	-1.0392044	1.0042963	-2.2700653	-0.83953255	2.4887676	-0.08557782	2.5812507	-0.6350452	-0.93825877	-1.0514839	-1.2802526	0.93455803	-0.29097533	0.124820605	1.6182734	-0.39694872	-0.06203846	0.062182344	3.1020973	-0.03809229	-4.060179	0.9257823	3.1281538	-3.1003103	-1.9063514	-1.6375334	-2.3882928	1.8305957	2.261488	0.59054404\n-1.0434146	0.51547784	-1.5295833	1.0207167	1.6268762	1.5778253	2.3660743	-1.8794668	-0.0774555	-0.67871517	-3.8901672	0.0066275434	-0.10939554	0.31336853	1.136114	-1.2011551	-1.4420768	0.2168202	1.6517863	-1.9601384	1.3316658	0.061144963	-0.55952936	0.3745523	-0.27004647	-2.7815971	0.54307604	-1.1764117	-0.8831133	-1.6938432	-0.28957963	-0.10989631	0.64884454	0.23237285	-0.5570937	-1.1244507	2.9933608	-2.2396293	1.0997726	-0.9702047	-1.1206955	-1.3672384	-1.4945605	1.2434492	1.3664688	1.436503	-1.506391	-1.7618948	0.627225	-1.312936	-0.8168285	0.09197677	-0.45832953	0.9738227	-1.1792649	2.3072069	1.5356483	1.3594649	-1.6253455	1.1631174	0.56387615	2.216388	-0.8515954	0.029831188\n-3.5229282	-2.0528452	-1.0371616	-2.1104386	2.395214	0.755937	1.8944343	0.46162614	-0.8884793	3.1530926	1.6272596	-1.0059816	-0.9053172	1.0452731	-0.63107514	-0.050884187	-2.5942576	-1.0427595	-0.63737255	-2.540025	0.8883525	-2.0351079	0.2107001	-1.7191668	4.132949	-0.59579724	2.25963	3.3230767	2.09997	-2.3737025	0.8396912	1.1415232	0.2255452	-1.2497447	-1.3033175	-2.3877535	0.52347946	0.6339075	-0.6751136	-0.58577526	0.4148369	0.4254338	-1.2700057	1.4286716	-2.334467	0.47909975	-1.4338325	1.5333948	2.6757195	-0.49530864	-1.4742613	3.3803775	-4.577863	1.763225	-0.13008957	1.3877156	0.15866677	1.0127499	-1.2189496	-0.7602286	1.0585388	-2.1822076	0.6683219	-0.20406649\n1.1234747	0.02782904	0.27351823	-1.7661576	-0.39329848	-1.4055417	0.92047805	0.095125146	-0.434862	-0.20274928	-1.3482317	-0.60536444	1.0860287	2.3064804	0.18891089	-0.042088844	0.055028133	-0.011087647	0.8572231	-1.3336077	1.9773546	0.017708292	1.6968219	-1.0750244	1.9633837	0.5947931	-0.22661103	0.3099007	0.38927993	2.9093747	1.1956612	0.8167809	-1.336082	-0.21188004	-1.6565814	-0.36484405	-0.9811132	1.771308	0.6756443	-0.4291006	-0.6478494	-1.6218244	-1.5699968	-0.09599429	-1.2925959	2.3273935	-1.0633895	0.021987023	-1.6811806	-0.27918217	-2.4882984	-0.13015269	0.585769	-1.5365821	-0.4492173	0.8629539	1.7064301	-1.6440257	-2.441596	-1.2244629	-0.28442118	1.3464032	2.4026177	0.78119624\n0.9012046	0.35477036	0.5943626	0.5758554	1.5927143	-0.5052442	-1.6414568	1.2596257	-1.0517354	0.76752037	-1.8491395	-0.31107074	-0.5486708	-0.28921333	-0.6244236	-1.2601678	-1.3996798	-1.454433	1.8429579	-2.7508519	0.13460675	1.6803303	2.0240982	0.23333424	-0.27413416	-2.339437	1.9466006	0.095050275	1.2310314	0.20449492	-0.75077164	-3.7492883	0.11769862	1.405347	1.3881282	0.44215	-1.3815922	2.8507824	-0.8764347	0.6041024	-2.2397082	2.454664	0.03212856	-1.626693	1.8312056	0.38378754	-0.3394843	-0.80019253	-0.9856813	0.1543901	-1.3604572	0.20409414	1.1523497	-2.7324448	0.7973172	1.3528134	0.7700287	-0.12840699	-1.5491778	0.5657123	0.48105696	-3.153491	-1.1398412	2.3884103\n-0.096014224	-0.9901135	1.9743758	-2.5728354	2.4518216	-0.34028494	1.4604878	-0.067313544	-1.0830617	-0.9222581	-2.9575481	0.7659178	0.3496675	-0.9083405	1.039167	-4.319625	-3.0559847	-0.90661204	0.5306984	1.4474782	1.9933825	-0.24742301	0.083264224	0.02631307	1.4707204	0.25105	1.9571428	-0.9019707	-0.591509	0.9728634	-2.782435	-0.17060596	-0.29264596	0.69669604	1.1512048	-0.79374963	-1.1306506	-1.8789694	-1.1079369	-1.9794406	-0.8127543	-0.27882117	0.040324263	-1.1833678	-0.53483844	-0.4422632	1.9580222	0.4302663	0.5448908	-1.1056534	-1.9387194	1.952817	-1.7491715	0.9255584	0.9392719	-2.3764846	0.74141717	-0.75274295	1.0894006	-2.916378	-0.018651795	1.4783406	0.16620228	-1.6499307\n1.2865604	0.26128006	-1.2109079	0.34957615	0.292412	0.64058536	-2.3628492	1.526019	-0.8754707	0.42963335	0.78986114	0.9353463	-2.227621	-0.6224065	0.36380175	-0.4376069	1.434838	-0.0833777	-1.0942553	0.95165634	0.79524314	-1.0467545	-0.7332256	0.8727925	0.8284852	1.4499587	-1.3841838	-1.6957647	1.7832617	-0.5612865	-0.32390755	-1.0288038	-1.1222479	-0.75487036	-0.75373775	-2.5211713	0.028116276	0.37053692	-0.1676761	0.8079338	2.5309079	-3.6010113	1.3441821	-0.54258484	2.1898868	-0.6606412	0.10316213	0.53286093	0.112911634	-1.1409396	1.4203362	0.7276573	-1.7987676	-0.37479475	-1.5699651	1.4609529	-1.7889426	0.73695296	0.5896043	0.98396266	2.4874942	1.5749037	0.77907634	0.40703008\n0.13492726	1.45318	1.8104458	-0.005380215	0.5612055	-0.10650248	0.59757125	0.17881778	0.5937313	1.4963597	0.08030574	-1.665146	2.0841768	-0.29094377	-1.153309	-1.8442221	1.0417244	1.4394156	1.4966066	-0.76059514	-0.64966863	-1.4292115	1.1152667	0.85512125	0.26525354	1.5070653	0.97125435	-0.15533583	0.69020087	-1.8960776	-0.19095506	0.42104185	0.636576	-3.2970898	-0.13967453	1.2079438	3.3055513	-0.63043994	-1.1533822	-0.8341091	-1.7911285	0.12191457	1.9847159	0.6281856	0.8035047	0.8957471	1.809647	1.0842115	-0.5290492	-0.92623544	-1.1830122	2.112413	0.99758273	-0.06511058	0.10852494	0.42556417	1.6554213	-0.6977744	0.009539352	0.49537522	2.959904	0.30061257	-0.15380695	-0.55483156\n0.21280383	2.2307634	-0.7139659	-0.001757969	0.66035575	-1.3761412	-1.1802429	-1.2352188	1.0801702	0.16097802	1.0786877	-0.060749926	-1.8565875	-0.37350982	-0.5211436	-2.007989	0.77658945	0.72931504	-0.9871417	-1.9395711	0.25100514	3.2004101	-2.2152941	-0.07831732	-0.6669258	-3.582869	-1.707446	0.41348594	-0.4498888	-1.1172819	-2.109687	1.2248216	-1.7304717	0.60016984	-1.5812988	-1.261623	-0.02540552	1.4025686	-0.478891	0.097858995	1.8696827	-1.1567986	-1.4854134	1.0824203	0.6081651	-0.07706813	0.6686509	0.9237959	1.5726521	-0.6284902	0.34505123	-0.39209726	-0.1231468	-2.0727687	-0.5899045	0.9911668	0.11852738	-0.29719025	-0.4140303	0.23518318	0.9827415	-0.6300954	-0.90541923	0.65978694\n0.45164415	0.30721602	1.831304	0.7747165	-0.599982	1.2751873	-0.3659376	-3.2648044	0.24506672	-0.63733387	0.044101834	-2.628633	-0.29703555	1.614024	2.7849371	0.43148345	1.926155	-3.1049485	-0.22076876	-1.3949977	0.2367939	0.5001361	2.914444	1.0562308	2.5370486	-0.6921691	0.1788902	-0.8293689	-0.89234513	-0.7256707	0.16551928	-2.4655337	2.6766512	-1.3686119	-3.1994548	1.2047247	0.14192769	0.13433631	-0.7548636	1.3309995	1.7239367	0.9586007	3.8851602	1.1429713	-0.0569041	2.781728	1.2081845	-2.3418381	3.0555727	-1.6023476	-0.07119695	2.3455336	-0.20263413	-0.3824934	1.679229	1.9068229	-2.2622204	2.7833323	0.24066225	1.0817364	-0.35553515	-1.6486416	0.33672658	0.10986015\n-0.930535	0.20765018	3.057733	0.6539686	-0.26028726	-0.5433444	-1.2049941	-0.779948	-1.7915729	-1.7151661	0.74494153	-0.41733718	0.11829291	-0.21756873	-1.041092	-0.030159902	2.7706835	2.5265267	2.041316	-2.2707164	0.26016572	-0.259913	-1.0732981	-1.5606217	0.10758227	-1.2054278	1.5429778	0.72727287	-2.030435	0.85171264	-0.95756286	1.6801256	-0.16227733	-1.2808253	-0.5230038	1.7547091	-0.8056655	1.1544453	-0.92790675	0.38217333	-0.55123746	-0.8882535	-1.7990749	-0.1617633	-1.5305454	0.5950817	1.6918247	-2.1398008	-0.5412988	-0.114866234	-0.18107814	0.021494232	1.4935699	-1.9035577	0.9399262	1.4825231	0.3375228	2.223099	-2.516464	-1.1274258	-2.6847267	1.1900547	1.5580637	-0.86265814\n2.450559	-3.5944943	1.1496081	1.8361084	0.816527	-0.66808754	-0.4617977	-1.105994	1.8834144	-0.21684484	0.7082467	-1.3386031	-0.4188113	2.6290576	-0.3233297	0.15320985	-1.7245655	0.45246246	-1.303622	-1.8671935	1.4991798	-0.10627577	-1.1534327	1.1382761	-3.4766839	-0.12381855	-1.0756146	0.8247681	-0.24909686	2.1366239	0.8610592	0.82112813	-2.1622782	-0.8000507	-0.23022984	-2.46769	-0.3512992	0.8364489	0.41616565	1.1486958	2.044641	2.7130857	-0.16273582	0.8238687	0.9114304	-2.2784061	0.28694075	-1.5359143	1.0175081	-0.65327466	4.1315713	-1.1063534	-1.5921502	0.064059936	1.8183378	1.1767783	-2.2192085	-1.1042483	-0.45379952	-1.0721861	1.7170163	-0.57283	-0.6740307	-0.77941835\n-1.6249691	-1.704123	1.2066712	0.55647314	0.042159323	1.1696728	0.43801764	-0.5114539	1.424815	1.7727953	-0.71974456	-1.1526438	0.846182	1.3290253	1.9877272	0.29507014	1.6150601	0.9784872	-1.5835154	-0.08451535	0.5671989	-1.7796872	-1.1212407	1.0601646	-0.65908414	-1.8504047	-1.8596679	2.9912784	-0.023754733	-0.092109405	2.191683	1.8902037	0.05971762	1.3371794	1.6195885	1.9235585	-0.21514021	1.326669	-0.39617458	2.3398502	-0.91653645	0.76660156	2.790564	-2.0237322	-1.4620374	-0.41071174	-0.8067544	0.8794077	1.0607976	-1.0724908	-1.707167	-0.124250345	1.9216299	-1.0292448	1.9853528	-1.5781524	1.8103642	-0.4200512	0.1615843	-2.0391037	-2.3619456	1.8626069	0.31235784	1.0556331\n1.3781562	-0.18911521	-1.4653367	-0.6309556	0.6195108	-0.19419739	-0.6406212	0.056477986	-0.51517713	-1.5726899	2.7121673	0.06687882	-0.3336717	1.0086836	-0.350488	-1.1311938	-1.9376215	-2.7981365	2.4401455	0.008943963	-0.11861967	-1.9373486	1.2491729	0.9972879	-0.53023946	0.20398204	0.989195	0.68629026	0.9435	0.7379348	2.921804	-1.3262212	-0.1362959	-0.52284676	-0.4965018	1.8331345	-0.8867477	-0.9550191	1.3107797	-1.6806493	-2.0443814	-0.28799748	-0.43352878	-1.0405517	-1.0696366	-2.605844	0.97648054	3.2398422	-0.30946097	0.8781171	0.011002318	-0.46943206	0.212745	0.61740017	0.16468875	0.21601756	2.3851392	-2.213545	2.8319676	2.3547554	-0.94231135	-0.2418152	1.1168711	-0.41176438\n0.26487726	0.63376814	-0.37347603	-0.2860646	-0.16637419	-0.49645582	-1.7627556	-1.4947811	1.3761702	-1.0786718	0.5047193	-0.27835995	-1.3306924	1.6846343	-1.3075163	0.45859262	-2.388768	-0.0339547	-0.029346444	0.057962816	-1.1740688	0.1577049	-0.53667945	-0.5547247	2.5208647	-0.9382633	-0.43000227	0.80661434	-0.40064386	-0.96422434	0.21222274	-0.26361078	-0.11733675	-0.9345743	-1.5092406	1.2654114	-0.23895302	1.7199907	1.7455361	-1.2871563	-0.8783066	-0.94649386	1.4406747	0.61021084	2.29736	-2.521707	-1.0777454	-2.304908	-1.5411034	-1.9310914	0.06624806	-0.4924591	-1.4371463	1.8477104	-0.2649308	-0.81408894	-2.4722443	-0.9621992	0.06569105	-0.62411124	-0.50027615	0.62992686	0.00011671695	-1.2062589\n-2.4868755	1.6623566	-0.70311415	1.2176471	0.7595878	0.27133346	-0.08210992	1.7678834	2.1395464	0.29694906	0.9423352	-2.0182946	-0.864212	-0.33691496	1.0105928	-0.5514249	-3.7914026	0.17834748	-0.90492284	-0.24787815	2.9137447	0.20956814	1.2311037	1.0213094	-0.73969334	1.2550573	0.4906606	0.024807429	-0.18347661	2.0956442	0.17660312	-2.3757997	-0.04055059	0.46610573	-3.787661	0.010313637	0.93962365	-0.59027505	-0.34651557	0.61246437	-1.7072488	1.6657621	0.48295027	0.5836562	-0.63538307	2.9326875	2.2364004	-1.1054435	2.8317666	0.1768329	-1.3513768	-1.7421741	1.2985667	-0.35712826	-0.6616658	-0.6408783	0.7617689	1.5237899	-0.5483615	-0.22450204	0.2656715	1.1530644	0.2105125	-2.1829684\n-3.3684137	1.7180446	-0.6874707	-0.37422663	-0.4910021	-0.5925714	0.9358787	-0.36653864	-0.10389293	1.3423908	-1.9467891	-0.77738565	0.55914897	-3.7007222	-2.540289	2.630852	1.1091381	-1.2625563	-4.255567	-0.5419386	0.13652901	-1.6176763	0.066579305	0.09066258	0.6403534	1.050747	0.2852176	-1.641224	0.6486676	-0.59435844	1.0346751	1.5400268	1.1555275	0.8512184	0.32027283	-0.73848075	-1.3357067	1.308374	2.0214293	0.25879267	2.5037372	-0.031961523	-0.34588566	-0.3988549	-3.0726306	1.0242355	1.4199808	-3.066346	-0.67684853	-1.9035325	-0.20111118	-4.027474	-0.3363595	1.7014861	-0.7114428	0.08799411	-0.6299547	0.55331844	1.4910743	0.84397787	-1.4391769	1.3779263	-0.77324677	0.93747133\n0.99972856	1.4519562	0.45251048	0.22778577	1.9693469	1.0120417	-1.3895372	1.3116347	1.9260522	-0.83101493	2.466342	1.495321	-0.051860176	-0.22605705	0.46572286	0.8242613	0.92908216	-0.12145219	0.22849932	-1.8388315	0.97719413	-0.372755	-2.844633	1.7968425	-0.0019365974	-0.0027945107	1.3160304	-0.94740385	-2.8687305	-0.9585148	-0.43341744	1.1800953	0.43180898	0.6332608	0.14768627	-1.9294112	1.6938915	0.6944083	-0.57575995	0.5049208	-0.72417873	2.433987	-0.17227384	0.8316107	-1.0178914	-0.365055	-0.36854276	-1.5121615	0.52689874	-2.4959521	1.6625115	0.03798146	-0.57616657	0.19078688	-0.46032184	-0.9742049	1.5380808	-2.0633004	-2.765974	-2.2029798	1.757382	1.0813377	0.13060988	-0.8764528\n3.2186697	0.71487	2.479334	0.96198773	1.3350756	1.18507	-0.49592653	-0.49313256	0.1447458	2.21805	3.2735367	1.0256828	1.6234826	1.1594803	-0.21466534	1.0949749	-0.07599066	-1.8574729	-0.21361102	0.22957718	1.2893896	-1.9920096	-1.0822538	2.0802453	-0.3003537	-1.9516975	-0.11380827	-0.22020449	-1.8807219	0.21636347	-0.35482788	0.55288017	-1.5203857	-3.8034732	-1.3998703	1.2964541	-1.3219589	0.011824179	-0.41391397	-0.3551931	-0.1444556	-0.11386382	1.6176628	-2.411236	-0.49454722	0.5372168	0.5914929	0.25234285	-0.65412337	-2.289121	-1.3137197	0.9432448	-0.9122636	1.6817952	-0.9560435	-2.1765184	2.190476	2.7095037	1.0442402	-0.077573165	-1.826778	0.102798395	1.2814126	0.24072963\n0.31676066	0.0061135185	-0.42123374	0.5034923	-0.37338877	-0.6400134	-2.9952693	1.5568318	1.0464116	-0.14004104	-0.11318442	0.46876794	-0.35035178	0.6945191	0.012927195	-1.9286503	-1.0554763	1.7338347	0.11764866	-0.89578676	-1.3519592	0.304453	2.0857794	-1.407655	0.20033176	0.07150346	1.3670418	-0.6043068	1.3541435	0.72195303	-1.2799207	1.3629571	0.99109805	2.4841146	-1.3305972	-0.47904956	-2.0522704	1.4382359	0.5668714	-1.0303172	-0.31608507	-1.0083315	-2.0720994	-0.24230236	1.0296068	0.6642358	0.8027324	1.8890666	0.25556257	2.6579995	-1.8302928	-1.6883204	-0.22363988	-0.7054323	1.1110892	-0.120450005	-2.6891382	-0.8725595	0.43125084	-0.8569436	0.13701905	-1.9306741	-1.0317309	-0.17240034\n1.7125027	-0.4038263	-0.6103118	-0.5036625	-0.8576844	2.1327007	1.1393578	-0.029730825	-3.4701004	-0.86133593	0.11597481	0.10232388	-1.8621536	0.5125436	0.7033608	-1.7369014	1.8583747	2.085735	0.6650518	-0.41083768	0.11522581	-0.74877393	0.9907671	-0.60883915	0.76875865	1.315591	0.7180733	-1.5851895	0.82584274	1.200288	1.0666713	-0.023703689	-0.8447052	0.13641556	1.5427027	0.763144	-2.5532215	0.47931805	-0.0016091601	-0.7507946	-0.04467389	-0.65916073	-1.1905861	-0.24021862	-0.08034638	-1.588526	-0.63212943	1.1453437	-1.4187381	1.2085127	0.13776284	-0.60878557	-1.2955588	-1.074534	-2.4523668	-2.4396105	-3.0515451	-0.82455605	-2.2786713	2.7893696	-0.72907305	2.039452	1.4640417	-0.47871855\n-0.5098818	-0.2564454	-1.0496604	-0.87523854	-2.131532	-0.30406123	0.98032314	1.5271729	-0.27989513	-0.27685452	-1.7398188	1.0344368	-0.12648505	1.4590852	0.68438774	2.022987	-2.0606434	-1.0811597	1.6698962	0.82662416	0.19350396	-1.9784069	1.1366018	0.9500282	0.4968987	-0.14091496	0.11250758	-0.8194263	1.6458796	-2.8048897	1.8090767	-1.448078	-0.112224884	-0.7641995	0.22946101	0.3531695	2.2836125	-1.4696277	-1.9490063	0.068730496	1.0880427	1.8035641	2.7572944	4.1503754	-0.26461524	-0.80278635	0.49328184	-1.1210886	0.2585033	0.97279966	-1.4341469	-0.6044311	1.6566112	-0.07702282	0.70599884	0.27374008	0.51833516	1.7743372	-0.49120286	-1.0678321	-1.4563986	-0.87877184	1.5049524	0.79266644\n0.5287444	-0.89500916	-2.1249745	0.74102587	0.3191514	0.020392766	-2.386104	-1.1879418	2.0905228	1.2262323	2.0557766	0.2042163	0.41080934	-2.05483	-0.43811244	-0.14107093	-1.1926343	-1.0425441	-0.6553369	-1.1999307	-0.2646885	1.9802834	-0.008626858	1.4688461	-0.82256526	0.83338255	0.8618037	-0.044653714	1.2437457	-0.1740296	-0.53968006	-3.8455043	0.834552	1.2974328	-1.419278	0.21485454	-2.776802	-1.9333361	-2.4793797	0.60094595	-1.5451291	-0.9304821	1.2129273	0.08766347	0.08628222	2.8343933	-0.5227494	0.86165893	-0.01075816	1.344766	-0.7021337	2.3385437	0.79631734	-1.4207515	2.511362	-1.198504	-1.1435423	-1.2049209	0.69034123	-1.487976	-0.105017446	-0.13801597	-1.0066481	-0.40247363\n0.10454362	-1.7209257	-1.1959422	0.44620982	0.7942349	-1.8719045	3.0577116	0.12552762	0.9341425	-3.128877	0.3781073	0.35753405	-0.5577875	0.44150418	-0.36363396	-0.45523912	1.2707816	-1.5183314	-0.3223678	-0.2693604	-0.12803	-1.7572823	-1.6513216	-2.6409311	-1.6647305	-1.3133931	-1.18378	1.7287632	-1.6171106	1.0748452	1.3902084	-0.48774293	-0.9030544	0.3727683	-1.6005328	-1.1049113	1.1740209	-2.786483	-1.6356664	-0.5393521	3.2164254	0.50302744	-1.437473	-0.12635325	-1.2701092	0.43254513	-0.6442214	0.55081916	-0.3862035	-1.9762306	0.86410856	1.2814403	0.17769203	0.629154	0.63282466	0.9862789	-1.140765	1.9541512	0.65619594	0.582022	0.9098377	2.1807857	1.934464	-0.7207731\n0.9969931	1.0566099	1.021417	-0.38982612	-0.4221409	-1.1455317	1.2289706	1.4794923	0.95914716	2.7534063	0.13724992	0.9427318	-1.8684746	-1.4441488	-0.26932758	-2.0227113	-0.56746435	-2.6722891	1.2710428	0.8310953	-1.0117736	0.68540514	0.6030895	-1.920775	-0.3727221	-0.70254123	0.85275316	1.5628052	-0.60946876	1.0161455	1.3932176	0.39337936	-2.7302992	-0.8155821	-1.2491361	-3.0726223	0.67372435	-0.36283776	-0.44097778	0.38583502	1.303111	-2.0349932	-0.31728753	-0.26681086	-0.68846244	-0.09394673	-1.502643	-0.19283055	-0.797489	0.71043587	-2.0762165	-0.40207282	-3.9745	1.4334774	1.0324947	1.5929176	1.2846305	2.2096488	0.18609136	-1.704339	0.12431288	0.52568626	2.5712912	1.6055424\n2.2883396	-0.03128935	-0.6590001	2.70466	-0.32068458	-1.4324961	-0.57298005	-0.96337515	-1.1450058	-1.0049174	0.3974483	0.5574724	-0.6647034	0.46870673	-2.210737	0.037012786	-1.4037825	-1.1569804	0.4314976	0.6895398	-1.5732175	-0.45601144	-0.15501352	2.1188579	0.024772786	1.2598891	-0.16564351	-0.97173154	-1.548587	2.4086967	-0.5815332	1.617816	-0.43824178	-1.5139586	-1.0120819	-0.1965061	-0.45404443	0.18336788	-0.19539194	2.6810853	-0.10773203	1.2498567	-0.2890634	0.86386627	-0.52348155	1.8436881	1.3571838	-0.5709755	2.174141	-0.16953896	-0.7309664	1.4411359	-0.5754435	-0.13037278	1.5378116	1.3354305	0.40225723	1.4920734	0.404741	-1.5945903	-0.2554219	1.0661128	2.0749614	-2.0338764\n0.1921612	-1.960869	1.4637786	-3.8875573	-0.63286364	0.45621175	2.9694238	-1.1066366	-0.4291136	-2.6189008	-2.7702305	-1.6859101	0.64451736	-2.0248065	1.1265963	-1.1356889	-0.26259094	1.0129533	-1.670454	0.49568033	0.08045895	2.6257339	-0.31937394	1.2410347	-3.1277146	-2.079665	-0.5402369	0.8777714	2.176101	1.2295753	0.4973701	0.5254269	-3.0010731	-0.26559114	0.32763106	-0.7424379	-0.20281003	-1.1587471	-0.5717919	-1.6412281	-1.9357411	-2.2698557	1.4541962	-0.410419	-1.3036143	2.2909515	-1.6195656	0.2969099	0.8100889	0.71500117	-0.27950194	-0.9521619	0.38452777	1.1361822	-0.3294268	0.7159374	1.3366615	-2.0773876	-1.0543272	-0.029531268	-0.79901415	0.67304677	-1.0384449	-1.203984\n-1.5371908	0.29812932	-0.18215147	-0.8391142	0.61516887	-1.7842883	-0.565934	-0.64447373	-0.94814014	-0.47819978	-2.28378	-0.12865038	-1.9497095	0.7351388	1.7489339	1.5816505	-0.93054396	-2.704034	0.11098519	-1.516888	0.2122849	-0.7422135	1.2562472	-0.041096687	0.02333874	-0.016651351	0.80824834	-1.9500705	0.62535286	0.69720376	0.056365106	-1.4235978	-1.2340133	1.3671716	0.28904778	1.3538325	-3.2425318	-1.2555864	-1.9370844	-0.094317384	-2.1803524	1.164291	-1.5460107	3.2423236	1.0332856	0.8928542	-1.0277723	-1.4011235	1.0164623	-1.5123473	-1.0450613	1.170327	1.9277416	-0.8520448	-2.3194785	1.4812778	-0.7631898	1.258868	-0.29199493	2.2185977	1.3830568	-0.2557692	0.37209874	-0.3014808\n-0.81117046	1.6059768	1.5422876	1.7684883	-0.96479225	1.2835848	0.68751144	0.10014723	-0.43307367	2.5690696	-1.1329387	1.3003922	-1.3352343	0.31299064	-1.2749054	-3.46732	2.658855	-0.08868987	-0.75434035	1.7114	-1.4034196	-1.2249709	1.9092004	2.2492416	-3.144363	0.27530143	0.48548612	-0.0555854	-0.53761333	0.16389632	0.013264853	0.9553987	-0.17591064	-1.6862301	2.489122	-1.1064285	-1.0354987	-2.719452	-0.5319353	-0.8145621	-0.37312526	0.5579864	-0.3526272	0.32225838	-1.63963	-0.47545066	0.37061733	-1.1170428	-1.4814402	-0.03565375	-0.8296866	1.586894	-1.4359542	-1.7067406	-0.50664586	0.24370603	-1.2209957	0.10370321	-0.8210638	-2.6131577	-1.2489699	1.1216956	-1.0568585	0.089477725\n-0.48073086	-0.9439189	-0.035526216	-0.19564757	-0.98891664	-0.38572195	-2.8165326	-0.8705622	-0.42318103	-4.037259	2.3253014	2.1227286	-1.4586196	0.32281852	-0.7100409	-1.0201548	-0.7711219	1.452396	-1.5074142	1.2201979	-0.2591547	-0.73913056	-0.1657285	-0.5041482	1.0799645	3.4805908	0.06409229	-0.59488815	-2.2513795	-0.09691983	0.30418566	2.0138884	0.59209824	1.9666204	2.5219033	-1.0647635	-0.8775269	-0.5451247	-1.7083032	-0.71304387	-0.60661554	-1.126299	-1.4689571	-2.3583808	-0.5784683	-0.21817185	-0.26187342	0.3313456	-0.45152652	0.9423108	0.68793267	-0.31080037	-1.0787283	-1.208581	-0.31572625	-2.2030022	-0.7541429	0.049955938	1.3098359	-3.2024732	-0.38560894	-1.864518	2.4819882	-1.3068717\n-0.006595523	-0.91230804	1.388617	-0.010476458	0.9777588	0.3349864	0.8983812	3.4565535	-0.20691268	0.49446005	-1.7173436	-1.1293118	-0.6144002	0.39766985	2.215691	1.6911573	-2.5440564	-1.2989622	-1.331741	0.7706185	1.4246796	1.5543969	-1.9274766	-1.4075431	0.06886404	1.0720143	-0.14756219	-1.4980295	0.1876141	-0.85594505	3.2210584	-1.4259862	1.0248704	-1.4693186	-1.7583281	2.4996877	0.4420004	2.4290576	0.5741945	-3.7921436	0.26513937	0.5215735	0.46958634	0.049632642	0.8665607	0.46510306	1.1262908	-1.5791965	1.1566216	0.8289794	-0.61451817	2.724199	1.4571	0.3034109	1.3925619	-0.89096797	-0.70568174	-1.2376443	-1.9386933	-2.4865808	-3.475601	1.0701354	-0.39922366	-0.41564873\n-1.3435104	-0.56493676	-1.080752	-1.1024226	-1.7414758	-1.3222412	1.3232394	-0.20870265	0.5672537	3.7231607	-0.1565879	1.530474	-0.95887965	-2.3503003	-0.95784205	0.5178369	-1.2672184	1.1268208	-0.18002482	-1.5021211	0.07315404	-0.17431217	-0.40151685	-1.9812478	-0.6383222	-1.3601712	0.33788773	-0.7658846	1.521328	-1.9222779	0.023366941	1.6820005	1.5874382	-0.058132824	1.004197	0.99465424	-0.24278688	1.6610546	2.1004853	0.6402567	0.64148974	-0.47623545	1.2552088	0.73824	-0.69236314	-0.5846266	0.50933504	-1.9661177	-1.0739198	1.3328633	-1.0083122	1.3712053	0.361436	1.2956386	0.8100899	1.036379	0.6952757	-0.96764606	-1.4093221	0.06498704	-1.8978497	1.9160707	-1.0551411	2.3144126\n0.97579515	0.5276933	2.1628978	0.6833516	0.76655805	-1.2406723	1.0077137	1.1709133	1.4056399	-2.5114136	-0.20741808	0.17353536	-1.7781787	-2.3593297	3.262636	-0.18257438	-0.23819898	-0.65970534	-3.4781797	0.9968492	0.64282906	-1.2207904	0.12747067	2.5417173	0.21160701	-0.06812294	-0.945028	1.0513824	-1.215153	1.9892523	-1.415299	-0.44560736	0.14349286	0.008149338	1.4210943	-1.9696261	-0.27187073	0.5195268	2.9277284	1.2050929	-1.6546731	-1.3131138	-0.8144459	1.6079655	2.1057615	0.1644796	0.3560724	5.325179	-0.700645	-0.92062706	-1.6477914	-0.18458505	1.4712006	0.22433831	0.83466005	0.46540165	-0.18073778	0.124106176	0.49985752	-1.3122196	-1.1661749	1.1713322	0.28161776	1.0536829\n-1.8604419	-0.8316642	0.96528184	1.3824846	-0.43516454	-1.1013942	-1.4571711	0.13857634	2.2384095	0.55072576	-1.653778	-0.751197	1.2284127	0.2928798	0.9978119	0.7873509	-3.3192775	-0.18029259	-0.79920745	-0.8867006	0.06936105	-2.4041657	0.029354585	-0.23491387	-1.0747231	2.25611	0.41443765	0.04534149	-0.6943406	-1.9119953	0.51045465	0.31426513	-0.62255746	-2.688203	-2.9573011	1.7543429	1.1921815	2.7397194	0.6783076	0.8779967	1.9443699	-0.21980926	-1.2077199	-1.6499296	-1.1036816	-0.60790116	1.9804912	0.9173816	-1.1276932	-0.4902341	-1.4516594	-0.41281855	0.5033258	-0.79117215	-2.1098988	0.72656333	-1.0457332	-0.38612702	0.47752228	-0.9113662	-1.1727295	0.13522327	-1.8931533	-0.6364545\n-0.37234935	0.6180409	0.1799184	1.9999506	-0.95817536	-0.63008016	-0.07128091	-0.8566178	-1.715937	2.4856892	-2.0787375	-0.47021607	2.5720348	-0.9044847	2.9973543	2.1575	1.0644073	1.6843886	0.32263836	-1.1838236	-0.51310164	1.508122	-0.17628281	0.30679774	0.58873504	1.2030864	2.4165103	-2.452235	-1.8274603	-0.01110832	-2.3489451	1.5238453	0.077226914	1.4845022	0.8584877	2.5123456	-1.4103471	0.42846152	2.8429828	1.1809977	-0.7930674	0.7939695	0.10936481	-0.6716956	-1.2884469	0.001901037	-1.0110766	1.0077003	-1.890687	3.087261	0.9798133	0.8778617	0.31994987	-2.4167213	1.5888335	-0.9864942	0.5769562	0.47713587	-0.41196674	2.6731517	0.5500309	-0.8177769	0.15848282	-1.7583302\n-1.4996024	-0.015186646	-0.48568714	0.18041892	-2.3698666	0.22716935	1.4151173	0.034163784	-0.904691	-2.6756723	1.2226896	-1.1896534	-1.1574112	-1.4164162	-0.95344937	1.1888312	-2.2343752	-1.647559	-0.7601167	0.53011966	-0.8444254	-0.016377727	0.55055845	-0.83631384	-1.9998138	-2.3112528	-2.1420045	-0.021919744	-0.7609711	-1.6660489	0.6269652	1.0934262	1.9305773	-1.7566394	-1.0149856	1.5789431	1.1139745	-0.07573341	-0.9450519	-1.6359069	-1.2830684	0.63047767	-0.93114626	1.5335025	-0.40985715	0.20998088	0.108156726	0.26832315	2.842714	-0.07829042	-2.2552896	0.5220219	0.3461402	-1.3150418	0.4165645	1.2336652	1.8918678	2.8629005	0.2531325	-2.2143486	0.19343811	0.15464763	-1.5850004	1.2196231\n0.22326232	0.305476	2.0118625	-0.6376566	-1.3669409	-2.2532768	1.181249	0.79186046	-1.6255668	1.0792743	-0.87464255	-1.3985595	-0.5569196	1.980366	-0.13297245	-2.2390478	-0.5365658	-0.13641742	0.7512947	0.6031957	0.00023074992	0.09953551	-0.20093237	-0.18146983	0.9066495	1.7486176	2.4230947	1.2698771	-0.47236553	0.6575293	2.1682093	0.16447583	0.3756835	-1.7707571	0.6128496	1.9497087	-0.685476	0.94417953	-1.4011173	-1.2968049	-0.21549216	0.9123129	0.39469382	0.08823306	-1.8388406	1.0618281	-0.27792546	-0.05367655	0.08862604	0.96554404	2.5413945	2.2525795	0.99864835	0.09948168	-1.4240819	-1.0474869	3.3246343	0.3547111	0.9385268	1.2632489	-1.333178	1.004868	-0.7783653	1.1776644\n1.9368488	0.6508481	0.8302767	-0.91509056	0.24652067	-2.1034925	-0.2985373	1.9154426	1.0763737	0.3165052	0.6508508	2.2658503	-2.4184318	1.0145766	0.904474	1.6291574	0.119598456	2.3652077	1.7500571	-0.46303678	-0.70682406	-1.2831031	-0.7342447	1.7347376	0.63586164	-1.2601753	1.9444181	-0.0028748966	0.047428306	-0.5493593	1.0837518	0.7935056	0.5905458	1.0135701	-1.6573831	-0.39476418	3.1033256	-0.14204976	1.3026539	1.2289948	1.2824333	-1.0174103	-0.9925352	-0.18706623	1.1132718	-0.5729188	1.9357675	-1.7417765	-0.25134164	0.98641956	0.47764713	0.16653517	-1.8270546	0.05809713	1.7002442	2.354609	-0.91052777	-1.8969498	0.8902612	0.33428264	3.5126503	-0.7243522	5.0367947	0.51673794\n0.02078934	1.009694	-1.2578869	0.28995547	1.0470454	-0.21108274	-1.2716453	0.6651761	-1.6567624	-0.40158302	0.16554283	1.0339744	-0.4476377	0.52803636	1.4543151	1.6784129	0.2580824	-0.36108857	-0.64763737	-4.0616016	2.9124658	0.50302815	0.25424457	0.78485453	-1.3125198	1.9400339	-1.4444572	-1.7292043	2.2190676	2.900051	0.5648571	-0.45071477	-0.62389696	-1.9515924	-2.2620752	0.30330566	0.28065932	1.3595423	0.42758632	-1.3425297	-3.0815663	0.6380573	-2.084464	2.562796	0.755519	1.2608457	-0.2473386	0.72739846	-0.8333583	-2.263556	1.3533564	0.28143626	-1.9830916	-0.990253	1.0239809	1.8740734	-2.1225226	0.1505359	1.9442217	1.5620488	2.3163009	1.7012504	0.57129884	-0.052077893\n1.2001837	-0.94192106	-0.9253222	-1.653465	0.65235245	-0.20446084	-1.3251904	2.0735128	0.60918856	0.08250855	-0.39893135	-0.18537174	-0.7946024	0.12434202	0.27471754	2.9251306	-1.8983345	2.0348897	-1.4387265	0.59454226	-0.6818035	-0.014719971	-3.131809	0.01333716	0.013913058	0.47608373	-0.051043067	-1.8349833	-2.5001836	-0.7320709	-1.734371	0.16639388	0.6766458	-0.7931038	1.8539193	0.14646819	1.2078707	0.42671177	0.04083791	0.48088384	0.831652	-0.6836985	0.97052395	0.06516849	-0.45014256	-0.37452877	1.4056069	0.078496054	-0.07904529	0.45462057	-0.054043382	-1.9385512	-0.5116597	2.160444	0.021954598	0.24667686	2.9595783	-0.09446059	-1.2993351	0.047632925	0.67198765	0.21836343	1.2539648	-0.82817996\n0.2857427	0.054283667	-0.67050785	2.2406735	4.017434	2.279936	1.3305829	1.1442361	-0.8166227	-1.6814778	-1.1940567	-2.6728506	-0.046377737	0.1349607	0.5476715	-1.1844065	1.4485254	-0.2717504	0.45685434	-1.4130883	-0.050837938	0.51890254	-1.3835384	1.798221	1.2284294	-1.2070408	-1.9837523	-0.48892817	-0.58824897	-0.21594714	0.9692058	-3.9200995	0.24098653	-0.09653319	-1.3726939	-0.06349425	-0.56451076	0.44763285	-0.9866585	-0.24589595	-0.09784277	-0.6566066	1.3835291	-0.5978048	-0.06949848	2.3038337	-0.9480586	-0.8753952	1.4348217	-1.3993156	-1.0945014	0.7346478	-0.25135744	0.294812	-1.1479659	-0.0420178	-1.7993447	0.85729593	-2.496687	-0.31176865	0.8256324	0.23690404	-0.29345128	-0.49853277\n2.2533169	3.9187775	4.329663	-1.5083567	-0.2559567	-0.735173	0.36061206	0.34453136	-0.26852876	0.057902478	-2.429853	-0.6791502	0.4345118	-2.7687912	1.3508081	-0.6897771	1.2134417	-1.6243284	-0.4899166	-0.4443714	-0.6472542	-1.8739647	0.51863754	2.455972	-0.7474532	0.13937773	1.3539015	0.18250111	0.41234347	-0.38371408	0.04533484	0.10464209	2.03594	0.21787891	1.010232	-0.6477929	-0.15912762	4.0956597	1.5665827	0.3243706	-1.0432724	2.6405435	-0.67884356	-0.69717026	-1.490693	1.0274754	-1.8327615	-3.5806093	-1.9080483	1.2506673	-1.682507	-0.93902683	0.62389225	1.1716406	0.9429717	0.7827143	-1.1217284	-1.132284	-0.12095889	-0.45318007	1.1318477	0.56550467	-0.09680387	1.7523624\n0.5630385	0.8946236	-1.1368757	2.0527072	-0.043471247	-1.8135535	-2.172068	-0.24311294	0.055635244	-1.967031	-2.0889273	0.5322315	-0.24150413	1.1018306	2.1633196	-0.6825469	-1.3902999	0.46716833	2.4084766	-0.8173717	2.1257956	-0.3131664	-0.99730855	0.0074170385	-1.3053346	-1.5332483	3.3245175	-0.53137785	3.832308	-0.30298635	-1.9944319	-0.35661998	-0.7321583	1.432105	1.3037978	0.63642335	0.6165728	-1.4241301	0.37506473	0.16665713	1.9245888	-1.3805269	-1.7334083	-0.38585484	3.5921733	-2.08717	1.3241534	-0.072301775	0.2514262	0.50004965	0.7679172	-0.30402434	-0.5680816	0.46736112	-2.4612763	-1.2426337	-1.5796782	-2.028996	-0.0472595	1.0325501	-2.0804234	-0.5810905	-1.640889	0.24807619\n1.0662804	-0.795421	-0.7495195	-1.9817289	-1.4217232	1.1757494	-1.3658456	-1.0273188	1.4621828	3.2225683	-0.0807439	0.3784098	1.0931576	-0.9663458	0.61836195	-2.445254	-0.8131754	-0.027861813	0.82551956	-0.058362875	-0.4116115	-3.547055	0.78305966	0.08950377	3.2611053	2.25507	1.6983213	2.3012135	-3.4645314	-0.81844234	1.2952627	-2.4591744	-3.8728688	1.0573272	0.5172205	-0.6402639	1.2348738	-1.9144233	-0.71609753	0.14813988	-0.94307476	2.4836838	-0.53205985	1.9975519	1.9293263	-1.5120854	-1.9665366	-1.1840055	2.8606985	-0.44354478	-0.61400145	-0.20240052	1.1689059	-1.1002252	-2.059359	-0.39858216	1.0558419	-0.94378304	-1.3039695	2.7233737	2.6705346	-0.53532004	-0.99869204	0.769712\n-0.8063543	2.812838	-1.3374074	0.003542522	-0.1785607	-2.014079	0.80070937	1.0718117	-0.057208013	-0.7547547	1.1132516	-0.40902779	0.3297252	-1.11293	-0.80167437	0.6036488	-3.140158	-1.6470118	1.4072263	0.19583903	-0.03535428	-2.6091402	0.3190032	0.9811484	1.273721	2.3092349	0.09594985	-0.7133947	-0.62714964	-1.0907519	0.935807	-0.29428598	2.637325	1.9432908	-2.9628205	1.7190875	1.752959	0.628197	-0.20999523	0.17717768	0.06298454	1.0478213	0.275588	-1.2884971	0.058792192	1.3782581	-1.0750611	0.7914733	-1.2947241	-2.674044	-0.2759758	-0.3351526	-0.5950414	0.508964	0.6771499	2.633046	0.40776205	0.982404	-0.9108427	-2.2247257	0.39644173	1.5361345	-1.5433933	0.6136791\n0.89057386	-0.824313	0.63651466	-2.4195395	1.1001666	-0.5103166	-1.4215379	1.1197401	-0.070315994	-0.78278637	-0.20876849	0.25527915	-1.9868195	1.4369153	-1.0812205	0.8303286	1.4668854	0.848954	-2.1512327	1.0419519	1.5089661	-1.40321	-0.47328597	-1.080031	1.7923237	-1.7969346	0.32584146	-3.3967183	1.176263	0.13992839	0.5539581	-0.1624208	-2.5003505	0.42184046	3.2659276	0.2573531	-0.79944414	-0.12600465	-0.24205321	2.1499593	0.897605	-0.3383999	1.6033574	1.4096454	1.1550226	-0.948814	0.927145	1.0243601	-0.5096978	-2.7035992	2.6909432	0.6022141	1.7820953	1.5431027	1.5425154	1.2801089	-1.4272866	0.83509564	1.2942077	-0.8549738	-2.229971	2.7707372	1.5594923	0.43136078\n-0.62029636	-0.5687178	-1.5463346	0.61176085	-1.2790091	-2.7877417	-0.3120781	-1.0457162	0.0015342468	-2.8758154	0.39470804	-1.9096109	-1.3157974	0.3945063	-2.8701894	-0.5951075	-0.2684904	-0.27739176	1.259168	2.0327754	2.9398289	1.0810056	0.369216	-0.106691375	0.94591486	-3.2970521	-2.2888188	-1.7803909	-0.6125314	-0.99563557	-0.032435343	-2.523262	0.3536741	-1.2263365	-0.00841421	-0.8755722	2.0259562	0.31225795	1.1079104	0.6425886	0.7658018	-0.09156364	-0.27223405	2.7613397	-0.71852094	0.4333111	-0.75018317	2.3412464	-0.58017033	-1.0844861	-0.105750725	0.041730408	2.4724557	0.21055798	-0.6237112	-0.7682382	0.3428787	0.0962007	-0.48074093	1.1065638	0.916818	0.012310016	1.5822586	-0.6214725\n-0.6638833	1.7552489	1.959924	-2.0259807	0.7828034	0.14932396	0.52810335	-0.01771975	-1.1991761	2.7084706	-1.235111	-2.2833962	-0.91311973	1.5999874	1.1038039	1.9667089	1.4659345	-1.9408286	-1.8892272	-0.9806835	-1.971766	1.4017124	-0.63608074	-1.8928356	2.6786425	0.31947815	-3.220531	-2.6147854	1.1311878	0.9509375	1.5789634	2.4007738	0.3766023	1.1373703	0.67384845	1.8273969	-0.294285	-1.6276597	0.21539676	0.7389518	1.5066556	0.34486508	2.232684	-0.64823127	0.4802516	-1.1893286	0.15276928	-0.85310423	0.9490358	-0.66828865	-0.49851936	-0.9866564	-0.12286182	0.656204	2.3351912	0.6085517	1.2412531	-0.70813936	0.22393021	2.6802814	-0.575929	0.25370347	1.9159311	-1.3465022\n0.76087296	1.745394	-0.5329744	-1.5461538	-0.5348798	0.9905523	0.39109203	1.1221689	-0.81499004	1.5914404	1.7214403	-0.18948779	1.2173344	-0.29024214	-0.9574338	-0.50997865	-2.2469006	1.1492873	1.1682922	-1.8431917	-4.4331813	1.9085722	-0.1895028	-0.35436058	0.861903	1.2122221	1.1363678	-1.4247893	0.997948	2.0982702	1.8453825	0.8136021	-0.46421215	-0.606801	-1.3669184	0.444306	-0.9647641	-3.297302	-1.7041242	-2.3868008	0.46681613	2.22256	-1.9504119	-2.2611363	-1.168033	1.728361	-0.5158587	-2.6467085	-1.2748781	-0.30272278	-0.7378989	-1.3017156	-2.361484	1.2476994	-0.18182035	0.89952624	1.2423971	0.7444933	0.24559535	0.52528197	-1.9900594	-1.9128982	1.4707143	0.40628102\n0.40682134	0.45121664	1.8046315	1.0974361	2.372072	0.4052838	0.43440628	0.43172193	-0.4015976	-1.2087473	0.18713175	1.5238513	0.98997766	-1.7859633	0.7011588	1.4611348	-0.17834328	-2.0949893	0.10146188	1.9104991	1.7608197	-1.7022564	0.07158911	2.3018868	0.60174805	-0.38737854	-1.042483	-1.1613314	-1.3120934	-0.75768006	-0.16423722	1.4968692	0.91670024	0.3347609	-1.582936	-0.121619456	2.743565	-0.68697464	0.00039582993	0.5104929	1.0805051	-0.9325967	-0.5252016	-0.13585871	-0.4922824	1.322324	0.85176694	0.23240915	0.7035073	-1.9155136	-2.7696755	-1.6541762	1.7597116	0.4330796	0.58491725	-0.8468114	4.109128	-1.4136988	-1.0406071	1.3032912	-0.081278086	-2.092178	0.3292129	-1.4241365\n0.1374058	0.6247584	-1.6048803	-0.8407414	0.15287358	-0.49974632	-1.9018488	-0.45427397	-0.367397	-0.91247284	-1.1142535	3.6844125	1.5823305	1.4730388	-0.518604	0.77670443	1.2890651	1.4513601	0.5484481	0.9607004	-1.9636977	0.29697	-1.4574201	-1.099924	1.2528912	0.23636566	2.708972	-0.6119868	-1.9015505	-0.60165477	0.51997876	0.168393	0.27777863	1.8132584	-0.35631162	-0.09262724	-0.68502617	-0.65989953	-1.5879526	0.99073285	-0.79379374	-1.2324413	-0.6753744	0.732466	-1.0891911	1.0239584	-1.5927368	-1.8353468	2.6853535	-1.7923024	-0.39184877	-1.6519383	-0.4271847	2.661672	-0.88599694	0.678206	-0.2657234	-1.1018442	-1.7565373	-1.0078197	1.9917051	0.16894	-0.18537505	-1.7738285\n0.9933486	3.5752697	-1.4805251	1.2196552	1.1901058	-0.30681846	-0.661736	2.1356652	-0.3330279	0.71306133	-0.42549315	-0.5270194	1.3947835	0.70602804	1.9646811	-0.55001837	-0.2751523	-2.0917745	-0.24344689	-1.9355304	-0.077909745	1.9430381	-2.377522	0.35341343	1.3059517	0.86892736	-0.5292168	2.5182283	-0.59642255	-2.639831	1.6092498	1.0331724	4.047991	-0.0060937274	0.22418338	1.1903683	-0.8797793	-0.040751133	-1.3976017	-0.41466385	-0.37037858	-0.13944675	1.3080941	-0.65601194	3.5891933	-2.227656	-1.5843081	-0.45395625	-1.0267777	-2.2860663	-0.52500266	1.9305166	1.0101311	-0.28848398	-0.8656576	-1.6150753	-0.45764297	0.59782916	0.067188695	0.72676927	-1.7437158	-0.30993134	-0.96750194	-3.008467\n-0.21148878	-2.3642733	1.2714726	1.1991864	0.6044296	-1.7698512	-0.4097563	-0.75443536	-0.01430088	2.9114702	0.30055133	-0.08613213	-0.49132663	-0.49440742	0.17665821	-1.5026689	-0.33909258	0.14680682	-2.7086487	-0.97180516	-2.8656967	0.695557	-1.4497972	0.8854457	-0.63340473	0.9484354	0.094600745	-2.1759322	0.7517102	0.5372124	-1.887457	-0.68967754	-0.37432978	0.6197028	1.9917266	-1.0786912	-2.032771	-1.8374633	-2.487971	-1.9718931	-0.7581197	2.405145	-0.89487565	-3.9800406	-0.7280203	-0.68586594	-0.15946384	-3.4939864	0.2497162	1.5707046	3.424054	1.0903672	1.9684621	-0.20779434	0.72985494	-0.7773704	-1.6142464	-0.036220036	-1.4478548	-0.046466395	-1.6141979	-0.10135088	1.0116577	-1.5058255\n1.1761309	0.1830402	-0.036186256	-3.0303566	-1.6612216	0.38444835	-0.6683196	-0.9594161	-0.7740211	1.2117467	-0.44367287	2.4777973	-2.7197459	-1.5980904	-1.5492984	0.17038973	2.1681693	3.1988068	-1.3838965	-2.2055485	-0.4535548	0.7380233	-0.41370943	-2.1855683	0.56592023	0.118995234	1.196061	1.7745761	0.8583662	0.7218919	-0.55649525	-0.69783986	-0.16130288	1.4888325	0.39707947	0.8715083	-0.693298	-0.1667511	-0.59919745	1.0778061	-1.0800533	0.04949125	1.6315647	-1.1679084	-1.9983191	2.010551	-0.048813134	-0.46932188	-0.1960089	-2.542466	-1.5639431	-1.7014173	0.7042074	-2.6506357	0.8008078	-0.2798828	-1.432417	0.27570054	-1.1233664	1.2361125	-1.7889197	-1.4501125	1.4971327	0.6489614\n0.60970205	-2.3914154	-1.1518669	0.79493535	1.4344264	0.0990942	0.8509646	-0.68910086	-3.8677485	-0.84340656	1.2064476	-1.384329	-0.37608075	-0.2430781	-0.8172191	-0.5911343	-0.5427438	0.7359816	1.7026973	-0.5452369	0.38741457	-0.37238652	0.055345986	-1.7394	-1.650011	1.9637783	-0.29169965	-2.6796906	-0.3241694	1.1331481	0.58917284	1.080086	1.1232917	-0.26611418	-0.07346924	1.9551076	0.771889	1.5027953	2.0823505	0.3761239	0.30241156	-1.5776716	-0.018322801	1.628948	-1.3437575	2.8433053	-0.09400477	-0.841017	0.22157039	2.302454	1.6776794	-0.88469195	0.1587679	-1.9756615	-0.59717196	-0.36527437	3.4324763	-1.254431	1.0649282	0.116395324	-1.7991639	-0.55138177	-0.7968688	-0.22872534\n1.3283801	-0.9248354	0.31137007	-1.598032	-0.554715	-0.26043415	0.50140566	-0.65999025	1.2009106	3.2730358	-2.3571553	-0.27931243	1.5337812	0.92903537	-0.331549	0.17744802	1.3079166	-0.26779857	-0.102284715	0.46407855	-1.3227129	-0.15425006	-2.5368562	2.427933	-0.7668363	0.97400016	0.7090762	0.45179504	1.2830083	-0.17515038	1.3175236	0.69259673	2.5833545	-0.25972375	-1.7676715	-1.9707727	-0.6971303	-2.5404544	0.6831738	1.9212463	-1.0011749	2.3562284	-0.28100392	-0.24608758	-1.635608	1.8020554	0.6361035	-0.24865931	-1.5746862	-0.65292555	0.46576703	0.16523482	1.1954749	0.7396701	-0.30185953	-3.651565	2.3348992	-0.35035077	-1.1401592	-0.75151396	1.2069579	0.73050684	-0.21181285	-0.6456995\n2.938924	-0.9285664	0.22956944	0.0403066	0.9322455	1.7378069	-0.6729089	-0.7083254	-0.26992765	-1.6757606	1.9819721	-1.3480228	1.6523733	0.6548627	-1.5510858	-0.59315336	2.0852587	1.2229574	-0.2511891	0.98278415	0.24137774	-0.89614266	-0.02631687	2.4515378	2.0736248	-1.2409151	0.016155178	2.0808647	-0.11586756	0.043269493	-1.2448847	0.32287845	-0.0049523204	0.73227274	0.6943169	-1.4680928	0.26161826	-0.611661	0.9398021	0.20306034	-0.7233309	-2.1692338	0.6710885	1.3477263	0.34252712	0.6991822	-0.40692744	-1.126468	1.9521974	-3.5521317	-0.68974787	0.79826033	-1.9655008	2.0257618	-1.7689196	-0.14636415	-1.5978124	-2.15631	0.64205164	-0.40271422	1.6589962	0.007959498	0.14755243	-2.2012951\n-0.628438	1.1368527	-1.2041739	1.69804	0.760828	-2.9876356	1.7883303	-1.0987822	0.24536811	-0.41859525	1.0117685	0.25402445	-0.4765044	0.31288865	0.7170509	0.55531526	0.99596834	-0.86733264	-1.0551754	-0.12189079	0.25668418	2.0592344	1.9741037	0.27609965	1.8774449	-0.2014031	1.0626603	-0.3209235	0.7029325	0.23442273	0.48190197	0.82846934	1.8030125	0.34834507	0.9033057	0.15011741	-0.47931567	0.6653441	0.31955522	-0.95737654	-1.5779668	0.8193722	0.057207037	-1.5735488	1.1286911	0.12080539	-1.3730127	-0.45301902	-0.85739213	0.11440062	-0.06309876	-0.63726765	-0.14353034	1.3973289	0.2840643	0.8726658	1.3244178	-0.6894377	2.086168	3.0557446	-0.38033321	-1.1894172	-0.77779794	-0.10677846\n2.3848739	1.8546945	-1.2906106	0.8024726	0.76685935	-2.8122158	-1.2340648	3.6879392	0.8650748	0.36404845	1.0374635	0.80797535	3.267093	1.707417	0.5685609	1.3775859	0.9478821	-1.2066972	-1.3299999	-0.030986013	0.08555452	-0.5140174	-0.040156573	1.0262254	2.895837	0.33281535	-1.4313911	0.15420741	-0.73342437	-0.8778333	0.5976969	2.7840326	0.23975393	3.287606	0.466867	0.47136196	1.5163429	0.49925008	0.76955175	-1.2583785	1.5906903	1.3916802	-0.42183045	0.3543977	1.0402521	0.9103535	-1.4438289	-0.9360782	-0.98565215	-0.4837675	4.6582627	2.5423305	1.1249084	-0.0020877176	1.9558539	3.024975	-0.7883388	1.3103029	0.105921164	-0.9735815	-1.5329779	-1.163534	-2.0308676	0.8406922\n1.112617	1.1606532	2.496357	-0.65509427	0.035816874	-1.1375293	0.068905875	1.4169894	1.2334019	-0.7302713	1.7807553	3.1891532	1.077954	0.36107048	2.204322	1.437867	1.9020959	0.67555207	0.71181303	0.6856511	1.222062	1.0426826	3.2291377	2.6181407	-1.8345873	-1.3666091	-0.10801861	1.3963566	-1.0015968	-1.7803724	0.76763076	1.4575948	0.9737785	-1.3123416	2.617636	0.35460916	0.17381299	-2.269864	-1.6130828	-0.9747171	1.5548443	-0.13270086	-0.9550963	-1.2490914	-1.6808968	2.6269267	0.84145725	-1.2838122	-0.33855245	0.94560623	-1.0988121	2.1833901	-1.0618463	2.009802	-0.30731982	0.97495514	0.7100755	1.7243265	-3.1741633	0.6769255	1.7243816	0.64162374	0.46856266	2.4119856\n0.88326913	1.8195698	0.3344743	1.9905543	0.55496967	0.12290654	-1.4844216	0.08580039	-0.9599298	1.3766506	-0.98886126	0.580023	-3.3739188	2.1119072	1.2892817	-1.2807707	0.9164647	-0.661378	-2.2313316	-0.832416	-1.7278227	-0.15433742	0.44095516	-0.5612103	1.7981743	-1.5894498	0.13905466	0.15411696	0.23815604	1.010846	1.852082	-0.6180269	0.9437449	2.3576252	-0.5217653	-1.5222645	-0.79857373	1.4522753	0.1973605	1.5205709	2.2341413	0.02842454	-1.0551378	1.0639415	-2.1628387	1.7877457	0.8367673	0.60321057	-0.7472001	1.5326116	-0.8123807	1.4987457	-0.06028681	-1.1160179	-0.8871036	1.0040097	4.1262703	0.8896243	-0.05887387	0.81633383	0.7621	0.005839091	-1.1879518	-2.032335\n-0.6897827	-1.0204905	-1.1934841	-1.8594835	1.1244484	-0.62430197	-0.49349964	1.3845898	-1.7291931	-0.45303002	-1.0279164	2.1571717	0.07187865	-0.40261096	1.3831908	-1.5858146	0.08822263	-0.61062986	-0.6277231	-0.39131677	2.1840067	-0.45259532	-2.294055	-0.1430111	0.23797575	-1.5579693	0.48753673	-0.43019262	0.12786248	0.35040817	0.35665298	2.6521344	-1.266449	0.1187028	-0.15263368	-0.8413343	1.7918959	0.061213687	0.060001157	0.04019614	1.9472336	1.1152722	-0.73524845	0.8153322	0.7417977	-1.871572	0.23082516	-0.23971856	0.03603287	2.6274698	-0.5026287	-0.05619086	0.25211012	0.30690822	1.235911	2.865652	0.9224467	-0.707859	0.60037315	1.6133326	-2.2065985	1.153478	0.22200398	-2.6202152\n-0.8223221	-1.479054	0.78540415	-1.4854293	0.6147644	-1.54332	1.5928552	0.110185	-0.9968417	-0.34546337	2.1306143	-2.3760052	2.9802415	1.2142221	2.0541906	-0.4783269	0.30024657	-0.99663115	-2.043085	1.6830784	-1.7705797	-2.0404532	-0.5517408	-1.0599804	0.072056375	-0.50988746	1.8894358	0.47707036	1.8367283	-2.0136015	-0.05825851	1.1588356	-0.6536638	1.5383824	0.47839853	-0.96224403	1.1057554	1.3378568	-2.480209	1.165995	-2.104165	0.83668137	-1.1224489	-2.1815236	-1.3020977	-0.9223229	1.2610443	0.60907596	-2.0076716	-0.21199837	1.6724052	-4.56231	0.050040707	0.43191692	0.6915637	-0.3056442	-1.331645	0.34619194	-0.81053126	-2.942656	-0.062975116	1.5898839	0.025335245	2.715092\n-1.633711	0.8464375	-0.6418068	-2.7059228	-0.5901851	0.82141846	1.0127904	1.1920695	2.4203458	-0.05590257	2.7747536	1.8630292	-0.39822948	-0.61887795	1.1158572	-0.2257831	-1.5073446	0.17200236	-0.6374432	-2.124822	3.494832	-1.407333	0.8892505	-0.31925192	-1.213584	2.275773	-1.5327954	-0.21121973	-1.1856128	1.5093215	0.4383406	2.0301387	-0.9443736	0.9686616	-0.16544692	-2.4075513	-2.0000796	0.4025335	0.1997938	-0.5835994	-0.02800916	-1.746278	0.8558896	-0.1967	2.3300452	0.8191889	-1.4660013	4.0884657	1.6290909	-0.32247594	0.34638217	-0.49331155	0.78268623	0.11939189	0.35241613	0.35632995	1.202584	1.2838717	0.55856407	0.4314887	0.03343221	2.3093433	-0.45953333	-0.6431985\n0.17539085	1.9556378	-1.2435166	-0.05813884	0.25205258	0.195605	1.5191231	-0.26584956	1.0972055	-1.9652183	0.034273025	-1.9818485	1.0974041	0.89809203	-1.2761517	0.50378317	-1.882297	-0.13826194	-1.9691572	0.40408412	0.7581065	-1.9182947	-0.7058572	1.7708044	0.64920086	1.8773375	-0.059576374	1.4177155	-1.9377494	0.17679624	1.3523906	1.8556943	0.9913988	-0.5581059	0.8748734	-1.0902073	1.384882	0.9717005	-1.2264537	0.9592231	1.6003054	2.4574103	0.00928008	0.8278825	2.674953	-0.43337566	-1.2886431	-0.92401713	0.9947571	-0.9890089	-0.85507894	1.2235085	1.5935751	-0.9655341	-3.2185853	-1.3099555	-1.0000483	-2.2973404	0.68749607	-0.2671707	1.5478469	-1.3594884	-2.1512537	0.5952514\n-0.30945742	0.84600407	-2.0787096	0.09299273	-0.7728174	-0.73146373	0.6017056	1.0897115	-0.39340344	-1.7287918	0.86584663	1.4500347	1.1654189	-1.4970604	-0.42094013	2.118142	2.3633122	-0.6127818	0.8342836	-1.1717834	-1.2965001	-1.8836864	1.2870393	-0.7753053	2.48656	1.1114691	-0.03672571	-3.1263797	-2.7916522	-2.8671036	-0.19023302	0.29027268	-1.9595207	-0.33976036	1.6450855	0.4523492	1.8288673	0.5396577	1.1045355	-1.3531886	-1.1913011	-0.068322405	-0.36724862	-1.8876749	-0.20525733	-0.7937503	0.8112542	-0.49491745	0.42273346	-0.102031656	1.5396615	0.5400984	-0.14991252	-2.97231	-0.28203544	-1.1087219	0.5388911	0.60423285	-1.0656595	-2.5108674	0.1928567	0.35329303	-2.4671745	3.238665\n-1.1109477	-2.568287	-0.5676646	-0.52703905	1.6883698	-0.100216255	-0.10311602	0.9185546	-2.0905695	-1.7560391	-2.3952782	0.28282836	0.0280337	0.5490998	0.31234506	1.8599871	-2.8673115	-0.40935552	0.19386376	0.62539715	-0.5631013	-0.754775	-1.442067	5.06774	0.11142975	0.10938528	-0.77979195	0.5154783	0.0013955632	-0.013541836	-0.73390543	0.19776803	-0.42896983	3.0335002	-0.37636667	1.2467954	-1.3389589	0.27958533	-2.52062	0.69796515	-2.4021873	-1.5642961	1.8293432	-0.67480147	2.194339	-0.81015605	0.10077007	-1.1167879	0.43682843	-0.87701076	-1.3425305	-2.2774713	-0.4580285	-0.01812978	-1.1641098	3.5988607	-1.9020491	-0.07215777	-1.2337618	-0.025688205	1.463117	1.6670529	2.6191497	-1.8887172\n-0.71467525	0.28695482	2.0970612	-0.10388727	-0.6906104	0.048800584	0.3795771	0.39755264	-1.360908	-1.0177879	0.14389583	3.3432865	2.742908	0.05139745	1.3550463	-0.6948085	-1.761731	0.51204604	-1.714972	-0.97929525	-0.6069114	-2.874989	-2.4648173	-0.95647144	0.89162594	0.12600504	-2.6611612	-0.066285774	-0.8180435	-1.918408	2.769006	0.8573381	-0.8213797	-1.9732912	0.9709212	-3.1777232	-0.090755194	0.40185025	2.2353945	0.6562229	0.3847288	0.8776747	-0.96615034	-1.3092116	-0.34686396	-0.8491381	-1.3321415	1.4487729	3.2197652	-0.8832115	0.6899078	0.7853855	-1.5451365	-0.16336903	3.2735152	0.7657582	1.3701938	0.032415595	-0.5440151	1.2007387	-1.0498289	2.2961154	0.12675408	2.3612866\n-2.2393315	0.7651198	-0.46462804	-1.3681928	3.0195887	0.82831365	-3.1804562	0.26301605	-1.6650336	0.06229002	1.0069996	-0.8359438	0.13034402	0.96998155	-1.7711774	0.84216803	-1.9564661	-1.2714112	1.1631263	1.1156048	1.0190139	0.7083804	0.10392988	0.3329277	-0.46580505	-1.2408319	-0.548706	-0.9867162	-1.4771526	0.91919565	0.1771005	-1.1114866	-0.39956	1.8838307	0.08534755	1.7372202	-0.28449148	0.13228494	-1.4826026	0.19611439	0.13822111	-0.44610053	0.6137857	0.00096686254	0.7446174	2.4957078	0.15007958	-0.5426498	-1.1431378	-1.3269392	0.6184875	-0.36979422	0.29747063	0.15572977	-0.12807742	-0.0052061183	0.92692566	0.16064218	-2.76272	0.7044548	1.2306072	-0.11622992	-0.8980956	1.5112156\n0.37775856	-1.9666854	2.3560383	2.7176378	1.5446523	-1.5374413	-1.9155275	1.8880473	0.16617188	3.1394625	0.5403653	0.20208588	-1.4288554	0.36960036	-1.2034556	-0.2786862	-1.5168723	2.1127684	0.54523486	-0.7783649	0.9561553	-0.6322545	0.009581553	-1.146152	-0.14556015	-1.0375814	-0.74723834	1.3531816	-0.48991168	-1.0162959	0.99455714	-0.78850573	-1.0697966	-1.9644084	3.507485	1.6233714	3.844822	2.5487473	-2.149773	-1.1532873	1.3745084	-2.2022314	-1.3654097	0.8250949	-0.41828418	2.0926259	0.5931078	0.7506173	-1.4400235	1.3297715	-1.5715473	-0.9123572	-2.984472	0.48023015	-0.00889917	0.19371209	-2.300909	0.3204499	-1.0639747	1.035576	-1.3196256	-1.7156285	2.8619258	0.108888984\n0.5924974	-0.16608459	1.7922453	-1.8910106	1.23659	-0.11370951	1.7969238	4.7478743	1.060344	0.12518689	-1.0934813	0.53138644	-0.5933734	0.74334544	-2.3484669	0.4706557	1.4853355	0.29474872	0.28378367	2.3460343	-1.9814475	1.0025797	0.3952372	-1.2216653	2.2209632	-0.33901232	1.1868696	-1.837018	0.42625168	-3.0400426	0.20912948	0.1743701	0.014072352	-0.68278086	1.1091887	0.272772	0.085227594	-0.94483	0.2534227	1.5170486	0.25777876	0.15202014	3.7333589	-1.7958337	1.8575549	3.0235126	-1.3681655	-0.55843025	-1.2487885	1.0399822	0.6356826	-0.25008816	0.5120997	1.7826339	0.41548625	-0.7066316	0.05960442	2.0702634	1.7813699	-0.58032745	1.6829898	1.4064603	0.36256748	-1.3506619\n-1.0061119	2.1260107	-0.061938148	-0.37442064	2.0474494	-0.5445572	-1.5415515	-3.6802235	0.16365351	-0.60483694	2.280335	0.44927767	-0.3684974	-0.6197605	0.36852172	-1.4765266	-1.5481868	0.18874703	-0.36441916	0.0679834	-1.230289	0.14408818	-1.9662936	0.80877584	-0.68919593	0.87229306	-0.94889677	2.3095334	-0.43333212	-1.5950708	0.16271468	-1.7520812	1.5380127	0.679283	2.529825	1.4535418	-0.82148856	-1.5045931	1.2745278	0.7055499	1.620627	0.9323755	0.15735869	-1.7887915	-1.823003	-0.42472968	-1.6653794	1.4140716	-2.4716268	-2.2797341	0.7839361	-1.2462074	-0.8373327	1.7957748	1.1169856	1.7952539	0.35717157	0.6083879	-4.129256	0.49200517	-2.238183	0.90730745	-0.4159538	-0.0131595135\n3.7407005	0.10530719	-0.30181307	0.3657774	0.3751869	-0.32107198	-0.71543294	-1.2673889	-1.422488	-0.06503122	-1.3550979	-0.19702977	2.3787243	0.120853715	-0.13182382	1.5635141	3.6007125	1.7943909	0.12658706	-0.48681659	0.8284423	-0.6875918	0.16153613	0.18684971	-1.0060583	1.9361814	3.0652916	-0.16134319	-2.3836684	1.3309922	-3.7638688	1.4277538	1.3490007	1.9694251	-1.1109035	2.342232	-0.31107908	-0.48117626	-1.6718949	0.5568989	0.9532809	1.2158265	0.7292235	0.040463235	-0.48829842	2.1678848	1.7803133	1.5996739	0.6392698	1.0508566	1.7678927	2.3140907	-0.5609311	1.2876123	0.83053565	0.6643411	-1.611677	-1.3245587	-0.66647506	1.637076	1.5326436	0.11404591	-0.18724586	-0.21430138\n-0.55638343	0.5691751	-0.14555834	-0.38594148	1.6564828	-0.3638204	1.3276137	-1.1983466	-0.34224352	-2.6032221	2.1482148	-2.5109234	0.8580741	1.0848761	0.3893505	0.32244188	-0.8328861	3.812067	-0.019994052	-1.5472294	1.8688463	0.69496024	1.1085299	-0.5961969	0.58627623	0.71810985	-0.81612736	-1.1414233	2.4794145	-0.1688599	1.575475	-0.6628663	1.0428843	0.9921248	-0.00091997144	0.3821977	1.3521034	-0.4680115	0.34019288	2.7101882	1.2861944	0.43619052	-2.5935557	0.8070232	-0.2054334	2.4074855	-3.4658632	-1.49225	1.5431927	2.06118	0.16745864	-3.5418713	-0.55017686	0.58199847	-0.23324153	-1.0061164	0.77312803	-1.3807927	-0.14821912	-0.98020476	0.70046824	-0.019682357	0.97487825	-0.7041017\n-0.7174124	2.2506697	1.4813772	-2.0525353	0.24456377	-0.37055874	-1.505198	2.0298347	1.2100425	0.4031368	-0.72635144	-0.3080312	-0.08426298	3.240007	2.3003976	-1.575916	0.03383187	1.8008215	-2.1120727	-1.6970329	0.7845922	-1.4762405	-2.2909544	1.7367446	0.2362813	0.8833939	0.4018744	1.0487398	1.5185549	0.1095593	-0.6786364	1.5422195	-1.2553645	-0.8137475	1.4798001	-0.2615584	0.3794351	-1.4534997	2.4115303	-1.2582872	-0.5518527	-0.06269159	-0.38409215	-2.0345168	0.067454174	2.1794455	1.576031	0.31168273	0.56737363	-0.28404194	2.14639	-1.1760818	1.5331974	-0.6597798	-1.1171612	1.9930696	0.19794789	-0.12628262	1.3605837	1.8916254	0.10700541	0.43644756	1.1499652	0.029718569\n-0.75391114	-0.40484625	1.4361789	0.93960685	-2.3192253	-0.5063884	0.17671148	-2.091656	1.6373631	2.7993257	2.8722832	-0.34562507	-0.5979605	-1.9487414	1.2591347	-0.48048177	1.0625974	-0.86307156	0.38439822	2.4004526	0.99614143	0.20993456	1.0962718	-0.51077247	2.0333624	-0.8418543	1.0736256	-0.0011816593	-0.02072	0.38974935	1.24711	2.641881	0.67499113	1.117244	0.20139977	1.0674773	2.0469677	1.4085191	0.07279063	-0.22646625	-0.27159324	2.5374804	-0.544528	-0.8085698	-0.50543755	-0.74935544	1.862334	-0.020464268	2.4162784	-1.6940101	-0.47209477	2.3078425	-1.4675173	-2.7485003	0.8291883	-1.114657	-0.091074675	-0.6261453	0.66165173	0.77175945	-2.9984236	-0.5689314	-1.5615399	-2.2048106\n0.17629594	0.38186747	0.2105059	0.66727287	-0.027678842	0.81955934	2.1804516	0.9501657	-0.64283055	0.50167125	2.2567427	-0.38902885	-0.8107774	1.6771755	-0.10169056	-0.58327425	0.11924437	-1.1776122	2.3125906	2.233495	1.2693962	-0.5871239	0.55136395	-1.4233129	0.41699147	0.034948636	1.0301923	-2.0829692	-1.1602536	-0.46453205	-3.0473485	0.11122727	-0.36103296	-0.08760588	1.1904126	-1.4880995	0.17703237	-0.5592302	1.2489293	-0.710858	0.36333087	-0.77591753	0.109302685	-0.40481368	-0.32283452	1.0157624	-0.7203759	-0.4620281	-0.14651401	-0.3236302	-0.61357987	-1.7343078	-0.13611126	-1.2805527	2.0977833	-0.41573685	-1.0805888	1.1775842	2.3608832	0.24187498	-1.3483186	0.35971543	-1.5532866	-0.91889095\n-1.5225042	1.1027824	0.32016027	-0.7760249	-2.7797477	-0.45671406	0.9929968	-2.1113114	0.95315135	-2.4494913	-2.8299565	1.4366192	-1.9661678	1.6368036	-0.3758457	0.96522766	0.14809853	1.0206317	2.338378	0.90883565	-0.14046384	-0.070065476	-0.38571534	0.9720979	1.0161029	0.32662857	0.93146527	0.0570178	-1.7907975	-1.0502611	1.2125286	-0.9024501	-0.065385	-1.2188395	0.4466173	-1.4971166	0.9961005	0.61695784	2.8322594	-2.550511	-1.1555338	1.0269415	1.268966	-0.8003846	-3.4734159	-0.82387364	1.009447	0.26841298	-2.1963334	-1.361812	-1.2799122	-2.0826185	-0.108554706	0.34194863	-1.1098876	0.28591052	0.29979602	1.2467482	-0.35836858	-0.031223759	-1.2874004	1.0884808	-2.7344904	-0.64079267\n-1.1760266	-1.016111	-0.4867057	-0.65932786	0.8560046	0.79274774	-0.16080174	-1.6639422	-0.19413345	1.8317577	0.5703742	1.2597171	0.06302939	0.41878757	-2.2548592	-0.9621802	0.86697733	-0.14100048	-1.5135956	0.56649244	-0.8436267	-1.004698	0.028983299	0.5040012	-0.58180404	3.031419	-3.3258233	1.9196118	-0.49821433	-1.2447731	2.93018	0.3599667	-0.18371148	3.2740924	-1.711396	-1.2874438	-1.857358	0.8676127	0.06262817	-0.08368335	2.043798	0.99880695	-0.41630206	-2.7973793	-0.6262622	0.027519707	-2.4553335	-1.8034915	2.4017534	-0.6734674	0.55982023	0.0042617866	-0.23864332	-0.3676713	-0.23741975	-0.42757857	-0.6809227	1.5554996	-0.7887055	0.6553777	0.54184824	0.46846715	1.697928	1.8892605\n-1.6378229	-1.0228442	-0.8521653	-1.8509048	1.3724116	-1.1089524	-1.5364238	-0.44658777	-0.51922417	-2.0652437	-1.9018776	-2.5044405	1.2151753	2.1604908	1.3722001	0.60836506	-1.0147824	1.3502736	1.6747348	0.3249067	0.00799625	-2.048037	1.2418206	0.52994764	1.5932847	-1.2326344	2.0175757	-1.9259254	0.6055938	0.6674575	2.818562	-1.3567916	2.1701143	-0.8525203	-1.6648353	-0.4469173	0.11708771	2.4118156	0.0013193842	0.8969579	1.1706536	1.4769157	1.9565357	-0.97609216	-0.15884483	-1.8265287	-0.16573074	1.529645	3.0861413	0.82770807	-0.10552336	1.2133296	-3.0072641	0.9466702	1.6915029	-1.99614	2.3324227	-0.018769916	-0.9183681	0.35724348	0.06090239	-1.8637383	2.0035484	0.9422102\n0.71713734	0.14295931	1.0692796	-0.55398923	-1.3336987	1.5939684	-1.9017571	0.16694796	-0.93424726	0.1720121	-2.4616675	1.792672	-1.2468208	1.3817866	1.5238379	-0.7560605	2.3499336	1.5861375	-0.19992273	-1.4958181	0.25496784	-0.96965533	0.61253697	0.0399525	-0.13759966	-0.77996767	1.7781167	0.118217	-0.8408019	1.5410157	-0.27726996	-1.956861	-0.19473583	-0.79741687	-1.4291033	-0.35823676	-0.6722463	-1.507618	0.76187116	2.8960748	0.090289794	-1.4066606	0.71541506	-0.18688548	1.3364546	1.2055602	-0.46215677	0.6842304	2.3383722	0.06467644	0.62243396	0.9615797	-0.7046453	-0.43679592	0.106431864	0.39334577	-0.475181	-0.8806101	0.2824515	-0.48428595	0.10358083	0.3239841	0.25206533	-2.4815152\n-1.4917469	0.27377212	-0.3753723	-1.4618077	-2.0525427	0.45647898	0.43196085	1.1916718	1.7276126	-1.4522754	-1.0345569	2.4491353	-2.396942	1.8573141	-0.16983432	-2.5813065	-2.169895	0.7200044	-0.8306573	-1.2035027	1.3912112	0.35004616	-0.6898675	2.5726109	-1.4586929	0.3856306	-0.36448318	0.66733444	1.0073898	1.5260108	3.5737743	-1.6018878	1.6069629	-0.31980422	0.95150936	0.25851533	-1.3439997	-0.9892943	-0.7062826	0.42488298	0.7971751	1.3219752	-0.52605647	0.86174846	-0.5702768	1.2405964	-2.6539125	-1.938912	-0.28921002	-1.8831671	0.20188856	-0.55977654	-0.3439963	-0.15329497	-1.759433	-0.5632422	-1.7560269	1.4361405	-1.3808582	0.025906084	0.7941803	1.1845176	1.7611988	-1.6082051\n-1.3976238	-0.2797075	-0.9117109	-1.1368706	2.3217661	-1.5146742	1.5046163	1.1473863	1.1540483	-3.5829751	1.1946808	-1.5471656	-2.115236	1.387597	-0.6765159	-0.6515977	-0.53594315	-0.50000167	0.46528697	-0.85173976	-0.066834055	-0.24464293	1.6552614	0.8223216	2.7318356	1.5624306	-3.3763552	-0.52156264	-0.22081318	1.0309286	-1.6378305	0.5835338	1.1342324	1.8727086	-0.4930687	-0.4908515	-0.2012469	1.47276	0.11224986	-1.3888136	1.6370065	-2.1256032	-0.6924532	1.2287974	-3.0917346	2.4192295	-0.0035192643	0.36926848	-1.8995206	-0.4818867	-1.1023136	0.06849639	-0.85984993	-2.0175343	-0.7150164	-0.90201133	-1.5725644	1.199462	-2.411997	-0.6985377	-2.1055872	1.3010907	-2.5130906	-0.01026553\n-0.66727877	1.6328809	0.1477591	0.6036466	0.4414165	1.1782303	-1.0250064	0.54916656	-0.38308188	1.809426	0.84971786	1.6963546	2.3333302	1.5708168	0.8353886	-0.548683	-0.6994846	-3.1987984	1.0712742	-0.28902182	0.87897396	0.4384317	2.4599829	0.46832561	2.7286212	-0.86501884	-0.53041	-1.7139459	-1.8539921	1.7667358	-2.6426954	-0.4518097	-0.0644461	1.3084263	1.5426435	-0.48233113	-1.072932	1.7396669	3.676555	-0.16710936	0.9572661	-0.3206629	1.4454404	1.2015345	1.1942235	1.0135834	-0.6607828	-2.264185	0.088283226	-1.0876571	1.9407476	1.5648365	-2.7142453	-0.20612393	2.6587608	-1.7582128	-0.33763763	2.2846408	-0.68240637	-1.0862952	-1.7983818	1.2421588	0.25103447	-0.06301117\n0.62347007	-0.6217084	-2.7756765	0.50801444	0.61782736	0.7751198	1.7518904	-0.18231642	1.0424163	0.9393517	0.667831	-0.51018655	-1.8679148	-1.0316362	-0.07340483	0.48349792	0.781628	-0.7070702	0.24096918	-1.499465	3.9073572	0.9057633	0.27470934	-2.0015666	-0.63553154	-0.96280766	-0.18464734	3.0483162	-0.3980106	0.74362165	-0.8251824	-1.0110745	1.1156994	0.9200043	-0.27401802	-2.086136	-1.2526019	-1.8164772	0.8278416	0.95279753	1.3965678	-0.21898274	2.3025718	0.8804701	0.814731	0.7363632	0.30236164	-0.46122524	0.678782	-0.06852493	0.82585204	0.27212352	-0.1895549	-1.1168052	1.0955194	1.2954013	0.28918582	0.085805655	2.7510028	-0.24159515	2.763611	-0.25737643	0.8641174	-1.635605\n-1.2358704	-0.76347566	0.9856605	0.49038464	1.0203068	0.2581358	-1.4499812	-0.97502714	-3.4216099	-1.0198926	-0.059602942	2.229064	0.45797783	2.3127418	-0.63332015	0.056182757	2.258474	0.09862358	0.87870073	-0.94064075	-1.1338706	-1.7396635	-0.80061054	0.0069830916	0.5092734	0.4487048	0.68874705	0.77419424	0.23953138	-0.831735	2.3622189	1.1692075	0.5804609	-3.0738165	1.82353	0.26687917	2.6001668	-1.2866746	2.6311917	-2.1542852	-0.3228619	-2.0859098	-0.47856167	1.2819164	-1.268213	4.135182	1.1916931	0.793328	-1.0941758	2.5964277	0.47415516	2.128747	0.09491757	1.0321319	0.4081279	1.2443641	-0.768934	1.3501449	-2.8034472	-1.6402657	1.3141001	-0.13991077	-0.14683466	1.820806\n1.7126669	1.5563337	1.7143596	-0.13715655	-1.4794486	1.289096	-2.7173247	-0.23393995	-0.245628	-0.39808747	-0.6746474	-0.7198315	2.161187	0.6117731	-0.3017608	1.6810548	1.3686169	-0.79421824	-1.4062467	-2.1549952	-2.896607	-0.64544445	-1.8040464	0.4992283	3.440687	-1.1290673	1.3396682	-2.2416162	0.63176644	-0.21317528	0.39610672	-0.66583306	-2.1914773	-2.507045	-0.6702499	1.1718857	-1.4172155	1.4005691	2.1093733	0.070189916	0.93285024	-0.22581814	0.532725	1.0001167	0.6069553	2.1786127	-1.9769619	-0.5550395	0.41086024	1.7793202	-1.034139	0.29144683	2.7683342	0.023142587	-1.5044512	1.5021297	0.48036847	0.9265908	0.8277947	2.3996596	0.7373583	-1.3971	0.6359371	0.41713905\n1.4006699	-0.8161545	-1.4347743	0.6228073	-0.44991422	-0.47479007	-1.2537943	-2.6453733	0.93011636	0.9515847	1.625421	-0.4122566	-2.0030346	0.5626368	-2.940129	0.13088316	2.0602572	-0.37655815	-0.29683715	1.0910766	1.0866555	1.1335572	0.7499306	0.98516005	1.2219832	0.05998504	-0.6507063	-1.5691073	1.3218888	0.75278693	0.9623366	-0.73168427	-0.2632255	-1.543105	0.6646557	-1.9379811	-0.60528004	0.14286572	1.0194349	0.7007667	-0.5476649	-1.311555	-0.41405523	-1.081614	2.864389	-0.35591972	-1.4804876	0.17878138	-0.5003132	-1.5916568	1.0596308	1.921962	-0.21134351	1.3267124	2.4538257	-0.03998022	-0.81948835	1.0759896	0.78282595	0.1861596	2.157796	2.8237042	-1.269838	-0.5237678\n-1.7397596	2.79175	0.57375157	0.6746621	1.5411114	-1.3883181	1.7123424	-1.611739	1.0572414	1.4002622	-0.7677758	0.14095145	-0.2053914	0.62326723	2.6695137	0.39473528	-3.3152778	-1.5890535	-1.7327348	-0.73966	-0.5672475	0.56750745	0.44822332	0.57279617	0.091562726	-2.5616672	1.463249	0.5742397	-0.8177332	0.556545	-1.1674197	-0.5568351	-1.2280496	-0.6002509	-4.549046	0.11932088	0.090529144	3.695601	0.18511611	-1.2559545	-1.2614129	-1.7218132	0.64329964	-0.3342615	0.5007837	1.6270394	-0.98466635	0.79900455	0.79984486	0.97053164	-1.9181156	1.1353663	0.41579944	-0.8111499	-2.5067906	-1.134595	-1.2661897	0.6757853	1.5166398	-0.61355823	-0.9247471	-1.2470777	-1.4309536	0.43639404\n0.2554724	0.24621265	0.89512616	-0.004527253	-0.746097	0.13754335	-0.21843995	-0.0107524	1.7957721	-0.46601245	2.0838072	-0.9915382	-0.012973299	-0.38665354	-2.4759967	1.5795712	0.28812343	0.23758222	-0.76468754	-0.10587881	-0.85700387	-0.71767366	-0.038305253	1.8719282	-1.2813301	0.9964865	-0.2753074	-1.2100619	-0.056293815	-0.052109197	-2.120491	1.289378	2.0141807	0.79482645	2.2427554	0.26476374	-0.46026343	2.9775186	-0.22418456	-1.4559467	-0.53648335	1.1049575	1.7690783	-1.0003747	0.91413915	-0.6666897	-0.32311654	-0.8392497	0.41167668	1.7897748	-2.5912378	0.015830971	0.13285252	0.4680739	-1.2181641	0.3622722	2.8337567	-1.3613318	-0.8277922	1.9922351	-0.049366236	-2.6202874	-0.31429666	-1.3208772\n1.5261153	-0.19297603	-1.4260249	-2.366767	-1.8378791	1.1819668	0.44100502	-0.62958145	0.09868426	-0.3632057	0.7382074	-0.80508137	-0.46139014	-1.3302579	0.15394352	0.7844104	0.07974627	3.8246465	-1.5065547	-0.41472092	-2.0393505	-0.7259104	-1.1954069	-0.5518126	-1.2207046	-0.5817369	0.39281544	-1.4468423	-0.07221789	0.31608757	-1.2847956	-0.29434544	-0.34423628	-1.7986743	1.9840873	-0.29114062	-0.48466077	1.5177217	3.4325325	-1.2157209	0.9822191	0.20089266	0.9524743	-1.2217442	2.4623377	0.54222924	1.1941391	0.77936053	-2.4233458	-1.5447874	-0.9787316	0.32511288	-3.3656113	-0.47311524	0.8401739	0.9984777	0.7250427	1.251985	-0.8893067	1.1355151	0.8095843	-2.092072	2.124255	-0.39357972\n0.8304149	2.4094489	0.22574387	-1.8036695	-2.808446	1.1889796	1.1422008	1.8161198	-1.4394058	-0.60261405	0.87266284	-1.4467393	-2.7784116	1.2864954	-2.5024204	0.059415154	-0.3642817	-0.27537742	3.084539	0.36363724	0.39144298	-0.86035514	3.2009556	-0.043968387	-1.4876777	0.35781297	-1.18605	-0.37068114	-0.28103316	1.635645	-0.052945595	-0.22749443	1.986545	-2.8972278	0.25144976	0.6306448	-1.9258014	1.2699835	1.7011635	-0.5658371	1.5135162	0.18600832	0.80224544	-0.17834899	1.7072842	0.81000495	1.1980082	-0.71769863	0.2536874	-0.021600053	2.2833128	1.2215246	0.305121	0.14377286	2.9667222	1.6176913	1.1259986	0.76772064	-1.5450042	-1.6301392	0.94900787	-1.8036977	1.0436319	-0.6322698\n-1.3768431	0.734319	-1.3084835	0.3425624	0.3878781	-2.0208395	0.57699573	-1.4557313	-1.1970199	-1.8967266	-1.8047448	-1.69211	-1.6296576	-0.8029422	-0.66373754	1.4692931	1.2880032	-0.91244924	1.1164743	2.1565027	1.3553412	0.31953692	0.062337946	-0.5257411	0.577776	-2.0248737	0.8347711	0.79499567	-0.7354102	-0.3517194	-2.3217201	1.6081983	1.8809056	0.85112566	0.16048408	2.8558707	0.23515955	2.0887568	-1.5066812	0.2809345	-2.2715251	1.3634024	0.916557	-2.3152347	2.221854	1.7751415	-0.6266489	-0.4989601	0.45711935	1.9429289	-1.5052295	-0.43515846	0.29885095	-1.8509072	-0.54269934	-1.0309213	0.93510485	1.996262	-0.7568147	-0.20816651	-1.1948525	1.491941	0.18745309	0.19233917\n-3.0676134	0.050627023	-1.1829224	0.38506284	-0.9508252	-0.39969495	-0.36803773	-0.3068377	-0.29196194	0.46302736	-0.17650047	1.8741691	0.2867884	1.0097009	0.67847866	1.423818	-0.0059335986	0.123255685	1.3696457	1.3259991	0.30542448	-0.35975432	-0.3856915	2.0086896	1.7224934	0.33245423	0.6069454	-0.009393989	0.7399594	-3.0311565	1.8707478	-0.47225276	-0.11860067	-1.4448531	-0.23173453	1.9891309	2.2615767	-0.9090502	2.6647909	0.6174933	1.106918	-0.45857534	0.36314884	1.1485263	-1.4376189	-2.120955	-0.41135	-1.7435194	0.37831876	0.526774	-1.9535251	-1.6562481	-1.6973662	0.0037307632	-0.19069523	1.9290162	1.8335465	0.52341115	2.8626509	-0.047073	0.12034351	1.6037909	-0.39824092	1.2173829\n1.4126959	-0.4633253	-3.1261492	0.09958796	-0.17464814	0.08837763	0.7311826	-0.7613371	2.1941307	-3.5493715	-1.2548445	-0.7908349	0.8482666	0.41784072	0.108432844	0.9876707	4.040538	1.8324469	2.317114	0.15695898	-3.7231605	-0.2818456	-1.22542	-1.3262879	-0.17705266	0.1859826	-1.8285851	-1.7315265	0.72629356	2.554685	-3.2353542	-0.37705722	-2.5020459	1.9099784	-2.1562002	-0.5389082	-0.31204447	0.15183187	0.082838535	2.3929536	0.71280676	0.15396965	0.33183104	1.4788158	-0.34823716	-0.27915043	-2.5448413	-2.1156874	1.2500212	0.92761666	0.28128266	-0.54271245	2.0270202	0.9157907	-1.5208749	0.29447487	-1.0168736	-0.767119	-0.1442464	-0.86865747	-0.59154004	0.82264405	-0.64050853	0.8221125\n2.1017907	-2.1313953	-0.20056523	2.0890672	1.4438463	-0.24195753	0.9744833	-0.95809907	-0.02187215	1.6762878	-2.2676082	-1.4702791	-1.0419656	0.85102856	-0.028111078	0.27899158	2.921198	-1.681346	2.157264	0.54963416	-1.809001	-0.72486454	-0.6051306	-1.3734064	0.8380903	2.1781454	0.3188863	2.3598235	0.45448628	1.7150955	0.20757996	0.60150254	-0.96487236	0.96773225	-0.8657484	-0.50266457	1.3604525	-2.0133905	1.3828015	0.021396164	-0.12890051	-2.4814024	-2.66019	0.61455494	-2.079555	-2.2645535	-1.2833427	0.8421974	-1.04979	-0.13211341	-1.8519547	0.40813878	2.1643622	-2.4314463	-1.2154722	1.4929881	0.10096132	3.3371994	-1.0570482	0.84902537	5.5081342e-05	-1.7067195	0.587465	0.44539624\n0.7760391	1.7161162	1.2125934	1.1216761	0.864964	-0.5387924	1.441177	0.95917004	-0.70581734	1.2468237	2.1638396	1.7140551	1.7466421	-0.95829046	0.64245766	-0.15265848	-0.46142715	-2.1120882	0.5624241	-0.25485563	0.68817157	0.38238177	0.7008514	-0.31569958	3.4066007	-3.4923475	-0.96197516	-0.6059114	2.2587378	-1.7698969	-0.4277308	-0.6380745	-0.51389563	-2.3867593	0.43692613	1.1672727	0.40333736	-2.516662	0.04861289	2.0211186	-1.2355739	-1.1238179	-0.36274126	0.8902062	0.87810874	0.52844775	0.16110937	-0.7782743	1.4961429	1.3540162	0.55970985	0.023260416	0.5082944	0.22887486	-0.7329198	1.3608052	0.37529308	-0.69847214	0.11973009	2.9840102	-1.385552	1.3390347	0.4119513	-0.15835698\n-2.7520337	-0.42756295	-1.4132345	-0.66108704	0.60700047	-1.8120575	-0.073185444	0.7940334	-0.23201048	-0.061691765	2.013229	-0.807415	-1.6485299	1.9500719	1.2754897	1.4865634	-0.8733792	-0.20705758	-1.6168925	-1.6667035	0.9774929	-3.353975	-0.31323704	-1.3705356	0.6412061	1.7407999	-2.6147904	0.6961933	0.0032937655	1.0249788	-0.82277787	0.7039296	-2.595929	0.06804496	-1.1999369	-1.1670964	-0.45598415	-2.597013	-1.2259903	1.9698151	0.5015293	1.1707698	0.6407588	0.37339732	0.22420262	0.61361736	2.1451542	-2.416906	0.56176984	-1.1297778	0.23924582	0.86070603	-1.4078935	-1.8706267	-1.4326122	0.8337707	-2.583581	-2.6556203	-0.28463542	0.25183007	0.8288315	1.3931533	-0.60002387	-1.3125639\n1.1754589	1.696788	1.733	0.49301156	-0.87378234	2.4899232	-0.4284185	-0.30909938	1.8003786	1.1310288	-2.603266	-1.0451399	-0.7880359	-1.7144814	1.5586739	0.8963157	0.40314788	-1.2115421	-0.4585341	0.24430382	0.039799236	1.2367307	-1.3039867	-0.100764036	-0.29326656	-0.54322	-2.3380904	-1.124679	-1.8134449	0.566977	-2.6839793	-2.0426517	0.4323164	-0.61210585	1.0716127	-0.07912462	1.0881587	-1.0400019	0.17753778	-2.257594	-2.370564	-1.7705513	1.4016763	-0.900059	3.0032365	2.1895893	0.15386781	2.0235858	0.3099363	1.9645388	1.4791437	0.9557501	-0.16522594	1.281441	-0.4553551	1.6568152	2.6117895	1.6767528	0.7260791	-0.27883056	1.2813791	-0.4612731	-1.6385286	0.19039696\n0.73897934	-0.5140045	-0.8521838	-0.13054618	-0.53933734	0.048081297	0.6161824	-0.0814123	-0.3920558	-1.5584205	-2.2033105	0.90638006	1.076111	-1.9127035	-0.644609	0.87525254	-0.57379985	0.4554066	1.4713833	0.17059918	-2.5865834	-3.2939723	0.9886889	1.877378	-1.0025705	0.106911816	3.373477	-0.6064121	1.4668679	-2.4966788	2.0138803	2.1710088	1.1566541	0.2731943	-0.55745786	1.5067981	0.50694287	-2.306243	0.55899686	0.9046153	0.16747387	1.296018	2.2526524	-0.48116308	0.43363878	-0.8781815	1.4775729	1.5010356	-0.7743929	-1.263599	-2.5729206	0.21759169	1.9429398	-0.13157071	2.4328697	1.1452235	-1.8684121	-1.2508484	1.4216071	-3.1609483	0.016312158	-0.31307355	-0.51828754	1.9848101\n2.4442072	-0.640635	2.334424	-1.2102484	0.78051627	-1.2556846	-2.6783674	0.08121557	0.5488777	-1.9832186	2.666107	3.7466135	0.12702796	1.1933342	1.4276336	0.75391585	-2.8149278	-0.27708396	-0.12536268	1.3911024	1.232237	-1.1829921	-0.053496312	1.8638628	0.33416992	0.6783761	0.96829796	0.52354485	-0.5857734	-0.71939766	2.075257	-0.5023267	2.573445	1.6100364	1.3040856	1.874755	-0.29580837	3.1303346	-1.4353046	2.1035478	-0.3795276	2.0037487	0.871229	2.3298378	-1.3037993	-0.14151065	0.10308789	1.2654513	0.8592198	-0.24283463	-3.7660174	0.36246502	-2.112991	-1.3923074	-1.0120596	-1.1625103	-0.29164693	0.46292052	2.4080615	2.528249	-0.9220371	0.43048647	-0.7359879	1.391042\n-1.9259756	1.2852044	-0.7800836	-1.1881381	-1.2611275	0.732751	-1.0882063	-0.7872352	1.5923209	0.061928984	0.0846296	0.23118065	-0.4331471	-1.4486235	2.845681	-0.06264768	1.7867485	-2.067391	1.442118	-0.48038095	0.15465862	0.09378014	-0.18311027	0.3987062	-2.121068	-0.40284264	-0.93180895	-1.5774517	2.4709094	-1.307411	-1.0690633	-2.123133	-0.8698081	-0.19796154	0.039710067	0.27540857	1.605433	1.20743	0.7197047	-0.39068988	1.0371598	0.15522799	-2.2101724	-0.91805667	-1.2151175	1.7634554	-1.9391843	1.7308849	0.93007857	-0.23812577	1.3781784	1.0901574	-2.2139745	0.44318396	1.1861801	2.7183778	1.6832685	0.4571605	-0.7890911	-0.46659732	-1.2050542	3.0382078	0.73444635	-1.2369742\n-0.28915706	-1.5053753	1.5438011	-1.3887662	-1.0514275	-0.50655466	-0.6567795	0.7677552	0.112670496	-0.30185214	0.53697675	-0.62771964	-0.50732285	0.7647203	-1.2413234	0.6977263	-0.03902382	0.35168087	-0.91257256	-1.7871279	-1.6526021	-1.1674631	-3.4243157	1.7327528	-0.9765124	-0.20991871	0.5461892	0.43141243	-0.99140686	0.7910876	0.7394536	0.444136	-1.7266129	2.205195	0.8333537	-2.832308	-1.5290633	0.66522974	-1.1034234	-1.5570667	-0.313266	-0.009313368	-2.171784	2.5176568	-0.20747901	2.6394567	-0.59448946	0.42924857	2.6890724	2.0228446	1.2277024	-3.0219176	-0.6406105	-0.47837552	-0.5138359	0.2816813	-1.1736851	-0.856761	0.41796103	-0.10872106	-2.1789126	-1.1418432	-0.56453985	-0.16757284\n2.635141	2.1670113	0.093346834	-0.6594623	1.097896	1.4066631	1.0016159	1.1795688	-0.22775897	1.2229637	0.09227134	-1.0959619	-0.61764336	1.3116114	-3.227878	0.9082293	0.06636245	0.5799051	-2.320162	1.1295171	-0.017044371	1.531916	-1.9144697	0.45271584	-0.46481538	-0.31902137	-0.107554235	-3.7725976	-1.4400058	-0.64675	2.2676067	0.72690696	0.6031239	-2.32323	1.765848	0.6137671	-0.5826169	1.4210994	2.2754588	0.5603034	-0.49470878	-0.5994907	-1.113189	1.111862	0.9122675	-0.30861443	-0.8200574	-1.3188361	-0.18089773	-3.1974397	-1.0334307	-0.27964684	-0.9785891	1.2647538	0.26831996	2.6847723	0.2683314	-1.2344618	0.4986366	-1.7495772	0.6117174	0.68310857	-0.7885958	2.2425563\n0.33628502	-2.2395594	0.71190023	0.4046937	1.4931823	-1.0616975	0.44193274	-1.0154456	1.6531615	-1.1059417	0.09853663	-0.6762685	-0.10273404	-0.9244548	1.2862234	-1.2396884	0.43231195	-0.07055503	-0.5724308	-0.018035462	-0.3727562	1.2001213	0.66281754	-1.7914237	3.029412	1.752511	0.34631667	-1.5856501	0.8658713	0.9140629	3.0434484	0.3008891	-0.32304472	-0.5720336	0.46661857	-3.0396602	0.5809464	-0.8589238	-0.37315348	1.1628802	-0.1111731	0.12024167	1.1288148	0.45812622	0.48557296	0.99163824	-0.23578534	-0.4049403	1.6063962	0.13877125	-0.7599639	1.2189511	2.3915305	1.1802121	-1.9586459	2.3432105	0.7372285	1.257393	1.054856	-2.0134647	-0.5866168	-0.13476579	-0.70456827	0.23441999\n1.8697093	-1.299279	-2.0128903	0.7409338	-1.2416905	-0.9358463	-2.1290467	1.7175117	-0.16747065	0.34407634	1.1274774	-0.87778205	-1.3092414	-0.8245885	-0.8644118	0.35671926	-1.6146779	0.02237426	-0.6632869	0.42831331	1.3524508	2.0721066	-1.0349456	-1.8375695	-0.0027497434	0.53997177	-0.25546142	-1.8147941	1.0234716	-0.35980058	-1.2597823	1.007719	-2.8483622	-1.1735502	-0.3973616	1.415251	0.19771993	-0.17941013	0.6895885	-1.702653	1.0386403	1.3657348	-1.5220754	0.42129925	-0.4985901	3.3910248	0.92053634	-2.1681764	-2.137095	0.5571901	0.07515693	-0.21914127	1.3183876	-0.3777643	1.9174274	-0.45346463	-0.8893277	2.5478308	-2.6966453	-1.7629403	-1.8927817	-0.4527008	-2.8782678	-1.95657\n-0.35612178	-0.01148601	1.1502345	1.8253884	1.8617375	0.090457946	1.8048825	-0.58947206	-0.07395917	-0.9023615	-0.4219418	2.1652148	2.0015981	0.5857869	1.3832927	-0.5086122	-0.69883364	0.30959335	0.10073646	1.1647234	0.09942218	-0.95252407	-1.1602197	1.0151922	-0.2973552	-1.5876497	2.4886255	0.25296643	-1.4240042	-2.3178601	0.42137682	0.37407926	-1.6632099	-2.7202942	0.05845727	2.5602703	0.2554704	1.67107	0.59649616	1.0636874	0.38239408	0.50461334	0.45364636	0.12379792	0.37891564	0.42586258	0.26513916	1.0719562	0.3757106	-1.3894228	-0.7075478	-0.3136313	1.5611097	1.7547288	0.6869345	1.2091649	-0.4634531	3.305755	-1.8146975	0.025449429	1.8845845	-1.0828618	-0.0056752316	1.0419981\n-0.44168288	0.88382256	-0.7367432	0.8815743	0.74119776	0.86703116	-1.3090557	-1.4960387	-1.1863956	0.98497146	0.100844435	-2.1577199	0.8134649	1.8931805	0.44919115	0.17645447	2.068852	-1.8100407	0.3930746	1.0062175	-1.2459776	-1.911861	-0.54272074	-2.3408737	-0.6469143	-0.54699326	-0.56918263	0.49450827	1.8443795	-0.91476744	-1.0062821	-3.9894161	-0.68712515	1.0108212	-0.93544585	1.7898817	-0.08896534	-0.3414798	-0.14851883	0.8378174	-0.24108872	-0.99154806	-1.9069016	0.23760101	0.041007478	-1.6816154	-0.10504997	3.2137666	1.8111749	0.7426657	0.89725995	1.841276	-2.4335093	-0.22810958	-0.932007	0.7141162	-2.6249306	-1.7533726	-1.7510844	-1.5858403	-0.783109	0.06394302	-0.09079799	-1.3618338\n4.0499454	1.3167368	-0.3220875	0.8106701	3.0351148	-1.7024451	-1.477505	1.0173032	4.247556	-0.30915707	0.8783173	-0.9277442	-1.376706	0.943761	1.0289707	-0.40967566	0.013434647	-2.4485784	-0.7000788	-0.5052691	2.0957305	-0.032443494	2.3691483	0.7507055	0.67861706	-0.456192	-0.09513979	0.01526018	2.3133495	0.9984412	0.89050263	0.264386	-1.7674339	-1.422104	-2.805323	-1.1000437	0.22806934	-0.79629856	0.78330237	-1.7023604	0.72635305	2.768922	2.8563926	-0.19612469	2.2945867	2.1258981	-1.6159074	2.4403474	-2.794695	0.80868167	-1.4689146	-0.8585642	-0.7876602	-2.747126	-2.1604936	0.18293217	1.8185211	-0.8802783	1.0916555	-0.31621292	1.589075	0.88946486	0.73339736	-0.40543142\n2.1120164	-1.0344764	0.461383	-0.008858529	1.9064181	-0.9697398	-0.3102636	0.34915656	0.19397807	-0.67572564	2.6361554	0.10056337	-0.6983525	0.6148871	-1.0039669	-2.2965882	0.6743297	-0.2528673	0.13693592	-1.8025494	-0.575688	-0.11331486	-1.0935365	0.6001397	0.94724965	0.2750514	1.3047696	1.5236776	-1.6159506	1.3836921	2.4563677	-2.4987292	0.061364446	0.27325216	-2.5918767	1.1418804	-0.8792852	-0.0639393	1.1390109	-0.6441062	-0.39617932	-1.8087703	-0.2044237	-1.5328287	-0.15888545	-0.18617113	-1.8992368	-1.0095136	0.8857857	0.119570404	-0.9748514	0.55379486	0.1867174	-1.7200403	-0.9166347	-0.46958	-0.96818674	-1.3717674	-0.90772504	-0.80864453	-2.8803554	-1.065158	0.61908096	-1.3318714\n-0.8968487	2.0763755	2.183949	0.91936487	1.9662911	-2.8743129	2.2812815	-2.2566113	-2.6609442	-0.44112495	-2.1622546	1.7264425	2.0404048	-0.37648708	-2.3266137	0.07796798	0.67076147	-1.8990985	-1.4076207	0.7924484	-1.8943298	0.49272764	0.08516133	1.0138657	0.22037688	0.1042192	0.57023686	2.0815165	3.2259498	0.16083343	-1.2975596	0.9438033	-0.7608409	0.7454013	-0.44402704	0.7097805	-0.14626823	-0.27647623	3.3074467	1.4051543	0.4589488	0.74750453	1.2224573	2.6552098	-1.2963231	0.50787055	1.1897796	0.6480448	-0.00065234076	-0.9597809	-0.14530027	0.40456972	0.7857952	-1.4080828	0.33123916	0.03408671	1.5142797	-1.9186838	0.56704026	-1.4213434	-0.11127283	1.5346934	-0.089209706	0.5521667\n1.5841832	-0.909728	0.3140619	-2.130091	-1.5131794	0.35590413	2.3308299	-3.0086102	-0.50979066	0.28046215	1.2801186	-0.54938793	-0.09155182	-1.4527707	3.0805533	-0.29613248	-1.3879205	0.2809977	0.6549546	1.5765485	-0.9030811	0.34705848	-2.008555	1.8984135	2.755506	-1.1679014	-1.836421	-0.86496216	-0.31463555	-0.97590405	0.16509369	-4.114134	1.0165163	0.2249952	2.0183392	2.2540686	-1.3816825	1.4045463	-1.864291	-1.6438452	1.0918677	-0.18658075	3.0974019	-1.8694934	0.13792315	-0.8105753	-0.19852465	0.8947938	-0.86688393	-0.6559542	-0.12277106	-3.395886	-0.19083373	-0.52500784	0.7701132	0.87372464	3.3602257	-1.4814785	-1.1654586	-1.6674986	-0.14332223	-0.7740165	-1.954848	0.64214283\n-3.0531144	-0.7077061	-3.095612	-1.4320129	-2.4434614	-0.807208	0.7795184	0.3487247	1.0717765	-0.13555841	1.925162	-2.5156424	-1.5823901	-0.17016277	-1.4482555	2.3098466	0.72942895	-0.6333031	-0.5161877	0.14465539	-0.039138276	0.9512376	-1.5615917	-1.3409528	-1.6924229	-0.84313077	-1.1187024	-0.85794467	-2.8702106	3.3684356	-0.6229851	2.0091121	-1.2742406	1.2245709	0.42558733	0.061782032	-0.4173993	1.658586	-0.06166833	-0.5463086	2.044445	-0.3686548	3.381436	-0.70880026	-1.6809686	0.2617733	-1.3235772	-2.1621203	0.97067916	-2.2878673	2.0146883	1.2213717	1.3170631	-0.5503151	1.398068	-0.6035144	0.2599954	-0.09825276	-0.15487885	0.1432557	0.63628125	-0.09576724	0.6665579	-0.9223277\n-0.43128902	-0.06667216	1.7578708	-1.9038092	3.781432	-1.276335	0.5261157	-0.31987017	1.5211825	-0.7508179	1.0020137	-2.0141892	-0.8608258	-0.3102608	-1.821714	-1.5133419	0.19167541	0.016554983	1.1183907	1.1399952	2.0326037	2.189797	-2.5167859	-1.5827788	-0.5638761	1.3605219	1.17064	-2.7712755	0.40575856	0.4072729	2.1028016	0.40439525	-0.90129864	-1.1879836	-1.581474	0.18607794	-0.9367679	-2.1344614	-2.1303759	2.0285006	-0.7875165	0.44350302	-0.9240426	-2.762956	0.7860036	-3.7402327	0.5998678	0.25528765	-1.1367638	3.2889807	1.2903371	1.212226	-0.6392315	0.51237524	0.4849982	4.190073	1.4554486	1.6570293	-0.6725122	-1.379418	0.49515224	2.272901	0.8754194	-1.1226671\n-0.59999233	1.3513658	-0.66409355	0.66499966	0.9339618	-0.8503514	-0.7074388	0.23224394	0.9127564	1.1313336	0.043397	-2.075033	-1.7554328	0.28414288	-0.3672793	0.31820533	-0.38221216	-0.010220316	-0.3750249	2.1461582	0.5484635	-0.84152395	0.29273504	0.93091094	0.5653627	0.025540428	1.0788931	-0.60678375	-2.308055	1.7614163	-1.4325262	0.44095612	-1.9373237	0.40088615	-0.66046274	-0.43642592	2.7674189	0.5834442	1.5269213	-1.1898192	-0.6446512	0.4661917	-0.5953158	2.4250576	-2.5805178	0.62790394	-0.16930288	-0.014252341	1.6440816	-0.5560091	-2.0620334	-1.4542792	-1.7908093	0.35165796	0.32603922	-0.97246784	0.46128872	-0.74103856	0.55746704	0.6779966	-0.6891638	0.5672627	1.7478851	1.2874786\n-0.5170505	-0.5520709	-1.1868477	2.0937076	-1.3124874	1.2649245	-0.35823494	1.8058766	-0.95539665	2.6532588	-0.7017256	-1.9849472	0.30211967	4.260206	2.3089473	-1.4985847	0.32238603	1.227303	-2.756278	0.04813186	0.36730605	-1.7863529	-0.37748858	-0.008478857	-0.9508896	1.5858903	1.9198045	-3.2136946	0.6604068	-0.17705359	-0.12656872	-1.161172	-1.1924622	0.19225706	-2.1334684	0.09396892	-0.62966096	-2.8536384	2.9425566	1.0373433	-0.5518158	-0.5546409	0.5844499	0.07578257	0.34077302	1.0214576	-1.1714246	-1.8663574	1.3387293	-0.739647	3.5377467	-0.165266	-1.5897045	-0.37700012	-0.43252668	2.3756738	-0.5625359	-0.71172065	-0.81768674	1.8813518	-2.5959291	1.19999	2.2295866	-0.5524173\n-0.25236058	-0.60693973	2.256091	-0.4354251	-0.69278085	-1.3138483	0.044683974	-1.1130855	3.5999768	0.45329446	-0.7954061	-0.16909091	-0.25606614	1.9565433	-1.5983787	-1.0075963	1.1448123	2.03809	2.0923457	0.07629899	-0.82474446	-2.1239798	0.8875955	-0.8881425	-3.9321182	1.0750277	-0.6818711	0.45236138	2.3707585	-1.06114	2.4321914	-0.9604402	-1.2531309	1.2948288	-2.5963383	0.23727491	-1.1922194	1.7515125	-0.7014293	-0.9035328	-0.42926538	-1.5286595	2.1344118	-2.6610532	1.9829236	0.987564	-0.7521766	0.58784235	1.477923	1.3966073	-1.2795871	-0.42695186	1.0397885	-0.03388167	1.0957607	-0.8425301	0.075409785	1.1754223	0.87872183	0.40745625	-0.73477894	1.8452319	-2.8878798	0.9638404\n2.6676357	-0.7750759	-0.27237302	-1.3617836	-2.1810143	-2.8988395	0.39437407	-2.1687887	1.6587478	1.74871	-0.31401742	2.0896857	1.576836	1.1988131	1.0868456	0.2652144	0.23403986	4.088284	-1.084035	0.6626923	0.7632835	-0.6808477	0.63178235	1.521146	-1.5562955	-0.9336188	1.5992192	-1.25018	-1.5277554	1.1901898	2.8194604	-2.6035607	-1.8071254	-2.4609036	-0.6709738	-2.7850227	-1.0049251	-0.7112922	-0.07105427	1.4209905	-1.3606204	-2.5918937	0.8095253	-0.16193938	-1.736885	3.2524574	0.31486228	-0.41091016	-1.4727399	-0.6524894	-0.48908696	0.6016367	-2.3324342	2.355461	2.6141179	-0.98462254	-0.04966545	-1.38389	-1.2819103	-0.29827943	-0.058500405	-1.1725848	-1.9700825	0.59382844\n0.28231135	-1.4335735	-0.5803536	1.3482323	1.1535801	-0.6555055	3.0455298	-0.58540064	-2.1808999	-0.66578615	0.2457069	-0.81053126	2.6872594	-0.4359739	1.0690591	0.48782507	-0.7899703	1.9007733	-2.1484263	0.60553044	1.9570955	-1.3035622	-1.5263022	1.7979693	0.386865	-1.9019468	-1.1905415	-3.5395308	1.860119	-0.29117426	-1.4722377	1.0928228	-3.5209267	-0.9116579	0.019514697	0.93560153	-1.4398974	-0.30696163	1.7877212	0.22153856	0.18640313	0.7250754	-0.50421387	1.111274	0.5462576	0.028356303	2.244678	-1.0950743	-1.2679542	-0.9929929	0.7888954	-0.7304795	0.5218276	2.2401237	0.32498938	0.042573042	-0.50459594	-1.6944872	0.70052326	-2.3165536	-1.1132679	0.39730582	3.181023	-1.7155168\n0.62559307	-0.21615855	-3.2340186	-0.047473844	2.6948156	-2.7382896	-0.26117304	-1.1918259	2.2632349	-0.68590367	1.1360663	0.79231596	-0.7139797	2.8541474	1.073551	-0.6263448	-1.1153702	-1.8783875	-0.69451755	0.8038431	2.034197	2.0153034	3.6495888	0.9561955	1.6494489	1.1807703	0.20615217	-1.2289987	1.1783781	2.9971855	-1.9211955	-0.16507055	0.47944918	-0.28346503	-0.061113086	-2.6111255	0.80200535	1.2092289	0.41183	-1.7950928	0.24720147	1.1146066	-1.3281724	-0.53830564	-1.570736	0.46376434	0.7807678	1.5990881	-1.2201381	1.5605515	-0.114927724	-1.1971593	0.37671533	-1.160343	2.0790737	0.83207405	-0.49170047	-0.7867477	-0.8085456	0.7487905	-0.33228955	1.4673169	2.4813352	-2.186326\n-2.3660135	1.066273	-0.3515694	-0.0331877	-2.03772	-0.53320235	-0.24807641	2.1073122	-2.0518632	-0.73333305	1.8981402	0.5864015	-2.269385	0.18226418	0.53816366	-1.1132578	0.15438417	-0.11046001	0.25761855	-0.40874994	0.29648298	-0.88616973	1.6425127	1.694907	-1.4482148	-1.0310352	0.14894442	-1.2800819	-0.43108985	-0.0639131	0.12696911	-2.6002035	-3.0008724	2.1982348	-0.22705619	1.2615322	1.6540697	0.98599654	2.3036773	0.61438316	0.7460537	-1.1724058	0.56581753	0.38325262	-1.2333748	0.37565517	-0.45417905	-2.1249866	0.22876534	0.33681184	-0.41075146	0.39639768	2.1617436	-0.28441557	-1.8633589	-0.9165236	-1.5841705	0.6652894	1.5449727	-2.3622992	-1.3305156	-0.8360822	1.2145917	0.33527634\n-1.6921508	0.68479043	-2.8079185	1.0481117	0.41693768	-0.2248928	-1.9855827	1.207677	0.49801818	-0.4045173	0.5691668	1.280337	-0.102027506	1.5710231	0.5021242	-0.5490574	-0.11652527	-2.535725	1.6642283	-0.5936569	0.42306036	-0.04504249	1.2745087	0.57384974	-0.66876996	0.67981154	0.73797125	-1.2845293	-1.9492123	0.44497746	0.8418026	0.7400734	-0.60131246	-0.82269204	-2.145922	1.4799609	0.7112142	-0.47983593	0.6670407	0.27966487	0.7671994	2.1945925	-1.8562531	0.36863104	1.026881	-0.12319934	1.1070634	-2.0787597	-2.8163824	0.48399323	1.613184	-2.2300549	1.0581878	-0.70572406	0.077624775	-1.258234	-1.6055655	-0.08414637	-0.07495522	1.4197497	0.618624	-2.3153133	-0.77064735	3.1806927\n-1.1461262	-0.63167876	0.8878433	0.54305124	-0.37822634	0.1206762	-0.95080745	-2.2718887	4.4634247	1.2364941	1.0707425	0.32379413	-3.0528772	-0.37665913	0.28106365	-1.2498966	2.334614	-1.8966081	-2.7253258	1.5008731	-1.5609298	0.19990723	-0.115399525	-0.4974095	1.2936128	0.70317507	0.83298236	0.5593591	-1.3659548	1.095266	-1.3169436	0.9524844	-1.0871251	0.2049793	-1.815441	1.8197793	-1.1625388	0.77042687	-1.8676201	2.0312417	0.8347347	2.0503027	-0.7099571	-0.60594565	-0.109902814	0.9337627	-1.5493852	-0.3213762	2.7255807	-1.0018641	-0.71166426	1.4851748	-1.2881483	2.7837002	1.1745794	0.82436746	-3.4847474	-1.0827882	-1.8917627	-0.36061528	0.33746547	-0.07936914	-0.1134443	-0.65519106\n1.7999444	-0.5191142	-0.51506877	-1.7969495	1.3090057	-0.08706549	0.33930326	-0.21100137	-1.701762	-2.2269275	-0.16562112	-0.7379185	0.1491852	-0.79357946	-1.4765115	-1.5244175	-0.29389042	-1.9853066	-0.2711865	-0.3917896	-2.2221293	1.784811	-0.9045479	-0.72866404	-0.31621727	0.02642713	1.0911703	0.17460962	0.76601446	1.1529441	-0.8640044	-1.103015	-0.26227757	-2.9348211	-1.2628132	1.2457888	1.5429702	-1.7822807	-0.5486234	1.569031	-0.15660504	0.9842123	1.7955171	-2.5940845	0.68395174	0.23682454	-0.50340253	-0.16040798	3.5978508	0.22976089	1.6547196	-0.88073945	-0.88511086	-0.52046347	0.9206778	0.18381816	1.5173155	1.5487565	0.102291584	-0.54562616	0.0011764975	-1.3026657	1.0218941	-1.1143391\n-2.1504774	-2.1598737	2.7399764	1.4208534	-1.2484164	-0.68173933	0.6031851	0.78647923	1.528419	-0.7700716	0.07162107	-0.89326614	-0.8555912	1.2738022	-1.8722758	0.055578697	1.209867	0.07592776	-0.76265717	3.519365	-2.243688	2.059752	-1.9198527	-0.4365329	0.6935477	-1.1597667	-1.5859678	1.5953128	-1.2392073	0.13889037	0.84447736	0.7017317	-3.9001694	0.39959756	-1.3043443	-1.2621186	0.27328104	-1.176949	-1.516103	-0.49786243	1.068221	-0.79283357	-0.45262188	-1.3382775	2.1609123	0.40215242	0.47572795	2.554475	1.3420463	0.015946107	0.82364076	-1.6487436	1.6082349	0.7924068	1.0148386	-1.7794902	0.5971749	-0.07286082	-0.1334028	-1.9294053	-0.25852257	0.6054316	0.95869225	1.434218\n-0.918409	-0.7810956	-1.0682427	-1.0594985	0.6951487	-1.5189698	-0.94126964	0.4799144	-0.8048745	-0.28017107	-0.8043761	1.1492786	-1.2392561	-0.33241442	1.4520473	-4.065645	-0.04957728	1.8108963	-3.0148735	-0.9496627	-1.1311386	-3.1476703	1.216955	-1.4796487	-3.2556891	-0.5086635	1.8238817	-2.18588	-1.3957188	-0.91624755	-1.6125894	-1.0255722	-0.6511749	-1.3291997	0.9628914	-1.5989149	-0.6833634	0.2435629	-3.6494818	0.68244755	-0.28528225	0.4947286	-1.7734715	0.14242251	-2.8827045	1.7871575	-2.2219794	0.99367684	2.0332162	-0.34324732	-2.386792	-1.1392504	0.92924887	-0.016435882	1.326704	-1.1912564	1.0844666	-1.888749	1.4265057	1.7727122	-0.71196055	-1.9689467	-1.9589994	-1.1831473\n0.51461846	-0.009125134	-0.74435824	-0.35202992	1.1471869	-2.156128	2.1139069	0.30500492	-1.8977897	0.64899564	1.3084835	0.49315724	-0.8547359	-2.0440438	-0.98848647	0.8617085	0.80621946	-0.82364416	-0.81580114	1.0279838	-1.7476462	-0.51143235	-0.2666986	-0.77062273	0.8437576	-0.33107784	1.1340297	-0.6373362	-2.0736127	1.6524868	1.791974	-1.306849	2.616297	-0.7879853	1.5260526	-2.1576993	2.8938649	-0.2433434	0.30476657	-0.3422309	-1.0883573	-0.47220853	-0.74207014	-2.1240425	-1.3563194	0.43468362	-0.16705875	-0.1424176	0.49873054	-0.89582324	0.005465748	-1.1740192	-0.13945961	1.1085027	0.39184803	-0.39457878	-1.3794562	-2.6148472	-1.5492357	-1.3129708	-0.40808445	0.8630922	1.2906778	-0.58363783\n0.42760584	0.2664267	-0.38647324	-2.6390984	-1.3102733	0.30789423	1.3631512	-0.68899447	-0.08469489	1.6208487	-0.92979676	-0.86561054	-1.5716052	-0.98888546	2.0176566	-1.2531455	2.6474988	1.007726	-0.99207026	-0.59266376	2.516088	0.1069462	1.0698494	-0.025957806	-2.012278	1.8007318	-1.1981292	-0.29283616	-2.2240808	1.4090649	-0.8723034	-2.5275702	-2.413136	1.1965804	1.900538	-2.2281857	1.5821038	0.8614011	2.3001573	1.4457153	0.9368972	1.8942066	-1.3300937	-2.8968043	-1.9820616	1.1777894	-0.89048815	-0.45033753	0.9052212	-0.5654547	0.38273782	0.6385733	-0.66559446	0.6229572	-1.1865584	0.94474894	-0.63495994	-1.6924578	0.14814144	-0.41319248	-1.0306761	0.76144254	1.7521572	1.1445479\n0.76908755	0.4116	0.5942819	-0.22336026	1.1810892	0.91743666	-0.2773844	-0.3885266	-0.24951747	1.7254351	2.2457845	0.6112886	0.16259174	1.5423605	3.3797302	-1.6902127	2.676685	0.05169953	-2.3699296	2.5165265	0.5590938	-0.7321386	2.3046114	0.94671464	-0.05512856	1.7754723	-0.05978257	1.5725511	0.33298197	-1.0805519	2.0962687	0.62259734	-0.090804555	-0.7276282	0.59022033	0.81094766	1.8394053	-0.30089608	-0.15740322	2.6774828	0.16349955	-0.29121357	1.4045011	0.2700837	0.08070404	1.3155247	0.2917061	1.7508206	-0.567711	3.451372	1.0199956	2.0834076	0.7221181	-2.3993673	-1.3764236	-0.84185797	0.75091934	-0.5759046	-0.86729175	-0.32731822	-0.5673955	-0.90163267	-4.153396	-1.7224201\n-0.29222775	0.5610627	-1.066388	1.6494325	1.032265	0.12581858	2.4967706	0.38733676	-1.2005571	1.1487612	-0.6539022	1.2840506	-1.4507688	-0.69819546	-0.2702531	0.3117685	-1.0938853	-0.85542893	2.6821063	-1.8097868	0.9466489	-1.791604	0.6892475	-0.56452906	0.33511335	0.12807333	-2.2362666	1.187658	-1.5780665	1.0593666	0.7735592	1.6436799	0.77838695	2.6758795	0.6033185	0.61411077	2.4618564	2.4210277	0.12551138	-0.3378459	1.0754181	-2.3702004	-0.6199181	-0.024287503	1.6275517	0.12018074	1.6529344	2.4809957	0.47927108	-0.56268394	-2.2647474	1.3690548	-0.13146444	1.131903	-1.5579636	-1.4256452	1.4773962	0.7780735	1.6587173	-1.1546409	1.1232752	0.45961326	0.4740158	4.1498528\n-0.2806727	0.69186527	-0.70307755	0.473628	-1.3881748	-0.16315928	-0.29795018	0.6618659	-2.049124	0.3476396	-0.68140227	-1.2223445	-0.18909231	-2.3159854	-1.688274	-1.6921691	0.6309543	1.5483077	3.164713	1.2856102	1.173923	-0.34788662	2.299771	-0.13226654	-0.89654446	-2.017773	-0.76677203	0.69701165	-0.2859146	1.1400472	-2.0791183	1.0653595	0.16690981	-2.9534605	1.0841235	0.7433066	2.6943252	0.48966545	-1.001212	0.73158884	0.6976074	0.81573004	1.3735224	-1.5519774	-0.21751443	-1.225457	0.38471913	-0.447797	-0.24735081	2.2068386	0.18107451	-0.9097806	3.1844103	-0.49763855	-2.3986132	-1.7543628	-0.28814805	0.7303172	-1.9541796	0.97850096	0.51134765	-0.78149223	2.9759314	1.3378614\n-0.16840822	-0.30984783	2.844266	-2.8497472	-0.65437615	1.1754899	1.8825327	1.0085361	3.110984	-2.62485	0.16139325	1.317297	1.2274905	1.463775	0.23614815	-2.511899	1.1905674	0.51388043	1.6903971	0.31391725	0.93785924	0.19530582	-1.4298909	-0.9937058	1.6950042	0.5129637	-0.59909946	-0.277892	1.2528821	-1.0178719	3.127177	-1.6037006	2.1745405	-1.8940336	0.82512033	-0.45180228	-2.9074278	-0.6756529	1.2642984	-2.1652784	-1.7235523	-2.3333743	-0.07982324	-1.1272931	-0.5268203	3.143277	0.9685638	-1.1977341	2.08043	-0.3354241	0.5963166	0.41075823	1.0615263	0.6167628	0.64868236	1.6265687	-0.76938224	-2.3203292	-0.051575482	0.58792686	-1.377386	-0.11002535	-1.237112	-0.8274019\n0.8119231	-0.7987475	-0.534769	1.3838866	-2.036683	-0.4244757	-2.191892	0.4181253	-0.36243957	-0.095550075	1.8216563	-2.7029798	-1.281628	0.0135854725	-0.53619367	-1.3672202	-0.4102843	-1.4320881	-1.1311228	1.9284018	-0.0075566974	-0.6641115	1.1874051	-0.23514487	-0.2034198	-0.1598658	-0.32651988	-1.1886507	-0.24525297	-0.7804413	-2.7237003	0.9999744	0.3825247	0.7034821	1.3378075	0.596054	-0.89052445	3.901197	0.34745085	0.11533506	-0.39375544	-1.7851422	-0.9661172	0.7563167	0.7677748	-1.0551416	-1.0390631	-0.043676786	-0.12503654	-0.20153804	-0.17615916	2.237319	1.666258	0.8694647	2.5099947	-1.955048	-0.060609832	1.734649	-1.7599939	0.4725427	-0.37304264	2.6842175	-0.46124268	-1.3923097\n1.767697	-1.2755653	-2.7183585	1.2605705	-0.8994748	2.2142115	-1.0484478	0.44414142	-0.682973	-2.439812	-2.150393	-1.1400695	1.6365063	1.9061922	-1.4573377	-2.5359447	2.4832342	-0.8915762	-0.23253609	-0.46092972	-1.8708173	-3.689183	0.39951032	0.9160901	0.68423396	-1.1705314	-0.17797345	0.13380873	-0.2700935	-0.96276015	0.6641376	0.79285574	-0.44914988	-0.22856706	-1.9318926	-1.2732016	1.3367734	-0.61503935	0.52019864	0.21468541	2.1539001	-1.0894421	-1.7489598	0.2504999	-1.7227812	1.3983383	-0.28931698	2.4361072	1.7902694	1.2295439	1.1118639	-0.8220232	-0.57486373	-2.2076542	0.6162104	-2.0000136	-0.9444934	-0.7017672	-0.35347077	-1.4342391	-1.3546588	-0.40228426	0.82762	1.0747439\n-1.4540757	-1.9011698	1.6500424	-2.2087762	0.03758465	-1.329978	0.8232807	-1.9424937	-1.6612383	-0.19996144	0.14003265	-0.65377426	0.8394377	1.5723667	1.7418183	1.0917044	-1.1354979	1.8074647	-1.396756	0.18859123	-3.529868	1.3740938	-0.068728596	2.4703906	-1.127234	-0.33167484	1.223716	-1.9408419	0.8753653	-2.3305912	-0.83798337	-0.97780806	-1.6772045	1.9925067	-1.2733016	-1.6290735	0.9679587	-2.0261152	0.6186852	1.0576702	-0.39883864	-2.656343	0.5451134	2.1876738	0.6991419	0.08464901	-0.7430365	1.9743463	1.765004	-1.3326815	1.8511992	-1.6972699	1.3207445	-1.4373538	0.0003354919	1.6002957	1.1712	2.022991	0.405748	0.93129575	-0.54974645	0.016808711	-1.7477254	-1.2980188\n-1.8306032	0.94506234	1.4718992	-2.4620996	-3.4412138	-2.3792224	0.4046875	-0.49730834	-1.3831381	-0.9962787	-2.2684267	-0.2642832	-2.7617812	1.3127848	1.7767875	-0.812705	0.53728044	-0.30354932	1.80487	0.84590805	1.1797204	0.007551755	1.3689313	2.0115504	-1.5882176	-2.4290128	0.12836656	0.31043684	-2.4367397	0.34343934	2.1182528	-0.78450984	0.34392852	-1.2100308	0.26852354	1.6293346	-1.3875785	0.35177496	-0.43415824	-0.9673636	-0.051309306	-1.3245682	-1.5141271	-1.9648434	-0.73617774	-1.1910557	-0.607581	0.18009649	0.21117853	0.12771279	1.3591291	1.6167468	-0.52617997	0.82660663	-1.2146469	1.7610372	1.3279656	1.9636885	-1.6665071	1.6929389	-1.642166	-0.5862697	-0.16095358	-0.8987977\n-1.7781997	-3.3655334	-1.4415796	0.22584304	-1.0585965	-2.4130414	0.55669636	-0.9667079	-1.6732814	-0.97192425	-0.1202585	1.1955978	-0.33969665	0.6393882	-2.8059535	1.0719126	0.60371774	0.39257684	1.8320183	-0.8325477	-1.124951	-1.0700461	-0.079797536	-1.2418594	-3.5998867	-0.6917116	0.6282031	-2.3296797	-0.29899412	3.0067508	-0.7570413	-1.242775	-0.83078384	1.0120388	0.51143205	-0.3791205	0.4665691	-1.0644759	1.0595957	-0.9883749	0.4346655	0.7791971	-0.4335774	1.687603	0.5893502	2.5107589	1.6801682	-0.5521265	1.5832406	-2.4363968	-1.1695073	-0.6353253	-1.1199806	-1.0389884	-0.8194461	-1.030384	1.4890535	0.32107916	2.2108893	1.1254262	-0.6937297	-1.7615541	-0.046730112	0.06287082\n-1.966991	-2.3204613	-1.0572444	1.7152141	0.40400007	0.39330062	-0.6355359	-1.6569716	-1.7532668	-0.4612125	-0.43256682	0.837059	0.8446304	-0.81500417	-1.0078052	1.5648305	-1.2924043	-1.3938814	1.3737962	0.29750085	0.21377787	-2.3285966	2.0057137	1.1349912	-1.661113	-1.6553055	1.1107037	-0.06923489	0.11200477	0.56665665	-1.0324408	0.9966481	0.33217707	0.26978981	-2.4139624	1.7471048	0.29630226	1.9917604	2.1671627	0.99503505	-0.84624857	-2.5006773	0.7930741	1.0324008	-1.2336913	-0.7239967	2.3386848	1.3143755	0.31444228	0.0073336945	0.88493335	0.547916	-0.102103464	0.878048	-0.073851526	1.1369325	-0.31084487	-0.3358539	2.504015	-1.4092561	-1.4204854	0.5874732	-0.9933802	-1.1212521\n-0.19801743	2.3823168	-1.3113139	0.08239385	2.125411	-1.2200705	-0.8605522	2.3239117	0.407198	2.0309708	1.7356433	0.03306335	-1.951003	-1.3521646	-1.6934462	-2.0458336	-1.5592836	0.74304265	-2.414906	-1.0650895	-0.2442264	-2.7311215	-1.1132475	1.5682243	-2.8559694	-0.9917651	-0.69337076	0.043496992	1.0811455	0.73837054	-0.9924187	-2.396221	0.37355226	-1.121808	-0.57691926	0.7802445	-1.4917991	0.018018438	-3.294849	1.9025319	1.3403307	-0.22063407	0.9638971	-1.5081636	0.28096566	1.9598292	-3.820525	1.3073043	-2.0368044	-1.5433214	-0.825438	1.1814147	0.820996	-1.1168907	-0.12224754	-0.3554292	-2.5212846	0.40925327	1.0493916	-1.3195058	-1.655239	0.99374	-0.5584973	0.590873\n0.6229436	1.9289526	0.32897574	-0.018139638	0.8754796	0.69936925	0.9618896	1.162149	1.4820535	-0.5393099	-2.797049	-0.17529055	-1.6277096	0.047112804	-0.06321944	-1.2902789	0.7209679	3.4096296	-1.6900617	1.0289426	2.8160877	-1.1153016	1.197853	-4.4535027	1.8306572	0.48826987	-0.07905985	-0.1339013	-1.2316375	2.2446399	0.124596514	1.9016798	-1.1648414	-1.1304488	0.78958684	-0.07252383	-0.8947474	-0.7081969	0.3243055	0.59550977	-0.6854311	1.0655762	-0.43065193	-0.087144285	-0.4695596	-0.7768963	-2.4953988	0.63425696	0.22349691	-2.130181	-0.34301904	-1.2837491	2.8812196	-0.50487614	-2.966269	2.9871194	-0.9682456	-2.120311	-0.15122718	-1.538851	-0.3772604	-0.6381986	2.472645	-0.60402507\n1.1565685	0.7806195	-0.64955676	-0.36436263	-1.316029	-1.0845306	-0.28986558	-1.4541805	0.96951866	2.1301095	-0.34958765	-1.7780004	0.054481477	1.4142442	1.8681657	-0.7755949	0.31236354	1.8584629	1.5678434	-1.5888414	2.2232366	0.33667684	-0.2661124	0.80404055	0.5839079	1.5929295	0.97925705	1.0467311	-1.6807873	-0.9031361	-1.949582	0.6720934	0.69286996	0.42379743	2.1533942	2.092473	-0.9302314	-2.3570273	1.8979712	0.5559893	-1.34743	-1.1231449	-2.5221975	-0.73844415	0.360307	0.5328667	-1.1972121	-1.6614767	-2.8360403	-0.10674595	-1.3888676	-1.1637276	-0.9506648	-1.8004377	-1.023501	-2.2867286	-0.77919537	0.64131415	0.48604193	1.4302661	-1.0503939	-0.42664516	-1.4206414	-0.88578\n-0.63396573	1.1570542	0.82673246	2.3606632	-1.6679398	1.9245673	1.3971221	-1.4971884	-1.7566237	0.65569025	1.7329397	-0.24946253	-1.1035904	1.3925	-2.5693386	-1.8492315	0.47709882	-1.7238182	3.9430194	1.0894431	2.7258234	0.94203645	-1.1663909	0.081234574	-0.075016804	0.23306032	0.76805085	-0.2384347	-0.5758393	-0.3357472	-0.35551816	0.4878538	-0.956792	0.21972011	2.5208127	-1.1287383	-2.770831	-2.8598292	-0.5845034	-1.453404	-2.7166216	-0.34803593	-1.209607	-0.4201964	-0.42724994	-1.0982423	-0.4426752	-3.9489949	0.9750777	1.5985552	-1.0804142	-2.4659436	0.4739506	1.3141756	-1.4983715	-0.7332489	0.8682174	-0.6949037	1.3948175	2.0365052	-2.474441	1.2924317	0.5756743	1.6084235\n0.13480884	0.08876764	0.43799728	-1.4998584	-0.95765513	-1.2930797	-1.32885	-1.7814814	1.5896746	0.3067896	-1.5824249	0.881942	-0.565589	-0.20884079	-0.33576345	0.265413	0.1388027	-0.87260413	-1.9653678	0.76733524	0.14267713	-0.52676606	1.0380265	0.953584	0.24218561	-0.66911143	-0.39049077	1.2599288	2.439134	-1.1493047	0.73019737	1.3036753	0.21103705	-0.03699954	1.398446	-0.82177913	-0.74728495	1.0848596	0.8589616	-3.5251005	-0.052004397	0.17517135	-1.3853137	0.9307678	0.13078445	-1.1896311	1.156271	1.4713246	1.2114857	-1.0018572	0.11346278	0.80493945	0.65033716	-1.1142402	0.15131763	1.1431068	-0.6061612	0.742249	0.8284282	-1.2674919	-0.792454	0.14517595	-1.7937485	1.4413646\n-1.0881914	0.36581966	-0.5592225	-0.14562762	0.06677962	-0.23100759	2.907946	0.99908674	1.5211046	-1.0834206	-0.20252223	1.3151793	1.6796936	1.909721	0.8865326	-1.4402732	0.59856033	0.30928493	0.29681468	-0.25367063	0.4383651	-0.43390566	-1.9400586	-0.16280201	0.93936914	-0.30001628	-0.2942685	1.2721332	1.2509823	0.2665193	-2.9242635	0.044837132	1.2730507	0.4811802	1.3732916	-0.10710633	2.3698304	-0.6361734	-0.026788281	-0.4727763	0.85647136	1.2623128	-0.25535992	-0.2632323	-1.1388924	-2.0049243	1.2087929	0.14203936	0.3749585	0.3675762	2.3930395	-0.24793784	-0.50996894	1.7981997	-0.8954265	0.3825546	-1.9562714	1.4147004	-0.50691867	1.1200057	-1.2843634	-1.0129168	-0.55600196	-1.2795033\n-0.19020362	0.14327958	-0.22104014	-0.14029647	-0.43203554	0.5835573	0.8688351	-1.1522504	2.5810843	0.2570652	-0.31175393	1.9348344	-0.63348675	2.7513282	-1.56012	-0.6657378	1.9138801	3.5027974	-0.81113654	0.010645076	-1.6249846	1.7025586	0.6699555	2.5056055	0.97428846	-2.498859	0.2804084	0.9100306	0.09675507	-0.16256027	-0.71424013	0.50168484	0.8996675	0.19407447	0.30584005	1.4693695	-1.4458005	0.5757238	1.2220974	-1.5554476	1.3066753	-1.109789	-2.4053438	0.4526511	2.6561217	0.41281635	-1.001886	0.4494088	1.4271635	0.6612127	-0.1044194	0.77005583	-2.4339461	-1.3434477	1.1968242	-1.245698	-0.20809127	0.78477705	1.6149012	-0.69923323	1.1883916	-0.79479146	0.4010625	1.2010083\n-0.28601646	-2.444197	1.2795926	-1.3801543	1.6161886	0.028717838	0.114126205	-0.36483893	2.3437257	-1.3917726	-0.22540757	1.020767	1.0122688	-0.69993424	0.76774174	0.107953735	-2.213955	0.14881235	-1.2953846	-1.8088634	0.5150167	1.2125691	1.3166599	-0.0036041173	0.8571662	0.21543483	-0.5444429	1.7011623	-0.8815734	-0.029622592	-1.8061292	-0.279925	-1.3174359	-4.0671034	-0.16704783	-1.114802	-1.0796405	-0.011201134	1.9568337	1.6420224	-0.26646033	1.170297	-2.685942	0.53106326	0.7826745	0.14822273	1.133027	-1.0541213	-0.845817	-1.3180615	-3.4673638	2.3850977	0.68602043	-1.3377472	-1.7410984	-0.6584902	0.5158403	1.2134008	0.6068917	-0.35743144	-2.0429783	1.9509012	-0.20917854	1.3406472\n-0.36364102	0.9975496	1.9543835	-1.1181821	0.065783694	-0.118345186	0.13760805	-0.527639	0.4539136	-0.9749884	2.347918	-0.3330167	-1.1715381	-1.5829916	2.9853354	-1.4637547	-0.3639419	0.28173152	-1.270152	1.9495082	2.0731406	-2.2298067	0.4010805	-0.6409019	-1.9604212	-1.0519869	-1.0711106	-0.4850087	0.72989786	0.8004786	-0.28656083	-0.6171694	1.5447059	-1.0898348	-2.6523013	-0.37031016	0.21537866	-1.8699616	-0.515931	0.19972192	-0.15747926	1.6916473	2.4540496	-2.1836944	-0.27237034	0.90649617	0.3977258	-2.1816232	2.2388031	-0.058030587	1.5019144	-1.1865036	1.0902828	1.923578	-0.9410041	0.4609793	-0.21441966	-1.6486496	2.461095	0.70980525	1.7638608	-1.5139672	0.18039401	1.5211432\n3.1755428	0.19178836	0.90276635	0.49752915	-0.718043	-1.5533737	-0.6547025	-0.74585503	0.41210306	-0.5153365	-0.25995797	-0.9246028	-0.41625693	-2.1841981	0.08724102	0.10794294	-0.6259328	-1.4338064	0.7747595	1.3974146	1.174393	0.8798551	1.684959	1.6010609	1.1156386	-0.07506854	-1.335405	-0.5344076	1.9621466	0.30424553	0.34653318	2.3295112	0.6721316	0.67952865	-1.1858331	0.87691027	-0.44586414	0.12740466	-0.61196136	-0.054618698	1.0991505	1.8547461	-1.7218848	-0.3068465	-1.0438219	1.84858	-1.1171588	-1.1395999	0.5196056	1.3003219	-0.18878119	1.9393542	0.14394021	0.9987367	0.052165464	-0.260375	1.3954186	-1.3486737	1.9731998	-0.10987781	-0.8628081	2.9938672	-0.82041824	-2.668452\n-0.2573756	0.3196614	1.568669	1.1175835	-0.516021	1.71393	0.6253763	0.353253	-0.57826024	0.6942009	1.2589116	0.9615674	-3.521109	1.5010008	0.41754952	-3.0458503	-3.1275856	0.77170795	-0.1726592	0.4261074	-1.1048248	-1.8571298	0.12362935	0.35604754	-2.2610595	-0.94923097	-0.6945296	2.292107	1.0140232	-0.6507898	0.48815742	0.79740536	-1.9205339	-0.4933039	-0.3492776	-0.90537304	-1.2142417	-1.8192679	-0.39984775	-1.2205184	-0.9292643	2.532459	-1.4355443	0.0023555316	0.6788854	-1.2287863	-2.6843936	-0.6962072	1.2633018	-1.5066408	-0.9325592	2.1638525	1.9985043	-0.3802097	-0.2660967	-1.6371787	-1.1409299	-1.5065411	0.36368042	1.9691565	-0.69924974	1.9730369	0.8236732	0.21625918\n-3.007946	1.2351002	-0.9045594	-1.1262512	-0.07978716	-0.28265306	1.5832007	-2.071064	0.71359795	-1.1867086	-0.35674247	-0.44839302	-1.391847	0.9949595	0.86749494	-0.07017669	1.9788228	-0.16891842	1.7856048	-1.4444069	-2.0539892	1.4073372	0.04432645	-2.698564	0.038290232	0.55356497	-1.6908463	-0.6210198	-0.8188325	1.0771325	2.189032	-0.72034436	-1.099804	0.14675704	-0.60587084	-0.5953935	-1.1241194	1.5265396	-0.32323852	-0.65010655	0.43046707	0.5610771	-0.85050106	-1.4081105	-2.4885824	0.6623915	-0.82428294	1.7485698	-0.75639683	0.120571285	-0.15077977	-2.5822144	0.68714195	-1.7536929	0.6508427	0.9073432	-0.4608511	1.4160626	-0.29219136	-1.0374684	1.7836311	-0.38527852	0.64496565	0.19864595\n1.3766059	1.9593434	-2.1938376	-0.24066001	1.8283451	1.2857054	-0.8206019	-0.42413905	-2.9223623	-1.5924054	-1.2070626	0.78493184	-0.5505178	0.40397108	0.973381	-0.042516235	2.3277328	-0.19163188	-0.27105784	-0.60185593	-1.0403847	1.6550785	-0.27032387	2.5375662	-0.453734	-0.6533938	0.7462296	-0.61023456	-0.5193351	-0.053907014	0.5841308	0.8287776	-1.4286889	-0.25322068	-0.508784	-0.71394724	1.7345611	0.5449563	2.0395272	2.2407713	1.3111922	0.6750349	0.9631813	1.2562586	-2.1829185	-0.3765327	2.2644677	1.5254935	-0.63952166	1.2268542	-0.9255961	0.28694502	-1.0901768	-0.27301455	-1.87726	-1.1162269	0.9348482	1.3657196	1.7766517	3.0506558	-1.0958239	-0.011479933	0.25286844	-1.4898491\n0.9055312	0.7000444	-1.786229	2.100962	-1.4771811	-1.3370852	1.1506511	0.8006972	0.064689666	0.45297834	0.36835906	0.066296935	-1.6405313	0.1875395	-2.4908206	1.5312291	0.85065526	-1.027974	2.0376008	0.55374634	-0.5441493	-1.7186567	-1.3480977	-1.6961634	-0.9582289	-2.2813087	-1.4779676	-1.0126244	0.25366527	-0.3896493	-0.033523284	1.3943607	-0.25635168	-0.87812376	1.1813452	-2.1620407	0.6459938	-0.54082966	0.56161493	1.1701148	0.86156064	-2.1873002	-3.2830477	0.05744406	0.4968456	-2.2373707	-1.2288923	0.46805796	0.7582506	-1.2440678	-3.4142923	-0.78552336	1.1555492	2.3189087	1.4311862	-0.9398241	0.34094274	-0.22352052	2.5683534	-1.3930963	2.1071057	-1.3079256	-0.89506847	-0.6549978\n-1.2254236	0.48894396	1.2631581	2.2499256	0.53779054	-1.2146131	-0.14574027	0.51044846	-0.58682764	2.6604571	0.68897694	0.18939	-1.5251433	0.222667	0.025311375	0.40225726	-0.861592	0.67405814	2.3520286	-0.9672879	-0.21796301	-0.62622684	-0.6051902	-0.5601216	-1.8188736	0.58996326	-1.3991338	-0.8551756	-0.7614633	-1.074384	-0.34361228	1.1301409	-0.7754639	-2.7784178	-2.2996633	-2.165671	-0.34531617	-0.8445463	-0.014360514	0.11467124	-0.32866073	1.4894722	-0.058818027	-1.1846344	0.6470884	1.446509	1.0524905	1.7750049	-1.526861	-3.3420355	0.26857913	0.51234144	-1.526734	1.497562	-1.0264487	-2.1302464	-0.8759112	-0.31489742	-0.09222717	2.3326428	1.0616304	-0.67737025	-2.1064706	1.9851961\n1.8526434	-0.080398224	0.45939615	-1.8583611	0.8415735	2.9879863	-0.7216953	-1.2095892	0.36954284	1.8829899	-0.7287557	1.9856312	-1.5513387	-0.51858497	1.3542506	-1.2228717	2.2803612	-0.6206375	-1.1944755	-1.5781722	-0.3015174	0.0056522707	0.78347206	1.2376685	0.54382366	3.1667233	-2.82187	1.7684789	-1.0942433	-0.67324597	0.24032238	0.50225157	-0.5048431	-0.94428295	-0.89271843	-2.4382634	0.220277	-0.467566	1.2245373	1.0579346	1.9825506	0.89902735	1.292357	-0.2989176	1.5678331	-1.3877358	-1.5070145	-1.6989374	0.5298753	-0.8294685	-2.0176706	-1.1292214	-1.293918	-0.96247673	0.14433539	-0.3305126	-0.14189921	1.7580365	0.1984058	1.8182503	-2.7357132	0.9162349	1.4041691	0.07211092\n0.8925151	-1.3876506	1.2835436	0.61565715	0.07962653	-0.48356342	-2.0095866	0.11173198	0.68720114	2.0574596	1.4835256	-0.7696039	1.0534681	-0.7099889	0.12671064	-1.5057461	-1.3109324	-1.3765348	-0.37130553	-1.0091122	-0.3299556	-1.984618	-0.9236854	-0.88366944	-0.81807756	-0.9031062	-1.7276103	-0.3217173	-0.4576839	-1.0690682	1.1631608	-2.1960309	-1.4159414	-1.9216751	0.8047661	1.0593464	0.96523535	-1.256273	-3.4588423	0.47342172	0.14455913	-0.9141031	-0.3772906	-0.11582975	1.4272695	3.5450652	-2.015037	1.9099407	-1.8059148	-0.6268292	0.72209144	-0.8621579	1.2669983	0.6814636	-2.6855261	-0.6434297	1.1049466	-0.041429635	-0.9151914	0.18354042	0.8697895	1.1821964	-3.8600469	0.20093234\n0.39953446	0.21972989	1.9462249	0.40605813	0.098042965	1.1330317	-0.32149434	-1.4404887	-1.0803934	2.5528793	-0.35180235	-0.85574347	0.5931483	0.16388877	0.5959418	1.8936635	-1.603179	1.2941754	0.097104914	-0.43784234	-0.2567941	-0.056836963	-1.6012423	-0.1946625	-2.3834329	0.34140185	-0.3053711	-0.7851225	-0.27061564	-1.0309355	-0.3560733	0.15704428	-2.1233425	-1.0846537	0.15472755	-0.6624872	1.4593453	-2.7158465	1.8288397	0.5468368	-2.0997105	-1.5339533	0.39531922	1.1187671	-0.9859632	3.309765	-2.3392031	-1.2356709	1.9267938	2.9478207	0.5990212	0.32831714	1.5631407	0.26568615	0.7547202	-0.44247872	-1.5875515	0.4880467	-0.8568474	0.927766	2.1011703	3.2991805	-0.837941	-0.0732916\n-1.6008041	-0.11079935	-0.4854632	-1.0818024	1.765555	-2.4819438	0.20949635	-2.6603732	-1.0202281	-3.4785216	0.48654476	-2.1037285	-0.6933646	1.0645336	-1.0718375	-0.29830915	2.8956008	-0.09476793	-0.02464593	-1.2276249	-0.1555019	-0.89727503	-1.839859	1.584587	1.3199643	2.270791	0.49228087	0.32225183	-3.7417164	0.05677968	0.74955773	-1.1795613	-0.29403043	0.4951106	-0.40618646	0.43227082	1.4586493	0.8176219	0.25099182	0.055627704	0.8537954	0.2395172	-0.26737022	2.2528913	-1.045315	-1.3965755	0.35719633	-1.4565747	-1.1728659	3.039092	1.6943514	-0.35821828	-1.5195336	-1.2892306	-0.16624092	2.6435108	-1.649359	1.5449451	-1.647205	0.21786653	-1.0728517	0.19439039	-1.8221105	-0.33343908\n2.6117144	-0.65611106	-1.9505938	1.6749657	-2.1161087	0.3204127	-0.56943655	1.2760022	1.18957	-0.6505159	-0.6733504	0.20957984	0.3603967	-1.377695	1.3934689	2.8138316	1.3934556	-2.0154867	0.5755004	1.2924281	0.8623947	-1.7635099	-0.53076065	-0.9645083	-1.2661526	0.4527512	0.7630385	1.6326542	-0.35428846	-0.29057968	2.0703592	-0.61211133	0.52166694	1.1620449	-1.3700446	0.90616715	-2.767826	1.3151416	0.66031003	2.498284	0.39351806	1.7754116	-0.5565468	-4.5059032	-0.19175547	4.0813966	2.036144	0.64113593	-0.33125114	-0.090215385	0.82312477	-0.8302839	-0.58164334	0.8493416	-0.03508633	1.5156004	0.5712998	-1.3743153	1.5386841	-0.32413775	-1.1058158	-1.80072	-2.8501601	-1.8535719\n-1.8797446	1.2274903	-1.3828692	1.3323052	0.16758436	-0.9725915	-1.6262559	0.99568313	-1.9357632	-1.1772256	0.4678365	-1.1027421	-0.58858293	-1.3290675	-1.9976643	-1.3406388	-0.38981262	-0.7598781	-0.11232957	-1.2829494	0.72805023	2.1499262	-0.7030832	0.3829511	1.3533045	-0.4265351	2.8859034	-3.528201	0.19137335	1.3728789	0.7697782	-0.50227034	-0.41070098	1.9237494	-0.28448373	-0.7543032	0.45403728	0.4736729	0.51686007	1.9340359	0.10689444	-1.0654383	-0.8059372	-1.8031917	0.10500173	-0.44876334	2.239065	-1.3501209	0.404935	-0.6832607	0.14937948	1.1078621	-0.37157807	1.0243567	-0.35456592	2.560731	0.24283214	2.0718884	2.1256804	1.9385612	0.16765924	0.037046682	-1.2041194	-0.82832754\n1.5430367	-0.23245981	0.43474773	0.9223305	0.90019053	-0.7731332	0.25704038	-0.37526053	0.741948	-0.3195934	-3.134745	-0.76311994	0.1717328	0.06665527	-1.8733125	-1.2999353	0.7798274	-2.0422509	0.8172175	0.63819027	1.6852518	-2.27386	-2.5090806	1.2182508	-1.902423	-1.2951901	-1.3184859	-0.11659243	-0.058611423	0.7942301	-0.15612142	1.0997422	2.5951722	2.2178154	-2.3495831	-0.5830301	0.08641982	-2.7633362	-0.50425416	0.70660174	0.9269687	0.21452136	-4.475233	0.9728514	-0.09199186	1.1264544	1.4064546	2.40183	0.84447145	-0.114539415	-0.52304494	0.9987271	1.1814082	-0.25108874	1.3175503	-0.5579913	-0.09149774	0.30085218	-0.7805509	1.9063541	-0.62442064	0.027789304	-2.0177042	-0.4613126\n0.78137493	1.8985479	-0.29450464	-0.5324507	0.36372486	1.3605106	3.0468054	1.3018248	-0.5170931	-0.8163555	-0.6528748	1.5645742	-1.2069702	-1.6913673	-0.32689124	1.7395358	-0.3978417	-0.6138648	-2.781296	3.5716493	3.214008	-0.15351188	1.2953377	-0.960199	1.9563313	1.317241	1.0104716	-0.073882155	0.5225988	0.7388171	-0.21973445	-2.1616142	1.0043125	2.7693117	-1.5059869	-0.17873417	-0.49981394	2.5770638	-0.34307936	-1.2191429	1.1909566	-0.03745799	1.220479	0.5838819	-0.7908356	-0.3704305	-0.20411259	-0.93552005	1.0593272	0.34024388	0.83510214	0.15300177	1.7467679	-0.2924048	1.9654087	-0.009257177	0.7177458	-0.6456723	0.4125596	-1.863577	0.99590164	0.6134784	-1.2228249	-0.27274367\n0.43177304	1.720466	0.17368689	0.051240582	-2.8851202	2.1652503	1.7216505	0.6080606	2.9000428	0.10681025	0.36344463	-0.70796853	-0.038444277	-1.2918328	0.014058586	-1.5853505	-0.4132794	0.09580992	-0.9422988	0.045356076	0.35152647	1.3399017	-0.8283603	-0.6860282	0.33471578	-1.5539975	-0.15744177	-0.059843615	0.04560259	3.4932446	0.44753757	1.1012915	-0.2606981	-2.5228243	-1.327264	-1.0730116	1.789531	-0.8246396	-2.4884384	1.0278023	1.3451711	-3.0999377	1.3109878	-0.15748344	-0.4392492	0.17941575	-0.96038026	0.7359115	0.018357094	-0.59927475	0.5653186	-0.5832527	-0.25247458	0.9541211	-0.6590439	0.89644504	0.26242986	1.1390095	-0.62822825	0.8687096	-0.47624576	0.8442016	1.4540648	0.19786523\n-0.16365992	-3.4884796	0.14861126	-1.044723	-0.74754435	0.20362116	-0.86295885	-3.0257788	1.1530924	-1.0149137	0.2558455	2.3180747	0.28735945	1.944986	-1.0140473	-2.0877838	1.6328582	2.3806636	-1.5932647	1.0368428	0.62670076	0.96725726	-1.6997933	-1.5470965	1.552025	-1.9735888	-1.0269511	0.6537989	-0.85916036	3.0661151	-4.0390797	-2.1465657	0.26996842	-1.3271184	-2.1544948	0.7624998	-0.50897676	0.84094155	-1.2763202	-0.98530275	-0.24645661	2.2263494	0.7845607	0.21340431	-0.31601	0.35181224	1.6656458	0.8623534	-0.39587665	1.1175927	-1.5447465	-2.000051	-0.88880426	-1.0486442	-0.29486358	-1.2956717	1.5354282	0.47599524	2.786616	-1.4464978	2.5691347	0.23764567	-1.6317134	-0.40753946\n2.9339638	0.709991	-1.8013426	-2.085032	0.5443105	-0.09772825	-1.3426051	2.1843479	-0.4414408	-2.221549	0.8865991	0.09057137	0.12611139	-2.1775556	-0.1457863	-1.2765083	-1.13917	-1.3061968	-1.7052652	1.7379252	-2.2956264	-0.80389345	0.13095936	0.2842362	2.7637532	-1.5393026	-0.59543306	-3.123834	0.99694306	2.4253879	0.32203534	-0.7191895	0.8815081	-0.09336457	0.08760617	0.2558376	0.9601721	2.0613873	0.09328161	-0.61642724	-1.0620636	0.3474343	-1.2600596	-0.5668884	-0.26808274	2.0045137	0.17746782	0.6341923	1.6898497	-0.072084986	1.0297253	-0.3586173	-0.52743256	-1.5844241	-1.2445116	1.7996742	-1.8988887	-2.6755557	-0.008864517	0.8560432	-0.46591613	0.90818894	1.0003762	0.3517853\n2.1594145	0.5362566	2.9866884	-0.2459543	-1.6138105	-3.1953905	1.2955452	-0.42354062	-2.0455487	-0.2704768	-2.6980968	-0.91673875	-1.6613705	0.8189886	0.6510838	1.0486059	-0.8542465	-1.8231902	1.7233567	1.7793949	0.1597531	-3.3601148	-0.011167002	-0.8746858	-2.2097993	-0.42491114	0.76352257	-2.0558264	0.20054276	-1.2609309	1.0143758	0.2069527	0.17045383	2.3022249	0.85165346	2.2909143	0.54476684	-1.3207031	-0.05003873	1.5824914	-1.3547293	2.215591	-1.1960595	0.87863505	1.272116	-0.6646905	1.6692331	-0.94304985	-1.4069483	-1.2529341	1.2792501	-0.8367352	-1.1908314	0.22520506	-0.25834623	-2.886267	-2.6629415	1.552166	1.8489414	-2.0637631	-1.116158	0.15870512	-0.056160916	-0.71927357\n-0.7752474	1.9182901	0.90885836	-0.6521552	0.036819454	-0.9024579	-1.1030792	1.5154209	-0.4631214	2.0419378	0.2675789	-0.72115856	1.2328281	1.180615	1.9481331	2.1085439	0.9694409	2.3835185	0.86408764	0.87826526	0.25811067	0.32284328	-0.16876942	0.52553463	-0.019731512	-2.1859925	-4.265009	-1.1106871	-1.8803668	-1.7216456	2.5787826	1.314553	1.813226	1.461434	-0.020448089	-2.1614401	-2.8896868	-3.0983233	0.16307408	0.2103597	0.21127938	1.1914251	0.91019034	-0.56519955	0.7604916	-1.902179	-0.4721317	1.2798696	2.4265702	0.5880802	0.6005327	1.837921	-1.365844	1.638811	0.35399967	0.50031364	-0.349	1.3586876	-0.9237906	1.198422	1.072613	-3.167563	-2.555968	1.0516897\n0.045538943	-1.2996953	3.0421	0.06111075	0.515973	-1.0613692	0.4213593	0.9484713	-3.2068768	-0.66282934	-2.682403	2.3071449	-1.4386457	2.996695	2.0802772	0.046192296	-0.96713346	0.37632468	-0.26976573	-0.8936733	0.3712083	1.5337719	-2.1085565	-0.6358364	-0.27393878	-1.2610494	0.72475797	-0.9544401	-0.39477247	-1.1569967	0.031931125	0.33831266	0.87152225	-0.35960755	-1.1873173	-0.0010656829	2.6130753	-2.1578364	1.7420025	-2.323951	-1.760263	-0.547665	0.5600261	-1.9010385	-0.6869217	-0.20503792	0.9696287	3.2258914	2.3430634	0.7582964	-0.2526986	-1.8123738	0.74165267	-0.55504817	1.7780292	-1.7959809	-0.6036807	-1.6744996	-0.49243486	1.1303657	0.1645522	-0.39118516	1.7350394	-1.2951579\n-0.09916018	1.5096004	-0.7920525	-0.6856309	0.677574	1.1615765	1.0186684	1.6609417	0.4787757	-0.2637888	-0.13912551	0.25796285	-0.047540702	0.37289017	-1.0740306	0.7671838	0.22030197	0.9147594	0.44683802	2.2370343	-2.9772997	0.41518652	1.0093703	-1.4514279	-2.0587595	-1.3736033	-1.7921042	-2.122665	1.6651988	-1.5868919	1.447203	-1.3375582	-1.7737999	-1.046908	2.2612238	-0.9161319	0.14885302	-2.2416644	0.62442327	1.4677676	0.92695767	-2.0645096	0.5776081	-2.0288324	-2.81713	0.045223378	0.496643	-0.2982319	0.1527034	0.51924706	-1.3794062	1.6194347	0.4286744	2.5313013	0.77131224	-0.0151511775	-1.1640035	-0.14234309	0.033210043	-0.5681569	-2.7923682	-2.3196054	-1.8422549	-0.9480592\n2.5548832	-0.41864246	1.9028202	3.4068124	0.039277617	-3.5149999	0.9243184	-1.6063972	0.8843919	-2.6511276	1.209276	-1.1934242	-1.7038938	2.6476645	-1.1599603	2.2809396	-1.4721321	0.56982034	0.6520664	0.139599	1.8552556	-0.5478872	-0.99569774	0.008554043	0.97473496	1.9265708	-1.6058996	-0.78067446	0.484954	-1.1257626	2.5942955	0.04023174	0.36070186	-0.7567274	0.639486	-1.0124164	0.039712336	0.30652308	-1.8041519	1.6772305	-1.1486965	-1.3328285	-2.6163464	1.9736564	-0.87778455	-0.9378873	-1.9709874	-1.0982767	-1.2228254	-1.6084648	0.6673048	-2.0890467	-1.1122538	-0.13559774	1.922519	0.3612185	-1.466487	1.1905986	1.2123709	2.6440754	-1.1597556	2.055919	2.5508018	-0.45681328\n-0.7440265	-0.3689087	-0.7961681	0.40095642	-0.7277178	-2.0785813	-2.8607893	0.92302376	-0.081534006	-1.8374994	1.9422333	-0.45643505	1.1600462	2.0053067	-2.1286638	-0.36162972	0.262169	-1.7265967	-1.4171497	1.0393664	-0.8200962	-1.7987871	-0.27584165	-1.1478438	1.1883409	-2.3964252	-0.31823066	1.7040546	2.3287094	0.9922361	1.0021026	0.70739096	-1.6929638	-1.8547604	0.9976469	2.2510946	-0.31690517	0.7465394	-1.0111805	1.9364877	-0.8607637	2.5412958	-1.3013127	-1.3553067	2.1136436	0.43757966	0.15794052	-1.0949826	-1.0274413	0.47789234	1.8250923	1.630335	-0.75130135	1.5176991	-0.271564	-0.98153704	2.3096912	0.34620333	-2.0872207	1.833956	1.1819971	-2.0884895	0.98063105	0.017115412\n1.982131	0.30358237	0.47511142	0.24743463	0.5669479	1.650963	0.7411196	0.15248345	-0.43708357	1.7586039	-0.8101807	0.2772865	-1.7646283	0.10399949	-1.3523729	-0.2601462	-0.55762804	-0.26307693	0.7307838	3.0706656	-0.37852687	0.010585167	-2.1009665	-0.5928039	-1.1873099	2.1658332	2.6582577	-1.9490644	0.68242425	0.30601197	1.0403765	-1.3874167	1.2854925	-0.8329038	1.4358922	-1.0172371	-1.1411867	-0.7608786	-0.9786453	-1.1267521	-1.5248199	-2.1871626	2.8405378	0.81890404	-0.74199647	-1.7229228	1.1801633	-0.7285336	-0.57833993	-0.9951231	2.3105612	2.5961401	0.12524375	0.45934087	1.9870526	-2.5111723	1.2871729	-0.5471523	-0.04191485	-0.24411556	0.45175812	3.836191	0.69748914	0.6688768\n1.9475406	-0.4543471	-1.5311724	0.19514999	1.1940097	-0.21867655	-1.2610719	0.31467354	0.06813213	1.3411222	-0.105421074	-4.0235195	0.12262931	1.7615428	0.63131565	0.99457747	1.5472109	-1.277697	-1.8603588	1.720744	0.7042804	-0.5349028	-0.07770777	-0.5902979	0.8645131	-0.24601185	2.2164328	-1.3520901	-2.0428526	2.0627842	1.6839072	-0.9678897	0.07699597	-1.0493246	0.012224237	1.2675287	-2.116765	-1.113384	2.8752131	-1.4225082	-3.8938854	-0.6672452	2.245247	-0.79413384	-0.67365694	2.6929264	1.84328	0.24084923	-2.0269601	0.14761207	-1.7034149	2.1923592	1.8257935	1.73662	0.21631812	-1.175259	1.1641458	2.2514265	-1.0831491	-1.7484895	-1.1032383	2.9173284	-0.58649343	0.1365046\n0.55231726	-1.7471223	1.4166719	-2.070952	-0.2985846	-0.53686494	-0.6030263	1.1903852	-0.2164439	0.074818745	0.7302062	-1.1695611	0.5303348	-1.3544497	-0.47698316	-1.6664659	1.039971	-1.7062033	0.15273595	2.0322917	-0.4815942	-0.9690635	1.9285039	0.8107848	2.2052433	-3.0949843	-0.66420305	0.69240296	-1.6464573	0.34914505	0.17818317	0.73081195	0.8336549	0.29332715	-0.15601616	-2.0791018	3.337546	1.0444971	-2.5578125	3.0484884	0.6226596	2.0077095	-1.4335921	1.0312754	2.412847	0.12685461	-3.0131996	0.5868516	-1.2582785	-0.4183713	0.24951094	1.3604228	-1.3305964	0.99338484	-0.4009417	-0.499109	-1.3540025	1.3673027	-0.079070486	2.7673337	1.1892365	2.3930824	-0.99868715	-0.70780224\n2.3654966	2.1504242	0.014845645	0.27572402	0.34585524	-0.61753905	-0.89059514	0.056505125	-0.21344331	-1.494518	-3.1123967	0.6908921	-0.3259731	-1.3943626	-1.8784146	0.78069866	1.1713601	-0.76332074	-1.0412264	0.42110935	-1.8355606	0.10535479	-1.0255151	-2.01819	2.527041	0.92022115	0.5054518	-0.30519244	1.415709	1.5465579	2.1306107	-0.5882877	0.6661525	0.5230696	0.27516028	-1.4440432	-0.1628904	-0.69019717	-0.8674956	-0.9854559	-0.46260723	1.016941	-0.29531303	0.75373554	-2.6016626	1.2958306	-0.35873914	1.0244501	0.5723781	-0.36038938	-0.3220235	-0.5036097	0.1436167	1.4165105	-0.40245372	-0.53459764	1.6572286	1.7845091	0.4715256	0.9957511	-4.4170537	0.09882525	0.5437571	1.2754326\n-0.72402585	-1.373245	0.20675242	1.9501532	-1.146948	-0.7680341	-0.33675304	-1.2453446	0.10797814	1.0942968	-2.303601	0.59167784	-3.196993	1.315441	0.8210796	1.1691957	1.3325406	0.65900636	0.042339943	0.8185194	-0.5827114	0.39828417	0.08385402	-1.1043191	-3.0653024	0.28398085	2.9062996	-0.07731752	-2.2453985	0.23016492	-0.0026738965	-0.94505066	-0.6102253	-1.2608262	-0.48382854	-2.9008343	-0.2309986	1.8381028	0.61271995	1.2645342	1.8726217	1.6524644	1.6463457	1.0061699	0.5550755	-1.5805492	1.4880967	-1.2266573	0.8261393	-0.8756316	1.8556802	-1.2243415	0.24533933	2.877273	1.9335015	-1.2375892	-0.07577415	0.05247314	0.6055348	1.4490862	-2.5291789	-0.88499856	0.7015485	-1.1057506\n-0.6170706	-0.6774683	0.76260036	1.2563243	-2.396483	-0.18421996	-1.8013018	-0.45875594	-0.8264758	0.23614077	-0.83382803	0.3775835	-0.8279236	1.1164006	-1.5199839	-0.033601496	3.2907994	-0.31630072	1.3488946	-1.0424209	2.537731	-2.4183686	0.4288096	-2.1044033	0.84709436	0.545036	-0.65343475	-1.115487	0.4990464	0.2144699	-1.149488	-1.3908972	-1.8483633	-0.17482807	2.026026	-0.0228312	0.52206665	-0.4641886	-0.39128175	-0.457218	-0.2512693	0.034782134	-0.637929	1.4587984	2.1132374	-1.1515605	0.27121884	-0.97993255	-0.55208933	0.66505945	-2.5738554	-1.2607759	-0.21235523	-0.49880123	-1.82308	-1.5949881	-3.9007385	-1.0996188	0.2665946	0.0012415494	-0.58086896	-1.2039137	0.417177	0.72202855\n-1.9440149	-1.1091905	1.0792047	1.2577027	-0.109099716	-1.376844	-0.35204723	1.8110927	-2.3208342	-0.89795303	-2.7776036	-0.49710655	-0.79829663	1.3799998	2.0324004	0.4604782	1.6817565	-0.11474302	2.2025557	1.3432338	-0.04304104	1.7973379	-2.0749161	0.871315	2.5329	0.13285027	0.265482	-0.022002896	-1.0025816	1.9336879	-2.7843988	2.2882426	-0.6774005	2.3697562	-2.80584	0.80976766	-0.27436164	0.35249692	-0.66869044	-0.896719	-2.0448687	0.59307724	-0.5084412	-2.7902858	-2.268772	0.77760726	1.8834121	0.8179805	0.23472884	1.6000015	-2.770754	1.0020291	0.98428875	-1.8289584	-1.4874055	0.1010683	0.8572532	-1.1517105	-0.99034065	2.4347823	-2.521641	-0.07794743	0.7494482	0.38739973\n-1.0167383	-1.2337996	1.8834828	0.26383004	-0.07822824	-1.3386303	0.9164681	-0.3235505	2.629115	-0.37876114	-3.1721475	-2.1519406	0.7972675	1.4107188	0.19492337	-1.6362097	-0.0394666	-1.7035668	-1.434641	-0.0075087454	-0.5207516	-0.17343034	0.67998755	-0.029374735	0.30896065	1.7895716	0.20978402	0.37176523	1.8247379	0.4508533	1.3506701	1.8382163	1.6058496	0.09227542	-1.4643568	0.31592503	-1.645713	-2.8895319	-0.3106918	1.1201886	-1.5525746	0.69226027	-0.16220534	0.4738173	1.885137	-0.89985424	0.6782771	0.45780322	2.0478785	1.500314	-1.6338464	0.01608176	-0.014439005	0.52109593	0.5249274	-0.25289175	1.4017645	1.1139197	-1.2948966	-1.3663411	0.28068826	1.4250792	-0.1823542	0.1435462\n-0.8125851	-0.34006095	1.3625852	1.1688576	-2.4933598	-0.40402094	0.33639082	2.9737704	0.11370575	-0.937874	-0.74940425	-0.8796685	0.76885456	-0.2549612	0.5826434	3.3969343	0.9815932	0.7205747	-0.5356584	1.44809	-0.0898453	-1.2176256	-2.0964487	-1.465428	0.1302936	0.4297802	1.1919852	-2.5143566	-1.2351301	0.7951877	-0.4911198	0.41293818	-2.2668867	-2.052647	1.3890401	0.5879425	1.0578146	0.17144956	-0.4379901	-0.11157813	-1.6496745	-0.15251644	0.5439652	0.21358675	-1.1805128	2.2190242	-1.792238	-2.5418015	-2.9441717	0.25888765	1.1615993	-0.943583	-0.45061982	-0.9211433	0.32952702	-0.21758823	-0.94591206	-1.6926087	0.9001146	-0.7619071	-1.1803026	-0.3913184	-1.9450266	1.4160895\n-0.82853305	-1.6787782	-1.3149484	2.741456	1.1570406	0.04395825	-0.065782	1.1698154	2.3405423	-0.8636139	-2.0259614	0.18638164	-2.649979	0.5948448	-1.1413103	-0.67542905	1.7631153	-1.265942	1.4350203	0.0771403	0.45763665	-2.9346638	1.8253193	0.6019408	0.6234173	0.30816993	2.3366492	-1.493001	-2.0690322	-0.42210776	1.8125969	0.8018819	-0.082612686	-1.565701	-0.22920756	0.08709254	1.157301	-1.0697747	0.13147122	-0.62449735	-1.7253361	0.1293957	1.4035859	1.5681864	0.21491988	0.5825922	1.4833497	1.2522384	2.5995739	0.30087253	-1.1733085	1.0310133	2.2041154	0.16634743	-1.3685195	-1.3115332	-1.7642199	-0.7750335	0.02154595	0.47860172	2.396542	-0.96352184	1.8477372	-3.754258\n-0.17719871	-0.5613794	-1.796643	-0.6860986	-2.3824193	-1.5067856	-0.71446705	-0.5229566	0.44154012	-0.41741273	-2.4164784	-1.8548311	-0.45671788	0.7693385	-0.32758614	-0.76128596	0.36239985	-1.0592136	0.0737086	-0.021122271	0.31772172	-0.26327085	-0.09901583	-0.98540425	0.5599687	-0.09649485	1.1671143	4.305063	-1.0202433	-0.7700843	-0.42049932	-0.48324966	-0.69299144	-0.9384271	-0.40812224	-0.86030775	1.0924933	-0.972386	-0.51733834	0.40222082	-1.9526795	1.3007818	-0.45105377	-2.3226824	-0.3363226	0.4021744	1.2681317	0.17350873	2.0621686	-0.5374285	-0.7429849	-2.8626354	1.8786478	0.15491082	-0.008979965	0.902486	-0.060641598	0.2472894	0.6865667	-1.3757778	-1.2704675	-2.0414338	-0.96590126	0.48476735\n-0.38789445	-0.7956735	0.75816476	1.5141722	0.22215031	0.1332869	2.6294956	-1.4315307	1.9371784	-0.696583	-0.07899299	-0.95627177	1.6748381	-2.239942	2.9606035	-0.02965934	-0.0804096	-0.55574214	0.83553666	-0.28054023	1.5469065	0.1703374	1.1210802	3.5323832	-0.8519136	-0.31829113	-2.8591058	0.012929875	0.2561129	0.08043181	2.9782536	-1.0306405	-1.6533034	0.328184	-0.849508	-0.13935885	-2.023867	-0.96044064	-1.5379587	0.40170953	2.0705707	-1.3344284	-0.2709618	2.894026	0.15856567	0.76210994	-1.1072809	0.581649	-1.4269358	-1.9801941	-1.7844499	-0.1875194	-1.840787	-0.5847434	-1.0888015	1.123655	-0.5038106	1.83561	2.1786697	-0.07655566	-0.708911	0.061637707	-0.13345787	-0.14995272\n0.61763036	-2.7572973	-0.9210066	2.1759093	1.1282613	-0.58237284	0.20670073	1.5020274	0.26625976	-0.28701296	0.64413124	-0.42148578	-4.0240054	-0.19621821	0.9316275	-2.745095	-0.2939188	-1.5928968	-0.88350517	1.3278552	-0.9144101	1.9039152	-0.98977536	-0.06834624	-2.092532	0.34894747	-0.25727072	-1.6214367	-0.31000182	-0.21534471	0.20026208	-0.47716504	1.2850912	-2.6807623	1.0845461	-1.9860568	0.4295179	-0.5242419	3.2893355	-1.5012264	1.0217247	-0.9071734	-0.4133939	0.6821862	-0.1694318	0.57322675	0.17899641	-0.6750377	-2.5196352	-1.7616171	-1.2127184	0.3497418	-0.11003342	0.7162589	-0.379161	-0.48399442	0.7415134	-0.13874808	-2.0653	0.1601248	0.40821758	-1.8942684	3.178652	-1.1613699\n0.8612221	-0.66018045	-1.6173258	-2.0823283	0.5161477	3.6033022	2.0944507	0.19129384	0.61533105	-0.56495595	-0.2590992	0.38356084	1.9758127	1.7337823	0.03858168	2.3521507	-2.5655603	0.12596291	1.7888143	0.23746595	2.2882493	0.062480662	2.469526	-2.945649	0.5852279	-0.91362387	-3.7641876	-3.3848188	-2.7754414	-0.16917281	-0.9466596	-1.5398636	1.6233408	0.03173888	1.9485347	-0.70026845	-1.3107541	0.30612695	2.3778434	2.8706567	-0.6600177	0.08204678	2.0874317	-0.3769012	-0.03396343	0.2718092	-1.3261393	0.27009058	-0.1278432	1.420663	-1.3823085	0.7095917	0.6133904	0.13247438	0.07641045	0.4186026	-1.2384446	0.87593454	-0.36997306	1.8098086	0.6259496	-0.9713708	1.212648	-0.025505608\n0.3105036	-1.156258	0.40617496	-1.535915	1.9766964	-0.26473305	-0.48134783	-0.8912563	-3.5630515	1.2226218	-2.314721	-1.5574318	1.1298054	0.33758557	1.92845	-0.6874258	-0.70052665	0.4906988	1.9243609	1.7205764	0.57198447	0.8116602	0.28590295	-0.094656	-0.99282956	1.1615394	0.22193003	1.8812329	-4.21843	0.094800316	-1.6876651	1.155313	-0.36020222	1.0540532	2.692309	-0.036327835	1.1320175	-0.19560535	0.1649941	-1.9043114	0.7329574	-3.3003652	-0.6132412	-1.0238279	-2.6725667	1.5026903	-1.1583815	1.2030575	1.719043	-1.5402914	1.1530026	-2.1553075	-0.14660321	0.112797536	2.3963885	1.686115	0.8697608	1.5558041	-0.9485303	-0.77788043	-2.2741358	-0.47483104	-0.3275124	0.37594658\n2.019369	1.7451059	2.940135	0.6798146	1.2261885	1.2068218	1.2340035	-0.38506955	0.35341033	-0.37787715	1.2704121	-1.135096	3.7992058	3.3443549	-1.8527251	-2.1511228	-0.608362	-0.30143574	-0.44375384	-1.1122172	1.1781191	0.6047294	0.7032843	-2.2211008	-1.334421	1.4992964	-0.3265187	0.37190676	2.4979923	-3.0520217	0.7551442	-0.6121636	0.44937462	-0.46406803	0.21269344	-0.063805126	-0.9248777	1.3727355	2.9042666	2.0882974	0.65713894	1.6322479	-0.20135453	0.21831997	-1.0081944	0.15695341	-0.91052866	-0.666326	0.33528522	-0.04390204	-3.5161545	-1.7982334	0.9505256	1.1236916	0.50657266	-0.07183691	-0.76458997	-0.88783604	-2.2400563	1.1359314	-1.9027874	-3.682138	-0.14891496	-0.89711267\n-2.1140313	1.0155646	0.748923	0.18134996	1.5573828	-1.282994	-0.8792766	-0.121062845	0.5310013	-2.2835395	1.8604549	-0.26176414	-3.087794	-0.16978891	-0.5489274	0.3076525	0.8731205	0.5690376	2.981667	-0.81302965	-0.93385935	-0.56613773	-0.37363672	0.70293415	1.2592676	1.4730645	1.1756566	0.1561542	-0.4129653	1.141871	-1.1080298	1.6051333	-0.9206719	0.04976933	-0.45822075	0.7372279	-1.6659905	0.16458601	1.4436644	-0.101493485	0.4524979	-1.559524	0.66552615	-1.344342	1.6505913	-1.1973397	1.064272	0.1720929	1.2025459	-1.3510106	1.1766562	-0.037164498	-0.7694229	2.5155187	-1.0532163	0.24458793	-0.39311954	1.0216072	0.70156336	0.9298339	1.4989449	1.6405448	-1.8149709	0.18183003\n-1.6758142	-0.99396276	-1.3161724	-0.8860564	-0.6008506	-0.87216026	1.1345295	-0.2783599	1.4375081	-0.945062	-0.1119769	2.8132753	-0.5147538	1.8992991	-0.07855486	-0.4125007	0.03293675	0.5526579	-1.6099973	-0.39876345	-1.0575042	-0.363179	0.9288476	-0.6213782	-1.6717927	1.5809036	1.4290673	0.1973423	0.21135099	0.4152991	3.160482	-0.77793896	1.934658	-1.0267756	-0.34228843	2.1401024	-1.1359236	-0.2737195	-2.3605635	1.3921822	-0.48660085	-1.2694244	0.1466856	-0.29848164	1.04752	-1.2046841	-0.8739684	-0.052093107	-1.1545702	1.2827605	0.45539877	-1.0577297	-0.053496584	-2.7609417	-0.37313947	-2.7098386	4.104628	1.4378191	0.10905605	1.8671535	1.7786895	-1.5038838	-0.24907254	0.88111335\n0.6643509	1.1970506	2.7098641	-1.8104291	-2.0385616	-0.43166453	-1.1090735	-0.8202725	-2.785355	-1.2031811	2.1542685	-0.19064353	-0.24716459	1.599319	-1.4435413	-0.7604585	-1.0537748	-2.9919884	0.5504511	2.28308	-0.9732388	-1.2432455	-1.5386819	1.1928687	-0.20219472	0.33171362	-1.2392583	-0.6467441	0.13827935	-0.28501725	-0.10173728	0.06967802	1.4907387	-1.4808725	-4.3887606	-1.0862627	2.9619732	0.81176823	1.6373281	-0.48987603	-2.7837515	2.2662005	-1.125228	0.35958827	-0.06248615	0.6505282	0.8628082	2.162344	-2.0084722	-0.29056233	-0.53274626	1.5909605	-0.58940995	1.003158	0.5249204	3.7717004	1.8084244	0.934644	-0.41391933	0.30836296	-0.81289244	-0.25817654	-0.18699856	-0.86742145\n-0.28450388	1.3588239	-0.61413497	0.5198748	-0.9802472	-1.7196655	-0.3058431	-0.121241406	0.5704739	-3.0821292	-1.0347493	-0.8859822	0.026102878	0.6434993	-2.2796009	-0.60440975	0.7653843	0.43687698	-0.5212352	-0.9595417	-0.026487028	-0.6069018	0.65020823	0.046289753	-0.43441832	-0.82330793	-0.92942023	-1.9886508	-3.6017833	-0.030329471	-3.154761	-1.0653487	2.1414435	0.26265666	-0.6913287	1.6692685	2.5374408	-0.07416995	-1.3820035	-0.083608136	-0.49034342	2.0977168	-0.06825636	1.2789235	0.90271574	-1.3991278	1.3225901	-2.6833558	0.55653816	-1.2625406	0.25895256	-0.28482017	-1.215074	0.3054858	-0.48795602	1.6065823	0.6113628	-1.2728819	-1.3826046	2.1403148	-1.8882937	-0.9764595	-0.15001582	-2.946651\n2.690157	-0.15123887	0.49539006	-1.9551367	-0.14096515	1.1501527	0.15453042	0.09988216	2.4467275	-0.6132734	0.31773317	-1.1322584	-0.71716803	-0.3829332	-1.1097872	1.5803016	1.2549173	-0.42242795	-0.2484502	-2.4093664	0.8929408	0.99862474	-1.3461529	-0.2970354	-0.60031	-1.0128019	0.14972033	2.1298747	4.06331	2.067703	0.73235494	-1.0001738	0.6323786	0.0927339	-0.34386516	-0.43826053	-1.2871308	-1.5121735	1.4292986	2.296339	1.0473003	0.19207789	0.5479506	0.2918346	0.064346746	-0.9509648	0.9426412	1.0656213	-1.6909767	-1.1023468	1.2370176	-0.32429007	0.6249352	-1.0503451	-0.5555951	-0.098906815	-4.4958925	-0.9161091	0.6534367	1.7926072	-0.2958696	0.24089406	-0.529069	-2.5453293\n0.15042129	-0.4793632	0.26455608	1.9876087	0.088549905	-1.7857099	-0.07510283	-0.059121855	1.2178245	1.0262548	-1.5398384	-0.73695314	-1.0644661	0.12302343	2.2499826	1.5281142	0.16194361	0.36042777	-0.48413196	1.3543435	-1.4513563	-0.11667824	-1.1028739	-0.69487065	0.26900604	-1.3747083	0.05668497	1.0928379	-0.51132107	0.35028082	0.4887349	-0.69044095	-0.76275086	-0.85620666	0.66838455	0.28952718	-0.11551759	0.013054113	-0.99559504	-0.04885316	2.0289733	-0.032825917	1.2503476	-1.2523283	-1.6672455	-0.40415823	-0.367584	-1.1238309	0.37790868	-0.6800841	-1.142814	-1.2499015	2.179182	-0.05713696	2.138972	0.24959621	1.7897998	-1.4164773	0.0071963533	1.4917154	-0.3666702	0.9423276	0.65295213	-0.07744878\n-0.63444495	0.21207896	1.5870754	-1.1210048	-0.6387532	-1.6806504	-2.0390582	-1.7180494	0.058948316	1.479258	-1.5766062	2.8216267	-0.9224018	0.29311335	-0.08570624	-1.0203083	-0.5777037	0.11384573	-0.5343564	1.4989281	-0.78068715	-0.21551827	0.16264771	1.4412884	0.04498856	3.7698336	-0.42943007	-1.7936747	2.0392437	1.095015	0.14550097	0.3595008	0.47297984	0.69337934	0.2021568	2.3164783	-2.9019408	2.993947	0.15079643	-0.14011662	-1.310762	0.14618455	0.41782537	-2.3795547	1.4494408	-0.27238283	-1.6447572	-0.59099114	-1.9968727	-0.046872135	-2.7614167	3.3772922	-1.2859251	-0.5906872	2.1173797	1.8750618	-2.4446375	-2.2083516	-1.0858262	-0.83889306	-2.1590698	-1.7158793	-1.4144859	0.058842823\n-0.6042923	-1.2118694	1.0940182	0.46405238	-1.978264	1.9427545	-1.7256156	1.4065483	-1.9482503	0.030694993	-0.737599	0.45486382	1.718261	-0.1843162	-0.16064109	-0.63202155	-0.8026745	0.1620697	-0.43579334	-1.6779792	1.4114033	-0.7054769	-1.2846693	-4.469906	-2.1810951	-0.1844892	-0.35052612	-2.8348927	-0.47277853	-0.36958262	2.698467	0.05438699	-0.452236	-1.7991778	-0.0714405	-0.80339706	-0.14094092	0.36281908	0.39907512	0.60306686	2.528525	1.160192	-1.6479212	-1.2820383	1.6732322	0.57577056	-0.17420734	0.40204078	-1.7838548	1.3260343	0.7826481	-1.1555454	0.8431044	1.149715	-0.3282055	0.66024554	-0.69658595	-0.47400528	0.32142082	1.7274863	-1.0876205	0.6425281	-1.079729	0.05033041\n1.9645528	-0.2524223	0.26536354	-0.34481984	1.2018418	0.6472645	0.45545608	2.285588	1.0822098	1.8201017	-1.0895758	0.11346238	1.8562645	-1.8121986	0.21926723	1.7035766	1.0817977	0.3112862	0.48759508	-2.0007708	0.07896748	-0.6642636	-0.29608953	-0.72095525	1.7730806	3.2531135	2.1741095	-0.8491298	-0.73454124	-0.89508	-0.39065439	0.45646322	-2.0230312	-1.4467334	0.2627919	-1.3760899	0.25190234	-0.47714496	1.4643769	-0.99147695	0.27380633	-2.0201554	-1.171271	0.38796145	-0.5814227	-0.007820476	0.02171033	0.7474914	1.0821264	-1.609662	-0.45155868	-0.31298587	-1.1563866	0.7021966	1.2803603	-0.46715927	-0.610312	-2.5753975	0.41983762	0.5281105	-1.601046	0.69185555	0.58804536	-0.44718462\n0.13226154	2.5185843	-1.4203657	3.5519416	-0.74829084	-0.38844413	1.5645356	-1.8620557	1.185339	-3.4333975	-1.8708109	0.05237157	-1.0137132	-0.763737	-0.37077928	0.80803245	1.9589003	0.65485144	-1.3738698	0.020958163	1.1562426	-2.5646293	-1.1965294	0.21540624	0.42284092	0.14211524	0.44781348	0.5676937	-2.4400516	-0.26140773	1.631336	-2.9165113	3.912805	-2.9703212	-0.7675817	-0.16447477	-2.2350662	1.9273365	0.63873553	1.3001342	-1.13227	0.4623595	-0.07981958	-0.55200696	-0.771993	0.14059418	1.0132841	-0.086524755	0.1892873	-1.5150945	-2.1546462	-0.6916639	0.50014305	-2.774596	-1.5215218	-2.1495	1.3661512	-0.23648246	-1.9394693	-0.14041297	-0.07575993	-0.9166195	0.32079554	-0.9377957\n0.4994841	0.055258248	-1.2373968	1.2449719	1.3615538	0.3316118	-2.315253	-2.0105214	0.6753451	-1.4656527	-1.8513414	-1.4896795	-2.7926915	0.13541102	-1.3093553	0.20556156	-0.90344685	-0.31633082	0.17706448	1.5687579	0.6636891	0.32841024	0.7246702	-1.0849787	1.483969	1.9781702	-1.3703761	-0.6596957	2.6995292	-0.6335655	-2.596084	-0.021659585	-3.0131345	-0.8279672	-1.6930832	0.3212589	0.680171	-1.9288818	0.9534567	-1.3596197	-0.591829	0.6812217	-1.6367624	2.548297	0.06630627	0.750055	0.27538916	-2.2395487	0.1399915	0.13158597	-1.7717257	0.58521736	-0.70669466	-0.5415709	-0.010725362	-1.4063352	0.4714149	3.3166351	0.46783122	0.025025874	-0.55787945	1.8140001	-1.3263209	0.3691337\n-1.9373775	-2.0502717	1.5588878	1.5483111	-0.052675232	0.30330506	-2.753686	-0.07868537	0.7537738	-1.5373372	0.2712052	0.3904265	-0.5076583	1.9267086	3.4883318	1.9292386	1.3771005	0.25441265	-0.79300135	-0.23808314	1.3844413	-0.66650736	2.2119849	-0.14126025	0.72741276	0.2991808	-2.293744	2.20375	1.3816546	1.6103126	0.8797992	-0.73068225	0.970946	0.28234124	2.5238166	0.6090472	1.2726338	-0.46627346	-1.4104553	-1.2689903	0.76605844	-1.3905128	-1.7253926	-1.3110015	1.1560618	0.783226	-0.2952132	1.6900393	0.5586026	-0.88217145	0.78660935	-0.0983795	2.4091513	1.4260558	-0.80199075	1.204414	-1.0348632	-2.4307091	0.06843762	-0.4537721	1.3095514	-0.6300763	0.033024296	1.0142748\n1.3209959	0.18249762	-0.7578248	-1.5247798	1.095216	-0.0513525	-1.881999	2.3181543	0.45242205	0.15355752	-1.6171564	-0.764649	-4.647474	0.07956046	-1.100309	0.2358863	0.106482916	-1.6455851	1.0824509	-1.0259027	0.71275246	2.0423448	-1.2067902	-0.5520568	-1.4226295	-0.025009388	-1.186547	2.1949754	-0.2494775	1.7667301	1.9521637	2.5171204	-0.044383258	0.8363144	2.2018917	-0.35137978	0.36597225	0.473916	-2.205664	0.3270824	2.3667104	-0.3574382	0.103804745	-0.79795533	-0.9870445	-1.9468743	0.39423865	0.7617981	-1.789356	-0.3568335	0.8645207	1.7487234	-1.37714	-1.3677149	-1.26201	0.89733684	-0.68895334	1.858309	-0.5261867	0.95052147	2.1954713	0.68956244	0.049811106	0.9597897\n0.5372768	0.07396412	-1.4431112	-0.37214884	3.4127893	1.7680146	0.5733187	-2.411903	0.7806097	0.3092953	-2.168165	-1.1708027	1.2749897	0.4001565	1.015815	1.0515642	-1.2476255	-0.6850616	0.668793	1.1330216	0.90544516	-1.371485	-2.10356	-1.5016123	0.974633	-2.8818738	0.55924577	-1.2641435	-1.6185634	1.0665498	-0.08597277	-0.34282017	0.119852215	0.13571653	0.10756947	1.7748942	0.56987756	0.3996271	1.0384648	-0.22719193	-0.2401441	-0.22309984	-0.3502004	0.63614446	0.1193246	1.4088092	0.37275472	-1.1240333	0.5841161	-1.2982553	1.0342093	-1.4497736	-0.11043027	2.911743	0.43394187	0.34043604	-0.4270811	-0.39253554	0.08956869	-0.8008182	0.154662	0.8546351	-0.8618695	-1.4782382\n0.26850483	0.5897933	-0.26339749	0.83978343	2.511574	-1.4252424	1.1848598	-3.3148558	0.49166545	-1.4187478	-1.7567544	0.78470194	2.1364887	-0.46036294	-0.9506112	-0.20365943	0.2738845	-0.567819	-0.9248688	1.8212491	-1.0221361	-0.9930509	0.214992	-0.2170427	1.5616491	-1.0809169	-1.2951492	0.22111979	-0.5048177	-1.421809	0.016685003	1.246018	0.4799957	0.11549631	0.05389079	2.7454307	0.5342565	0.02898154	0.3362285	-0.466994	2.5178373	0.4918926	-0.30128568	1.5410761	-1.9308938	1.1691799	0.6326308	1.2965622	-0.023412816	1.6413959	2.9534538	1.0868993	-2.2753432	-0.3326474	-0.39547467	-1.6638759	0.112939514	-0.9101862	-0.5947089	-1.4700251	-0.276468	0.92847294	1.2569636	1.7507982\n-0.32820183	-0.3471449	1.5255799	-1.2480286	-1.6413761	0.1704253	-0.84149486	0.16898605	0.66666484	-1.0526216	2.1306744	-1.7132154	0.73608553	-1.3571339	-2.8966799	1.834983	2.572348	0.3663967	1.6793077	0.463622	0.5958057	0.84878075	1.6029012	1.4881968	-0.30111057	-0.051506396	1.5654212	0.4984337	-2.2662363	-0.53410995	-1.6378008	-1.7187494	0.6451037	1.7501987	-0.47381398	-1.2290596	-1.3074116	0.995137	1.4675373	1.1581157	1.8295742	1.7747598	-0.6558211	-0.40638703	0.19930194	1.4485112	-0.25047246	-0.8728162	1.1865225	-1.2489974	0.841248	3.3427022	0.42976558	-0.84860337	-0.5154623	-0.037991337	-0.21797685	0.29471526	2.326234	0.73876303	-0.6374883	-1.0907447	-0.47996885	1.4907671\n-1.727651	-0.57123625	-1.081538	0.26857692	2.5446815	0.858082	-1.0101465	2.22188	2.1035583	-2.6967797	-2.3970635	-0.7509806	-1.269748	0.97215676	0.20597838	-1.236819	-0.8897324	2.300625	0.88715506	0.9980503	0.22629854	-0.77837664	-4.7130375	3.454907	-1.4646267	-0.61069274	1.5529394	0.26777256	0.21526875	-0.20978184	-2.868205	-1.1913122	-1.8962784	-0.44050243	-0.7204478	0.96080077	-0.5807804	0.557099	1.1721045	-1.6544024	-3.631782	-1.3001993	-2.030354	3.1301367	-1.2719005	-1.1069205	1.565347	-0.58237207	1.5465769	-3.0265417	-0.16856077	-0.08091118	2.79295	-0.8550688	0.7327795	-1.6596485	-0.6273959	0.2686275	0.22217275	-0.9649257	-1.6110013	1.4982245	-0.5167434	0.29475942\n-1.8587033	-2.2647712	-1.7860291	-0.76263	1.7633604	-1.2675271	-2.1626592	0.26314285	-0.4188486	-1.1742492	0.9820468	0.79804695	0.5760362	-1.1516227	0.2948434	-2.4462137	-1.5365206	3.4260886	1.0428984	-3.1425734	-1.51753	-0.86098427	2.469914	-2.3951821	-0.4925453	0.08869362	0.50521743	-0.26913646	0.7538759	-1.141822	-1.1798548	-0.38452405	-0.7734437	-1.1334898	-0.27287653	-0.21425685	0.3767519	-0.49406642	-0.5118457	-1.6320747	1.1858666	-1.8518809	-1.4900941	0.42865515	1.1179112	1.6969675	-3.017145	2.9983873	-1.6684449	0.19719891	-1.5172689	-0.37219718	1.6417367	1.8084205	-1.7000461	0.77910936	-1.5182242	1.1375991	0.29453126	-0.14148141	0.56511647	-2.1708016	-0.42274052	0.4982701\n-3.3466969	-2.021935	0.8314869	0.6593966	1.0079993	-2.7241225	0.3277269	-0.5476079	-0.14921153	0.93469596	0.3467783	1.6314563	-0.4852052	-0.2885604	2.262432	1.1660135	-1.8288139	1.8675616	-0.3124861	-0.95230776	-0.42529497	0.73390603	1.5487207	-0.111803085	1.5933076	-1.7681824	1.1920537	-0.9525704	1.5435321	-0.20404582	-1.2166458	-0.27575454	-1.4916718	-1.9413172	2.3612924	0.91689694	-0.48460063	0.6432334	-0.55779344	1.5806613	0.3067947	-2.0183282	-2.3348708	1.9102052	0.80015415	1.6091285	0.50392574	1.8338835	-0.040195502	-0.020222507	1.9504969	0.19982675	-0.7302283	2.4396265	1.225727	1.4839073	-0.7407358	0.18405084	3.7799902	-0.7796059	-2.1709504	3.7479458	-0.33008903	-0.101765744\n1.2836654	-1.0162003	-0.8805113	-0.38014707	-0.34638345	1.4397396	-2.971318	-0.07117314	0.9126204	-0.96632403	-0.036186006	-0.48457605	-0.17355172	-0.23729639	-1.9602265	-2.2652204	-1.296246	-0.988763	0.5615073	-1.4819992	0.6642563	-0.16762908	-1.1273347	-1.6307604	2.165412	0.5556915	0.5638474	3.3051426	1.7847328	0.73359746	-1.1585236	0.6478372	1.1568	2.8077946	-0.9786923	-0.9856226	2.1609182	1.8748758	-1.0559647	0.7477002	0.32171908	1.6113527	1.9867612	0.27444538	-0.19915883	1.9465599	0.15668233	0.09008301	-3.6959414	-0.29457405	0.53684145	0.5484919	-0.16259676	0.7085302	0.69909716	-0.3255576	1.112172	0.15326354	0.9412703	1.3813897	-1.6322466	0.0675625	0.07852855	-0.4799583\n2.2465577	1.5537033	-0.789879	2.1255293	0.07441052	0.095360935	0.08782335	1.1669742	-0.3515232	-0.9737748	0.6988986	1.1240345	0.85915667	-0.37407923	-0.5870782	1.917454	-2.0632193	-2.1892369	2.5563338	-0.5020018	-1.2740314	-2.5300763	-0.27514443	0.54322606	-0.4800386	1.555423	-1.7406613	0.20861116	0.10664397	1.0870329	-2.3887396	3.714086	0.09975414	0.4702663	2.031332	1.9672865	-0.74916136	-3.8772092	-2.4357615	0.43656603	1.3964669	0.6103988	-0.59311557	0.8369391	-0.52122116	-0.04682486	1.2902343	0.32327637	1.4918191	-0.8157809	-0.67507607	-0.2590946	0.5876384	1.2564437	-0.027258512	-1.2794071	2.161649	-0.84122574	-2.095028	-0.010964056	0.15157446	-0.062116828	0.60181576	0.114359364\n-0.14481632	-0.51722544	-0.6227185	-0.20510265	-1.492811	-1.0527306	0.26389042	-1.294231	-2.6332157	-0.5990869	-0.27791208	2.9033766	-2.4628642	-1.5623556	0.5122692	0.6579724	-3.6739876	1.1969581	-1.5785899	-2.0254405	-0.33617878	1.1946319	-2.0465214	0.5953421	-1.5413854	-1.5849366	-1.2013413	-1.2800082	1.4396889	0.7787034	-0.23812	1.3236922	1.9045945	0.103702664	1.8079537	0.78835106	-1.2269782	1.672018	0.46647966	-0.47246152	0.6763687	-0.002836828	-0.43434435	0.005874662	0.5602949	1.079967	1.5540469	-1.7467978	-0.34566826	0.13972874	-0.61673033	-0.21090813	1.7068828	-0.10827292	3.7870815	-0.562423	-0.76199085	-2.481839	0.9506132	-0.76341635	1.4689907	-0.21675292	-1.5961628	-1.434821\n-1.6267346	1.4227904	0.42573696	-1.5057181	-1.4139724	-2.627493	-1.541514	1.947845	0.8345342	-1.2241727	-0.0069196774	0.5253796	-0.1678433	-0.16103263	0.6811017	1.4266266	1.6063945	2.752783	1.5176681	-0.079500616	1.116683	-0.33951244	-0.98289645	1.7770022	-0.26186723	0.31904152	2.2009294	-1.7446218	-0.3289461	2.9992628	-0.050175954	1.7817833	0.18525153	-0.05159576	-0.28870887	0.5894894	1.8529851	-1.481246	-0.71506137	-0.3870348	-0.8876958	-0.35206237	1.6438903	0.56297433	0.32213676	-0.62415206	-1.4373667	2.2451553	0.9471066	-1.4102135	-0.63617384	1.4103442	0.7260222	-0.14958024	0.7362643	1.5310858	-1.1650506	0.5386003	0.21430463	1.1530442	0.01619922	-0.97917736	0.8078545	0.13373148\n-0.8739638	-0.92192584	0.12473602	1.0068089	-3.1137238	0.11267085	1.5690944	0.48901108	-0.113731004	2.0855322	-1.3280985	0.68866706	-1.0712047	-1.3001454	0.89381605	1.5336179	-0.47789195	-0.18085346	-1.2384871	-0.49993414	2.199344	0.85115445	-1.0687584	-1.5459646	1.1174989	-2.2989671	-2.026105	-1.2220169	-0.015341617	0.075702846	-1.0500011	1.4313943	0.31123772	-0.8348475	-3.4347851	-2.658732	-0.4883291	0.15126655	1.9994389	1.1790931	-1.3103932	1.292286	-0.20434093	-0.35003293	-0.41927904	-0.5709673	0.68350786	3.0500991	3.5575695	-2.0429645	1.5577719	0.020255694	-2.05535	0.115250476	-1.7118207	0.7708088	-2.464033	-1.1752771	-0.7479646	1.5645748	1.1469042	-0.022857983	1.7616203	0.64978456\n1.3028394	1.3679305	0.301696	-1.3200094	-1.5709599	1.0019497	2.0743825	-0.6311358	-0.65329325	-2.569717	-1.8856825	0.5667867	-1.9492186	-1.8570453	0.043953847	3.0609858	-0.84076375	1.009634	-0.2076283	2.842163	-0.16348012	-0.00934587	1.7277519	1.0328085	-2.1162093	0.9735064	2.6794558	0.74319065	-0.19582266	2.0398982	0.53639406	0.30558676	-1.2207012	-2.978872	-1.6806456	2.0536275	-1.0611593	-0.6009007	-3.038142	-1.1805238	1.6908334	2.3811612	-0.14811757	0.9715966	-1.6166605	0.069453806	-0.45675606	-0.18075396	0.54050034	-2.4283128	-0.7754078	-2.6841078	-1.9897543	0.8083316	-2.2821777	0.94276494	0.079855405	-0.54273826	-0.022994647	-1.0415937	-0.9440531	1.4035778	0.73768395	0.07031012\n1.3640901	1.5087863	1.7154248	-0.00692018	0.038941972	2.2158792	3.0021555	0.5554951	-0.7187333	1.0525839	1.795051	-1.7706217	-1.0712622	0.041612282	0.019504365	0.19672556	-1.5944482	-1.5094539	1.1103665	-0.82656366	-1.2522718	-0.31160736	2.5693285	0.51730585	0.28823367	-0.00034316932	1.442271	0.687702	0.71829236	-0.8055556	3.5377693	2.000375	-1.575989	2.1638088	-0.18230857	-1.7869923	2.2192578	-1.4728608	-0.7304654	1.1732445	-0.6661766	-3.0180483	-0.09889658	-0.097792014	-2.2498102	-1.4109316	-2.3027382	-0.8763308	-1.4780862	1.5575615	-1.3514493	-0.37406304	-0.79138666	0.5533634	0.10887549	1.6478263	-0.31057367	0.3286816	0.8681608	1.2657077	-0.9970763	-0.2213008	1.9628233	-0.7648892\n-0.19388653	1.4348476	1.0188695	0.27536	-0.008129631	2.4747243	0.3930881	-1.6849668	0.3912805	-0.22476497	-1.111415	-0.66748756	0.5187653	0.31218562	0.8523069	-0.71818787	-1.3477991	2.9659476	-0.2623353	1.2725885	1.8129436	-0.69753164	1.4093966	-2.8385813	-1.1580528	-2.4994023	0.66141814	0.3559522	2.8560195	-2.000155	-0.6254951	-1.9046472	-0.22818187	-0.37286213	0.58357316	1.1586932	-1.952316	-2.0721521	-0.03048694	-0.20013271	-0.6056614	-3.307734	2.3112347	1.1221304	-1.4389831	-1.1678009	0.7003014	0.6522904	-0.31882307	-0.92657673	-0.9177297	-0.88552123	1.4658115	-1.2238693	-0.27996835	-1.7193881	0.14151847	0.93159646	0.527819	0.54602635	-0.05405893	-0.2732356	1.3574903	-0.23408933\n-0.11750836	0.20904593	0.7426682	-0.2587225	-1.5738117	0.34219357	-1.2107266	0.41476288	0.6680879	-3.5523105	0.116267025	2.3206947	-0.27643773	-0.57878315	0.10363308	0.5820043	2.6211188	-1.2557153	-2.7777271	-1.5932468	-2.000206	-2.2232053	0.9021936	1.1219566	-1.4009632	0.21742065	0.30435875	-0.38748282	-1.509813	0.79862577	1.1595252	1.0984459	-2.2712486	-1.8783021	1.3501313	-1.0557407	0.1505382	-1.2289926	-0.670589	-1.920609	0.46139306	-0.58865744	1.0973119	0.106961414	-0.4169481	1.3866276	-0.691847	-1.6687707	0.87834376	-0.7511014	1.1024588	-0.3757609	0.112017855	1.860265	0.6696719	0.34409434	-2.0309858	-0.74422747	0.9276075	1.6306834	-1.3845613	0.30203775	-0.68814653	-0.65204674\n-0.4826584	-0.13876942	-0.14712726	2.0103695	-1.7151115	2.6272748	0.03800839	-1.0823853	-0.8064172	0.90754944	-2.204618	0.9052938	-0.91188884	1.4765435	-1.2472888	1.5634779	1.8988315	-1.6859214	-1.3942837	0.9858282	-2.0088663	-0.7189105	0.31133083	-0.7763099	-0.2608648	0.87608904	-0.91978115	0.03737631	1.5665739	1.4584785	4.4470096	-1.6125001	-0.92685956	-0.61865103	-1.232743	-1.8728778	-1.9696546	-2.026587	-0.62942326	0.7486287	-1.3278829	1.4973346	0.05918666	0.31916505	2.7527869	-2.5012062	-0.098818876	-0.67052555	1.5421386	1.9150532	1.4712903	0.88805485	-0.18820743	-0.21248294	-3.6342046	-0.4825679	0.4056537	-1.6835517	-1.5921122	2.1653872	-0.78301394	1.0327263	-1.7455071	0.8676425\n1.2995191	0.5936181	-0.5411616	0.13886793	0.3003865	1.5872478	0.24160004	0.9474854	3.032626	0.4599531	-0.28955775	-1.3589535	0.5265882	-0.43175408	1.4632398	0.42049474	-1.3329682	-2.8502977	-0.21894802	-0.47600815	1.3850462	-1.793448	1.0180625	-0.88569653	-1.6668844	0.10489999	-1.059353	1.9918556	1.1737338	-2.4448328	0.43751863	0.3798664	-0.5785838	0.57205987	-0.46623433	-1.8120328	-0.79138124	-0.7349213	-3.2737732	1.6657906	2.9765835	1.258497	-0.016075702	0.2098073	-0.10466946	-0.9198689	-2.385847	-0.5681308	1.990774	-1.5934815	1.7133946	0.6088009	0.20083979	-2.4596877	-1.948317	0.6656656	-1.9590404	1.1890153	2.0252404	0.17490745	-0.8950367	0.0075600594	1.8677871	-0.24549793\n1.4138134	-1.495359	2.3890152	1.1570015	0.8346443	-0.23460908	-0.98639935	-0.13174383	0.82763505	-0.6738309	-1.8169911	1.5636156	1.0789695	1.3109881	0.74185294	1.0100307	0.23884135	1.7805923	-0.20748307	1.2578	-0.9004652	-0.26236847	0.51817155	2.1504116	4.0351567	-1.1585602	-1.0440457	1.7858851	-0.03976113	0.83193904	1.1571053	1.5213629	1.5056324	-1.7513196	1.1516776	1.3876723	1.0168322	0.50841993	0.41729537	-1.8244321	-0.39917642	0.9581582	-3.0922444	-1.0122412	-2.733032	1.7238542	-0.8499708	-2.0940273	0.08610111	0.33385563	1.5112927	-1.5623746	0.8874647	3.2930048	0.72743315	0.9180856	0.24486652	-1.5431602	0.73579186	-0.7880155	-0.6320252	-0.8465038	-0.2635374	0.5305522\n-3.6052237	1.3296998	1.1530825	0.8323451	-0.101021804	-1.7988646	-2.7120688	-0.20957878	-2.053283	-0.72313994	-0.012191244	-1.1413293	-0.2167644	-0.10261387	2.905538	-0.24497446	2.01667	0.42430696	-0.19929117	1.600274	1.0099999	0.20577765	1.3412358	1.533722	-0.47332954	-1.4664267	1.4884504	2.2625327	0.4960946	-0.61860406	-0.80008113	-1.1825582	-0.3507929	-2.6719456	-0.7317323	1.8410766	2.4859602	-2.3973806	1.4155228	0.18745364	0.9989475	-1.0070598	0.5131297	-3.1428452	-1.576695	1.6241099	-1.128505	-0.2327336	0.36927322	1.6309361	1.6814207	0.86038727	1.5651258	1.0456445	2.5382886	1.3047801	-1.1427233	-1.5528399	0.09584622	-1.2307429	0.9708606	1.1039366	2.5373902	-0.77715576\n-0.78101194	0.6533782	-2.232561	-0.4403286	1.0914534	-0.2983593	-0.9609712	0.042511437	-0.99203604	1.0589042	1.0515937	0.9310473	1.0776119	0.25957018	1.5525835	-0.51694083	-1.6469508	-0.87081695	-1.4195948	-1.3712258	1.6999383	-0.17934634	0.36814398	-0.5218254	0.55683726	-0.9167755	1.3573115	-0.24484433	0.2788488	0.78295976	1.0537488	1.685928	-0.5357113	0.092466846	-2.5034387	0.100799166	-0.42193952	1.602763	0.17728445	-0.22432357	1.0499289	0.9710157	1.2560183	0.07663304	-3.0189617	-0.8813405	-2.1517785	0.10267432	2.2614632	-2.2156458	-2.237526	0.575717	1.1298529	-0.117688335	-0.90516	2.135568	0.4261377	1.8340462	1.8988997	1.6931368	-1.2490613	-1.8716533	0.5190462	-1.4088838\n1.2377088	1.4155192	0.9525365	-1.0128012	-2.0264177	-0.52968866	1.7365626	-0.8265706	-1.1031871	-2.4584394	2.5301626	0.96989477	-1.0884727	-1.3254755	1.4834435	0.7641146	0.7012468	-0.11700602	-0.9928516	-1.9587063	-1.7057308	-1.921186	0.5305691	0.5526783	1.7885988	-1.5933336	1.3525938	0.57019275	0.71190715	-1.0361584	-0.9321016	-0.5829965	1.4912802	-0.08371793	1.665899	0.6145239	-1.5387913	-1.0511564	0.4683237	0.16169937	-2.897885	-1.4738907	-0.6355729	0.51615477	-0.2513632	0.17215389	0.0035240233	-0.11700046	-0.30648217	0.6254407	0.990657	-0.14003542	0.77691954	-0.30094612	1.9101475	0.32562032	-1.2804397	0.10590903	-0.59270954	-1.10116	3.399316	-1.545433	0.13630398	1.2688841\n0.5667707	2.195222	1.9815569	-1.7362946	1.2943323	-0.37036622	-1.028498	-0.87117696	-0.29754516	-2.257074	1.426358	-3.4822063	-0.6329413	0.8330947	2.0085104	-0.32919422	-0.4502093	2.4416268	-0.07343111	-2.4575415	1.8218479	-2.806447	2.3905404	-0.4321612	0.28729552	-2.210784	1.1952865	-0.63331497	-0.9203131	0.3600237	-0.4933754	-0.85369766	-0.33517423	1.3760172	0.74242723	0.017623411	1.9004751	1.7822437	0.42095405	-0.112177566	-3.639393	-1.1122705	-0.5309245	-0.7755962	-0.03485503	0.2553744	1.2991254	0.806312	0.42518523	-1.0645108	-2.6720586	-1.5049661	-0.1890996	0.307861	-2.7273505	-0.021081125	-1.7137775	1.6254944	1.229321	-0.32156873	1.0941949	-0.7224913	2.0559757	-0.7198588\n0.33438495	1.9391055	0.17135692	1.6853353	0.384108	-0.1818641	0.14085689	0.35472262	-0.22244117	-1.8405379	1.673759	0.93882155	-0.34484512	-0.29130712	1.3450212	-1.454805	-1.2103362	0.5999775	-0.75951666	-0.42255375	-1.6761177	-0.6933069	0.7938359	0.69021225	-0.8423056	1.5432656	2.361666	1.4644561	0.8581316	-1.830267	0.84220475	0.9715649	-1.0867184	-0.4634733	-0.32685044	-0.7968136	-1.4369495	0.9787258	-0.21710756	-0.653876	1.2146018	-0.302196	1.3997587	0.09738968	-2.1802547	-0.62936795	0.26356444	-0.6694198	0.1413727	-0.14623095	-0.07294374	-0.03574113	2.3655741	-0.35382435	0.67662007	-1.1053766	-4.1092715	0.12645349	-0.6918165	-1.2244514	-0.57624406	0.9809351	-1.0026921	1.9900885\n-1.2253042	-0.035993513	2.7257776	1.9784983	1.4243644	-0.6197151	-3.3524308	-0.09388885	1.0853565	0.3836381	0.052086625	0.9537794	0.8346053	-0.8845762	1.0236899	-1.4506462	1.8312961	1.8951674	-0.29372486	1.3353338	1.1159462	0.29699513	0.2273282	-0.8769219	0.25907692	-3.469539	1.7031345	-2.492628	-1.5896577	0.60876733	0.20978233	0.40149584	-0.86391	-2.301333	0.8481313	1.6734989	-1.0593475	0.07333166	1.1435694	0.46018574	1.6540625	-0.38599148	1.1562341	-1.9950492	-0.47630855	-0.37420416	-0.60506225	-2.5333788	-1.6585608	1.0324312	0.027740974	1.270204	-1.6513	-3.697774	-0.047031265	-0.7956238	-0.82906556	0.429508	-0.45218253	-0.40668976	0.05267823	0.4598421	0.75588065	-0.72001404\n-1.0921588	-1.766343	0.19674033	-1.141244	0.019712713	0.55313855	0.5521452	1.4481134	-0.07935693	-2.2581913	-0.04208453	1.6530026	-0.281531	0.63093346	-0.74984145	3.3524845	0.11444773	-2.3456821	-0.040201392	1.7825739	0.044625837	0.6270821	-1.5255774	-0.7762826	0.1824102	-0.7586344	-2.0685778	-1.096287	-0.6461279	2.151353	-2.295457	1.6845143	-0.16148265	2.6968668	-1.356305	1.763613	-0.32667813	-0.40555844	0.00858751	0.3704008	-0.4405997	-0.54264164	-0.9311563	-1.0959221	-2.2036736	0.96076506	-3.900657	-0.21993127	0.59377897	-0.29663897	-0.5341986	-0.25538597	-0.7692744	2.2813475	0.6039217	1.5542455	-1.5261546	1.2387416	-0.0031107285	0.19282435	-0.9346237	0.23519585	0.70514417	0.72610337\n-0.36538368	-0.99303037	-1.517705	0.96167696	-3.2532263	-1.714001	-0.013775122	-0.8149737	-1.96219	-0.40982547	1.2419617	0.26563287	-2.1595454	2.010155	-1.3318655	0.9957703	-0.37325874	-1.5384645	3.1556711	2.134063	-2.1608145	-0.031204907	-0.23993903	1.1647475	-0.29166263	-0.8388365	0.2484149	-0.89378023	-1.0347052	-0.50799793	1.248211	-1.1534749	-2.3968182	-0.87650675	-1.5082898	1.7150861	-0.7553661	-0.19854178	-0.88337743	-0.21398391	-1.8918475	0.17252955	0.02378569	-0.29784504	2.6371102	-0.68947405	-2.0228708	0.011329347	0.5033747	0.5308149	1.4710976	1.3342124	-1.0371778	1.0996255	-0.87078285	-1.8906962	-0.43989724	-1.9906591	-1.4737997	-0.34283715	-2.8344293	0.25772908	0.5084072	2.4645422\n0.7751696	-2.2322612	-1.7626431	2.3177164	1.0580603	-0.7918664	-0.59088635	-0.4368108	1.1751845	-0.43743867	0.9881899	-0.3773897	0.8450441	0.88052976	1.782924	-1.8767798	-0.10463889	-0.5605753	0.029481212	-0.044896144	-3.3436296	-0.19510876	-1.858295	-1.5813161	-1.2858436	-0.68408924	0.9529393	0.6341885	1.4280077	-0.9018195	-0.3302188	2.1287222	0.18077813	0.5967053	0.88608915	-1.1509815	-0.45775506	0.24765296	-1.1166335	1.8844678	-0.3441144	-1.4500135	-0.9681328	1.8849127	-0.08132482	-0.72367513	-0.6751797	0.39182198	-1.3558149	1.3609457	-0.92701775	-0.22051199	1.1616969	1.3584169	2.700156	0.05794131	1.0290112	2.5036304	2.1206486	0.508931	-0.90053177	-0.024361936	0.77400315	0.5566993\n-0.635386	-0.82646894	-1.7625315	-0.56839675	0.44506928	1.0677762	-0.33383256	0.5875388	1.3042775	-1.5370142	-0.20402296	0.2727363	-1.2208966	1.7644076	-0.89419234	0.44302222	-0.9195803	-0.98311967	-0.28893945	-0.3297596	-0.50848144	-3.9984848	0.086997904	0.34721404	2.208566	0.76513076	-0.01096856	-0.31339005	2.6244166	0.10198649	2.6918867	-0.31428352	1.8376944	1.0509775	-0.87188536	-1.5705187	-1.0827512	1.0295504	-0.4958535	0.95356554	1.1343683	0.6940111	-0.034934048	0.6700854	2.0675318	-1.9281409	4.048812	0.13137391	-0.7120649	-0.51404023	1.8660935	0.244428	2.3757193	-0.28114673	-2.9684792	-2.2820182	0.64696217	1.2040943	-0.5561873	-1.3290961	0.6455582	-0.7836817	-2.5360763	-0.9908732\n0.6648036	0.16029648	-0.88567185	-0.924566	1.9117761	1.0601761	1.9133972	1.9919741	0.34982446	0.5207617	-1.0766107	0.04813497	-1.5581744	-1.1328113	2.177037	-1.6789156	0.6146982	-0.14830005	-2.1513338	1.5119106	0.19649188	1.9966007	0.40241113	-0.2830759	-1.306422	-0.6073167	1.4086264	-2.2186697	0.88184804	0.6910516	0.53748935	1.9357396	1.6613673	1.1009979	-0.9357894	1.9212445	-2.168034	-0.27694243	-0.67654717	0.37410042	-0.04057619	-2.1607468	1.9394027	-0.82522744	-0.31021377	-1.4916437	-3.4223294	0.5840498	2.2371516	-0.8860089	0.42505017	0.322699	-2.4237287	2.0017836	0.57766277	0.103975646	0.961136	1.2513748	1.0533978	-0.47062075	-1.0783968	0.35424528	-1.6308576	0.022681406\n1.6771915	-0.7733046	0.5976155	-1.6226854	0.24755332	-0.56945837	-0.6279066	-1.2865053	0.30133498	-0.8135459	-1.2288495	0.011484259	0.62349147	-0.5049733	-0.9348472	2.8765218	-0.7242556	-0.65493906	1.9646195	-2.4259562	-0.2711548	0.3819025	-2.1130912	1.1636286	2.814989	-0.51642114	0.98924977	-1.8907163	-0.42380622	0.20619549	-1.9680034	0.54105663	-1.7378834	-1.648254	-1.5106713	0.7771634	-0.47860423	0.40259475	0.30247495	0.99078375	-0.35818514	-1.1229082	1.1558653	3.4377496	-2.3671892	1.2819312	1.8446094	0.47149444	-1.0648832	-1.3093638	0.88878596	-0.6172958	2.087894	-2.260625	-1.3852736	0.6412074	0.22428411	-0.78015685	-0.36238062	0.9212008	-0.41408277	0.44781223	0.120728664	-0.72201145\n0.16103692	-2.392316	-0.39097485	1.1725345	2.4180224	1.6111599	2.4769413	-0.6005763	-3.1887925	-0.23658681	2.0497916	-0.5814012	-0.8138731	2.485358	-0.43490958	1.285287	0.8541566	-0.04359328	0.687314	-2.1899085	-0.77461135	1.165703	-3.7159767	3.0586092	-0.09473085	1.1104996	-0.045223366	2.0748916	2.7776182	-0.36361152	-2.3874004	-0.5443579	0.9907999	0.22031826	-0.8610128	0.003977139	-0.5262037	0.42927152	3.9082496	0.4305733	1.7806503	2.1827285	-0.38344717	-0.5468603	-1.0272344	1.1808822	0.3564761	-0.009782714	-0.42266527	-0.6095933	-0.566212	0.3974605	0.55576134	1.3405709	0.013507102	-1.1040084	3.470637	-2.7701015	-1.9457173	-0.4758141	-1.0922066	-1.1913989	0.014150912	-1.4766914\n0.571757	-3.8697352	0.72970164	0.9926987	-1.3826864	2.1717522	1.0970746	0.15927829	-0.016492842	-1.4349073	-0.0730354	1.0460478	2.3828506	-0.7267245	0.26868013	0.77901405	0.113341406	0.01584344	-1.1136135	0.5432719	0.6628239	0.6257214	-0.13398549	2.518177	-1.6161443	1.0628037	-1.1163223	-0.4435819	-2.20867	1.7364838	-0.17053878	-0.31448197	-0.40504384	-0.5674	1.451048	2.1470673	-0.8931402	2.0691533	1.9158232	-0.64005244	-1.5235431	1.016858	-2.9862819	-1.3791869	0.9789662	1.0121776	-0.3506403	0.4534428	0.5491643	-0.03647303	-1.9387473	-1.321273	1.3703831	1.2886001	-0.073959924	-2.1701663	0.8797339	-0.7857242	-1.2684984	1.2914263	1.9340485	0.67960423	-0.41336957	2.24097\n0.31320027	0.002130238	0.16969196	-0.7122139	-0.8432642	2.1016512	-2.677476	1.6094579	1.2093964	-0.036815062	-0.13281351	2.865228	-0.90716904	0.24136406	-1.2601771	-1.3905282	0.4558036	-0.6494861	-0.5032926	0.48689294	1.0108647	-0.24962749	-0.8655794	-0.8223819	2.8858757	0.56963015	-0.35765585	0.9684669	-0.84532857	-0.70239574	-0.0016989575	-2.2140353	-2.1592658	-0.39511433	2.3889706	-0.8687443	-1.960681	1.7745242	0.2863575	0.18934177	-0.31073606	2.061931	-1.7266475	-0.76630646	1.0587262	2.2210846	-2.5420656	-0.06013406	1.3014872	0.91209364	0.8580124	2.092944	1.6961117	0.21614087	-0.4362018	-0.8158399	-2.2242398	-0.15168686	0.36396274	0.003071038	-1.220983	2.0743732	0.18608196	0.6971173\n1.4713062	3.5632408	0.36378756	-0.75211394	2.5308359	-0.8451006	-1.5665914	-2.2817612	-0.10790221	-0.5380987	-1.0257658	-1.0777829	0.87103623	0.61158216	0.33439973	-0.9880048	-0.24216524	0.3888636	-1.5328711	1.7025174	-1.3174549	0.06585328	0.50313574	0.35642886	-1.6339515	0.531065	0.71384436	0.36951146	-0.5533042	-0.36037096	-1.6747004	1.4574344	-0.21219991	1.4109328	-1.1652614	-0.1814305	1.9301581	-0.64101195	-1.3127446	-1.5170122	1.496372	0.6866989	-2.4282124	0.17340048	-3.6870902	1.0705817	0.4893507	-1.1944361	1.2099609	3.860575	0.13142598	-0.33211458	0.88084793	-0.66416234	0.7354627	-3.1920028	-1.7331523	-0.26693463	1.000401	1.0020005	0.79600483	0.47870767	-0.78638023	2.0240316\n0.07076124	-0.30338648	-0.2175377	0.36360323	2.0971913	-2.0626402	-2.9685488	0.1129459	1.3596334	0.3850853	1.623374	-1.1466377	0.9379626	1.9687796	-1.1787562	0.8007848	0.7385258	-1.2262272	-1.3070471	-1.0053684	0.37201115	-0.6472346	0.6596682	-0.9195978	2.0031893	-0.5514362	0.96708524	1.3290079	-2.6461833	-2.578434	1.3420826	-3.2064571	-0.0634652	0.7907372	1.7438816	-0.08800475	0.39271817	-1.7135476	0.9404221	-0.42416817	-1.6990519	-1.3180966	-2.6297827	-0.9718147	-0.169533	2.5105476	-1.4344628	1.7714051	0.22383998	-0.3536759	-0.62927425	-1.3904469	-2.1672885	-0.46868572	0.41678357	-0.59829074	0.025596231	2.5487156	-0.20465578	-1.2938944	-1.3207235	-1.0319138	2.2958717	0.40296152\n0.60753983	0.33696106	1.8747523	-0.31769103	1.5491894	0.45193568	-0.08636231	0.5729138	-0.38231984	0.46941322	-1.1510917	0.8097005	0.9701699	-1.3485725	-0.26534307	-0.8423863	-1.219232	-1.1280433	-1.2882138	-1.254091	1.0153764	-0.6912268	1.1149839	1.6556244	1.7347454	-0.14246368	3.0491931	-0.41655633	0.510405	1.0445977	-0.67718786	-0.6384088	1.591062	-1.2614537	-0.680943	0.8793116	-0.2751069	0.14170074	-0.5558934	0.16487488	-2.3167925	-0.054644562	-0.487146	1.328701	-2.16305	3.5277247	1.8494537	-1.2292141	-0.5437927	-0.3898606	1.4660212	-0.43142062	2.5732195	-1.8363583	0.4879638	-1.0933537	-0.35329747	1.8403697	2.4637063	-0.56794065	0.18260354	-0.9392589	-1.3528662	-0.967002\n0.76206607	1.793942	1.3824152	-0.8727758	-1.4799347	-0.6581065	0.025265664	-2.3445826	1.87279	-0.33183637	-1.3524883	-0.6346727	0.1967228	2.218843	1.110887	-1.7607697	-1.5825311	0.425947	-0.0043664672	-0.041925907	0.17017587	-0.55191576	-0.7371637	0.2261847	-0.3042622	-1.6318257	0.71146715	-2.8787217	-0.16465178	0.80772907	0.46436748	1.466162	1.1959864	-1.8284698	-0.40760663	-2.0002248	0.030250316	0.011898842	0.5924276	1.4320244	1.4167025	-0.1834542	-2.6036496	1.839872	-0.9140124	1.3713058	-1.9987209	-2.2518666	-0.9265415	1.4563044	0.4593366	-1.0007248	-0.8590658	-1.0877298	0.8600234	1.166675	-1.701753	-0.68105096	-0.5304228	0.23288709	1.1112183	2.118852	-1.5278838	-1.6934593\n-0.24922825	-0.7430291	-1.2786069	0.31471783	0.09364511	0.98996353	0.838524	0.5569257	-0.35126916	-0.56785804	-0.26274398	0.86935383	-1.5858359	-0.878713	1.3852284	-0.802131	0.9395455	1.9716258	-2.57167	1.431435	-2.050016	-1.805284	0.88911843	-1.5648282	0.30272225	2.2316203	1.7188483	0.20341389	-0.7559647	-0.74665946	0.8585603	-0.29773557	-0.9808989	0.30288377	1.1695193	0.5007902	-2.447917	0.32530746	0.8936897	-0.80434644	-0.31030008	-0.720841	-0.10473382	-0.7062151	-0.73241806	0.66353655	-0.22451894	-0.72954977	-0.08905747	-2.540355	1.7764413	-0.16843411	-2.6818912	-0.55467117	-1.5661602	-1.1993451	0.98761773	1.8615499	2.2895045	-1.6029122	-1.0944979	-2.0448377	0.90083975	0.4701675\n3.1890125	0.9109552	-1.8168126	-0.7013943	-2.290311	-1.591856	-0.15054075	-0.39800146	-1.3159436	-1.1559242	-1.3481787	2.8171873	-0.384131	2.5835094	-2.3266938	1.5048522	-3.1420546	-1.9611614	-0.30457234	-0.69501233	2.3331013	-1.4085714	0.042231314	0.3678527	-0.25856647	0.7797693	-0.13463724	2.1212268	-2.5297546	-1.3766524	0.9127637	-1.050655	1.256326	0.58411336	0.7206012	1.056201	-1.2169906	-0.15337177	-1.1450969	-1.2758123	2.1686168	-1.2203753	0.9479492	1.0866115	-1.1601977	2.263537	-3.2051487	-0.41990623	0.6914107	-1.1070629	0.745483	-0.4239372	-1.027686	0.23285401	-3.2040708	1.0546156	-0.39729044	0.9957151	0.97253907	-2.972042	1.3059583	-1.3171847	0.52681595	2.2395191\n-0.27496514	-0.3878554	1.3982011	1.1080604	-1.9054283	-1.1005211	0.18134217	1.7969685	1.2375926	-1.0963748	0.9246179	-0.8184599	-1.5190805	1.4379133	0.890033	0.9201789	1.2173605	-0.5331662	0.3335357	-1.6538302	0.37482172	1.615828	-1.2495531	-0.25803202	1.0533648	-0.08814624	0.7480183	-0.8631881	-1.7342402	-0.6132167	-0.22306946	3.2757897	1.6087359	0.60749537	1.3433093	-1.38556	3.2270577	-0.71300036	-0.39375308	2.2168663	-1.6302794	-1.2712295	0.8320281	0.5260306	-0.5375037	0.19111973	0.83862287	-1.616105	1.57859	0.3015638	-1.8291435	-0.6858913	-0.88319784	0.4389105	1.5781821	-1.353962	0.7284749	1.3642441	-0.015388079	1.769778	2.0539932	0.30673328	0.45602718	0.47033724\n0.9753559	-1.0230471	-0.7181594	0.79988605	-0.3569892	-2.0461588	-0.9249677	1.7598327	0.40390307	-1.9222984	0.9051555	-0.053448197	-0.8372753	1.6472791	-1.3662955	0.6165798	-0.9844539	1.7441145	-0.5579578	2.4529893	1.592781	1.8287193	-1.3327805	0.8864792	-0.7429644	0.115357645	0.83694816	-0.56063956	2.102528	-1.1273308	1.1993676	-0.5809526	-1.5102744	-3.7427773	-0.6991867	-1.2027465	-1.011604	0.81837916	-3.4470785	-1.3501241	-0.46657175	1.7005779	2.081352	2.012092	1.5183502	-0.94124424	-1.0300258	-0.7251642	1.6311387	0.19324978	0.9848774	-2.712185	-0.6609314	-0.49524078	2.8153067	0.4113571	-3.556461	-0.78442395	-0.09710856	3.95049	-1.0029888	4.196191	-2.1583366	-1.5269208\n-0.65582246	0.5903513	0.59959555	-1.3207101	-0.30328804	-0.39110056	-0.3712275	0.5164814	-0.35097244	-0.7604446	-0.76256853	0.09081211	1.3073044	0.9813657	0.18382587	-1.0540427	0.87146574	1.6350868	-1.7477642	-0.71634483	-0.68184304	0.3841992	2.0940735	1.1570408	0.5699708	1.4086047	1.2475566	-2.2658343	-1.6862639	1.7820812	-1.2508708	0.8910506	-0.73215544	-0.14018488	-0.66697365	-2.6620011	0.71146816	-1.2185986	0.059129536	0.18214564	-0.032997895	-1.3176215	-1.4576714	-1.3790171	1.0247136	1.2958422	-1.8304592	-1.0701755	0.03088777	0.5240509	1.932392	-2.4013755	0.55355525	1.1553442	-1.3020203	1.7419611	0.7820951	2.3755615	0.5944428	-1.8431673	0.16895655	0.9589761	-1.3317459	-0.88163894\n2.3800125	-1.3363864	1.105705	-1.5186727	0.9243113	-0.20231186	2.0561945	-0.2648788	0.1862852	0.35069314	0.67138594	0.75438166	0.30134797	0.30038163	2.0743742	-1.2723603	-0.5837469	-0.8258335	-1.5283487	-0.5525823	2.458704	-0.42566082	0.654686	-0.6628859	0.6172187	-0.94564426	-1.6880581	1.4892323	0.59644586	0.31867185	0.80573326	0.8077118	-0.09530377	0.44264656	0.02795967	1.3802594	1.0978268	0.25177783	0.6946419	1.213802	4.333078	1.966324	0.22901548	-0.36071196	-0.043526523	-3.3338556	1.142634	-0.5947111	-1.498369	-1.3869725	0.63295954	-0.26488027	-1.6481775	2.2138844	-1.8530216	0.2801103	0.20959571	-1.8384614	0.68875045	1.8989817	-2.0954807	-0.9405803	2.3888712	-1.0519308\n-1.2036352	-1.7135292	-1.8867112	1.150944	-2.094564	-3.1391432	0.10443779	-0.42910495	-0.46502852	2.1779969	-0.70586604	1.7741859	0.76682013	-1.5196196	-1.2072717	3.8438287	0.514287	2.6545665	-0.8245101	0.32478425	-1.0267096	-0.1349378	-0.73142743	0.07418528	-2.2381942	-2.4985607	0.465202	-1.7123107	2.3311186	-1.0828787	1.5896664	2.3288825	-0.69535875	2.3152168	1.3896405	-2.607025	2.5999331	-1.5082625	1.1953365	-0.9070913	-0.30364454	0.39808378	2.3641393	-0.7781549	-0.5116919	0.32942945	-1.1449143	-3.196555	-2.3898923	-0.58420545	1.0774913	-0.6841043	-1.6254054	-1.0890688	-0.874232	0.47778493	-2.1959252	-0.6455496	1.564058	-0.017779125	-1.8269393	-0.18366347	-1.1887586	0.72890973\n-2.8333793	-0.73192483	-2.2529309	1.4547292	2.2568114	-0.38909072	1.3144302	0.38474888	0.2050804	-0.86490107	0.754017	-0.7515443	-0.5526905	-0.33518744	-0.40898618	-0.6400273	0.17754047	0.8499588	-1.1122341	0.7093521	-1.8833289	1.2682697	0.36876568	-0.7464753	-1.0317534	0.02753785	0.02394617	-0.863644	-0.025049621	-2.1265836	1.2148501	2.3506267	0.05775013	-0.423235	0.42484105	0.37134567	0.6088545	-1.7710567	-0.04144302	-1.0247221	-0.2563252	-1.2478712	0.0072747217	0.34738675	0.2000778	0.60767156	1.951153	0.12907957	-1.6044402	1.0806901	-3.1418536	1.8611223	3.1813242	1.064683	0.8070044	0.3869336	-2.8337185	-1.3468395	0.72386336	1.3066437	0.7950959	1.7494998	0.651385	0.44526625\n1.5274304	-2.6204789	2.554544	-0.034335196	0.96810734	-1.7851824	0.49276426	-0.94602394	1.4097451	0.7849152	-1.4077826	-0.98502415	0.060400654	-1.0094556	0.9277367	0.16791968	-2.4787805	-0.8458746	-0.9451618	0.9611338	-1.331782	0.5298783	0.7704117	-0.49723458	-0.36957183	-2.3012018	3.0923605	-0.95559746	0.71414834	2.7349164	-1.5125526	-0.0631289	1.0959799	0.18249917	3.0400012	-0.5971695	-0.52623093	2.174947	0.7225656	-1.4960725	1.0512856	1.5333138	0.83423996	-2.3728764	-0.5215273	0.14007112	-2.5985649	-1.2725183	-0.868113	1.9520704	-0.6310059	0.34310704	1.7805593	1.3253708	-2.0491498	2.1663544	2.1464286	0.26841044	1.3178873	-1.1790853	-2.558221	0.49844134	2.7193055	0.45266786\n0.49102646	0.6603447	-0.7278361	0.46236858	-0.8830002	1.1151866	-0.45598936	-2.0524287	-0.16822378	0.17855304	0.047731716	-0.16949177	1.2116141	2.3322713	-0.3534794	0.6915377	-0.7019701	1.8721054	0.121252015	-0.7494956	0.59033823	0.85769683	-0.6089547	-0.2973712	1.102481	-0.8697349	-0.78410757	-1.5776795	1.1449847	0.7224933	-2.5213983	1.1665648	0.5967884	0.4738738	1.9669983	-0.07222253	0.7386342	2.394521	-2.0742605	2.0874734	1.3346714	-1.2982004	0.35432133	0.13932264	0.2888171	0.42945933	0.90715915	2.2259583	-1.2952775	-0.221867	-0.80728143	-0.6944416	0.68234414	0.05710926	0.07622311	-1.7191702	-0.6542642	-1.2700638	-1.7134483	1.4005778	-1.0114137	1.0607183	0.46602604	0.14385334\n1.2676764	-1.1165338	0.6611828	2.1445327	-2.4992092	1.136349	-0.40371087	2.6551175	0.11407233	-2.4460857	0.12947005	-1.9493793	-1.0840588	-2.5929732	1.6030977	-0.92842	-0.8609888	-1.7103765	0.33661747	0.96846265	-0.17832881	2.4038885	0.09133637	-2.0214803	-0.89731175	0.039903246	0.5114209	3.2944272	-0.7429433	0.9982103	0.3875137	-1.725736	1.3674742	-1.9662812	1.4998709	1.5717732	-0.4158238	0.4625841	0.10033186	2.0000677	1.464285	0.37248302	-0.26567432	-2.149928	-0.53871375	0.4673885	-0.26321554	1.734877	-0.33544707	1.9343102	-0.03718574	1.06724	-0.22466569	-0.60089046	1.0926331	0.3488048	1.4557338	-2.5499485	1.8206133	-1.2094218	-2.4239442	0.4389522	-2.6927326	-0.8646713\n-0.62536395	-0.48192486	2.0894704	1.0095124	0.8522065	-0.2619447	-0.3156991	-1.5099409	-1.796734	-0.7538192	0.51108134	1.9677303	4.3229885	-0.12074321	-0.17279007	2.6372926	-0.40588436	-1.9560536	0.2691794	0.811962	0.78370035	1.2464517	-1.614076	0.38602436	-0.6375401	-1.3656049	-0.09727935	0.11332629	0.46718088	0.24000132	-0.31152508	-0.175974	2.00641	0.58219165	1.994984	0.6809271	2.0887265	1.0961176	-0.5666407	0.9981298	1.4001789	1.5963417	-0.029374799	1.3700457	-1.3312504	-1.2580942	-2.4420323	-1.2381704	-2.0441046	-1.8418561	-1.7953987	0.023355914	-2.6052322	1.9592768	-1.281533	-0.9618612	0.18066636	-1.439784	0.6836169	1.4703263	1.3919135	-0.70225984	0.98258543	0.51226264\n-0.57032436	-3.4286575	0.8274098	-0.99218357	-0.80446815	2.5734293	-2.7009342	-1.8137155	0.65588474	1.0617748	0.2909405	0.5072126	-0.32971925	1.2682341	-0.93943024	1.9032153	0.96160376	1.1560576	-0.689138	-2.053737	-0.65268296	-1.8043077	-0.14859681	1.0511674	-0.89758426	1.3474905	1.5494183	-0.5254124	1.283928	1.0060112	0.7069106	-1.4041746	0.16877703	-0.90436727	-1.2056792	-2.356166	0.020388767	-1.0807128	2.4297957	0.83513063	-1.4407233	-0.15971237	0.34414783	1.77089	-2.8769946	1.1920959	-1.390326	-0.5468118	-1.7398925	-0.12281701	-0.5094455	2.3242462	1.0795987	-1.9763374	-0.14926726	-0.72042066	-0.11274545	-0.5923101	-2.4293213	-0.118884206	-1.2347215	-0.45665953	-0.33980995	0.4363033\n2.1022675	2.751849	0.1574356	2.5751028	-0.73642886	-1.2275282	0.8094209	1.9981314	0.6182724	0.006966894	-0.34182993	1.1954582	-1.6155887	1.0954226	-0.40936145	0.33993915	2.895355	0.30781668	0.97882855	2.6093225	0.9218384	0.43681777	0.72003525	0.38702983	0.45525226	-0.19162756	-0.21101387	-1.2003598	-0.77583444	-0.17872457	2.7235348	-1.0859836	1.0740838	1.1139321	-0.23850517	-2.4012277	-1.3829644	0.026371602	0.9031932	-1.3369243	-1.2821658	-0.030141601	-1.3627267	0.0575307	-0.6747194	0.49402386	-2.4850292	-1.6219732	1.3364651	1.3636725	-0.3851469	-1.745446	-0.6059615	-1.5291126	-3.5675132	-0.24214545	-0.6639776	-0.43214265	-0.8968252	-0.0660825	0.48018253	-1.0190544	0.48087022	-2.4441655\n1.030009	0.2402349	0.84151846	-1.3956717	0.1192264	1.2290459	0.2642484	0.71442485	0.6967157	-2.7537777	-1.6803365	0.26484823	1.1702396	0.29863194	3.2110665	-0.41471323	1.6798426	-1.380736	2.71517	-2.7093902	0.49401698	0.5385573	-0.58311844	2.631126	0.75512874	-0.15056515	-0.19375093	-1.7467793	0.5077737	-1.0318276	-0.30847764	-0.58807933	2.2094803	-0.45823446	-1.0438076	-1.6807718	-0.8037838	-0.27153316	1.1260897	-0.6129935	-1.933436	0.5734954	-2.1352887	-1.381501	2.3289707	-1.6399997	-0.1807477	-0.33222297	1.2677671	0.7072633	0.40900427	0.29514822	-0.4500661	-0.3263941	-0.012733467	-1.0493653	-0.40940776	-2.5984323	-0.94038373	-0.10434789	-0.5422621	-0.45735753	-0.753969	-0.7229345\n-0.5227976	-3.391858	1.5799261	-2.7036161	1.447268	1.4795303	-0.53978175	-1.0251993	-0.8146381	1.3961695	-1.8765613	1.7140732	-0.45081797	1.2849576	-0.422645	-2.1957798	0.26660085	0.7144909	0.86792475	3.3800273	-3.035573	-2.7050045	-1.5036777	-1.106989	2.2641447	0.07487806	-1.4008671	0.3406656	-0.9369408	-0.49942392	0.9266972	-0.032043234	-1.3839024	-0.8120119	1.7585486	1.8420542	-2.722992	0.81233627	-2.2017667	-0.6303871	2.1103904	-0.042745672	0.2322757	1.1236577	2.8530574	-1.5163335	-1.0218991	0.21926798	0.40930304	-0.09062187	0.2586032	-0.32938367	-0.634348	4.283433	0.99455404	2.722932	0.14477998	-3.376654	2.792019	0.95376766	-1.7230412	1.2244633	-0.48339695	-1.152233\n3.0620594	0.6229115	1.7915788	-1.0949363	-0.059973538	-2.01338	-0.4105298	-2.9840171	-1.7258431	-2.5896337	0.41973898	0.61492246	-2.622195	-0.008829593	0.040640738	-0.39790684	0.60784817	0.6499131	-0.13540305	0.12376362	-1.8927755	-1.4617829	1.4221095	1.29196	-2.5731976	1.7949655	2.6323814	-2.1235874	-1.9632274	-1.1718451	0.97632396	0.29868454	-0.3830593	0.40425447	-1.6705729	-2.449523	0.73751974	-2.8904707	-2.5956867	-0.39578763	-0.6163912	1.441305	-1.8405415	-0.047492553	0.9513607	1.0810465	0.43821916	-1.3619207	-0.7413803	-2.298196	-0.42016393	0.6844699	-1.3543689	0.11119029	-2.3138485	1.0134847	1.544567	-0.9468798	0.80803835	-0.2476508	-0.33061552	1.8857553	-1.2240992	-0.48785943\n0.17427215	2.09461	0.5730963	-2.3317354	2.0038912	1.5481211	0.8735892	-0.098838806	-0.6261838	1.3706986	-1.2321049	-0.8602877	-0.85038644	1.7867169	-0.3958845	-3.3517084	0.51282775	-1.7799817	-0.4610911	-3.2619922	-0.37274092	-0.63027954	-0.28944507	0.64775616	-2.1072836	-1.2377093	0.24197799	-0.6599815	1.1203167	-0.14808291	0.3510341	2.247319	0.32147822	2.4876456	-1.9728271	-3.8728013	0.31417683	0.90524805	-0.5623192	-1.837257	0.11965905	-0.5594968	-2.1914902	-0.76487195	3.773604	1.5991727	-0.42236316	-2.6399689	0.3359587	2.0306928	1.9165387	1.9438087	-0.9874562	-0.90867627	0.2970293	0.15228677	0.47228184	-0.12965752	-0.8266016	2.31987	0.5323303	-2.1200001	0.23243973	-0.48402247\n-1.6732118	-3.8104498	1.3609585	-0.635097	0.8116421	-1.6134223	0.2658898	-1.1546345	0.18574828	-1.4210938	0.43218473	-0.9873841	-1.3702905	-0.5168475	0.015051712	-0.9073526	0.3447562	1.7748564	1.539496	0.59875196	0.96258795	0.97542256	0.8980891	0.46584037	0.47806534	-2.1913316	-0.3553123	-0.39268258	0.24303867	0.47505927	0.07072988	1.7488186	-2.2283723	0.22013155	0.72951806	0.8681077	2.5889907	-0.18559967	-1.4875315	2.8253312	1.3609076	-1.1564542	0.78949445	-0.94977283	0.16429667	0.12651792	-0.04025232	2.4790258	-0.66102105	-0.88412017	3.0777633	-1.9457533	-0.29630652	0.5266281	-1.2504864	0.78024924	0.31494153	-2.160114	0.34500432	-0.74445635	-0.76984066	-0.4094228	0.48943445	0.19170809\n-1.9815508	-1.677499	-0.4826763	2.5894685	0.59892607	1.6445591	-0.18761896	0.4218962	1.1257559	0.42802408	0.28584707	1.3085212	0.93861514	0.22941422	2.7235997	4.0555167	-0.9332917	0.08753665	0.6324814	0.48449633	-2.2247894	-0.96411574	-0.58768547	-0.96942824	1.0488595	-0.5435196	1.3401176	-1.2935699	-2.142707	-1.3704615	1.2633723	2.4826872	0.64235175	0.31663552	0.5348078	2.0012705	-0.18372266	0.60756624	1.463027	0.88657343	0.8442506	1.6496524	0.14782354	1.2435834	1.3135803	-0.60154176	0.8108104	2.8019552	-1.7701249	-0.72479385	-0.87074953	1.7911195	1.019408	-0.47536457	0.38873672	1.4898794	2.7205725	-0.71477664	2.5540624	-0.32605466	0.0380078	-0.99085796	-0.9739733	2.5197887\n-2.0140257	0.7986933	-0.10667453	3.3485663	0.8140687	-1.3310945	-2.0186343	-0.956441	1.2887638	-1.575461	1.1315631	1.0255965	0.95105165	1.4040319	3.0228336	3.3172581	-0.36022982	3.910804	-0.76268107	0.6051331	0.6038788	1.290502	2.3955808	0.08310299	-0.51346034	0.7504711	0.8316495	-0.61254513	-0.243701	-0.41363642	-0.9922084	0.45386147	3.1856809	0.06688941	-0.48458222	-0.7404289	2.4271839	0.6844084	-3.744141	1.015069	0.9339821	3.9070587	-0.2311937	2.296486	-0.51103926	-0.106286585	-0.15986815	-1.236333	-0.2806732	-2.6769407	-1.044072	1.4750147	1.1389871	-1.3691071	-0.39927268	-1.8520273	-0.12693478	1.2267529	-0.38062847	-0.84353924	-0.805771	1.5493814	0.0140673295	-0.2001784\n0.33904815	1.0446291	-1.2605494	-2.3266191	-0.0043375767	0.31779653	0.9732676	-0.17240013	-0.075740784	-2.09844	0.23185955	1.7779791	0.36447716	1.8358655	1.4440042	2.0309358	-0.61945736	-1.1303136	-0.33245188	0.19403255	-0.2577297	0.23715717	-1.9082155	-0.05913069	-0.12685812	-0.9838109	2.083857	-1.4324279	2.137279	0.2148641	2.9316912	1.3890337	0.11779489	-0.9279685	0.601605	-0.9020732	-1.6354169	0.5068866	-0.27430168	-1.4822289	-0.19304326	0.8175584	0.10499817	-2.6219275	2.1853304	1.5897824	0.5423196	-1.156514	-2.0565279	2.7786784	2.3366227	-1.4863551	0.50447124	4.520857	-0.5413647	-1.1436695	-1.4888444	-0.07369398	-0.6561929	-0.110588655	-3.0289645	-1.6052537	1.8728459	0.3823868\n0.7495609	1.3591584	-0.67608505	0.6910985	-0.99437046	0.16296041	-1.6506915	-0.0038870876	-0.10047409	-1.5324969	0.5298495	0.21632445	0.9864715	1.696549	1.3520945	-0.5181514	-0.86549723	0.3435506	-0.6031389	1.0357928	0.9456206	1.7116219	-0.20303649	-1.9355191	1.6783005	1.97237	-0.40989625	-2.129705	-1.8373766	2.5002415	1.224293	0.04769004	-1.4505651	-1.0769595	0.46261293	-1.7525514	1.1681836	1.3515288	-1.8026992	-0.61308914	-3.0833874	0.09446159	-1.3297536	1.6680934	-1.0481958	2.0602126	-0.65495235	-2.0685477	0.3308896	0.4401706	0.48892775	-0.6297317	2.3860402	-0.79724485	-0.28555605	1.444685	-0.2010199	-0.48283222	-2.1278949	0.3772366	-0.9186749	0.0147409905	-1.3574324	1.6250615\n-1.5598621	1.2070675	2.092342	-0.8022012	-0.12893467	-1.7945389	-0.11710781	-2.5095212	-1.1703515	1.8228737	1.0556276	1.2354585	2.039836	2.3460848	0.43352148	1.0880625	-1.472154	-1.0643196	-1.9893528	-1.514559	0.45210993	-1.0673494	0.006854211	-1.8961136	-0.3991876	-1.727427	-2.45858	1.1332139	-0.29179052	-0.51964736	-1.8501899	0.34121996	-0.30008385	-1.0306424	2.1699855	0.644357	-0.6092254	-2.2804983	-1.3279648	0.06365832	0.9416886	-1.5672169	0.9088094	-1.1646478	-1.1743096	-0.5211171	1.6954453	0.31962186	-0.5721766	-1.8808109	0.4962756	-2.773476	-1.09683	1.249792	0.8863359	1.5338051	-0.107113145	0.54328656	1.8554515	0.5801173	-0.44221482	-0.2419343	0.37730968	0.6712278\n-0.52250504	0.5586628	1.4212968	2.6561656	-0.62624806	-1.5084444	-2.1613297	0.5858776	0.052582018	-1.3342931	-1.5027467	-1.0189432	-0.53362036	1.8115381	0.2473582	-0.99418366	0.2532188	-2.4523942	2.6363595	-2.9930022	-1.2036488	-1.6883012	-0.48109174	-2.0792851	-1.189803	0.07362952	2.788803	-0.25306833	1.3253127	0.6001472	1.8017627	-1.6759113	-2.5179305	0.08462658	-1.2667165	0.5952052	-0.34033257	0.38101003	-1.6826681	0.1624446	-2.0509639	-0.83838105	-0.71175	-1.3919277	0.014256018	0.17392516	-0.32091695	2.9809916	3.7398036	-1.3811706	-0.62305945	0.010974985	-0.5372423	2.3932853	0.68503076	3.315448	-0.7441977	0.85130215	0.4197405	2.160076	-1.874109	0.5521476	0.2070215	2.1618147\n1.018732	-2.400808	-0.056487095	1.080296	1.0843703	-0.16291852	1.4795196	-0.422038	-0.5407775	-1.6544331	0.49978936	2.0949476	-1.7768711	0.29473636	-0.8921301	-0.45780256	-1.9244848	-1.1252494	0.17434758	-0.43321767	0.55272675	2.112615	0.25168356	0.14035639	-0.8547256	1.0751901	-0.095835775	1.6714364	0.45168057	-0.2559814	0.761739	-0.3590849	-0.36924347	1.0915561	0.5616253	2.2774162	-1.9402192	-0.15748519	1.0935236	0.7469708	0.23107524	-2.1625185	0.78563654	-2.3433897	0.3321944	-0.6217097	0.28967714	2.6039476	-1.9631826	-0.1979914	1.4542928	2.088992	-0.31723085	0.1169595	-0.10648727	0.46310344	-2.2641482	1.7650785	-0.47630554	0.9468881	0.15285347	0.9501656	-0.21265078	0.0980279\n3.2841387	-1.5751297	1.6190692	-1.486137	0.840315	1.7847869	-1.585559	-0.029884564	1.2822698	-0.11937161	0.025202306	-0.21539144	-1.0000877	-0.9030811	-0.17644633	-0.10580417	0.8388346	-0.66149426	-1.45599	-0.43264517	-2.1306014	-0.35498416	-0.72662663	0.08521518	1.4473373	0.7307568	-1.1757145	1.601031	1.1885235	-0.2546224	-1.8227341	1.6931703	-1.985871	-1.8810344	0.41615954	-0.8683551	-2.279085	1.5321364	1.3631176	-0.93321735	0.78875536	-0.36868677	-0.40244117	1.6732215	-0.10165555	-1.8342196	-1.1605926	-0.5721716	-1.2369957	0.08504456	0.43194935	0.7274414	1.1033735	-2.9185088	-0.37715605	-0.38782334	-1.368344	-1.6459867	-0.046719853	-0.062472887	-0.6392285	-0.60276467	1.8169636	-3.9139907\n3.7074664	0.60138226	1.6221491	1.3287076	0.6413584	3.139077	1.4326403	0.022302793	-0.73789227	-0.5503039	1.2599641	-1.2397437	-0.11635834	0.2896138	1.4849995	-0.805354	-1.3699802	-1.2566282	-0.27971366	-1.2536049	-0.77130586	-0.017558265	-0.790734	-1.3652036	-0.5032146	-1.718295	0.03530765	-0.18967624	-3.8182545	1.2651937	-1.0545269	-1.9899491	1.2782503	0.0903778	0.69870013	-1.6149027	1.2877017	0.32181987	1.4520901	-1.8771483	-0.5475379	0.7085529	2.353137	-1.409046	1.2888653	1.4108183	0.9458619	-0.58506745	-0.31338614	0.12106925	-0.08961848	-1.3265164	-0.6940895	-0.7842135	0.67565	1.4448333	-2.2261174	-0.8123013	1.0908746	0.25538015	-1.3988612	-0.97298175	0.2361758	0.70578057\n";

  // hw4/client/dev/app.tsx
  console.log(bd_sents_default);
  console.log(covid_sents_default);
  var vocab = parserMetadata(metadata_default);
  var embs = parserVector(vectors_default);
  var sents = [
    ...covid_sents_default,
    ...bd_sents_default.map(([didx, sent]) => [didx + covid_sents_default.at(-1)?.[0] + 1, sent])
  ];
  var terms = [
    ...covid_tokens_default,
    ...bd_tokens_default.map(([sidx, token]) => [sidx + covid_sents_default.length, token])
  ];
  var tfidf = calcTfidf(vocab, sents, terms);
  var sentEmb = tensor2d(calcSentsEmbWithTfidf(vocab, embs, tfidf, sents, terms));
  var App = defineComponent((_, { slots }) => {
    let keyWord = ref("");
    let candidate = ref([]);
    let showingCand = ref(false);
    let showingRank = ref(false);
    let search = (e) => {
      showingRank.value = false;
      if (e.target.value != "") {
        keyWord.value = e.target.value;
        showingCand.value = true;
        candidate.value = vocab.map((token) => ({
          token,
          distance: levenshteinDistance(keyWord.value.split(" ").at(-1).toLowerCase(), token.toLowerCase())
        })).sort((a, b) => a.distance - b.distance).slice(0, 10).map(({ token }) => token);
        console.log("search");
      }
    };
    let embSim = ref([]);
    let calcEmbSim = (query) => {
      return tidy(() => {
        const qEmb = query.split(" ").map((term) => vocab.findIndex((v) => v == term)).map((vidx) => vidx != -1 ? tensor2d([embs[vidx]]) : zeros([1, embs[0].length])).reduce((prev, emb) => prev.add(emb), zeros([1, embs[0].length]));
        sentEmb.mul(qEmb).sum(-1);
        return qEmb.mul(sentEmb).sum(1).divNoNan(qEmb.square().sum(1).sqrt().mul(sentEmb.square().sum(1).sqrt())).arraySync();
      });
    };
    return () => /* @__PURE__ */ h("div", {
      class: "app"
    }, /* @__PURE__ */ h("br", null), /* @__PURE__ */ h("table", null, /* @__PURE__ */ h("tr", null, /* @__PURE__ */ h("td", null, /* @__PURE__ */ h("button", null, "tf-idf")), /* @__PURE__ */ h("td", null, /* @__PURE__ */ h("button", null, "tf-isf")), /* @__PURE__ */ h("td", null, /* @__PURE__ */ h("button", null, "tfidf")), /* @__PURE__ */ h("td", null, /* @__PURE__ */ h("button", null, "tfidf")))), /* @__PURE__ */ h("input", {
      type: "text",
      onInput: search,
      placeholder: "Search",
      value: keyWord.value
    }), /* @__PURE__ */ h("ol", {
      style: [showingCand.value ? "" : "display:none;"]
    }, candidate.value.map((token) => /* @__PURE__ */ h("li", null, /* @__PURE__ */ h("a", {
      onClick: () => {
        console.log(token);
        keyWord.value = [
          ...keyWord.value.split(" ").slice(0, -1),
          token
        ].reduce((p3, w) => `${p3} ${w}`, "").slice(1);
        embSim.value = calcEmbSim(keyWord.value);
        showingCand.value = false;
        showingRank.value = true;
      }
    }, token)))), /* @__PURE__ */ h("ol", {
      style: [showingRank.value ? "" : "display:none;", "width: 50%"]
    }, embSim.value.map((sim, sidx) => ({ sidx, sim })).sort((a, b) => b.sim - a.sim).map(({ sim, sidx }) => {
      const didx = sents[sidx][0];
      const sent = sents[sidx][1];
      return /* @__PURE__ */ h("li", null, didx, /* @__PURE__ */ h("br", null), sent);
    })));
  });
  createApp(App).mount(document.body);
})();
/**
 * @license
 * Copyright 2017 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2018 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 * =============================================================================
 */
/**
 * @license
 * Copyright 2018 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2019 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2019 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 * =============================================================================
 */
/**
 * @license
 * Copyright 2019 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2020 Google Inc. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2020 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2020 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2020 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the License);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an AS IS BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2021 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2021 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
/**
* @license
* Copyright 2018 Google LLC. All Rights Reserved.
* Licensed under the Apache License, Version 2.0 (the "License");
* you may not use this file except in compliance with the License.
* You may obtain a copy of the License at
*
* http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
* =============================================================================
*/
/** @license See the LICENSE file. */
//# sourceMappingURL=index.js.map
